<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>07/26/2010</start_date>
		<end_date>07/30/2010</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[Los Angeles]]></city>
		<state>California</state>
		<country></country>
	</conference_loc>
	<conference_url></conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES382</series_id>
		<series_title><![CDATA[International Conference on Computer Graphics and Interactive Techniques]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>1836786</proc_id>
	<acronym>SIGGRAPH '10</acronym>
	<proc_desc>ACM SIGGRAPH 2010 Art Gallery</proc_desc>
	<conference_number>2010</conference_number>
	<proc_class>conference</proc_class>
	<proc_title></proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn13>978-1-4503-0390-3</isbn13>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>2010</copyright_year>
	<publication_date>07-26-2010</publication_date>
	<pages>102</pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<abstract>
		<par><![CDATA[<p>The work exhibited in the SIGGRAPH 2010 Art Gallery investigates the polysensory nature of human experience in a technologically enhanced environment. The exhibition explores the permeable membrane of the techno-human interface, where we engage an array of tools to materialize and visualize artifacts of creative expression. Integral to the work is human haptic interaction, involving the "viewer" and/or the artist through a unique physical interface.</p> <p>Our sensory systems, like the aesthetic experiences they ascertain, operate simultaneously on several channels. Touch, for example, is not a binary system, but a complex structure of multiple sensory mechanisms, synthesizing such information as pressure, temperature, hardness, vibration, and weight. This sensory amalgamation is exploratory in nature, developing haptic awareness through the active combination of kinesthetic and tactual evidence. An object brought to the hand cannot be described like the one explored by the fingers.</p> <p>While the initial focus of the exhibition was on the sense of touch, the jury felt it was relevant to extend the breadth of sense experience. Therefore, the selected works include a range of sensory involvement, including scent and audio interactions. Some works are more solely focused on bodily presence, while others address the virtual hand in the machine. Overall, the multi-layered polysensory experience of the artwork has become the dynamic focus, forcing vision to share the pedestal of privilege with other sense modalities.</p>]]></par>
	</abstract>
	<publisher>
		<publisher_id>PUB27</publisher_id>
		<publisher_code>ACMNY</publisher_code>
		<publisher_name>ACM</publisher_name>
		<publisher_address>2 Penn Plaza, Suite 701</publisher_address>
		<publisher_city>New York</publisher_city>
		<publisher_state>NY</publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>10121-0701</publisher_zip_code>
		<publisher_contact>Bernard Rous</publisher_contact>
		<publisher_phone>212 869-7440</publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url>www.acm.org/publications</publisher_url>
	</publisher>
	<sponsor_rec>
		<sponsor>
			<sponsor_id>SP932</sponsor_id>
			<sponsor_name>ACM Special Interest Group on Computer Graphics and Interactive Techniques</sponsor_name>
			<sponsor_abbr>SIGGRAPH</sponsor_abbr>
		</sponsor>
	</sponsor_rec>
	<categories>
		<primary_category>
			<cat_node/>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
	<chair_editor>
		<ch_ed>
			<person_id>P2264030</person_id>
			<author_profile_id><![CDATA[81100643663]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>1</seq_no>
			<first_name><![CDATA[Lira]]></first_name>
			<middle_name><![CDATA[]]></middle_name>
			<last_name><![CDATA[Nikolovska]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[]]></affiliation>
			<role><![CDATA[Conference Chair]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
	</chair_editor>
</proceeding_rec>
<content>
	<section>
		<section_id>1836787</section_id>
		<sort_key>10</sort_key>
		<section_seq_no>1</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Art papers]]></section_title>
		<section_page_from>330</section_page_from>
	<article_rec>
		<article_id>1836788</article_id>
		<sort_key>20</sort_key>
		<display_label>Pages</display_label>
		<pages>10</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[The immediacy of the artist's mark in shape computation]]></title>
		<page_from>330</page_from>
		<page_to>339</page_to>
		<doi_number>10.1145/1836786.1836788</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836788</url>
		<abstract>
			<par><![CDATA[<p>This paper contributes to the area of computation in the production of artistic form. The author-artist describes a computational system in the form of a curvilinear, parametric shape grammar. Based on an analysis of over 3,000 entries in her traditionally hand-drawn sketchbooks, she describes the grammar that synthesizes drawings in the design language of her evolving style and serves as a tool for self-understanding of her artistic process.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264031</person_id>
				<author_profile_id><![CDATA[81100508902]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jacquelyn]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Martino]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Research, Hawthorne, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>96736</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[
P. McCorduck, <i>Aaron's Code: Meta-Art, Artificial Intelligence, and the Work of Harold Cohen</i> (New York: W. H. Freeman, 1991) xvi, 225.
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[
R. Verostko, "Epigenetic Painting: Software as Genotype," <i>Leonardo</i>, Vol. 23, No. 1, 17--23 (1990).
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[
G. Stiny, <i>Shape</i> (Cambridge: MIT Press, 2006) 432.
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1667261</ref_obj_id>
				<ref_obj_pid>1667239</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[
M. &#214;zkar and G. Stiny, "Shape Grammars," <i>ACM SIGGRAPH 2009 Courses</i> (2009).
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[
G. Stiny and J. Gips, "Shape Grammars and the Generative Specification of Painting and Sculpture," republished in <i>The Best Computer Papers of 1971</i>, O. R. Petrocelli, ed. (Philadelphia: Auerbach, 1972) 125--135.
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[
G. Stiny and W. Mitchell, "The Palladian Grammar," <i>Environment and Planning B</i>, Vol. 5, No. 1, 5--18 (1978).
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1360701</ref_obj_id>
				<ref_obj_pid>1399504</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[
M. Lipp, P. Wonka, and M. Wimmer, "Interactive Visual Editing of Grammars for Procedural Architecture," <i>ACM SIGGRAPH 2008</i> (2008).
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[
R. G. Lauzzana and L. Pocock-Williams, "A Rule System for Aesthetic Research in the Visual Arts," <i>Leonardo</i>, Vol. 21, No. 4, 445--452 (1988).
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[
J. Kirsch and R. Kirsch, "The Anatomy of Painting Style: Description with Computer Rules," <i>Leonardo</i>, Vol. 21, No. 4, 437--444 (1988).
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>572943</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[
T. W. Knight, <i>Transformations in Design: A Formal Approach to Stylistic Change and Innovation in the Visual Arts</i> (Cambridge, New York: Cambridge University Press, 1994) xvii, 258.
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1237150</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[
J. A. Martino, <i>The Immediacy of the Artist's Mark in Shape Computation: From Visualization to Representation</i>, Doctoral Thesis, Massachusetts Institute of Technology, hdl.handle.net/1721.1/37265 (2006).
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[
T. W. Knight, "Color Grammars: Designing with Lines and Colors," <i>Environment and Planning B: Planning and Design</i>, 16, 417--449 (1989).
]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 The Immediacy of the Artist s Mark in Shape Computation Jacquelyn A. Martino Artist, researcher 19 
Skyline Drive IBM Research Jacquelyn A. Martino Hawthorne, NY 10532 USA jacquelyn.martino@gmail.com A 
b S T r A CT This paper contributes to the area of computation in the production of artistic form. The 
author-artist describes a computational system in the form of a curvilinear, parametric shape grammar. 
based on an analysis of over 3,000 entries in her traditionally hand-drawn sketchbooks, she describes 
the grammar that synthesizes drawings in the design language of her evolving style and serves as a tool 
for self­ understanding of her artistic process. background and Context The algorithmic artist bases 
rules on a visual understanding. Algorithmic approaches facilitate formal understanding of visual productions 
and afford the artist repeatable processes. Addition­ally, the algorithmic approach affords a mechanism 
for the artist to explore new insights in a formal way. Cohen [1] and Verostko [2] are two artists who 
work this way. This paper examines shape grammars [3, 4] as they relate to artistic practice from process 
to product. Shape grammars afford a computational approach to design generation via formal visual production 
rule systems. Unlike other graphics production systems, artists draw the geometry for shape grammar rules 
directly in the pictorial vocabulary rather than write sym­bolic references to the geometry. This distinguishing 
characteristic supports well the dynamic role of the hand and eye in visual processing, allowing the 
artist to keep the acts of shape visualization and geometric representation unified. The first shape 
grammar language, defined by Stiny and Gips [5], implements a system for original paintings beginning 
with rule development and image synthesis rather than starting with an analysis of an existing style. 
Starting with the Palladian ground plans of Stiny and Mitchell [6], many seminal shape grammar formalisms 
address architectural design analysis and synthesis. Recent implementations in computer graphics focus 
on 3D building generation [7]. Lauzzana and Pocock-Williams [8] have used shape grammars to analyze and 
synthesize the art of Kandinsky; Kirsch and Kirsch [9] have analyzed and synthesized the art of Diebenkorn 
and Miró; and Knight [10] has analyzed the changes in styles of the De Stijl artists. Despite this rich 
art and design history, practicing artists have not previously used shape grammar devices to analyze 
and synthesize work within their own dynamically evolving design language. My experience is that defining 
computational devices for one s own work supports greater aesthetic understanding and leads to clearer 
stylistic development. To share this experience, I present the process I used to formalize my hand-drawn 
shape marks as computational devices. Overview I regard the canvas, or 2D picture plane, as the expressive 
and dynamic problem space of the artist who fluidly reframes both the problem and the solution with each 
successive mark. The immediacy of mark-making any time the marking tool comes in contact with the picture 
plane for the purposes of adding or subtracting is the most important element in transforming the blank 
canvas into an image. To draw expressively, the artist must have access to curve generation devices that 
support immediacy. To draw shape computationally, the expressive apparatus ideally supports geometric 
visualization and representation as a single act. In support of my investigation, this paper presents 
a parametric, curvilinear shape grammar that I base on an analysis of a subset of my traditionally-drawn 
sketchbook corpus. I compare the grammar s synthetic production with the hand-drawn baseline corpus to 
show the possibilities in computing imagery consistent with the evolving style of the artist s own hand. 
The grammar supports both explicit and implicit shape recognition while giving the artist the ability 
to draw (shape union) and erase (shape difference) computationally. A driving research objective in formalizing 
the design language has been to understand my personal artistic process to the extent that it informs 
my work and suggests new directions for my evolving style. The results of the analysis phase of the research 
support the supposition that formal algorithmic understanding of one s artistic process has direct and 
positive influences on the evolution and refinement of the style. This formal understanding founded a 
subsequent objective to develop software sketches implementing the rule base [11]. In the following sections, 
I introduce examples from the baseline corpus, discuss the analysis methods of the corpus, illustrate 
the resulting design language, discuss a synthetic and a hand-drawn production, and conclude with future 
directions. baseline Corpus An interest in Mayan glyphs began to influence my sketchbook entries and 
paintings in the late 1990s (Figure 1). These compositions held some aesthetic interest, but generally 
lacked stylistic clarity. I felt that the compositions were merely a collection of the parts, making 
no significant aesthetic statement. Dissatisfied, I decided to work in earnest on the development of 
form (drawing) and to pursue almost nothing new with respect to color or texture (painting). Figure 
1. The Mayan glyph influence. (a) 1:1 scale sketchbook drawings; (b) three digital paintings with a clear 
glyph influence, but also a hint at the potential for more artist-specific forms. Originals 6 x 6 . &#38;#169; 
2010 Jacquelyn A. Martino. With this focus, I maintained a traditional sketchbook practice outside of 
any computational framework until achieving a level of stylistic consistency and clarity (Figure 2). 
This approach allowed for two important developments. One, I had a sizable corpus to use as a basis for 
the analysis phase. Two, I was able to develop the foundation corpus without the a priori influence of 
potential technical constraints or merits of a particular computational approach. Figure 2. Sketchbook 
instances at 1:1 scale that demonstrate a clear stylistic evolution. &#38;#169; 2010 Jacquelyn A. Martino. 
Analysis During the analysis phase of my body of work, I used two basic sets of tools. The first was 
a continuation of my regular practice of sketchbook drawing using either a pen or a mechanical pencil. 
The second tool augmented the traditional sketchbook. I registered a sketchbook on a pressure-sensitive 
tablet and used a stylus equipped with a mechanical pencil lead of the same specification that I used 
for the traditional sketchbook method. As I drew on the sketchbook­augmented tablet, I recorded my drawings 
as QuickTime movies. This setup created in essence two original substrates: the sketchbook and the time-based 
digital canvas. Although I could have easily completed the time-based drawing process without the addition 
of a sketchbook and used a typical, non-leaded stylus, the augmented approach was valuable for a variety 
of reasons. The presence of the sketchbook and the leaded drawing instrument closely emulate the traditional 
drawing process. Although it is not uncommon to place a piece of paper on a tablet to get the physical 
interplay of paper tooth, the leaded stylus meant the ability to collect the exact same data in two equally 
useful forms: analog and digital. Drawing with paper and pencil, specifically the feel of the instruments, 
decidedly influences the quality of the mark and affects the drawing experience. With two tightly related 
data sources for my shape marks, I was able to review repeatedly a drawing s progress and conduct a non-automated 
analysis of the spatial relations among the marks. Basing the shape rules on the actual process that 
I had used to draw yields the antici­pated product of a design language conforming rather closely to 
process. In this way, the pictorial vocabulary of my language does double duty, illuminating both artistic 
process and product. Developing the Design Language Shape grammar computations start with an initial 
design state. This state may be the blank canvas, or the empty shape. A computation, or rule application, 
is in two parts. The first part is to recognize a shape in the current design state. The second part 
is to replace the recognized shape with another shape. The replacement can be a transformation, a different 
shape, or an additional shape. The computational rule is defined by a left side, A, and a right side, 
B. The generalization of a rule is A -> B, and read, see A, erase A and draw B in A s place. The rules 
in the grammar that I will discuss are specific to stroke shape, but nothing precludes the artist s use 
of rules to define any aspect of the design, such as color, materials, etc. [12]. Additionally, the artist 
may add rules at any point in time without the requirement to re-model the design space. Approximately 
70 time-based drawings and a sketchbook source 3,000 drawings at last count are the basis for my observations 
and analysis. While formulating the rules, I gave specific attention to the relation among the marks 
and their resultant shapes, the styling of the shapes, and the spatial relations of closed and open shape 
outlines. A critical observation was that frequently I was using a non-drawn shape to reserve and define 
space on the canvas. Specifically, the visible marks are perturbations, or parametric variations, of 
simple implied shapes such as squares, triangles, and rectangles. Early in my analysis, it became clear 
that my marks brought attention to small areas of the overall canvas. I defined these areas by a series 
of outline-like marks that represented both closed and perforated, or segmented, shapes. In addition 
to single shapes within a shape, other group­ings of outlines occur in the foundation corpus. For example, 
there are numerous cases of a primary outline shape supported by multiple fenestrations, or punctures. 
Groupings of closed shapes in close side-by-side proximity are also common. Gaps left among the marks 
anticipate erasing. A salient observation on open and closed outlines is that they represent essentially 
the same forms. An open outline is simply a closed outline with erasures loosely fitted along the curve 
of the implied primitive shape. Further, any number of stretch, squash, and skew operations may distort 
the primitive shape. Since ultimately the erased portions serve as space holders for new marks loosely 
conforming to the same implied shape, the spatial relations of the marked and unmarked portions pose 
an interesting problem in formalizing the rules related to these seg­mented shapes. The problem has its 
roots in the ability to keep an overall balance to the completed shape. Too few segmentations, and the 
result is visibly too similar to its implied primitive. Too many segmentations, and the shape does not 
conform enough to examples from the baseline corpus. To represent the mark in a form that allows its 
computation as described above, the system must translate the series of points that make up a stroke 
into some usable form. Since the piecewise Bézier has many properties that respect the gesture of a mark, 
the system takes the hand-drawn data and converts it to a piecewise curve. Figure 3 shows rules 1 through 
3 governing the initial shape placement on the canvas, parametric constraints of Béziers, and intersection 
points for eventual shape segmentation. The first step is to create a space holder based upon an implied 
shape. Rule 1 addresses this requirement, stating: Replace the empty shape, Ø, with a closed shape. The 
figure example shows both a triangle and a square as the closed shape options. Additional closed shapes 
could include a rectangle, pentagon, etc. Rules 2 and 3 use the triangle as an example. Note that the 
shapes of rule 1 have similar scale, but shapes in the design can be of dissimilar scale. To define the 
parametric constraints for manipulating the Bézier, I use minor scaling of the implied shape to generate 
guide shapes. The current experimental scale factor is +/- 10%. Once the artist draws the implied shape, 
the next task is to find its center of mass and scale the shape based on the center, as in rule 2. Rule 
2a states: Calculate the center of mass of the implied shape. Rule 2b states: Scale the implied shape 
up 110% and down 90% from the center to create the parametric space guide shapes for perturbing the implied 
shape. Rule 2c states: Once the guide shapes are in place, erase the center-of-mass marker. Rule 3 replaces 
the implied shape by a loosely conforming piecewise Bézier curve. A set of intersecting lines at the 
interior of the smaller guide shape creates intersection points on the scaled guide shapes and the original 
implied shape. These intersections serve two func­tions. The first is to define the sub-shapes of the 
implied shape that the Bézier curves will ultimately replace. The second is to define the manipulation 
parameters of the Bézier pieces. Specifically, rule 3a states: Draw intersecting lines equal to or greater 
in number than the number of sides of the implied shape. Their intersection must be at the interior of 
the smaller guide shape and they may not coincide. Rule 3b states: Once the intersecting lines are in 
place, the points where they intersect the guide shapes and original implied shape become the param­eter 
space. Sub-shapes in the form of Bézier curves replace the original implied shape. The guide shapes remain 
to serve as the constraints for moving the control points of each individual Bézier. Rule 3c states: 
Remove the intersecting lines and hide the Bézier handles. Rule 3d states: Remove the guide shape to 
leave the final parameterized shape. Clearly, rules 1 through 3 apply equally to shapes within shapes, 
i.e., interior and exterior shapes.  Figure 4. rules 4 through 7 govern shape decoration. &#38;#169; 
2010 Jacquelyn A. Martino. Figure 4 shows rules 4 through 7 governing shape decoration. Specifically, 
rule 4 adds a decora­tion to the exterior shape. Rule 5 adds a decoration to an interior shape. Rule 
6 is a variation of Rule 4 allowing further decoration to the exterior of a closed shape. Rule 7 allows 
a decoration between two closed shapes. Rules 1 through 7 only apply to single closed shapes. Rule 8, 
in Figure 5, pertains to multiple shapes by deleting shape segments and joining interior and exterior 
shapes. Beginning with the segmented exterior shape product of rule 3b, rule 8a states: Draw an interior 
shape such that the intersection of the parameter lines is at its interior. After following all the rules 
for segmenting an implied shape to perturb the interior shape, a triangle in our example, then delete 
a segment on each of the interior and exterior shapes as the common intersecting lines indicate in rule 
8b. For multiple segment deletions, apply these rules multiple times. Finally, rule 8c states: Join the 
open ends of the interior and exterior shapes. Figure 5. rules 8a, b, and c govern shape segmenting 
and joining of interior and exterior shapes. &#38;#169; 2010 Jacquelyn A. Martino. Synthesis Using the 
Design Language In the previous section, I have detailed a rule-based design language using a shape grammar. 
The purpose of this language is to illustrate the utility of a formal understanding in evolving the style 
of my artistic productions. In this section, I show a derivation using the rules in Figure 6 and I examine 
the synthetic results in an effort to understand the success and room for improvement with respect to 
the rules. Comparing the final shape of Figure 5 with sketchbook examples in Figure 2, both the synthetic 
shape and the hand-drawn shapes follow the general spirit of using implied primitive shapes. The rules 
governing segmentation of the implied shape capture the undulation of the implied form moderately well, 
although we can see that perturbations in the hand-drawn shape are more radical than in the rule-based 
shape. The rules for joining exterior and interior shapes handle that relationship reasonably well, although 
the joints in the hand-drawn shape go further toward obscuring the implied interior shape than the formal 
rules currently support. Contrasting the synthetic results with the hand-drawn, the synthetic shape is 
much smoother than its hand-drawn counterpart. The current iteration of the shape rules knowingly restricts 
the number of points, and hence the number of Bézier curves that form each shape. When drawing the hand-drawn 
shape, the curves are far less simplified as the synthetic drawing tool uses a high level of curve precision. 
Specifically, the tool draws points at a higher temporal frequency for the duration of the stroking gesture. 
Generally, this higher level of precision should more closely emulate the hand-drawn feeling of the shape. 
To represent this aspect of the hand more accurately, future iterations of the shape rules need to capture 
information about precision and number of data points collected over time. This phenomenon is somewhat 
like the use of a pencil when the drawing gesture is slower or faster. A fast gesture will be more flowing 
even in the continuous, analog domain of the pencil. While conversely, a slow gesture will contain more 
information and have a less-than­clean, even jittery, appearance on the page. A second observation is 
that the parameter space defining the erased portion of the implied shapes is too predictable and symmetrical 
in comparison to the hand-drawn equivalent. The experimental 10% value of uniformly scaling the implied 
shape up and down is too restrictive. A first step in its refinement would be to make the scaling factor 
non-uniform. Despite the need for further rule refinement, however, the overall impact of the rules is 
that they generate shapes that are clearly in the style of the non-rule-based forms. The Importance of 
Visual Algorithms in Artistic Practice The rule system and example derivation that I have detailed in 
the above sections can only provide a static viewport into my artistic practice. Specifically, this is 
not the first generation of the system, but rather the current result after multiple refinements. Given 
this, the question becomes: What motivates me to formalize and refine my work with a computational apparatus? 
The answer is deceptively simple: I desire to achieve mastery of my craft. A distinct part of the path 
to mastery is the ability to make incremental correction toward a classic exemplar or some artist-defined 
conceptual endpoint within the continuous loop of making new examples and analyzing the results. For 
me, this make-analyze-correct loop gains focus with the requirement that rule design imposes on formalizing 
the visual understanding of my artistic productions. Essentially, the computational system amplifies 
and clarifies the necessary dialogue between my work and myself. Defining rules allows me to examine 
not only my results, but also my pathway to those results. When reviewing my sketchbook entries, I could 
see that some forms were more pleasing than others, but I did not understand exactly what in their production 
made this the case. For example, writing rules required me to examine the spatial relations of interior/exterior 
shapes and formalize that relationship in a way that was testable and reproducible. Similarly, rule-based 
 Figure 6. A step-by-step derivation of a shape using the rule-based design language. &#38;#169; 2010 
Jacquelyn A. Martino. results inconsistent with my hand-drawn targets could simultaneously reveal either 
the need for correction or possible new directions for exploration. Since the practice of visual creation 
is one of shifting priorities that balances seeing new possi­bilities with correcting existing instantiations, 
the use of shape grammars for my visual production system seemed a natural fit. Specifically, as these 
grammars are non-symbolic, my rule system illuminates process and product while providing methods that 
allow for an emerging schema of visual problem solving. Such choices fit within the generalization that 
artists who choose algorithmic methods demonstrate an acute interest in a formal expression of their 
creative selves. Conclusions and Future Work The main contribution of this work is a first-person account 
of an artist using shape grammars as a tool for personal artistic reflection and growth. With this project, 
I experienced the value of visual algorithms as an apparatus to develop a style over time and to explore 
my artistic process. In this paper, I have detailed a rule-based design language using a 2D parametric, 
curvilinear shape grammar. I based the language on an analysis of a subset of my own drawing style and 
demonstrated an instance of the shape rule synthesis. In addition, I have discussed ways to improve the 
grammar to emulate more closely my artistic target of hand-drawn sketchbook entries. Finally, I have 
discussed the role that algorithmic approaches play in my concept of gaining mastery of craft. Refining 
the grammar to its current stage has allowed me to sharpen my understanding of the individual shape-forms 
that make up my personal artistic language. While I am able to use this understanding to generate compositions 
using these forms, I have not yet specified rules for completing an entire canvas. Similarly, my use 
of color remains informal and intuitive. In future extensions to this system, I plan to extend single 
shape-form rules to canvas-sized compositions with formal uses of color. Figure 7 shows a digital painting 
post-formalization of my shape rules and pre-formalization of my composition and color rules. I offer 
this to suggest, when compared to the painting of Figure 1b, that computational understanding is an enabler 
of stylistic maturation. Figure 7. Digital painting that incorporates post-algorithmic understanding 
of my design language. &#38;#169; 2010 Jacquelyn A. Martino. Acknowledgements For their insights, efforts, 
and feedback I thank Terry Knight, Joe Marks, George Stiny, John Richards, Peri Tarr, and the anonymous 
reviewers. references 1. P. McCorduck, Aaron s Code: Meta-Art, Artificial Intelligence, and the Work 
of Harold Cohen (New York: W.H. Freeman, 1991) xvi, 225. 2. R. Verostko, Epigenetic Painting: Software 
as Genotype, Leonardo, Vol. 23, No. 1, 17 23 (1990). 3. G. Stiny, Shape (Cambridge: MIT Press, 2006) 
432. 4. M. Özkar and G. Stiny, Shape Grammars, ACM SIGGRAPH 2009 Courses (2009). 5. G. Stiny and J. 
Gips, Shape Grammars and the Generative Specification of Painting and Sculpture, republished in The Best 
Computer Papers of 1971, O. R. Petrocelli, ed. (Philadelphia: Auerbach, 1972) 125 135. 6. G. Stiny and 
W. Mitchell, The Palladian Grammar, Environment and Planning B, Vol. 5, No. 1, 5 18 (1978). 7. M. Lipp, 
P. Wonka, and M. Wimmer, Interactive Visual Editing of Grammars for Procedural Architecture, ACM SIGGRAPH 
2008 (2008). 8. R.G. Lauzzana and L. Pocock-Williams, A Rule System for Aesthetic Research in the Visual 
Arts, Leonardo, Vol. 21, No. 4, 445 452 (1988). 9. J. Kirsch and R. Kirsch, The Anatomy of Painting 
Style: Description with Computer Rules, Leonardo, Vol. 21, No. 4, 437 444 (1988). 10. T.W. Knight, Transformations 
in Design: A Formal Approach to Stylistic Change and Innovation in the Visual Arts (Cambridge, New York: 
Cambridge University Press, 1994) xvii, 258. 11. J.A. Martino, The Immediacy of the Artist s Mark in 
Shape Computation: From Visualization to Representation, Doctoral Thesis, Massachusetts Institute of 
Technology, hdl.handle.net/1721.1/37265 (2006). 12. T.W. Knight, Color Grammars: Designing with Lines 
and Colors, Environment and Planning B: Planning and Design, 16, 417 449 (1989).  Glossary Algorithmic 
artist: One who uses algorithms, or well defined rules, of their own definition in creating their artistic 
productions. Syn. algorist, as defined by www.verostko.com/algorist.html.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1836789</article_id>
		<sort_key>30</sort_key>
		<display_label>Pages</display_label>
		<pages>10</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Learning from weaving for digital fabrication in architecture]]></title>
		<page_from>340</page_from>
		<page_to>349</page_to>
		<doi_number>10.1145/1836786.1836789</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836789</url>
		<abstract>
			<par><![CDATA[<p>This project restructures weaving performance in architecture by analyzing the tacit knowledge of traditional weavers through perceptual study and converting it into an explicit rule in computational design. Three implementations with different materials show the advantages of using computational weaving that combines traditional principles with today's digital (CAD/CAM) tools to develop affordable fabrication techniques.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor>Architecture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010472</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264032</person_id>
				<author_profile_id><![CDATA[81466648001]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Rizal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Muslimin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Massachusetts Institute of Technology, Cambridge, Massachusetts]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. Lasch and B. Aranda, <i>Tooling</i> (New York: Princeton Architectural Press, 2006).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Peter Testa created Weaver algorithm in Maya Extended Language. The main structure of Testa's Carbon Tower is a thousand feet of long helical bands of carbon fiber woven together from the bottom to the top, eliminating the need for joints. M. McQuaid, <i>Extreme Textiles: Designing for High Performance</i> (Princeton Architectural Press, 2005).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C. Lasch and B. Aranda {1}.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M. McQuaid, <i>Extreme Textiles: Designing for High Performance</i> (Princeton Architectural Press, 2005).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Sabin's eBraid tower proposal uses two interconnected braids: an external braided carbon fiber diagrid superstructure and internal conducting braids with the capacity to absorb, collect, and deliver energy and light. J. Sabin, &lt;www.jennysabin.com/&#62;.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[P. Oliver, ed., <i>Encyclopedia of Vernacular Architecture of the World</i> (Cambridge: Cambridge University Press, 1997).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Sch&#246;n coined the term "reflection-in-action" in terms of teaching artistry, using case studies from architectural studio education as well as music. D. Sch&#246;n, <i>Educating the Reflective Practitioner: Toward a New Design for Teaching and Learning in the Professions</i> (Jossey-Bass: San Francisco, 1990).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[For textiles, Semper uses the term "plaiting" to mean interwoven objects. He uses the term "weaving" to criticize the contemporary practice of industrial weaving as lacking a practical aesthetic and drowning in its excessive resources, in comparison to traditional weaving (by the Hindus and Kurds), far simpler and less industrial but with a greater understanding of art. Furthermore, Semper stratifies textile art into the following: 1) bands and threads, 2) spun yarn, 3) twisted yarn, 4) the knot, 5) the loop stitch, 6) plaiting, and 7) felt. To analyze structural performance in plain interwoven surfaces, this research uses knots and plaiting. The yarn and how it is twisted plays a significant role in further analysis of material performance of interwoven surfaces. G. Semper, <i>The Four Elements of Architecture and Other Writings</i>, trans. Mallgrave and Herrmann (Cambridge: Cambridge University Press, 1989).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[F. Otto, Institute for Lightweight Structures (IL) (University of Stuttgart, 1969).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. Garcia, "Introduction: Architecture + Textiles = Architextiles," <i>Architectural Design</i>, 76(6), 5--11.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Gibson refers to the haptic system as an apparatus by which the individual receives information about both the environment and his body. In addition, Gibson warns that what is simple for mechanics is not simple for human mechanoreception---a tactual receptor of mechanical energy in all of its manifestations, including vibration---and that biomechanical stimulation is not reducible to physical magnitudes. However, information about stress/strain, forces, vector direction, and coordinates are compatible enough with digital computation, enabling it to perform the weaving of the structural configuration but not the total sensory experience of the weaver. J. J. Gibson, <i>The Senses Considered as Perceptual System</i> (Boston: Houghton Mifflin, 1966).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. J. Gibson, <i>The Senses Considered as Perceptual System</i> (Boston: Houghton Mifflin, 1966).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[G. Semper, <i>The Four Elements of Architecture and Other Writings</i>, trans. Mallgrave and Herrmann (Cambridge: Cambridge University Press, 1989).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. J. Gibson {12}.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1795940</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[G. Stiny, <i>Shape: Talking about Seeing and Doing</i> (Cambridge: MIT Press, 2006).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[T. Knight, "Shape Grammar and Color Grammar in Design," <i>Environment and Planning</i>, No. 21, 705--735 (1994).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[W. J. Mitchell, "Functional Grammars: an Introduction," <i>Reality and Virtual Reality</i>, Association for Computer Aided Design in Architecture (1991).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>286918</ref_obj_id>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[G. W. Flake, <i>The Computational Beauty of Nature: Computer Explorations of Fractals, Chaos, Complex Systems, and Adaptation</i> (Cambridge: MIT Press, 1998).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1400412</ref_obj_id>
				<ref_obj_pid>1400385</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[T. Knight and L. Sass, "Visual Physical Design Grammar," SIGGRAPH 2008 Design and Computation Gallery: Complexity and Craftsmanship.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>83596</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[P. Prusinkiewicz and A. Lindenmayer, <i>The Algorithmic Beauty of Plants</i> (Springer-Verlag: New York, 1990).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[A. Killian, "Fabrication of Partially Double-Curved Surfaces out of Flat Sheet Material through a 3D Puzzle Approach," ACADIA Proceedings (2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[A. Siza, <i>Serpentine Gallery Pavilion 2005</i>, Serpentine Gallery, London (2005).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[K. Snelson, <i>Kenneth Snelson: The Nature of Structure</i>, New York Academy of Sciences, New York (1989).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[J. A. Frumar et al., "Tensegrity Structures with 3D Compressed Components: Development, Assembly and Design," <i>Journal of the International Association for Shell and Spatial Structures</i>, Vol. 50, No. 2, 99--110 (2009).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Y. Weinand, "Innovative Timber Constructions," <i>Journal of the International Association for Shell and Spatial Structures</i>, Vol. 50, No. 2, 111--120 (2009).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Centre Pompidou-Metz, <i>Centre Pompidou-Metz</i> (Paris: Editions du Centre Pompidou, 2008).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Learning from Weaving for Digital Fabrication in Architecture rizal Muslimin Massachusetts Institute 
of TechnoCambridge, Massachusetts USA rizal@mit.edu logy Rizal Muslimin AbstrAct this project restructures 
weaving performance in architecture by analyzing the tacit knowledge of traditional weavers through perceptual 
study and converting it into an explicit rule in computational design. three implementations with different 
materials show the advantages of using computational weaving that combines traditional principles with 
today's digital (cAD/cAM) tools to develop affordable fabrication techniques. Introduction: the Missing 
Link between Digital and traditional Weaving A number of recent architectural design practices are revisiting 
weaving to promote the excel­lence of digital architecture computation [1]. Various braiding, knotting, 
and weaving algorithms make it possible to generate interwoven objects seamlessly with the digital model 
and materialize them with rapid prototyping machines [2]. However, some fundamental weaving properties 
seem to be missing. While traditional weaving performs both aesthetic and structural functions, some 
of today s digital architecture, as demonstrated by the Aranda/Larsch algorithm, use weaving mainly as 
surfacing pattern and not as a method of structural assembly [3]. Other promising proposals, such as 
Peter Testa s Carbon Tower [4] and Jenny Sabin s eBraid tower [5], apply weaving to large-scale architectural 
design by using carbon fiber (Figure 1d and 1e) . In several traditional communities, where digital fabrication 
tools and advanced materials are not available, hands-on weaving routines are still widely exercised 
in craft-making and house construction (Figure 1a, 1b, and 1c) [6]. While weavers are working with the 
raw material, their senses and logic perform an immediate problem-solving procedure, as every knot they 
make constrains the next weaving step. This activity is analogous to how Donald Schön illustrates designers 
sketching their designs as a reflection-in-action practice [7]. In the case of weaving, the weaver s 
hands act as a force and stress gauge, while the weaving algorithm runs tacitly in their minds. The resulting 
weaving patterns are structurally durable and aesthetically contextual in their culture. In contrast 
to synthetic materials such as carbon fiber, natural materials such as grass, reeds, palm leaves, or 
rattan may offer flexibility and elasticity that might be useful in traditional architecture, but their 
limited dimension and lack of long-term endurance are not suitable for large-scale architectural designs, 
which require a certain degree of stiffness and permanence. This research aims to bridge the gap between 
the absence of structural aspects in digital weaving and the lack of rigidity in traditional natural 
materials by analyzing structural performance in traditional weaving and implementing it using a digital 
computational method. In this pursuit, the following questions emerged: First, how do we frame the notion 
of weaving as it might be used in various fields? Second, how do weavers sense the interwoven object 
in order to make an assessment of its rigidity? Third, how can we explore the material behavior in relation 
to estab­lishing novel manufacturing means and ensuring adequate production capacity? And finally, how 
can we convert traditional weaving procedures into the digital realm so that they will be not only compatible 
with further computational processes, but also capable of expressing various patterns, as traditional 
weaving is? In exploring these questions, three projects show the conver­sion from and application of 
traditional weaving to digital weaving in designing woven shelters that combine conventional building 
materials (bricks and wood) with fast, easy, and cheap construction. Weaving in Architecture The use 
of weaving in contemporary architectural design as well as in this research is less about creating a 
new genre but more about a journey to the origin of architecture. In his four ele­ments in architecture 
proposition, Gottfried Semper states that the origin of architecture overlaps with the creation of textiles, 
for people invented interwoven fences as the earliest vertical spatial enclosures, which then led to 
the invention of woven objects on a more domestic scale [6]. In addition, Frei Otto argues that the first 
human dwelling was constructed by weaving living plants (young conifers, bamboo, or branches of broad-leaved 
trees) because they were easy to harvest and manipulate by hand (Figure 1a) [9]. Moreover, the terms 
technology and textile are both derived from the Latin texere, meaning to weave, connect, and/or construct 
[10]. Given this intertwining history between architecture and woven surface, it is necessary to place 
the notion of weaving on a transcendental level between the fields of architec­ture and other disciplines 
that benefit from weaving (art and craft, textiles, material science) and focus more on the overlaps 
between those fields when weaving is used to meet a certain goal in design (geometrical composition and 
load distribution). For instance, we could compare knots in basketry to joinery in traditional grass 
roofs. By associating various aesthetic and functional values between these fields, we might gain valuable 
inspiration on the versatility of weaving in different applications. Based on this rationale, the term 
weaving in this research is framed as a system of interlacing objects into a structurally interdependent 
pattern, in which the object can be parameterized with various material properties, the structure can 
be reconfig­ured with different loading configurations, and the pattern may be embedded with other adaptable 
geometry for given material properties and structural configuration. Haptic system in traditional Weaving 
In reference to Gibson s definition, haptic system could yield information about solid objects in three 
dimensions, whereas sense of touch does so in only two dimensions [11]. Thus, we might imagine that Aristotle 
s sense of touch evaluates weaving structural behavior by pressure and tension on the skin along a single 
axis (lateral or axial), whereas the Gibsonian haptic system assesses the higher dimension of weaving 
activity in three main weaving procedures: First, the weaver s hand has both a passive role to feel the 
stress and strain of each knot and an active role as fabricator of the weaving (Figure 2e). Second, for 
weavers thread is not merely a construction material but also something that performs as cutaneous appendages 
and receptive units to transmit structural data from the woven object to the weaver s hand as the thread 
is stretched and pulled (Figure 2f). Third, the weaver s body performs dynamic touching as skin, joint, 
and muscle act together with different degrees of sensitivity. The stretching muscles transmit stress 
and strain data, the joint rotation transmits the angle and position coordinates, and the skin pressure 
provides contact information. In combination, they project a vector space in the surrounding environment 
to provide information regarding the weaving surface s stiffness (Figure 2g) [12]. This study argues 
that the above perceptual apparatus helps weavers to analyze the interwoven object in two scales: first 
in the knots and second in the plaiting surface [13]. In the knots scale, the weaver s sense of touch 
informs the way force and stress are distributed and creates structural interdependency at each intersection, 
by which the yarn in the X axis is being supported by vertical stress (sV) from the Y yarn on the interlaced 
area (A) (Figure 2c). In the plaiting scale, the weaver s haptics system can tacitly perceive pressure 
and tension stress along the surface by pulling the woven thread in vector space (Figure 2d). This is 
the point where material properties play a significant role in the weaver s perception of the weaving 
s structural properties. Elastic materials (reeds or coconut leaf) can transmit stress and strain information 
of the knot bending stress to the weaver s hand as it feels the distance (D) and coordinate changes (Xi,Yi,Zi). 
  Figure 2. sensing the structural behavior of a woven object. (a) the interwoven surface. (b) the 
surface translated into a structural grid. (c) structural analysis of the knot scale. (d) structural 
analysis of the plaiting scale. (e) the weaver s sense of touch. (f) the weaver s use of threads as cutaneous 
appendages. (g) the dynamic touching of the weaver s movements. &#38;#169; 2010 rizal Muslimin. Weaving 
Materialization The challenge for this research is to answer how rigid material can perform weaving configura­tions 
based on perception studies of traditional weaving. The preceding assumption of the weaver s touch and 
haptic apparatus enlightens us that, structurally, weaving configuration balances the stress among tension, 
bending, and shear of the plaiting surface and the knots. Therefore, by applying this structural equilibrium 
in rigid materials, one can gain the benefit of traditional weaving within the more stiff and reliable 
materials, even with non-continuous material [14]. The demonstration in Figure 3 shows the conversion 
process from traditional elastic materials to rigid materials through computational reasoning as follows: 
Visual Embedding. A geometrical pattern is visually embedded into the plaiting pattern to discretize 
weaving continuity based on the structural configu­ration from the sensing experience. For the first 
project, the segmentation literally subdivided the long yarn into a planar composition at each knot (planar 
tile), while for the second project the pattern is embedded by linear composition using the edge of the 
weaving pattern (line segment) (Figure 3a) [15]. Structural Optimization. The load distribution of the 
discrete elements guides the translation from two-dimensional pattern into three-dimensional shape. Areas 
where X and Y yarns interlace point out the location for notches and tabs as well as the increased height 
(H) of the area that supports the vertical forces. The three-dimensional shape is then digitally optimized 
using finite-element analysis to find the effective loading distribution. In finite-element analysis, 
similar sensing mechanisms do occur, albeit in an opposite way: the tactual sense happens in the woven 
object, while human hands act as instruments for applying the external forces and controlling the degrees 
of freedom. In other words, the sensing agent is embodied in the thread instead of in the external force 
(Figure 3b). Materialization. The optimized shape is then converted to a building component for architec­tural 
construction: the planar discrete element materializes into a brick, while the linear element transforms 
into a beam. For the first project, clay was chosen as the material because it is renewable, decomposable, 
and abundant in nature. The second project uses plywood for its light weight and its wide use in framing 
of structures. The third project uses paper to simulate the behavior of the weaving pattern, using elastic 
material as a comparison to rigid material (Figure 3c). rule for Assembly An assembly rule is assigned 
to the discretized building component so that it becomes program­mable to generate various geometric 
patterns from a few modules while retaining the essential structural properties of weaving. In this case, 
the rule assignment uses shape grammar not only because it is parametrically compatible with other computational 
algorithms (L-systems, cellular automata, fractals), but also, more importantly, concerning the limitless 
variety of weaving configurations, the labeling system and shape relationship in shape grammar can manage 
and elaborate different emergent behavior [16]. Moreover, shape grammar is capable of translating abstract 
logical propositions into a concrete functional feature [17]. The following applications with different 
materials (clay, wood, and paper) demonstrate the way shape grammar s label and shape relationships mediate 
computational algorithms, generate programmable components, and accommodate weaving structural behavior. 
  Project 1: Weaving as brick Assembly In this project, points in the pixelated pattern correspond to 
the surface of a brick module (Figure 4a). Shape grammar analyzes the original pattern as a two-dimensional 
array of red and white cells, and tracks the pattern linearly, cell by cell, along the same axis, similar 
to the rules in von Neumann s cellular automata [18]: red means the cell exists, and white means the 
cell is empty (Figure 4b). More specifically, the rule reads the current cell as a labeling point and 
its connection to the next cell as the shape relationship. Then, for each iteration, shape grammar looks 
at the next cell to see whether it exists, is empty, or is not detected, and assembles the corresponding 
brick on the projected grid based on the following rules (Figure 4c): Continuous Rule to form a continuous 
line: IF the next point exists, THEN use a continuous brick; Checkered Rule to form a checkered pattern: 
IF the next point is empty, THEN use a checkered brick; Edge Rule to stop the iteration at the edge 
of the surface: IF there is no point afterward, THEN use the edge brick.  Each brick is connected to 
the other bricks through the same axis using notches and tabs as the joint elements, creating both a 
self-supported surface and a mosaic of the pattern with little cement or mortar. Structurally, the checkered 
composition is more rigid than the continuous one, so the more the checkered rule is used, the firmer 
the surface will be. Also note that in this project the brick module uses a rectilinear grid, which causes 
the surface to be generated in rectilinear fashion. Likewise, different brick modules with diamond, circular, 
or triangular shapes will create different geometrical expression.  Figure 5. Weaving with wood for 
shelter construction. (A) Finite element analysis optimizing the distance between notches for each beam. 
(b) Parametric rule for overlapping plywood. (c) Application of the rule using a 90° angle for four beams. 
(D) Application of the rule using a 120° angle for three beams. (E) Application of the interwoven beam 
grammar in shelter construction. &#38;#169; 2010 rizal Muslimin. A similar approach to eliminating the 
use of mortar to create low-cost patterns using self-consis­tent rules has been implemented in Larry 
Sass and Terry Knight s meandering bricks. The components of meandering bricks have integrated alignment 
features (two horizontal and vertical notches as aligners) so that they can be easily matched and locked 
together manually without binding materials [19]. The difference between these two methods is that in 
this project, the interwoven arrangement between bricks establishes a firm alignment capable of supporting 
the axial and lateral forces. Connections with neighboring bricks along the perpendicular axis prevent 
vertical shear that might be caused by lateral loads at each joint. In this way the wall's thickness 
can be significantly reduced (Figure 4d). Project 2: Weaving in Wooden structure In contrast to the brick 
assembly, which continuously distributes the load in a single axis, the overlapping load distribution 
along both the X and Y axes in wooden-beam weaving makes it possible to use short plywood as a structural 
member. Here, the label and shape relationship grammar were determined parametrically by the rotation 
center point and the number of beams to copy and rotate the first beam, as the initial shape, into three 
or four pieces at each knot using the following rule (Figure 5b): The Labeling Rule locates the rotation 
center point based on the distance between notches and tabs from the finite element analysis (Figure 
5a) so that each member will interlock in a proportionally stable manner. The Rotation Rule defines the 
type of shape relationship based on the rotation angle (a, alpha) and the number of beams (n) that will 
be produced on each knot (a = 360 / n). In this example, three beams rotate by 120 degrees to create 
a triangular pattern (Figure 5d), while four beams rotate by 90 degrees to express a rectilinear pattern 
(Figure 5c). The Recursive Rule mirrors the new rotated beams so that its new center point can be used 
as a label to create other new beams recursively. Once the rotation center point label and shape relationships 
are defined, shape grammar generates the woven beam surface analogous to an L-system genera­tion of various 
plant geometries [20].  The resulting woven plywood creates a strong rigid structure that can support 
loads along the axial, lateral, and vertical axes with different patterns (Figure 5e). The same intention 
to reduce and simplify joinery components has been demonstrated by Axel Killian in his puzzle­like adaptable 
detail (3D puzzle) of a curved surface by combining computer-controlled fabrication and generative modeling 
in order to generate cutting geometries [21]. But dependence on advanced fabrication machines is not 
critical, as simple rectangular notches and tabs in this beam can be easily cut using traditional woodworking 
tools. Therefore, this woven beam is more like the work of Cecil Balmond, Eduardo Souto de Moura, and 
Alvaro Siza in their 2005 Serpentine Pavilion Gallery [22]; Kenneth Snelson s tensegrity [23]; Frumar 
et al.'s tensegrity structures with 3D compressed components [24]; Studio Weinand s textile applications 
on building scales [25]; Shigeru Ban and Arup AGU s Centre Pompidou [26]; and many other remarkable strategies 
for pursuing integrated joints for cheaper and more efficient construction. Project 3: Weaving the Paper 
beam In exploring paper flexibility, I bent the rectangular surface by shifting the midpoints of its 
side length (Figure 6a). To this bent paper I then applied the same rules from the second project using 
120-degree angles to create a two-dimensional triangular pattern. However, the woven bent paper beam 
demonstrates unexpected behavior, as the pattern blossoms from a flat into a round surface as it is assembled. 
This effect is caused by the bending moment on each module, which tends to twist the shape back to its 
original flat surface (Figure 6b). Furthermore, this project exercises the parametric feature of the 
rotation rule by changing the value of the angle and the number of beams in each generation. The first 
iteration rotates the paper beam 120 degrees to create triangular relationships. The composition from 
this iteration then acts as an initial shape for the second iteration, which uses a 60-degree rotation, 
creating another shape relationship: a hexagonal star (Figure 6c). This hexagonal star is then used as 
an initial shape for the third iteration that goes back to 120-degree angles, and the process continues 
to populate the surface with the same values afterward. Similar to the previous design, the bending moment 
in each knot causes the surface of the whole pattern to bend. conclusions Essentially, this research 
has incorporated weavers tacit knowledge into an explicit algorithm in computational design by combining 
the benefits of digital computation with hands-on experi­ence in weaving through the following contributions: 
I justified J.J. Gibson s haptic system in looking at weavers perceptual experiences to understand the 
structural mechanism of traditional weaving. I developed a new, faster, and cheaper assembly system in 
brick construction by using the principles of weaving, as well as a new joint system in wood assembly 
that does not require additional joint components such as nails, screws, and bolts. I generated a rule 
for weaving brick that makes it possible to create various pixelated patterns and one for weaving beams 
that makes it possible to express ornamental structures by parametrizing the angles and the number of 
beams. Further studies and experiments are required in order to improve the habitability standard of 
such woven shelters. Some of the questions that need to be addressed in future work are: How do we make 
the interwoven brick waterproof so it can be used as a roof and strong enough to be used as a horizontal 
woven floor plate? What is the best depth-to-height ratio of the module? What is the span limit? Can 
it be assembled in linear fashion to form a column? In the extreme case, consider: How can we construct 
the interwoven beam using wood pieces of unequal dimensions, allowing us to use wood from rubble to build 
temporary shelters after an earth­quake, for example? This research is a preliminary inquiry into one 
of many approaches to weaving in architecture. It takes into account the role of perception in design 
and a computational design framework. The following are a few suggestions for further studies on weaving 
in architecture: Examine other perceptual apparatuses: This perceptual investigation on traditional weaving 
activity has been focused extensively on the weaver s tactual experience rather than other perceptual 
apparatuses. Thus, further investigation (for example, on how weavers visual perception works as they 
decide which pattern or what type of knot to use, and how it is related to their haptic system) would 
provide a significant continuation of this research. Extend the geometrical language: For a practical 
reason, the case study used in this research is a simple plaiting surface that has a standard rectilinear 
pattern, while there are many other varieties of patterns in traditional weaving that remain unexamined 
so far. This opens enormous possibilities for more geometrical exploration in this traditional-digital 
weaving conversion, at the knots level and/or at the surface level. Explore the computational methods: 
Through the use of shape grammar in this research I have applied other computational algorithms such 
as L-systems and cellular automata to the labeling and spatial-relationship system. However, the most 
powerful feature of shape grammar is its capability to generate many different designs using just a few 
simple shapes by visually embedding several geometrical properties and parameterizing various label positions 
and shape relationships. Thus, as an alternative to using other patterns or other algorithms, one can 
just continue exploring different labeling and shape relationships using the preceding shape from the 
interwoven brick walls, wooden beams, and bent paper to achieve other novel assembly techniques in architecture. 
  Figure 7. comparison between traditional weaving using continuous materials (top left and top right) 
(photos &#38;#169; Andry Widyowijatnoko) and computational weaving using segmented materials. &#38;#169; 
2010 rizal Muslimin. In conclusion, algorithms in general should not be perceived as applicable only 
to modern, state-of-the-art digital technology. Instead, we should begin to appreciate many of the built-in 
algorithms in existing traditional production techniques. By recognizing and incorporating such algorithms, 
designers might be able to make the intuition behind their own perceptual modali­ties more explicit and 
optimize their use of computational aids (Figure 7). references and Notes 1. C. Lasch and B. Aranda, 
Tooling (New York: Princeton Architectural Press, 2006). 2. Peter Testa created Weaver algorithm in 
Maya Extended Language. The main structure of Testa s Carbon Tower is a thousand feet of long helical 
bands of carbon fiber woven together from the bottom to the top, eliminating the need for joints. M. 
McQuaid, Extreme Textiles: Designing for High Performance (Princeton Architectural Press, 2005). 3. 
C. Lasch and B. Aranda [1]. 4. M. McQuaid, Extreme Textiles: Designing for High Performance (Princeton 
Architectural Press, 2005). 5. Sabin s eBraid tower proposal uses two interconnected braids: an external 
braided carbon fiber diagrid superstructure and internal conducting braids with the capacity to absorb, 
collect, and deliver energy and light. J. Sabin, <www.jennysabin.com/>.  6. P. Oliver, ed., Encyclopedia 
of Vernacular Architecture of the World (Cambridge: Cambridge University Press, 1997). 7. Schön coined 
the term reflection-in-action in terms of teaching artistry, using case studies from architectural studio 
education as well as music. D. Schön, Educating the Reflective Practitioner: Toward a New Design for 
Teaching and Learning in the Professions (Jossey-Bass: San Francisco, 1990). 8. For textiles, Semper 
uses the term plaiting to mean interwoven objects. He uses the term weaving to criticize the contemporary 
practice of industrial weaving as lacking a practical aesthetic and drowning in its excessive resources, 
in comparison to traditional weaving (by the Hindus and Kurds), far simpler and less industrial but with 
a greater understanding of art. Furthermore, Semper stratifies textile art into the following: 1) bands 
and threads, 2) spun yarn, 3) twisted yarn, 4) the knot, 5) the loop stitch, 6) plaiting, and 7) felt. 
To analyze structural performance in plain interwoven surfaces, this research uses knots and plaiting. 
The yarn and how it is twisted plays a significant role in further analysis of material performance of 
interwoven surfaces. G. Semper, The Four Elements of Architecture and Other Writings, trans. Mallgrave 
and Herrmann (Cambridge: Cambridge University Press, 1989). 9. F. Otto, Institute for Lightweight Structures 
(IL) (University of Stuttgart, 1969). 10. M. Garcia, Introduction: Architecture + Textiles = Architextiles, 
Architectural Design, 76(6), 5 11. 11. Gibson refers to the haptic system as an apparatus by which the 
individual receives information about both the environment and his body. In addition, Gibson warns that 
what is simple for mechanics is not simple for human mechanoreception a tactual receptor of mechanical 
energy in all of its manifestations, including vibration and that biomechanical stimulation is not reducible 
to physical magnitudes. However, information about stress/strain, forces, vector direction, and coordinates 
are compatible enough with digital computation, enabling it to perform the weaving of the structural 
configuration but not the total sensory experience of the weaver. J.J. Gibson, The Senses Considered 
as Perceptual System (Boston: Houghton Mifflin, 1966). 12. J.J. Gibson, The Senses Considered as Perceptual 
System (Boston: Houghton Mifflin, 1966). 13. G. Semper, The Four Elements of Architecture and Other 
Writings, trans. Mallgrave and Herrmann (Cambridge: Cambridge University Press, 1989). 14. J.J. Gibson 
[12]. 15. G. Stiny, Shape: Talking about Seeing and Doing (Cambridge: MIT Press, 2006). 16. T. Knight, 
Shape Grammar and Color Grammar in Design, Environment and Planning, No. 21, 705 735 (1994). 17. W.J. 
Mitchell, Functional Grammars: an Introduction, Reality and Virtual Reality, Association for Computer 
Aided Design in Architecture (1991). 18. G.W. Flake, The Computational Beauty of Nature: Computer Explorations 
of Fractals, Chaos, Complex Systems, and Adaptation (Cambridge: MIT Press, 1998). 19. T. Knight and 
L. Sass, Visual Physical Design Grammar, SIGGRAPH 2008 Design and Computation Gallery: Complexity and 
Craftsmanship. 20. P. Prusinkiewicz and A. Lindenmayer, The Algorithmic Beauty of Plants (Springer-Verlag: 
New York, 1990). 21. A. Killian, Fabrication of Partially Double-Curved Surfaces out of Flat Sheet Material 
through a 3D Puzzle Approach, ACADIA Proceedings (2003). 22. A. Siza, Serpentine Gallery Pavilion 2005, 
Serpentine Gallery, London (2005). 23. K. Snelson, Kenneth Snelson: The Nature of Structure, New York 
Academy of Sciences, New York (1989). 24. J.A. Frumar et al., Tensegrity Structures with 3D Compressed 
Components: Development, Assembly and Design, Journal of the International Association for Shell and 
Spatial Structures, Vol. 50, No. 2, 99 110 (2009). 25. Y. Weinand, Innovative Timber Constructions, 
Journal of the International Association for Shell and Spatial Structures, Vol. 50, No. 2, 111 120 (2009). 
 26. Centre Pompidou-Metz, Centre Pompidou-Metz (Paris: Editions du Centre Pompidou, 2008).   
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1836790</article_id>
		<sort_key>40</sort_key>
		<display_label>Pages</display_label>
		<pages>9</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Glowing Pathfinder Bugs]]></title>
		<subtitle><![CDATA[a natural haptic 3D interface for interacting intuitively with virtual environments]]></subtitle>
		<page_from>350</page_from>
		<page_to>358</page_to>
		<doi_number>10.1145/1836786.1836790</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836790</url>
		<abstract>
			<par><![CDATA[<p><i>Glowing Pathfinder Bugs</i> is an interactive art project primarily aimed at children and created by the digital arts group Squidsoup. It uses projection to visualize virtual bugs on a real sandpit. The bugs are aware of their surroundings and respond to its form in their vicinity. By altering the topography of the sand, participants affect the bugs' environment in real time, facilitating direct communication between them and computer-generated creatures.</p> <p>This highly malleable and tactile physical environment lets us define and carve out the landscape in which the creatures exist in real time. Thus, virtual creatures and real people coexist and communicate through a shared tactile environment. Participants can use natural modes of play, kinesthetic intelligence, and their sense of tactility to collaboratively interact with creatures inhabiting a hybrid parallel world.</p> <p>This paper describes the project and analyzes how children in particular respond to the experience; it looks at the types of physical formations that tend to be built and notes how children instinctively anthropomorphize the bugs, treating projected imagery as living creatures - though with a ludic twist.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Artificial, augmented, and virtual realities</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Virtual reality</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010392</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Mixed / augmented reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010866</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264033</person_id>
				<author_profile_id><![CDATA[81100148835]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Anthony]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rowe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Institute of Design, Oslo, Norway]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P2264034</person_id>
				<author_profile_id><![CDATA[81466647742]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Liam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Birtles]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Arts University College at Bournemouth, Wallisdown, United Kingdom]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Squidsoup, www.squidsoup.org.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1109541</ref_obj_id>
				<ref_obj_pid>1109540</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[E. Ackerman, "Playthings That Do Things: A Young Kid's 'Incredibles'!," <i>Proceedings of IDC 2005</i>, Boulder, Colorado, 1--8 (2005).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258715</ref_obj_id>
				<ref_obj_pid>258549</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[H. Ishii and B. Ullmer, "Tangible Bits: Towards Seamless Interfaces Between People, Bits and Atoms," <i>Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</i>, 234--241 (1996).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[E. Lupton, "Skin: New Design Organics," <i>Skin: Surface, Substance and Design</i> (New York: Princeton Architectural Press, 2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[
<i>Freq2</i>, www.squidsoup.org/freq2.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kinesthetic Intelligence, en.wikipedia.org/wiki/Theory_of_multiple_intelligences.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[
<i>Sandscape</i>, tangible.media.mit.edu/projects/sandscape/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1125678</ref_obj_id>
				<ref_obj_pid>1125451</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. Parkes, V. LeClerc, H. Ishii, "Glume: Exploring Materiality in a Soft Augmented Modular Modeling System," <i>Extended Abstracts of Conference on Human Factors in Computing Systems</i>, ACM Press, 1211--1216 (2006).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1031369</ref_obj_id>
				<ref_obj_pid>1031314</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[H. Ishii, et al., "Sandscape: Bringing Clay and Sand into Digital Design --- Continuous Tangible User Interfaces," <i>BT Technology Journal</i>, Vol. 22, No. 4, 287--299 (2004).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Seevinck and E. Edmonds, "Emergence and the Art System 'Plus Minus Now,'" <i>Design Studies</i>, Vol. 29, No. 6, 541--555 (2008).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[D. Harrison, et al., "Shift-Life: Experiencing the Big Idea," <i>Proceedings of the Digital Arts and Culture Conference</i>, www.escholarship.org/uc/item/9q6716gd?display=all (2009).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Point Grey Bumblebee, www.ptgrey.com/products/bumblebee2/index.asp.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. Hillman, <i>Re-visioning Psychology</i> (New York: Harper and Row, 1976) p. 16.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Squidsoup, <i>Glowing Pathfinder Bugs</i>, www.squidsoup.org/bugs.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Glowing Pathfinder Bugs: A Natural Haptic 3D Interface for Interacting Intuitively with Virtual Environments 
 Anthony rowe Artist/Educator/Researcher Institute of Design Anthony Rowe and Liam Birtles Oslo School 
of Architecture and Design PO Box 6768 St. Olavs plass 0130 Oslo Norway A B s tr A ct ant@squidsoup.org 
Glowing Pathfinder Bugs is an interactive art project primarily aimed at children and created by the 
Liam Birtles digital arts group squidsoup. It uses projection to visualize virtual bugs on a real sandpit. 
the bugs are Artist/Educator Arts University College at Bournemouth aware of their surroundings and respond 
to its form in their vicinity. By altering the topography of the Wallisdown, Poole sand, participants 
affect the bugs environment in real time, facilitating direct communication between Dorset BH12 5HH United 
Kingdom them and computer-generated creatures. lbirtles@aucb.ac.uk this highly malleable and tactile 
physical environment lets us define and carve out the landscape in which the creatures exist in real 
time. thus, virtual creatures and real people coexist and communicate through a shared tactile environment. 
Participants can use natural modes of play, kinesthetic intel­ ligence, and their sense of tactility 
to collaboratively interact with creatures inhabiting a hybrid parallel world. this paper describes the 
project and analyzes how children in particular respond to the experience; it looks at the types of physical 
formations that tend to be built and notes how children instinctively an­ thropomorphize the bugs, treating 
projected imagery as living creatures though with a ludic twist. Introduction Glowing Pathfinder Bugs 
builds on Squidsoup s interests in combining informal modes of communication with the individual s sense 
of space be that visual, physical, social, or emotional space to create an arena where meaningful and 
creative interaction can occur [1]. The piece is an attempt to provide an environment where people, primarily 
children, can collaboratively engage with (and attempt to control) responsive elements in a highly tactile, 
multisensory, spatial environment.  The piece is effectively a dynamic, responsive world in miniature. 
Initial ideas revolved around weather patterns and flooded land­ scapes, but it became clear that the 
real interest was not in the landscape itself, but the creatures that live in it. By focusing on the 
relationships between the environment and its inhabitants, the project developed into a malleable inhabited 
space, where the virtual creatures are aware of, and respond to, their changing environment. The environment 
itself Figure 1. Glowing Pathfinder Bugs, detail. can be manipulated and controlled from a &#38;#169; 
2009 squidsoup.org. God-like perspective by participants. The initial inspiration for the piece came 
from the artists observations of their own children at play, both in traditional sandpits and with animals. 
The powerful impetus children feel to anthropomorphize and create narratives around living creatures 
[2] seemed to have a reso­nance with the landscaping potential of the sandpit. From an interaction design 
perspective, the technical interpretation developed out of a search for new modalities for creative interaction, 
mediating virtual experiences and systems in physical space. This came from a desire, in common with 
broader efforts within the tangible interactions and physical computing move­ ments, to seamlessly bridge 
the gap between tactile materials and computerized systems [3]. Natural user interfaces are, and have 
been for a while, moving more into natural material interfaces, where the properties of a physical mate­rial 
are defined or designed according to the requirements and affordances of the application [4]. In the 
case of Glowing Pathfinder Bugs, the initial motive was to use an engaging physical interface to sculpt 
the topography of a virtually inhabited environment, with a minimal learning curve. The project developed 
in part from a series of projects by the artists that use the human body to control hybrid experiences 
in real time. Glowing Pathfinder Bugs draws in particular on Freq2 (Figure 2) [5], where participants 
silhouettes are used to define the leading edge of an extruding virtual landscape. In Glowing Pathfinder 
Bugs, the physical landscape is mapped directly into virtual space; any changes to the physical topography 
of the sandpit are immedi­ ately mirrored in the virtual environment. However, the themes of communication 
and collaboration, the sense of and control of real and virtual space are present in nearly all of Squidsoup 
s work (see, for example, Driftnet, Come Closer, Altero, and Ocean of Light). These works are also part 
of a broader lineage of artworks that merge physical environments with connected virtual layers; examples 
of this range from David Small s Stream of Consciousness to the large-scale projected works of AntiVJ 
and UrbanScreen. sand as Interface Sand was selected as the interface for a number of reasons. It is 
a material that most children are very familiar with and play with instinctively; thus it brings the 
right affordances with it, enticing interaction and engagement. Its physical properties, in particular 
its malleability, can also be easily controlled. The addition of a little water to the sand makes it 
sticky and malleable, able to be formed into steep mountains, valleys, tunnels and spires. Its associations 
with beach holidays and sand castles, suggesting fun and carefree play, are perfect for attracting younger 
(and older) participants. Additionally, it fulfils a vital role in harnessing kinesthetic intelligence 
[6], allowing for creative dynamic spatial interaction.  The Tangible Media Group at MIT has also explored 
the use of malleable materials like sand as interface [7,8], though both the application and the technical 
methods used are different from Glowing Pathfinder Bugs. Sandscape, for example, is aimed primarily at 
professional architects/ designers and used for rapidly sketching out possible architectural landscapes. 
Their results suggest that such forms of Continuous TUIs (tangible user interfaces) are intuitive to 
work/ play with, and can be used to facilitate collaboration and promote the involvement of lay people 
[9] ideal for the more intuitive and playful application discussed here. Sand has also been used as 
the interface in other digital art installations. It has been used to symbolize a larger environment, 
though the modes and effects of interaction have been quite different. +-now by Jan Seevinck [10] uses 
dry sand as a time-based sketching tool and looks at the emergent forms that arise. Dew Harrison s Shift-Life 
[11], a modelled Darwinian eco-system, also focuses on emergence but through illustrating evolutionary 
artificially intelligent processes that take account only of predefined meta-interactions (e.g., pouring 
acid rain onto the ecosys­tem from a watering can), rather than direct interaction with, and responses 
from, individual creatures. Glowing Pathfinder Bugs is unique in using the sand as the primary mode of 
synchronous communication between participants and virtual creatures. This creates a direct and understand­able, 
yet somewhat unpredictable, form of interaction. The piece has been exhibited at numerous events: almost 
a dozen times in various locations in Northern England as part of PortablePixelPlayground, at SOMA/Art 
Centre Nabi (Seoul, 2009), AbandonNormalDevices (FACT, Liverpool, 2009), iDesign (University of Westminster, 
London, 2009), Onedotzero (BFI London), and Technofolies (Montréal Science Centre, 2010). Glowing Pathfinder 
Bugs Direct Mapping of the Virtual onto the Physical In Glowing Pathfinder Bugs, the sandpit is visible 
from a distance but, on approach, visitors notice small bright creatures wandering about on the sand 
 these are the Glowing Pathfinder Bugs. Each bug is projected onto the sand, and is free to move around 
the sandpit according to certain predefined rules and behaviors (discussed below). The bugs are therefore 
visualized in Figure 3. Glowing Pathfinder Bugs, inhabiting both real and physical space. &#38;#169; 
2009 squidsoup.org. their real location: they can be seen inhabiting the sandpit, they are aware of 
their surround­ings, and they can navigate around obstacles and along gullies as the landscape is forged 
(Figure 3). This means that there is no positional disjunction at play in the installation the real 
and virtual worlds are directly mapped onto each other. Each bug is projected onto a specific coordinate 
in the sand, and is directly aware of, and reacts to, its local physical landscape in real time. If a 
 bug s physical environment is altered, its effect is felt simultaneously in the virtual world. This 
is in stark contrast to the majority of augmented reality or even general metaphor-based interfaces, 
where a positional jump is required. In most interfaces, the physical component of the interac­tion is 
generally at one location and mapped onto a virtual space that is at another location (e.g., the physical 
mouse maps to the virtual on-screen cursor), causing the interactor to cope with a location jump that 
is at odds with our normal relationship with the physical world. Although we are now very familiar with 
such positional disjuncts, its abnormality means that it detracts from participants sense of engagement 
and flow. Children and adults are generally very quick to understand the processes and rules of engage­ment 
in the piece. They appreciate that, by altering the landscape, they directly affect the behavior of 
the bugs. They can encircle them, trapping them in small areas, they can determine where they go, separate 
them, or force bugs together. People recognize there is a clear and direct relationship between their 
actions and those of the virtual bugs. The idea of creative interaction mentioned above extends to how 
people play with the bugs they can be antagonized, terrorized even, but they can also be anthropomorphized, 
cared for, and husbanded. One of the initial intentions of the piece was to encourage a simple form of 
animal husbandry; a sense of looking after, controlling, breeding, and caring for these virtual creatures. 
 Yet the environment in which the bugs live can be regarded as both medium and interface: there are no 
imposed rules that relate explicitly to the use of an interface or sophisticated instruction set that 
requires language or experience to use. The intention here is that any hierarchy that forms among the 
participants is not one of prior knowledge, but is, broadly speaking, an entirely common skillset, a 
skillset that can be observed even in the youngest children, one which you bring with you or that you 
develop collaboratively. A Bug s-Eye View (technical) The project s main technical method evolved from 
experiments using a stereo camera [12] to track body movement and shape in real time. Imagery from calibrated 
stereo camera pairs can be analyzed in real time to produce acceptable quality depthmaps images where 
the color of each pixel denotes its distance from the camera lens (in Figure 4, red is nearest the camera, 
and blue furthest away). The setup for Glowing Pathfinder Bugs points the camera at the sandpit. It 
is positioned directly above the pit, next to a projector that is also pointing in the same direction. 
The two are roughly calibrated, so that the camera image is in alignment with the projected image. Thus, 
projecting the depthmap image, calculated in real time as described above, would make any peaks appear 
red, and troughs appear blue. The depthmap is not, however, displayed or projected except for initial 
calibration. It is used instead as the basis for each bug s decision-making process regarding its trajectory. 
A bug, projected onto a certain location in the sandpit, can easily analyze its matching virtual surround- 
  Figure 4. sample sandpit seen from above, and associated depthmap image. &#38;#169; 2009 squidsoup.org. 
ings (from the related depthmap) and use this topographical information to take appropriate decisions 
as to where to go next (Figure 5). The method is particularly well-suited to recording the topography 
of sand, as overhangs and tunnels are hard to achieve. This means that topo­graphical surfaces that are 
occluded and therefore not detectable by the camera are rare, and an accurate virtual model can be read 
at all times. Speed of movement was used to differentiate sand from faster moving participant limbs. 
Now that the bugs were aware of their surroundings, the next step was to develop a decision­making process 
for the bugs that enabled them to react in a meaningful manner to their changing environment and communicate 
effectively with their human interactors. Figure 5. three stage process involved in Glowing Pathfinder 
Bugs creature analysis and behavior. sand topography is scanned in real time and turned into a virtual 
depthmap layer. the depthmap for the area around each bug is analyzed to determine its new posi­ tion. 
the bug is then projected back onto the sand in the new position. &#38;#169; 2009 squidsoup.org. Bug 
Behavior and User trials Psychologist James Hillman said, Where imagination reigns, personification happens 
[13]. Edith Ackermann points out that this ability to personify and empathize is a key component of learning 
and development, allowing us to appreciate and understand others points of view, and then adjust our 
own. She points to three attributes that maximize engagement with enhanced or animated toys: artificiality 
(how real does the toy appear to be), believability (consistent and meaningful behavior), and conviviality 
(apparent ability to empathise and engage directly in this case associated with anthropomorphic potential). 
All three attributes are important, but the key here is believability in order for the crucial relationship 
between changes to the environment and the behavior of the creatures to be apparent and understandable. 
 To achieve this, various methods of bug-based decision-making were attempted. The require­ments of the 
bugs were: Natural-looking behavior and sense of purpose The bugs need to behave as though they are alive; 
movement is their prime opportunity to encourage anthropomorphism; it can suggest character, optimism, 
courage, and so on. Early models tended to revert to disconcerting behavior patterns: repetitive movements 
where a bug would move rapidly between two points was a common problem. Similarly, code that selects 
the current location as the best available option is undesirable, as the bugs will just stay still, or 
move within tiny areas. Our bugs needed a sense of purposefulness. Ability to distinguish between steep 
and shallow inclines The aim was to create bugs that could be shepherded, controlled, hemmed in. They 
therefore needed to see steep inclines as barriers. Shallow inclines, and shallow drops, needed to be 
acceptable to cope with roughly hewn gulleys. So a relative system was developed that compared the bug 
s current altitude to the possibilities around it while preferencing the area ahead of it. Trials with 
various bug behaviors suggested that those with a preference for modest down­ward inclination were the 
most reliable at following rough gulleys, and so this was adopted as the standard behavior. User trials 
also highlighted two other requirements for the bugs behavior, slightly at odds with each other: Panic 
 The bugs were freqently attacked in trials. Let s pop it and Kill it were common instincts among some 
demographics. It became apparent that the bugs needed an increased instinct for self-preservation. They 
were therefore programmed to de-materialize if under attack. An attack is detected if there are widescale 
rapid changes in the local topography (caused by arm and hand movement picked up near the bug by the 
camera). De-materialization is manifested through a colorful splat (much like that which occurs when 
two bugs metamor­phose, see above), and the threatened bug disappears. It (or another bug, depending 
on one s interpretation) then crawls out of the ground a few moments later in another location. Don t 
panic The bugs needed to perceive the difference between being attacked and friendly advances. Many 
children in the trials wanted to pick the bugs up (Figure 6), which could very easily trigger a panic 
state. The behaviors needed to be adjusted to cope with gentle upward vertical movement, so long as the 
area all around the bug remained at similar heights as it rose. If only part of the bug is picked up 
it will, entirely understandably, panic.  the Narrative Environment As an introduction to the project, 
and to explain the behavior of the bugs in an easy to under­stand way, a playful plotline was built around 
the piece that imagined the bugs had been captured by Victorian explorers in a distant land (Figure 7): 
Recently discovered by Squidsoup researchers in Faroffistan, the Glowing Pathfinder Bug appears to be 
a hybrid centipede/caterpillar. It lives in the sandy deserts of Faroffistan, and has the habit of roaming 
along small trenches, gulleys, and paths. Its usual habitat has been recreated here. The Glowing Pathfinder 
is also a very sociable animal it likes to meet other bugs, and when two Pathfinders meet, VERY strange 
things happen! [You] may be lucky enough to witness their unique and magnificent instant metamorphosis. 
 Some form of reward or positive feedback is required when bug shepherding has been mastered, and two 
creatures meet. A cartoonish interpretation of metamorphosis has been incorporated into the piece for 
this: when two creatures meet, there is a colorful splat, and the two merge into a single, more advanced, 
organism. The visualization (the splat) draws on the stains a butterfly leaves behind when it emerges 
from the chrysalis. Three types of creature were designed: a small, standard bug; a larger, fatter, brighter 
bug (the product of two small bugs merging); and a butterfly (formed when a large bug merges with another 
bug). There are a maximum of six visible bugs at any time. However, each time metamorphosis occurs, two 
bugs merge into one and this leaves a bug free to re-emerge as someone else at another location on the 
sandpit. This gives the piece an indeterminate feeling, as though bugs magically keep appearing, yet 
there are never too many to be able to control effectively. created Environments The relatively simple 
behaviors of the bugs are not complex enough to encourage the production of a wide range of forms in 
the sand. Additionally, the focus of the piece is not on the aesthetics but the function of forms created. 
Nevertheless, the forms are of interest and act as a record of the interactions of participants and the 
communication between kids and bugs. The forms created by participants are surprisingly consistent and 
homogenous, and can be categorized as follows: Mounds These are usually the first form to be built. Part 
rudimentary sandcastle, part test to see the effect on the bugs, mounds are often the first attempt on 
the part of users to affect or communicate with the bugs. A mound is then frequently elongated to form 
a barrier. Barriers At its simplest, a barrier is a wall that divides bugs, stopping them from traversing 
between zones (Figure 8). However, the idea is often expanded, and the wall may subsequently not be perceived 
by the builder as a barrier at all, but more of a challenge to test the behavior of the bug: will the 
bug cross over, how high does the barrier need to be, and so on. Sometimes the building process results 
in a focus on form for its own sake.  Dishes These attempt to bring together; to corral the bugs into 
specific areas. Rather than leaping fences, the bugs can be huddled together, surrounded by the edge 
of the dish. Dishes are generally produced when small groups of participants (2-4) are actively engaged 
in the development of sand forms. Several participants referred to such structures as amphitheatres or 
arenas for combative sport. Gullies Gullies are complex forms that imply leading and direction: children 
are not simply herding or dividing, but are sending the bugs on a journey and so may be creating a narrative 
for the bugs or inventing more complex games from the simple interface. Gullies usually occur either 
as a second barrier (i.e., making a long, narrow zone bounded by two barriers), which then evolves into 
its own form, or through the encouragement of an adult. However, in both cases, the gullies can develop 
into complex branching structures. The motive of the participant is also worthy of note. The behavior 
of the bugs elicits the building of forms that control them. This control can be used to separate and 
isolate, or to bring together to kill or to help procreate and this relationship between cause and effect 
is well understood and ruthlessly exploited (by children in particular). Thus the forms that emerge on 
the surface of the sandpit may look similar but emerge from very different intentions. Similarly, the 
collabora­tive aspects of construction are very complex, and may be competitive or collaborative, and 
geared towards the full range of ends discussed above. Findings and conclusions Glowing Pathfinder Bugs 
was conceived as a small but immersive space where people can commu­nicate directly, and interact physically, 
with responsive virtual creatures. It uses sand as a physical interface that doubles as the environment 
in which virtual creatures live. Ackermann suggests that to optimize engagement and quality of user experience, 
the creatures need to respond in a believable way, simultaneously responding meaningfully to changes 
in their environment, and in a convivial way to engender empathy and relationships, while retaining an 
appropriate level of artificiality. It seems that the design decisions taken have managed to fulfill 
these criteria. Several public trials and exhibitions of the piece have shown that it is effective and 
attracts a large and engaged audience, particularly among younger participants. Attendance time is very 
variable, but some children have stayed for well in excess of an hour, and have frequently returned. 
High levels of flow and immersion in the piece, and affinity with the virtual bugs, were exhibited by 
many participants. These properties are helped by the very direct and physical nature of the interface, 
coupled with the lack of positional disjunction. Bug behavior also, being clearly responsive and quite 
animal-like, assists in building relationships between bug and user, causing in some instances a real 
sense of loss when a bug pops or is killed (this is captured on video see [14]). The bug behavior, design, 
and the use of a sandpit, with all its inherent associations, also  ensure a strong ludic element to 
the piece, putting people in a mental space where play is clearly the point, and is likely to be rewarded. 
The paper undertakes some rudimentary user analysis of the forms created in the sand by participants. 
These are fairly homogenous, but occur for a range of reasons defined by complex and conflicting forces 
(controlling bugs, the will to sculpt form directly, differing perceptions of the processes at play). 
The forms created are very different from those generally sculpted in sand. Further research on this 
aspect of the project would require analysis of the forms created under different circumstances for 
example, by altering the bugs behavior and appeal (e.g., making more realistic bugs, spiders, or snakes). 
At a broader level, it is clear that this kind of approach to physical interface design has huge potential. 
The use of 3D cameras in computer interfaces (whether using an infrared camera or stereo comparisons 
as used here) is an expanding area, though the usage generally focuses on the tracking and analysis of 
body movement and gesture. The potential for using similar technolo­gies and techniques for analyzing 
topography/surface shape is pregnant with possibilities and potential uses. Work so far on this project, 
and others mentioned in this text, point the way for exciting future projects and research. Acknowledgements 
Glowing Pathfinder Bugs was commissioned by Folly for the PortablePixelPlayround. Practical project development 
was carried out by Squidsoup (Anthony Rowe, Liam Birtles, Chris Ben­newith, Gareth Bushell). references 
1. Squidsoup, www.squidsoup.org. 2. E. Ackerman, Playthings That Do Things: A Young Kid s Incredibles 
!, Proceedings of IDC 2005, Boulder, Colorado, 1 8 (2005). 3. H. Ishii and B. Ullmer, Tangible Bits: 
Towards Seamless Interfaces Between People, Bits and Atoms, Proceedings of the SIGCHI Conference on Human 
Factors in Computing Systems, 234 241 (1996). 4. E. Lupton, Skin: New Design Organics, Skin: Surface, 
Substance and Design (New York: Princeton Architectural Press, 2002). 5. Freq2, www.squidsoup.org/freq2. 
 6. Kinesthetic Intelligence, en.wikipedia.org/wiki/Theory_of_multiple_intelligences. 7. Sandscape, 
tangible.media.mit.edu/projects/sandscape/. 8. A. Parkes, V. LeClerc, H. Ishii, Glume: Exploring Materiality 
in a Soft Augmented Modular Modeling System, Extended Abstracts of Conference on Human Factors in Computing 
Systems, ACM Press, 1211 1216 (2006). 9. H. Ishii, et al., Sandscape: Bringing Clay and Sand into Digital 
Design Continuous Tangible User Interfaces, BT Technology Journal, Vol. 22, No. 4, 287 299 (2004). 
10. J. Seevinck and E. Edmonds, Emergence and the Art System Plus Minus Now, Design Studies, Vol. 29, 
No. 6, 541 555 (2008). 11. D. Harrison, et al., Shift-Life: Experiencing the Big Idea, Proceedings of 
the Digital Arts and Culture Conference, www.escholarship.org/uc/item/9q6716gd?display=all (2009). 12. 
Point Grey Bumblebee, www.ptgrey.com/products/bumblebee2/index.asp. 13. J. Hillman, Re-visioning Psychology 
(New York: Harper and Row, 1976) p. 16. 14. Squidsoup, Glowing Pathfinder Bugs, www.squidsoup.org/bugs. 
  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1836791</article_id>
		<sort_key>50</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Touching space]]></title>
		<subtitle><![CDATA[using motion capture and stereo projection to create a "virtual haptics" of dance]]></subtitle>
		<page_from>359</page_from>
		<page_to>366</page_to>
		<doi_number>10.1145/1836786.1836791</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836791</url>
		<abstract>
			<par><![CDATA[<p>This paper describes the work of a group of artists in Australia who used real-time motion capture and 3D stereo projection to create a large-scale performance environment in which dancers seemed to "touch" the volume. This project re-versions Suzanne Langer's 1950s philosophy of dance as "virtual force" to realize the idea of a "virtual haptics" of dance that extends the dancer's physical agency literally across and through the surrounding spatial volume. The project presents a vision of interactive dance performance that "touches" space by visualizing kinematics as intentionality and agency. In doing so, we suggest the possibility of new kinds of human-computer interfaces that emphasize touch as embodied, nuanced agency that is mediated by the subtle qualities of whole-body movement, in addition to more goal-oriented, task-based gestures such as pointing or clicking.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Haptic I/O</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.4.8</cat_node>
				<descriptor>Stereo</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.8</cat_node>
				<descriptor>Motion</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor>Performing arts (e.g., dance, music)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352.10010380</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation->Motion processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010238</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->Motion capture</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352.10010238</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation->Motion capture</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10011752</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Haptic devices</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264035</person_id>
				<author_profile_id><![CDATA[81466647513]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vincs]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Deakin University, Burwood, Victoria, Australia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P2264036</person_id>
				<author_profile_id><![CDATA[81537753556]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McCormick]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Deakin University, Burwood, Victoria, Australia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Daly, "Dance History and Feminist Theory: Isadora Duncan and the Male Gaze," <i>Gender in Performance</i>, L. Senelick, ed. (Hanover, NH: Tufts University Press, 1992) 239--259.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[L. Louppe, trans. S. Gardner, "Corporeal Sources: A Journey through the Work of Trisha Brown," <i>Writings on Dance</i>, Vol. 15, Winter, 6--11 (1996).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. K. Langer, <i>Feeling and Form: A Theory of Art</i> (New York: Scribner, 1953).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. K. Langer {3} p. 178.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Birringer, "Dance Media and Technologies," <i>PAJ, A Journal of Performance and Art</i>, Vol. 24, No. 1, 84--93 (2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Kozel, <i>Closer: Performance, Technologies, Phenomenology</i> (Cambridge, MA, and London: The MIT Press, 2007).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[K. Vincs and K. Blashki, "Diegesis in Poesis: Real-Time Interactive Dance Performance," <i>Proceedings of the 6th DAC Conference</i>, Digital Experience: Design, Aesthetics, Practice, IT University of Copenhagen, December 1--3, 2005, 178--183 (2005).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[K. Vincs and M. Delbridge, "The Silk Road Project, interactive media and live motion-capture performance," Deakin University, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A. Daly {1} p. 253.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. Franco, <i>Dancing Modernism/Performing Politics</i> (Bloomington and Indianapolis: Indiana University Press, 1995).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. K. Langer, <i>Feeling and Form: A Theory of Art</i> (New York: Scribner, 1953).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[A. Daly {1} p. 239--259.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[S. K. Langer, <i>Feeling and Form: A Theory of Art</i> (New York: Scribner, 1953).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. Rovan, R. Wenschler, and F. Weiss, "Artistic Collaboration in an Interactive Dance and Music Performance Environment: Seine Hohle Form, a Project Report," COSIGN 2001, 1st International Conference on Computational Semiotics in Games and New Media, Amsterdam, September 2001, www.cosignconference.org/conference/2001/papers, accessed March 20, 2010.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[H. Bailey, "Ersatz Dancing: Negotiating the Live and Mediated in Digital Performance Practice," <i>International Journal of Performance Arts and Digital Media</i>, Vol. 3, No. 2 &amp; 3, 151--165 (2007).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[J. Martin, <i>The Modern Dance</i> (New York: A. S. Barnes &amp; Company, 1933).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Touching Space: Using Motion Capture and Stereo Projection to Create a Virtual Haptics of Dance Kim 
Vincs and John McCormick AbSTrACT This paper describes the work of a group of artists in Australia who 
used real-time motion capture and 3D stereo projection to create a large-scale performance environment 
in which dancers seemed to touch the volume. This project re-versions Suzanne Langer s 1950s philosophy 
of dance as virtual force to realize the idea of a virtual haptics of dance that extends the dancer s 
physical agency literally across and through the surrounding spatial volume. The project presents a vision 
of interac­tive dance performance that touches space by visualizing kinematics as intentionality and 
agency. In doing so, we suggest the possibility of new kinds of human-computer interfaces that emphasize 
touch as embodied, nuanced agency that is mediated by the subtle qualities of whole-body movement, in 
ad­dition to more goal-oriented, task-based gestures such as pointing or clicking. Introduction In computer-mediated 
environments, where actions and events are conceptual as much as material/physical, what does it mean 
to touch? In this context, a touch point might as easily be virtual as physical. But what would the nature 
of virtual touch be? Questions about the nature of touch and response are really questions about the 
nature of agency the power and the will to act within/on an environment. A touch might not, in a digital 
context, be thought of as exclu­sively physical, but, on the other hand, given the complex relationships 
between embodied experience and haptic sensation, might not be entirely conceptual. Dance has, in the 
wake of the objectivist, formalist dance that arose during the 1960s and 1970s, tended to think of agency 
primarily through the materiality of the moving body. Underpinned by the complex association between 
subjectivity and the materiality of the dancing body that has been traced back to Isadora Duncan and 
the beginning of modern dance [1], subjectivity has been considered to be inscribed in fundamental movement 
patterning [2]. Earlier theories, however, were more focused on the nature of agency itself in dance, 
than on its inevitable relationship with the materiality of the dancer s physical body. Writing in the 
1950s, philosopher Susanne K. Langer put forward the hypothesis that the primary illusion of dance is 
virtual force [3]. She argued that dancers create symbolic representations of agency and will of power 
 by evoking forces that appear to animate their bodies/selves from within. Langer was describing what 
might, from a contemporary perspective, be re-versioned as a form of virtual haptics a metaphorical 
touching of the space around a dancer. There was no inherent materiality in Langer s idea of dance as 
virtual agency because she believed that the original source of dance s primary illusion, which she called 
vital gesture, was, itself, an illusion. For Langer, a dancer perturbing space was an illusion created 
by carefully calculated movement trajectories and dynamics. Dance is actual movement, but virtual self-expression 
[4]. She described dance as the first instantiation of a mythical consciousness Kim Vincs Artist Deakin 
Motion.Lab Deakin University, Burwood Campus 221 Burwood Highway, Burwood, Victoria Australia 3125 kvincs@deakin.edu.au 
John McCormick Artist Deakin Motion.Lab Deakin University, Burwood Campus 221 Burwood Highway, Burwood, 
Victoria Australia 3125 john.mccormick@deakin.edu.au in which the world was understood as a web of living 
forces, powers with will, agency, and purpose. Dance, in her view, crafts images of these experiences 
of agency and power. Langer describes dance as pure agency. Leaving aside for the moment her critique 
of the mythic consciousness as an early stage of human development (which can be understood as specific 
to the historical context of 1950s evolutionist/universalist thought), Langer s writings provide a provocative 
starting place for exploring the idea that dance might encompass virtual, as well as actual, physical, 
touch. Touch in digital environments has been virtualized distanced from being, agency, sensation, by 
the abstract, utilitarian nature of most human-computer interfaces. Dance might provide a means of exploring 
ways of reinserting the complexity of whole-bodied agency the nuance of physical sensation and action 
 within virtualized digital interfaces. Figure 1. Dancers Lisa bolte and Adam Thurlow perform a pas 
de deux with real-time motion capture generated stereo-projected particle trails, created using Autodesk 
s Motion builder. The particle trails and levels of particle acceleration are generated by the movements 
of different combinations of markers from both dancers. The image is composited to give a sense of the 
effect, due to the difficulty in recreating the 3D illusion. Photo &#38;#169; James Lauritz Photography. 
This paper describes a project that re-reads Langer by designing an interactive dance perfor­ mance system 
that touches space with kinematics, which have embedded in them the subtle, poetic, embodied dynamics 
of dance; trajectory, velocity, acceleration the how of movement, rather than the utilitarian what of 
task-based gestures such as pointing or clicking. The system embeds live dance performance in a large-scale 
3D stereo projection environment driven by live motion capture, to create an interface that responds 
to the quality of movement, which we argue can be understood as a poetic rendering of agency, a state 
of being and acting in the world. The system is, in a sense, a literal realization of Langer s theory, 
made using a technology that reinterprets her idea of virtual force as extended physical agency. This 
paper describes i) the system design, ii) the aesthetic issues involved in creating choreographic processes 
that would facilitate a visualization of Langer s ideas, and iii) an evaluation of this process as a 
means of creating a virtual haptics of dance. Designing and Implementing a Large-Scale 3D Projection 
System and Live Motion Capture Pipeline The primary design goal of the project was to develop a visually 
integrated live/3D stereo environment. The dancer would need to be integrated in physical space with 
the surrounding 3D imagery, and the whole synthesized by an audience into a cohesive visual percept. 
This necessi­tated designing a system with sufficient scale to allow life-sized images to be projected 
behind the dancer, and enough screen width to provide stereoscopic image separation sufficient to bring 
images forward to the depth of the dancer. Because the stereoscopic effect of 3D images project­ing into 
the space is produced by presenting separated polarized images to each eye, if an image moves partially 
off the edge of the screen, the stereoscopic effect is immediately lost. A 400-inch silver-coated reflective 
screen was installed that provided sufficient area to create stereoscopic images that were large enough 
to provide an immersive background for the performers, and which could be moved both behind and in front 
of the plane of the screen. The system was designed to be portable to allow for use in different performance 
configurations. We therefore opted for a customized projector/polarized lens-and-glasses system that 
can be repositioned and recalibrated for different performance configurations, rather than an off-the­shelf 
system that is difficult and time-consuming to recalibrate and cannot be easily moved to trial different 
performance configurations. Motion capture was integrated using a 24-camera Motion Analysis optical system 
capturing a 10m x 10m volume. The stereoscopic screen was positioned at the back of the capture volume. 
The audience viewed the performance wearing polarized glasses and saw 3D imagery, driven in real time 
by the dancers motion capture data, projected both behind and in front of the projection plane. The 3D 
imagery appeared, at different times, to expand the dimen­sions of the performance space behind the projection 
screen, and to come forward off the screen to swirl around the dancers. Positional motion capture data 
from 30 markers was streamed in real time to Autodesk s Motion Builder software and to the Unity game 
engine to provide a range of possibilities for constructing motion graphic environments. As this was 
an exploratory project, the team decided to trial a number of different approaches to creating stereo 
imagery that were subsequently shown as a series of seven short (approximately five-minute) vignettes. 
Figures 1 through 4 show the main visual elements used across the seven vignettes. The images are composited 
to recreate the live effects, given that it is impossible to recreate the stereo experience using either 
still or moving images. The vignettes used variations on three main approaches to create different kinds 
of virtual topographies from the dancers movements that were projected across the performance space in 
3D. The first approach was to create particle systems that acted as trails, creating a moving topography 
that both mapped and amplified into the space the movements of specific markers (Figure 1). The second 
approach created a continu­ous trail from the movement of a single marker (Figures 2 and 3), which created 
a visual record of the entire movement sequence. Virtual camera controls within the program allowed us 
to fly through the trace as it was created, which had the effect of rotating and zooming the image as 
it was created. The third approach generated a moving topography of geometric shapes that  expanded 
and contracted in response to the dancers movements (Figure 4). Choreographic/Artistic Processes Developing 
Aesthetic Approaches that Would Underpin a Virtual Haptics of Dance The aesthetic goal of the project 
was to augment the dancer s physical influence by extending it into the surrounding volume. We were not 
interested, therefore, in creating an improvisational, interactive environment between the performer 
and the imagery. Improvisational approaches position the dancer within an explicitly interactive dialogue 
with the technology by cultivating and presenting for view reiterative feedback loops of intentionality 
in which dancers respond to images driven by their own actions. While improvisational approaches have 
dominated computer-mediated dance performance because they foreground the interaction between dancer 
and technology as systems of relationship [5, 6], and we have ourselves employed this approach in the 
past [7, 8], this project called for a different approach. We were interested in creating an environment 
that seemed to extend the dancers influence, their apparent interiority in Langer s terms, across a volume 
of external space. The image here is not one of feedback, of responding to a system that is, at least 
partially, a result of one s own actions, but rather one of influence, in which one s own sense of physical 
agency radiates outwards and imposes itself on the surround­ing space. This approach had a certain practical 
resonance with the fact that, when using this particular 3D projection system, the performer cannot see 
the stereo images she creates. Even if the performer wears polarized glasses, the image separation is 
calibrated for the audience and the image appears at radically different depths from the projection plane 
for audience and performer. This, in itself, might be surmountable through a reverse engineering process 
in which a performer could rehearse with polarized glasses and mentally re-calibrate the image position 
from the audience s point of view. However, the immersion in a 3D environment, the sudden visual/ visceral 
shifts in the z-axis that characterize the 3D experience, remain unavailable to the performer because 
visual perception of a 3D image is only possible when facing directly to the screen. Consequently, true 
interaction between the performer and 3D images based on the performer s embodied, kinesthetic/artistic 
sensibility is impossible in this kind of project. Use of a head-mounted display would give the dancer 
an awareness of their relationship to the 3D environment, however the works were designed from the perspective 
of an external audience viewpoint, not the dancer s subjec­tive view. A further aesthetic issue was the 
question of genre. Contemporary dance, by virtue of its Figure 3. Dancer Adam Thurlow performs with real-time 
motion historical underpinnings in modern dance, capture generated stereo single marker trace created 
using brings with it strong and complex contextual Unity game engine. A single marker (in this case the 
wrist associations with the presentation of subjectiv­ marker, to take advantage of the multiple turns 
and leaps in the ity. Modern dance embraced the apparent movement material) is used to generate a standing 
trace of an production of subjectivity, which Daly terms, entire sequence of movement. The image is composited 
to give a sense of the effect, due to the difficulty in recreating the 3D in her discussion of Isadora 
Duncan, the illusion. Photo &#38;#169; James Lauritz Photography. process of making ongoing movement 
a  metaphor for what they then termed soul, what we call the self [9]. Objectivist dance, firstly through 
the influential formalism of Merce Cunningham and then through the work of the postmodern dancers of 
the 1960s and 1970s, problematized this emphasis on dance as a metaphor for self, using the material 
physicality of dancers movement to expose the illusory nature of the subjectivity it had come to suggest. 
However, the material reality of the dancing body and the production of images of subjectivity in dance 
are not mutually exclusive, but are interre­lated in complex ways, even in the work of artists who might 
seem to be purely expressive and objectivist choreographers, such as Graham and Cunningham, respectively 
[10]. For this project, we sought to drive a disjuncture between what Langer termed self-portraiture 
as the central motif in solo modern dance, along Figure 4. Dancer Lisa bolte performs with real-time 
motion with the reaction it creates objectivist, non­capture generated geometric topography created 
using subjectivist dance and the notion of agency in Unity game engine. The spheres unfold in different 
con­ movement [11]. Drawing inspiration from figurations, the scale, direction, and configuration of 
which Langer s idea of a world alive with teleological are driven by the movement of a single marker 
(in this case the ankle marker, to take advantage of the linear shapes of forces, we wanted to avoid 
locking those forces the adagio movement). The image is composited to give a too quickly into either 
the psychologically sense of the effect, due to the difficulty in recreating the charged portrait of 
dancer-as-self or the objectiv­3D illusion. Photo &#38;#169; James Lauritz Photography. ist denial of 
interiority, which are associated, respectively, with expressionist and formalist formulations of contemporary 
dance. Instead, we chose to explore contemporary ballet, with its more distanced understanding of the 
performer-character relationship as one of expression but not necessarily autobiographical association. 
This genre offered, perhaps in some ways ironically, our contemporary dance team a less familiar and 
conventionalized space in which to explore a virtual haptics of dance. Ballet, while certainly subject 
to its own conventions of expressivity, provided a movement palette that allowed us to venture into emotionally 
charged territory without automatically referencing the complex ramifications of the modern dance tradition 
of dancing self as an embodiment of Nietzschian will [12], in which a created personality is given the 
dancer s name [13]. For the first vignette, we developed a choreographed solo that played on the strengths 
of the female dancer, who is an Australian principal ballerina known for her virtuosic technique, musicality, 
and powerful emotional interpretations. We created a stereo environment that used the position and speed 
of head, wrist, spine, hip, shoulder, and ankle markers to generate particle streams. The use of a high-end, 
commercial optical motion capture system was critical to achieving traces that contained the precise 
trajectory and dynamic of the dancer s movement. These were rendered with virtually no perceptible time 
lag between movement and trace. This ensured that the poetic of the movement quality inherent in the 
trajectory and dynamics of the marker movement was preserved within the 3D environment. Creating and 
maintaining a stable full-body template of the performer in real time was challenging, but essential 
to this process, as well as constituting a significant technical achievement in and of itself. The spatiality 
of the projected 3D imagery was mathematically resized and repositioned to compensate for effects of 
the virtual cameras in the software, which amplify the performer s movement closer or further away along 
the z-axis with respect to the real space into which the environment is projected. This amplification 
causes mismatches between the scale of the performer and the relative positions of the marker-driven 
particle trails, which presented both a technical problem to be solved and also an opportunity for creating 
levels of abstraction in the imagery. Rovan et al. argue that a degree of abstraction is necessary in 
interactive performance to prevent an over-predictable system [14]. In our process, while the particle 
trails were clearly related to the performer s movement dynamics, they were also spatially offset and 
their trajecto­ries magnified, so that they seemed to move in the space with the dancer but not to consistently 
correlate with specific body parts. The spatial mapping between marker and resultant particle trail varied 
with the distance of the performer from the origin of the capture space along the x- and z-axes, resulting 
in an ambiguous, if clearly related, connection between performer and image. The particle trails were 
imbued with extra acceleration that responded to a threshold root marker velocity, so that the trails, 
which seemed to stream behind the dancer as she moved, elongated with faster movement, but also seemed 
to fly further out into space, to disperse and decay, when the dancer moved through space at speed. The 
effect was of an increased impact on the space with movement, while, conversely, less movement resulted 
in more compact trails that seemed to coalesce into fiery streams. Complicating this pattern was the 
different dynamic of the twelve markers driving the trails, which gave rise to constant variation within 
the appearance of the different particle effects. The conceptual coherence of a highly skilled dancer 
s body moving in harmonic, physically grammatical, ways, contrasted with the particle trails, which seemed 
to amplify the discordance of the movement parameters (velocity, acceleration) that create the seemingly 
composed, integrated physicality one sees watching the dancer. Juxtaposing these two radically different 
percepts of the dancing body, in the context of an elite, virtuosic contempo­rary ballet performance, 
created a layered and nuanced sense of agency. Rather than a purely or simply psychological metaphor, 
the work created a sense of the dancer s agency that rippled out into the surrounding volume in ways 
that were at once psychological/imagistic and mathemati­ cal/abstract. Performance Outcomes Topographies 
of a Virtual Haptics of Dance The effect of projecting real-time 3D images around a dancer was to require 
the explicit complic­ity of the audience. The perceptual concentration required when watching the final 
performances was reminiscent of attempting magic eye puzzles in which one must create a disjuncture between 
visual accommodation (focus) and convergence to accept two separated images as a single visual percept 
that seems to float off the page. Helen Bailey, discussing her Stereobodies project, which presented 
audiences with two dancers, one real and one a stereo projection, suggests that this process requires 
a significant suspension of disbelief that highlights the theatricality of the event [15]. The complex 
3D pathways of the stereo imagery in our project, and the constantly changing spatial relationships between 
performer and images, demanded a fundamentally perceptual synthesis of spatial topography. Audiences 
had to fuse dancer and projected trompe l oeil into a single geometrical percept before a theatrical 
suspension of disbelief could occur. Even when this synthesis was accomplished, it was somehow more a 
metaphorical, conceptual fusion than a simply visual one. Watching, one knows that the particle trails 
are artificial. They have no substance, no mass, and consist purely of light, so that while we may think 
we know where they are on the z-axis, we do not know what they are. This allows a metaphorical space 
in which the imagery can be what we want it to be. However, it is still material in that it is precisely 
connected to the performer s movement dynamics by virtue of its replication of the spatial trajectory, 
velocity, and acceleration of the movement. The dancer walks forward with quiet tension, and streams 
of fire extend behind her head. She lies on her back and looks into the distance, and trails seem to 
swirl around her head. She pirouettes, and fireflies seem to float in the air around her. Other vignettes 
created for this project suggested different kinds of metaphors. A classical ballet pas de deux generated 
particle trails from each dancer that interwove in an abstract/metaphoric representation of the touch 
between the two bodies, while enlivening the air above the dancers by extending their movement dynamics 
into space. The technical requirements of re-spatializing the particle trails generated by two dancers 
displaced the image further from the performers. This extended the reach of the dancers apparent influence 
on the volume, but also stretched the conceptual and perceptual synthesis required of the audience as 
the spatial mapping became more abstracted. In contrast, the visually denser environments created using 
Unity generated a single electrified trace from the wrist movement of an entire dance and streams of 
geometrical shapes that created an evolving series of spiraling spheres. These processes created larger, 
more cohesive environments. The images were much larger than the performers and created a kind of all-encompassing 
backdrop to the dance that engaged large portions of the audience s peripheral vision. This approach 
was a much easier visual/perceptual prospect, and while the images tended to be behind rather than around 
the plane of the dancer, these works created the most cohesive visual effects. Each of the works generated 
a different kind of topography by extending the illusion of agency embedded in the dancers movements 
into the surrounding volume. This implies touch, but proprioceptive feedback in these systems is virtual, 
not actual. The space cannot touch back. However, an audience can read into the imagery what they might 
feel were they to touch space in this expanded, amplified way. Virtual proprioceptive experience in this 
project could be thought of as similar to virtual kinesthetic experience in John Martin s formulation 
of meta­kinesis, through which observers construct and feel kinesthetically while watching a dancer s 
movement that is based on their expectations of what they would feel if performing that move­ment [16]. 
Conclusion For Langer, influence was illusory, an image drawn from pre-scientific culture in which magical/ 
spiritual forces were the only conceptual possibility, and transplanted into a scientific culture in 
which personal agency is a symbolic representation of the feeling of power. However, in the electronic/digital 
environment of the 21st century, an understanding of agency in precisely the sense of understanding the 
world as comprising a system of potentially, metaphorically, and sometimes actually teleological forces 
is needed to make sense of new technologies, new intelligences, new conceptions of being. This project 
uses interactive dance performance to question, challenge, and suggest new ways of imagining the haptics 
of touch as fundamentally intertwined with a new, perhaps neo-teleological, understanding of personal 
agency and action. Langer s idea of agency is about influence. It is holistic, but not exclusively material/physical. 
Langer s virtual force is not influence segmented by the discrete language of gesture point, click, 
yes, no. But, equally, it is not exerted solely through an undifferentiated, organic/embod­ied physicality. 
This project provided a process for mapping dance movement to what might be thought of as a way of virtually 
touching space. The distinction between touch as a completed gesture and touch as a manifestation of 
presence, will, and agency can perhaps be defined by the ability to embed the nuance of personal action, 
which in dance translates to the qualities of movement, within an externalizing technological system 
that also displays the brush strokes of trajectory of actions that are not gestures as such, but gestural 
in their deliberate spatiality. This project, in creating such a system, provided, firstly, a comment 
on the nature of touch as agency and, secondly, a nuanced and sensitive system for extending the possibilities 
of dance beyond the dancer s body and into the surrounding metaphorical and physical volume. Acknowledgements 
The authors would like to acknowledge the dancers, Lisa Bolte and Adam Thurlow, musicians Rob Vincs and 
James Wakeling, technical team Daniel Skovli and Peter Divers, administrator Kim Barbour, and lighting 
designer Scott Allan, for their extraordinary artistry and technical expertise, their willingness to 
embark with us on such a radical artistic journey, and their ability to make the journey such an enjoyable 
one. This project was supported by the Deakin Motion.Lab, Deakin University, through Deakin University 
s Research Infrastructure Scheme Grant, and by the Australian Research Council s Discovery Projects funding 
scheme (DP0987101). references 1. A. Daly, Dance History and Feminist Theory: Isadora Duncan and the 
Male Gaze, Gender in Performance, L. Senelick, ed. (Hanover, NH: Tufts University Press, 1992) 239 259. 
 2. L. Louppe, trans. S. Gardner, Corporeal Sources: A Journey through the Work of Trisha Brown, Writings 
on Dance, Vol. 15, Winter, 6 11 (1996). 3. S.K. Langer, Feeling and Form: A Theory of Art (New York: 
Scribner, 1953). 4. S.K. Langer [3] p. 178. 5. J. Birringer, Dance Media and Technologies, PAJ, A Journal 
of Performance and Art, Vol. 24, No. 1, 84 93 (2002). 6. S. Kozel, Closer: Performance, Technologies, 
Phenomenology (Cambridge, MA, and London: The MIT Press, 2007). 7. K. Vincs and K. Blashki, Diegesis 
in Poesis: Real-Time Interactive Dance Performance, Proceedings of the 6th DAC Conference, Digital Experience: 
Design, Aesthetics, Practice, IT University of Copenhagen, December 1 3, 2005, 178 183 (2005). 8. K. 
Vincs and M. Delbridge, The Silk Road Project, interactive media and live motion-capture performance, 
Deakin University, 2007. 9. A. Daly [1] p. 253. 10. M. Franco, Dancing Modernism/Performing Politics 
(Bloomington and Indianapolis: Indiana University Press, 1995). 11. S.K. Langer, Feeling and Form: A 
Theory of Art (New York: Scribner, 1953). 12. A. Daly [1] p. 239 259. 13. S.K. Langer, Feeling and 
Form: A Theory of Art (New York: Scribner, 1953). 14. J. Rovan, R. Wenschler, and F. Weiss, Artistic 
Collaboration in an Interactive Dance and Music Performance Environment: Seine Hohle Form, a Project 
Report, COSIGN 2001, 1st International Conference on Computational Semiotics in Games and New Media, 
Amsterdam, September 2001, www.cosignconference.org/conference/2001/papers, accessed March 20, 2010. 
 15. H. Bailey, Ersatz Dancing: Negotiating the Live and Mediated in Digital Performance Practice, International 
Journal of Performance Arts and Digital Media, Vol. 3, No. 2 &#38; 3, 151 165 (2007). 16. J. Martin, 
The Modern Dance (New York: A.S. Barnes &#38; Company, 1933).  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<article_sponsors>
			<funding_agency>Australian Research Council's Discovery Projects funding scheme</funding_agency>
			<grant_numbers>
				<grant_number>DP0987101</grant_number>
			</grant_numbers>
		</article_sponsors>
	</article_rec>
	<article_rec>
		<article_id>1836792</article_id>
		<sort_key>60</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Visual anecdote]]></title>
		<page_from>367</page_from>
		<page_to>374</page_to>
		<doi_number>10.1145/1836786.1836792</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836792</url>
		<abstract>
			<par><![CDATA[<p>The discourse on information visualization often remains limited to the exploratory function - its potential for discovering patterns in the data. However, visual representations also have a rhetorical function: they demonstrate, persuade, and facilitate communication.</p> <p>In observing how visualization is used in presentations and discussions, I often notice the use of what could be called "visual anecdotes." Small narratives are tied to individual data points in the visualization, giving human context to the data and rooting the abstract representation in personal experience. This paper argues that these narratives are more than just illustrations of the dataset; they constitute a central epistemological element of the visualization. By considering these narrative elements as parts of the visualization, its design and knowledge organization appear in a different light.</p> <p>This paper investigates how the "story" of data representation is delivered. By means of ethnographic interviews and observations, the author highlights the different aspects of the visual anecdote, a specific point where the exploratory and the rhetorical functions of visualization meet.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Theory and methods</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.1.2</cat_node>
				<descriptor>Software psychology</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010216.10010217</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Philosophical/theoretical foundations of artificial intelligence->Cognitive science</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10011748</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Empirical studies in HCI</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003123.10011758</concept_id>
				<concept_desc>CCS->Human-centered computing->Interaction design->Interaction design theory, concepts and paradigms</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003126</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->HCI theory, concepts and models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264037</person_id>
				<author_profile_id><![CDATA[81332519345]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dietmar]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Offenhuber]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Massachusetts Institute of Technology, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>300679</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[S. K. Card, J. D. Mackinlay, and B. Shneiderman, <i>Readings in Information Visualization: Using Vision to Think</i> (San Francisco: Morgan Kaufmann, 1999).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[E. R. Tufte, <i>The Visual Display of Quantitative Information</i> (Cheshire, Connecticut: Graphics Press, 2001).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[B. Latour, <i>Reassembling the Social: An Introduction to Actor-Network-Theory</i> (Oxford: Oxford University Press, 2005).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1079847</ref_obj_id>
				<ref_obj_pid>1079828</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. Chen, "Top 10 Unsolved Information Visualization Problems," <i>IEEE Computer Graphics and Applications</i>, Vol. 25, 12--16 (2005).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. Kaiser, "Stick-Figure Realism: Conventions, Reification, and the Persistence of Feynman Diagrams, 1948--1964," <i>Representations</i>, 49--86 (2000).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Kaiser {5}.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Gallop, <i>Anecdotal Theory</i> (Durham, North Carolina: Duke University Press, 2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2206941</ref_obj_id>
				<ref_obj_pid>2206936</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[
C. F. Chabris and S. M. Kosslyn, "Representational Correspondence as a Basic Principle of Diagram Design," <i>Lecture Notes in Computer Science</i>, Vol. 3426, 36 (2005).
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[K. S. McLeod, "Our Sense of Snow: The Myth of John Snow in Medical Geography," <i>Social Science &amp; Medicine</i>, Vol. 50, 923--935 (2000).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[H. Brody et al., "Map-Making and Myth-Making in Broad Street: the London Cholera Epidemic, 1854," <i>The Lancet</i>, Vol. 356, No. 9223, 64--68 (2000).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Gallop {7}.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[SENSEable City Lab, www.senseable.mit.edu/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[B. Latour {3}.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[SENSEable City Lab, Obama | One People, February 2009, www.senseable.mit.edu/obama/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[F. Calabrese and C. Ratti, "Real Time Rome," <i>Networks and Communication Studies</i>, NETCOM, Vol. 20, No. 3--4, 247--257 (2006).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[F. Hartmann and E. K. Bauer, <i>Bildersprache: Otto Neurath Visualisierungen</i>, 2nd ed. (Vienna: Facultas. wuv Universit&#228;ts, 2006).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>503423</ref_obj_id>
				<ref_obj_pid>503376</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[P. Baudisch et al., "Keeping Things in Context: A Comparative Evaluation of Focus Plus Context Screens, Overviews, and Zooming," <i>CHI '02: Proceedings of the SIGGCHI Conference on Human Factors in Computing Systems</i> (ACM Press, 2002) 259--266.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Visual Anecdote Dietmar Offenhuber AbstrAct the discourse on information visualization often remains 
limited to the exploratory function its poten­tial for discovering patterns in the data. However, visual 
representations also have a rhetorical function: they demonstrate, persuade, and facilitate communication. 
 In observing how visualization is used in presentations and discussions, I often notice the use of what 
could be called visual anecdotes. small narratives are tied to individual data points in the visualiza­tion, 
giving human context to the data and rooting the abstract representation in personal experience. this 
paper argues that these narratives are more than just illustrations of the dataset; they constitute a 
central epistemological element of the visualization. by considering these narrative elements as parts 
of the visualization, its design and knowledge organization appear in a different light. this paper 
investigates how the story of data representation is delivered. by means of ethnographic interviews and 
observations, the author highlights the different aspects of the visual anecdote, a spe­cific point where 
the exploratory and the rhetorical functions of visualization meet. the story of Visualization: Where 
Is It Located? What do people mean when they speak colloquially of the story of a visual data representation? 
How is the story connected to the visualization and where is it located? This relationship depends on 
how visualization is used, for it can serve two purposes: thinking and showing. Visualization fulfills 
both an exploratory function, as a tool for finding new knowledge, and a rhetorical function, as a vehicle 
for communicating meaning. the Exploratory Function The discourse in the information visualization community 
traditionally focuses on the explor­ atory aspects. The main objective of information visualization, 
according to common definitions [1], is to amplify cognition by externalizing thought processes. As a 
tool for crystallizing new knowledge, visualization allows us to perceive and recognize patterns in data. 
In this context, the story refers to the patterns and structures hidden in the representation. Thus, 
the story is inside, implicitly embedded in the data. While the persuasive power of images is generally 
acknowledged, the ethical codex of information visualization demands skepticism, by avoiding everything 
that might distort the nature of the data [2]. the rhetorical Function In contrast to the exploratory 
approaches emphasized in the information sciences, theorists of diagrammatic representations tend to 
focus on the rhetorical function of visualization. Bruno Latour, for example, argues that the importance 
of visualization (or, as he calls it, inscription) is, first of all, the unique advantage [it gives] 
in the rhetorical or polemical situation [3]. By this he means the possibility to demonstrate a finding 
in a shared, highly formalized language. The primary advantages of these inscriptions are their mobility 
and immutability, not their percep­tual advantages for discovering patterns, which Latour considers vastly 
exaggerated. In this Dietmar Offenhuber Researcher Massachusetts Institute of Technology Department of 
Urban Studies and Planning 77 Massachusetts Ave, 10-485 Cambridge, MA 02139 USA dietmar@mit.edu  context, 
the story is the (social) narrative associated with representation. Here, the story is located outside, 
in the discursive context of the representation. the coupling of Narrative and structure The various 
visual languages of visualization are generally tightly coupled with the data repre­sented. As long as 
we remain concerned with the description of structures in the data, this coupling between form and content 
is simple and direct. However, once visualization is under­stood as the representation of meaning [4], 
this mapping becomes more ambiguous, since meaning is a mental concept, not a feature of the data. In 
this ambiguous space, both explor­atory and rhetorical functions are intertwined, while the visual vocabulary 
may remain persistent. Narrative and structure in Feynman Diagrams A compelling example of the dynamic 
relationship between notation and meaning can be learned from David Kaiser s analysis of the history 
of Feynman diagrams [5], which demon­strates how an essentially arbitrary visual language outlived the 
theory it initially described. In 1948, Richard Feynman presented the notation technique as a mnemonic 
device for complex computations in the field of quantum physics. In this notation, each visual element 
represents a mathematical relationship associated with a specific particle interaction (Figure 1). Decades 
later, the specific brand of quantum field theory the diagrams are based on became contested and other 
theoretical frameworks were proposed. However, while the theory disappeared, the diagrams stayed: the 
champions of the new theory started to invent new meanings [6] for the diagrams, which otherwise would 
have become useless. The reason for this surprising persistence might be the fact that Feynman diagrams 
offer a persuasive picture of the physical process: they reminded the physicists of the photographs from 
bubble chamber experiments and were compatible with previously established diagrammatic methods such 
as Minkowski diagrams. Thus, the diagrams have served as a vehicle for commu­nication from the very beginning 
and have quickly found their way into textbooks. While the algorithm behind the visual language of the 
diagrams was at all times explicitly defined, the temptation to see them as a pictorial representation 
of reality remained an effect that Kaiser compares to the notion of realism as an apparent ability to 
capture reality. Therefore, Feynman diagrams show both functions of visual representation. On the one 
hand, their visual algorithm simplifies computation and exploration. On the other hand, their apparent 
realism provides them with rhetorical power for discourse. These two functions are not exactly congruent, 
since the pictorial aspect suggests more than the notation explains. Yet both func­tions are simultaneously 
present. the Visual Anecdote Feynman diagrams represent an exceptional example where the two functions 
live contentedly next to each other. However, this is not always the case. More often than not, the rhetorical 
and exploratory functions meet only at a single point in the form of an anecdote. Anecdotes are accounts 
of single incidents, short, seductive and humorous, sometimes true, sometimes invent­ed, with a point 
and a direction. Jane Gallop calls the anecdote a theoretical moment [7], a possible catalyst for a bigger 
theory. While the Oxford English Dictionary defines the anecdote as a narrative of a detached incident, 
or of a single event, told as being in itself interesting and striking, thus emphasizing its detached, 
singular nature, Gallop points out that the anecdote, as a narrative of the moment, calls for contextualization 
into a bigger story. Exactly the same relationships are at work between the exploratory and the rhetorical 
functions of visualization the relationship between a general theory and a specific incident, an abstract 
algorithm and a tangible narrative.  Figure 2. snow s spot map of the Golden square cholera outbreak, 
1854. the broad street pump is located at the center of the map. &#38;#169; 1854 Public Domain. snow 
s Map as a Visual Anecdote I will explain the notion of the visual anecdote through the well-known example 
of John Snow s map of the London cholera epidemic of 1854, one of the strongest narratives of visualization. 
While different versions of the map exist, all of them show two kinds of data: the locations where cholera-related 
fatalities occurred and the locations of public water pumps in the city. In one area of the map, black 
marks aggregate around the famous Broad Street pump, thus suggest­ing a causal connection between that 
pump and the casualties of the disease (Figure 2). There has been some debate about whether the map actually 
led to the discovery of the connection between water and cholera [8]; historical examination revealed 
this role of the map to be a myth [9]. However, the actual role of the map is of no concern in this context; 
instead I will focus on how this map works as a narrative device. From a rhetorical perspective, all 
visual parameters are perfectly adjusted to support the narrative connected to the map. Unlike other 
maps of the cholera outbreak of 1854 [10], Snow s map is perfectly centered on the Broad Street pump. 
Further, the map only contains information about the fatalities and pumps, thus suggesting a connection 
between these two elements. Another issue is the choice of graphic symbols: the fatalities are marked 
as short black lines, resembling small bar graphs aligned to the street network. Only in the area around 
the Broad Street pump is the number of deaths high enough to create a solid black area that is able to 
draw the viewer s attention. The point I want to stress is that the spatial organization of the map 
depends on whether the rhetorical or the exploratory function is examined. From the exploratory perspective, 
the information space is homogenous. The map maintains some generality; it might as well be used to learn 
about the street names in 19th century London. From the rhetorical perspective, how­ ever, the narration 
establishes a spatial hierarchy that divides the map into more and less important areas. The argument 
focuses on one single point, the cluster of fatalities around the Broad Street pump. the Myth of Generality 
To characterize Snow s map as a propagandistic device, however, would be the wrong conclusion. The map 
is not a rhetorical device in the same sense as a billboard, for its visual language is consistent and 
precise. Its rhetorical power depends precisely on this consistency for contextual­izing the anecdote 
into a bigger frame in the sense of Gallop s anecdotal relation to theory [11]. This contextualization, 
however, should not be confused with generalization. Observing presentations involving data visualizations, 
I often notice a rhetorical maneuver: after puzzling the audience with a complex visualization, the presenter 
selects, seemingly arbitrarily, a single data point and connects it to a story, an anecdote that unlocks 
the principle of the whole representation. I suspect that this single data point is seldom as arbitrary 
as it might seem, in fact the whole visualization might be designed to highlight this single point a 
rhetorical device allowing the audience to reproduce the discovery of meaning in the data. Obama | One 
People, sENsEable city Lab In the last section of this paper I will focus on the communication process 
around the presenta­tion and development of data visualizations with interview excerpts from a small 
ethnographic project on the subject matter. The interviews were conducted in the SENSEable City Lab at 
MIT [12], whose objective is to analyze and improve cities based on real-time information sources. While 
the lab is prolific in its visualization production, research on visualization methods is not the ultimate 
objective. Instead, visualizations play a central role in project collaborations with other departments, 
with external sponsors, and in communication with the general public. Projects typically involve a number 
of external academic partners, organizations, or companies forming a consortium. Many projects involve 
public exhibitions, which are not only a means of dissemination, but also a catalyst for research: by 
involving companies and organizations in a prestigious exhibition project, it became possible to gain 
access to datasets that would be otherwise out of reach for research purposes. This complex network of 
relationships makes the Lab a perfect case study for the investigation of the rhetorical aspects of visualization, 
which becomes a mediator [13] and a currency for the negotiation of research between the involved actors. 
 Figure 3. Obama | One People: visualization of call destinations during the 2009 presidential inauguration. 
&#38;#169; 2009 sENsEable city Lab. I first met the designer Mauro Martino, a research fellow at the 
SENSEable City Lab, to talk with him about his visualization of the cell phone activity in Washington, 
D.C., during Presi­dent Obama s inauguration speech [14]. Based on mobile call data from a telecom provider, 
the project tried to answer the following questions: Who was in Washington, D.C., for President Obama 
s inauguration day? When did they arrive, where did they go, and how long did they stay? The dataset 
divided the city into a regular grid containing aggregated mobile call volumes, the call destinations, 
and the region code of the caller (Figure 3). Mauro sifted through the animated 3D landscape of cellphone 
activity and showed me the differences in the activity profiles between a usual week and this special 
event. When I asked him what he considered to be the story of visualization, he replied that it is certainly 
not about the complexity and richness of the data. For a car manufacturer participating in one of the 
Lab s projects, he recently completed a real-time visualization combining a multitude of data streams 
in a strikingly complex representation. He said, but for me it is just a screen saver, since there is 
no story. Compare this to the Obama visualization. It contains just the call intensities, but you can 
talk about it. The car data was more complex and rich, but the Obama data contained a story. However, 
he also noted, An important point is to match the interests of our partners with the story. There are 
many ways to change the visualization in order to show different stories. The goal behind the visualization 
of the presidential inauguration was to develop a representa­tion that was as powerful a display of the 
impact of communication technology on cities as SENSEable s New York Talk Exchange (Figure 4). This project 
mapped the global call activity of New York on a neighborhood level, reflecting the cultural and geographic 
diversity of its population. The Talk Exchange exhibit was also a success for the Lab's partner AT&#38;T, 
who provided the telecom data, and consequently the Lab proposed the Obama project to AT&#38;T as well. 
 And indeed, the data from inauguration day show quite an interesting pattern. As journalists move into 
the capital, the activity slowly builds up, then a dent appears in the activity profile: a moment of 
silence, as the city holds its breath during the inauguration speech, followed by a peaking wave of activity 
before everything goes back to normal after six days.  Figure 4. New York talk Exchange: visualization 
of global call destinations by neighborhood in New York city. &#38;#169; 2008 sENsEable city Lab. According 
to Mauro, there was another pattern: We saw that some states seemed to have more interest in the inauguration 
event than others. However, we had to change it, since the data was considered impolite. How can data 
be impolite? I asked. It turned out that the distribution of mobile communication across the states positively 
correlated with the proportion of African Americans in these states. According to Mauro, nobody in the 
Lab noticed this connection, but AT&#38;T noticed it immedi­ately and initially objected to the visualization. 
Today, the controversial findings are published on the Lab s web site. Still, Mauro concedes that there 
was some degree of negotiation involved: Usually there are several stories in the data you have to select 
one. You can change the visual­ ization by putting emphasis on a different story. real time rome I conducted 
another set of interviews with Francisca Rojas, a PhD candidate in urban studies and researcher in the 
SENSEable City Lab. In one interview, she talked about an earlier project involving live telecommunication 
data: Real Time Rome [15], a live visualization of urban activity presented at the Venice Bienniale 
2006 (Figure 5). The analytical part of the project involved to some degree a validation of assumptions 
about the everyday in a city like Rome: You see how over the course of a day people wake up on the fringes 
of the center, they go into the center, and then back out at night. You could assume that this is how 
the city operates it is not telling you anything new, but it exposes a pattern that you would not be 
able to get at otherwise at that broad scale. By lucky coincidence, the dataset covered an event that 
engaged the whole city the 2006 soccer World Cup final, France against Italy. The tides of mobile phone 
activity reflected the events around the game. Francisca said, Once we implemented the idea, we saw that 
the data really did show these huge spikes in cell phone usage. We all saw the visualizations and were 
trying to figure out what that was telling us about human behavior. We always had to remind ourselves 
 that it was people making phone calls. It was a proxy for human activity, not the actual activity. We 
understood the visualizations as emotional maps of the city you see how it is quiet during the match, 
then the usage of phones spikes during the halftime, and then at the end. And then, when something happens 
like Zidane s headbutt to the Italian player... Of course, this anecdote concludes every presentation 
of the project. Figure 5. real time rome: visualization of call activity in rome during the World cup 
final soccer game. &#38;#169; 2006 sENsEable city Lab. conclusion As demonstrated in the examples, the 
rhetorical perspective reveals a range of strategies that also have consequences for the exploratory 
aspects. The design decisions behind Snow s map can be understood as a rhetorical strategy to direct 
the exploratory process. In the example of the Obama inauguration visualization, these design decisions 
become explicit in the context of the communication process between all involved actors. The rhetorical 
instruments depend on the expectations of the different stakeholders collaborating researchers from 
other disciplines, sponsors, the researchers inside the lab with their research interests, as well as 
the media and the general public. Visualization thus becomes a currency for negotiating research, a currency 
that has a specific value for every stakeholder. The notion of the anecdote goes beyond rhetorical principles 
of visual communication [16], since it also covers the non-visual and performative aspects of the presentation. 
The nature of the anecdote, as theorized by Gallop, provides a link between a specific incident and a 
larger story, similar to the visualization concept of focus plus context [17]. My interview partner Mauro 
noted, If you want to design general tools, you are interested in the whole range of possibilities, in 
the interaction and so on. But if you are interested in a particular dataset, the story is crucial. While 
the exploratory perspective emphasizes generality, the rhetorical perspective emphasizes the anecdote. 
 Acknowledgement I want to thank Professor Michael Fisher for his support. references 1. S.K. Card, J.D. 
Mackinlay, and B. Shneiderman, Readings in Information Visualization: Using Vision to Think (San Francisco: 
Morgan Kaufmann, 1999). 2. E.R. Tufte, The Visual Display of Quantitative Information (Cheshire, Connecticut: 
Graphics Press, 2001). 3. B. Latour, Reassembling the Social: An Introduction to Actor-Network-Theory 
(Oxford: Oxford University Press, 2005). 4. C. Chen, Top 10 Unsolved Information Visualization Problems, 
IEEE Computer Graphics and Applications, Vol. 25, 12 16 (2005). 5. D. Kaiser, Stick-Figure Realism: 
Conventions, Reification, and the Persistence of Feynman Diagrams, 1948 1964, Representations, 49 86 
(2000). 6. D. Kaiser [5]. 7. J. Gallop, Anecdotal Theory (Durham, North Carolina: Duke University Press, 
2002). 8. C.F. Chabris and S.M. Kosslyn, Representational Correspondence as a Basic Principle of Diagram 
Design, Lecture Notes in Computer Science, Vol. 3426, 36 (2005). 9. K.S. McLeod, Our Sense of Snow: 
The Myth of John Snow in Medical Geography, Social Science &#38; Medicine, Vol. 50, 923 935 (2000). 
10. H. Brody et al., Map-Making and Myth-Making in Broad Street: the London Cholera Epidemic, 1854, The 
Lancet, Vol. 356, No. 9223, 64 68 (2000). 11. J. Gallop [7]. 12. SENSEable City Lab, www.senseable.mit.edu/. 
 13. B. Latour [3]. 14. SENSEable City Lab, Obama | One People, February 2009, www.senseable.mit.edu/obama/. 
 15. F. Calabrese and C. Ratti, Real Time Rome, Networks and Communication Studies, NETCOM, Vol. 20, 
No. 3 4, 247 257 (2006). 16. F. Hartmann and E.K. Bauer, Bildersprache: Otto Neurath Visualisierungen, 
2nd ed. (Vienna: Facultas. wuv Universitäts, 2006). 17. P. Baudisch et al., Keeping Things in Context: 
A Comparative Evaluation of Focus Plus Context Screens, Overviews, and Zooming, CHI 02: Proceedings of 
the SIGGCHI Conference on Human Factors in Computing Systems (ACM Press, 2002) 259 266.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1836793</article_id>
		<sort_key>70</sort_key>
		<display_label>Pages</display_label>
		<pages>9</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Data portraits]]></title>
		<page_from>375</page_from>
		<page_to>383</page_to>
		<doi_number>10.1145/1836786.1836793</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836793</url>
		<abstract>
			<par><![CDATA[<p>Data portraits depict their subjects' accumulated data rather than their faces. They can be visualizations of discussion contributions, browsing histories, social networks, travel patterns, etc. They are subjective renderings that mediate between the artist's vision, the subject's self-presentation, and the audience's interest. Designed to evocatively depict an individual, a data portrait can be a decorative object or be used as an avatar, one's information body for an online space.</p> <p>Data portraits raise questions about privacy, control, aesthetics, and social cognition. These questions become increasingly important as more of our interactions occur online, where we exist as data, not bodies.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>K.4.1</cat_node>
				<descriptor>Privacy</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003456.10003462.10003477</concept_id>
				<concept_desc>CCS->Social and professional topics->Computing / technology policy->Privacy policies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10003029</concept_id>
				<concept_desc>CCS->Security and privacy->Human and societal aspects of security and privacy</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264038</person_id>
				<author_profile_id><![CDATA[81100223099]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Judith]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Donath]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Harvard Berkman Center, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P2264039</person_id>
				<author_profile_id><![CDATA[81466648525]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alex]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dragulescu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[San Jose, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P2264040</person_id>
				<author_profile_id><![CDATA[81311484237]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Aaron]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zinman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MIT Media Lab, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P2264041</person_id>
				<author_profile_id><![CDATA[81100539968]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Fernanda]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vi&#233;gas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Research, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P2264042</person_id>
				<author_profile_id><![CDATA[81339537840]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Rebecca]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xiong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[E. van Alphen, "The Portrait's Dispersal: Concepts of Representation and Subjectivity in Contemporary Portraiture," <i>Portraiture: Facing the Subject</i>, J. Woodall, ed. (Manchester: Manchester University Press, 1996) 239--56.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. T. Hancock and P. J. Dunham, "Impression Formation in Computer-Mediated Communication Revisited," <i>Communication Research</i>, Vol. 28, No. 3, 325--347 (2001).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>962972</ref_obj_id>
				<ref_obj_pid>962752</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[F. B. Vi&#233;gas and M. Smith, "Newsgroup Crowds and AuthorLines: Visualizing the Activity of Individuals in Conversational Cyberspaces," <i>37th Annual Hawaii International Conference on System Sciences</i>, IEEE Computer Society (2004).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1124919</ref_obj_id>
				<ref_obj_pid>1124772</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[F. Vi&#233;gas, S. Golder, and J. Donath, "Visualizing Email Content: Portraying Relationships from Conversational Histories," <i>SIGCHI Conference on Human Factors in Computing Systems</i>, Montr&#233;al, Canada (ACM Press, 2006).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. West, Portraiture, <i>Oxford History of Art</i> (Oxford, UK: Oxford University Press, 2004).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. Dragulescu, <i>Lexigraphs</i>, www.sq.ro/lexigraphs1.php (2009) (cited January 7, 2010).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. E. Brennan, "Caricature Generator: The Dynamic Exaggeration of Faces by Computer," <i>Leonardo</i>, Vol. 18, No. 3, 170--178 (1985).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Abrams and P. Hall, eds., <i>Else/where Mapping</i> (Mineapolis, MN: University of Minnesota Design Institute, 2006).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>322581</ref_obj_id>
				<ref_obj_pid>320719</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[R. Xiong and J. Donath, "PeopleGarden: Creating Data Portraits for Users," <i>ACM Symposium on User Interface Software and Technology (UIST)</i>, Asheville, North Carolina (ACM, 1999).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[A. Zinman, <i>Personas</i>, personas.media.mit.edu (2009) (cited January 6, 2010).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1489874</ref_obj_id>
				<ref_obj_pid>1488734</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Y. Assogba and J. Donath, "Mycrocosm: Visual Microblogging," <i>42nd Hawaii International Conference on System Sciences</i>, Big Island, Hawaii (2009).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Data Portraits  Judith Donath, Alex Dragulescu, Aaron Zinman, Fernanda Viégas, Rebecca Xiong AbstrAct 
Data portraits depict their subjects accumulated data rather than their faces. they can be visualiza­tions 
of discussion contributions, browsing histories, social networks, travel patterns, etc. they are subjective 
renderings that mediate between the artist s vision, the subject s self-presentation, and the audience 
s interest. Designed to evocatively depict an individual, a data portrait can be a decorative object 
or be used as an avatar, one s information body for an online space. Data portraits raise questions about 
privacy, control, aesthetics, and social cognition. these questions become increasingly important as 
more of our interactions occur online, where we exist as data, not bodies. Introduction We live in an 
increasingly digital world. We work, shop, and socialize online, and in the process we accumulate, often 
unknowingly, vast shadow bodies of data. Our online discussions are archived, our purchases tracked, 
our locations sensed, and our educational and medical histories recorded. These data bodies extend in 
time, reaching into the past, charting the evolution of one s ideas, career, and style. By visualizing 
this data, we can create portraits of people that depict not the subject s face, but a rendering of their 
words and actions. Portraits have long used data in their depictions. In Renaissance paintings, richly 
rendered and highly symbolic garments and possessions portrayed social position (e.g., Hans Holbein s 
The French Ambassadors); in contemporary work, the person may be evoked only through their personal possessions 
(e.g., Christian Boltanski s Missing House). The data portraits in this paper depict a person through 
their digital archive. Calling these representations portraits rather than visualizations shifts the 
way we think about them. A portrait is an evocative depiction, meant to convey something about the subject 
s character or role in society. The term portrait also highlights the subjectivity of the representa­tion. 
The goal of most data visualization is to be as objective as possible. With a portrait, however, the 
artist s personal style and interpretation are important aspects of the work [1]. A portrait involves 
negotiations between the subject and artist: the subject may wish to be portrayed in an ideal light, 
while the artist may want to show what they think the subject is really like. This tension, as well as 
the beliefs and conventions of the culture in which it is created, shapes the portrait. Creating data 
portraits raises many questions. Does the subject or artist control what data should be included? What 
should such a representation look like? How can it be designed to make intuitive sense to the viewer? 
Judith Donath Academic Harvard Berkman Center 25 Everett Street Cambridge, MA 02138 USA judith@vivatropolis.com 
Alex Dragulescu Artist 1653 Andalusia Way San Jose, CA 95125 USA dragu@mit.edu Aaron Zinman Designer 
MIT Media Lab 75 Amherst Street E14-548 Cambridge, MA 02142 USA aaron@zinman.com Fernanda Viégas Researcher 
IBM Research 1 Rogers Way Cambridge, MA 02142 USA fernanda@fernandaviegas.com rebecca Xiong Entrepreneur 
22 Chestnut Street Cambridge, MA 02139 USA becca@yana.com  Functions of Data Portraits The data body 
is not readily perceivable. Even if you can see, for instance, all the comments that someone has made 
in an ongoing discussion, this unwieldy archive does not easily provide you with a clear picture of their 
role in the community. You would need to spend hours poring through transcripts, piecing an impression 
together through scattered remarks. Visualization reifies and condenses this data into something we can 
easily perceive. A graphical representation can compactly embody a tremendous amount of information, 
making it possible to see years of activity in a single glance. Figure 1. Authorlines. &#38;#169; 2003 
Fernanda Viégas and Marc smith. One use for data portraits is in online communities, where difficulty 
in forming impressions of people is often a problem [2]. AuthorLines, for example (Figure 1), portrays 
an individual in terms of their posting and response pattern in a discussion group [3]. Data portraits 
such as this can help members of a community keep track of who the other participants are, showing the 
roles they play and creating a concise representation of the things they have said and done. Here, the 
portraits act as proxies for the subjects, affecting how others in the community act towards them. Data 
portraits may reveal information about us, but they can also help us control it. They can function as 
mirrors, showing us the patterns in our data. Today, increasing amounts of informa­tion, including health 
records, purchases, travel patterns, etc. are being kept about us, but we have little sense of what it 
says about ourselves. The data mirror, a portrait designed to be seen only by the subject, is a tool 
for self-understanding. Like a physical mirror it lets you assess your appearance and may be a catalyst 
for changing it. Themail (Figure 2) uses email correspondence to portray its subject s changing relationship 
with another person [4]. It highlights words they use more frequently with that person than is typical 
in the subject s other correspondence and in general English usage. Themail was originally created to 
be a personal data mirror a visualization one would use to make sense of one s own corre-spondence. 
But the users liked to publicly display the images. These visualizations function as portraits of a relationship, 
and displaying them is akin to the way people display pictures of themselves with friends and family. 
Here the portrait functions both as data mirror (a tool to help someone make sense of a vast trove of 
personal data) and as decorative object imbued with personal meaning As artistic works, data portraits 
can, like traditional portraits, be decorative objects commemorat­ing the subject s social status and 
affiliations. They can also function as social critiques, highlighting the loss of privacy and control 
in a world of increasingly ubiquitous surveillance. While data portraits may look very different than 
traditional facial portraits, their uses echo the role of portraiture throughout history: as works of 
art, biographies, proxies, and evidence [5]. Figure 2. Themail. &#38;#169; 2005 Fernanda Viégas, scott 
Golder, Judith Donath. Visual Design Data portraits come in all forms. Some look very much like statistical 
graphs; others are more figurative. With faces, we are neurologically wired and socially trained to infer 
meaning from structure and expression. Data does not have this inherent legibility; making data portraits 
meaningful is a key challenge. The form of the portrait is itself part of the message-bearing content. 
Statistical graphs appear authoritative and objective. AuthorLines, for instance, uses bubble graphs, 
a form usually associ­ ated with financial reports. For all the starkness of its graphics, it is a very 
expressive group portrait. Carefully chosen statistics let the audience see the different roles individuals 
play within the group. However, without knowing what the data is, one would never guess that it represented 
people rather than, say, mortgage failure rates or gross national product. Lexigraphs (Figure 3) is a 
group portrait of users of Twitter, a micro-blogging site [6]. Each is shown as a silhouette outlined 
in words derived from their updates, animated by the rhythm of their postings. Each silhouette is identically 
shaped the individuality of the portrait is in the specific words and rhythms. The silhouette is thus 
purely decorative it bears no specific informa­tion. Yet setting the words in the shape of heads contributes 
greatly to the sense that one is looking at a portrait of specific individuals. It is important that 
these head shapes are themselves quite abstract there are no features, simply the impression of a human. 
 Human-like shapes have the advantage that they are easily recognizable as portraits. The disad­vantage 
is that we are so attuned to human forms that we are prone to reading too much information into them. 
Anything face-like is perceived as a face, often with gender and expression, even if made from cloud 
shapes or moon craters. In making data portraits that reference the human form we need to be careful 
not to create an inadvertent picture of a person. Figure 3. Lexigraphs I. &#38;#169; 2009 Alex Dragulescu 
and Judith Donath. The meaning of a portrait is the impression it evokes of its subject. Traditional 
portraits use the familiar language of facial structure and expression we read the image as we would 
read a face seen in person. Abstract data portraits do not have this everyday familiarity. When one is 
creating a visualization to be used for statistical analysis, it is reasonable to require the audience 
to read the axis and study the data. But for a portrait, the meaning the impression it creates of its 
subject needs to be more immediately and intuitively accessible. Three key ways of doing so are to incorporate 
text, to use metaphor, and to create multiples. Incorporating text: Many data portraits are based on 
their subjects texts, and incorporating some of these words into the portrait provides immediate context 
and detail. The key is in choosing the most evocative ones. Several portraits discussed here (e.g., Themail 
and Lexi­graphs) analyze word usage to find words the subjects use with unusual frequency. The technique 
is similar to that of creating a caricature: one finds the norm and highlights the ways that the subject 
deviates from it [Brennan, 7]. Lexigraphs and Themail are neutral caricatures (as was Brennan s facial 
caricature generator): they mark deviations from the norm, but do not further distort or highlight based 
on the meaningfulness of a word or feature. The Conversation Map (Donath, in [8]) similarly pulls out 
characteristic words, but in this case the portrait is hand-made: the artist, having formed an impression 
of subjects, chose the highlighted phrases, creating a more vivid but also more subjective depiction 
(Figure 4). Words are the raw material of many data portraits, and developing new techniques for analyzing 
them, both purely computationally and with human participation, is a key element in the design of future 
portraits.  Figure 4. Conversation Map. &#38;#169; 2005 Judith Donath. Using metaphor: Metaphor is a 
powerful, but sometimes tricky, way to introduce meaning. Metaphors help us understand one thing in terms 
of another it has been argued that all of our ability for abstract thought is by using metaphor to build 
up understanding from a physical foundation. The metaphorical poetics of PeopleGarden [9], which portrays 
the participants in a discussion group as flowers and the group as a garden (Figure 5), makes interpreting 
meaning intuitive. As the height of a real flower indicates its age, the height of a PeopleGarden flower 
indicates how long someone has been posting to the group. The number of petals represents posting frequency: 
a lush blossom indicates an engaged contributor. A petal s color indicates whether it is an initial posting 
or a response, and the color fades over time: it is easy to remember that a faded flower is an inactive 
participant. The flower metaphor makes the portraits easily legible. It gives them visual appeal and 
a sense of vitality: rather than a dry statistical graph, here the data appear as an enticing garden. 
The problem is that the metaphor overwhelms the content it depicts. A person is portrayed as a pretty 
flower no matter what he or she is saying. The challenge in using metaphor is to abstract sufficiently 
from the source. Much of the legibility of these portrayals could be preserved in a less literal representation, 
with growth and height indicating age, brightness and fading showing recent presence, denseness of detail 
indicating activity meanings drawn from, but not literally depicted as, our familiarity with natural 
forms. Creating multiples: Most data portraits are created in a series; the creativity is in the algo­rithm 
creation, which can be applied to numerous subjects. This also helps make these abstract depictions legible, 
for it is primarily in the context of other portraits made in the same fashion by comparing them to 
each other that one can understand the nuances and vocabulary of the portrait s design. Lexigraphs, 
for instance, shows a group of Twitter users, portraying each with salient words from their current and 
past updates. It animates with the rhythm of each user s postings. While one would get some sense of 
a person by seeing only their portrait, it is only upon seeing the whole group that one can judge whether 
the person is prolific or personal, etc., in their postings, for one needs a community to compare with. 
 Figure 5. PeopleGarden. &#38;#169; 1999 rebecca Xiong and Judith Donath. the Automated Artist Data portraits 
can be individually created, with the artist active in the depiction of each subject (e.g., Conversation 
Map). But many are created algorithmically. The artist designs a program for making portraits, rather 
than the portraits themselves. There are several steps mining for data, analyzing it, and then depicting 
it all of which involve creative choices. But it is still an auto­ mated process a final stage, perhaps, 
in the increasing mechanization of portraiture. The traditional painted portrait is made by hand, the 
artist consciously shaping each brush stroke. The advent of photography changed the artist s relationship 
with the work s creation: the artist s eye and intention remained actively involved, but creating the 
image itself became the job of a machine. Data portraits automate the process even further, raising questions 
about the artist s role in their creation and about the source of meaning and artistic interpretation 
in these works. The algorithmic artist expresses a vision for society by choosing what patterns to highlight 
and how to depict them. PeopleGarden (Figure 5) depicts active participation positively; by using a different 
algorithm, the artist could commend the use of first-person pronouns, or supportive affect. Lexigraphs 
maintains a neutral stance about its subjects words; by using color to highlight angry words or to separate 
political positions, the artist could create a more pointed depiction of the community. Objective/subjective/Accurate 
 In the world of information visualization, the goal is to depict the data as objectively as possible. 
This is the opposite of art, where the artist s subjective vision is central. Data portraits sit between 
these extremes: their techniques come from the world of statistical analysis, but their purpose is artistic. 
Some may be closer to one extreme or the other neither is right, but understanding where a particular 
portrait falls in this subjectivity continuum is a key element in understanding its function. Objectivity 
and accuracy are different, and a computational portrait can be objective without being the latter. Personas 
(Figure 6) is a piece that critiques the role of the machine as artist [10]. It creates a portrait based 
on the results of a Web search for the subject s name. It analyzes the resulting texts and attempts to 
characterize the person by fitting them into a set of categories of roles and interests. The result is 
sometimes surprisingly apt, but can also be very far off, the result of the computer s inability to distinguish 
among different people with the same name and errors in language comprehension. Personas is meant as 
a reminder of the fallibility, social naiveté, and opaqueness of the computer as portrayer at a time 
when such computer analysis of people is increasingly prevalent. Figure 6. Personas. &#38;#169; 2009 
Aaron Zinman and Judith Donath. Privacy and control Privacy and control are central issues in portraiture. 
When the subject controls the portrayal, and chooses to reveal little other than the public image, the 
resulting portrait is often dull and lifeless, e.g., many official portraits of politicians and executives. 
Portraits that reveal the subject s vulner­ability, such as Nan Goldin s photographs, are more interesting 
to the audience, but they may be very discomforting to the subject. How much is revealed by a portrait 
and who controls it is the center of the tension between artist, subject, and audience. Several of the 
data portraits discussed here use public data, such as Twitter feeds or discussion posting. They are 
analogous to street photographs: the subject and artist have no ongoing relation­ship, and the material 
(whether face or text) was captured in a public setting. Other works may give the subject the ability 
to decide what data to show, a necessity for portraits that are based on private data, such as web browsing 
history or email. Some of the most revealing data portraits are self-portraits, where the subject freely 
chose the material to present. Mycrocosm (Figure 7) users record everyday personal statistics using simple 
graphs to display their data [11]. People track what they ate for breakfast, when they went to sleep, 
the ups and downs of relationships, and whether people remembered their birthday independently or via 
an automated reminder. Both the choice of data and the specifics of their entries create the self-portrait. 
 Figure 7. Mycrocosm. &#38;#169; 2009 Yannick Assogba and Judith Donath. Privacy and control are closely 
intertwined: having a relatively innocuous piece of information revealed without your consent may feel 
like a violation, while freely displaying personal informa­tion of your own volition can be empowering. 
Privacy depends on audience. We may be comfortable with a silly snapshot seen only by close friends, 
but would be deeply embarrassed should it be shown in public (a tension that is a matter of heated current 
debate now as people post old photos to semi-public sites such as Facebook). Privacy violations occur 
when information is taken out of context. Living in an era of unprecedented archiving and recording, 
our identities are inevitably entwined with depictions of our accumulated data. By viewing these depictions 
as portraits and deliber­ately creating them in that tradition we see and can influence how these images 
balance the diverse goals accuracy, privacy, dignity, and enjoyment of the artist, subject, and viewer. 
Acknowledgements Much of the work described here was created with the Sociable Media Group of the MIT 
Media Lab. We would like to thank our colleagues there for their creative inspiration and technological 
innovations. And we thank the sponsors of the MIT Media Lab for making this work possible. references 
 1. E. van Alphen, The Portrait s Dispersal: Concepts of Representation and Subjectivity in Contemporary 
Portraiture, Portraiture: Facing the Subject, J. Woodall, ed. (Manchester: Manchester University Press, 
1996) 239 56. 2. J.T. Hancock and P.J. Dunham, Impression Formation in Computer-Mediated Communication 
Revisited, Communication Research, Vol. 28, No. 3, 325 347 (2001). 3. F.B. Viégas and M. Smith, Newsgroup 
Crowds and AuthorLines: Visualizing the Activity of Individuals in Conversational Cyberspaces, 37th Annual 
Hawaii International Conference on System Sciences, IEEE Computer Society (2004). 4. F. Viégas, S. Golder, 
and J. Donath, Visualizing Email Content: Portraying Relationships from Conversational Histories, SIGCHI 
Conference on Human Factors in Computing Systems, Montréal, Canada (ACM Press, 2006). 5. S. West, Portraiture, 
Oxford History of Art (Oxford, UK: Oxford University Press, 2004). 6. A. Dragulescu, Lexigraphs, www.sq.ro/lexigraphs1.php 
(2009) (cited January 7, 2010). 7. S.E. Brennan, Caricature Generator: The Dynamic Exaggeration of Faces 
by Computer, Leonardo, Vol. 18, No. 3, 170 178 (1985). 8. J. Abrams and P. Hall, eds., Else/where Mapping 
(Mineapolis, MN: University of Minnesota Design Institute, 2006). 9. R. Xiong and J. Donath, PeopleGarden: 
Creating Data Portraits for Users, ACM Symposium on User Interface Software and Technology (UIST), Asheville, 
North Carolina (ACM, 1999). 10. A. Zinman, Personas, personas.media.mit.edu (2009) (cited January 6, 
2010). 11. Y. Assogba and J. Donath, Mycrocosm: Visual Microblogging, 42nd Hawaii International Conference 
on System Sciences, Big Island, Hawaii (2009).   
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	</section>
	<section>
		<section_id>1836794</section_id>
		<sort_key>80</sort_key>
		<section_seq_no>2</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Touchpoint: haptic exchange between digits]]></section_title>
		<section_page_from>388</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>P2264043</person_id>
				<author_profile_id><![CDATA[81466648676]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Elaver]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Indiana University-Purdue University Fort Wayne]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1836795</article_id>
		<sort_key>90</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Echidna]]></title>
		<page_from>388</page_from>
		<page_to>389</page_to>
		<doi_number>10.1145/1836786.1836795</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836795</url>
		<abstract>
			<par><![CDATA[<p><i>Echidna</i> is an interactive sound sculpture, made partly in collaboration with PhD researcher Tom Frame from the Surrey Space Centre. <i>Echidna</i> is like a fussy tumbled creature that has its own (electronic) voice. When it is touched, and the electromagnetic field around it is disturbed, sound emerges. The sculpture is made of tangled wire and sits on a plinth with electronics inside. It hums happily until touched, at which point it will squeak and react to one's presence. The work combines a circuit which directly measures electrostatic changes in the environment and a custom-designed phase-locked loop system, used to drive an audio speaker.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Auditory (non-speech) feedback</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003128.10010869</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction techniques->Auditory feedback</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264013</person_id>
				<author_profile_id><![CDATA[81466640949]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tine]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bech]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University West England, United Kingdom]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Tine Bech Tine Bech Digital Culture Research Centre University West England United Kingdom mail@tinebech.com 
Collaborator: Tom Frame Echidna Echidna. &#38;#169; 2009/2002 Tine Bech and Tom Frame, Photo &#38;#169; 
Nicolai Amter. Echidna is an interactive sound sculpture, made partly in collaboration with PhD researcher 
Tom Frame from the Surrey Space Centre. Echidna is like a fussy tumbled creature that has its own (electronic) 
voice. When it is touched, and the electromagnetic field around it is disturbed, sound emerges. The sculpture 
is made of tangled wire and sits on a plinth with electronics inside. It hums happily until touched, 
at which point it will squeak and react to one s presence. The work combines a circuit which directly 
measures electrostatic changes in the environment and a custom-designed phase-locked loop system, used 
to drive an audio speaker. &#38;#169; 2010 Tine Bech | Leonardo, Vol. 43, No. 4, pp. 388 389, 2010 Tine 
Bech (Master of Fine Arts, Sculpture) is a visual artist and researcher who works with interactive installations 
and public art. She was born in Denmark and now lives and works in London, United Kingdom. Bech s work 
has been exhibited in Scandinavia, Europe, Russia, and the United States, in venues including Aarhus 
Kunstbygning (Centre for Contemporary Art, Denmark), the Fort Collins Museum of Contemporary Art (United 
States), L Gallery (Moscow), Trøndelag Centre of Contemporary Arts (Norway), Bankside Gallery, and The 
Royal British Sculptors Gallery (United Kingdom). Bech was selected for the Cultural Leadership program 
Method-Artists Leading Through Their Practice (2009), and was recently awarded a PhD research grant at 
the Digital Culture Research Centre, The Pervasive Media Studio (University West England). Echidna. 
&#38;#169; 2009/2002 Tine Bech and Tom Frame, Photo &#38;#169; Nicolai Amter. Bech s work is intentionally 
accessible and, according to the artist herself, often hums and reacts with a playful anthropomorphic 
life that is liable to take you by surprise. Bech focuses on the use of interactive electronics and location-tracking 
technology, urban spaces and environ­mental elements including gravity, water, sound and light in order 
to develop spaces where play and experiences of immersion take place. Bech s work investigates the use 
of interactive technology and how it can address the interplay between the digital and the physical, 
exploring the body moving through the environment in which it is immersed. The body is the membrane through 
which we must necessarily relate to the world. However, the borderline between the two is not sharply 
defined; body and world are entwined in a constant dialogue. This dialogue is an important part of Bech 
s work. Echidna | Tine Bech 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1836796</article_id>
		<sort_key>100</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Strata-Caster]]></title>
		<page_from>390</page_from>
		<page_to>391</page_to>
		<doi_number>10.1145/1836786.1836796</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836796</url>
		<abstract>
			<par><![CDATA[<p><i>Strata-Caster</i> is an online virtual art installation, created on a private island in Second Life (secondlife.com). Viewers travel by way of a wheelchair, while being made acutely aware of their physical and virtual status, and are invited to re-examine this position in life in relation to all others (both physical and virtual).</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Artificial, augmented, and virtual realities</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Virtual reality</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010866</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010392</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Mixed / augmented reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264014</person_id>
				<author_profile_id><![CDATA[81466647337]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Joseph]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Farbrook]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Worcester Polytechnic Institute, Worcester, Massachusetts]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Joseph Farbrook Joseph Farbrook Worcester Polytechnic Institute Worcester, Massachusetts USA farbrook@wpi.edu 
Strata-Caster Strata-Caster is an online virtual art installation, created on a private island in Second 
Life (sec­ondlife.com). Viewers travel by way of a wheelchair, while being made acutely aware of their 
physical and virtual status, and are invited to re-examine this position in life in relation to all others 
(both physical and virtual). Scarcely a generation ago, moving image screens were restricted to television 
and cinema, with content almost exclusively generated by corporations and conglomerates that dictated 
the form and aesthetic of what should and should not be seen by the masses. Content was restricted almost 
entirely to news and entertainment, and limited in scope to what could be sold as a commodity. At present, 
technological advances have given moving image screens an explosion of new forms and possibilities with 
regard to content. Considering the hours we spend staring into screens, it could be argued that we are 
seeing an ever-greater part of our lives mediated by this device. Virtual reality has quietly emerged 
on this side of the screen and embedded itself into our psyches. The collective imagination is, to an 
ever-greater extent, being co-opted and aligned to the operational workings of &#38;#169; 2010 Joseph 
Farbrook | Leonardo, Vol. 43, No. 4, pp. 390 391, 2010 this new prosthetic. It is now a critical time 
for artists to temper this overwhelming involvement and offer insights into this reality, complete with 
new paradigms of perception, new ways of seeing into and through the ubiquitous screen. Strata-Caster 
is an installation that explores the topography of power, prestige, and position. It exists in the virtual 
world of Second Life, a place populated by approximately 50,000 people at any given moment. Although 
virtual and infinite, it continues to mirror the physical world, complete with representations of prestige 
and exclusivity. Even without the limitations of the physical, why are borders and separation still prized 
so highly? Entry into this installation is by wheelchair, an unfamiliar interface to the limitless expanse 
of virtual space, but one that continuously calls attention to limitation and position. Strata-Caster. 
&#38;#169; 2008 Joseph Farbrook. Joseph Farbrook grew up in New York City and Santa Fe. Raised by his 
father, a concrete poet, and his mother, a painter, Farbrook attended the University of Colorado, where 
he wrote electronic music, poetry, and fiction. Becoming interested in a more immersive approach to narrative, 
he began using computers and the Internet as creative media. Subsequently discovered by the art department, 
he was offered a fellowship to pursue an MFA in digital art. Working in a visual arts environment, Farbrook 
began creating electronic installations, interactive video, and virtual reality narratives. He also developed 
media-reflexive live performances mixed with interactive screen projections. Farbrook s latest work explores 
the intersections between video, video games, and sculpture. Farbrook exhibits both nationally and internationally. 
Recent venues include the Museum of Contemporary Art (Denver), La Fabrica Arte Contemporaneo (Guatemala), 
Museo De Arte Contemporaneo (Columbia), as well as venues in the Netherlands, China, Czech Republic, 
and the United States. Farbrook is presently an assistant professor of interactive media and game develop­ment 
at the Worcester Polytechnic Institute. Strata-Caster | Joseph Farbrook 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1836797</article_id>
		<sort_key>110</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Cursor Caressor Eraser]]></title>
		<page_from>392</page_from>
		<page_to>393</page_to>
		<doi_number>10.1145/1836786.1836797</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836797</url>
		<abstract>
			<par><![CDATA[<p><i>Cursor Caressor Eraser</i> is an installation and online artwork exploring the erotic image and the seductive potential of tangible interfaces.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264015</person_id>
				<author_profile_id><![CDATA[81466647788]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Filimowicz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Simon Fraser University, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Michael Filimowicz Michael Filimowicz School of Interactive Arts and Technology Simon Fraser University 
Canada mfa13@sfu.ca Collaborators: Melanie Cassidy, Andres Wanner Cursor Caressor Eraser Cursor Caressor 
Eraser. &#38;#169; 2010 Michael Filimowicz. Cursor Caressor Eraser is an installation and online artwork 
exploring the erotic image and the seductive potential of tangible interfaces. Cursor Caressor Eraser 
is an interactive installation and net artwork contemplating the erotic image and themes of sensuality 
in time. Caressing gestures of the interactors produce erasures of digital photographic imagery, resulting 
in visual palimpsests. These erasures thematize temporal dialectics of touch and bodily encounters with 
others, such as forgetting and remembering, or recognition and strangeness. A simple gesture a stroke 
across a touchpad or the movement of a mouse creates a series of rich variations of bodies in change. 
In the installation, interactors touch and caress a sculptural, sensitive interface that has been derived 
from body molds casts of the body arranged as a landscape to be explored by the interactor. Michael Filimowicz 
is a new media artist working in the areas of sound, experimental video, creative writing, net art, public 
art, and digital photography. As a writer, he has published poetry, fiction, and philosophy, and as a 
sound designer he has mixed soundtracks for film and televi­sion. He is on the faculty in the School 
of Interactive Arts and Technology at Simon Fraser University. &#38;#169; 2010 Michael Filimowicz | 
Leonardo, Vol. 43, No. 4, pp. 392 393, 2010 Melanie Cassidy is a sculptor, filmmaker, and art director 
in Vancouver s film industry. She has exhibited her sculptural works internationally and designed custom 
fabrications for feature films and television series. Andres Wanner was trained as a physicist (University 
of Basel) and as a visual communications designer (University of Art and Design, Basel) in Switzerland. 
His field of work is where art and technology intersect. He likes to tinker, invent and play. He is on 
the faculty of the School of Interactive Arts and Technology at Simon Fraser University. Cursor Caressor 
Eraser. &#38;#169; 2010 Michael Filimowicz. Cursor Caressor Eraser | Michael Filimowicz 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1836798</article_id>
		<sort_key>120</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Final Wisdom I]]></title>
		<page_from>394</page_from>
		<page_to>395</page_to>
		<doi_number>10.1145/1836786.1836798</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836798</url>
		<abstract>
			<par><![CDATA[<p><i>Final Wisdom I</i> is an interactive installation where participants shape their experience with a work of visual and sonic poetry by means of gesture, touch, and proximity. The work is engaged through an interactive software framework that provides an interface to the physical world through objects reacting to touch, sound, and pressure, presenting viewers with a shifting environment of media as they navigate and shape their experience with a work of spatialized poetry. <i>Final Wisdom I</i> is the work of artists Hans Breder and John Fillwalk, with poetry by Donald Kuspit, music by Carlos Cuellar Brown, and programmer Jesse Allison.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264016</person_id>
				<author_profile_id><![CDATA[81435596699]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fillwalk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ball State University, Muncie, Indiana]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 John Fillwalk John Fillwalk Electronic Art, Department of Art Ball State University Muncie, Indiana 
USA jfillwalk@bsu.edu Collaborators: Hans Breder, Donald Kuspit, Neil Zehr, Carlos Cuellar Brown, Jesse 
Allison idialab.org johnfillwalk.com upgrade.idiarts.org Final Wisdom I. &#38;#169; 2010 Fillwalk, Breder, 
Kuspit, Brown, and Allison. Final Wisdom I Final Wisdom I is an interactive installation where participants 
shape their experience with a work of visual and sonic poetry by means of gesture, touch, and proximity. 
The work is engaged through an interactive software framework that provides an interface to the physical 
world through objects reacting to touch, sound, and pressure, presenting viewers with a shifting environment 
of media as they navigate and shape their experience with a work of spatialized poetry. Final Wisdom 
I is the work of artists Hans Breder and John Fillwalk, with poetry by Donald Kuspit, music by Carlos 
Cuellar Brown, and programmer Jesse Allison. As an intermedia artist, John Fillwalk actively investigates 
emerging technologies that inform his work in a variety of media, including video installation, virtual 
art, and interactive forms. His perspective is rooted in the traditions of painting, cinematography, 
and sculpture, with a particular interest in spatialized works that can immerse and engage a viewer within 
an experi­ence. Fillwalk positions his work to act as both a threshold and mediator between tangible 
and implied space, creating a conduit for the transformative extension of experience, and to pursue the 
realization of forms, sounds and images that afford interaction at its most fundamental level. In working 
with technology, he values the synergy of collaboration and regularly works with other artists and scientists 
on projects that could not be realized otherwise. Electronic media extend the range of traditional processes 
by establishing a palette of time, motion, interactivity, and extensions of presence. The ephemeral qualities 
of electronic and intermedia works, by their very nature, are inherently transformative, and the significance 
of the tangible becomes fleeting, shifting emphasis away from the object and toward the experience. 
&#38;#169; 2010 John Fillwalk | Leonardo, Vol. 43, No. 4, pp. 394 395, 2010 John Fillwalk is Director 
of the Institute for Digital Intermedia Arts (IDIA Lab) at Ball State University, an interdisciplinary 
and collaborative hybrid studio. An intermedia artist and Associate Professor of Electronic Art, Fillwalk 
investigates media in video installation, hybrid reality and interactive forms. He received his MFA from 
the University of Iowa in Intermedia and Video Art, and has since received numerous grants, awards, commissions 
and fellowships. Donald Kuspit is an art critic, author and professor of art history and philosophy at 
State University of New York at Stony Brook and lends his editorial expertise to several journals, including 
Art Criticism, Artforum, New Art Examiner, Sculpture and Centennial Review. Hans Breder was born in Herford, 
Germany, and trained as a painter in Hamburg, Germany. Attract­ ed to the University of Iowa s School 
of Art and Art History in 1966, Breder established the Intermedia Program. Carlos Cuellar Brown, a.k.a 
ccbrown, is a composer, instrumentalist and music producer. Formally trained as a classical pianist, 
Cuellar specialized in experimental music and intermedia with the late American maverick composer Kenneth 
Gaburo. Jesse Allison is the Virtual Worlds Research Specialist, IDIA, Assistant Professor of Music Technology, 
Ball State University. He is also President of Hardware Engineering with Electrotap, LLC, an innovative 
human-computer interface firm. Final Wisdom I. &#38;#169; 2010 Fillwalk, Breder, Kuspit, Brown, and 
Allison. Final Wisdom I | John Fillwalk 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1836799</article_id>
		<sort_key>130</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[hanahanahana]]></title>
		<page_from>396</page_from>
		<page_to>397</page_to>
		<doi_number>10.1145/1836786.1836799</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836799</url>
		<abstract>
			<par><![CDATA[<p>To experience <i>hanahanahana</i>, the participant applies perfume to a leaf-shaped piece of paper and holds or shakes it in front of the wall. A flower image then appears in each bud-like device. The degree of transparency of the flower changes gradually according to the strength of the floating scent, while color and shape also vary according to the sort of fragrance applied to the paper. Participants can enjoy temporal and spatial variations of floating air with olfactory sensations from the scent, visual sensations from the projection screen, and tactile sensations from the wind.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Haptic I/O</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10011752</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Haptic devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264017</person_id>
				<author_profile_id><![CDATA[81100527572]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yasuaki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kakehi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Keio University, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P2264018</person_id>
				<author_profile_id><![CDATA[81100047313]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Motoshi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chikamori]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[plaplax, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P2264019</person_id>
				<author_profile_id><![CDATA[81332510306]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kyoko]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kunoh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[plaplax, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Yasuaki Kakehi, Motoshi Chikamori and Kyoko Kunoh Yasuaki Kakehi Keio University Tokyo, Japan ykakehi@sfc.keio.ac.jp 
Motoshi Chikamori plaplax Japan motoc@plaplax.com Kyoko Kunoh plaplax Japan kunoh@plaplax.com hanahanahana 
 To experience hanahanahana, the participant applies perfume to a leaf-shaped piece of paper and holds 
or shakes it in front of the wall. A flower image then appears in each bud-like device. The degree of 
transparency of the flower changes gradually according to the strength of the floating scent, while color 
and shape also vary according to the sort of fragrance applied to the paper. Participants can enjoy temporal 
and spatial variations of floating air with olfactory sensations from the scent, visual sensations from 
the projection screen, and tactile sensations from the wind. The aim of this project is to seek the possibilities 
of expression through scent information. hanahanahana. &#38;#169; 2009 plaplax. hanahanahana is an interactive 
installation that enables the real-time visualization of a scent flow in ambient air. More concretely, 
this system visualizes temporal and spatial variations of flowing air by projecting images on space according 
to scent distribution data. From the perspective of Touch Point, hanahanahana offers a novel interaction 
design that engages multiple senses. A previous version of this piece was presented as a poster at SIGGRAPH 
2007. While the system originally used only one sensor device, the current version of hanahanahana involves 
multiple devices shaped like buds attached on several points of a wall to visualize the spatial spread 
of the &#38;#169; 2010 Yasuaki Kakehi, Motoshi Chikamori, and Kyoko Kunoh | Leonardo, Vol. 43, No. 4, 
pp. 396 397, 2010 scent. Technically, each device can separately detect the magnitude and the variation 
of the ambient scent in real time with the aid of several gas sensors. Yasuaki Kakehi received his PhD 
in Interdisciplinary Information Studies from the University of Tokyo in 2007 and is now a lecturer at 
Keio University. Kakehi has developed various real­world-oriented interactive media and created media 
artworks based on innovative technologies. His works have been presented at various exhibitions, including 
SIGGRAPH and the Ars Electronica Festival. His awards include the NHK Digital Stadium Grand Prix in 2004. 
Motoshi Chikamori graduated from the Faculty of Environmental and Information Studies, Keio University, 
in 1995, and then went on to receive a Master's degree in Art and Design from Tsukuba University in 1998. 
Kyoko Kunoh graduated from the Faculty of Policy Management, Keio University, in 1995 and received a 
Master's degree in Media and Governance from Keio University in 1997. Chikamori and Kunoh began their 
collaboration as the media products group minim++ in 2000. They have produced many interactive works 
using toys and children s play as motifs. Their works have been featured internationally in such venues 
as Ars Electronica, SIGGRAPH, the Centre Pompidou, and the Tokyo Metropolitan Museum of Photography. 
 hanahanahana. &#38;#169; 2009 plaplax. hanahanahana | Yasuaki Kakehi et al. 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1836800</article_id>
		<sort_key>140</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[The lightness of your touch]]></title>
		<page_from>398</page_from>
		<page_to>399</page_to>
		<doi_number>10.1145/1836786.1836800</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836800</url>
		<abstract>
			<par><![CDATA[<p>In this piece one touches a larger-than-life torso that reacts. The skin of the body moves subtly as one's hand moves over the surface. If the hand is held down for a moment and then taken away, an impression of the hand is left behind. This imprint soon lifts off the surface and begins to blow around as if it were a leaf or tissue caught in a breeze. Many people can touch the surface at the same time, sharing in the interaction.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Haptic I/O</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10011752</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Haptic devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264020</person_id>
				<author_profile_id><![CDATA[81100224595]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Henry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kaufman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tactable, Cambridge, Massachusetts]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Henry Kaufman Henry Kaufman Tactable Cambridge, Massachusetts USA henrysigg@tumbao.net The Lightness 
of Your Touch In this piece one touches a larger-than-life torso that reacts. The skin of the body moves 
subtly as one s hand moves over the surface. If the hand is held down for a moment and then taken away, 
an impression of the hand is left behind. This imprint soon lifts off the surface and begins to blow 
around as if it were a leaf or tissue caught in a breeze. Many people can touch the surface at the same 
time, sharing in the interaction. The work employs rear infrared illumination and custom computer vision 
software to track the touches that the camera sees and map them to the curved screen. The touch outlines 
are con­verted to polygonal meshes that are placed in a fluid flow simulation that makes them blow like 
leaves in a breeze. When someone touches you and takes their hand away, what do you feel afterwards? 
Is that tingling warm sensation something of them, or is it created in your body? What remains of yourself 
when you touch something? If you could see the imprint of your touch, how would it appear? Kaufman's 
vision was to make it possible to see what you leave behind, turning that ephemeral residue into something 
visible. By showing people s touches to be semi-physical objects, the work seeks to create awareness 
with regard to touch and, perhaps, encourage more touching. In general, people need more physical contact 
to be healthy and balanced. &#38;#169; 2010 Henry Kaufman | Leonardo, Vol. 43, No. 4, pp. 398 399, 2010 
Many Western cultures discourage touch. Whether through fear of litigation or sexual harass­ ment, or 
uptightness in general, it seems that personal contact has become something to be avoided. One nurse 
told Kaufman that she was asked to stop hugging the patients in a nursing home even though she knew it 
helped them. Kaufman hopes that people will spend some time with this piece, that their explorations 
will lead to meditative reflection about touch and per­ sonal contact, and that their experience prompts 
discussion about touch whether intimate, friendly, or for therapeutic healing and personal boundaries 
in general. This piece is part of a series composed of three related works. The first, The Memory of 
Your Touch, explores the material of touch itself by giving physicality and weight to the touches that 
people leave behind. The second (the present work), The Lightness of Your Touch, explores touch on a 
human body, specifically a belly, and gives the touches a behavior like leaves blowing in the wind. Finally, 
the third work, A Touch of Ancient Memories, explores the "touches" as handprints created by our ancestors 
in cave paintings around the world. The Lightness of Your Touch. &#38;#169; 2004 Henry Kaufman, Photo 
&#38;#169; 2007 Henry Kaufman. Henry Kaufman brings his lifetime passion for computer graphics and a 
deep curiosity about touch to his production of interactive art. He received a double BA magna cum laude 
with honors in Visual Arts and Computer Science, and an MS in Computer Science from Brown University, 
and has worked in a variety of areas, including games special effects, graphical music composition software, 
and special effects for broadcast television. His work has been shown at the DeCordova Museum, Axiom 
Gallery, and the MIT Museum, and he has collaborated on innovative exhibits at many museums, including 
New York s MoMA and Liberty Science Center. Kaufman s work is known for breaking new ground in interactive 
public experiences and has earned many awards, including the Communication Arts Interactive Design Annual, 
ID maga­zine Interactive Annual, several Clios, and an Emmy nomination. In 2007, he started Tactable 
to focus on multi-touch tables and walls. The Lightness of Your Touch | Henry Kaufman 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1836801</article_id>
		<sort_key>150</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Tools for Improved Social Interacting]]></title>
		<page_from>400</page_from>
		<page_to>401</page_to>
		<doi_number>10.1145/1836786.1836801</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836801</url>
		<abstract>
			<par><![CDATA[<p><i>Tools for Improved Social Interacting</i> is a series of wearable devices---including the Anti-Day-dreaming Device, Happiness Hat, and Body Contact Training Suit---that use sensors to condition the behavior of the wearer to better adapt to expected social behaviors. The work explores the potential for technology to shape how we think, feel, and act. It also questions our social expectations, attempting to better understand their function and worth.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.4</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>K.3.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010489</concept_id>
				<concept_desc>CCS->Applied computing->Education</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010455</concept_id>
				<concept_desc>CCS->Applied computing->Law, social and behavioral sciences</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264021</person_id>
				<author_profile_id><![CDATA[81466641936]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lauren]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McCarthy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Los Angeles, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Lauren McCarthy Lauren McCarthy University of California, Los Angeles Los Angeles, California USA laurmccarthy@gmail.com 
www.lauren-mccarthy.com Tools for Improved Social Interacting Tools for Improved Social Interacting 
is a series of wearable devices including the Anti-Day­ dreaming Device, Happiness Hat, and Body Contact 
Training Suit that use sensors to condition the behavior of the wearer to better adapt to expected social 
behaviors. The work explores the potential for technology to shape how we think, feel, and act. It also 
questions our social expectations, attempting to better understand their function and worth. The Happiness 
Hat trains the wearer to smile more. An enclosed bend sensor attaches to the cheek and measures smile 
size, affecting an attached servo with metal spike. The smaller the smile of the wearer, the further 
a spike is driven into the back of their neck. The Body Contact Training Suit requires the wearer to 
maintain frequent body contact with another person in order to hear normally; if he or she stops touching 
someone for too long, static noise begins to play through headphones sewn into the hood. A capacitance 
sensing circuit measures skin-to­skin body contact via a metal bracelet sewn into the sleeve. The Anti-Daydreaming 
Device is a scarf with a heat radiation sensor that detects if the wearer is engaged in conversation 
with another person. During conversation, the scarf vibrates periodically to remind the wearer to stop 
daydreaming and pay attention. &#38;#169; 2010 Lauren McCarthy | Leonardo, Vol. 43, No. 4, pp. 400 401, 
2010 This project, and McCarthy's work in general, explores the potential for technology to shape our 
thoughts, feelings, and actions. In what ways can it be used to affect our interactions and relationships, 
and what does it mean to employ this kind of control? What social expectations do we have of each other, 
and what is the function and value of those expectations? The wearable devices provide haptic and audio 
feedback that is imperceptible to all but the wearer, allowing the devices to be fully integrated into 
everyday life. McCarthy is interested in the invisible influences of technology that can result in perceptible 
changes and shifts. As technologies that can manipulate our brains continue to be developed, it is essential 
that we explore the possibili­ties while considering the effects. Designer, artist, and programmer Lauren 
McCarthy is currently an MFA student in the UCLA Design | Media Arts program. She received a BS in Computer 
Science and a BS in Art and Design from MIT. Her work explores the structures and systems of social interaction, 
identity, and self-representation. She is interested in the slightly uncomfortable moments when patterns 
are shifted, expectations are broken, and participants become aware of the system. Her work takes any 
form necessary: video, performance, software, internet art, interactive objects/environ­ments, and media 
installations. McCarthy most recently worked at Small Design Firm on projects for the US Holocaust Memorial 
Museum, Thomas Jefferson s home at Monticello, and the Metropolitan Museum of Art. She has also worked 
at Continuum and the MIT Media Lab. Tools for Improved Social Interacting. &#38;#169; 2009 Lauren McCarthy. 
Tools for Improved Social Interacting | Lauren McCarthy 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1836802</article_id>
		<sort_key>160</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Dinner Party]]></title>
		<page_from>402</page_from>
		<page_to>403</page_to>
		<doi_number>10.1145/1836786.1836802</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836802</url>
		<abstract>
			<par><![CDATA[<p><i>Dinner Party</i> is an interactive installation, where a single chair and a place set for one person seem to provide a solitary dining experience. However, the installation offers an interaction between oneself and imaginary creatures. As if she or he is about to enjoy a meal, a participant sits down at an interactive table on which are placed several objects that he or she can move. The objects cast virtual shadows on the tabletop, with animated creatures hiding in these shadows.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Artificial, augmented, and virtual realities</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Virtual reality</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010392</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Mixed / augmented reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010866</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264022</person_id>
				<author_profile_id><![CDATA[81421598048]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hye]]></first_name>
				<middle_name><![CDATA[Yeon]]></middle_name>
				<last_name><![CDATA[Nam]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology, Atlanta, Georgia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Hye Yeon Nam Hye Yeon Nam Georgia Institute of Technology Atlanta, Georgia USA hyeonam@gmail.com Collaborators: 
Crystal Campbell, Carl Disalvo, Zach Lieberman, Kueiju Lin, Martín Nadal, Jeremy Rotsztain Dinner Party. 
&#38;#169; 2008 Hye Yeon Nam, Photo &#38;#169; Chang Kyun Kim. Dinner Party Dinner Party is an interactive 
installation, where a single chair and a place set for one person seem to provide a solitary dining experience. 
However, the installation offers an interaction between oneself and imaginary creatures. As if she or 
he is about to enjoy a meal, a participant sits down at an interactive table on which are placed several 
objects that he or she can move. The objects cast virtual shadows on the tabletop, with animated creatures 
hiding in these shadows. Among our everyday habits, having a meal is a banal routine. With tabletop technology 
and computer vision, however, a diner encounters a magical moment where imaginary creatures appear during 
the meal. Meaningless everyday gestures become meaningful when a participant touches the point of entry 
into a new world. Dinner Party provides an environment where people meet and interact with Lewis Carroll 
s Jabberwocky (1872), which describes creatures hiding in the shadows. There is a chair, a table, and 
a table setting for one person s dinner. The table becomes the interactive platform between the participant 
and the imaginary creatures living in the shadows of the table setting. Creatures move from the main 
plate s shadow to other shadows while scattering or hiding in between. When the participant waits long 
enough, the creatures reveal themselves and the Jabberwocky poem appears on the table. In our solitary 
modern society, an imaginary friend is able to make our loneliness disappear. Hye Yeon Nam is a digital 
media artist working on audio/video installations in Atlanta and New York City. She is a PhD candidate 
at Georgia Institute of Technology and holds an MFA in digital media from the Rhode Island School of 
Design. Crystal Campbell practices poetic design, where the meaning of a product or service is open-ended. 
She holds an MA summa cum laude in &#38;#169; 2010 Hye Yeon Nam | Leonardo, Vol. 43, No. 4, pp. 402 
403, 2010 Creative Practice for Narrative Environments (MACPfNE) from Central Saint Martins, Lon­don. 
Carl DiSalvo is Assistant Professor of Digital Media in the School of Literature, Communication and Culture 
at the Georgia Institute of Technology. He earned a PhD in Design from Carnegie Mellon University in 
2006, and was a post-doctoral fellow at the Center for the Arts in Society and the Studio for Creative 
Inquiry from 2006-2007. Zachary Lieberman teaches at Parsons School of Design. His work uses technology 
in a playful way to explore the nature of communication and the delicate boundary between the visible 
and the invisible. Kueiju Lin is the music director of the M.O.V.E. Theater Group (Taipei) and an assistant 
professor at the National Tainan University of the Arts. She holds a PhD in composition from University 
of California, San Diego. Martín Nadal is a digital media artist/programmer based in Spain. His collaborative 
works have been showcased at Ars Electronica 2006, Ars Electronica 2008, eyebeam, MadridMediaPrado, and 
Noche en Blanco. Jeremy Rotsztain is a Canadian video artist and software developer. He recently completed 
his Master's degree in Art and Technology at the Interactive Telecommunications Program of New York University. 
 Dinner Party. &#38;#169; 2008 Hye Yeon Nam, Photo &#38;#169; Chang Kyun Kim. Dinner Party | Hye Yeon 
Nam 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1836803</article_id>
		<sort_key>170</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[samplingplong]]></title>
		<page_from>404</page_from>
		<page_to>405</page_to>
		<doi_number>10.1145/1836786.1836803</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836803</url>
		<abstract>
			<par><![CDATA[<p><i>samplingplong</i> features a projected mouse cursor interacting in physical space, generating miniature sound compositions with pleasurable arrangements from the everyday soundtrack of the digital age.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Input devices and strategies (e.g., mouse, touchscreen)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003125</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10011666</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Touch screens</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264023</person_id>
				<author_profile_id><![CDATA[81466648219]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Joerg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Niehage]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Frankfurt, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Joerg Niehage Joerg Niehage Frankfurt Germany joerg@schroeder-niehage.de samplingplong samplingplong 
features a projected mouse cursor interacting in physical space, generating miniature sound compositions 
with pleasurable arrangements from the everyday soundtrack of the digital age. &#38;#169; 2010 Joerg 
Niehage | Leonardo, Vol. 43, No. 4, pp. 404 405, 2010 samplingplong is an interface consisting of physical 
objects electronic junk, plastic toys, com­pressed air valves, pneumatically operated components, coiling 
cables and wires arranged on a tablecloth. These objects are turned into interactive instruments via 
a computer-controlled device. An improvised ensemble evolves, eliciting by means of mouse-over and mouse-click 
short miniature compositions of dense rhythmic clicks, hisses, whirs, hums, and crackles. The result 
is a tapestry of sound bursting forth from the floral-like web of cables and tubes. The installation 
can be experienced by rolling the projected mouse-cursor over the improvised instruments, causing small 
sound events which allow the user to play spontaneous improvisations. Clicking these objects starts short 
programs of loop-like compositions small techno-compositions en miniature, rhythmic patterns of analog 
(or real) sounds, physical low-tech simulations of electronic, digital music. All represent an ironic 
comment on interactivity. Joerg Niehage (Germany) studied Communications Design at the University of 
Applied Science in Darmstadt. His work operates between the fields of graphic design, installation and 
sound art. Niehage has participated in exhibitions and festivals that include Ars Electronica (Linz), 
Trans­mediale (Berlin), FILE 2009 (São Paulo), Transitio_MX (Mexico City), Schirn Kunsthalle (Frankfurt), 
Lab30 (Augsburg), the Athens Video Art Festival, and Mousonturm (Frankfurt). samplingplong. &#38;#169; 
2009 Joerg Niehage. samplingplong | Joerg Niehage 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1836804</article_id>
		<sort_key>180</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Empire of Sleep]]></title>
		<subtitle><![CDATA[the beach]]></subtitle>
		<page_from>406</page_from>
		<page_to>407</page_to>
		<doi_number>10.1145/1836786.1836804</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836804</url>
		<abstract>
			<par><![CDATA[<p><i>Empire of Sleep</i> is an interactive virtual environment installation viewed in stereoscopic 3D on a large rear projection screen. Participants interact using a hand-held camera to take photographs of the scene, triggering the virtual camera to move to new points of interest. A group of surreal-looking figures, clothed in early 20th century bathing suits, are scattered about on several isolated sand bars somewhere on an open and calm body of water. They first appear as if there for recreation, but there is a pensive mood, as if some unusual event is taking place unknown to the viewer.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Artificial, augmented, and virtual realities</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Virtual reality</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010866</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010392</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Mixed / augmented reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264024</person_id>
				<author_profile_id><![CDATA[81335496510]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Price]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ohio State University, Columbus, Ohio]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Alan Price Alan Price The Advanced Computing Center for the Arts and Design Ohio State University Columbus, 
Ohio USA aprice@accad.osu.edu Empire of Sleep: The Beach Empire of Sleep is an interactive virtual environment 
installation viewed in stereoscopic 3D on a large rear projection screen. Participants interact using 
a hand-held camera to take photographs of the scene, triggering the virtual camera to move to new points 
of interest. A group of surreal­looking figures, clothed in early 20th century bathing suits, are scattered 
about on several isolated sand bars somewhere on an open and calm body of water. They first appear as 
if there for recreation, but there is a pensive mood, as if some unusual event is taking place unknown 
to the viewer. &#38;#169; 2010 Alan Price | Leonardo, Vol. 43, No. 4, pp. 406 407, 2010 Alan Price's 
interest is in creating new forms of interactive and virtual cinema, in which the viewer's experience 
is informed by alternate methods of both display and user input, creating an intuitive and visceral sensation 
for the viewer in extending his or her reach into the space in which the story or event unfolds, creating 
virtual worlds that have awareness and responsiveness to the presence of the observer. It is not about 
user intervention or control of the story, but rather the symbiotic relationship between the observer 
and the narrative event. Price is interested in designing physical user interfaces that are thematically 
interpretive of the subject matter repre­sented in the work and, more importantly, that allow the viewer 
to feel as if physically extended into the virtual space, giving a sense of embodiment and immersion 
that dissolves the separation between the two. This is not limited to methods for engaging multiple senses 
or surrounding the viewer to make him or her feel physically immersed, but investigating ways in which 
actions and their familiarity, such as taking a photograph, provide a sense of playing a role and of 
being integral to the representation of events taking place. Empire of Sleep: The Beach. &#38;#169; 
2009 Alan Price. Price is an artist who creates real-time responsive animation. With his background as 
a film­maker and animator, he emphasizes narrative and cinematic structure in his works with immersive 
and interactive storytelling. Utilizing video game technology and a combination of ready-made and custom 
hardware, he creates virtual environments and responsive spaces to explore alternative forms of personal 
expression in time-based digital media. His animation and interactive work has been exhibited internationally 
and is on permanent display in museums of art, technology, science, and history. He is currently a professor 
at the Ohio State University s Advanced Computing Center for the Arts and Design. Empire of Sleep | 
Alan Price 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1836805</article_id>
		<sort_key>190</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Lotus 7.0]]></title>
		<page_from>408</page_from>
		<page_to>409</page_to>
		<doi_number>10.1145/1836786.1836805</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836805</url>
		<abstract>
			<par><![CDATA[<p>What happens when technology makes the leap out of the computer screen and becomes embedded in our walls, bodies, and urban landscapes? This was the inspiration for Studio Roosegaarde's most recent interactive artwork, <i>Lotus 7.0. Lotus 7.0</i> is a "living" wall made of smart foils, electronics, and lamps that interacts with human behavior.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264025</person_id>
				<author_profile_id><![CDATA[81466648619]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Roosegaarde]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Studio Roosegaarde_explorations in Art & Technology, Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Daan Roosegaarde Daan Roosegaarde Studio Roosegaarde_explorations in Art &#38; Technology Netherlands 
daan@studioroosegaarde.net www.studioroosegaarde.net Lotus 7.0 What happens when technology makes the 
leap out of the computer screen and becomes embedded in our walls, bodies, and urban landscapes? This 
was the inspiration for Studio Roosegaarde's most recent interactive artwork, Lotus 7.0. Lotus 7.0 is 
a living wall made of smart foils, electronics, and lamps that interacts with human behavior. Based on 
the concept of photosynthesis (light transformed into food), a smart foil was developed to open when 
lit. When someone walks past, hundreds of squares fold open in an organic way, creating new relations 
between private and public space. Here, physical space becomes immate­rial in a poetic morphing of space 
and human interactions. &#38;#169; 2010 Daan Roosegaarde | Leonardo, Vol. 43, No. 4, pp. 408 409, 2010 
 Lotus 7.0. &#38;#169; 2010 Daan Roosegaarde. Daan Roosegaarde is an artist working in Rotterdam, the 
Netherlands. He studied at the Academy of Fine Arts AKI in Enschede and received a Master s degree at 
the Berlage Institute, a Postgraduate Laboratory of Architecture in Rotterdam. Currently Roosegaarde 
is the Creative Director of Studio Roosegaarde, an artistic laboratory for interactive projects which 
won the Dutch Design Award 2009. In this interaction, his sculptures create a situation of tactile high-tech 
where visitor and public space become one. Roosegaarde's interactive projects have been shown internationally 
at V2_ (Rotterdam), the Netherlands Media Art Institute/Montevi­deo/Time Based Art (Amsterdam), the Tate 
Modern (London), YCAM (Japan), the National Art Center (Tokyo), the Venice Biennale 2009, and the Victoria 
and Albert Museum (London). Lotus 7.0. &#38;#169; 2010 Daan Roosegaarde. Lotus 7.0 | Daan Roosegaarde 
 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1836806</article_id>
		<sort_key>200</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[In the Line of Sight]]></title>
		<page_from>410</page_from>
		<page_to>411</page_to>
		<doi_number>10.1145/1836786.1836806</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836806</url>
		<abstract>
			<par><![CDATA[<p><i>In the Line of Sight</i> is a light installation that uses 100 computer-controlled tactical flashlights to project low-resolution video footage of suspicious human motion into the exhibition space. Each flashlight projects a light spot on the wall. All flashlights combined create a ten-by-ten matrix representation of the source footage, featured on a video monitor in an adjacent part of the gallery. <i>In the Line of Sight</i> is an artistic exploration of low-resolution video projections exploring electronic images not as simulations of reality but as objects anchored in the physical space.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264026</person_id>
				<author_profile_id><![CDATA[81319500913]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sauter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois at Chicago, Chicago, Illinois]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P2264027</person_id>
				<author_profile_id><![CDATA[81460650688]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Fabian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Winkler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Purdue University, West Lafayette, Indiana]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Daniel Sauter and Fabian Winkler Daniel Sauter University of Illinois at Chicago Chicago, Illinois 
USA contact@daniel-sauter.com Fabian Winkler Department of Visual and Performing Arts Purdue University 
West Lafayette, Indiana USA fwinkler@purdue.edu In the Line of Sight. &#38;#169; 2009 Daniel Sauter, 
Fabian Winkler. In the Line of Sight In the Line of Sight is a light installation that uses 100 computer-controlled 
tactical flashlights to project low-resolution video footage of suspicious human motion into the exhibition 
space. Each flashlight projects a light spot on the wall. All flashlights combined create a ten-by-ten 
matrix representation of the source footage, featured on a video monitor in an adjacent part of the gallery. 
In the Line of Sight is an artistic exploration of low-resolution video projections exploring electronic 
images not as simulations of reality but as objects anchored in the physical space. Daniel Sauter s works 
are designed as open frameworks that require an active audience to complete the work. Sauter is interested 
in creating artworks that evolve over time, anticipating unpredictable and unexpected interactions between 
the work and the audience. This relationship focuses on unique experiences and engagement with the work. 
It questions the very nature of authorship and mastery by replacing finished work with open and ongoing 
processes. Fabian Winkler s work proposes new practices for looking at familiar objects and spaces around 
us. Using the expressive and aesthetic potential of new media technologies, he creates critical, surprising, 
and sometimes humorous interventions. By linking technologies with concepts and vice versa, four different 
media have become integral to Winkler s art practice: sound, light, robotics, and moving images. Winkler 
relates sound to the physical structures and the electronic components of his works and sees light s 
potential for abstraction to create new, artificial realities and to transform objects and environments 
visually and ideologically. Winkler treats robotic and kinetic systems as sculpture, installation, and 
environment, allowing audiences to experience the &#38;#169; 2010 Daniel Sauter and Fabian Winkler | 
Leonardo, Vol. 43, No. 4, pp. 410 411, 2010 work on different poly-sensorial levels. With moving images, 
the cinematic apparatus mediates audio-visual, tactile, and emotional experiences of synthesized realities. 
It presents the audience with (im)possible worlds similar to Winkler s artworks. Daniel Sauter is currently 
an assistant professor and program coordinator at the University of Illinois at Chicago, School of Art 
and Design. He creates interactive installations and site-specif­ic interventions dealing with the cultural 
and social implications of emergent technologies. His work spans a variety of disciplines, including 
electronic art, performance art, robotic art, sound art, interactive sculpture, and software art. While 
technology plays an important role in his work, it is not foregrounded. He uses technology as artistic 
material, embedded in larger social and cultural contexts. Sauter s research is driven by a curiosity 
about the ways in which tech­nologies shape and transform urban spaces, social relationships, and the 
human body. Sauter s collaborator, Fabian Winkler, is an assistant professor of Visual and Performing 
Arts and area head of the program in Electronic and Time-Based Art at Purdue University. In his interactive 
installations and video works, Winkler explores the aesthetic potential and the cultural implica­tions 
of seemingly well-known artifacts through the use of new technologies. His art practice is trans-disciplinary, 
located at the intersections of the moving image, spatial structures, sound, and robotics. Conceptually, 
his works are often influenced by archeological research into the history of technology and observations 
of social processes. In the Line of Sight. &#38;#169; 2009 Daniel Sauter, Fabian Winkler. In the Line 
of Sight | Sauter and Winkler 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1836807</article_id>
		<sort_key>210</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[Glowing Pathfinder Bugs]]></title>
		<page_from>412</page_from>
		<page_to>413</page_to>
		<doi_number>10.1145/1836786.1836807</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836807</url>
		<abstract>
			<par><![CDATA[<p>Using the shared environment of a sandpit, <i>Glowing Pathfinder Bugs</i> allows virtual creatures and real people to coexist and communicate. The sand operates as a tactile interface, allowing participants to define physical landscapes to which the digital creatures respond in real time. The result is a form of animal husbandry---a sense of controlling and caring for the bugs.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Artificial, augmented, and virtual realities</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Virtual reality</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010392</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Mixed / augmented reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010866</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264028</person_id>
				<author_profile_id><![CDATA[81100148835]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Anthony]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rowe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Oslo School of Architecture and Design / Squidsoup, Norway]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Squidsoup Anthony Rowe Oslo School of Architecture and Design / Squidsoup Norway ant@squidsoup.org 
Collaborators: Anthony Rowe, Liam Birtles, Chris Bennewith www.squidsoup.org www.squidsoup.org/bugs Glowing 
Pathfinder Bugs. &#38;#169; 2009 squidsoup.org. Glowing Pathfinder Bugs Using the shared environment 
of a sandpit, Glowing Pathfinder Bugs allows virtual creatures and real people to coexist and communicate. 
The sand operates as a tactile interface, allowing participants to define physical landscapes to which 
the digital creatures respond in real time. The result is a form of animal husbandry a sense of controlling 
and caring for the bugs. Glowing Pathfinder Bugs was commissioned by Folly for PortablePixelPlayground 
(www.portablepixelplayground.org). Glowing Pathfinder Bugs resulted from a period of research into interaction 
in three physical dimensions. Techniques and technologies that were originally designed to track human 
gestures and movement have been used here to blur the boundaries between the real world and virtual space. 
 &#38;#169; 2010 Squidsoup | Leonardo, Vol. 43, No. 4, pp. 412 413, 2010 In this work, the physical and 
tactile landscape of a sandpit is mapped directly onto virtual space. Any changes to the physical topography 
of the sandpit are immediately mirrored in the virtual environment. The virtual space is then mapped 
directly back onto the physical space by project­ing the bugs onto the sand. The creatures are able to 
navigate this ever-changing landscape, aware of their physical surroundings, searching out gullies and 
low-lying areas in real time. Because the bugs decisions are based on their environment, and this is 
controlled by partici­pants, there is a strong sense of communication and interaction between the bugs 
and people. This interaction extends to how people play with the bugs. They can be antagonized even terrorized 
but they can also be anthropomorphized, cared for, and husbanded. Squidsoup s work combines sound, physical 
space, and virtual worlds to produce immersive and Glowing Pathfinder Bugs. emotive headspaces. They 
aim to allow participants to take active control of their experience. &#38;#169; 2009 squidsoup.org. 
They explore the modes and effects of interactivity, looking to make digital experiences where meaningful 
and creative interaction can occur. Squidsoup is an open group of collaborators. Glowing Pathfinder Bugs 
was created by Anthony Rowe, creative lead and Squidsoup founder. He is also Associate Professor of Interaction 
Design at the Oslo School of Architecture and Design (Norway). Chris Bennewith, visual designer at Squidsoup, 
is Associate Professor, Head of the Institute of Visual Communication at Massey University, Wellington 
(New Zealand). Liam Birtles is Senior Lecturer in Digital Media Production at Arts University College 
Bournemouth (United Kingdom). Glowing Pathfinder Bugs | Squidsoup 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1836808</article_id>
		<sort_key>220</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>07-26-2010</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[ADB]]></title>
		<page_from>414</page_from>
		<page_to>415</page_to>
		<doi_number>10.1145/1836786.1836808</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1836808</url>
		<abstract>
			<par><![CDATA[<p><i>ADB</i> is a snake-like, modular robot designed for haptic interactions with people, writhing, wriggling, twisting, and squeezing in response to how it is held and touched. It can be used to explore intimate and emotional relationships with technology through direct physical contact. <i>ADB</i> adapts to and reciprocates the energy one puts into it through one's body. When touched, it comes to life. When stroked, it seeks more of you. When harmed, it defends.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Haptic I/O</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10011752</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Haptic devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P2264029</person_id>
				<author_profile_id><![CDATA[81466644572]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nicholas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stedman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[York University, Toronto, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Nicholas Stedman Nicholas Stedman Course Director FACS New Media Program York University Toronto, Canada 
Adjunct Instructor New Media Program Ryerson University Toronto, Canada nickstedman@gmail.com Collaborator: 
Kerry Segal ADB. &#38;#169; 2008 Nicholas Stedman. ADB  ADB is a snake-like, modular robot designed 
for haptic interactions with people, writhing, wriggling, twisting, and squeezing in response to how 
it is held and touched. It can be used to explore intimate and emotional relationships with technology 
through direct physical contact. ADB adapts to and reciprocates the energy one puts into it through one 
s body. When touched, it comes to life. When stroked, it seeks more of you. When harmed, it defends. 
ADB is composed of a series of identical modules that are connected by mechanical joints. Each module 
contains a servo motor, a variety of sensors, including capacitive touch sensors, a rotary encoder, and 
a current sensor to provide information about the relationship to a person s body. The electronics are 
enclosed within plastic shells fabricated on 3D printers. For the past decade, Stedman has been designing 
and fabricating machines, combining ideas and techniques drawn from both visual arts and engineering. 
He relates closely to the practices of Device Art and Making. Much of his work involves writing software, 
designing mecha­nisms and electronic circuits, and working with materials, while at the same time exploring 
the social, environmental, economic, and civic impact of technologies those he produces and those he 
employs. &#38;#169; 2010 Nicholas Stedman | Leonardo, Vol. 43, No. 4, pp. 414 415, 2010 In particular, 
Stedman's artwork pertains to embodied communication and social robotics. He makes robots that engage 
people in non-linguistic, haptic interactions. By eliminating symbolic communication such as language 
or even gesture, and focusing instead on direct bodily engage­ ment, the objective is to stimulate sensations, 
and perhaps emotions, in human participants. The aesthetic experience is comprised of the tangible feelings 
which the machine produces through physical interaction, as well as the ideas and associations that are 
evoked through the unusual experience of engaging in a sensual relationship with an artificial entity. 
The robots are composed of assemblies of haptic-expression modules which, like pixels, can be coordinated 
to render a representation, in this case through kinetic deformation against a person s body. The modules 
are built from a variety of sensors, motors, and other electronic and mechanical components, all enclosed 
within CNC fabricated shells, which protect the technol­ ogy and determine the outward appearance. A 
wide variety of control programs are possible with such architecture, and the modules are designed to 
be easily reprogrammed in order to support explorations in software. While Stedman is most interested 
in decentralized machine learning techniques (including genetic algorithms and artificial neural nets), 
the control software he uses is that which affords the desired behavior with some economy. ADB. &#38;#169; 
2008 Nicholas Stedman. Nicholas Stedman is an artist and device-maker whose projects have ranged from 
machines and interactive installations to performance technology and software. In recent years, he has 
focused on building robots which physically interact with people. Such devices have been enacted in galleries, 
festivals, and other public forums where people can examine and interact with them. Stedman graduated 
with an MFA from the State University of New York at Buffalo in 2008 and now teaches digital media at 
York University and Ryerson University in Toronto. His artwork has been showcased at several international 
festivals including Future Physical, Ars Electronica, and ISEA. Stedman's collaborator, Kerry Segal, 
is a performer and community artist. She explores the sensorial experience of embodiment through theatre 
and dance, and by involving participants in ad hoc performances that stretch their boundaries. She works 
with Nicholas Stedman, perform­ing with his robots, and helping others to both explore the machines and 
reflect on their relationship to technology on an intimate and sensual level. Segal lives in Toronto, 
Canada where she works with Jumblies community arts group. Her works have been shown in various Canadian 
and international festivals, including fFida, Rhubarb, and CAFKA. ADB | Nicholas Stedman 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	</section>
</content>
</proceeding>

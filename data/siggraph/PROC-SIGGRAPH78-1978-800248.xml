<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>08-23-1978</start_date>
		<end_date>08-25-1978</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[]]></city>
		<state></state>
		<country></country>
	</conference_loc>
	<conference_url></conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES382</series_id>
		<series_title><![CDATA[International Conference on Computer Graphics and Interactive Techniques]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>800248</proc_id>
	<acronym>SIGGRAPH '78</acronym>
	<proc_desc>Proceedings of the 5th annual conference</proc_desc>
	<conference_number></conference_number>
	<proc_class>conference</proc_class>
	<proc_title>Computer graphics and interactive techniques</proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>1978</copyright_year>
	<publication_date>08-23-1978</publication_date>
	<pages>363</pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<publisher>
		<publisher_id>PUB27</publisher_id>
		<publisher_code>ACMNY</publisher_code>
		<publisher_name>ACM</publisher_name>
		<publisher_address>2 Penn Plaza, Suite 701</publisher_address>
		<publisher_city>New York</publisher_city>
		<publisher_state>NY</publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>10121-0701</publisher_zip_code>
		<publisher_contact>Bernard Rous</publisher_contact>
		<publisher_phone>212 869-7440</publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url>www.acm.org/publications</publisher_url>
	</publisher>
	<sponsor_rec>
		<sponsor>
			<sponsor_id>SP932</sponsor_id>
			<sponsor_name>ACM Special Interest Group on Computer Graphics and Interactive Techniques</sponsor_name>
			<sponsor_abbr>SIGGRAPH</sponsor_abbr>
		</sponsor>
	</sponsor_rec>
	<categories>
		<primary_category>
			<cat_node>I.3</cat_node>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
	<ccs2012>
		<concept>
			<concept_id>0.10010147.10010371</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
			<concept_significance>500</concept_significance>
		</concept>
	</ccs2012>
	<general_terms>
		<gt>Design</gt>
		<gt>Theory</gt>
	</general_terms>
	<chair_editor>
		<ch_ed>
			<person_id>PP39058581</person_id>
			<author_profile_id><![CDATA[81100315822]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>1</seq_no>
			<first_name><![CDATA[S.]]></first_name>
			<middle_name><![CDATA[H.]]></middle_name>
			<last_name><![CDATA[Chasen]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[]]></affiliation>
			<role><![CDATA[Chairman]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
		<ch_ed>
			<person_id>PP39105007</person_id>
			<author_profile_id><![CDATA[81332520985]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>2</seq_no>
			<first_name><![CDATA[R.]]></first_name>
			<middle_name><![CDATA[L.]]></middle_name>
			<last_name><![CDATA[Phillips]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[]]></affiliation>
			<role><![CDATA[Chairman]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
	</chair_editor>
	<ccc>
		<copyright_holder>
			<copyright_holder_name>ACM</copyright_holder_name>
			<copyright_holder_year>1978</copyright_holder_year>
		</copyright_holder>
	</ccc>
</proceeding_rec>
<content>
	<article_rec>
		<article_id>807359</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[The use of grayscale for improved raster display of vectors and characters]]></title>
		<page_from>1</page_from>
		<page_to>5</page_to>
		<doi_number>10.1145/800248.807359</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807359</url>
		<abstract>
			<par><![CDATA[<p>Decreasing memory costs will soon allow grayscale displays in low-cost raster graphic terminals. Subtle shadings can be used to provide improvements in line quality and character flexibility which could allow raster displays to compete on better terms with the more expensive calligraphic displays. Algorithms for achieving smooth vectors and rotatable dot matrix characters are outlined and scan conversion is discussed. A discussion of the relation between image quality and number and distribution of gray levels follows, with concluding remarks on costs and other practical matters.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Alphanumeric displays]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Digital image memories]]></kw>
			<kw><![CDATA[Graphic displays]]></kw>
			<kw><![CDATA[Raster displays]]></kw>
			<kw><![CDATA[Scan conversion]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.3</cat_node>
				<descriptor>Grayscale manipulation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P86300</person_id>
				<author_profile_id><![CDATA[81100447047]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Franklin]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Crow]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Texas, Austin, Texas]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M., "Trends in Graphic Display Design", IEEE-TC, Dec. 1976]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M., 2648A Graphics Terminal, Hewlett-Packard, Palo Alto, California]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M., 4025 Terminal, Tektronix Inc. Beaverton, Oregon]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M., IGT 100 Interactive Graphics Terminal, California Computer Products Inc., Anaheim, California.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359869</ref_obj_id>
				<ref_obj_pid>359863</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Crow, F. C., "The Aliasing Problem in Computer-Synthesized Shaded Images," CACM, November 1977.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Shoup, R. G., "Some Quanization Effects in Digitally-Generated Pictures", SID 1973 Symposium Digest of Technical Papers, May 1973.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Davis, S., Computer Data Displays, 1969, Prentice-Hall, Englewood Cliffs, New Jersey.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M. and Sproull, R. F., Principles of Interactive Computer Graphics, 1973, McGraw-Hill Inc.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Biberman, L. M., ed., Perception of Displayed Information, 1973, Plenum Press, New York]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Cornsweet, T. N., Visual Perception, 1970, Academic Press, New York.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Blackwell, H. R., "Contrast Thresholds of the Human Eye", Journal of the Optical Society of America, 1946, Vol. 36, pp 642-643.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Graham, C. H. ed., Vision and Visual Perception, 1975, John Wiley and Sons, New York.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 THE USE OF GRAYSCALE FOR IMPROVED RASTER DISPLAY OF VECTORS AND CHARACTERS Franklin C. Crow University 
of Texas Austin, Texas ABSTRACT Decreasing memory costs will soon allow grayscale displays in low-cost 
raster graphic terminals. Subtle shadings can be used to provide improvements in llne quality and character 
flexibility which could allow raster displays to compete on better terms with the more expensive calligraphic 
displays. Algorithms for achieving smooth vectors and rotatable dot matrix characters are outlined and 
scan conversion is discussed. A discussion of the relation between image quality and number and distribution 
of gray levels follows, with concluding remarks on costs and other practical matters. Key words and phrases: 
computer graphics, raster displays, scan conversion, graphic displays, digital displays image memories, 
alphanumeric CR Categories: 8.2,6.35 INTRODUCTION Recent precipitous drops in the cost of memory have 
kindled a great deal of interest in raster displays refreshed from digital image memories [I]. Such displays 
allow the low cost of television technology to be put to good use in terminals with graphic capabilities 
[2,3,4]. In the near future, terminals with enough memory to provide several blt~ for every dot position 
will be practical. The ,~se of these additlonal bits to provide grayscale images opens up a host of additional 
uses for raster display terminals; facsimile transmission and display of processed images, for example. 
A less obvious advantage to be gained from grayscale lles in the higher quality vectors and characters 
obtainable. Improved quality could allow raster displays to replace more expensive calligraphic displays 
in many applications and invite applications for which the expense of a calligraphic display can't be 
justified. Advantages currently offered by calligraphic displays derive from their analog vector generators 
which allow nice straight, precisely positioned vectors. Characters made from short strokes can thus 
he placed precisely and in any orientation; it is no more difficult to write characters at one size or 
angle than at another. Thus applications such as graphic composition for various print media which require 
precise yet arbitrary positioning of characters would need calligraphic displays. On the other hand, 
raster displays, especially grayscale displays, are more effective for shaded areas and photographic 
reproductions. Clearly, a display o~ferlng both capabilities would be most useful. The purpose of this 
paper is to demonstrate to what extent a grayscale raster display can provide those capabilities. This 
work was supported by the National Science Foundation under grant MCS 76-83889. A raster display can 
only produce dots in given positions. Therefore, vectors made of these dots appear Jagged since they 
must follow a regular grid defined by the raster scan. Furthermore, vectors may not be arbitrarily positioned, 
but must begin and end at dot positions. Similarly, characters for raster display are produced from a 
dot matrix description. As long as the dot matrix of the character is properly aligned with the raster, 
such characters are quite readable. However, attempts to rotate or scale such characters yield horrible 
results except in specific cases such as rotations of ninety degrees or integral scale factors [figure 
I]. RASTER figure i Therefore, smooth and arbitrarily posltlonable vectors are needed to produce stroke 
characters and dots of arbitrary size and position are needed for dot matrix characters. These may both 
be realized by using gray levels to create the appearance of image details lying between dot positions. 
 Consider the image of a small spot displayed on a raster. Such a spot can appear to be moving smoothly 
across the display from pixel to pixel i£ one plxel is dimmed while the next is simultaneously brightened 
[figure 2]. Thus adjacent pixels at half intensity give the appearance of a spot lying between them. 
 Similarly, gray levels allow a nearly vertical vector displayed on a raster to appear smooth instead 
of jagged. Instead of representing the horizontal position of the vector with a single dot, two or three 
dots of varying intensities can be used [figure 2]. While the vectors thus produced are fatter and not 
so precisely delineated, the apparent position of the vector is actually more accurate since it is implicitly 
derived from the nearby environment rather than explicitly set forth by the display. The Interesting 
result of all this is that the use of grayscale allows, to some extent, the representation of detail 
finer than the resolution of the display; details may be placed to "subpixel'~ resolution. Therefore, 
by producingblurred images I greater precision is possible.This is true only because the sharp images 
made with black or white displays contain inherent inaccuracies. A discussion of these matters can be 
found in an earlier paper [5]. ~::~ ..~'"I: / ..T  /"/i! / i figure 2  The recent availability 
of digital grayscale displays has stimulated a number of similar but independently discovered algorithms 
for smoothing Jagged vectors and representing small spots.Shoup [6] published a description of a vector 
drawing algorithm and Steve Gabriel invented a spot representation algorithm in use by the Evans and 
Sutherland Corp. These and many other unpublictzed or proprietary algorithms are not substantially different 
from the independentlydeveloped algorittms presented below. DISPLAY OF A GENERALIZED SPOT A properly 
adjusted dlgltal raster displayconsists of regularly spaced dots which overlap by about one-half [7,8,9]. 
Ideally the Intensity displayed at each plxel should represent the intensity and size of whatever is 
to be represented by the area of the dot on the display. Thus a very small object midway between two 
plxe~s would contribute to the intensity of each. In most cases, an infinitely small, infinitely bright 
spot would contribute to the intensity of four plxels [figure 3a]. Equivalent images may be obtained 
using a hypothetical model which leads to a simplerrealization. Let the dots ot the raster be modeled 
as infinitely small points and the spots to be represented modeled as larger blobs [figure 3b]. This 
leads directly to a procedure which allows representation of spots in not only arbitrary positions but 
also arbitrary sizes. 0  (a) (b) figure 3 In proper theoretical terms, the hypothetical continuous 
image containing spots to be represented must be sampled to provide a digitalimage for display. Sampling 
theory states that if we are to correctly sample and reproduce an image, it must not contain spatial 
frequencies greater than one-half the sampling frequency. To meet this condition, the hypothetical continuous 
image must be filtered to remove higher frequencies. An adequate approximation to filtering is achieved 
by representing spots as larger blobs, denser at the middle than at the edges. A blob may be represented 
by a square matrix of intensities greatest at the middle and decreasing toward the extremes in all directions. 
Superposing this matrix over the raster, the element of the matrix which lies closest to a ~ iven pixel 
gives its intensity [figure 4]. Any istribution of intensities which stores the highest values in the 
more interior positions of the matrix works reasonably well. OHIlIXO0 X 01222210 12233221 123hh321 
 i23hdX21 X 12233221 01222210 00111100 X X X figure 4 Clearly, a larger spot may be represented 
by scaling up the size of the superposed matrix. What is less clear is that a spot smaller than the size 
of a raster dot can also be represented. To represent a smaller spot, it is sufficient to scale down 
the values stored in the matrix. When objects too small to be resolved are perceived, size and intensity 
become interchangeable [10].Thus by scaling either the values or the spatial displacement ot the members 
of the matrix, spots which are arbitrarily small or large, respectively, may be represented. For the 
case of spots the same size as raster dots, the superpositton of the intensity matrix can be fairly simple. 
Assume a 256 X 256 dot raster. To define a raster position requires 8 bits of information for each of 
two dimensions. If 12 bits are kept for each dimension, a spot can be positioned to greater accuracy 
as follows. Having determined a raster position from the most significant 8 blts, the least significant 
tour bits can be used to determine the superposition of a 32 X 32 intensity matrix over the raster. Four 
values may then be read from the matrix by using the least significant four bits of the two coordinates 
and the complements of those four bit quantities to index from the center of the 32 X 32 matrix [figure 
5]. + + (li,23) (27,23) + (16,16)  (11,7) (27,7) + + Indices into a 32 X 32 table for h pixels. 
Spot is at (5/16,9/16) where lower left "+" is (0,0) and upper right "+" is (I,i). figure 5  (2) 
A three pixel per scanline table based on adjacent pixel overlap of fifty percent. A somewhat more expensive, 
and effective, table may be constructed using three dots per scanline. Using the same model for the vector 
but assuming horizontal overlap of the square pixels by fifty percent, we discover that three pixels 
overlap the vector on each scanline. The le~tmost and rightmost pixels are calculated as before but the 
middle plxel intensity is constant since the dot is entlrmly overlapped by the middle pixel [figure 
9b]. Ca) (b) ! ! i !   fliii!iiii!!!iiiiiiiii!i!iiii!iiiiililiiiil ! I subpixel position figure 
9 Both of the above sets of tables may be modified by modeling the pixels as horizontally varying sensitivity 
functions rather than constants. The proper intensities for the tables are then given by the integral 
of the sensitivity function over the extent of the overlap. Figure I0 compares all four possibilities 
allowed by the first tw~ table derivations and constant versus varying intensity functions (print quality 
may obscure subtle variations here). It should be noted that the more a vector slants to the diagonal, 
the greater the area it actually occupies along each scanllne. Therefore, for best results, an intensity 
correction based on the slope should be applied. Normally the lack of this correction won't be noticed. 
However, certain patterns such as concentric clrcles tend to emphasize the problem. A photograph of such 
a pattern in which the intensity response of the film emulsion used properly distorts the displayed image 
intensities can reveal the effect quite noticeably. Intensitles may be corrected through multiplication 
by a value from yet another table containing areadlfference factors for the various slopes. This table, 
accessed by the horizontal increment fxom one scanline to the next, should contain eqrt( I + (I/slope)**2) 
for each of the possible more vertical slopes. The reciprocal of the slope is, of course, Just the horizontal 
increment. Alternatively, if a multiply per pixel is too expensive, it has been suggested that several 
intensity tables corrected for different slope ranges could be used. Care must be given to the vector 
endpoints under some conditions. If smooth vectors are the only concern, then endpoints may be constrained 
to coincide ,with raster dot positions. However, if repetitive patterns are to be displayed, the endpoints 
must often be more exact to avoid unpleasant artifacts [figure 11]. The endpointsmay be most easily represented 
using the procedure for spot representation outlined above. The values for the last scanline may be calculated 
using only a part of the spot intensity matrix. However, if the display is to be used solely for drawing 
vectors, then a scale factor based on the subpixel position of the endpolnts with respect to the vertical 
dimension may be used. So far, vectors have been considered in isolation. However, virtually any diagram 
may have vectors which meet, intersect, overlap, or otherwise interact. When two different vectors affect 
the same pixel, a rule for determining the resultant intensity is necessary. The simplest rule is to 
overwrite the old intensity whenever a new pixel is calculated. However, when using grayscale, gaps will 
appear in the earlier vectors where they are overwritten by darker plxels from later vectors. Ideally, 
a calculation based on the areas occupied by the two vectors within a pixel should be used. However, 
this is impractical, at best, since the relationship of the two vectors is unknown (eg. do they overlap 
or abut?). One compromise is to sum intensities, always checking to ensure that the sum does not exceed 
the maximum allowable intensity. This works well enough except where vectors themselves are allowed to 
vary in intensity. Thus if two half-brlght vectors intersect, a noticeably bright spot occurs around 
the point of intersection. Finding the maximum intensity allowable in such a situation would be possible 
by searching for the maximum intensity in the immediate vicinity of the pixel in question. However, this 
hardly seems worth the trouble, in view of the expense of the search, the limited bandwidth of the image 
memory (which may not even have a readback capability) and the fact that precisely these same effects 
occur on calligraphic displays. GRAY LEVELS Generally, the more gray levels, the better the obtainable 
image quality. However, this trend ceases somewhere around six to eight bits depending on the quality 
of the display. Basically, the contrast ratio available on the display surface and the ability of the 
human e e to detect intensity variations determine t~e number of gray levels needed. Research in human 
vision indicates that humans can barely notice the difference between adjacent areas whose intensity 
differs by 2 per cent [11,12]. If the most intense spot the display can ~roduce is 25 times more intense 
than the dimmest (typical for CRTs [7,8.9]) then log z~ / log 1.02 or about 162 gray levels are needed. 
These levels should be distributed exponentially, each level representing a two percent increase over 
the previous level. Note that the dimmest spot that can be produced is dependent on such factors as the 
ambient light level and the reflectivity of the screen. Thus the environment of the display can affect 
the number of gray levels needed. However, the 2 p@r cent noticeable intensity difference assumes aisplay 
of images with large areas of only gradually varying intensity. Such images are very different from those 
under cpnsideration here. Ongoing experim@nts indicate that zewer bits of zntensity varlatlon are neeaea 
 for adequate quality in scan converted vectors. As indicated above, human ability to notice a difference 
in intensity is based on the log of intensity, and therefore the gray levels displayed should follow 
an exponential function. However, in order to properly re~resent spot positions as described above, it 
zs necessary that two dots displayed at half intensity deliver the same energy to the eye as a single 
dot at full intensity. This dictates a linear distribution of intensities. Since the latter concern is 
of greater importance here, linear intensities are preferred. COSTS AND CONCLUSIONS As microprocessors 
replace random logic in display terminals, it becomes more reasonable to increase the complexity oz the 
operations   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807360</article_id>
		<sort_key>6</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[A hidden-surface algorithm with anti-aliasing]]></title>
		<page_from>6</page_from>
		<page_to>11</page_to>
		<doi_number>10.1145/800248.807360</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807360</url>
		<abstract>
			<par><![CDATA[<p>In recent years we have gained understanding about aliasing in computer generated pictures and about methods for reducing the symptoms of aliasing. The chief symptoms are staircasing along edges and objects that pop on and off in time. The method for reducing these symptoms is to filter the image before sampling at the display resolution. One filter that is easy to understand and that works quite effectively is equivalent to integrating the visible intensities over the area that the pixel covers. There have been several implementations of this method - mostly unpublished - however most algorithms break down when the data for the pixel is complicated. Unfortunately, as the quality of displays and the complexity of pictures increase, the small errors that can occur in a single pixel become quite noticeable. A correct solution for this filter requires a hidden-surface algorithm at each pixel! If the data at the pixel is presented as a depth-ordered list of polygons then the average visible intensity can be found using a polygon clipper in a way similar to that employed by two known hidden-surface algorithms. All of the polygons in a pixel are clipped against some front unclipped edge into two lists of polygons. The algorithm is recursively entered with each new list and halts when the front polygon is clipped on all sides, thereby obscuring the polygons behind. The area weighted colors are then returned as the value to be added to the other pieces in the pixel.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Aliasing]]></kw>
			<kw><![CDATA[Clipping]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Filtering]]></kw>
			<kw><![CDATA[Hidden-surface removal]]></kw>
			<kw><![CDATA[Sampling]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Hidden line/surface removal</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P75663</person_id>
				<author_profile_id><![CDATA[81100160637]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Edwin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Catmull]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Lab, New York Institute of Technology, Old Westbury, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Catmull, Edwin, A subdivision algorithm for computer display of curved surfaces, Technical report UTEC-CSs-74-133 University of Utah, 1974]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359869</ref_obj_id>
				<ref_obj_pid>359863</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Crow, Frank, The aliasing problem in Computer-generated shaded images, CACM November 1977]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Myers, Allan J., An efficient visible surface program, Ohio State University, Computer Graphics Research Group, report to NSF, July 1975]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Shoup, R.G., Some quantization effects in digitally-generated pictures, Society for Information Display, 1973 proceedings.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I.E., Polygon sorting by subdivision: A solution to the hidden-surface problem, Unpublished manuscript, October 1973, Also public lecture at University of Utah 1973.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360802</ref_obj_id>
				<ref_obj_pid>360767</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I.E., and Hodgman, G.W., Reentrant polygon clipping, CACM January 1974.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I.E., Sproull, R.F., and Schumacker, R.A., A characterization of ten hidden-surface algorithms, ACM Computing Surveys, March 1974.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563895</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hamlin, Griffith Jr., and Gear, C.W., Rasterscan hidden surface algorithm techniques, Siggraph 1977 proceedings.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563896</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Weiler, K. and Atherton, P., Hidden surface removal using polygon area sorting, Siggraph 1977 proceedings.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A HIDDEN-SURFACE AIC43RITHM WITH ANTI-ALIASING Edwin Catmull C~mputer Graphics Lab New York Institute 
of Technology Old Westbury, New York 11568 ABSTRACT  In recent years we have gained understanding about 
aliasing in computer generated pictures and about methods for reducing the symptoms of aliasing. The 
chief symptoms are staircasing along edges and ob- jects that pop on and off in time. The method for 
reducing these symptoms is to filter the image be- fore sampling at the display resolution. One filter 
that is easy to understand and that works quite effectively is equivalent to integrating the visible 
intensities over the area that the pixel covers. There have been several implementations of this method 
- mostly unpublished - however most al- gorithms break downwhen the data for the pixel is cc~plicated. 
Unfortunately, as the quality of displays and the complexity of pictures increase, the small errors that 
can occur in a single pixel become quite noticeable. A correct solution for this filter requires a hidden-surface 
algori~ at each pixel! If the data at the pixel is presented as a depth-ordered list of polygons then 
the aver- age visible intensity can be found using a polygon clipper in a way similar to that employed 
by two known hidden-surface algorithms. All of the po- lygons in a pixel are clipped against some front 
unclipped edge into two lists of polygons. The al- gorithm is recursively entered with each new list 
and halts when the front polygon is clipped on all sides, thereby obscuring the polygonsbehind. The area 
weighted colors are then returned as the value to be added to the other pieces in the piyel. Key words: 
aliasing, clipping, computer graphics, filtering, hidden-surface removal, sampling. CR classification: 
8.2 INTRODUCTION  Aliasing is now being recognized as an impor- tant factor in analysis of image synthesizing 
algo- rithms. Attention has turned to anti-aliasing partly because of the need to refine pictures but 
mostly because the complexity of scenes has in- creased and with it the need to have pictures free of 
aliasing symptoms. A polygon hidden-surface algorithm is presented here with the focus of attention 
on anti-aliasing. One goal has been to produce a "correct" image for the anti-aliasing technique used. 
Speed, while im- portant, has played a secondary role. The techniques for hidden-surface elimination 
have improved in the last few years with the Suth- erland et al [7] paper providing coherence to the 
development. Several new algorithms have come along [3,8,9], each adding new insight into the ways that 
we can take advantage of coherence for some class of objects to facilitate display. Progress for anti-aliasing 
has been slower. In general pictures have not been extremely complicat- ed and the more obvious effects 
of aliasing, like jagged edges, could be fixed up with ad hoc tech- niques. Methods for anti-aliasing 
have been presented in [1,2,4]. Frank Crow's dissertation was devoted to the topic and the results were 
pub- lished in [2]. ANTI-ALIASING In general, the aliasing problem has been grossly underestimated 
in computer graphics. Its symptoms include: i. jagged edges 2. small objects popping on and off the 
screen in successive frames  3. moire patterns in rendering periodic images  4. fine detail breaking 
up.  The problem occurs chiefly because image space is sampled at discrete points corresponding to 
the pixels. There are several unpublished schemes for al- leviating the problem for simple cases -in 
partic- ular the symptom of jagged edges. They are unpub- lished because either they are incidental to 
some other algorithm or they are proprietary. Frank Crow has written about anti-aliasing in [2]. From 
his study we can extract some key ideas: i. The image space objects have sharpness and de- tail that 
cannot possibly be reproduced on a raster display. It is the attempt to sample that detail at discrete 
points in the image that causes the problem. 2. Point sanpling of an unfiltered object is never correct 
at any resolution. It is frequently thought that the symptoms of aliasing will not be noticeable if the 
resolution is high enough. Unfortunately, this is not true. 3. The image should be filtered to eliminate 
detail that is too fine. After filtering the image can be sampled. One simple filter is to integrate 
the visible intensities over the area of each pixel. In other words we take the average visible intensity 
over the square area represented by each pixel if the image is divided into a rectangular grid. This 
corresponds to convolving the continuous image with a two-dimensional Fourier (box) window. While there 
are better filters, this one is easy to understand and easier to implement analytically than other filters. 
The use of this filter will be called "area sampling." The difference between point sampling and area 
sampling is qualitative while the difference between area sampling and better filters is quanti- tative. 
The s~n of all intensities for a point sampled picture will vary as the object is translated, ie. for 
a fine picket fence the picture can be all white in one picture and all black in the next. The s~n of 
all intensities for an area sampled picture will be constant under translation because area sampling 
integrates all the intensi- ties. The difference between area sampling and better filters is quantitative 
since most reason- able filters would also integrate the intensities. The difference between filtered 
pictures is lowered as the resolution is increased since the sum of in- tensities in a local area will 
be the same or near- ly so. We cannot say this when comparing point sampling with sampling of filtered 
images at high resolution. A line that is much thinner than a pixel will appear dotted using point sampling 
and jagged using area sampling. As the resolution is increased, point sampling will still produce dots 
but area sampling will produce a nice line. In order to truly filter the image before sam- pling, an 
analytic continuous solution to both the hidden-surface problem and the filter convolution must be found. 
The magnitude of this problem grows dranatically with the order of the filter employed. There are several 
approaches or simplifications that one might take to implement filtering. This paper presents an approach 
that uses an analytic solution for area sampling. The problem then is to correctly integrate the intensities 
of all visible objects at a single pix- el. This seems to require some kind of hidden- surface algorithm 
at every pixel! As an exanple where some algorithms might fail see figure i. top view 'l 1 green S 
iblack ,/ ~ i , . blue j I black Figure 1  The correct integration would be 25% green, 25% black, 50% 
blue and no red. A simple minded algo- rithm that did not properly take into account what was hidden 
might distribute the intensities in- correctly and may even let some red show through. Unfortunately 
for computer graphics our eyes are quite capable of seeing errors like these even though they maybe only 
one millionth of the area of the screen. AN AIC43RITHM WITH ANTI-ALIASING In terms of the Sutherland 
et al criteria the algorithm presented here: i. sorts all polygons in y. 2. sorts all active polygons 
for a scanline with an x-bucketsort.  3. sorts in z by searching a z-list for each enter- ing edge. 
 4. does not use scanline-to-scanline coherence be- cause an x-bucket is used.  5. Uses point-to-point 
coherence since order in the z-list does not change.  While this order of techniques probably has not 
been used before, it is not new in any spectacular way. However, care has been taken to ensure that everything 
necessary for anti-aliasing is available and to a much higher precision than the display. The last step 
is to determine the intensity at the pixel given the z-list. An integrating algo- rithm is presented 
here that determines which pieces of polygons in the pixel are visible and then analytically calculates 
the average intensity. Finding which pieces of polygons in the pixel are visible is not unlike the original 
hidden- surface problem except that we have two simplifica- tions: i) we are only interested in the stun 
of the intensities of each piece weighted by its area and 2) the higher level hidden-surface algorithm 
may have already determined the order of the polygons. CLIPPING Clipping is an important part of the 
algorit/ml. The clipping algorithm used was originally intro- duced in [6]. A variation is presented 
here for completeness. When a polygon is clipped against a line it is divided into two polygons. See 
figure 2. After clipping ; cl ipl ine Figure 2  We can determine if a point is on side A or side B 
by inserting the coordinates of the point into the equation of the line: d = ax + by + c.  If d is 
less than zero then the point is on side A, otherwise it is on side B. We are going to gen- erate an 
A and a B polygon. The Clipping Algorithm I. A polygon is a list of points PI, P2,...Pn.  II. Call 
Pn the previous point. Determine which side it is on. III. Loop through each point, called the current 
point. A. If current point on A side then: I. If previous point on A side then: Copy current point 
to A polygon. 2. If previous point on B side then:  Calculate intersection of line with edge formed 
from current point and previous point. Copy calculated point to A and B po- lygons. Copy current point 
to A polygon. B. If current point on B side then: i. If previous point on B side then: Copy current 
point to B polygon. 2. If previous point on A side then:  Calculate intersection of line with edge 
formed from current point and previous point. Copy calculated point to A and B po- lygons. Copy current 
point to B polygon. C. Call the current point the previous point. FINDING VISIBLE SURFACES  The image 
space polygons handled by this algo- rithm are of the following form: i. There is a list of vertices 
on the left and the right. 2. The first vertex of each list is the highest in Y.  3. Each succeeding 
vertex is lower in y than the preceding one.  4. The edge formed by the left vertices does not  cross 
the edge of the right. This form of polygon definition (see figure 3) is optimized for polygons with 
large numbers of edges. See figure 8 where the colored areas and the black line are both specified with 
polygons. The black lines are long thin polygons. left t i ist Figure 3 All other polygons in various 
stages of the al- gorithm are in the more conventional form of a list of vertices. It is ass~ed that 
an edge connects the first and last vertex. This form is necessary for the clipping algorithm presented 
above. The purpose of the first level of the algorit|~n is to find all polygons that overlap a particular 
scanline and then to clip away everything that doesn't overlap it. Since the scanline has the width of 
one pixel we are left with a list of very narrow horizontal polygons. The next step is to find which 
of those narrow polygons on the scanline overlap a particular pixel and then clip away those not over 
the pixel. If the closest polygon completely covers the pixel then its intensity value can be put into 
an array for the scanline, otherwise the list of polygons needs to be passed to the integrater. Of course 
one objective is to do the above very quickly. To do so requires that we take advantage of coherence 
and sorting techniques to quickly reduce the n~nber of items for consideration at each step. The algorithm 
proceeds sequentially to each scanline beginning at the highest. At each scan- line there is a list of 
active polygons that over- lap that scanline. Note that a scanline is really a strip with width. At each 
scanline a horizontal strip is clipped off of each active polygon leaving only that port of the polygon 
which lies below the scanline. (See figure 4.) ~-hor izontal polyqon scan- i ine  roainin polygon 
 Figure 4  Similarly at each pixel, the horizontal strip is clipped at the right edge of the pixel to 
determine the polygons within the square pixel area. For efficiency it is worth noting that the mid- 
dle of most horizontal polygons completely covers the respective pixels. It would be wasteful to clip 
at each pixel in that case. We treat the mid- dle as a solid run or segment and only need to count the 
pixels that it covers (see figure 5). The ends can be clipped off at the boundary of a solid segment 
and treated as indicated above. ' The depth ordering is maintained with a sorted z-list. The first item 
in the list is the closest. When a new edge is encountered in the x-bucket it is entered into the z-list 
in order. If intersec- tions are allowed, each item in the z-list must be checked against the incoming 
item over its full ex- tent to check for possible intersection which would require splitting a polygon. 
 The Hidden-surface Al~orithm I. Sort all polygons on highest y value. II. Initialize active polygon 
list to be empty. III. Repeat for each scanline:  A. Add polygons from y-list that enter on this scanline 
to active polygon list. B. Initialize the x-bucket to be empty and the scanline array to background. 
 C. Loop through each polygon in active  po- lygon list  i. Clip off of each polygon the piece that 
lies on the current scanline. See figure 5. 2. Replace polygon in list with polygon that has piece clipped 
off.  3. If there are pixels under the piece that are completely covered, then for efficiency reasons 
we can break the piece into three pieces: the center solid piece and two polygons clipped off at the 
ends at the pixel boun- daries. The two end polygons are called irregular pieces.  4. The pieces are 
sorted into the x- bucket according to the leftmost pixel covered.  D. Initialize the z-list to be 
empty. E. Repeat for each pixel across the scanline:  i. Sort every entry at the current x po- sition 
of the x-bucket into the z- list. 2. Evaluate the z-list if not empty: a. If a solid piece, get its 
color  else if an irregular piece is in front of a solid piece then find the area of the irregular piece 
over the pixel to weight the two colors else call the pixel integrater to get color b. Write the color 
into scanline array. THE PIXEL INTEGRATER  Given a list of polygons in the z-list, it is necessary 
to find the area of each visible polygon piece in order to determine its contribution to the pixel intensity. 
The polygons in the z-list are in sorted z-order with the first polygon being the closest. One of the 
key ideas of this algorithm is that the list of polygons can be divided into two lists with an edge 
of a polygon being used as the divid- ing line. A generalization of this idea based on using planes for 
dividing polygon lists is due to Ivan Sutherland [5] and in fact is part of a com- plete hidden-surface 
algorithm that he invented. This technique was used in another hidden-surface algorithm subsequently 
developed at Cornell[9]. Since the polygons are already in sorted order, we pick an edge of the first 
polygon to use as the dividing line. If this algorithm is recursively applied to both of the resulting 
lists of polygons then very shortly the front polygon of a list will cover all polygons behind it since 
everything else will have been clipped away. The area of the front polygon can then be found to weight 
the intensity. The sum of the weighted intensities from all the lists gives the final average intensity. 
 irregular middle irregular piece piece piece points~ pol~:: 1 Figure 5 For this algorithm we make 
the following obser- vations: i. Since z order is implied in the list, there is no need for any z calculations. 
We may there- fore think of the polygons as two-dimensional; they will be clil~ped against a line and 
not a vertical plane. 2. A pixel pol~gon for this algorithm is a list of vertices with implied connection 
of the first and last vertices.  3. A vertex consists of x, y, and clipflag, where clipflag is used 
to indicate whether or not the edge connecting that vertex and the next one has been clipped.  4. A 
pixel polygon that completely covers a pixel will be called a "solid polygon."  To prepare the z-list 
for the algorithm: i. Each polygon will be transferred to a pixel po- lygon list in order until a solid 
polygon is reached. If there is no solid polygon, a d~may solid polygon is added with the background 
as its color. 2. All polygons are clipped to the pixel boun- daries.  3. All edges that lie concurrent 
with the pixel boundaries are marked as clipped, ie. the last polygon should cover the pixel and all 
four edges are marked as clipped.   The Basic AlgoritTm for Integratin~ ACKNOWLEDGMENT i. Consider 
the first polygon in the list (which is also the closest). 2. Look for the first unclipped edge. If 
there is no unclipped edge or there is only one polygon in the list then return the color of the polygon 
weighted by its area.  3. Clip all polygons in the list against the edge and put them in two lists, 
one for each side of the edge. Set clipflag for each edge that lies along the clipping line as it is 
clipped.  4. Reenter this algorithm for each of the two lists.  5. C/]nbine and return the two results. 
  IMPLEMENTATION The hidden-surface algorithm and pixel in- tegrater were implemented by the author 
at the Com- puter Graphics Iab at the New York Institute of Technology. The polygons to be rendered were 
flat colored with many edges to satisfy the needs of cartoon animation. These pictures are character- 
ized by a large nt~nber of pixels that have more than two polygons. See figure 6. The hashed po- lygon 
C covers the boundary between polygons A and B. The pixel pointed at by P has four polygons in it, three 
of which are visible. Boundary between /~f'polygonsB A and B / j ~7~thin polygon J I ~,pixel / 
~thin polygon which covers boundary Figure 6  The ability to call the pixel integrater is under user 
control. The user can request jagged edges with the result that the progrem runs approx- imately three 
times faster for complicated pic- tures. Full anti-aliasing is only required for quality recording. Figure 
7 shows a picture with aliasing. We have been able to use and evaluate the algo- rithm. See figure 8,9, 
and I0 which were made at 512x512 resolution with 8 bits each for red, green and blue. Movies generated 
using this algorithm have not shown any aliasing symptoms for the class of images created. This has made 
the effort worthwhile. The Computer Graphics Lab was conceived and spon- sored by Dr. Alexander Schure, 
President of New York Institute of Technology. Lance Williams pro- vided critical reading of the first 
draft. REFERENCES I. Catmull, Edwin, A subdivision algorithm for computer display of curved surfaces, 
Technical report UTEC-CSs-74-133 University of Utah, 1974 2. Crow, Frank, The aliasing problem in Computer- 
generated~haded images, CACM November 1977  3. Myers, Allan J., An efficient visible surface program, 
Ohio State University, Computer Graphics Research Group, report to NSF, July 1975  4. Shoup, R.G., Some 
quantization effects in digitally-generated pictures, Society for In- formation Display, 1973 proceedings. 
 5. Sutherland, I.E., Polygon sorting by subdivi- sion: A solution to the hidden-surface prob- lem, 
Unpublished manuscript, October 1973, Also public lecture at University of Utah 1973.  6. Sutherland, 
I.E., and Hodgman, G.W., Reentrant polygon clipping, CACM January 1974.  7. Sutherland, I.E., Sproull, 
R.F., and SchLm~acker, R.A., A characterization of ten hidden-surface algorithms, ACM Computing Surveys, 
March 1974.  8. H~nlin, Griffith Jr., and Gear, C.W., Raster- scan hidden surface algorithm techniques, 
Sig- graph 1977 proceedings.  9. Weiler, K. and Atherton, P., Hidden surface re- moval using polygon 
area sorting, Siggraph 1977 proceedings.  I0  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807361</article_id>
		<sort_key>12</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Color gamut transform pairs]]></title>
		<page_from>12</page_from>
		<page_to>19</page_to>
		<doi_number>10.1145/800248.807361</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807361</url>
		<abstract>
			<par><![CDATA[<p>Digital control of color television monitors&#8212;in particular, via frame buffers&#8212;has added precise control of a large subset of human colorspace to the capabilities of computer graphics. This subset is the gamut of colors spanned by the red, green, and blue (RGB) electron guns exciting their respective phosphors. It is called the <underline>RGB monitor gamut</underline>. Full-blown color theory is a quite complex subject involving physics, psychology, and physiology, but restriction to the RGB monitor gamut simplifies matters substantially. It is linear, for example, and admits to familiar spatial representations. This paper presents a set of alternative models of the RGB monitor gamut based on the perceptual variables hue (H), saturation (S), and value (V) or brightness (L). Algorithms for transforming between these models are derived. Particular emphasis is placed on an RGB to HSV non-trigonometric pair of transforms which have been used successfully for about four years in frame buffer painting programs. These are fast, accurate, and adequate in many applications. Computationally more difficult transform pairs are sometimes necessary, however. Guidelines for choosing among the models are provided. Psychophysical corrections are described within the context of the definitions established by the NTSC (National Television Standards Committee).</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Brightness]]></kw>
			<kw><![CDATA[Color]]></kw>
			<kw><![CDATA[Color transform]]></kw>
			<kw><![CDATA[Gamut]]></kw>
			<kw><![CDATA[Hue]]></kw>
			<kw><![CDATA[Luminance]]></kw>
			<kw><![CDATA[NTSC]]></kw>
			<kw><![CDATA[Saturation]]></kw>
			<kw><![CDATA[Value]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Paint systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P15765</person_id>
				<author_profile_id><![CDATA[81100078209]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alvy]]></first_name>
				<middle_name><![CDATA[Ray]]></middle_name>
				<last_name><![CDATA[Smith]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Lab, New York Institute of Technology, Old Westbury, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Faber Birren. Creative Color. Van Nostrand Reinhold, New York, 1961, p. 12.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Deane B. Judd and Gunter Wyszecki. Color in Business, Science, and Industry. (3rd Ed.), John Wiley Wiley Sons, New York, 1975.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Proceedings of the I.R.E., 42 (Jan. 1954) {special NTSC issue}.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Jay M. Tenenbaum, Thomas D. Garvey, Stephen Wyl, Helen C. Wolf, and David Nitzan. An interactive facility for scene analysis research. Technical Note 87, SRI Project 1187, Stanford Research Institute, Menlo Park, CA, (Jan. 1974), pp. 34-39.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 COLOR GAMUT TRANSFORM PAIRS Alvy Ray Smith Computer Graphics Lab New York Institute of Technology Old 
Westbury, NY 11568 ABSTRACT Digital control of color television monitors --in particular, via frame 
buffers -- has added precise control of a large subset of human colorspace to the capabilities of computer 
graphics. This subset is the gamut of colors spanned by the red, green, and blue (RGB) electron gunsexciting 
their respec- tive phosphors. It is called the RGB monitor ganut. Full-blown color theory is a quite 
complex subject involving physics, psychology, and physiol- ogy, but restriction to the RGBmonitor gamut 
sim- plifies matters substantially. It is linear, for example, and admits to familiar spatial representa- 
tions. This paper presents a set of alternative models of the RGBmonitor gamut based on the per- ceptual 
variables hue (H), saturation (S), and value (V) or brightness (L). Algorithms for transforming between 
these models are derived. Particular emphasis is placed on an RGB to HSVnon- trigonometric pair of transforms 
which have been used successfully for about four years in frame buffer painting prograns. These are fast, 
accu- rate, and adequate in many applications. Computa- tionally more difficult transform pairs are some- 
times necessary, however. Guidelines for choosing among the models are provided. Psychophysical corrections 
are described within the context of the definitions established by the NTSC (National Television Standards 
Ccranittee). Key words: color, gamut, hue, saturation, value, brightness, laminance, NTSC, color transform. 
 CR categories: 8.2, 3.41, 3.17. INTRODUCTION A color television monitor with independent video inputs 
to each of its red, green, and blue guns is an RGBmonitor. The range of colors produced by the guns of 
an RGBmonitor is its gamut. In com- puter graphics, the guns are digitally controlled, the full analog 
range of each gun being approximat- ed by n=2 m distinct and equally spaced values. For m~8, most hi, 
hans cannot perceive the difference between analog and digital control, the discrete and continuous become 
one perceptually. For this reason, we shall use the term ganut to refer to both the continuous gamut 
defined above and the di- gital approximation to it which is the primary con- cern of this paper. We 
shall assume that an RGB monitor is a linear device. But the light intensity emitted by the cathode 
ray tube in a television monitor is a non- linear function of its driving voltages. Hence the assamption 
of linearity implies the existence of a black box between the ntmlbers used for digital in- put and the 
nt~bers actually used to digitally con- trol the input voltages. This black box cempen- sates for the 
nonlinearity of the cathode ray tube. It can be implemented as a simple lookup table and is called a 
gamaa-correction , or compensation, table. Hence an RGB monitor lS assumed to contain a ga~na-correction 
table (perhaps in software) for each gun. It is this combination which is thought of as a linear device. 
 Since the three guns of an RGB monitor can be varied independently and must have nonnegative in- put 
less than a given maximt~n rating, its gamut can be represented by a cube (Fig. i). We shall refer to 
this "natural" gamut model as the (RGB) colorcube. In the colorcube model, a color is a vector in a 
 (finite) 3-dimensional space where the dimensions R, G, and B are called the primaries. The coordi- 
nate system is a rectangular one. It is a simple space in which familiar linear algebra operations hold. 
For example, Plate 1 shows the result of ap- plying the following simple linear transform to the RGB 
colorcube of Fig. i: = .21 -.52 .31 30 .59 .i Thus the new set of primaries I, Q, and Y also form 
a linear space. They are, in fact, the transmission primaries recormnended by the NTSC (National Televl- 
sion Standards Co~nittee) in 1953 (3) as a basis for generating the broadcast color television sig- nal 
in the U.S. The Y dimension, called it~ninance, measures the brightness perceived by a h~nan watch- ing 
a typical home television receiver (and is, in fact, the only signal received by a black-and-white set). 
That is, IQY space can be considered a psychophysical adjustment of ~ space which takes into account 
both the properties of the RGB phos- phors and the perceptions of the so-called standard observer (2). 
 In this paper we explore two gamut models, both with polar coordinate systems. In some situations, such 
as color mixing, these models are more intui- tively satisfying or more convenient to an artist  12 
 than the colorcube. Hence we derive algorithms for transforming between these alternative models and 
the colorcube. A transform pair consists of the algorithm for transforming from the colorcube to one 
of the alternatives and the inverse algorithm for transforming back to the colorcube. We also indicate 
when it is advantageous to use one or the other of the models instead of the colorcube. In particular, 
the NTSC space will be a special case of only one of them. The first of the two new models, the hexcone 
model, is intended to capture the co~on notions of hue, saturation, and value (HSV) as three dimensions--~r 
describing a color. Briefly, hue is the dimension with points on it normally called red, yellow, blue-green, 
etc. Saturation measures the departure of a hue from achromatic, i.e., from white or gray. Value measure 
the departure of a hue from black, the color of zero energy. These terms, defined more carefully in a 
following section, are meant to capture the artistic ideas of hue, tint, shade, and tone illustrated 
in Plate 2. The other model, the triangle model, has the close- ly related dimensions hue, saturation, 
and brightness (HSL). (Alternatl-i~-enam~s for bright- ness are lightness and intensity. The distinction 
is sometimes made that brightness refers to self- l~ninous objects and lightness to non-self-lt~ninous 
objects. We maintain this distinction here but use the s3~nbol L to avoid conflict with B for blue. An 
alternative for saturation is chroma although the distinction is sometimes made that saturation is a 
relative measure of color "purity", or non- whiteness, while chroma is absolute.) Hue and sa- turation 
are as for the hexcone model, but bright- ness measures the energy in a color instead of its non-blackness. 
We might define it by L u = ( R + G + B )/3, the denominator serving merely to normalize the brightness 
into the range [0,i]. The definition we shall introduce in a later section is much more general than 
this, however. It includes, for exam- ple, L n = Y = .30*R + .59"G + .II*B. which is NTSC luminance. 
So the triangle model is actually a class of models. The two running exan- ples of it in this paper will 
correspond to bright- ness definitions Lu, the unbiased case, and Ln, the NTSC case. The distinction 
between value and brightness is im- portant. It is illustrated by this example: Red, white, and yellow 
all have the same value (no blackness), but red has one third the brightness of white (using definition 
L..), and one half the brightness of yellow. T~e principal distinction between the two is the manner 
in which the pure (fully saturated) hues are treated. There is a plane containing all the pure hues 
in HSV space, but not in HSL space. Hence V would be used where the pure hues are to be given equal weight--e.g, 
in a painting program. L would be used where colors must be distinguished by their brightness--e.g., 
in choosing colors for an animated cartoon such that the colors are distinguishable even on a black- 
and-white television receiver. BACKGROUND AND EXPERIENCE  Transform pairs based on the hexcone model 
have been used successfully in painting prograns at Xerox PARC (Palo Alto Research Center) for four years 
and NYIT (New York Institute of Technology) for three years. At both of these computer graph- ics installations, 
digital control of an RGB moni- tor is exercised via a frane buffer (or picture memory), a piece of memory 
large enough to hold one video frame in digital form. The frame buffer con- tents can be viewed on an 
RGB monitor thirty times a second - i.e., at video rate. The triangle model is a generalization of a 
model derived at SRI (Stanford Research Institute) (4). In that reference, a transform from RGB to HSL 
for what we call the unbiased case is derived. The in- verse transform from HSL to RGB is derived here. 
 THE HEXCONE MODEL  A person using a computer to control an RGB monitor could, by varying each of the 
primaries, mix any c~lor he desired (if, of course, it were one of the n colors in the ganut). The reader 
can try this mixing technique by mentally varying R, G, and B to obtain, say, pink or brown. It is not 
unusual to have difficulty. Following is an alternative way, mimicing the way an artist mixes paints 
on his palette: He chooses a pure hue, or pigment, and lightens it to a tint of that hue by adding white, 
or darkens it to a shade of that hue by adding black, or in general obtains a tone of that hue by adding 
some mixture of white and black, a gray (i). Plate 2 stmmarizes these terms. The hexcone model is an 
attempt to transform the RGB colorcube dimensions into a set of dimensions modeling the artist's method 
of mixing. These are called hue, saturation, and value (HSV). Varying H corresponds to traversing the 
color circle. De- creasing S (desaturation) corresponds to increasing whiteness, and decreasing V (devaluation) 
corresponds to increasing blackness. Following is a simple interpretation of these dimensions. Then we 
state the RGB to HSV color transform pair of al- gorit~ns and proceed to derive them. The tion contains 
a detailed description geometry of the hexcone model. deriva-of the COLOR BAR INTERPRETATION OF HSV 
A color is represented in Plate 4 by three bars. It is obtained by mixing R, G, and G in the propor- 
tions implied by the lengths of the three bars. It is convenient to understand HSV in terms of this 
representation. V is simply the height of the tal- lest bar. If X is the height of the ~nallest bar, 
then (X,X,X) is the gray which is desaturating the color. Subtracting this "dc-level" of gray from the 
color, leaves the hue information as a propor- tional mix of two primaries. This leads us to the observation 
that a color is a mixture of at most three primaries, a hue of at most two primaries, and a primary, 
of course, of one primary. RGB TO HSV ALGORITHM (HEXCONE MODEL)  Given: R, G, and B, each on domain 
[0,i]. Desired: The equivalent H, ~, and V, each on range 13 [0,1]. i) V := max(R,G,B) ; 2) Let 
X := min(R,G,B) ; 3) S := (V-X)/V; if S=0 return; 4) Let r := (V-R)/(V-X); g :-- (V-G)/(V-X); b := 
(V-B)/(V-X) ; 5) If R=-V then H:=(if G=X then 5+b else l-g); If G=V then H:=(if B=X then l+r else 3-b); 
else H:=(if R=X then 3+g else 5-r);  6) H := H/6; Remarks: i) H=0 is taken to be red (i.e., G=B and 
R>B) by convention. 2) Special care must be exer- cised at the singular points S=0 -i.e., where R=G=B, 
the gray, or achromatic, axis of the hex- cone. Hue is not defined along this axis. Often the hue is 
simply i~material at such a gray_~_~.ray int A practice which frequently succeeds is to deflne H at 
a singularity to be what it was as a result of the last call to the transform. Smooth traversals of the 
gamut tend to leave H at a reasonable defin- ition using this technique. HSV TO RGB ALGORITHM (HEXCONE 
MODEL) Given: H, S, and V, each on domain [0,i]. Desired: The equivalent R, G, and B, each on range 
[0,1]. i) H := 6*H; 2) Let I := floor(H); F := H -I; 3) Let M := V*(I-S) ; N := V*(I-(S*F)) ; K := 
V*(I-(S*(I-F))) ; 4) Switch on I into case 0: (R,G,B) := (V,K,M); case i: (R,G,B) := (N,V,M); case 2: 
(R,G,B) := (M,V,K); case 3: (R,G,B) := (M,N,V); case 4: (R,G,B) := (K,M,V); case 5: (R,G,B) := (V,M,N); 
 Remarks: i) Floor(x) is the integer just less than or equal x. 2) Only one case is executed in the switch 
statement. 3) The expression (R,G,B) := (X,Y,Z) abbreviates R:=X; G:=Y; B:=Z. DERIVATION OF THE HEXCONE 
MODEL If the colorcube is projected along its main diago- nal (the gray axis) onto a plane perpendicular 
to the diagonal, a hexagonal disk (a hexagon and its interior) results (Plate 3). The interior points 
are those colors one would see looking at the colorcube along its gray axis in the direction from white 
to black. For each value of gray, there is an associated subcube of the colorcube (Fig. i). Corresponding 
to each subcube -i.e., to each gray value -is a projection as before. As the gray level changes from 
0 (black) to 1 (white), one moves from one hexagonal disk to the next. Each  disk is larger than the 
preceding one, with the disk for black being a point. This is the hexcone. Each disk can be thought of 
as the three "bright- est" faces of the associated subcube projected onto a plane. The projection is 
scaled so that the length of a side of the colorcube in the projection equals the length of a side in 
the solid. Notice that by specifying V, one has specified that at least one of R, G, or B equals V, and 
none is larger. Hence V = max(R,G,B). Consider any one disk in the hexcone (selected by varying V). 
H and S must specify a point in this disk. In the hexcone model, H is taken to be the angle and S is 
taken to be the length of a vector centered on the gray point of the disk. In Plate 3 the loci of constant 
S are shown for one disk. They are hexagons. So when we speak of the angle H, we imply a proportional 
length along these hexago- nal loci, not along circles. S is assumed to be a relative length, relative 
to the longest possible radius at the given angle. S varies from 0 to 1 in each disk. S=0 implies the 
color is gray value V for disk V (centered at gray value V) regardless of hue. S=I implies a color lying 
on the bounding hexagon of disk V. Notice that S=I implies at least one of R, G, or B is 0. For disk 
i, this bounding hexagon may be identified with the color circle. As H is varied from 0 to 1 around this 
hexagon (saturation locus), the two of R, G, and B which are nonzero are specified (and one of these, 
of course, is I). Thus V determines one primary, and the vector of length S and angle H determines the 
other two. This is how we compute saturation from RGB: Consider the hexagonal disk in Fig. 2 which is 
di- vided into three sectors which are subdivided by the dashed lines to form six sextants. Let [IJ] 
be the length of the vector from arbitrary point I to arbitrary point J in this figure. Then S for the 
color at point P is s = IWPI/IWP'l = IWDI/IWYI = (IWYI-IDYI)/IwYI. For disk V each side of the hexagon 
has length V; hence [WY[ = V. For P in the sector shown (-60<H<60 degrees), R = V. The sextant in this 
 sector into which P falls depends on which of the other two primaries is snaller. In this example, 
B is the smallest component so P falls in the sextant for which 0<H<60. Notice that B = IDYI and G 
= V-IPDI in this sextant. So IDYI = min(R,G,B) in this sextant, and S = (V-min(R,G,B))/V. Similar 
argt~nents for each of the other five sex- tants show this to be a general relationship for all H. The 
relationship for H can be derived from the same figure. For P in the sextant shown, H (on range [0-i] 
) is H=IAPI/IADI= ( IEPI-I EAI )/IADI=( I EPI-IAFI )/[ADI. But G = IEPI and B = [AF] and lAB] = [WD[ 
implies \, H = (G-min (R,G,B)) / (V-min (R,G,B))  14 in this sextant. The exact expression for H is 
dependent on the sextant but can be derived simi- larly. The results are summarized in the statement 
of the algorithm above. Fig. 2 can also be used to derive the inverse of the transform derived above. 
For P in the sextant shown R > G and R > B hence R = V. S in this sex- tant is S= I WPI / IWP ' I=IWDI/IWYI 
=(IWYI- I DYI )/IWYI= (V-B)/V. Thus B = V*(1-S).  H (on domain [0-i]) in this sextant is H=IAPI/IADI=(IEPI-IEAI 
)/(IEDI-IEAI )= (G-B)/(V-B). Substituting the expression just derived for B yields G = V*(I-S*(I-H)). 
 Similar derivations can be made in each sextant to obtain the results in the algorithm statement above. 
 THE TRIANGLE MODEL  Consider the normalization of a given color (R,G,B) defined by r = WR*R/L; g = 
WG*G/L; b = WB*B/L  where L = WR*R +WG*G +WB*B  is the generalized brightness and weights  wR>o; 
w 0;  and w R + w G + w B = i.  All such normalized colors fall in the plane r+g+b=l  and are bounded 
by the equilateral triangle shown in Fig. 3. The gray points, R=G=B, all map into W = (WR,WG,WB).  
For example, if w R = wc = w R = 1/3, the gray point is (i/3,1/3,1/3)~ ThYs special case, as mentioned 
earlier, is called the unbiased case (Plate 5). Another case of speciall--i-n-~est mentioned earlier 
is the NTSC case for which w~ = .30, ~G = .59, w~ = .ii. H--e~e--~= L = Y is t~e normalization factor 
 n . .  in the NTSC case. The gray polnt (.30,.59,.11) is "biased" away from the centroid of the equilateral 
 triangle (Fig. 5). The triangle so obtained is an example of what is known in color theory as a chromaticity 
diagrsm (2). The most fanous such diagram is that from 1931 of the CIE (Cen~nission Internationale de 
 l'Eclairage), shown in Fig. 4. It includes the en- tire hi,nan color ganut. We include it to cast the 
current paper in appropriate perspective: The ganuts of two RGBmonitors are shown as triangular subsets. 
The larger is the 1953 NTSC recommended ganut, and the smaller that of an actual modern gamut (for a 
Barco monitor at NYIT). RGB TO HSL AIC43RITHM (TRIANGLE MODEL)  Given: R, G, and B, each on domain 
[0,i]. Desired: The equivalent H, S, and L, each on range [0,i]. i) L := WR*R +WG*G + WB*B; 2) Let 
r' := R/L; g' := G/L; b' := B/L; Let r := wR*r' ; g := wG*g'; b := WB*b'; Let rr := r-wR; gg := g-wG; 
bb := b-WB; 3) S := 1 - min(r',g',b'); if S=0 return; 4) Let k 0 := sqrt(rr 2 + gg2 + bb2); Let w~ := 
l-WR; Let d := w~*rr - wG*gg - WB*bb; Let k I := sqrt(w~2+ WG2 + WB2) ;  Let x := d/(k0*kl); 5) H := 
90 - arctan(x/sqrt(l-x2)) degrees; 6) If b' > g' then H := 360 - H; 7) H := H/360; Remar ks: As in the 
hexcone model, H=0 at red by convention, and the gray axis is a locus of singu- larities in H. HSL TO 
RGB AIC43RITI~4 (TRIANGLE MODEL) Given: H, S, and L, each on domain [0,i]. Desired: The equivalent R, 
G, and B, each on range [0,i] . i) H := H'360; 2) Compute angles a 0 := A(PRWPG) and a I := A(PGWPB) 
(in degrees); 3) Compute angles A 0 :-- A(RRWQR) , A 1 := A(RGWQG), and  A 2 := A(%w%); 4) If 0_<H_<a 
0 then begin H := H-A0; b := Ws*(1-S) ; r := WR+WB*S*cos(H)/cos(60-H ) ; 15 g := l-(r+b) ; end else 
if a0~H_<(a0+al) then beg in H :-- H-a0-AI; r :-- WR*(1-S) ; g := WG+WR*S*cos (H)/cos (60-H) ; b 
:= l-(r+g) ; end else begin H := H-a0-al-A2; g := WG*(I-S) ; b := WB+WG*S*cos(H)/cos(60-H); r := 
l-(g+b); end 5) R := r/wR; G := g/wG; B := b/WB;  Remarks: i) For ease of presentation, it is as- stoned 
that the user has at his disposal a procedure TRIANGLE which computes, for a given set of weights, all 
constant angles and lengths in the equilateral triangle associated with the triangle model (Fig. 5). 
See derivation below. 2) As op- posed to the hexcone model, it is possible to transform HSL on the given 
domains into unrealiz- able RGB values (R, G, or B > i) because the g~nut is finite. For example, this 
is the case if L=I and S>0. It is not difficult to derive, although we do not do so here, a set of realizability 
conditions for computing when this will happen. EXAMPLES The unbiased case: w R = w G = w B = 1/3 
a 0 = a I = 120 degrees A 0 = A 1 = A 2 = 0 degrees The NTSC case: w R = .30; w G = .59; w B = .ii 
 a 0 = 156.58; a I = 115.68 degrees A 0 = -21.60; A 1 = 14.98; A 2 = 10.65 degrees DERIVATION OF THE 
TRIANGLE MODEL  As mentioned above, there is assuaed to be a pro- cedure TRIANGLE with which any constant 
concerning the triangle in Fig. 5 can be computed, given weights w_,w~, and w_. Two types of constants 
are c~puted b9 ~IANGLE~ angles and lengths. For 3-dimensional points X, Y, and Z, I XYI represents the 
length of the vector from X to Y, as before. A(XYZ) represents the angle at Y between vector YX and vector 
YZ. The following observations about the geometry of the triangle are useful in the derivation: (i) 
The lines PiQi, i=R,G,B, all intersect at W by construction.  (2) The line PwQR is the locus of points 
(r',g',b') for which g'=b ~'.  (3) Any point in the planar region bounded by tri- angle PwQ~pc has g'>b'. 
Any point in PnQ~P~ has b'>g'. HeHc~ PRQ R separates the g'>b' regYo~ ~from the g'<b' reglO~. Similarly, 
P~O^ separates the b'>r' region from the r'<b' r~g~fon, and PBQB separates the r'>g' region from the 
g'>r' region.  (4) For i=R, G, or B, IWQil/IPiQil = w i and IWPil/IPiQil = l-w i.  (5) The RG sector 
is the region bounded by WPRP G- The GB--sector is the region bounded by WP_PB, and the BR s~--~ is the 
region bounded by WPBP ~-  As in the hexcone model, H and S of an arbitrary color are definedwith respect 
to a vector from the gray point W. Let the normalized color be represented by point P. Then H is the 
angle A(P~WP), and S is the ratio IWPI/IWP'I, where WP' is the intersection of the extension of WPwith 
the nearest side of the triangle (PRPG in the case shown in Figs. 7 and 9). Consider Fig. 3 for computing 
S in terms of R, G, and B. T is the projection of W onto the rg plane parallel the b axis. Q is the projection 
of P onto WTparallel the rg plane. S=IWPI/IWP' I=I~I/IWTI=( IWTI-IQTI )/IWTI. But IWTI = w B and IQTI 
= b in the sector shown; hence S = l-b'. But b'=min(r',g',b ') in the RG sector. In fact, an argument 
similar to that above for P in each of the other two sectors shows the relationship S = i - min(r',g',b') 
 to be true in general. Fig. 5 will be used to compute H. For 0<H<I80 de- grees WPR'WP = IWPRI*IWPI*COS(H 
) where WPR'WP is the dot product. But IWPI = k , I WPRI = k], and WP_'WP = d as defined in the alg~ 
rit~ stat~nent. L~t x = d/(k0*kl) Then H = arccos(x). If b'>g', then H must be greater than 180 degrees. 
So in this case H is re- placed by 360-H to remain within the range of prin- cipal values. Since arccos(x) 
= 90 - arctan(x/sqrt(l-x2)) for principal values, the desired expression for H is derived. Derivation 
of the inverse transform proceeds using Fig. 5:  16 In the RG sector, we have seen that S=l-b'. Thus 
 b=WB*(l-S ) . Similarly, in the GB and BR sectors, r and g are given as stated in the algorithm above. 
 To determine another of the remaining two primaries in each sector, notice that for P in the RB sector, 
 r/I=(IWQRI*CoS(A0)+IWPI*cos(A0+H))/(IPRQRI*CoS(A0)) r = w R + k0*IWPI*cos(A0-H), where kn=i/(JPpQpJ*cos(An)). 
The only unknown on the right is JWP~ which Is computed as follows: S = (IWPI*cos(B0-H)) / IWRBI, where 
B0=A(PRWRB). Hence r = WR+WB*S*cos(A0+H)/cos(60-(A0+H)) , since A0+B0=60 degrees and k0/IWRBI = WB/l 
= w B Similarly, g and b can be derived to be as in the algoritha statement for the GB and BR sectors, 
respectively. Finally, since r+g+b=l, the r~maining primary in each sector is easily obtained. CONCLUSIONS 
 The transform pair derived from the hexcone model (RGB to HSV) require no trigonometric or other ex- 
pensive functions. Hence they are quite fast, a fact of considerable importance when they are to be performed 
at the pixel level in a frame buffer. For example, in the RGB paint program at NYIT there is a type of 
painting called tint paint. Here the user selects a color to paint with. Its tint (H and S) is extracted 
by use of the RGB to HSV transform. Now painting in a frane buffer can be thought of as overwriting a 
small 2-dimensional subset of a large 2-dimensional array, the frane buffer, where the position of the 
overwriting is controlled by the user with a tablet and stylus. A small 2-dimensional array called the 
brush governs this overwriting like a bit mask: Where there is a 0 in the brush, no overwriting occurs, 
but where it is non-0, the color selected by the user is written into the frane buffer. Tint painting 
is the fol- lowing variation on simple painting: At a point (pixel) about to be written in the frame 
buffer, an RGB to HSV transform is performed to extract the value V there. A new color is formed from 
the tint the user selected and V of the pixel. An applica- tion of the HSV to RGB transform converts 
the color to usable form, and then it is written into the pixel. If the transforms are slow, the user 
can "feel" it by sluggish response of his brush. The triangle model transforms (RGB to HSL) are too 
slow to be used in software form in interactive si- tuations such as painting because of the function 
 response, especially if implemented in microcode. An important use of the triangle model is for mani- 
pulation of the NTSC space. As indicated in Fig. 4, modern monitors depart somewhat from the 1953 NTSC 
recommendations. The generality of the trian- gle model makes it a simple matter to obtain the RGB to 
HSL transform pair for the slightly dif- ferent weights which describe a particular modern monitor (2). 
A simple recalculation of constants suffices. ACKNOWLEDGEMENT To Dick Shoup of Xerox PARC whose encouragement, 
sponsorship, and technical assistance made this research possible and whose "magic dreem machine" inspired 
it. Also to David DiFrancesco for the color photographs, Ephraim Cohen for trigonometric assistance, 
Larry Masinter for improved notation. REFERENCES i. Faber Birren. Creative Color. Van Nostrand Reinhold, 
New York, i--~, p. 12. 2. Deane B. Judd and Gunter Wyszecki. Color in Business, Science, and Industry. 
(3rd Ed.), John Wiley Wiley Sons, New York, 1975.  3. Proceedings of the I.R.E., 42 (Jan. 1954) [spe- 
cial NTSC issue].  4. Jay M. Tenenbaum, Thomas D. Garvey, Stephen Wyl, Helen C. Wolf, and David Nitzan. 
An in- teractive facility for scene analysis research. Technical Note 87, SRI Project 1187, Stanford 
Research Institute, Menlo Park, CA, (Jan. 1974), pp. 34-39.  (o,o,1)  (1,0~ G / R calls to sqrt(), 
arctan(), and cos(). It is prob- able, however, that approximations to these func- tions (e.g., linear 
interpolation between values in Fig. i. RGB colorcube and subcube. a lookup table for cos()) would 
lead to speedier 17 .8 ° i277onr H G "0 b~ ~ ~, 6 Y x Fig. 2. A vector in a hexagonal disk. Fig. 4. 
1931 chromaticity diagram showing 1953 NTSC reco.rnended gamut (solid triangle) and a modern gamut (dashed). 
 % PB (0,0,1) 0,1,01 , g R G //~/ 11,0,0) PR PP RB QB % r Fig. 3. Normalized color triangle. Fig. 5. 
Computing H in the triangle model. 18  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807362</article_id>
		<sort_key>20</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Color spaces for computer graphics]]></title>
		<page_from>20</page_from>
		<page_to>25</page_to>
		<doi_number>10.1145/800248.807362</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807362</url>
		<abstract>
			<par><![CDATA[<p>Normal human color perception is a product of three independent sensory systems. By mirroring this mechanism, full-color display devices create colors as mixtures of three primaries. Any displayable color can be described by the corresponding values of these primaries. Frequently it is more convenient to define various other <underline>color spaces</underline>, or coordinate systems, for color representation or manipulation. Several such color spaces are presented which are suitable for applications involving user specification of color, along with the defining equations and illustrations. The use of special color spaces for particular kinds of color computations is discussed.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Color]]></kw>
			<kw><![CDATA[Color displays]]></kw>
			<kw><![CDATA[Color space]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Image synthesis]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.4.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P330478</person_id>
				<author_profile_id><![CDATA[81100234905]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Joblove]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P68460</person_id>
				<author_profile_id><![CDATA[81100196982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Greenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Hunt, R.W.G., The Reproduction of Colour (third ed.), John Wiley &amp; Sons, New York, 1975, pp. 40-43.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Wyszecki, Gunter and Stiles, W.S., Color Science John Wiley &amp; Sons, New York, 1967.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Ratliff, Floyd, "Contour and Contrast," Scientific American, vol. 226, no. 6, pp. 90-101 (June 1972).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Hunt, R.W.G., "Light and Dark Adaptation and the Perception of Colour," Journal of the Optical Society of America, vol. 42, pp. 190-199 (1952).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Hunt, R.W.G., "The Specification of Colour Appearance I. Concepts and Terms," Color Research and Application, vol. 2, pp. 55-68 (Summer 1977).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Munsell, A.H., A Color Notation (eighth ed, ed. &amp; rearrg.), Munsell Color Company, Baltimore Maryland (1939).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[International Commission on Illumination, Proceedings of the Eighth Session, Cambridge, England, 1931.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 COLOR SPACES FOR COMPUTER GRAPHICS by George H. Joblove and Donald Greenberg Program of Computer 
Graphics Cornell University ABSTRACT Normal human color perception is a product of three independent 
sensory systems. By mirroring this mechanism, full-color display devices create colors as mixtures of 
three primaries. Any displayable color can be described by the corresponding values of these primaries. 
Frequently it is more convenient to define various other color spaces, or coordinate systems, for color 
representation or manipulation. Several such color spaces are presented which are suitable for applications 
involving user specification of color, along with the defining equations and illustrations. The use of 
special color spaces for particular kinds of color computations is discussed. KEYWORDS: Computer Graphics, 
Color, COlor Displays, Color Space, Image Synthesis COMPUTING REVIEWS CLASSIFICATION: 8.2 Introduction 
 The normal human visual system is comprised of three lute power level (or height of the distribution) 
 components which produce color sensation. Full-determines what is perceived as the intensity. Two color 
display devices used in computer graphics take kinds of light-sensitive bodies in the retina, rods advantage 
of this phenomenon and produce their en-and cones, send signals to the brain. The rods tire range of 
color simply by mixing three primary function mostly in very dim light to which the colors. This paper 
describes the concept of color cones are insensitive. At normal light levels, space, wherein color is 
regarded as occupying a virtually all visual information is provided by the three-dimensional volume. 
One such space is inher- cones. Three types of these receptors, each sensi- ently defined by the primary 
colors of a display tive to different wavelengths, together are respon- system; others may be used provided 
that locations sible for color discrimination. The strengths of within them may ultimately be transformed 
to three the resulting three separate signals are interpre- proper input parameters for the display device. 
ted as a particular chromaticity. Although the sensitivities of the three receptors overlap, one Following 
a review of the principles of color, sev-is sensitive particularly in the blue area of the eral color 
spaces will be presented which are use- spectrum, one in the green, and one in the red. 1 ful for the 
purpose of communicating color specifi- cations between a computer graphics system and a Different spectral 
distributions can produce the user. Other color mappings which are primarily same color sensation, or 
receptor responses. This suitable for internal use by the graphics system phenomenon is called metamerism; 
"different" colors for color computations are discussed. which appear the same as a result are called 
meta- mers. 2 If light has a flat, even spectral distri- bution, or any other distribution that stimulates 
Light, Color, and Perception all three receptors equally, it is seen as black, gray, or white, the achromatic 
colors. Any other Visible light is electromagnetic radiation in the distribution produces the sensation 
of a chromatic range of wavelengths to which the normal human vis- color, one which has a distinguishable 
hue. ual system is sensitive, about 400 to 700 nanometers. The wavelength determines the perceived hue 
of the Any three wavelengths of light can be mixed in vary- light; the amplitude is interpreted as intensity. 
ing proportions to create many different colors. Some sets of three wavelengths can produce more In 
general, light is not of a single wavelength but colors than others, but the particular characteris- 
a continuous mixture of all the wavelengths across tics of the three human receptor systems make it some 
part or all of the visible spectrum. The per- impossible for any such set of three primary colors ceived 
color is then a function of the spectral dis-to duplicate all colors. The three primaries which tribution 
of amplitude by wavelength. The shape of can be mixed to produce the greatest number of the distribution 
determines what is perceived as colors are particular wavelengths of red, green and the chromaticity 
(color without regard to intensity) blue. For this reason, most color display systems of the light. 
For a given chromaticity, the abso- are based on three light sources which are as close 20 to these 
colors as possible. Chromaticity is a function of the ratios between the primary colors. If their relative 
values are ex- pressed as proportions of the sum of all three, chromaticity may then be plotted as a 
function of any two primary colors as shown in Figure i. In this chromaticity diagram, the locations 
of the three primaries are the vertices of a color tri~ angle which is the boundary of the area represent- 
ing all colors which they can reproduce. The horse- shoe-shaped curve is the locus of spectral colors 
 and therefore bounds all the visible colors. The colors on the straight line connecting the end- points 
of the spectral locus are the pure non- spectral hues. The colors lying within the spec- tral locus 
but outside the color triangle are those which cannot be produced by the primaries because, in terms 
of the diagram, they would each require one primary component to assume a negative value. The primaries 
are "optimum" in that the area repre- senting the nonreproducible colors is minimum. Ultimately, any 
color to be displayed by a red/ green/blue component system must be specified by those components. All 
colors which can be created can therefore be represented within a cubic volume in the all-positive octant 
of an orthogonal three- space whose axes are the rgb primaries (Figure 2). For many applications, it 
is convenient to regard a color as a point in this rgb color space. For many others, however, it may 
be preferable to specify colors as points in some other color space. If this alternative space has been 
defined parametrically in terms of r,g, and b and a function exists to transform its coordinate system 
to an rgb coordinate system, the result of such a transformation can be fed to the display device. Color 
Spaces for User Interaction Because most people are not familiar with additive primary mixing, rgb space 
is not always suitable for applications when the user is composing colors. However, many people who 
are artistically inclined are quite proficient at seeing a color as a mixture of the "subtractive primaries" 
cyan, magenta, and yellow. A color space so defined is just the in- verse of the rgb space, with white 
at the origin (Figure 3). The correspondingly simple transforma- tion to rgb space is given by: [r 
g b] = [i 1 i] -[c m y] (eq. i) where r,g,b are the red, green, and blue components, c,m,y are the cyan, 
magenta, and yellow components, all scaled in the range [0 0 0] to [i 1 i]. Most viewers, though, first 
notice a color's hue and then characteristics which might be described as lightness, brightness, brilliance, 
strength, satura- tion, vividness, purity, etc., many of which are interrelated. For interactive purposes, 
then, a system of specifying colors based on such qualities would be most natural for a naive user. 
Since hue is a circular or modular quality, while all the other characteristics mentioned imply the existence 
of minimum and maximum values, points in any color space related to these qualities may be specified 
by cylindrical coordinates. The scaling of the angular component (that is, the precise func- tion relating 
hue to the angle) is somewhat arbi- trary for these applications. The remaining two axes can be defined 
in a variety of ways. One convenient arrangement of hue is an equidistant gree~ 620 530 ~ r e e n I 
\N00% ~ 570 I I 0.4 4ao ewhite o.~ s,0 "o Figure 2. RGB color space, and color solid. Y~ s2o~" ~magenta 
470 630 . 700 - ~44o,.~ ' _ 0.6 o.8 I.o '~ Figure i. Chromaticity diagram, with color triangle, spectral 
locus, ~n and "line of purples," for monochromatic primaries of yell~"~..~.~-'"'~ I~' ~ wavelengths 650 
nanometers (red), 530 nanometers (green), Figure 3. Cyan/magenta/yellow color space, and 460 nanometers 
(blue). and color solid. 21 spacing of the primaries and their complements in their natural order, 
with other hues located by linear interpolation as graphed in Figure 4a. The rgb-component ratios are 
computed from the hue angle as follows: r l if 0 ~ h ~ 1/6 or 5/6 ~ h < 1 =$2 -6h if 1/6 <h ~ 2/6 
r I 0 if 2/6 < h < 4/6 L6h -4 if 4/6 < h < 5/6 (eq. 2a) ~6h if 0 < h ~ 1/6 =~ 1 if 1/6 <h <3/6 g |4 
-6h if 3/6 <h < 4/6 ! ~0 if 4/6 < h < 1 (eq. 2b) 0 if 0 < h < 2/6 ~6h -2 if 2/6 <h <3/6 b =~I if 
3/6 < h < 5/6 ! L6 -6h if 5/6 < h < 1 (eq. 2c) where h is the hue angle in revolutions modulo 1 (with 
equivalent wavelength decreasing from red with positive revolution from zero). Because this function 
is non-continuous, hue series will exhibit Mach banding (the illusion of overly light or dark areas) 
at the discontinuities due to the tendency of the human visual system to enhance such variations in luminance 
for any of the three receptor systems 3 (see Figure 4a). These discontin- uties can be eliminated by 
using a sinusoidal in- terpolation instead of the linear one, as illus- trated by Figure 4b, in which 
 [r g b] = ([i 1 i] + cos(([l 1 l]-[r'g'b'])~))/2 (eq. 3) where r',g',b' are computed using equations 
2a, 2b, and 2c. Several methods exist for describing the chromatic content of a color, which is the 
attribute of a visual sensation according to which an area appears to exhibi~ more or less chromatic 
color, or "color- fulness." Two words which are normally used some- what loosely have been precisely 
defined as follows5: "Chroma" is colorfulness judged with reference to white or the general level of 
sur- rounding illumination; the "saturation" of a color is its colorfulness judged with respect to its 
lightness. Thus pure monochromatic red light of low intensity or lightness has very high saturation but 
low chroma. The Munsell Color System (1905) 6 , one of the earli- est arrangements and means of describing 
color and one which is in common use today, maps colors according to a quantity closely related to chroma 
 (called "Munsell chroma"), in addition to hue, and lightness relative to a reference white ("Munsell 
 value"). For user interaction with a computer graphics system, a convenient adaptation of this arrangement 
may be defined as follows: The grays are linearly interpolated on a straight line (the cylindrical 
axis) from black to white; the colors which are of maximum chroma for their respective hues (for the 
given rgb display space) are located on a circle centered On the gray axis and per- pendicularly intersecting 
it halfway between the black point and the white point; and all other colors are linearly interpolated 
by rgb components between black, white and the colors on that circle of corresponding hues. All the colors 
that can be displayed define a volume (hereafter referred to as the color solid) which in this color 
space is bi- conical. The space and color solid are diagrammed in Figure 5. Figure 6a is a radial (constant-hue) 
section of the color solid, and Figure 6b is a sec- tion perpendicular to the cylindrical axis (con- 
stant-intensity). In this space, the lightness or intensity of a color is defined by the vertical coordinate 
of the horizontal plane which contains the color; the radius relates to its chroma. It is usually more 
convenient to define the space so that the radius corresponds to the chroma rel- ative to the maximum 
achievable chroma for the hue and intensity of the color. In this color space, the color solid is a cylinder, 
with black and white bases at which levels the relative chroma is unde- fined. This space and cylindrical 
color solid are diagrammed in Figure 7. Figure 8a is a projection of the surface of the cylinder, and 
Figure 8b is a radial (constant-hue) section. The rgb components of a color described by its coordinates 
in this space are [r g b] = ([.5 .5 .5] + c(r'g'b' ]-[ .5 .5 .5])) 2i if i < 1/2 [.5 .5 .5] + c([r'g'b']-[.5 
5 .5]) + ([.5 .5 .5] -c([r'g'b']-[.5 .5 .5])) (2-2i) if i ~ 1/2 (eq. 4) where c is the relative chroma 
and i is the inten- sity (each on the range 0 to i), and [r'g'b'] is computed using an equation such 
as 2 or 3. In a color space defined by hue, chroma, and inten- sity, all the colors of a given saturation 
define a conical surface whose apex is the black point (at which the saturation is undefined). A color 
space may be defined in which the radial component is directly related to saturation by letting that 
com- ponent be s = (max(r,g,b) -min(r,g,b)) / max(r,g,b) (eq. 5) Furthermore, the axial component 
can be specified to correspond to that component of color which is equal (and maximal) for all the colors 
representing the maximum intensities for all chromaticities and zero for black. In other words, the circle 
of maximum-chroma colors can be located so its center intersects the cylindrical axis at the white point. 
This axial component is denoted here by the term "value." In this color space, the color solid is a right 
circular cylinder (Figure 9) whose "top" base is a circularized chromaticity diagram, whose "bot- tom" 
base is black, and whose cylindrical surface 22   u,v. CIE color solids, such as xyY, U*V*W*, L*u*v*, 
etc., could even be used once the proper corres- pondences of the display primaries were determined. 
However, the usefulness of these spaces in computer graphics applications has not been demonstrated. 
 Color Spaces for Computation Suitable color spaces can also serve to facilitate certain color computations 
encountered in the gener- ation of images. Some of these computations are tri- vial and can be done in 
the rgb space of the display system. For example, the shadow series for a color illuminated by a single 
light source is determined by linear interpolation between the color and black in the rgb space. For 
other computations, different color spaces can be more useful. The effect of atmospheric scattering 
and haze on colors viewed at long distances may be approximated using a cylindrical color space. In this 
system, the changes that a particular color will undergo may be determined by computing a straight line 
from the original color to a bluish gray. Such a line in rgb space might not prove satisfactory in terms 
of the colors through which it passes. The simulation of specular reflection by a chromatic object requires 
a series of colors starting at black, increasing in intensity with saturation in the direction of the 
particular hue, and then de- creasing in saturation and ending at or near white. In any of the spaces 
discussed so far, such a color scale lies on a complex curve. If a color space can be defined in which 
the locus of these colors or, satisfactory approximations, is an easily cal- culated function, the computation 
of the image may be simplified. A general class of computations which could greatly benefit from such 
a technique are those involving the simulation of chromatic alteration of chromatic colors, such as the 
reflection of colored lights by colored objects or the transmission of colored light by a colored transparent 
medium. Proper simulation of such effects requires the specification of re- flection and transmission 
characteristics, not by rgb primary components, but rather by complete spec- tral distribution curves 
and computations over these spectra. However, this requires a very large and probably impractical amount 
of computation. A good approximation based on primary components could be very useful. Another problem 
is to simulate the effects of chromatic transparency or filtration. Several color spaces are presently 
being examined in which a linear interpolation between the incident color and the filter color yields 
a good approxima- tion of a likely resultant transmitted color. The concept of color space is also useful 
in the creation of synthetic-color images in which the variation of some parameter is represented as 
a var- iation in color. The colors define a path through color space. The intermediate colors obtained 
by computing a straight line in rgb space probably are not as visually preferable as those existing on 
such a line in one of the cylindrical color spaces discussed earlier. In any of the latter spaces, all 
of the intermediate colors could have the same saturation as the end colors; whereas in rgb space, they 
would be paler. Summary Color display devices used in computer graphics pro- duce their range of colors 
by mixing the three pri- maries red, green, and blue. For many applications, the interactive use of this 
additive color mixing is not always suitable. By defining color spaces as three-dimensional volumes representing 
the available color spectrum, more appropriate methods for select- ing colors can be obtained. This pape~ 
has described several of these useful color solids and their beneficial characteristics. The equations 
for transforming to these color spaces from rgb space have been presented. Of particular importance is 
the fact that linear paths through certain color spaces can accurately represent complex color trans- 
itions such as shadowing or filtration. The utili- zation of the appropriate color space can thus re- 
sult in substantial savings in the computational time for the creation of synthetic images. Acknowledgement 
 This research has been sponsored in part by the National Science Foundation under grant number DCR 74-14694 
entitled "Development of Computer Graphics Techniques and Applications." References i. Hunt, R.W.G., 
The Reproduction of Colour (third ed.), John Wiley &#38; Sons, New York, 1975, pp. 40-43. 2. Wyszecki, 
Gunter and Stiles, W.S., Color Science John Wiley &#38; Sons, New York, 1967.  3. Ratliff, Floyd, "Contour 
and Contrast," Scien- tific American, vol. 226,' no. 6, pp. 90-101 (June 1972).  4. Hunt, R.W.G., "Light 
and Dark Adaptation and the Perception of Colour," Journal of the Opti- cal Society of America, vol. 
42, pp. 190-199 (1952).  5. Hunt, R.W.G., "The Specification of Colour Appearance I. Concepts and Terms," 
Color Research and Application, vol. 2, pp. 55-68  (Summer 1977).  6. Munsell, A.H., A Color Notation 
(eighth ed, ed. &#38; rearrg.), Munsell Color Company, Baltimore Maryland (1939).  7. International 
Commission on Illumination, Proceedings of the Eighth Session, Cambridge, England, 1931.  2S 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807363</article_id>
		<sort_key>26</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[A scan line algorithm for computer display of curved surfaces]]></title>
		<page_from>26</page_from>
		<doi_number>10.1145/800248.807363</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807363</url>
		<abstract>
			<par><![CDATA[<p>The conventional procedure for generating shaded images of curved surfaces is to approximate each surface element by a mosaic of polygons and to then apply one of several established polygon display algorithms. The method described here extends these polygon based techniques to produce an excellent approximation of bi-cubic parametric surfaces in scan line order.</p> <p>Each surface patch is described in terms of cubic edge curves, including parametric curves on the interior of the patch as well as the patch boundaries. Specifying interior edges has the effect of subdividing the patch and generally results in a more accurate image. The silhouette, approximated by a piecewise cubic interpolant, further divides the patch into front facing and rear facing portions.</p> <p>The edge curves are intersected by successive scanning planes to form the endpoints of scan line segments. Depth and surface normal are linearly interpolated between the endpoint values. Visibility is calculated for each segment by a hybrid priority/z-buffer scheme. Shading is computed using Phong's illumination model with the interpolated surface normal.</p> <p>The algorithm is currently used for display of B-spline surfaces as part of an experimental display processor.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Hidden surface removal]]></kw>
			<kw><![CDATA[Raster display]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Hidden line/surface removal</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P285628</person_id>
				<author_profile_id><![CDATA[81100586999]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Turner]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Whitted]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Electrical Engineering, North Carolina State University, Raleigh, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A SCAN LINE ALGORITHM FOR COMPUTER DISPLAY OF CURVED SURFACES Turner Whitted Department of Electrical 
Engineering North Carolina State University Raleigh, NC 27650 Abstract The conventional procedure for 
generating shaded images of curved surfaces is to approximate each surface element by a mosaic of polygons 
and to then apply one of several established polygon display algorithms. The method described here extends 
these polygon based techniques to produce an excellent approximation of hi-cubic parametric surfaces 
in scan line order. Each surface patch is described in terms of cubic edge curves, including parametric 
curves on the interior of the patch as well as the patch boundaries. Specifying interior edges has the 
effect of subdividing the patch and generally results in a more accurate image. The silhouette, approximated 
by a piecewise cubic interpolant, further divides the patch into front facing and rear facing portions. 
The edge curves are intersected by successive scanning planes to form the endpoints of scan line segments. 
Depth and surface normal are linearly interpolated between the endpoint values. Visibility is calculated 
for each segment by a hybrid priority/z-buffer scheme. Shading is computed using Phong's illumination 
model with the interpolated surface normal. The algorithm is currently used for display of B-spline 
surfaces as part of an experimental display processor. Key Words and Phrases: computer graphics, hidden 
surface removal, raster display. CR Categories: 8.2 This work was supported by the National Science 
Foundation grant MCS75-06599. This paper will be published in a future issue of Communications of the 
ACM. 26 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807364</article_id>
		<sort_key>27</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[A scan line algorithm for displaying parametrically defined surfaces]]></title>
		<page_from>27</page_from>
		<doi_number>10.1145/800248.807364</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807364</url>
		<abstract>
			<par><![CDATA[<p>This paper presents a scan line algorithm for drawing picture of parametrically defined surfaces. A scan line algorithm is characterized by the order in which it generates the picture elements of the image. These are generated left to right, top to bottom in much the same was as a picture is scanned out on a TV screen. Parametrically defined surfaces are those generated by a set of bivariate functions defining the X, Y and Z position of points on the surface. The primary driving mechanism behind such an algorithm is the inversion of the functions used to define the surface. To keep the algorithm general enough to apply to a wide variety of functional forms, this inversion is done numerically. It is only required to provide mechanism for evaluating the function and its derivatives at any parametric location.</p> <p>The algorithm proceeds in two phases. First, a numerical search is made to find the local maxima of the Y definition function within the desired parameter ranges. These determine when portions of the surface first become visible as the scan plane progresses down the screen. Secondly, the actual scan conversion process is performed, maintaining a list of segments of the surface intersecting the current scan plane. As the scan plane passes local maxima of the Y function new segments are added to the list. In addition, any existing segments are updated to reflect their intersection with the updated scan plane. All intersection calculations are performed by a bivariate Newton-Raphson solution of the defining equations. If the solution does not converge, it is due to the scan plane passing a local minimum, causing segments to be deleted from the active list. Finally, within one scan line, an X scan must be performed to generate the Z information about the surface for each picture element. This is also performed by a bivariate Newton-Raphson iteration with a different set of defining functions.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Bicubic patches]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Hidden surface elimination]]></kw>
			<kw><![CDATA[Numerical inversion]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Hidden line/surface removal</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Line and curve generation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P131722</person_id>
				<author_profile_id><![CDATA[81100294395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Blinn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech/JPL, 4800 Oak Grove Dr. 125-241, Pasadena, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A SCAN LINE ALGORITHM FOR DISPLAYING PARAMETRICALLY DEFINED SURFACES James F. Blinn Caltech/JPL 4800 
Oak Grove Dr. 125-241 Pasadena CA 91103 Abstract This paper presents a scan line algorithm for drawing 
pictures of parametrically defined surfaces. A scan line algorithm is characterized by the order in which 
it generates the picture elements of the image. These are generated left to right, top to bottom in much 
the same was as a picture is scanned out on a TV screen. Parametrically defined surfaces are those generated 
by a set of bivariate functions defining the X, Y and Z position of points on the surface. The primary 
driving mechanism behind such an algorithm is the inversion of the functions used to define the surface. 
To keep the algorithm general enough to apply to a wide variety of functional forms, this inversion is 
done numerically. It is only required to provide a mechanism for evaluating the function and its derivatives 
at any parametric location. The algorithm proceeds in two phases. First, a numerical search is made 
to find the local maxima of the Y definition function within the desired parameter ranges. These determine 
when portions of the surface first become visible as the scan plane progresses down the screen. Secondly, 
the actual scan conversion process is performed, maintaining a list of segments of the surface intersecting 
the current scan plane. As the scan plane passes local maxima of the Y function new segments are added 
to the list. In addition, any existing segments are updated to reflect their intersection with the updated 
scan plane. All intersection calculations are performed by a bivariate Newton-Raphson solution of the 
defining equations. If the solution does not converge, it is due to the scan plane passing a local minimum, 
causing segments to be deleted from the active list. Finally, within one scan line, an X scan must be 
performed to generate the Z information about the surface for each picture element. This is also performed 
by a bivariate Newton-Raphson iteration with a different set of defining functions. Key Words and Phrases 
 Computer Graphics, Hidden Surface Elimination, Bicubic Patches, Numerical Inversion C R Categories 
5.12, 5.13, 5.17, 5.4, 8.2 This paper will appear in a future issue of the Co.~nunication8 of the Association 
for Computing Machinery and was distributed to SIGGRAPH '78 registrants 27 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807365</article_id>
		<sort_key>28</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Towards the design of an intrinsically graphical language]]></title>
		<page_from>28</page_from>
		<page_to>32</page_to>
		<doi_number>10.1145/800248.807365</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807365</url>
		<abstract>
			<par><![CDATA[<p>Coding a large and diversified graphics application system is a difficult task. We suggest an approach to this problem in which programs are built up using <underline>Objects</underline> (e.g., Classes, Modules) newly generated or drawn from a library. Each Object has an <underline>Aid</underline> which supports an interactive dialogue with the programmer resulting in the insertion of the appropriate references to the Object into the developing code. An Aid can display graphical Objects and accept sketching and picture editing. An <underline>Association</underline> capability allows the programmer to generate code corresponding to the displayed graphical material. The Association can be literal, with numerical values being inserted, or symbolic, with variable arguments inserted. A <underline>Programming System</underline> that is so structured implements an <underline>Intrinsically Graphical Language</underline> because the code can be &#8220;written&#8221; using both textual and graphical dialogues.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Aids]]></kw>
			<kw><![CDATA[Deixis]]></kw>
			<kw><![CDATA[Disambiguation]]></kw>
			<kw><![CDATA[Graphical dialogue]]></kw>
			<kw><![CDATA[Human computer dialogue]]></kw>
			<kw><![CDATA[Intrinsically graphical languages]]></kw>
			<kw><![CDATA[Modular programming]]></kw>
			<kw><![CDATA[Program development]]></kw>
			<kw><![CDATA[Programmer's assistant]]></kw>
			<kw><![CDATA[Structured editing]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Languages</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>D.2.3</cat_node>
				<descriptor>Object-oriented programming</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.2.3</cat_node>
				<descriptor>Program editors</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10011007.10011006.10011066</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Development frameworks and environments</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011008.10011009.10011011</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->General programming languages->Language types->Object oriented languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003128</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction techniques</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Languages</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31023041</person_id>
				<author_profile_id><![CDATA[81470651582]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Futrelle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Dept. of Genetics and Development, 515 Morrill Hall, University of Illinois, Urbana, Illinois]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P330324</person_id>
				<author_profile_id><![CDATA[81100273378]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[G.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Barta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Dept. of Computer Science, University of Illinois, Urbana, Illinois]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>512762</ref_obj_id>
				<ref_obj_pid>512760</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Ingalls, D. H. H. The Smalltalk-76 Programming System Design and Implementation. Fifth Annual Symposium on Principles of Programming Languages (ACM, New York, Jan. 1978), 9-15.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356719</ref_obj_id>
				<ref_obj_pid>356715</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Sandewall, E. Programming in the Interactive Environment: the "LISP" Experience. ACM Computing Surveys 10 1 (March 1978), 35-71.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 TOWARDS THE DESIGN OF AN INTRINSICALLY GRAPHICAL LANGUAGE R. P. Futrelle* and G. Barta** University 
of Illinois Urbana, Illinois 61801 ABSTRACT Coding a large and diversified graphics applica- tion system 
is a difficult task. We suggest an approach to this problem in which programs are built up using Objects 
(e.g., Classes, Modules) newly generated or drawn from a library. Each Object has an Aid which supports 
an interactive dialogue with the programmer resulting in the insertion of the appropriate references 
to the Object into the developing code. An Aid can display graphical Objects and accept sketching and 
picture editing. An Association capability allows the programmer to generate code corre- sponding to 
the displayed graphical material. The Association can be literal, with numerical values being inserted, 
or symbolic, with variable arguments inserted. A Programming S_~te_m_mthat is so structured implements 
an Intrinsicall[ Graphical Language because the code can be "written" using both textual and graphical 
dialogues. KEY WORDS AND PHRASES: Intrinsically Graphical Languages, human computer dialogue, graphical 
dialogue, modular prograa~ing, program devel- opment, programmer's assistant, structured editing, Aids, 
disambiguation, deixis CR CATEGORIES: 4.20, 4.22, 4.42, 4.43, 8.2 I. INTRODUCTION Many graphics applications 
systems offer a variety of easy-to-use and responsive facilities. But too often there are no such nice 
facilities available to support the program development pro- cess itself. What does exist is rarely 
directed toward graphics. It is natural to want to design a "language" in which the program text and 
graphical objects are treated on an equal footing, a language in which This research was supported by 
the National Science Foundation under MCS77-03264. *Dept. of Genetics and Development, 515 Morrill 
Hall **Dept. of Computer Science the coding is done by typing text and by drawing pictures. Such a 
fully integrated language we call an Intrinsically Graphical Language or IGL. A direct attack on this 
problem fails because text and pictures are of two different modalities so that the relations between 
them are not readily perceptible to a human being. Adding any number of graphics subroutines to a conventional 
pro- gramming language still fails to give us a langu- age in which we can develop code via drawings. 
We must instead build a system that can translate from one modality to the other as the programmer requires. 
This capability can then be integrated into a system which helps the programmer generate, inspect, test 
and revise code. All of this taken together constitutes a Programming System (PS) for an IGL. Such a 
system is heavily integrated to the point that it is hardly useful to discuss an IGL as an entity separate 
from the Programming System which contains it. The Programming System is itself an on-line inter- active 
graphics system. It contains conventional editing and sketching facilities; but the power of these facilities 
is markedly expanded by the Aids described in Sec. 5. Every object (e.g., procedure) available to the 
system has an Aid associated with it. The Aid supports an efficient dialogue between the programmer and 
the object of interest and is actively engaged in integrating the object into developing code. 2. EDIT/SKETCH 
 Let us recall briefly how conventional on-line editors assist in the development of programs. These 
editors work directly with "listings", the surface structure of the code. They are confined to the lexical 
level, to looking at character sequences, not at the deeper syntactic level. Some editors expand this 
power through the ability to execute user-defined macros. An editor allows user entry, allows search 
based on string matching and allows revision including simple replacements as well as movement of a number 
of characters or lines as a group. Editors are now being designed that are specific to particular languages. 
They use knowledge of the language syntax so that they can operate in terms ofte. g., declarations, functions, 
arguments, assignment, quo£ed strings, types, IO, etc. Such  28 structured editors can be built to 
operate directly  on the tree generated by the parser, the internal representation, rather than duplicating 
the parser's work. It is important to understand how we refer to text items to be edited, because these 
problems must also be solved in the graphics domain. Items can be referred to associatively, through 
pattern matching, e. g., "FIND string". Items can also be referred to relative to the current position 
or other reference points, e.g. using "previous", "next", "top line + 3", etc. Identifying an item be 
referring to its position in context, rather than naming it, is using deixis. A Sketch facility gives 
the programmer the ability to input pictures by drawing. It is a key ele- ment of many applications systems. 
In these systems the goal of sketching is to build and modify (edit) the data structures which corre- 
spond to the displayed material. The techniques developed in these systems are not well-adapted to generating 
code. 3. PROGRAMMING SYSTEMS A typical programming system for an IGL would contain the following subsystems 
(where we roughly separate the static, S, from the dynamic, D): i. Meta i.i Help i.i.i Description 
(S) 1.1.2 Aids (D) 1.2 Documentation  2. State  2.1 History (S) 2.2 Current (S)  3. Library  
3.1.1 Files (S) 3.1.2 Procedures (S) 3.2.1 Search (D) 3.2.2 Update (D)  4. Language  4.1 Parser 
(D) 4.2 Compiler (D)  5. Edit/Sketch  5.1 Enter (D) 5.2 Find (D) 5.3 Revise (D)  6. Testing 
 6.1.1 Core code 6.1.2 Context 6.2.1 Run 6.2.2 Trace  Section 1.1.1 includes the ordinary replies 
to "Help" commands. The Aids of 1.1.2 are the pro- cedures that can themselves generate code and pictures 
to assist programming. The State 2 is a data base containing some history of the pro- gram development 
process (prior states) 2.1, as well as the current state 2.2. The Library 3 must be structured to give 
efficient access to the large number of small procedures that will exist in the system we envisage. 
The Parser 4.1 gen- erates the deeper program representation for use by many other components. Under 
Testing we distinguish between the Core Code to be tested (6.1.1) and the Context in which it is to 
be run  (6.1.2). The Context includes initial conditions and input data. The major difference between 
a Programming System and a conventional computer shop or facility with many of the same sub- systems, 
is that the subsystems would be thor- oughly integrated in a Programming System, all equally accessible 
through a uniform, high level interface. We realize that many serious questions of detailed design and 
implementation must be raised and resolved if the above list is to be anything more than a "wish list". 
 4. THE SETTING For the remainder of the discussion we will assume that we are dealing with a general-purpose 
pro- gramming language in which programs can be built up of a number of classes or modules which we will 
call Objects. An Object has both procedural and data-like properties, collectively called Attributes, 
and is normally only accessible through these Attributes. An Object is a general form which may have 
specific Instances in which some values are bound. For example, a Building object might have an instance, 
Fred's House. Fred's House could contain an attribute Drawing, which might be produced by sketching. 
Data- oriented attributes might include Age and Locatio~ Procedurally-oriented attributes could include 
Paint it, Deteriorate or even Wave Bye-Bye, if Fred's House were so gifted. The devices available to 
the programmer would be a keyboard and a graphics device such as a tab- let with stylus. Feedback would 
be provided by one or more high resolution displays (typically color raster units). 5. AIDS An Aid 
is an object that helps the programmer to incorporate another object into the program code being developed. 
Let us assume that partially completed code, the Code-in-progress, is dis- played on the screen and the 
text cursor is positioned at the point where a reference to the numerical function Fun is to be inserted. 
Not remembering the exact form of the Fun attributes, the programmer types "Fun", and then types "Aid" 
or hits "Get Aid" on the screen. The Aid for Fun is evoked and appears on the screen: Aid for Fun A. 
Set Fun (Seed) B. Fun (Arg) Insert in code More aid Notes ....  Realizing that the attribute (A.) 
required is "Set Fun", the prograrmner hits it and hits "Insert in code" on the screen and the attribute 
is inserted in the code in place of "Fun" in the form "Set Fun (+)", where the cursor + is auto- matically 
positioned to next allow entry of an argument other than the dummy argument "Seed". The exact design 
of the Aid in terms of keyboard use or stylus sequence is not at issue here. The impor- £ant point is 
that each Aid encapsulates just those aspects of an object needed to use the object suc- cessfully and 
supports a dialogue with the pro- grammer customized to the particular object. The Aid does not display 
the actual code which imple- ments its Object. In the example above, more com- plex interactions would 
require expanding the Aid by hitting "More aid". Description and specifica- tions of Fun are contained 
in the "Notes" section of the Aid. The second simple example involves graphics. Suppose the object Bow, 
which looks like is to be used. Its Aid can be summoned: Aid for Bow A. Show Bow (L,W,Cent) B. Erase 
Bow Show Adjust Insert in code More aid Notes .... If "Sho~'is hit, this appears: If "Adjust' is hit, 
the display is augmented to:   Cent W V L  If "Cent" is hit, the bow can be moved about. If "W" is 
hit the display could be: W V Then the Bow could be altered by grabbing ~ with the interactive stylus 
yielding: V  W _L or W "Show Bow" could then be inserted into the devel- oping code with the adjusted 
numerical values of its arguments or with variable, symbolic arguments. This insertion would ultimately 
result in a dis- play of a Bow in the finished application system. If the last example has any virtues 
they are sim- plicity and the fact that code is generated with- out the user having to remember and type 
the at- tribute and its correct parameter set. Thus, the possibility of error is decreased. Furthermore, 
the object parameters could be adjusted visually and inserted in code, again without typing in the numerical 
values. The major fault of the example is its simplicity; it is a toy example. The true value of Aids 
is only realized when their power and utility are expanded considerably as we dis- cuss below. Deixis 
This is the act of referring to an item in context without having to name it. Pointing at an object is 
such a deictic reference. Using "this" or "it" in discourse is anaphora, a form of deixi~ Deixis in 
all forms is a major component of human communication. If a visible object appears on the screen, pointing 
to it may be an ambiguous reference, because the object may be complex, having many attributes. We 
shall argue that care- ful and efficient disambiguation of deictic re- ferences can make deixis a powerful 
programming tool. Meaning and Intent We are promoting a certain style of programming based on selection 
from a number of visible alternatives. If at any time the programmer can enter items more efficiently 
by composing them in the head and typing in, that option is of course available. In either event, the 
goal is to transmit to the machine to embody in the Code-in-progress, the programmers meaning  and 
intent. The four aspects of this process that we will discuss are: Structure, Direct entry, Choice and 
Association. Structure We use this word in the sense it is used in "structured editor" (Sec. 2). The 
Programming System would make heavy use of a parser to identify the syntactic units in the code as well 
as making use of a symbol/library data base to identify programmer defined objects. It is because of 
this that the system could insert "Set Fun (+)" in the Code-in-progress in the previous example. If the 
system operated entirely on the lexical level, some portion of the displayed string such as "Set Fun 
(+"or"Set Fun (Seed)+" would have to be copied into the code and edited appropriately in conventional 
ways. A structured approach can further guarantee that all parentheses will be balanced as in the previous 
example, that every "If" string appears with its obligatory "Then", and that in comments, these rules 
are quite pro- perly not enforced, etc. If as in most languages, save some such as Lisp, the surface 
or lexical level is far from the syntactic representation (parse tree) then the editing operations must 
coSedit both levels in parallel, backing up and reinvoking the parser as necessary. Structure in the 
graphics domain refers to the level of representation at which interaction pro- ceeds. At the lowest 
level, individual marks ~ixels, points or lines) are collected with little structure and operated on 
mark by mark, paralleling character-by-character text editing. At the other extreme, the entry and manipulation 
of graphical material is the creation of an instance of a well-structured object (the Bow example above). 
Parsing can be useful in the graphical domain. Graphic or pictorial material from one source, e-g., a 
free hand sketch, can be analyzed or parsed in terms of more structured objects, e.g. , in terms of closed 
or almost closed lines, internal and external regions, con- cave and convex regions, etc. Then when one 
of these objects is referred to or altered, an entire subset of the original sketch is dealt with as 
a unit. Direct entry This is the conventional method, the creation of parts of the Code-in-progress 
by direct programmer entry, by typing, rather than selection of already available objects via the display. 
This entry process can be assisted by concurrent syntactic analysis, e. g., assuring that the code up 
to a certain point is the left prefix of a legal program. The system could also alert the program when 
a previously undefined name is entered and suggest closely related, pre- viously defined names to cover 
misspellings. Choice The goal of the choice process is to nar- row down a set of possibilities to the 
point that a final decision is made and an act performed. A keyboard is the most highly developed device 
yet for choosing alternatives --one types enough characters, plus a delimiter, to uniquely identify an 
object. The keyboard is in one-to-one cor- respondence with conventional code. When choices are available 
on a display the situation is dif- ferent (cf. Association, below). It is not ef- ficient to use the 
display as a poorly designed keyboard, nor to simply list all syntactic units e.g., If, Then, Else, 
=, <, >, Fun, Bow, Aid, etc. A choice sequence is a process in which a choice made in one context instantiates 
another context in which further choices are possible. For this to be efficient the process should converge 
rapidly, in two or three hits typically. For example, a programmer working with Bow in the previous example 
would first establish a context such as Adjust, then a selection of L, W, or CENT would allow tuning 
of the shape and position of the displayed object. Without the prior es- tablishment of such a context, 
a hit on the figure would be ambiguous and would produce a Help-ing response, a suggestion to choose 
a con- text! The successive refinement and restriction of contexts is most efficient if the successive 
contexts are approximately independent or ortho- gonal. Basically this means that the choice sequences 
ending with the performance of an act, such as changing a parameter or inserting code, are unique and 
minimal in length. The indepen- dence guarantees that each choice conveys the maximum possible information. 
 Association One of the most crucial issues in the proper design of an IGL Programming System is how 
to handle references to and choices involving pictorial information. The programmer's goal is to build 
an applications system. Since we are not advocating a purely iconic approach, the system must be built 
by specifying the code, in some programming language whose exact design is not at issue here. An impasse 
results because pic- torial information does not map on to code in any obvious way. This results from 
the fact that the picture displayed is a complex function of the many attributes of the full object. 
If the pro- grammer points to a certain part of a picture it is not obvious which attribute, the color, 
line width, region, position, etc. is intended, and furthermore whether reference is being made to the 
generic attribute, the value(s) bound to it, or what. Aids must therefore be designed to Associate references 
to pictures, deictic references, with the code that is to be produced, inspected or modified. Suppose 
for example the programmer saw the reference "Show Bow (A,B,C)" in the Code- in-progress. The general 
Association mechanism of the system would allow the programmer to point at the argument "A" in the code 
text and see:  Association would work symmetrically so that point- ing at the Bow picture would highlight 
its appear- ances in the code, perhaps through the services of a specialized Association Aid. Many of 
the Objects in an application system have variable arguments so they can assume the many different 
forms the ultimate user will require. But how are these to be represented on the dis- play to assist 
the coding process? Our sugges- tion is that they be given example values during the coding process, 
e. g., a complex object con- sisting of an indeterminate number of polygons variously placed could 
be given the example values of one pentagon and one hexagon at specific positions. These example values 
would be retained in the finished application system, hidden from the user but always available to the 
 programmer who might want to modify the system code. 6. THE CODING PROCESS We specifically have in 
mind the coding of large and diversified applications systems, rich in pre-built or partially pre-built 
graphics. It is nice, when possible, to use Objects created at other times or by other programmers . 
But the mind cannot recall the structure of more than a limited number of these. Too often programmers 
choose to recreate rather than reuse, because they cannot recall! If an efficient Library of Objects 
and their Aids is available and if the Aids help the programmer to understand and use available Objects 
efficiently, then some of this needless reinvention can be avoided. Such a Library can also support structured 
growth in which Objects and their Aids are co-modified to perform different or more ambitious tasks. 
 The logic of the coding process is now simple -- Aids expose and explain the attributes of Objects, 
which are the only access points an Object has. The Aids furnish pictures with graphical Objects. The 
Association capability along with disambig- uation by Choice sequences gives the programmer the ability 
to first look at some graphics of interest and then move the relevant parts of its textual representation 
into code. This can be done independently of whether variables or numerical values are needed as arguments. 
Since the entire Code consists of Objects operating on Objects, Aids and Association can function at 
every level needed.  7. THE CREATION OF AIDS Aids themselves must be created whenever new Objects are 
created. The Object must be written so that it contains useful comments, usually some for each attribute. 
It is a simple matter to automatically generate an Aid containing the attributes and their comments, 
but containing none of the code which actually implements any of the attributes. This last point is important; 
the programmer, in the ideal situation, will never want to see the code which is inside the Object to 
be used. If the Aid is aiding a graphical Object then it can be written to create an instance of the 
Object to display for the prograrmner's benefit. The Aid can also rely on Dialogue Objects that will 
be designed with care because of the pivotal role they play. In building a graphical Aid, Associa- tions 
must be specified between meta-elements such as the L and W displayed in the Bow example, and the actual 
variables in the code. Once this is done (with the help of the Aid for Association) then users of e.g., 
the Aid for Bow, will find that the proper association is made. Since the comments and attributes in 
an Object are shared by its Aid, an editing change on a comment will change it simultaneously, will co-edit 
it, in both Object and Aid. Each Aid is an instance of an Aid Object and is constructed using, of course, 
the Aid for Aid! There's little to help us build this last men- tioned Object.  8. CONCLUSION An alternative 
discussion of many of the topics of this paper including extensive figures and references can be found 
in (i), available from us. We further urge any interested readers to study two recent papers (2), (3), 
which discuss working systems already using a number of the ideas discussed in this paper. ACKNOWLEDGEMENT: 
We thank the referees for their con~nents on the first draft of this paper. REFERENCES 1. Futrelle, 
R. P. and Barta, G. First Notes on Intrinsically Graphical Languages. Report GR-6- 78, Galatea Project, 
School of Life Sciences, U. of Illinois, Urbana (Jan. 1978), 42 pgs. 2. Ingalls, D. H. H. The Smalltalk-76 
Pro- gramming System Design and Implementation. Fifth Annual Symposium on Principles of Programming Languages 
(ACM, New York, Jan. 1978), 9-15.  3. Sandewall, E. Programming in the Interactive Environment: the 
"LISP" Experience. ACM Computing Surveys i0 1 (March 1978) , 35-71.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807366</article_id>
		<sort_key>33</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[BASIC Zgrass&#8212;a sophisticated graphics language for the Bally Home Library Computer]]></title>
		<page_from>33</page_from>
		<page_to>37</page_to>
		<doi_number>10.1145/800248.807366</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807366</url>
		<abstract>
			<par><![CDATA[<p>Home computer users are just now discovering computer graphics. Modest extensions to BASIC allow plotting but not much more. The Bally Home Library Computer, however, has hardware to aid implementation of video games. Custom integrated circuits working on a 160&#215;102 pixel (2 bits per pixel) color television screen allow certain forms of animation in real time. To give this power to the user, BASIC Zgrass has been designed and implemented. It is an extension of BASIC that allows parallel processes, picture objects that move, scale and group together as well as several drawing modes. There are also software controls of a three-voice music synthesizer, interactive input devices, a film camera and an IEEE bus interface. We will concentrate mainly on the language design for making it all easy to learn and use.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Art]]></kw>
			<kw><![CDATA[Graphic language]]></kw>
			<kw><![CDATA[Intepreters]]></kw>
			<kw><![CDATA[Interactive computer graphics]]></kw>
			<kw><![CDATA[Real-time]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.3.2</cat_node>
				<descriptor>BASIC</descriptor>
				<type>P</type>
			</other_category>
			<other_category>
				<cat_node>K.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010476.10011187</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011008.10011009</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->General programming languages->Language types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Languages</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15032130</person_id>
				<author_profile_id><![CDATA[81100432746]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tom]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[DeFanti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois at Chicago Circle]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P331306</person_id>
				<author_profile_id><![CDATA[81332498208]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jay]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fenton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Dave Nutting Associates]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P209901</person_id>
				<author_profile_id><![CDATA[81100561384]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Nola]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Donato]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois at Chicago Circle]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Nelson, Ted, The Home Computer Revolution, 1977, p. 79.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[DeFanti, T.A., "The Digital Component of the Circle Graphics Habitat," Proc. NCC, 1976.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[DeFanti, T.A., Sandin, D.J., and Nelson, T.H., "Computer Graphics as a Way of Life," Computers &amp; Graphics, Vol. 1, No. 1, May 1975.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Goldberg, A. and Kay, A., Smalltalk-72 Instruction Manual, Xerox PARC #ssl76-6, March 1976.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Papert, Seymour, A Computer Laboratory for Elementary Schools, Logo Memo 1, MIT Artificial Intelligence Lab, October, 1971.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Alpert, D., and Bitzer, D., "Advances in Computer-Based Education," Science, Vol. 167, March 1970.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Feldman, J.A., "Proceedings of the Extensible Languages Symposium," SIGPLAN NOTICES, Vol. 4., No. 8., August 1969.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 BASIC Zgrass--A ~ophisticated Graphics Language for the Baliy Home Library Computer Tom DeFanti, University 
of illinois at Chicago Circle Jay Fenton, Dave Nutting Associates Nola Donato, University of Illinois 
at Chicago Circle Abstract Home computer users are just now discovering computer graphics. Modest extensions 
to BASIC al- low plotting but not much more. The Bally Home Library Computer, however, has hardware to 
aid im- plementation of video games. Custom integrated circuits working on a 160XI02 pixel (2 bits per 
pixel) color television screen allow certain forms of animation in real time. To give this power to the 
user, BASIC Zgrass has been designed and im- plemented. It is an extension of BASIC that al- lows parallel 
processes, picture objects that move, scale and group together as well as several drawing modes. There 
are also software controls of a three-voice music synthesizer, interactive input devices, a film camera 
and an IEEE bus in- terface. We will concentrate mainly on the language design for making it all easy 
to learn and use. Content Indicators 1.51, 1.52, 2.12, 3.41, 3.44, 3.80, 4.13, 4.22 Keywords: interactive 
computer graphics, in- tepreters, real-time, graphic language, art Introduction and General Motivation 
 Zgrass can be called an immodest extension of BASIC (Ted Nelson refers to it as "Super BASIC" [I]}. 
It is an extension in that graphics support and user instruction facilities have been added to the capability 
of running BASIC programs copied out of a hobbyist computer magazine. It is immod- est in that great 
liberties have been taken to weed out some of BASIC's undesirable programming conventions. Zgrass is 
actually a video game pro- gramming language designed specifically to en- courage creation of beautiful 
animations in short order. It is also designed to teach many of the important concepts of interactive 
systems and 2-D computer graphics. The hardware used is the Bally Home Library Computer built around 
the Bally Arcade unit. It is a Z-80 based machine with special integrated circuits which help the processor 
manage the 160xi02 2-bit-per-pixel color output connected to any standard color tv set. The alphanumerics 
gen- erated by program output and keyboard input are video mixed over the color graphics so text is not 
constrained to the 160xi02 format. The two bits in each pixel indicate one of four bytes from which an 
index into a 256-element color map is taken. Thus, four of 256 colors can be on the screen at once. The 
hardware also includes some tricks which have been found useful in professional video arcade units, 
its projected cost, without color tv, is about $750.00, including the arcade unit. Zgrass itself takes 
up 16k bytes of ROM storage and has 16k bytes of RAM for user storage and system use. An additional 
16k ROM (referred to as the 'extension' below) plugs into the side and provides room for a compiler and 
other features. Audio cassette storage and modem link- age to other computers is provided. Software for 
driving optional intelligent floppy disk drives is also built-in. Further hardware in this unit in- cludes 
four hand controls, a 24-key pocket calcu- lator keyboard, a three-voice sound generator and an IEEE 
Bus interface. Zgrass is the operating system for this computer as well. Zgrass design concepts are 
rather different from those apparently underlying the current batch of home computer systems. Home systems 
are now trying very hard to be cheap minicomputers for ex- pert users. These users when at home can 
be likened to the ham radio operators of the nineteen fifties, able to change diodes, violently shake 
intermittent boards and, in general, understand the innards. These persons can also get gratifi- cation 
from fighting with manuals and the trials of the latest software release, just as we profes- sionals 
do for a living. Zgrass, however is designed for the two- hour-a-week user. This type of person is guaranteed 
to continually forget the syntax and semantics of whatever software exists. Zgrass is designed (certainly 
at the cost of computer time and memory use) so the user does not have to rely on a manual to decipher 
everything. In short, this system is trying to be the Model T of the home computer industry, with all 
that implies. We shall see. Above all, Zgrass is designed to be as at- tractive and as fun as pinball 
but considerably more intriguing and useful. General Zgrass Concepts "Right away" is the foremost design 
concept of Zgrass. Positive experiences in the first two hours of play are essential. When it is not 
part of your job or intended career, you must be able to do interesting, beautiful things right away, 
without reading a five-pound manual. BASIC is now the home computer language. BASIC was designed as 
a teaching language and shines in its simplicity and easy matrix opera- tions. It is, however, a poor 
language for the 33 manipulation of anything but numbers. It has no features that make writing large 
progams (over 200 statements) easy. Its subroutine capability is archaic. But, it is obviously a success 
in what the designers intended, otherwise it could not presently be the universal home computer language. 
 In particular, though, BASIC is a poor language for animation. To be sure, plotter art and decaying 
sine curves are well suited to BASIC. But our almost eight years of experience with the GRASS language[2] 
and Dan Sandin's color video Im- age Processor[3] as well as being directly or in- directly involved 
with roughly half of the most popular arcade video games, has given us insight into the potenti~± of 
a color tv set, and you just cannot do a tv set justice in BASIC. The next several pages will give details 
on syntax of Zgrass, but first we will further con- sider the "right away" criterion. Anyone who al- 
ready knows BASIC should be able to write Zgrass programs immediately. For those persons in Ameri- ca 
who do not religiously read "BYTE" or "Creative Computing" (a sizable part of the population), we have 
been developing self-paced instructional software for Zgrass. The prototype system now functions quite 
well in GRASS (see paper by Towle and DeFanti, these proceedings). Both GRASS and Zgrass have enough 
supervisory functions and error trapping features to allow a good programmer/educator to write programs 
which exe- cute and verify instructional programs written by beginning students. We feel that the chief 
prob- lem in teaching programming is that it, as an ac- tivity, is poorly simulated by the examples and 
the Backus-Naur-type syntax information usually found in manuals. Normal programmers have fellow workers, 
consultants or at least other students around to help out. The home user has no such recourse. The essence 
of the teaching problem stems from the fact that novices have tremendous prob- lems with meaningless 
(to them) error messages. You really have to know nearly everything about a system before you can start 
knowing why what you have typed does not work. This is absolutely not an overstatement of the problem. 
 All this commentary leads directly to comput- er aided instruction. While CAI has not quite lived up 
to its expectations for teaching other subjects, it can be used to teach people how to program. It is 
rel~tively straightforward to lead the user through commands, interactively teach looping concepts and 
verify the results of care- fully chosen problem sets. All possible errors can be trapped and explained 
in detail. Our ex- perience with this type of teaching is very supportive--non-programmers (primarily 
art stu- dents and a few university officials) can be doing fascinating graphics of great beauty in half 
an hour. The whole process has the feeling Of a game and is consistently rewarding. Providing internal 
system support for these teaching programs is no doubt the second most important design concept of Zgrass, 
after "right away" of course. Note that few (if any) programming languages allow you to write programs 
to interactively teach programming. Smalltalk[4] and Logo[5] teach by user experimentation in surroundings 
not lacking professional help. Plato[6] has no student pro- gram or storage space (only authors can write 
and store TUTOR programs). One could probably design some CAI programs in Snobol or Lisp but these are 
hardly languages for novices and they are not known for their lucid error message handling, or availability 
on micros. Perhaps a graphics- extended APL might do. It would be wonderful if the experience with Zgrass 
encouraged others to design extensions to languages with teaching in mind. Zgrass Technical Details 
 Zgrass is an interpreter of commands and as- signment statements stored internally as ASCII strings. 
These strings may be entered and execut- ed line by line, formed into programs (called "macros"), edited, 
and even built and pulled apart by string manipulation primitives. (A compiler which eliminates most 
of the interpretive overhead and which takes better advantage of the resident hardware floating point 
unit is part of the 16k extension ROM.) We are determined to maintain compatibility with at least TINY 
BASIC (it is hard to say what "standard" BASIC really is). Since BASIC has line numbers, Zgrass labels 
must start with a number (e.g. 100, 1obekenobe, 707crash, etc.). A BASIC program copied out of "BYTE" 
would simply have a lot of extraneous labels. Labels in Zgrass are obviously not used to order and edit 
the state- ments as in BASIC since one would hardly like to have alphabetically ordered labels and Zgrass 
has a good on-screen editor anyway. Our definition of compatibility is r~stricted to executing perfect 
programs written in BASIC. Getting them in, edit- ing, executing and debugging them is done dif- ferently. 
 Commands are made up of a keyword followed by zero or more operands. Examples of commands are: goto 
4jail move deathweapon,xl,yl clear input dea,fbi,c print beep,"who loves ya, baby?" (some of the 
more idiosyncratic BASIC commands, notably "if" and "for" have their peculiar syntax retained for compatibility). 
 Commands are gentle to users. If not enough arguments are supplied, if an incorrect argument is given 
or the argument is non-existent, a spe- cial error fixup routine is entered. This routine prints out 
the command in error, points at the ar- gument in error and says, for example, "NO! this command wants 
a variable name here." The user can then type in a correct argument and the command goes on. He can 
also elect to enter command mode to create a missing name, for example, and then resume the above process. 
All this will happen whether commands are entered line-by-line or exe- cuted as part of a macro. Note 
that all commands are more or less self documenting. You can type the command name and it asks you 
for the operands. This error facility allows one to get by trivial syntax errors without constant re-editing. 
It is also a sloppy way to get input to macros, although there are several conceptually clearer (to 
computer folk) ways. Many commands have options indicated by post- fixing the command name with a hyphen 
plus a modifier (e.g. "input-string" which can be shor- tened to "in-str" or even "i-s"). The hyphenated 
option construction is more English-like than 34 single-character switches and it helps keep down proliferation 
of command names. Since every command has an internally stored list of what argument types it wants, 
the "help" command can easily print these out with options (there are about 20 different argument types 
in Zgrass, like number, string, expression, picture prototype, array and so on). Further syntax and semantic 
information is available in the manual Macros Any string can be executed in Zgrass. If it contains 
meaningful commands, it can be used as a program. Again, programs in Zgrass are called "macros." Macros 
can call other macros, call them- selves, execute in foreground or in parallel with other macros in the 
background, supervise other macros and interact with macros running on other but the information you 
need most often is at your fingertips "right away." A few more details about variables are neces- sary. 
Variable names (macros are actually string variables) can ~e any length and must start with an alphabetic 
character. Variables used as macros may not have names ~hich conflict with system names. Global variables 
start with lower case letters and local variables start with upper case letters. The system decides whether 
a variable is a numeric or string variable by examining the con- text in which it is first used. (Commands 
are terminated by semicolons or carriage returns. The alphanumeric generator which is video mixed over 
the color graphics or routed to a separate monitor puts up sixteen 32-character lines. The alphanumeric 
handler au- tomatically folds lines over 32 characters long for display purposes but does not insert 
a car- riage return. A special character indicates folded lines.) Arithmetic statements are similar 
in format to assignment statements in BASIC or FORTRAN, with the exception of the left arrow used. The 
parser automatically changes equals signs (which are used for conditionals) to left arrows to maintain 
com- patibility with BASIC yet allow a sophisticated expression evaluator to operate unambiguously by 
not having to deal with multi-purpose operators. Examples of arithmetic assignment statements are: abc~sin(argl)+cos(arg2) 
babarum@1.2 c~whodunit(f,g,huh) where the last example contains a user-defined function (a macro, of 
course). Numeric variables are kept in fixed or float- ing point by the system, switching mode as neces- 
sary without user knowledge. The luxury of a floating point arithmetic unit helps calculation speed considerably. 
There are also reserved sys- tem variables which hold the values of the hand controls, keypad keys, 
external I/O strings and other special things. Strings are assigned as follows: tom~'this is a single 
line" sam@tom&#38;tom&#38;babarum ;.concatenat er~' ' ;.to enter a carriage return mymacro@<print tom,cr,tom," 
again" stuff~hello> ;. stuff gets "hell~ for a=1 to 10 print stuff,a next a> The last example shows 
nested assignments and a way to create a macro. Note that acceptable string delimiters are ",',<,>,[, 
and ], the last four of which must be balanced. String decomposi- tion is handled by a variety of string 
commands in the 16k extension. Zgrass machines. Zgrass differs from BASIC greatly when it comes to 
subroutine linkage. Zgrass has a very convenient and conceptually clear way of passing arguments--you 
simply make believe the macro is a command and use standard command syntax Further- more, the "input" 
command (for numbers) and the "input-name" and "input-string" commands (for strings) fetch the arguments 
passed in a way that automatically request user input from the terminal if not enough arguments are passed. 
This linkage is discussed in more detail below Looping and control transfer is done with "goto," "for/next" 
and "gosub." (Gosub is re- tained for compatibility.) A version of goto called ',skip" has the option 
of jumping relative a number of lines, a good feature for those quick loops in which you forgot to put 
the label There is also a "return" command which can pass an argu- ment back if it is a function call 
like "whodun- nit" above. When a macro is asked to execute (by typing its name as the first thing on 
a line, like a com- mand), the system builds a macro invocation block (MIB). The MIB holds information 
about local variables, for/next blocks, argument and data lists and so on. When the macro is done, the 
MIB is deleted along with all the pieces hanging off it. The storage allocation/reclamation algorithms 
used are again similar to GRASS's. Numeric arguments are passed using the "in- put" command. It is similar 
to "input" in BASIC but it first checks the argument list. If there is an argument, it is grabbed. Otherwise, 
the user is requested to enter the value. Input works in concert with "print" which supresses output 
when arguments are present. (Of course, there are op- tions to input and print which force terminal I/O.) 
Thus, a macro that has lots of prompting in- formation can be called by another macro without all sorts 
of editing to remove the prompts, but the macro will wake up and start asking questions if not enough 
arguments are supplied. One can create self-documenting macros which are effi- cient, yet help out when 
necessary. (How many times have you forgotten the arguments to a subroutine?) The "input-name" command 
functions similarly for strings and is used to get names passed as ar- guments. You use the "@" operator 
to indirectly reference strings. For example: getandmove@<lagain print "gimme a pixname" inp-name gettemp 
;.get name if gettemp='',return ;.if null, return get-tape @gettemp ;.get it from tape move @gettemp,x3,Y3 
;.attach control3 display @gettemp ;.and show it goto lagain> getandmove apple,witch,~itles,, 35 where 
the last line is the call and the lines course, there can be maDy prototypes floating above are the 
macro definition presumably entered before the call. Comments are lines or sub-lines which start with 
a " " The "input-string" command expects string delimiters around arguments passed so that whole commands 
can be arguments (you cannot pass a comma with the input-name option). This is important for the construction 
of teaching and verification pro- grams, among other things. If the argument is not there, input-string 
will require input from the keyboard, but without the string delimiters, just like input-name. The principle 
here is to make macros look like system-defined commands as much as possible, a rather loose definition 
of extensibility, but one that is meaningful when speaking about inter- preters (a conclusion adapted 
from comments in [7]). Picture and Pattern Drawing Zgrass has several predefined variables which cause 
drawing on the screen when they are written into. To display a point, you set variables xs and ys to 
the x and y coordinate. When you set variable cs to a value from one to four, the point is displayed 
with the color value indicated by the value of cs. There are also the "line," "box," and "circle" commands 
which draw vectors, and filled rectangles and ellipses on the screen. Picture Animation Once a picture 
is drawn on the screen, all or part of it may be stored as a picture prototype with the "snap" command. 
Picture prototypes are pixel lists in this case and are kept in user 16k RAM rather than in the screen 
4k RAM. So, a pic- ture is something you see on the screen and a pic- ture prototype (or "prototype" 
for short) is its representation in user memory. One then attaches the prototype to a vari- able, time-based 
variable (a user-defined special variable whose value varies automatically over a given time period), 
hand control, or user-defined function. The prototype is displayed with the "display" command. After 
that, anytime the vari- able or function changes, the prototype will be erased with an "exclusive or" 
write and rewritten with its updated translation or other transforma- tion with an "exclusive or" write. 
This technique lets pictures of one color pass over pictures of another color without leaving holes (using 
stan- dard bit plane raster scan graphics techniques). There is an interrupt level routine which manages 
movements of prototypes and a host of other de- tails, along the lines of a conventional refresh graphics 
driver. The user has a simple way to in- dicate wha~ maximum percentage of time should be allocated 
to interrupt level updating, the rest being left for command processing. The same interrupt routine 
also manages pic- ture prototype lists made up of lists of points, vector endpoints, box and circle drawing 
informa- tion. With the 16k extension, rotation and scal- ing of these lists is possible. Prototype lists, 
of course, have to be built up rather than snapped using options to the line, box and circle com- mands. 
The user can access individual endpoints and manipulate the prototype as a whole. Of around at once. 
 Again, the user's aesthetics and perceptions are essential. Since everything is real-time (or close 
to it) the user can easily see the effect of various commands on the screen, the implications of varying 
amounts of interrupt processing time, the ways of using different colors, and so on. Prototype lists 
and patterns can be grouped into a tree structure which allows concatenation of transformations. Moreover, 
the "select" com- mand specifies a sequence of pictures to be put up and erased in round-robin fashion 
(imagine several views of a walking "man" being switched to provide the illusion of walking). A simple 
Super 8 camera hookup ailows more complex, synchronized sequences to be filmed, if desired. Conclusions 
 Zgrass is designed to be a first programming language which encourages both novices and experts to learn 
about color graphics, generate meaningful and pretty displays, possibly make Super 8 movies, and perhaps 
even access governmental databases and control electric train sets. The software is designed to be multi-leveled 
and rich with feed- back. Considerable research into the teaching as- pects has been folded into the 
design. Continuing developmental elfort along these lines now concerns higher resolution displays, much 
faster mfcroprocessors, parallel programming techniques and connection to videodisks and other television 
equipment. Zgrass is one way you can control the amount of sex and violence on your tv set. References 
 [1] Nelson, Ted, The Home Compute__rr Revolution, 1977, p. 79. [2] DeFanti, T.A., "The Digital Component 
of the Circle Graphics Habitat," Proc. NC_~C, 1976. [3] DeFanti, T.A., Sandin, D.J., and Nelson, T.H., 
"Computer Graphics as a Way of Life," Computers &#38; Graphics, Vol. I, No. I, May 1975. [4] Goldberg, 
A. and Kay, A., Smalltalk-72 Instruction Manual, Xerox PARC #ss176-6, March 1976. [5] Papert, Seymour, 
A Computer Laboratory for Elementary Schools, Logo Memo I, MIT Artifi- cial Intelligence Lab, October, 
1971. [6] Alpert, D., and Bitzer, D., "Advances in Computer-Based Education, Science, Vol. 167, March 
1970. [7] Feldman, J.A., "Proceedings of the Extensible Languages Symposium," SIGPLANNOTICES, Vol. 4., 
No. 8., August 1969. Addendum: Zgrass Command List (in addition to BASIC) (The commands beginning with 
a '*' are in the 16k extension.) (Not all options are indicated.) 36 command name function box draws 
a rectangle on the screen &#38; select causes picture prototypes to be has options for building picture 
switched round-robin fashion on prototype lists the screen *change circle clear changes t~e values of 
an endpoint in a picture prototype list draws an ellipse on the screen &#38; has options for building 
picture prototype lists clears the screen snap sync takes a screen image in rectangu-lar bounds and makes 
it into a movable picture prototype tells the system how much time to devote to interrupt-level updating 
versus command processing *close colors closes off an open picture proto-type list chooses 4 colors of 
256 for screen *rip allows a macro to be executed at interrupt level (stands for "very important program") 
use *compile compiles code for speed copy makes a copy of a picture proto- type with a new name delete 
deletes and reclaims storage of a named thing display causes a picture prototype to be exclusive or'ed 
onto the screen and be updated when necessary *film sets up filming mode for a Super 8 camera *fetch 
retrieves a given endpoint in a picture prototype list get gets a macro, array, picture pro- totype list, 
etc. from tape, disk, etc. group collects picture prototypes into a group which can be referenced with 
a single name. Transformations may be done to the group as a whole or to individual members. help prints 
commands and required argu- ment types ieee provides interface to IEEE bus input used to input numbers, 
strings from terminal or passed argument lists line draws a vector &#38; has options for building picture 
prototype lists memory gives a usage map of memory move attaches a picture prototype to two variables, 
devices, etc. so that when they change, the proto- type is automatically erased and redrawn in the new 
position with options for "exclusive or" or "load/store" read and write to screen *onerror traps errors 
to a user's routines *open allocates storage and starts up a picture prototype list *pattern allows a 
pixel list to be directly built rather than snapped play interprets a string, array or pic- ture prototype 
as a musical score to be played by the three-voice synthesizer put stores a macro, array, picture prototype 
list, etc. on tape, disk, etc. rename renames a named thing to a new name *rotate like move but the prototype 
is ro- tated *scale like move but the prototype is scaled 37 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807367</article_id>
		<sort_key>38</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Definition and use of higher-level graphics input tools]]></title>
		<page_from>38</page_from>
		<page_to>42</page_to>
		<doi_number>10.1145/800248.807367</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807367</url>
		<abstract>
			<par><![CDATA[<p>A proposal is made for the definition of 'tools', high-level graphics input functions based on the six primitive input classes Clock, Pick, Button, Key, Valuator and Locator.</p> <p>Tools are defined in terms of input expressions, the operands of which are themselves tools, the definition of which may be nested inside this tool. Input expressions are written much like production rules in phrase structure grammars. Determining whether a tool is 'satisfied' can therefore be done most advantageously by an input expression parser.</p> <p>Tool definitions may occur in-line or stored in a library. They are activated by a 'create' primitive, which creates an instance of the tool and causes the input expression to be made active. The parser then determines whether a tool is actually used. Following a 'read' issued to the tool, the tool body generates the returned information as specified by the tool definition. Tools may be explicitly freed by a 'free' primitive; in the case of nesting, tools are freed implicitly when the surrounding tool is freed.</p> <p>Using this approach to higher-level input primitives, a programmer does not have to think about graphics input in terms of awaiting events, interrupts and the like. The creation of a defined tool implies a function awaiting action from the tool.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Graphics input]]></kw>
			<kw><![CDATA[Graphics tools]]></kw>
			<kw><![CDATA[High-level input tools]]></kw>
			<kw><![CDATA[Input devices]]></kw>
			<kw><![CDATA[Interaction]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Input devices</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010391</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics input devices</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Languages</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P331278</person_id>
				<author_profile_id><![CDATA[81100632326]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jan]]></first_name>
				<middle_name><![CDATA[Van den]]></middle_name>
				<last_name><![CDATA[Bos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Information, University of Nijmegen, Nijmegenm The Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Newman, W.M., A system for interactive graphical programming, Proc. AFIPS SJCC, Vol. 32, 1968, pp. 47-54]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cotton, I.W., Network Graphic attention handling, Proc. ONLINE 72, 1972, pp. 465-490]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Foley, J.D., and Wallace, V.L., The art of natural man-machine communications, Proc. IEEE, Vol. 62,4, 1974, pp. 462-471]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>988659</ref_obj_id>
				<ref_obj_pid>988655</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Deecker, G.F.P., and Penny, J.P., Standard input forms for interactive computer graphics, ACM-Siggraph Computer Graphics, Vol. 11,1, 1977, pp. 32-40]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563739</ref_obj_id>
				<ref_obj_pid>964963</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Trambacz, U., Towards device-independent graphics systems, ACM-Siggraph Computer Graphics, Vol. 9, 1975, pp. 49-52]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>804734</ref_obj_id>
				<ref_obj_pid>800143</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Wallace, V.L., The semantics of graphic input devices, Proc. ACM-Siggraph, 1976, Miami, Fla, USA, pp. 61-63]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[ACM-Siggraph GSPC, First report on graphics standards, Proc. ACM-Siggraph, 1977, San Jose, Cal., USA]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Caruthers, L.C., Groot, D., Hermans, E., Van Dam, A., and Van den Bos, J., GPGS - General purpose graphic system, Proc. ACM - International computing symposium, 1977, Liege, Belgium, pp. 411-416]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563878</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Caruthers, L.C., Van Dam, A., Van den Bos, J., GPGS- A device-independent general purpose system for stand-alone and satellite graphics, Proc. ACM-Siggraph, 1977, San Jose, Cal., USA, pp. 112-119]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Habermann, A.N., Path expressions, Computer Science Report, June 1975, Carnegie-Mellon University, Pittsburgh, Pa., USA]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>1243380</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Dahl, O.-J., and Hoare, C.A.R., In Structured Programming, Academic Press, New York 1972, pp. 175-220]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Anson, E.K., GPGS-370 Tektronix driver installation, July 1976. Informatica/Comp. Graphics group Internal report.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 D~INITION AND USE OF HIGHER-LE91~ GRAPHICS INPUT TOOI~ Jan van den Bos Informatica,Uhiversity of Nijmegen 
Nijmegen ,The Netherlands ABSTRACT A proposal is made for the definition of 'tools', high-level grai~%ics 
input functions based on the six primitive input classes Clock, Pick, Button, Key, Valuator and Locator. 
Tools are defined in terms of input expressions, the operands of which are themselves tools, the definition 
of which may be nested inside this tool. Input expressions are written much like pro- duction rules in 
phrase structure gr~. Determining whether a tool is 'satisfied' can therefore be done most advantageously 
by an input expression parser. Tool definitions may occur in-line or stored in a library. They are activated 
by a 'create' primi- tive, which creates an instance of the tool and causes the input expression to be 
made active. The parser then determines whether a tool is actually used. Following a 'read' issued to 
the tool, the tool body generates the returned infonmation as specified by the tool definition. Tools 
may be explicitly freed by a 'free' primitive; in the case of nestin% tools are freed implicitly when 
the surrounding tool is freed. Using this approach to higher-level input primi- tives, a programmer does 
not have to think about graphics input in terms of awaiting events, inter- rupts and the like. The creation 
of a defined tool implies a function awaiting action from the tool. Keywords: cc~m/ter graphics, graphics 
input, high-level input tools, interaction, input devices, graphics tools CR category: 8.2 i. INTRODUCTION 
 The sheer ntm~er and variety of input devices in interactive ccm~uter graphics for a long time has bewildered 
builders of graphics languages and subroutir~ packages, and theoreticians alike in their attempts to 
fonna11 ze and classify the specification and handling of these devices. Several papers [ 1,2,3,4,5] 
have more or less succesfully tried to create same order in this chaos. It was also recognized fairly 
early that in order to make a graphics application downward ccmpatible, here meaning that it would run, 
per- haps with some awkwardness, on a simpler display station than for which it was originally written, 
graphics should either support only a minimally equipped device or allow simslation of tools on insufficiently 
equipped displays [5] . Because of this lack of fozmalization of basic input tools very few papers deal 
with the subject of higher-level input primitives [ 6] . The state of this discussion is reflected by 
the point of view ~opted in the status report presented by the Graphics Standards Planning Committee 
(GSPC) [7]. As far as input devices are concerned we find here a division in event and sa~plir~ tools. 
The event class oonl-alns the Pick (lightpen), Button (pro- grammed function Key) and Keyboard (alphanumeric 
keyboard), the ssarpling class consists of Locaters (cursors, trackers) and Valuators (dials, poten- 
ticmeters). The report offers a modest step to- wards higher-level input functions through the association 
mechanism. How~_r this facility does not offer a naming facility. It only provides for associating primitives 
in pairs: we are given the opportunity to construct our own tools via this extension mechanic. The GSPC 
report also makes a start about the simulation of tools but offers no mechanism to do so - presumably 
the simulation has to be provided by the input device driver, as is done for instance in the graphics 
system GPGS [ 8,9] In this paper we offer proposals regarding the following issues: -Basic primitives 
and information returned -Notaticn used in defining tools -Creating, reading and freeing tools -Further 
notation and properties of tools -Input tool libraries and simulation. 2. PRIMITIVE INPUT FACILITIES 
 There are several ways to classify basic input devices. The GSPC report canes close to accepted practice 
and we will therefore adopt its approach for the follc~ring tools: Pick, Button, Valuator, and Locator. 
Instead of Keyboard,which is not a primitive at all, we propose a new primitive named Key, an input device 
represented by a single alpha- ntm~ric key hit. We also introduce the basic tool Clock, with a single 
parameter 'time'. This func- tion simply delays the progran for an interval 'time' after which the program 
resumes processing  at the next statement. This tool frequently pre- cedes sarmpling, or other actions 
that have to be performed at specified intervals. Also needed as shown later for ~ite tools is a so-called 
Escape tool. This is a tool defined by the user for the purpose of cancelling preceding actions. This 
adds up to 7 basic tool classes re- 38 turning standard informatien as listed in Table I. For the lightpen 
this information depends On the naming conventions for output primitives. We have followed the GSPC report 
which defines a two-level output hierarchy, namely na~ed picture segments (segname) ccnsisting of named 
primitives (pickid). There is hc~ever no problem in adopting other naming conventions. device info 
returned Clock -> real time Pick -> string segname, int pickid Button -> int buttonnr Key -> char c 
Valuator -> real or int v Locator -> real or int x,y(,z) Escape -> void Table I Basic Input TOols  
We further make a distinction between event devices (Clock,Pick,Button, and Key), and sampling devices 
 (Valuator and Locator). If there are more devices than c~e in a particular class X we denote them by 
XI,X2,... Diffez~nt frcm the GSPC report, a c~mplete tool may be defined by the tool class and the infozmatien 
returned. For example Button stands for any button, but Button(9) stands for button 9, Pick("menu",5) 
stands for the lightpen pointing in picture segment "menu" at the picture element named 5, Clock(60) 
denotes an inter- val of 60 timer units (say seconds), etc.  3. NOTATION TO DEFINE TOOLS We define 
a tool as a logical input device, which upon activation, returns information; it my also influence the 
status of the (graphics) program in- directly through side-effects. Our notation is based on the notation 
for path expressions [ I0] and the 'class' construct of Si~ula [ ii] . A tool definition consists of 
a na~, fozmal paraneters (optional), one input expression, a returns expression (optional), an opticnal 
tool body consisting of nested tools, stat~nents, and local procedures, and finally an optional initialization 
statement. An input expression starts with the reserved word input, it is followed by an input rule 
and ends with the reserved word end. An input rule consists of one or more operands. The operands of 
the input rule are themselves tools, i.e. functions or procedures which produce sane result depending 
on the values of the (graphical) input paraneters. The operands in an input expression may possess a 
parenthesized list of returned values (attributes). For simple input expressions there are 3 operators: 
 * ; + in order of precedence. Braces { and } may be used to override this precedence. The operator * 
is the Kleene star. It is used as a unary postfix oper- ator indicating that the operand my he executed 
zero or more times before going on to the next operand. The ; operator is the sequencing operator: a;b 
means that a has to cxmplete before b starts. The ; operator may be cr~itted so that one may write ab 
instead of a;b. The + operator represents exclusive selection: a+b means that either a or b, but not 
beth, must be executed before proceeding. The returns expression starts with the reserved word returns, 
followed by the types and names of the values returned, and ends with end. The values may be directly 
produced by the operands of the input expression or by the local tools or proce- dures. The fonm~l 
parameters allow copies of the tool with differing properties to be made. If nested tools appear they 
must be referenced frcm an input expression at a higher-level. Local pro- cedures fulfil the nonmal subroutining 
require- ment. The scope of the procedure extends from the current to lower levels. In this concept 
of tool, the central role is played by the input expressions. There is a strong resen- blance between 
a tool definition in tess of an input expression and a production rule in grammars, as for instance in 
~NF notation for context-free gr~. A tool is activated when the syntacti- cally correct input sequence 
is present. Since nonmally a number of tools have been defined and created (see below) there also exists 
a ntm~er of inp/t expressic~.s. Any input symbol of an input sequence will have to be matched by a parser 
against the active input expressions. An input se- quence is syntactically correct when it matches one 
of the outstanding input expressions. Just as with language parsers anbiguities may occur. Al- though 
these could be flagged by a compiler they are not always semantically incorrect because of the fact that 
input expressions are only made ac- tive at execution time. Different from 'nozmal' language grSalwars, 
the parser has to make a distinction between event and sampling devices. A tool is an event device when 
 at least one ic~r-level event tool occurs in an input expression, otherwise it is a sampling tool. 
 If a sampling operand occurs in an input expres- sion, the parser will always satisfy it, that is 
sanpling will always occur, provided that the ssm~pler is active (created). It is ini0ortant that a 
positive partial match of an input symbol (event or sample) is acknowledged graphically. Also a negative 
echo (such as a ques- tion mark) in a situation of no-match will be a timely indication to the user that 
he is on the wrong track. If a user halfway in an input sequen- ce decides to cancel the entire sequence, 
he does so by activating the Escape tool. He should have defined this tool earlier (preferably at the 
global level) in ~ of some existing tool, e.g. tool Escape = input Pick ("menu",cancel) end end Escape; 
 A few simple ~les may aid in understanding the concept of tool. First, we define a basic tool, e.g. 
a Locator, as follows: tool Locator = input Locator end returns real x,y end end Locator  AS (me 
sees, the only thing that this definition accfmplishes is to indicate type and name of the values returned. 
It is assumed that the definition of Locator is in fact done in a prolog to the gra- phics program. AS 
such this notation appears to be somewhat verbose and may therefore be replaced by the shorthand fonu 
 tool Locator(real x,y) end  If no naming conflict occurs the real variables may be referred to as x 
and y, otherwise the qualified nanes Locator.x and Locator.y must be used. One should also realize that 
toolnanes such as Locator, Button, etc. may be redefined. At the level (e.g. a block) where this happens 
this has the in~plication that the basic tool with the sane name is no longer available. The shorthand 
mechanism may be used for all tools that have been previously defined. In the next example we first 
define the basic tool Key, then we use this tool in a ccn~posite tool that returns a random number. 
tool Key = input Key end return8 char c end end Key; tool Randcm(real first) = input Key("R")+Key("r") 
end; returns real rand end; real seed; rand:=randGm (seed) ; comment randem is a function returning 
 a randem integer; init seed :=first end Random; The tool works as follows: If either "R" or "r" is 
depressed on the alphanumeric keyboard the proce- dure random is called. The resulting value is re- turned 
in rand. When the tool is created (see be- low) an instance of tool Random is created (pro- vided tool 
Key exists' ) and through the init sta- t~nent seed is initialized. 4. INVOKING AND FREEING TOOLS The 
previous section dealt with the definition of tools in general, but a definition does not con- stitute 
a tool itself. It merely defines a data structure and the operations allowed on this data structure. 
Optimally, internal details should be hidden from the user of the tools, so that he need only be aware 
of the tool interface, that is given same input the tool will produce sane output value or function. 
 Four primitives control the dynanic use of tools, nanely create, read, cleanup, and free. create creates 
an instance of the tool, executes the init statement, and activates the input rule. create operates 
implicitly on embedded tools; read reads the tool infomnation by activating the rejoin8 statement in 
the tool definition. If no tool information is present it waits until the tool produces it following 
user input actions; it therefore also serves as a synchronization primi- tive. It returns following 
the execution of an implicit or explicit cleanup; cleanup tezminates the reading of the to01 , and 
 re-executes the init statement, so it serves as a tool return statement. It therefore is present in 
all tool definitions with the exception of tools which do not contain nested tools, e.g. basic tools. 
When this primitive is executed on an outer tool, all inner tools are also terminated and re- initialized. 
It does not destroy the instance of the tool; free de-activates the input rule, frees the tool instance 
and the tool storage; however the tool definition r~nains in force. As an example we use the tool RandGm 
defined in the previous section to generate a vector, called  rn~nbers, of randcm ntmlbers: create 
choice := Randcm(l.0); for i to upb rnumbers do read choice; rnumber~i] := choice.rand od; free choice; 
 If a tool has no parameters we may use the nane of the tool itself, instead of assigning a reference 
to the tool instance to a variable, e.g. create Pick,Button,Keyboard. 5. ~ NOTATION AND EXAMPLES OF 
COMPOSITE TOOLS 5.1 NOTATION We may use the input expressions to define arbitra- rily ccmplex input 
functions. The functions named in the input expression are either tools defined at the sane or a surrounding 
block level in the program or else should be defined within the tool definition; in the latter case they 
can only be in- voked frGm within. Furthelu~ore a tool definition may use one or more global variables 
which have to be passed through a parameter list, as well as local variables. Tools may be defined inside 
other tools but then have a strictly local scope. ~Dre ccmplex input expressions may be fozmed with 
 the operators &#38;, >, and <. a&#38;b means beth a and b have to be perfozmed, but the order is irrelevant. 
 a>b means the same as a+b, but if a and b can both be executed then a takes precedence; the reverse 
 holds for the operator <. The &#38; operator has a higher priority than +, but < and > have the s~m~e 
 priority as the + operator. The operator ; is dis- tributive with respect to + &#38; < >. No other 
opera- tors have this property. Yet another form of input expression is the condi- tional expression: 
 [ <cond l>:<elernl>,<condZ>:<elem2> ..... <condn>: <elemn>,<elemelse>]  The conditional element is 
equal to the lefhnost element for which the corresponding condition is true, if none are true elemelse 
is selected. The elemelse part is optional.  5.2 EXAMPLES Example 1 In this example we construct a 
tool that generates n points for a spline curve, given arrays of x and y coordinates. The tool is to 
be activated by the lightpen pointing at an ip-menu item '* SPLINE' which has pickid=5 in segment 'menu'. 
Alternatively button 5 may be used to accc~iolish sane. The tool definition goes as follows: tool Spline([ 
] real xi,yi,int n) = input p+b end; returns [ ] real xs,ys end; tool p = input Pick("menu",5) end; 
if dim yi>2 then splinf (xi ,yi ,xs ,ys ,n) fi end p; tool b = input Button(5) end; if dim y~2 then 
splinf (xi,yi ,xs ,ys ,n)  fi end b; cleanup Spline end Spline ; Exa~ple 2 In this example we show 
the use of the Kleene star to define an input device 'keyboard' (often consi- dered to be a primitive): 
 tool keyboard = input s* < t end; returns string buf end; tool s = input Key end; returns char c end; 
end s; tool t = input Key(CR) end; cleanup keyboard end t; buf +:=c; init buf =-'' # initialization 
 end keyboard; The effect is that characters are collected in the keyboard buffer buf until a CR (carriage 
return) is detected, cleanup re-initializes all local va- riables. Example 3 The next ~le shows how 
to define a tablet with start and stop button. When button 9 is depressed the tool starts and will sample 
the pen coordina- tes of the tablet with interval 'time'. These coordinates are returned in xs and ys. 
Button i0 te2mdm~tes the tablet: tool tablet (real time) = input t > [ starts:s,g] ; returns real xs=Locator2.x, 
 y~Locator2, y end; bool start; tool s = input Button(9) end; start:=false end s; tool g = input Clock(t/me);Locator2 
end; end g; tool t = input Button(10) end; cleanup tablet end t; init start:=true # initialization 
# end tablet; Example 4 In the previous example we built a ccnposite tool that merely returned coordinates 
to the user. The following example (and exanple i) shows that these rather low-level returns may be replaced 
by high- level output functions. Here we build a tool that constructs a polygon on the screen by means 
of sampling a Locator device at intervals 'time'. The tool has two buttons, one to start drawing, the 
other one to stop drawing. tool Inline (string segnane, real time) = input t > [ start:s,g] end; bool 
start, open; tool s = input Button(9);Locator2 end; create segment (segnane) ; open : =true ; moveabs2 
(Locator2 .x,Locator2 .y) ; start :=false end s; tool g = input Clock(time);Locator2 end; drawabs 
2 (Locator2 .x,Locator2. y) end g; tool t = input Button(10) end; if open then close segment fi; 
cleanup Inline end t; init start:=true; open:=false ; end Inline create Inseg: =Inline ( "Poly", 0.5) 
; read Inseg; free Inseg   5.3 R~%~KS The mechani~n for defining and creating tools des- cribed sofar 
lends itself to a highly structured approach to graphics program design. The create primitive has reminiscences 
of the case statement in higher-level progranming languages. Each alter- native input sequence ~ong the 
allowed ones is spelled out in a tool definition statement. The definition itself may contain embedded 
definitions and creations, thus ensuring that in a particular branch (module) of a program only those 
tools are available that are desired. Using tools in this disciplined manner allows for careful control 
of side effects. Ideally a program starts with making an initial tool (something akin to an identity 
tool) available. This tool is activated as soon as the operator of the program carries out an initialization 
proce- dure. From then on the program enters one of the tools defined at a lower level and so on. In 
so doing a cc~olete program can be considered a tool with all desired actions prescribed within the tool 
definitions '. 6. TOOL LIBRARIES AND THEIR ~OLE IN SIMULATING ABSenT TOOLS Higher-level tools such 
as the ones defined earlier may in fact be of more general use. It is conceive- ble that some of the 
tools we defined, e.g. key- board and tablet, are used in many different graph- ics prograns. In these 
cases one could put the de- sired tools in so-called tool libraries. The mem- bers of a tool library 
are tool definitions either in source code or, more efficiently, in machine code. Tool libraries play 
a role analogous to macro libraries: whenever an undefined tool is referred to it is either in the 
tool library or it is a syntactic/semantic error. Tool libraries may also be used as private librar- 
 ies in order to keep user programs structured, un- cluttered and easily understandable. Just like 
subroutines and macros, tool definitions and espe- cially remote tool definitions enhance the modula- 
 rity of graphics programs. The tool library may also be used to simulate tools which are not present 
on the available display device. In this way one keeps the flexibility of a more powerful device without 
burdening the device driver with software for simulation. The following example shows the simulation 
of a lightpen for a device with at least 1 Button, a Keyboard, and a Locator. The tool uses the exter- 
 nally defined keyboard device (see Sec. 5 ex.2). tool P = input [ start:begin,get] end; returns string 
segname, int pickid end; bool start; tool begin = input keyboard end; if keyboard.buf="LP" or keyboard, 
huf=" ip" then start:=false fi end begin; tool get = input Button; Locater end; if find(Locator.x,Locator.y, 
segnane, pickid) # given x,y this rtn finds segname &#38; pickid of primitive # then cleanup P else 
create segment ("MSG"); moveabs2 (0.0,0. I) ; text ( "L±T~Iq MISS~" ) ; close segment fi end get; 
ini t start:---true end P; AS we see this tool P not only simulates the lightpen, it also issues a 
message in a situation of no-hit. The keyboard is not strictly necessary but entering the string "LP" 
(or "ip") makes the user more conscious of the fact that he is going to simulate the Pick device. This 
exanple paints an almost correct picture of the way GPGS [ 12 ] siu~lates the Pick on a storage tube. 
The signi- ficant difference is that there the simulation is part of the device driver and therefore 
rigidly fixed. In contrast our tool definition method gives the user cGmplete freedcm, yet allows same 
default simulation to be stored in the library. 7. GONCLUDING R~v~RKS Since the input device model 
described above is still in the proposal stage and although inlole- mentation has constantly played a 
role albeit in the background, no full impl~mentation has been considered yet. No great difficulties 
are anti- cipated implementing the tool definitions. Ho~ever issues of indeteamda~cy at the parser level 
have not been sorted out and are probably best avoided in a first inplementation. The implementation 
itself could be done via a preprocessor which translates our notation into a language such as Fortran 
or Algol68. Another way would be to use an extendable language such as Simsla or Algol68 to ini01ement 
our model as a language extension. Both these alternatives are attractive to us because we have GPGS 
[ 9] inter- faces to Fortran and Algol68 and could therefore implement our ideas in tezms of calls to 
a sub- set of GPGS routines. The third solution would be to build an interpre- ter or a compiler for 
our language. This would re- quire appreciably more effort in tezms of design and implementation. With 
regard to the advantages for the user of our notation, we hope that the examples and acccn~pa- nying 
remarks have given him a flavor of the method. We think that the notation proposed will allow for neatly 
structured prograns, not only at compile time but also at run-time. FrGm the structure of the program 
it will be imme- diately clear at what time which tools are active. By programming output functions as 
side-effects of tools it will also be clear what the results of the tools are on the display. Instead 
of using a rou- tine such as await event in GSPC [ 7] he now uses a more powerful and more concise combination 
of tool definition and creation. The power of the notation will allow the user to define highly ~site 
tools, yet treat them in the program as simple tools, thus considerably en- hancing his expressive power. 
 REFER~Km~ i. Newman, W.M., A system for interactive graphic- al programming, Proc. AFIPS SJCC, Vol. 
32, 1968, pp. 47-54 2. Cotton, I.W., Network Graphic attention han- dling, Proc. ONLINE 72, 1972, pp. 
465-490  3. Foley, J.D., and Wallace, V.L., The art of nat- ural man-machine ~cations, Proc. IEEE, Vol. 
62,4, 1974, pp. 462-471  4. Deecker, G.F.P., and Penny, J.P., StaDd~rd input forms for interactive computer 
graphics, ACM-Siggraph Ccmputer Graphics, Vol. ii ,i, 1977, pp. 32-40  5. Trambacz, U., Towards device-independent 
graph- ics systems, Af24-Siggraph Ccr~puter Graphics, Vol. 9, 1975, pp. 49-52  6. Wallace, V.L., The 
semantics of graphic input devices, Proc. AC~-Siggraph, 1976, Miami, Fla, USA, pp. 61-63  7. Af24-Siggraph 
GSPC, First report on graphics standards, Proc. AC~4-Siggraph, 1977, San Jose, Cal., USA  8. Caruthers) 
L.C., Groot, D., Hermans, E., Van Dam, A., and Van den Bos, J., GPGS - General purpose graphic syste~a, 
Proc. A<!M - Interna- tienal ccrnputing symposiam, 1977, Liege, Belgium, pp. 411-416  9. Caruthers, 
L.C., Van Dam, A., Van den Bos, J., GPGS- A device-independent general purpose system for stand-alone 
and satellite graphics, Proc. AflM-Siggraph, 1977, San Jose, Cal., USA, pp. 112-119  I0. Habezmann, 
A.N., Path expressions, CGmputer Science Report, June 1975, Carnegie-Mellon University, Pittsburgh, Pa., 
USA ii. Dahl, O.-J., and Hoare, C.A.R., In Structured Pregramling, Academic Press, New York 1972, pp. 
175-220 12. Anson, E.K., GPGS-370 Tektronix driver instal- lation, July 1976. Infozmatica / Ccr~p. Graphics 
group Internal report.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807368</article_id>
		<sort_key>43</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[A graphics-based programming-support system]]></title>
		<page_from>43</page_from>
		<page_to>49</page_to>
		<doi_number>10.1145/800248.807368</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807368</url>
		<abstract>
			<par><![CDATA[<p>A programming support system using extended Nassi-Shneiderman diagrams (NSD) is described. The aim of the work is to develop techniques for improving the quality and cost of specifying, documenting and producing computer programs. NSD's can be executed interpretively or compiled to produce running code. The system implementation has begun and charts can be drawn on a variety of display devices. The system is being developed using the Picture Building System developed earlier.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Interactive computer graphics]]></kw>
			<kw><![CDATA[Nassi-Sheiderman diagrams]]></kw>
			<kw><![CDATA[Program representation]]></kw>
			<kw><![CDATA[Structured programming]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>K.6.3</cat_node>
				<descriptor>Software development</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.2.3</cat_node>
				<descriptor>Structured programming</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.2.9</cat_node>
				<descriptor>Productivity</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.2.2</cat_node>
				<descriptor>HIPO</descriptor>
				<type>P</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10011007.10011074.10011092</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management->Software development techniques</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011074</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003490.10003503</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Management of computing and information systems->Software management</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003490.10003491</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Management of computing and information systems->Project and people management</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011074.10011081</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management->Software development process management</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011008.10011024</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->General programming languages->Language features</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011074.10011075.10011079.10011080</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management->Designing software->Software implementation planning->Software design techniques</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011074.10011075.10011079.10011080</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management->Designing software->Software implementation planning->Software design techniques</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Languages</gt>
			<gt>Management</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39076447</person_id>
				<author_profile_id><![CDATA[81100597796]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[H.]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Frei]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM, Research Division, San Jose, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39085195</person_id>
				<author_profile_id><![CDATA[81502770375]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Weller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM, Research Division, San Jose, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39065971</person_id>
				<author_profile_id><![CDATA[81467646466]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Williams]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM, Research Division, San Jose, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Boehm, B.W. "Software and its Impact: A Quantitative Assessment", Datamation, Vol. 19, No. 9, May 1973.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Chapin, N. "New Format for Flowcharts", Software Practice and Experience, Vol. 4 No. 4, Oct. 1974.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>1243380</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Dahl, O.J., Dijkstra, E.W., and Hoare, C.A.R. "Structured Programming", Academic Press, New York, 1972.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Fagan, M.E. "Design and code inspections to reduce errors in program development", IBM Syst. J., Vol. 15, No. 3, IBM Corporation, 1976.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Gewald, K., et al. "COLUMBUS - Strukturierte Programmierung in der Praxis", Elektronische Rechenanlagen, 19. Jahrg., Heft 1, pp. 30-34, Feb. 1977.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Jones, C. "Program Quality and Programmer Productivity", IBM Technical Report, TR 02.764, Jan. 1977.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>956645</ref_obj_id>
				<ref_obj_pid>956641</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Lindsay C.H. "Structure Charts - A Structured Alternative to Flowcharts", ACM SIGPLAN Notices, Vol. 12, No. 11, Nov. 1977.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>574884</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Martin, J. "Design of Man-Computer Dialogues", Prentice-Hall, Englewood Cliffs, N.J., 1973.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Mills, H.D. "Software Development", IEEE Transactions on Software Engineering, Vol. SE-2, No. 4, Dec. 1976.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Moorhead, W.G. "GXRAM, Relational Data Base Interface for Graphics", IBM Research Report RJ 1735, 1976.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>953350</ref_obj_id>
				<ref_obj_pid>953349</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Nassi, I., and Shneiderman, B. "Flowchart Techniques for Structured Programming", SIGPLAN Notices of the ACM, Vol. 8, No. 8, Aug. 1973.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Reaser, J.M., et al "A Production Environment Evaluation of Interactive Programming", National Technical Information Service, AD/A-006 502, Dec. 1974.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>362858</ref_obj_id>
				<ref_obj_pid>362851</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Sackman, H., Erikson, W.J., and Grant, E.E. "Exploratory Experimental Studies Comparing on-line an off-line Programming Performance", CACM, Vol. 11, No. 1, pp. 3-11, Jan. 1968.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Stay, J.F. "HIPO an integrated program design", IBM Syst. J., Vol. 15, No. 2, IBM Corporation, 1976.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>810742</ref_obj_id>
				<ref_obj_pid>800265</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I.E. "Sketchpad, A Man-Machine Graphical Communication System", Proc. Spring Joint Conf., pp. 329-346, Spartan Books, New York, 1963.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Urschler, G. "Automatic Structuring of Programs", IBM J of Research and Development, pp. 181-193, March 1975.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359368</ref_obj_id>
				<ref_obj_pid>359367</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Van Gelder, A. "Structured Programming in Cobol: An Approach for Application Programmers", CACM, Vol. 20, No. 1, Jan. 1977.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>61465</ref_obj_id>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Weinberg, G.M. "The Psychology of Computer Programming", Van Nostrand, New York, 1971.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563309</ref_obj_id>
				<ref_obj_pid>563274</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Weller, D., and Williams, R. "Graphic and Relational Data Base Support for Problem Solving", Proc. of Conf. on Computer Graphics, SIGGRAPH-ACM, Vol. 10, No. 2, 1976.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>362577</ref_obj_id>
				<ref_obj_pid>362575</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Wirth, N. "Program Development by Step-wise Refinement", CACM, Vol. 14, No. 4, pp. 221-227, April 1971.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A GRAPHICS-BASED PROGRAMMING-SUPPORT SYSTEM H. P. Frei D. L. Weller R. Williams IBM Research Division 
San Jose, CA. ABSTRACT PROGRAM REPRESENTATION A programming support system using extended Nassi-Shneiderman 
diagrams (NSD) is described. The aim of the work is to develop techniques for improving the quality and 
cost of specifying, documenting and producing computer programs. NSD's can be executed interpretively 
or compiled to produce running code. The system implementation has begun and charts can be drawn on a 
variety of display devices. The system is being developed using the Picture Building System developed 
earlier. KEY WORDS AND PHRASES: interactive computer graphics, Nassi-Sheiderman diagrams, structured 
programming, program representation CR CATEGORIES: 4.12, 4.13, 4.22, 4.33, 4.34, 8.2 It is our belief 
that what is needed is a total software support system along with a shift in emphasis in the software 
development process. The fact "that an application system is maintained indefinitely after a definite 
period of development" [MIL 76] as well as the tremendous decrease in hardware costs (along with increases 
in speed), should encourage one to choose reliability and maintainability as the dominant criterion rather 
than the more traditional execution speed when deciding on appropriate tools for software production. 
For example, it is much easier to speed up and optimize a neatly designed and reliable piece of software 
than to debug a fast running unstructured one. A total software support system must support the design, 
coding, debugging, maintenance, and documentation of software systems. THE SOFTWARE PROBLEM During 
the last decade software systems showed the tendency of growing drastically in both size and complexity. 
Frequently, the increased size and complexity result in software systems that are unreliable, error prone, 
and difficult to maintain. Also, studies by the U.S. Navy have shown that in the last 20 years the cost 
of software for hardware/software systems has grown from less than 20% of the total cost to more than 
75% of the total cost [BOE 73]. Many corporations have recognized the severity of this problem and have 
begun to study the software problem. Capers Jones [JON 77] reports the deplorable fact that in the 
traditional world of programming more than half of the total effort expended goes to defect removal activities 
in the forms of testing and post-release defect repairs. Mills mentions that "some 75 percent of data 
processing personnel are already taken up with maintenance, not development. And unless radical new 
methods are found, maintenance will go even higher in its demands and will very nearly stifle further 
development" [MIL 76]. Documentation also seems to be a problem since Capers Jones indicates that for 
a large system it would take someone one or two months just to read the documentation [JON 77]. Thus 
we conclude that there is a great need for a software support system, possible based on existing concepts. 
 Most of the new programming techniques, in the literature often referred to as "Structured Programming" 
[DAH 71] or "Modern Style Programming" [JON 77], can lead to better software development. These techniques 
include graphic design methods like HIPO and Nassi-Shneiderman diagrams (NSD), top-down and modular programming, 
and on-line development of programs. It seems to be proved that "Modern Style Programming" is considerably 
less expensive than "Old Style Programming". Capers Jones even claims that these methods reduce debugging 
and maintenance costs by over 50% [JON 77]. The problem seems to be supplying a programming support system 
that supports "Modern Style Programming" and maybe even disallows nonstructured methods. Graphical 
representations for design and implementation have been known to be of great value in engineering and 
many other fields. But many fields have an advantage over programming in that they have what could be 
called a "natural" graphical representation. By "natural" it is meant that the items of interest already 
have a two dimensional layout. For example, the formalism of schematic diagrams for electrical circuits 
just maintains the topology of electrical circuit connections without creating something new. Programming 
languages lack a "natural" graphical representation. Therefore an artificial graphical representation 
should be created that can be used for software design and implementation. Such a representation will 
undoubtedly facilitate the visualization of program structure making 43 understanding of the program 
easier. The consequence of this is that the programs will be easier to write, debug, and maintain. A 
number of graphical representations of programs have been used for a long time, but they have never, 
to our knowledge, been used in an interactive graphics environment for the purpose of programming. Three 
existing graphical representations are examined with a view to their possibilities as actual interactive 
graphical programming languages. The three methods examined are: flow charts, HIPO diagrams [STA 76], 
and Nassi-Shneiderman diagrams [NAS 73]. A number of people have mentioned structured flowcharts [CHA 
 74] [LIN 77], but these charts are very similar to Nassi-Shneiderman diagrams and will not be considered 
separately. One of the oldest charting methods is the drawing of conventional flow charts. This method 
was developed originally for supporting the writing of programs in assembly or even machine language. 
Flow charts consist of very simple and self-explanatory symbols and have the property that they clearly 
demonstrate the control flow of the programs they represent. On the other hand, flowcharting does not 
support the modular design of programs, but rather allows the creation of "spaghetti bowl" designs that 
are difficult to test and correct. Unfortunately, these diagrams also have the tendency of spreading 
out over large sheets of paper. To overcome this disadvantage, several charts on different pieces of 
paper are connected together by so-called off-page connectors. It turns out, however, that it is very 
difficult to recognize the overall structure of a program represented by a large flow chart. HIPO diagramming 
is a more recent technique for documenting and programming than flowcharting. Programs are represented 
by two distinct kinds of diagrams consisting of simple rectangular figures. One kind of diagram breaks 
a task down into subtasks using task and subtask descriptions in a natural language (e.g. English). 
The other kind of diagram describes the input, the actual action to be performed, and the output of 
each rectangular figure. Such an approach certainly supports top-down development of programs and clearly 
 demonstrates the structure of the program in question. (The method was originally developed as a means 
of program documentation!). On the other hand, the structure and the action of the program are entirely 
separated. This is the reason that the breaking down of a task into subtasks becomes a rather arbitrary 
action when this method is employed. In addition, the use of a natural language with all its imprecision 
is a serious drawback. Furthermore, a HIPO diagram tends to show no context for the part of the program 
represented by the diagram, which makes it difficult to use as a design or testing vehicle. Needless 
to say, it does not help to prevent errors committed due to lack of information about the context. 
 NSDs were developed with the aim of supporting Structured Programming [NAS 73]. Programs are described 
by a collection of rectangular figures each of which represents a program segment. Such a rectangular 
figure may contain either a succession of simple statements written in the base language (e.g. PL/I) 
or other rectangular figures representing structured statements (e.g. IF, DO). It is quite an advantage 
that there are special NSD figures symbolizing structured statements like IF, DO, and CASE, even though 
these symbols have to be learned by the user. The size of an individual diagram representing a procedure 
is somewhat artificially restricted by the size of the sheet of paper. Although this approach greatly 
encourages modular design and clearly demonstrates both syntax and the logical meaning of each piece 
of the program, it is questionable as to whether it is also useful for the development of large programs. 
However, "Endicott programmers report that they prefer Nassi-Shnelderman charts to either flow charts 
or HIPO diagrams" [JON 77]. The use of NSD has been shown to be cost-effectlve, whereas the use of HIPO 
diagrams was shown to be cost-effective only some of the time, and the use of flowcharts was shown to 
be usually not cost-effective [JON 77]. Two existing partial programming support systems [GEW 77] [VAN 
77] which make use of NSD claim to have noticed great advantages for software design and development. 
Unfortunately, neither of these systems allows a user to interact with an NSD in a graphics mode. Undoubtedly, 
the proper use of NSD and HIPO diagrams can greatly support top-down development of programs and the 
understanding of a complex program structure. On the other hand, developing and drawing charts is a rather 
cumbersome process and if at a certain point during the design phase alterations to the program structure 
become necessary, the revision of the already drawn charts causes a great deal of work. Although there 
exist some interactive systems that support the drawing, charts representing a program are still manually 
translated into machine executable statements and this translation represents an additional source of 
errors. Also, an additional checking step becomes necessary. It is widely agreed that the introduction 
of graphics techniques into many kinds of human activities and in particular into program development 
is a great help. Usually two reasons are mentioned in this connection. First of all, it is an advantage 
to simply introduce an additional way of human perception as a supplement to reading. Secondly, graphical 
figures have proved to be a powerful way of communicating. Methods should be sought to intesrate program 
documentation--often considered to be a secondary job of minor intellectual value--into the program development 
phase either by entirely automating documentation or by choosing a self-documenting program representation. 
 It should also be noted that there is convincing evidence to support the idea that the use of interactive 
systems reduces costs for software development [JON 77] [REA 74] [SAC 68]. Based on the material presented 
above, it is assumed that a software support system should provide a programming language with a graphical 
representation clear enough for documentation that can be edited in an interactive graphics fashion and 
automatically be converted into executable code, and should lead the user towards structured programming. 
 44   her programs, instead of a linear text string representation for a conventional programming 
language. Specifying a program as a two dimensional structure exhibits the meaning of a program more 
clearly and results in better coding, improved programming productivity and higher quality documentation 
thus reducing the time and effort (cost) for production and maintenance of software. ACKNOWLEDGMENT 
 The authors wish to thank Herbert Weber and Jose Becerril who helped with the initial design of the 
programming support system presented in this paper. REFERENCES [BOE 73] Boehm, B.W. "Software and its 
Impact: A Quantitative Assessment", Datamation, Vol. 19, No. 9, May 1973. [CHA 74] Chapin, N. "New Format 
for Flowcharts", Software Practice and Experience, Vol. 4 No. 4, Oct. 1974. [DAH 72] Dahl, O.J., Dijkstra, 
E.W., and Hoare, C.A.R. "Structured Programming", Academic Press, New York, 1972. [FAG 76] Fagan, M.E. 
"Design and code inspections to reduce errors in program development", IBM Syst. J., Vol. 15, No. 3, 
IBM Corporation, 1976. [GEW 77] Gewald, K., et al. "COLUMBUS - Strukturierte Programmierung in der Praxis", 
Elektronische Rechenanlagen, 19. Jahrg., Heft i, pp. 30-34, Feb. 1977. [JON 77] Jones, C. "Program Quality 
and Programmer Productivity, IBM Technical Report, TR 02.764, Jan. 1977. [LIN 77] Lindsay C.H. "Structure 
Charts -A Structured Alternative to Flowcharts", ACM SIGPLAN Notices, Vol. 12, No. ii, Nov. 1977. [MAR 
73] Martin, J. "Design of Man-Computer Dialogues", Prentice-Hall, Englewood Cliffs, N.J., 1973. [MIL 
76] Mills, H.D. "Software Development", IEEE [MOO 76] [NAS 73] [REA 74] [SAC 68] [STA 76] [SUT 
63] [URS 75] [VAN 77] [WEI 71] [WEL 76] [WIR 71] Transactions on Software Engineering, Vol. SE-2, 
No. 4, Dec. 1976. Moorhead, W.G. "GXRAM, Relational Data Base Interface for Graphics", IBM Research 
Report RJ 1735, 1976. Nassi, I., and Shneiderman, B. "Flowchart Techniques for Structured Programming", 
SIGPLAN Notices of the ACM, Vol. 8, No. 8, Aug. 1973. Reaser, J.M., et al "A Production Environment 
Evaluation of Interactive Programming", National Technical Information Service, AD/A-O06 502, Dec. 1974. 
 Sackman, H., Erlkson, W.J., and Grant, E.E. "Exploratory Experimental Studies Comparing on-line an 
off-line Programming Performance", CACM, Vol. ii, No. i, pp. 3-11, Jan. 1968. Stay, J.F. "HIPO an integrated 
program design", IBM Syst. J., Vol. 15, No. 2, IBM Corporation, 1976. Sutherland, I.E. "Sketchpad, A 
Man-Machine Graphical Communication System", Proc. Spring Joint Conf., pp. 329-346, Spartan Books, New 
York, 1963. Urschler, G. "Automatic Structuring of Programs", IBM J of Research and Development, pp. 
181-193, March 1975. Van Gelder, A. "Structured Programming in Cobol: An Approach for Application Programmers", 
CACM, Vol. 20, No. I, Jan. 1977. Weinberg, G.M. "The Psychology of Computer Programming", Van Nostrand, 
New York, 1971. Weller, D., and Williams, R. "Graphic and Relational Data Base Support for Problem Solving", 
Proc. of Conf. on Computer Graphics, SIGGRAPH-ACM, Vol. I0, No. 2, 1976. Wirth, N. "Program Development 
by Step-wise Refinement", CACM, Vol. 14, No. 4, pp. 221-227, April 1971. 49 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807369</article_id>
		<sort_key>50</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[A microcomputer based system for automated pattern digitization and editing]]></title>
		<page_from>50</page_from>
		<page_to>53</page_to>
		<doi_number>10.1145/800248.807369</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807369</url>
		<abstract>
			<par><![CDATA[<p>Since the first microcomputer was produced in 1969 by Intel Corporation to support the functions of an intelligent terminal, the complexion of digital computers has changed radically. Microcomputers have been successfully applied to a wide variety of dedicated tasks requiring relatively slow calculation speeds and limited numeric accuracy.</p> <p>However, little has been done to bring the LSI microprocessor into stand alone interactive graphics systems. This has been so probably because of the large data files and rapid computation speeds demanded by most interactive graphics applications. This paper outlines a hardware and software configuration for a microcomputer based graphics system developed in response to a need in the sewing industry for a low cost pattern digitizer.</p> <p>A basic graphics package was written which renders both text and vectors on the storage terminal. Around this core, an application program was organized which permits an operator to log piercing point coordinate data from a scaled drawing. Output is then committed to paper tape for permanent storage and PROM for control of the sewing machine. Additional features allow for graphical editing of patterns, display of stored pattern &#8220;programs&#8221; from PROM or paper tape, and merging of new and/or old patterns.</p> <p>Some proof of the success of this project was documented during final checkout, where the time to reduce a drawing to formatted binary on a control PROM was improved from about one man day to a matter of minutes.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Digitizing system]]></kw>
			<kw><![CDATA[Graphics in industry]]></kw>
			<kw><![CDATA[Microcomputer applications]]></kw>
			<kw><![CDATA[Microcomputer graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>C.5.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Digitizing and scanning</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Graphics packages</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010506</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Document scanning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10011187.10011191</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications->Microcomputers</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P333942</person_id>
				<author_profile_id><![CDATA[81100032802]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Pavliscak]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Director of Development, Union Special Corporation, 400 N. Franklin St., Chicago, Illinois]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P330395</person_id>
				<author_profile_id><![CDATA[81332530147]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[G.]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Stowell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Assistant Professor, Schools of Mechanical Engineering and Computer Science, Purdue University, W. Lafayette, Indiana]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14221215</person_id>
				<author_profile_id><![CDATA[81324487523]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Bailey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Graduate Student, School of Mechanical Engineering, Purdue University, W. Lafayette, Indiana]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M. and Sproull, R. F., "Principles of Interactive Computer Graphics," McGraw-Hill, 1974.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>542882</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Peatman, J. B., "Microcomputer Based Design," McGraw-Hill, 1977.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Union Special Corporation, "Catalog 503M. Instructions for Adjusting and Operating The Union Special Memory Stitcher Sewing System," Union Special Corporation, 400 N. Franklin St., Chicago, Illinois, 1976.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A MICROCOMPUTER BASED SYSTEM FOR AUTOMATED PATTERN DIGITIZATION AND EDITING Dr. T. J. Pavliscak Dr. 
G. W. Stowell Director of Development Assistant Professor Union Special Corporation Schools of Mechanical 
Engineering 400 N. Franklin St. and Computer Science Chicago, Illinois Purdue University, W. Lafayette, 
Indiana M. J. Bailey Graduate Student School of Mechanical Engineering Purdue University, W. Lafayette, 
Indiana Since the first microcomputer was produced in 1969 by Intel Corporation to support the functions 
of an intelligent terminal, the complexion of digital computers has changed radically. Micro- computers 
have been successfully applied to a wide variety of dedicated tasks requiring relative- ly slow calculation 
speeds and limited numeric accuracy. However, little has been done to bring the LSI microprocessor into 
stand alone interactive graphics systems. This has been so probably because of the large data files and 
rapid computa- tion speeds demanded by most interactive graphics applications. This paper outlines a 
hardware and software configuration for a microcomputer based graphics system developed in response to 
a need in the sewing industry for a low cost pattern digitizer. A basic graphics package was written 
which renders both text and vectors on the storage terminal. Around this core, an application program 
was organized which permits an operator to log piercing point coordinate data from a scaled drawing. 
Output is then committed to paper tape for perma- nent storage and PROM for control of the sewing machine. 
Additional features allow for graphical editing of patterns, display of stored pattern "programs" from 
PROM or paper tape, and merging of new and/or old patterns. Some proof of the success of this project 
was documented during final checkout, where the time to reduce a drawing to formatted binary on a control 
PROM was improved from about one man day to a matter of minutes. Keywords and Phrases: computer graphics, 
microcomputer applications, digitizing system, micro- computer graphics, graphics in industry. CR Categories: 
3.26, 3.54, 8.2 I. INTRODUCTION Support and motivation for this project was pro-During early stages 
of development, sewing pat- vided by Union Special Corp., a manufacturer of terns drafted on graph paper 
were reduced to industrial grade sewing machines. The need for lengthy "truth tables." These tables recorded 
a more automatic means of entering pattern data the exact binary image which would be written was prompted 
by a new product~ the "Memory into a control PROM. The user was saddled with Stitcher I'' which is in 
essence an N/C area sew-the task of following the graph to each piercing ing machine. The sewing machine 
accepts inter-point symbol, recording its distance from the changeable read only memories (PROMS) containing 
previous entry, and attaching a code which con- digitized sewing patterns of up to 340 steps. trols the 
sewing action. A typist converted the Two short programs (sides A and B) or one long binary table to 
perforated tape which was in turn pattern (Extended) may be stored on one 512X8 used by a commercial 
PROM programmer to make the PROM. Each program step moves the material actual control memory. relative 
to the needle up to 15 increments in the +x and/or ~y direction(s) (one increment = It was soon obvious 
that this technique would be 0.0125"), dictates the speed of movement, and too time consuming to accomodate 
the large vol- specifies whether or not to pierce the fabric. umes of patterns which were expected. However, 
In this manner, a three inch square design may be any new method was required to prove economical sewn 
at a rate of up to 3000 steps/minute. To in comparison. Several options were possible, change patterns, 
the ROM is replaced by one con-ranging from stand-alone automated drafting sys- taining the new program 
set. tems to completely custom, minimum hardware con- figurations. Both extremes were too expensive, 
1 Trademark of Union Special Corporation the former requiring too much capital investment, 50 and the 
latter was excessive in labor costs. A middle ground consisting of off-the-shelf items requiring little 
custom construction was chosen and tailored to the task by means of software. The following two sections 
expand on the hardware and software aspects of the design. II. HARDWARE CONFIGURATION Figure i illustrates 
the overall hardware config- uration. The heart of the system is an Intel 8080 based microcomputer. Initially, 
the CPU contained 16K bytes of read/write memory, enough to develop the application software. However, 
only 4K bytes of read/write memory are retained after installa- tion for variable storage since the program 
is committed to PROM in the microcomputer for opera- tor convenience. Four 16-bit parallel programmed 
I/0 ports and two serial communications interfaces provide the in- terconnections to all peripheral devices. 
A Serial data transfer rate of 9600 baud allows ade- quate interaction by the user at the storage CRT. 
Even the most complex display requires only about three seconds to render. The other serial path is connected 
to a paper tape reader/punch. High data transfer rates are unimportant here because of the inherent mechanical 
limitations (30 CPS) of the device. The remaining parallel ports are assigned to a large data teblet 
and a custom designed external PROM programmer. These devices can transfer data rapidly and require 
a wide path (some 30 bits), so it is more than convenience that forced their connection in this manner. 
 Currently, pattern drawings can range up to two feet square, and after a search of manufacturers, a 
strain wave type tablet with an active area matching that dimension was chosen. The standard resolution 
of i00 points per inch more than ade- quately distinguishes coordinate data, since the application calls 
for only 120 resolution points- per-foot. For display and user command interaction, a large screen 
storage CRT terminal was chosen. High resolution combined with moderate cost made this device a clear 
choice over the more expensive, but more interactive, random vector displays and the low cost, but 
lower resolution, raster-type terminals. Drawings are displayed as they are digitized or edited at 
half the original scale along with data, menu, and message information. At this scale, even a single 
LSB digitizing error is clearly discernable. A combination paper tape reader/punch supplies a means 
for permanent storage of digitized patterns and a method of viewing and editing archived sew- ing programs. 
For long term data integrity rea- sons, paper tape was chosen as the archival medium. It now appears, 
however, that the physical bulk of the file needed to hold old pattern programs will force a switch to 
the less reliable, but more com- pact medium of floppy disc. The cost of each is approximately the same. 
 The final hardware item is a PROM programmer/ reader which, by necessity, had to be custom designed. 
The target PROM is a National Semi- conductor 5204 which appears to be only a moder- ately popular chip 
with few companion off-the- shelf programmers. None is compatible with this microcomputer. So far, the 
hardware has proven both relAable and cost effective. The total capital investment is around $20,000. 
Interactive graphic terminals along often exceed this figure. IMcROCCM~ Figure I: Pattern Digitizer 
Equipment Configuration III. SOFTWARE ORGANIZATION The software for this project was developed under 
an 8080 cross assembler (supplied by Intel Corp.) running on Purdue University's CDC 6500 Dual-Mace system. 
The environment for development was the Computer Aided Design and Graphics Laboratory, a teaching and 
research facility in the School of Mechanical Engineering at Purdue. The base of the 7000-1ine system 
is in two parts: the data structure and the graphics package. The graphics package was designed to utilize 
the Tektronix 4014 or 4010. Three assembly language subroutines were written to move (blank line), draw 
(solid line), and place an alphanumeric string on the screen. These routines were named (sur- prisingly) 
MOVE, DRAW, and ALPHA, respectively. From 8080 assembly language, DRAW and MOVE expect the address of 
the X,Y pair (two words/pair) to immediately follow the call. Alpha expects the character string, terminated 
by a byte of 0, to follow its call: ;DISPLAY A LINE FROM (I00,000) TO (200,200) ;AND WRITE A WORTHLESS 
MESSAGE ;AT (500,600) CALL MOVE DW A ;ADDRESS OF i00,i00 PAIR 51  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807370</article_id>
		<sort_key>54</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[GAIN]]></title>
		<subtitle><![CDATA[An interactive program for teaching interactive computer graphics programming]]></subtitle>
		<page_from>54</page_from>
		<page_to>59</page_to>
		<doi_number>10.1145/800248.807370</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807370</url>
		<abstract>
			<par><![CDATA[<p>Recent trends in the manufacturing and sales of home computers indicate that a new form of instruction must be developed for teaching programming in the home. Students learn programming from interacting with computers and other students in a classroom setting. The home user may not have this option. Manuals do not teach; they are good for looking up information you have forgotten. Workbooks and textbooks do not have a structure conducive to teaching&#8212;you have to understand everything before you can figure out &#8220;undiagnosible syntax error&#8221; or &#8220;OC4.&#8221; An approach has been developed at UICC which uses sophisticated error handling and modest program verification to supervise the beginning user while he/she is constructing and executing computer graphics programs. New, inexperienced computer users are now doing interesting (to them) programs within a half hour. This &#8220;interactive workbook&#8221; concept will be expanded and is currently a working prototype of a teaching package to be available on a home computer graphics/color TV system next year.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer assisted instruction]]></kw>
			<kw><![CDATA[Interactive computer graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>K.3.1</cat_node>
				<descriptor>Computer-assisted instruction (CAI)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.2.4</cat_node>
				<descriptor>Correctness proofs</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003790.10003792</concept_id>
				<concept_desc>CCS->Theory of computation->Logic->Proof theory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010992.10010993</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Software functional properties->Correctness</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010489.10010490</concept_id>
				<concept_desc>CCS->Applied computing->Education->Computer-assisted instruction</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
			<gt>Performance</gt>
			<gt>Verification</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P334109</person_id>
				<author_profile_id><![CDATA[81546850256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tom]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Towle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois at Chicago Circle, BOX 4348, Chicago, IL]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15032130</person_id>
				<author_profile_id><![CDATA[81100432746]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tom]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[DeFanti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois at Chicago Circle, BOX 4348, Chicago, IL]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Mennie, Don, "Everybody's Doing It (Computing at Home)," IEEE Spectrum, Vol. 14, No. 5, May 1977, pp. 25-34.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Machover, C., et al. "Computer Graphics Displays," IEEE Spectrum, Vol. 14, No. 8, August 1977, pp. 24-32.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Kay, A.C., "Microelectronics and the Personal computer" Scientfic American, Vol. 237, No. 3, September 1977, pp. 231-244.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[DeFanti, Tom, "The Digital Component of the Circle Graphics Habitat," Proc. NCC 1976.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[DeFanti, Tom, et al. "Computer Graphics as a Way of Life," Computers &amp; Graphics, Vol. 1, No. 1, May 1975.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356677</ref_obj_id>
				<ref_obj_pid>356674</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hantler, S. and King J., "An Introduction to Proving the Correctness of Programs," Computing Surveys, Vol. 8, No. 3, September 1976, pp. 331-353.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Burstall, R. "Some Techniques for Proving the Correctness of Programs which Alter Data Structure," Machine Intelligence 7, American Elsevier, New York, 1972.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356602</ref_obj_id>
				<ref_obj_pid>356599</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Elspas, B., "An Assessment of Techniques for Proving Program Correctness," Computing Surveys, Vol. 4, No. 2, June 1972, pp. 97-147.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[King, J., "Proving Programs to be Correct," IEEE Transactions on Computers, Vol. 20, No.11, November 1971, pp. 1331-1336.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 GAIN: An Interactive Program for Teaching Interactive Computer Graphics Programming by Tom Towle and 
Tom DeFanti University of Illinois at Chicago Circle Box 4348 Chicago Ii 60680 Abstract Recent trends 
in the manufacturing and sales of home computers indicate that a new form of' instruction must be developed 
for teaching pro- gramming in the home. Students learn programming from interacting with computers and 
other students in a classroom setting. The home user may not have this option. Manuals do not teach; 
they are good for looking up information you have forgot- ten. Workbooks and textbooks do not have a 
struc- ture conducive to teaching--you have to understand everything before you can figure out "undiagnosi- 
ble syntax error" or "OC4." An approach has been developed at UICC which uses sophisticated error handling 
and modest program verification to super- vise the beginning user while he/she is construct- ing and 
executing computer graphics programs. New, inexperienced computer users are now doing interesting (to 
them) programs within a half hour. This "interactive workbook" concept will be ex- panded and is currently 
a working prototype of a teaching package to be available on a home comput- er graphics/color TV system 
next year. Content Indicators 1.51, 1.52, 2.12, 3.80, 4.13, 4.29, 4.6 Keywords: interactive computer 
graphics, computer assisted instruction I. Introduction Home computers are no longer a concept of the 
future. Systems are now available to the consumer from various manufacturers across the country in- cluding 
companies as well known as Heath and Radio Shack. These computers generally use a form of BASIC and have 
many available accessories like video terminals, tape and disk storage and graph- ics displays[l,2,3]. 
For such systems, the prob- lem of teaching, that is the problem of developing teaching mechanisms, is 
immediate. Normally, a person who wants to learn to pro- gram enrolls in a course where teachers, teaching 
assistants, manuals and a group of peers, all in- volved in the same learning tasks, are all around. 
None of these facilities, except manuals, are available in the home. Manuals are mostly for reference, 
for looking up information you may have forgotten. Learning to program from a manual is, at best, difficult, 
especially for someone with no previous programming experience. Self instruc- tional texts for languages 
such as BASIC are available and do provide a structure for the new user to follow. However, the number 
of possible errors that can confront one writing his first programs makes this type of instruction little 
better than just reading a manual. What the learner needs, in addition to a structured presen- tation 
of the material, is supervision while writ- ing and executing programs so that the problems, which are 
sure to be encountered, can be dealt with in a manner which will minimize the frustra- tions and will 
encourage the learner to continue with the instruction. This kind of supervision is available in the 
classroom (at least theoretical- ly) but not the home, unless the supervision is done by the computer 
itself. This paper is a report on a program that pro- vides this kind of supervision and is now being 
used at the University of Illinois at Chicago Cir- cle to teach the operation of the Graphics Sym- biosis 
System (GRASS). This Grass Assisted IN- struction (GAIN) Program will be described follow- ing a brief 
description of the GRASS system. Spe- cial emphasis will be placed on the method of in- troducing non-programmers 
to computer use and the built-in error handling and program verifica tion features. Although GAIN was 
designed to teach GRASS, we feel that it is a valid prototype for a program to be used on a home computer 
system. GAIN resolves many of the difficulties encountered in the home learning situation. First, it 
is available on demand and it requires no equipment other than the computer system. GRASS, unlike FORTRAN, 
BASIC and others, allows a supervisory program to be written which can handle the problems encountered 
by new users. Of equal importance is the ability of GAIN to provide a structured situation in which the 
learner can get past those first few hours of pro- gramming. A new user's success or failure during these 
first few hours often determines whether he will continue to remain interested in learning programming. 
And, although GAIN does not teach highly sophisticated programming techniques, it does introduce the 
learner to several fundamental notions such as the use of variables, programmed loops, and conditional 
statements. GAIN can make this introduction sucessful and productive. The new user will very quickly 
be creating programs which are powerful and, because graphics are in- volved, beautiful. 54 Ii. Interactive 
Graphics and the GRASS System Fundamental to the concept of interactive computer graphics programming 
as envisioned and implemented in GRASS (or a reasonable home comput- er system) is the idea that inexperienced 
users such as artists and educators should be able to develop computer graphics interactively without 
 the constant assistance of computer program- mers[4]. In addition, such a system should be able to 
be used in real-time situations so that it can be played like an audio synthesizer or be used to serve 
up "short order" animations for edu- cational use or enjoyment. Therefore much em- phasis has been 
placed on making the system "new- user" oriented[4,5]. The hardware used is a PDP-11/45 with a Vec- 
 tor General 3DI scope and a VT05 video terminal. In addition, there are thirty channels of analog 
input for dials and the like, and eight channels of analog output. The structure of GRASS and the use 
of many intuitive commands greatly aids the new user to quickly achieve results. Some of this structure 
and the commands are described below. A more complete description of GRASS is found in reference[4]. 
If you are already familiar with GRASS, please skip to section IIl of this paper. Pictures in GRASS 
are lists of 3-D vector endpoints. The vector list is first declared by the command "OPEN PNAME." PNAME 
is a user-chosen name which is then associated with the vector list in core and on the disk. The user 
specifies endpoints with the command "PUTPO1 XARG,YARG,ZARG,KARG" whose first three ar- guments specify 
the x,y, and z coordinates of the end of the vector and may be numbers, expressions, or devices such 
as dials, joysticks, and so on. KARG must evaluate to 0 or 1 and indicates whether a line should be 
drawn to the point or not. Judi- cious use of the PUTPOI command can result in a flexible tablet drawing 
program, for example. A point placed in the vector list may be deleted with DELPOI which simply deletes 
the last point in the list. CLOSE terminates the vector list and returns any unused storage. Once 
a picture has been named, provided with endpoints, and closed, it may then be manipulated with several 
intuitive commands which reflect the hardware capabilities of the Vector General (MOVE, SCALE, ROTATE, 
etc.). The user need no longer be concerned with the individual endpoints unless he wants to be. The 
manipulations may be connected to variables, dials, and so on, and the updates are done at interrupt 
level and shipped to the Vector General via direct memory access (DMA). Pictures may be grouped together 
for reference or concatenation of transformations (and the user does not have to understand matrix multiplica- 
tion). Manipulation commands remain attached un- til FIX or RESET commands are issued. Most GRASS commands 
may be typed in one by one and executed. The user can thus observe the action of commands without having 
to write pro- grams. For the more sophisticated user, commands can be collected into programs, which 
we call "macros." IF, RETURN, SKIP (like GOTO in BASIC) and DO (like GOSUB in BASIC) provide transfer 
of control. Macros communicate with users with PROMPT and INPUT (extensions of the PRINT and IN- PUT 
commands in BASIC). GRASS is intendea for the person whose exper- tise is in something other than computer 
program- ming. The many intuitive commands and immediate visual feedback work to make this intent a 
reali- ty, at least within certain limits. The new GRASS user must be able to learn some of the language 
 and relate certain commands to system response. GAIN was developed in part to resolve the problems 
of first use of GRASS. GAIN provides syntactic information but it also provides in- teractive experience. 
As the user progresses through GAIN, he is exposed to many of the system capabilities and, within a 
short time, is able to fascinate himself. And, if desirable, GAIN lets the user go play once enough 
has been learned to create the intended titles or graphics. That is, you do not have to learn how to 
write a macro if all you want to do is create simple visuals for a videotape. IiI. GAIN as an Interactive 
Workbook In developing GAIN, it was decided early on that as little time as possible should be spent 
teaching GRASS commands. Instead, the emphasis is placed on using and interacting with the commands to 
achieve some meaningful results and allow expo- sure to the system, thus providing increased motivation 
for further learning. GAIN consists of a printed workbook and a series of interactive GRASS macros. 
The workbook provides a structured introduction to the GRASS commands and a hardeopy reference on use 
and syn- tax. The interactive macros provide experience in command usage, exposure to system capabilities, 
and, most importantly, provide step-by-step super- vision and assistance when difficulties occur. GAIN 
is divided into two main parts. The first part provides information on the commands and practice in the 
skills necessary to create pictures. The second part does the same with the manipulation of pictures. 
Within each part are several sections of increasing difficulty. Most sections are composed of workbook 
material fol- lowed by exercises on GRASS. The GAIN exercises generally reinforce the information presented 
in the associated workbook section and provide super- vised hands-on use of the system. Part I: Picture 
Creation Section 1.1 of the workbook contains use and syntax information for the commands necessary 
to build picture lists: OPEN, PUTPOI, DELPOI and CLOSE. At the end of this section (2 pages of reading), 
the user is asked to do the first com- puter exercise by typing "DO EXI" on the video terminal(VT05). 
Immediately, some text indicating the goals of the exercise (creating picture lists) is displayed. The 
user is then presented with a simple picture composed of dashed lines which he is supposed to duplicate. 
The dashed lines have the coordinates of their endpoints displayed as well. The user then inputs commands 
one by one to cover the dashed lines with the solid lines of his own picture list. The system first requests 
the input by prompting, for example, "TYPE THE COMMAND TO OPEN YOUR PICTURE LIST AND NAME IT." The user 
should then respond by typing "OPEN BOX" for exam- ple. The fact that the user is allowed to name his 
own picture is important, at least to him. It ac- 55 curately simulates actual use of the system and, 
in addition, reinforces the feeling that the user is in control. Once a correct command is entered, 
it is exe- cuted right away so that the user can see the ef- fect, if any, on the screen. Commands which 
actu- ally place points and draw vectors are checked against the model picture list of dashed lines to 
make sure the proper coordinates have been used. If the point or line is incorrect, the user is asked 
to delete it (with DELPOI) and then told to continue. The order of the endpoints is up to the user and 
no time limits are imposed. Besides see- ing the results, the user is told when he types perfect commands, 
a method of providing positive reinforcement. Although this all sounds rather dry, when you are working 
with this program it has all the feeling of a game and is actually fun. When the user determines that 
the picture is complete, he closes the picture (with CLOSE). The user's picture is checked for completeness 
and if it is not, he is required to complete it first. If everything is satisfactory, the user is issued 
a diploma on the line printer and presented with a more complicated dashed picture to copy. In this 
exercise three pictures, of increas- ing difficulty, have to be completed. The first is just a single 
line and can be drawn by typing just four commands, while the third picture is three-dimensional and 
requires at least nine statements to draw. The user has to do the third picture without making more than 
one mistake in selecting the proper command (syntax errors often come from mistyping, so they are reported 
without penalty). If two or more command selection mis- takes are made, the user is required to draw 
an additional picture. If less than two mistakes are made in completing the third picture, he is given 
the choice of doing more pictures or of going on to the next section of the workbook. The average subject 
takes about ten minutes or so to go through the first part, the variance having more to do with typing 
skills than anything else. The Use of Variables and Loops to Create Pictures The second and more satisfying 
section of Part I. discusses the use of variables, arithmetic and logical operators, and loops. The learner 
is shown how to assign values to variables and how to use variables in the PUTPOI command. Two new com- 
mands are presented: IF and SKIP, which allow con- ditional and unconditional program control transfer. 
These commands illustrate concepts basic to most computer programs, but the emphasis is on using variables 
in the PUTPOI command. Two exercises are indicated at the end of this work- book section, Exercises 2 
and 3. The first of these two exercises teaches a macro which is presented in the workbook: OPEN PIX 
 A:0 PUTPOI A,0,O,I ;I INDICATES MOVE NO DRAW PUTPOI A,500,O,O ;0 INDICATES DRAW A=A+50 IF A GT 500,SKIP 
2 SKIP -4 ;BACK TO FIRST PUTPOI CLOSE This macro will draw a series of parallel vertical lines. The 
commands and the parallel lines drawn are displayed for the user who is then asked to replace the assignment 
statement in the second line. He does this by entering the statement on the VT05. The statement is inserted 
in the macro which is then displayed for the user. The macro is executed and the user can see the result 
of the change. Any errors in syntax or execution caused by the insertion of the user's command such as 
supplying a negative 10,000 as an initial value, are trapped during execution (as explained in sec- tion 
IV below), and the user is informed of the error and the cause. When the user performs the task three 
times, by which time the effect of the change should be apparent, he is given the choice of doing it 
again or of going on. Subsequent parts of Exercise 2 allow the user to replace the PUTPOI commands, 
the incrementing statement, and the conditional statement. As be- fore, the user's statements are inserted 
in place of the existing commands and the entire series is displayed and re-executed. After each part 
is ac- complished the user can continue with new substi- tutions or go on to the next step. Exercise 
3 contains two subparts. The first subpart presents three additional picture drawing macros in which 
command substitutions are allowed. The first macro is: OPEN LINES X=I000 Y=I000 Z:I000 PUTPOI X,Y,Z,I 
PUTPOI -X,Y,Z,0 X:X-20 Y=Y-20 Z=Z-20 IF X GE -1500,SKIP -5 ;GOTO FIRST PUTPOI CLOSE In this macro, the 
user is allowed to replace the three initializing statements. Besides providing practice in setting variables, 
this macro demon- strates using multiple variables in PUTPOI, nega- tive incrementing, and the use of 
a lower bound in an IF statement. This macro also can illustrate digital wraparound if the user chooses 
X:IO00 and Y=0 in the looped statements (which he is en- couraged to do). This picture, like the rest 
to follow, is three-dimensional and, when the user is done, the picture is displayed rotating with xyz 
axes superimposed so the third dimension may be observed. The second macro uses the same three vari- 
ables as the previous one but contains five PUTPOI commands which create a series of parallelograms. 
This time the user is asked to replace the initi- alizing and incrementing statements for X,Y, and Z. 
Rather interesting pictures can be created with this one. In addition, the use of a loop counter is 
demonstrated. The third macro is shorter but is the most flexible for creating interesting pictures: 
OPEN CHANGE A:O B:-40 PUTPOI A*20,A*A/4,B*B,I PUTPOI B*30,-500,-B*B,O A=A+I B=B+I IF B LE 40,SKIP -4 
CLOSE The arguments of the PUTPOI commands are expres- sions and the exercise encourages the user to 
ex- periment with changing these expressions. Most GAIN users get stuck here in the sense that they do 
not want to stop. We often have to intervene. The second part of Exercise 3 displays a pic- ture for 
the user. Given this picture and a gen- eral description of the commands necessary to draw it, the user 
is expected to construct his own mac- ro and type it in (under GAIN control). For exam- ple, the following 
is acceptable: OPEN PIX A=IO00 PUTPOI A,1500,0,I PUTPOI A,-1500,0,0 A=A-100 IF AGE -IO00,SKIP -3 
 CLOSE When this macro is executed, any errors are trapped and explained, and the user can go back and 
rewrite it or end. If it executes without er- ror, the resulting picture is matched against the picture 
that was supposed to be drawn. If they do not match, he may choose to do it over again or stop. A second 
picture is available for those who are successful at matching the first. Storage and Editing Commands 
 Section 1.3 in the workbook discusses storing things on the disk. The commands introduced are PUTDSK, 
GETDSK and DELETE and the directory display commands DIRCOR and DIRDSK. This section is followed by Exercise 
4 which first requires the user to create a picture. This picture is used to take the user through a 
series of storage and re- trieval exercises designed to demonstrate the disk and core storage procedures. 
 The fourth and fifth sections of the workbook go on to describe the creation and editing of mac- ros 
(up to now, the user has been typing macros into GAIN, not GRASS's editor). These sections are optional 
and not pre-requisites to Part 2 of GAIN which deals with picture manipulation and an- imation. Part 
2: Picture Manipulation Part 2 requires the user to be able to create pictures and store them on his 
own. These pic- tures are used to teach various manipulation com- mands. Section 2.1 and Exercise 5 present 
infor- mation on, and help the user practice, the DASHES, POINTS, and LINES commands. These are the least 
difficult manipulation commands to use and under- stand. The exercise requires the user to get a picture 
from the disk and then to change the display using each of these commands. Section 2.2 explains the 
syntax and use of the GETPOI and ZAPPOI commands. These commands are used to obtain and change picture 
coordinates in a vector list. Four exercises follow this workbook section. In Exercise 6 the user changes 
a vector list using given coordinates and the ZAPPOI command. Exercise 7 requires the user to obtain 
the coordi- nates with the GETPOI command before changing them with ZAPPOI. Exercises 8 presents several 
macros using the GETPOI and ZAPPOI commands, in which the user replaces command statements as in the 
second exercise. Exercise 9 requires the user to write complete macros using these commands. Like the 
macro writing portion of the third exercise, this one is optional. Section 2.3 gives the user the information 
needed to use GRASS devices (dials etc.) with manipulation commands and two of these (MOVE and SCALE) 
are presented. Exercises 10 and 11 help the user to practice these commands with devices. Section 2.4 
and Exercise 12 are devoted to use of the ROTATE command. This exercise, along with exercises 10 and 
11, demonstrate the GRASS device conventions and the concepts necessary for fairly powerful and sophisticated 
manipulations of graphics. The last workbook sections inform the user about the linear and sinusoidal 
time-based vari- ables. These GRASS devices, used with certain manipulation commands, allow precisely 
timed se- quences of movements to be accomplished very sim- ply. Exercise 13 supervises the use of these 
dev- ices in the MOVE, SCALE, and ROTATE commands and in macros using these commands. The final part 
of this exercise demonstrates a Ping-Pong type game created using commands and concepts presented in 
GAIN. IV. Error Handling and Program Verification The heart of GAIN is the GRASS language which provides 
facilities which allow GAIN to exercise the user's new knowledge under program control. Two of the more 
important facilities are those for character string manipulation and execution and for system error trapping. 
 Character String Manipulation and Execution GRASS has some string handling features, although it is 
hardly SNOBOL. String variables in GRASS are named $A-$Z and they may be assigned with the INPUT command 
or with an assignment statement of the form: SA=$B,$A,"TNIS IS A LITERAL",$C (etc.) where a comma is 
the concatenation operator. There is string decomposition capability in the SEARCH command too. Any string 
variable in GRASS can be executed by typing its name on a line all alone. Thus, user-typed commands can 
be checked, executed individually, inserted into already ex- isting macros or combined to form new macros 
quite easily. System Error Trapping The system error facilities which normally interrupt execution 
and print out a one-line error message on the VT05 may be disabled with the ONER- ROR command. ONERROR 
allows a great deal of flex- ibility in handling user errors and it has two forms: ONERROR A,ANY LEGAL 
GRASS COMMAND ONERROR/$ $A,A,ANY LEGAL GRASS COMMAND where A and SA are any numeric and string vari- 
ables, respectively. When ONERROR is in effect, and an error happens, control is transferred to the command 
indicated by "ANY LEGAL GRASS COMMAND" above. This command can he a call to a fixup routine, if necessary, 
or a simple one-line recovery. The error number (there are about 150 different error messages in GRASS) 
is put in A and the line which caused the error is put in SA if desired. Since this error handling 
is the most impor- tant part of GAIN (if it were not for user errors, GAIN would be useless), we will 
elaborate in de- tail below on the types of errors that GAIN han- dles. Error Routines The general 
procedure in a GAIN exercise is to ask the user to input a command to achieve a specified result. The 
command is paced in a string variable with the INPUT command and then checked with an IF command to see 
if the proper command was chosen. If not, the command error as- sistance macro for that command is called 
and it provides further information about the command that should have been used. The error count is 
also maintained which indicates what information should be presented. Once a user's input has been checked 
for the correct command, or when it is inserted in a mac- ro, the command, or macro, is executed. Errors 
en- countered on execution cause one of the general error assistance macros to be called. These macros 
report on the type of error found and describe what needs to be done to correct the error in a two or 
three line message. The user's input is then displayed and, if more than one command statement was typed 
in, the particular line which caused the error is noted when possible. Logic and program flow errors 
are nearly im- possible to correct with a manual. GAIN, however, does a good job of isolating the run-time 
errors encountered as a result of combinations of com- mands, like excessive looping (which causes one 
to run out of core or get stuck in an infinite loop), for example. Most of these errors can be caught 
with the ONERROR command but detecting an infinite loop requires the SKIPMAX command which generates 
an error if an indicated maximum number of SKIPs occur. This error, in turn, can be trapped by ONERROR, 
of course. Some mistakes, like failing to close a pic- ture file when done, will not generate errors 
im- mediately but later if one tries to open a new picture file. GAIN simulates these situations by opening 
dummy files and trapping the possible er- rors. Although the majority of execution errors can be anticipated 
and handled by the fixup routines, there is always the possibility that the user might come up with a 
new error situation. This most often happens if a user somehow reads ahead or invents a command which 
happens to exist any- way, but has not been introduced yet. Also, the user is not always prohibited 
from using the ONER- ROR command or RESTART commands, and this could confuse any program. Fortunately, 
we have pri- marily naive and not malicious users. In the event an unanticipated error is found, the 
user is told that GAIN cannot handle it and he is encouraged to continue on with the exercise. Verification 
Routines Catching syntax and execution errors is only half the task of GAIN. Commands and macros typed 
by the user must usually achieve a specific result such as creation of a particular picture list. This 
requires that some verification of the results be done. GAIN's verification processes are admittedly 
simplistic compared with formal program verification work by others which is con- cerned with the formulation 
of methods to get com- puters to construct or assist in the construction of program proofs[6,7,8,9]. 
Most of this work has been oriented toward developing generally applica- ble program verifiers that decide 
whether a pro- gram will terminate and generate correct output given correct input. For GAIN's purposes, 
a program is considered correct if it produces the correct result, be it a single statement or a complex 
macro. In general, a different verifier must be written for each part of each exercise, a considerable 
but not impossi- ble task. In practice, these verifiers have turned out to be rather general and will 
handle certain classes of programs. One class of programs that GAIN verifies con- tains those in which 
the user is required to copy a displayed dashed-line picture by placing one vector at a time with PUTPOI. 
This type of user input is verified each time a vector is placed in the user's open picture by checking 
if the line is in fact in the dashed-line picture. When the user indicates that the picture is complete, 
the pic- ture is checked to see if it has all the lines needed. With larger pictures, some searching 
time becomes perceivable since no order is implied in the dashed picture and all vectors have to be cross-matched 
with the user's vectors. When the user writes a complete macro to copy a picture it is necessary to 
use a two-pass verif- ier which first checks if all the lines that the user has generated exist in the 
dashed-line pic- ture and then checks to see if all lines in the dashed-line picture exist in the user's 
picture. If both passes approve, the macro is deemed veri- fied. This verifier will work with any picture 
and copy. Besides creations, picture manipulations must also be verified. If the manipulation is one 
which changes a vector endpoint within a picture, the same verifier is used as in the previous case. 
If, however, the manipulation is done by the Vec- tor General hardware, as is the case with rota- tion, 
scaling and translation, the verification is done by checking the end values of the variables which control 
the hardware. These verification procedures, while not com- plex in theory, are quite useful in practice 
when combined with the error checking d~cribed ear- lier. For GAIN's purposes, these techniques pro- 
vide the user with fast and informative feedback on successes and mistakes, thereby keeping frus- trations 
to a minimum and motivation high. Users have good feelings for the programs and want to continue to trust 
GAIN as a teacher. V. Problems and Future Developments The chief problem with GAIN is that it be- comes 
more difficult to program meaningful learn- ing experiences and simulations as the user's skills increase. 
GRASS is a very multi-leveled system which one continues to learn for years. Trying to provide the user 
with only those things he needs to know requires needs assessment capa- bilities which we have not yet 
achieved. For the genuine novice, the situation is simple because there are certain things common to 
any operation of GRASS. As the user gets more specialized in his interests, though, the prospect of 
satisfying him relies more on his own experimentation rather than us trying to guide him through. There 
is no reason to justify enormous amounts of programming to try to guess what a more experienced user 
might want to do. GAIN is primarily intended to get the user to this experimentation stag~ and then 
go away. Summary GAIN has been useful in introducing GRASS in a structured way to those entirely unfamiliar 
with programming. It has also taught good programmers GRASS very quickly. GAIN gets one to a place where 
he can create and manipulate pictures without outside help. It achieves this goal by using sophisticated 
error handling and informal program verification routines which lead the user to see and understand his 
errors. We believe this approach is a valid model for teaching computer graphics and video game programming 
in the home. References [I] Mennie, Don, "Everybody's Doing It (Computing at Home)," IEEE Spectrum, 
Vol. 14, No. 5, May 1977, pp. 25-34. [2] Machover, C., et al. "Computer Graphics Displays," IEEE SDectrum, 
Vol. 14, No. 8, Au- gust 1977, pp. 24-32. [3] Kay, A.C., "Microelectronics and the Personal Computer" 
Scientific American, Vol. 237, No. 3, September 1977, pp. 231-244. [4] DeFanti, Tom, "The Digital Component 
of the Circle Graphics Habitat," Proc. NC~ 1976. [SJ DeFanti, Tom, et al. "Computer Graphics as a Way 
of Life," Computers &#38; Graphics, Vol. I, No. I, May 1975. [6] Hantler, S. and King J., "An Introduction 
to Proving the Correctness of Programs," Computing Surveys, Vol. 8, No. 3, September 1976, pp. 331-353. 
 [7] Burstall, R. "Some Techniques for Proving the Correctness of Programs which Alter Data Structure," 
Machine Intelligence ~, American Elsevier, New York, 1972. [8] Elspas, B., "An Assessment of Techniques 
for Proving Program Correctness," Computing Surveys, Vol. 4, No. 2, June 1972, pp. 97-147. [9] King, 
J., "Proving Programs to be Corrects" IEEE Transactions on Computers, Vol. 20, No. 11, November 1971, 
pp. 1331-1336. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807371</article_id>
		<sort_key>60</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[The interactive digitizing of polygons and the processing of polygons in a relational database]]></title>
		<page_from>60</page_from>
		<page_to>63</page_to>
		<doi_number>10.1145/800248.807371</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807371</url>
		<abstract>
			<par><![CDATA[<p>A system is described for the interactive digitizing of polygons for such two-dimensional spatial modeling applications as growth studies and thematic map production. A digitizer connected online to a mini-computer with a refresh display is used for capturing polygon data from source documents. An area boundary network is developed by digitizing nodes, pointing to node pairs, and then digitizing edges only once. A CRT display monitors, and bell-rings confirm input operations. Facilities to erase nodes or edges are available. From the nodes and edges, software produces polygons which the user may name or discard. Slivering and overlap are eliminated because contiguous polygons have identical edge descriptions. Named polygons are then transferred to a large university time-sharing computer where spatial editing operations may be carried out, such as unioning pieces of a large map. The named polygons may he given additional non-spatial attributes and entered into a relational type of data base.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Choropleth maps]]></kw>
			<kw><![CDATA[Digitizing]]></kw>
			<kw><![CDATA[Polygons]]></kw>
			<kw><![CDATA[Relational database]]></kw>
			<kw><![CDATA[Thematic maps]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Relational databases</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Digitizing and scanning</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Spatial databases and GIS</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003236</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Spatial-temporal systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010887</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Geographic visualization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010506</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Document scanning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003197.10010822</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Query languages->Relational database query languages</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10002955</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Relational database model</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Management</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P331527</person_id>
				<author_profile_id><![CDATA[81100422456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[McIntosh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Michigan, Ann Arbor, Michigan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>563306</ref_obj_id>
				<ref_obj_pid>563274</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Dueker, Kenneth J., "Cartographic Data Structures: Alternatives for Geographic Information Systems", Proceedings of the Third Annual Conference on Computer Graphics, Interactive Techniques, and Image Processing SIGGRAPH '76, Vol. 10, No. 1, July 1976, pp. 167-172.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Turner, James A., Two-Dimensional Polygon Routines: Programmer's Manual, Architectural Research Laboratory, The University of Michigan, Ann Arbor, Michigan, 1976.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563304</ref_obj_id>
				<ref_obj_pid>563274</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Tuerke, Klaus, "A System for Interactive Acquisition and Administration of Geometric Data for Thematic Map Production", SIGGRAPH '76, Vol. 10, No. 1, July 1976, pp. 154-162.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4198</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Date, C.J., An Introduction to Database Systems, Addison-Wesley, Reading Mass., 1975.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 THE INTENACIIV~ DIGITIZING OF ~61YGONS AND IHE P~OCESSING CF POLYGCNS IN ~ REIA~IONAL DATABASE ~ohn 
F. ~clntosh The University of Fichigan Ann Arbor, Michigan AHSTRRCT A system is described for ~he interactive 
digitizing of polygons for such two- dimensional spatial modeling applications as growth studies and 
thematic map ~roduction. A digitizer connected online to a mini-computer with a refresh displa~ is used 
for capturing polygon data from source documents. An area boundary network is developed by digitizing 
nodes, pointing to node pairs, and then digitizing edges only once. R CRT display monitors, and bell-rings 
confirm input operations. ~acilities to erase nodes or edges are available. From the nodes and edges, 
software produces polygons which the user may name or discard. Slivering and overlap are eliminated because 
contiguous polygons have identical edge descriptions. Named polygons are then transferred to a large 
university time-sharing computer where spatial editing operations may be carried out, such as unioning 
pieces of a large map. The named polygons may he given additional non-spatial dttributes and entered 
into a relational type of data base. KEYWORDS AND PHBASES: choropleth ma~s, digitizing, polygons, relational 
database, thematic maps CR CATEGORIES: 3. lq, 8.2  I NTRODUCTION Choropleth or thematic maps are a 
powerful medium for presenting two-dimensional spatial data. Examples of the use of this type of map 
can be found in all disciplines, from geography to ~edicine. Their ability to convey information about 
surfaces is such that n uch effort has gone into computerizing their production and manipulation. There 
are two common wa~s of representing area data in a computer. The simplest and oldest technigue employs 
a square grid of cells representing the values cf data  ~oints on the surface. ~his matrix maps readily 
into computer memory, and is easy to manipulate once there. Overlaying of areas is particularly nice 
to do. ~he shortcoming of grid representation is the small cell size, and hence the large amount of storage, 
needed to preserve fine detail. A newer technique emflcys a mosaic of polygons, of arbitrary size and 
shaFe, representing the boundaries of like valued data points. A considerable economy of storage is achieved 
and fine detail can be preserved. The disadvantage is a certain amount of computational complexity. This 
paper describes a system that overcomes most of the problems previously encountered in encodin% and ma~Ji~ulating 
polygons. CIGITIZING PCIYGCNS The capture and encoding of polygons from source documents has often 
been a ~rocess prone to error. Dueke~: [I] itemizes possible errors sQch as missed line segment, failure 
to end a line segment, and failure to latch together line segments at a common junction. If digitized 
separately, points that are intended to coincide often do not. This causes slivering and overlap of polygons. 
We found that by digitizing online, in a highly interactive manner, these errors could he detected and 
recovered fro~ immediately. The need for post-digitizing error checking programs is eliminated, and one 
has greater confidence in the accuracy of the data. ~he following is a description of how the user 
interactively e~codes polygons. ~e minicomputer is in a stand-alone mode at this point. After powering-up 
the machine, hoot- strapping the operating system, and evoking the program from floppy-disk, the user 
tapes his source document to the digitizing surface. He is prom~ted to digitize the lower-left, lower-righf, 
and upper-right corners of the document. These three coordinates allow the progras to  60 develop a 
rotational transformation that is applied to all suiseguently digitized coordinates. No great cane must 
be taken in positioning the doc,|ment as it is thus automatically ,]nskewed. The ~oundary rectangle implied 
here is alsc used to compute scale factors for the display screen. Next the user is ~rcmFted to o~tionally 
digitize two ~eference coordinates and type their corresponding values. Scaling and translation factors 
are computed, to he applied to the final output polygons. If the source document consists of many sheets 
that border or overlap, polygons may be encoded in the co~rect relative position. The main business 
of the use~ now begins. His task is to specify the nodes and edges of a network which will hound the 
areas of interest. Initially there are four nodes and four straight edgss which hound tlze document. 
By positioning the digitizer cursor anywhere inside the boundary of the document and hitting a button 
on the cursor, a new node is created. The node appears on the displa 2 screen as a bright dot. If the 
coordinates are near an existing node, a new node is not created, but a bell sounds once as an indication 
of a find. If the coordinates are rea~ the boundary, the new node is placed exactly on the boundary and 
the hell sounds three times. "Near" is a tolerance distance dynamically selected hy some toggle switches. 
 A particular toggle s~itch permits the user to detail an edge, at any time. l~e user positions the 
curso~ on the starting node of the edge axld a bell ring confirms that a node was found. :he edge detail 
is then traced from the source document, either as a continuous stream of coordinates by holding down 
the cursor button, or as a sequence of ~recisely located coordinates by positioning the cursor for 
each hit. Tc end an edge, the toggle switch is reset and the cursor is positioned on the desired end 
node. A bell ring again confirms that a node was found and the edge appears on the display screen. 
It is permissible to close the edge on the starting node. It is the user's responsibility ~ot to cross 
an edge, over itself or over another edge. The error of failure to latch together line segments at 
a common junction is solved by explicitly pointing to a common junction node. lhe ~rc~lem of slivering 
and overlap is eliminated by digitizing edges only once. An edge may he erased ~y pointing to it on 
the display screen with a light fen. One ~ell confirms a find, a hit on an auxiliary button on the cursor 
erases the edge, and two bells confirm the erasure. The edge may £e redone any number of times. A node 
may be erased by finding it  with the cursor and hitting the same auxiliary button. ~ny edge connected 
to that node is also erased. The error of missed line segments is thus a~eliorat~d by displaying the 
current state of the encoding session a~d by permitting unlimited erasure and reex~try. It is worth 
remarking that users asked for the continual confirmation bells. They seem to reassure users that the 
computer actually carried out the desired operation. Prior to adding the hell signals, the cursor button 
was being regularly mashed to death by anxious fingers. When the document has been encoded to the user's 
satisfaction, a keyboard command starts the program on an irreversitle cycle of for~ing polygons from 
the nodes and edges. As each polygon is constructed,  it is displayed on the screen. The user has the 
option of n~ming it or discar ding it.  WORKING DATA STRUCTURE While the user is digitizing the area 
hounding network of node~ and edges, ~ut before polygons have been generated, a working data structure 
is maintained. A node list contains the X and Y coordinates of all digitized nodes. There is a next-entry 
pointer which is updated whenever a node is added or deleted. The index position on the list of a node's 
coordinates also serves as a node's "number0'. An edge list contains the node numbers of the start and 
end nodes of an edge. ~aintained in parallel with the edge list, such that indices of a particular edge 
are the same, a location list contains the starting record number and record count cf the coordinate 
string describing an edge. lhese coordinates are stored in an unformatted floppy disk file. Also maintained 
in parallel with the edge list, are two lists containing the angle from the start node to the first coordinate 
en an edge, and the angle from the end node to the last coordinate. ~his information is used later in 
pol~gcn formation. A boundary polygon is program defined from the digitized corner~ of the source document. 
Two lists contain the X and Y coordinates and another list contains the node numbers of the corners. 
These corner nodes are also automatically put into the first four entries on the node list. ~hen a location 
is digitized, the node list is searched for near nodes. If no node is within the user selected tolerance 
distance, a new node is added. Hchever, before it is added, the boundary polygon is checked to determine 
if the node is near the boundary. If it is near t}e boundary, it's coordinates are adjusted  61 such 
that the node is exactly on tke boundary polygon, and the node is added to the program's boundary polygon 
defi~itien. If a location is found to he near an existing node, that node's number is posted as found. 
~he user ma~ hit the delete button, and the node will be removed from the node list and from the display 
screen. If the user has indicated that an edge is to be detailed, a found node number is entered on 
the edge list a~ the starting node. The string of coordinates describing an edge are written to a disk 
file as fast as they are received and transformed from the digitizer. When the user indicates the end 
of edge detailing, he points to an existing node whose number is entered as the end node oa the edge 
list for that particular edge. ~he angles mentioned earlier are computed on the fly. Cf course the case 
of a straight rode-to-node edge is recognized. When the digitizing of an edge is complete, a dis;la~ 
subpicture is created. The coordinates are re-read from the disk file, scaled, filtered, and displayed 
on the screen. System display suppert routines return a subpicture number on a light pen hit. A hit 
on the display screen can identify an edge because a correspondence is maintained between display suhpicture 
numbers and indices into the edge list. If the user hits the delete button immediately after an edge 
has been found, it is erased from the screen and the ne~t- entry pointer on the edge list is u~dated. 
The coordinates on the disk are left intact; the pointers to them are overwritten hy the ne~t new edge 
entr~. PCLYGON SET ?CRMAIION When the user indicates that he is finished digitizing, the progra~ begins 
to form polygons from the nodes and edges. T--nr W~I f..... l 121 151 %" ¢~J I LI~KS I I l I I I! 7 
I l I r.L.~ I I 71 21 ; =- I 181 I =~l -~ II "~IL l---J. ...... r-1 ...... T~ 31 6 I I 19! %J 161 ¢~J 
61 q 1 I I 8 I I 5 81 I 1 6 '91 I I 9 61 I I ? 81 I..--. i 8 ¢JI i 7 81 I 8 71 r~-3 r-~-~ 9 7 I lql 7 
91 _ --: __~_J L..--~--J figure 1 Edge Graph and Link List of Nedes  Tills process is irreve[sihle; 
if some edge has been accidently ~issed, the ~hcle document usually must he redigitiTed. The first step 
is identifying polygons is to build a link list cf node number pairs signifying edges, boundary edges 
are entered on the list once, because they can belong to only one polygon. Inte~io~ edges are entered 
twice, once in each direction, because they are shared ty two ~clygons. In this manne~ edges become directed. 
Figure I illustrates an edge graph and the corresponding link list. lhe algorithm for findi~g ~olygons 
is as follows: I. star% with the first node i** the list,  2. find the unused nodes that connect to 
the node,  3. choose a next node that is at the smallest angle frem the preceeding edge (these angles 
where prevJousl~ computed) and mark it as used,   ~. recover the detailed edge coordinate string from 
disk, 5. check for closure, if not go tc 2. Figure 2 -Polygons with }~olez When all nodes on the link 
list have been used, all polygons have been found. ~le area of each polygon is combated using Simpson's 
rule, o~ the trapezoid method of approximating the area under a curve. The area is saved as something 
of possik]e interest to the user. ~ore importantly, if the area is negative (a counte~-clockwiae ordering 
of nodes), the polygon is known to be a hole in some other polygon. ~o find a home for a hole, all ~ositive 
polygons are examined. Polygo~s which enclose the coordinates of a node on tke hole, are selected as 
candidates for owning the hole. lhe smallest enclosing ~olygon is finally taken to have t~e hc]e in it. 
Figure 2 illustrates how holes may in turn have holes. A hole is stored once as a polygon in its e~n 
right, and again in the definition of the smallest polygon that encloses it.  62 Ibis program forms 
polygon "sets" as the fundamental unit of output, because ~clygons mal have one or more holes in tLem. 
Turner [2] is responsible for this notion. Tuerke [3] describes a polygon digitizing s~stem similar to 
this one in many respects. He addresses the ~rchlem of islands and enclaves, and descrikes a solution 
of connecting the hole to the enclosing polygon with an auxiliary edge segment. We believe that a polygon 
set is an improvement in the treatment of holes. RELATIONAL DAIA EASE Polygon sets output from the 
digitizing system are always subjcint. The data is transmitted to the Unlversity's time- sharing system, 
wh6re ~e have "shape editing" programs that allow assen, hly of disjoint ~olygo~, sets. It is here that 
all polygon fragments of a coverage, perhaps from different sheet~ and different digitizing sessions, 
may be union~d together into one set under one name. It was mentioned earlier that coordinates near the 
boundary of a document are moved exactly onto the boundary. This is to avoid slivering cf pelygons that 
are split across sheets. If the sheets ove~!ay somewhat, the overla~ area of the ~elvgon parts is discarded. 
In either the colinear cr overlapping cases, a true union is carried out wherein the common edce disappears. 
The final result is a collection of polygon sets, each set consisting of one o~ ~ore polygons, and each 
set located in a na~ed disk file. An experimental relational data base system has been developed within 
t~e Architectural Research laboratory. ~anipulation of relations between entities, and between entities 
and their attributes can he carried out. A modest command system allows the basic operatiens of projection, 
join, union, difference, and selection as s[ecified by Date[,]. ~he data types under the domains of 
a relation are essentially non-spatiai in this system. They may he a real number, an integer, an 8-character 
string, or a Julian date. Spatial data has been introduced into this system by designating a special 
"shape" domain. The pool cf values which may appear under the sha~e domain are the names of the files 
containing polygon ~et definitions. Belations of entities that have a shaFe attribute may be graphically 
displa~ed, as well as tabularized. A spatial intersection operation is available to construct enquires. 
A spatial un~on {overlay) operation is available to display resultant relations. Thus spatial and non-spatial 
data atout coverages are integrated in manne~ that permits a uniform treatment by the user. CONCLUSICN 
 The system described here was originally put together in response to an u~gent n~ed to digitize some 
data dra~n on Geological Survey 7 1/2 minute guad sheets. If went through several refinements in reaponse 
to user suggestions and later data acquisition emergencies. It remains basically experimental. The users 
are mostly students. Typically, they appear with several sheets of coverages ~oughly outlined with a 
felt pen. Some use the system as nothing more than a super planimeter. All are happy to he immediately 
rewarded with hardccpy of their digitizing fro~ an electrostatic plotter. So far, no large data base 
has been built from high resolution source documents. ~o make a more operational instrument, it is planned 
to add further features to t~e system. Linear data will be introduced as a second type of shape demain, 
fen roads and streams. Point data will also he introduced for text and symbols. We believe that we ha~e 
evolved a~, easy, relatively error-free style for casual users to digitize polygons. And ~e believe that 
the computational complexity of handling polygon data is not prohibitive.  8EFERENCES [I] Dueker, 
Kenneth J., "Cartographic Data Structures: Alternatives for Geographic Infor~ation Systems',, ~K~S~ E~ 
~ Third Annual Conference ea co.&#38;uter G~ph!~s, Interactive lechni~§, a~ ~ Processing SIGGRAPE [!~, 
Vol. 10, Ko. I, July Ig76, pp. 167-172. [2] Turner, James A., Two-Di~ensional Pol__ySo~ Routines: Froqrammer's 
~anual, Architectural Research Laboratory, ~he University of Michigan, Ann A~bor, Michigan, 1976. [3] 
Tuerke, Klaus, "A System for Interactive Acguisitio~ and Administration of Geometric rata for Thematic 
Gap Production", ~IGGRAPH 1!~, Vol. 10, No. I, July I~76, pp. 15,-162. [~] Date, C.J., An Introduction 
~c Database Sxstems, Addison-Wesley, Reading Mass., Ig75.  63  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807372</article_id>
		<sort_key>64</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[A fixed grid curve representation for efficient processing]]></title>
		<page_from>64</page_from>
		<page_to>69</page_to>
		<doi_number>10.1145/800248.807372</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807372</url>
		<abstract>
			<par><![CDATA[<p>A compact form of representation for curves and regional boundaries is described.</p> <p>A curve is approximated by a polygonal line where each side joins a grid point to one of its eight nearest neighbors (as is done in the commonly used chain-encoded representation). Vertex number (2k + 1)2<supscrpt>m</supscrpt> is defined relative to vertex number k2<supscrpt>m+l</supscrpt>. The resulting representation requires about 5 bits of storage per vertex, irrespective of the total length of the curve.</p> <p>Sections of a curve may be collectively examined. Typically, that part of the curve between vertices number k2<supscrpt>m</supscrpt> and (k + 1)2<supscrpt>m</supscrpt>, for some k and m, is considered. Given the locations of the endpoints of a section and the number of sides in the section, it is easy to compute a bounding rectangle which must completely contain the section. Often, this is all the information we need to know about a section. For example, two sections cannot intersect if their bounding rectangles do not overlap. When necessary, a section can be easily divided into two smaller sections, each of which can be examined in turn. This process may be continued down to single sided sections if necessary.</p> <p>Under favorable circumstances, for an n sided approximation to a closed curve, the time required to determine if a point is inside the curve is independent of n. The intersection of n sided approximations to two curves can usually be found in 0(1n n) time.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Cartography]]></kw>
			<kw><![CDATA[Chain-encoding]]></kw>
			<kw><![CDATA[Computational geometry]]></kw>
			<kw><![CDATA[Contour representation]]></kw>
			<kw><![CDATA[Geographical information processing]]></kw>
			<kw><![CDATA[Graphics]]></kw>
			<kw><![CDATA[Grid based representation]]></kw>
			<kw><![CDATA[Line-drawing processing]]></kw>
			<kw><![CDATA[Points in polygons]]></kw>
			<kw><![CDATA[Polygons]]></kw>
			<kw><![CDATA[Regional boundary representation]]></kw>
			<kw><![CDATA[Searching]]></kw>
			<kw><![CDATA[Spatial information]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Boundary representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.1.2</cat_node>
				<descriptor>Approximation of surfaces and contours</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010918</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Approximation algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010400</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Point-based models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31071360</person_id>
				<author_profile_id><![CDATA[81332491680]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Warren]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Burton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Michigan Technological University, Houghton, Michigan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Boyell, Roger L. The method of successive grids for reduction of function storage requirements. Comp. J. 5 (Jan. 1963), 320-321.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359445</ref_obj_id>
				<ref_obj_pid>359436</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Burton, Warren. Representation of many-sided polygons and polygonal lines for rapid processing. Comm. ACM 20, 3 (March 1977), 166-171.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Burton, Warren. A fixed grid curve or region representation for rapid processing. Report CS78-1. Dept. Math. and Comp. Sci., Michigan Technological Univ., January 1978.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356627</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Freeman, Herbert. Computer processing of line-drawing images. Comp. Surveys 6, 1 (March 1974), 57-97.,]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Mandelbrot, Benoit. How long is the coast of Britain? Statistical self-similarity and fractional dimension. Science 156 (May 5,1967), 636-638.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Mandelbrot, Benoit. Fractals: Form, Chance and Dimension. W. H. Freeman, San Francisco, 1977.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A FIXED GRID CURVE REPRESENTATION FOR EFFICIENT PROCESSING Warren Burton, Michigan Technological University 
Houghton, Michigan ABSTRACT A compact form of representation for curves and regional boundaries is 
described. A curve is approximated by a polygonal line where each side Joins a grid point to one of 
its eight nearest neighbors (as is done in the commonly used chain-encoded representation). Vertex number 
(2k + I)2 m is defined relative to vertex number k2 m+l. The resulting representa- tion requires about 
5 bits of storage per vertex, irrespective of the total length of the curve. Sections of a curve may 
be collectively examined. Typically, that part of the curve between vertices number k2 TM and (k + i)2 
TM, for some k and m, is considered. Given the locations of the endpoints of a section and the number 
of sides in the section, it is easy to compute a bounding rectangle which must completely contain the 
section. Often, this is all the information we need know about a section. For example, to two sections 
cannot intersect if their bounding rectangles do not overlap. When necessary, a section can be easily 
divided into smaller two sections, each of which can be examined in turn. This process may be continued 
down to single sided sections if necessary. Under favorable circumstances, for an n sided approximation 
to a closed curve, the time required to determine if a point is inside the curve is independent of 
n. The intersection of n sided approximations to two curves can usually be found in 0(In n) time. 
KEY WORDS AND PHRASES: cartography, chain- encoding, computational geometry, contour representation, 
geographical information pro- cessing, graphics, grid based representation, line-drawing processing, 
points in polygons, polygons, regional boundary representation, searching, spatial information. CR 
CATEGORIES: 3.14, 3.23, 3.30, 3.79, 8.2  I. INTRODUCTION There are a number of ways to represent an 
 approximation to a planar curve in a computer. With the chain-encoded method (4), the curve is overlaid 
with a grid, as shown in Fig. i. Each time the curve crosses a grid line the nearest grid point is noted. 
When these grid points are linked together in order, we get a polygonal approximation such as the one 
shown in Fig. 2. Each side of the resulting polygonal llne joins a grid point to one of its eight nearest 
neighbors. The polygonal line can be very compactly represented by a starting point and a string of octal 
digits, where each octal digit indicates the direction to the next vertex. Unfortunately, vertices may 
only be accessed in sequential order when this method of represen- tation is used. This is fine for short 
curves but can be very expensive when long curves are used in search type operations. h I L i I i -~: 
-@ -/z+ -+ --+ -+ -, -+ --, -'~ --~ -4 i p ~ i I l i f I I I I ! -"+ + -, + ~ + -+ - -+ --~ -+ -4 
i ill l J , ~1 I I I~ i ' s::" :/ :_'_:\: _" :/'" : ............. 4 I l i ; t/ I t i I \l I / 1 I I 
I i / I I I I I I I I I , ; ! /" ; ! i I I I I I I I i. -+ -¥"-@ -i -+ - -~ -÷ -t -+ -~ -4 I i ; ~ I 
I I i I I I Figure 1 An alternative approach is to approximate a curve with a polygonal line and represent 
the curve by a list of vertices. If we do not require that the vertices be located at grid points, fewer 
vertices are required. The binary searchable polygonal representation, or bspr (2), uses this approach 
but requires that certain additional information be stored. The additional information facilitates the 
rapid searching of polygonal lines. The key idea behind the bspr is that a section, or set of consecutive 
sides, of a polygonal llne  64 can be examined collectively. For each section examined, a bounding 
rectangle which completely contains the section is known (either stored or easily computable, depending 
on the section). When necessary, it is always possible to split a multlple-slded section into two subsections 
and examine each separately. To compute the inter- section of two curves, for example, we proceed as 
follows. f , I I nnl In t Inn 14t% 14o '~,~ I I ! 9, / % t I .~'-~/--~ / I I I I I I~llr. t ! . + -I 
 I I .% ill/I I I I I I I I \ I~ C I -r'l- --+ -~ --~-.--~ -+ -+ -e - -+ -~-. \Ad] I , ~ ), , , ~ ,^ 
, , , | 8,-÷-.~.ff,--~-b -/ ~~--.%----~~ ..... *-.4~'% , , ._, /~-:) , , , /, ,\ , , , /' , ...... } 
-" -3 z: I I I I I I I I ~! I ~ i" ...... ,, I I I I I I I I ! I ; o 'o- ~t-~--s-~,~.-%- %- ~z-~e-"-~ 
" i:.:-?,_/~ Figure 2 If the bounding rectangles of two polygonal lines do not overlap then the polygonal 
lines cannot intersect. If the two polygonal lines each consist of a single line segment then any point 
of intersection can be quickly computed. In all other cases, the polygonal line with the larger bounding 
rectangle should be split into two sub- sections and the points of intersection between the other original 
polygonal line and each of these new subsections must be found in turn, in a recursive manner. This results 
in what is essentially a binary search for the points of intersection. Similar search strategies exist 
for other problems. A paper by Boyell (I) suggests an approach by which it is possible to combine the 
advantages of the bspr and the chain-encoded representation. The resulting structure, called the binary 
searchable grid chain representation or bsgcr, is described in section 2. Algorithms for pro- cessing 
a bsgcr are described in section 3. These algorithms are briefly analyzed in section 4 and several extensions 
to this work are considered in section 5. Section 6 is the conclusion. 2. THE DATA STRUCTURE The chain-encoded 
representation is compact because each vertex is defined relative to the previous vertex. The bspr can 
be searched quickly since sections can be considered collectively. The bsgcr will be based on a chain. 
Let v(i) denote the ith vertex with vertices numbered as in Fig. 2. When searching we will only consider 
 sections running from v(i2 m) to v(max(n,(i + l)2m)) for some integers i and m, where n is the number 
of sides in the chain. When using a search such as the one described in the introduction, for i odd 
v(i2 TM) will be first required when the section running from v((i -i)2 m) to v(max(n,(i + l)2m)) i~ 
split. (Note that (i -i)2 m = ((i -i)/2)2 m~± Hence we can define vertex i2TM relative to vertex (i 
- i)2TM. For example, in Figure 2, vertices 19, 20, 21, 22, 23 and 24 are defined relative to vertices 
18, 16, 20, 20, 22 and 16 respective- ly. Vertex number i2 m can be defined by a string of 2m + 3 bits. 
If m=0 then the vertex is defined relative to the previous vertex. We recall that this requires i octal 
digit or 3 bits. If m 0 then the x coordinate difference from v((i -i)2TM) to v(i2 TM) is in the range 
-2m ! dx(i2m) ! +2m, noting that the x coordinate value can differ by at most one from one vertex to 
the next. Since the y coordinate difference has the same range, the difference pair can have any one 
of (2 m+l + 1) 2 values. Since (2 m+l + 1) .2 < 22m+~ for m 0, the difference pair can be represented 
by 2m + 3 bits. This means that 3 bits are required for every other (odd numbered) vertex, 5 bits for 
every fourth vertex, 7 bits for every eighth vertex, and so forth. On average, just under 5 bits per 
vertex are required for these relati%e differ- ences. We will use dv(i) to denote the string of bits 
which defines v(i) relative to some previous vertex. The complete bsgcr consists of some fixed length 
header information and the strings of bits, dv(1) for i < i < n, listed in vertex order. The header information 
includes the endpolnts of the curve, a tight fitting bounding rectangle for the curve, and the number 
of sides in the chain.  3. THE ALGORITHMS The algorithm for finding the points of inter- section of 
two bspr's, as described in the introduction and in (2), can be used for bsgcr's also. The section length, 
rather than bounding rectangle slze, will determine which section is to be split. A bounding rectangle 
can be computed for each section which is examined by the algorithm. Theorem i: Given the number of 
sides, n, of a section and the coordinates of the endpoints, (xa,ya), (xb,yb), of the section, then the 
entire section must be contained in a rectangle with corners at (xmin,ymin), (xmax, ymln), (xmax,ymax) 
and (xmln,ymax) where xmln = ~xa + xb -n)/27 xmax = ~(xa + ab + n)/2J ymin = ~ya + yb -n)/2] ymax 
= ~(ya + yb + n)/2]. Proof: Since llne segments are convex, some  vertex, (xleft,yleft), must be as 
far to the left as any point in the section (taking left to be in the negative x direction, as usual). 
Since the chain contain only n segments and the x coordinate value can change by at most one along any 
segment, it follows that (xa -xleft) + (xb -xleft) in" This implies that xleft > (xa + xb -n)/2. 
Since vertices must have integer coordinates, xleft ~xmin = ~xa + xb -n)/~ . The other three parts 
to the proof are similar.  Note: This means that a section must be com- pletely contained in a n × n 
square centered on the midpoint of the chord Joining the endpoints of the section. When the bounds of 
this square do not all have integer values, the square can be reduced to an (n -i) x n or n × (n -i) 
or (n -i) × (n -i) rectangle.  This reduces the problem down to determining the locations of the endpoints 
of each section. We will need another theorem in order to know where to look for the strings of bits 
defining the endpoints of particular sections. Theorem 2: The total number of bits required to store 
the values dv(1), for 1 < i < n, is Z(n) = 5n -2k(n) where k(n) is the number of 1 bits in the binary 
representation of n. Proof: We first consider the case where n = 2 m -1 for some integer m. For m = 
i, ~(i) = 3 since dv(1) always requires 3 bits. For m i, £(2 m -i) = Z(2 m-I -i) + 2m + 1 + £(2 m-I 
-i), since Z(2 m-I -i) bits are required for dv(1) through dv(2 m-I ~ i), 2m + 1 bits are required for 
dv(2m-±), add £(2 m-I -i) bits are required for dv(2 m-I + i) through dv(2 TM -i). We can easily confirm, 
by induction, that £(2 m -i) = 5(2TM -i) -2m. Since £(2 m) = £(2TM -i) + 2m + 3, with dv(2 m) requiring 
2m + 3 bits, we have Z(2 m) = 2m5 -2. Finally, if n has k(n) 1 bits in its binary k(n) 2J i representation, 
then n = ~ for some i=l k(n) {Ji}i=l with J l TM J 2 "'" > J~$n) >-- 0. k(n) " Clearly, ~(n) = I 
~(2 Ji) since i=l dv(l + Pl I- 2 jl) through dv( ~ 2 ji) will i=l i=l require £(2 jp) bits. Hence Z(n) 
= k(~)(2Jib--2) = 5n -2k(n). i=l Corollary: The total number of bits required to store the values of 
dv(i), for J2 TM < i < (J + i)2 m iS Z(2 m -i) = 5(2 m -I) -2m. These results confirm that we need an 
average of  just under 5 bits of storage per vertex for the variable length portion of the bsgcr. They 
also tell us where to look for the bit strings de- fining particular vertices. For example, suppose 
a section running from v(24) to v(32) of some bsgcr must be split. We need to determine the location 
of v(28) which is defined relative to ~24)~ By the corollary we know that there are 5(~ -i) -2 2 = ii 
bits (represent- ing dv(25), dv(26) and dv(27) of lengths 3, 5 and 3 respectively) which must be skipped 
in going from the end of bit string dv(24) to the start of dv(28). Similarly, if the section from v(64) 
to v(128) is to be split, then the string of bits between dv(64) and dv(96) is 5(25 -i) -2 . 5 = 145 
bits long. (Clearly it is desirable to have a table giving 5(2 m -i) -2m for various values of m, rather 
than to repeatedly compute these values.) There are other interesting search algorithms. To determine 
whether a point is inside a closed curve, a line crossing algorithm is used. A point is inside a closed 
curve if and only if a ray originating at the point crosses the curve an odd number of times (going from 
inside to outside or visa versa with each crossing.) We will select a ray going to the right. If the 
point is not inside the rectangle bounding a section, then it is easy to determine whether the ray crosses 
the section an odd or even number of times from the location of the bounding rectangle and the loca- 
tions of the endpoints of the section. If the point is inside the rectangle and the section contains 
more than one side, then the section must be split. If the section contains a single side, then it is 
easy to determine if the ray crosses the section. This algorithm is consider- ed in more detail, in the 
context of the bspr, in (2). A number of other search type problems, such as finding the minimum distance 
between two curves, can be efficiently solved by using bsgcr's. 4. ANALYSIS In this section we will 
consider two simple problems in order to gain an understanding of the asymptotic behavior of the intersection-of-curves 
and the polnt-lnside-of-a-closed-curve algorithms. We will also briefly consider how tightly a computed 
bounding box is likely to fit a section of a curve. The problem of determlning whether a point is in- 
side a circle will be the first problem consider- ed. We willlassume that the circle is approxi- mated 
by a 2 j sided chain where j is some large integer. The initial and final vertices, which are identical, 
should be located at the extreme right point of the circle. If a point is outside the bounding rectangle 
of the circle, then it is possible to determine immediately that the point is outside the circle. We 
will consider points located randomly, with a uniform distribution, inside the bounding rectangle, which 
is in fact a square. The cost of the containment determination will be  measured in the number of sections 
which must be split, noting that 2k + i sections are examined when k sections are split. This problem 
has been considered in the analysis of bspr's [2]. We will take a similar but less detailed approach 
here. All sections running from i2m+ v((i + l)2m), for some integers i and m, are candidates for consideration. 
Exactly those sections which con- tain the point being tested in their bounding rectangles must be split. 
Without loss of gener- ality we can take the area of the original bound- ing rectangle to be one, so 
the probability that the point lies in some region of this rectangle is equal to the area of the region. 
This means that the radius of the circle must by 1/2. Clearly the point is in the rectangle of the complete 
circle and the two top level subsections (half circles), giving 3 sections which must be split for every 
point. It is easy to confirm that the expected number of computed quarter circle bounding rectangles 
which contain the randomly placed point is a little less than i. 5 (excluding the area outside the original 
tight fitting box.) This brings the total to 4.5 sections. It is also easy to confirm that for a grid 
width of d a circle is approximated by about 2/2(i/d) sides. (In the first eighth circle each side has 
a positive y component. The total y gain is /2/4 by simple geometric computation.) If we divide the circle 
into 2 TM sections, each contains about /2/2m-l(i/d) sides and has a cqmpwted ~ounding rectangle containing 
about i/2zm-o(i/dZ) grid squares. The total area of each rectangle is i/22m-3. There are 2 m such rectangles 
with total area i/2 m-3. Some of this area will lie outside the original tight-fitting bound so the argument 
will give us an upper bound. It follows that the total number of sections which must be split is less 
than 4.5 + [ i/2 m-3 = 6.5, giving a upper i=3 bound on the expected amount of required pro- cessing 
which is independent of the precision to which the circle is approximated. We expect to split less 
than 6.5 sections, or equivalently, less than 14 sections are examined. Of course, the closer the point 
is to the circle, the greater the number of sections which must be split. Figure 3 shows a typical 
point, a very precisely defined circle and the computed boxes for those sections which are examined 
but not spllt. The number of sections examined and split is always one less than the number of sections 
examined but not split. The boxes indicate the precision to which different parts of the circle must 
be examined. Figure 4 shows similar information for a point which is very near the curve. If we were 
to solve the same problem by computing the distance from the center of the circle to the point, then 
the number of significant digits to which the computation would need to be carried would depend on how 
close the point was to the circle. The number of digits required would tend to vary directly with the 
number of section splits required for the binary search method. In the first case we are computing a 
distance, in the second we are searching for a crossing point. In both cases we continue our computation 
until our answer is sufficiently accurate to determine point containment. Figure 3 Figure 4 We will 
now tur~ our attention to the problem of finding the points of intersection of two curves. Again we turn 
to a simple and admittedly well- behaved example. Consider two straight lines, both approximated by 
chains, intersecting at a point. Since we always split the longer section (and make a systematic selection 
with equal length sections) when the computed rectangles of sections of two curves overlap, it follows 
that the sections of  67 a curve of a particular size which must be split are those whose rectangles 
overlap rectangles of sections of the other curve having a particular size.  If we go down two levels 
in our search, to the point where, for each curve, we are dealing with sections which are half as long 
as the former sections, then we are back to essentially the same position as before, except at 1/2 scale. 
(There are some differences. The point of intersection may be relatively nearer to or farther from the 
edge of a box. However, the expected situation is the same.) The depth of the search is equal to the 
sum of the logarithms base 2 of the lengths of the two curves (or, equivalently the log of the product 
of the lengths). Since at each level we have the same expected situation, it follows that the search 
time for the point of intersection varies loga- rithmically with the number of sides. If the two lines 
under consideration are close to parallel, the constant of proportionality is likely to be fairly large, 
since lots of rectangle pairs will overlap in situations where the corre- sponding sections do not intersect. 
If two curves intersect in several places, then at each point of intersection there will be a logarithmic 
search. If curves wiggle near each other, without inter- secting, then the search must proceed to the 
point where the computed section rectangles no longer overlap. Since the character of curves and the 
expected degree of intertwining between curves varies from application to application, it is difficult 
to make any precise performance estimate that is likely to be meaningful to real world users. All we 
can say is that in nice cases, we tend to have a logarithmic search. One final question will be considered 
in this section, in anticipation of the next section. It is often the case that a section can be enclosed 
in a rectangle which is much smaller than the computed rectangle for the section. The probability that 
a section must be split tends to vary with the size (either area or length) of the rectangle. We would 
llke to know how tightly the computed rectangles of a "typical" section tends to fit the section. If 
a curve wiggles a lot, then a minimal rectangle may be very much smaller tha~ a computed rectangle since 
the size of the computed rectangle depends  numbers of sides, there may be considerable advantage to 
using tight fitting rectangles, at least at upper levels.  5. EXTENSION AND VARIATIONS In this section 
we will consider three topics; explicit representation of minimal rectangles, algorithms for curves defined 
at different scales, and the extenslonof this approach to three dimensions.  We start by considering 
the amount of storage necessary to explicitly represent minimal rectangles. We let (xleft,yleft) be the 
left most vertex of a section with n = 2 m side and endpoints (xa,ya) and (xh,yb). Recalling the proof 
of Theorem 1 from section 3, we see that xmin = ~xa + xb - n)/2 l ~ xleft ! mln(xa,xb) ~ ~xa + xb)/2J. 
 At most, xleft can assume any one n/2 + 1 = 2 m-I + i values: ~xa + xb)12J, ~xa + xb)12 iJ, .... kxa 
+ xb)/2 -n/2~. Similarily, xright, ytop, and ybottom each may take on any one of at most 2 m-I + I values. 
(Note: When m=0, the four values are determined by (xa,ya) and (xb,yb).) Clearly, we can define each 
of these values with m bits. Without packing, the bounding rectangles can be defined by 4m bits. With 
packing 4m -3 bits are required for m ~ 4, and 0, 4, 7 and I0 bits are required for m = 0, i, 2 and 3 
respect- ively. For 1 ~ i < n, with n being the number of sides of a Gh@in, v(i) divides a section with 
at most 2 m(i)+l sides into two sections, each with at most 2m(i) sides, where m(i) is the number of 
2's in the factorization if i. For indexing and bit counting purposes, we can associate the minimal rectangles 
for these two sections with v(i). Note that we do not need to associate any rectangle with v(O) or v(n) 
given that the n~inimal rectangle for the entire curve is stored. Using argument similar to those in 
the proof of Theorem 2 it is easy to show that, without packing, a total of 8(n -k(n) - m(n))bits are 
required for the bounding rectangles, with k(n) being the number of 1 bits in the binary expansion of 
n and m(n) being defined as above. This means that the storage required for the bsgcr and minimal rectangles 
is about 260% of that required by the hsgcr alone. Packing reduces this figure some. only on the number 
of sides in the section. Studies by Mandelbrot (5,6) indicate that for many curves there may be values 
C and z which are characteristic of the curve, such that the expected area of the rectangle for an n 
sided section is Cn z, with 1 < z ! 2. For very wiggly "space filling" type curves, z is likely to be 
near i, whereas for straight lines z = 2. (In the notation of Mandelbrot z = 2/D. For natural curves 
z is likely to range from about 1.96 for smooth curves such as the coast of South Africa down to about 
1.6 for irregular curves such as the east coast of Britain, based on figures quoted in (5).) In an environment 
where curves tend to have relatively small z values and very large With packed rectangles we must treat 
the bottom 4 levels somewhat differently since more than 4m -3 bits are required for rectangles of section 
with 2 m sides for m < 4. It appears that the real need for minimal bounding rectangles occurs at the 
higher levels, partlcularily in light of Mandelbrot's work. The obvious solution is to store rectangles 
of minimal size only for those sections with a certain minimum number of sides. For example we might 
compute the bounding rectangles when m(i) ~ 4. This reduces the storage requirements for rectangles to 
34[n/16] -8(k([n/16]) + m([n/16])) -26, or Just under 2.125 bits per vertex. Asymptotic storage requirements 
for a bsgcr and minimal rectangles  for appropriate sections with 16 or more sides come to 7.125 bits 
per vertex, or 7.5 bits per vertex if xleft, xrlght, ytop and yb~ttom are not packed. The use of bsgcr's 
is partlcularily appropriate to environments where different curves must be represented to different 
precision. To get a less precise approximation of a curve, one simply avoids going full depth. For example, 
given a precisely defined road and a roughly defined region receiving more than 20 inches of rain in 
an average year, one may wish to know the point at which the road enters the region. Clearly there is 
no merit in finding the point to a greater precision than that used to define the regional boundary. 
The precise road definition is of no real use to us. Once we have a road section with a bounding rectangle 
which is both as small or smaller than the size of the grid used to define the region and is known to 
contain the desired point of intersection, then we need not proceed further. If we require that the point 
of intersection lie on the road, then any vertex of the selected road section will give us a result which 
is accurate to the precision of the regional boundary. The ability to access a curve at any of various 
accuracies also makes smoothing a curve for display trivial. In general, if different grid sizes are 
used, it is desirable to have the ratio between any two be a power of two. We now turn our attention 
to surfaces in three space. The paper by Boyell discussed in section 2 is quite general. Given a integer 
valued function z(i,J) defined in terms of two integer parameters, i and J, with 0 < i < imax, 0 < j 
< jmax, Boyell's method may be applied provided Iz(i,j) -z(k,Z) I < max(li - k|, |J -£1) for all valid 
i, j? k and £. The value of z(i,j) is defined relative to z(i -2m,j) or z(i,j -2 m) or z(i -2m,J -2 m) 
where m = min(m(1),m(j)), depending on whether m = m(1) or m = m(J) or both. Contour maps and other functional 
(or 2 ~ - D) surfaces can, of course, be represented in this way after suitable scaling. More general 
surfaces may be represented by parametrically representing x, y and z coordi- nates. Conditions similar 
to the restriction on the rate of change for z given above apply to all three coordinate functions. By 
using more bits to represent each difference, we can reduce these restrictions to Iz(i,j) -z(k,l) I e 
C max(li - kl,lJ - ~I), with similar in- equalities for x and y. The practicality of using this method 
to represent surfaces has not been fully investi- gated. It may be useful where several instances of 
an object must be displayed, each with a different scaling. If the master copy is defined as described 
above, then it is possible to access different instances at differing preclsions by not going full depth 
in retrieving control points. The method also may make it possible to quickly solve problems such as 
finding the point of intersection between a curve and an irregular surface.  6. CONCLUSION By storing 
the differences between the coordinates of various vertices of a chain approximating a curve (so vertex 
number (2k + I)2 m is defined relative to vertex 2k2m), we have been able to develop a compact representation, 
the binary searchable grid chain representation or bsgcr, which can be quickly processed. We need less 
than 5 bits of storage per vertex, plus several words of header information, for each curve. For nice 
cases, the time required to determine if a point is inside a closed curve is independent of the number 
of side in the chain approximating the curve. Points of intersection can be found by a logarithmic 
search. More information on the bsgcr may be found in [3]. ACKNOWLEDGEMENT I would like to thank Robert 
Fowler of Simon Fraser University for bringing to my attention the direct relationship between the depth 
of the search in the inside test and the number of significant digits needed to compare the radius of 
a circle to the distance from the center of the circle to the point being tested. The algorithms described 
in section 3 have been programmed in FORTRAN and tested by Richard Verburg. REFERENCES i. Boyell, 
Roger L. The method of successive grids for reduction of function storage requirements. Comp. J. 5 (Jan. 
1963), 320- 321. 2. Burton, Warren. Representation of many- sided polygons and polygonal lines for 
rapid processing. Comm. ACM 20, 3 (March 1977), 166-171.  3. Burton, Warren. A fixed grid curve or region 
representation for rapid processing. Report CS78-I. Dept. Math. and Comp. Sci., Michigan Technological 
Univ., January 1978.  4. Freeman, Herbert. Computer processing of line-drawing images. C omp. Surveys 
6, i (March 1974), 57-97.,  5. Mandelbrot, Benoit. How long is the coast of Britain? Statistical self-similarity 
and fractional dimension. Science 156 (May 5, 1967), 636-638.  6. Mandelbrot, Benoit. Fractals: Form~ 
Chance and Dimension. W. H. Freeman, San Francisco, 1977.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807373</article_id>
		<sort_key>70</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[3-D graphic display of discrete spatial data by prism maps]]></title>
		<page_from>70</page_from>
		<page_to>75</page_to>
		<doi_number>10.1145/800248.807373</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807373</url>
		<abstract>
			<par><![CDATA[<p>An efficient algorithm for displaying 3-D scenes showing a discrete spatially varying surface is described. Given a 2-D map or planar graph composed of polygons where each polygon has a positive real number attribute, a prism is erected on each polygon with height proportional to that attribute. The resulting 3-D scene is plotted with shading and hidden lines removed. Thus the spatial variation of the attribute may be quickly and intuitively grasped by the nontechnical observer. This has applications to areas such as geography if the map is a cartographic map, or to physics if the map diagrams the periodic table. The algorithm takes time O(N*log(N)) where N is the number of edges in the map. Most of the calculations can be done without knowing the prism heights so extra plots with different attributes for the prisms can be produced quickly. This algorithm has been implemented and tested on maps of up to 12000 edges.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[3-D]]></kw>
			<kw><![CDATA[Cartography]]></kw>
			<kw><![CDATA[Display]]></kw>
			<kw><![CDATA[Graphics]]></kw>
			<kw><![CDATA[Hidden surface]]></kw>
			<kw><![CDATA[Map]]></kw>
			<kw><![CDATA[Perspective]]></kw>
			<kw><![CDATA[Prism maps]]></kw>
			<kw><![CDATA[Shading]]></kw>
			<kw><![CDATA[Thematic mapping]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Hidden line/surface removal</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P239147</person_id>
				<author_profile_id><![CDATA[81100065331]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Randolph]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Franklin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Center for Research in Computing Technology, Harvard University, Cambridge, Mass.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31084530</person_id>
				<author_profile_id><![CDATA[81100349371]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Harry]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Lewis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Center for Research in Computing Technology, Harvard University, Cambridge, Mass.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Anderson, Delmar E. &amp; Angel, James L. &amp; Gorney, Alexander J. World Data Bank II: content, structure &amp; application. An Advanced Study Symposium on Topological Data Structures for Geographic Information Systems, Oct 16-21, 1977, Laboratory for Computer Graphics and Spatial Analysis, Graduate School of Design, Harvard University.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Chrisman, Nick. Concepts of space as a guide to cartographic data structures. An Advanced Study Symposium on Topological Data Structures for Geographic Information Systems, Oct 16-21, 1977, Laboratory for Computer Graphics and Spatial Analysis, Graduate School of Design, Harvard University.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Dougenik, James. LINGUIST: A table driven language model for Odyssey. An Advanced Study Symposium on Topological Data Structures for Geographic Information Systems, Oct 16-21, 1977, Laboratory for Computer Graphics and Spatial Analysis, Graduate School of Design, Harvard University.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Douglas, David &amp; Peucker, Tom. Algorithms for the reduction of the number of points required to represent a digitized line or its caricature. Canadian Cartographer, Dec 1973.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Franklin, Wm. Randolph. Combinatorics of hidden surface algorithms. Harvard University, Center for Research in Computing Technology, Technical Report, 1978.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>280635</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Knuth, D. E. The Art of computer programming, vol. 3. Sorting and Searching, Addison-Wesley, 1973.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[The Lab for Computer Graphics and Spatial Analysis, Harvard University. ASPEX users' reference manual, (Jan. 1978).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[The Lab for Computer Graphics and Spatial Analysis, Harvard University. SYMVU manual, (1977).]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Mandlebrot, Benoit. Fractals: form, change and dimension. WH Freeman and Co., San Francisco, 1977.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>810236</ref_obj_id>
				<ref_obj_pid>800179</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Newell, M. E. The progression of realism in computer generated images, ACM 1977 National Conference.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M. &amp; Sproull, R. F. Principles of interactive computer graphics. McGraw-Hill, 1973.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Tobler, Waldo. A Computer Program to Draw Perspective Views of Geographic Data. Cartographic Lab Report, #1, Dept. of Geography, U. of Michigan.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 3-D GRAPHIC DISPLAY OF DISCRETE SPATIAL DATA BY PRISM MAPS J Wm. Randolph Franklin Harry R. Lewis 
 Center for Research in Computing Technology Harvard University, Cambridge, Mass., 02138 CS sections: 
8.2, 3.19, 3.23, 3.39, 3.59, 3.79, 3.9, 5.25, 5.31 Key words: prism maps, graphics, 3-D, display, 
hidden surface, map, perspective, cartography, thematic mapping, shading 1.0 ABSTRACT An efficient 
algorithm for displaying 3-D scenes showing a discrete spatially varying surface is described. Given 
a 2-D map or planar graph composed of polygons where each polygon has a positive real number attribute, 
a prism is erected on each polygon with height proportional to that attribute. The resulting 3-D scene 
is plotted with shading and hidden lines removed. Thus the spatial variation of the attribute may be 
quickly and intuitively grasped by the nontechnical observer. This has applications to areas such as 
geography if the map is a cartographic map, or to physics if the map diagrams the periodic table. The 
algorithm takes time O(N*log(N)) where N is the number of edges in the map. Most of the calculations 
can be done without knowing the prism heights so extra plots with different attributes for the prisms 
can be produced quickly. This algorithm has been implemented and tested on maps of up to 12000 edges. 
  2.0 INTRODUCTION Consider a scene consisting of a base map such as the USA, as shown in Figure I, 
with prisms of varyxnE height~ on each skate. For example, in Figure 2, each state's height is proportional 
to its number of alcoholics per 100,000. It is very easy to see how the data varies: Nevada is first 
which we can rationalize easily enough, but Rhode Island is second and Wisconsin is third. This is totally 
unexpected. We could also obtain these facts from a Census table but that table could not show us the 
spatial relationships: each of these three states is surrounded by neighbours with far lower rates. 
This example illustrates both what a PRISM-MAP is and why it is so useful. With the information explosion, 
it is no longer enough to produce data; the data must be in a form that a casual observer can easily 
and intuitively appreciate or else it is worthless. As computing power becomes cheaper, powerful display 
techniques like this become more important both because there is more data to display and because the 
display techniques are less expensive to use. This paper describes a new, faster algorithm to produce 
prism maps. Indeed, most of the calculation can be performed on the two dimensional base map, producing 
an intermediate file that can be combined with different sets of heights to produce new plots. This 
algorithm takes time O(N*log(N)) where N is the number of edges in the map. If cost were no object this 
algorithm would not be necessary, since a three dimensional scene could be generated from  i 9 6 3 0mlO 
3 Figure I: Base map of USA by state. Figure 2: Estimated Alcoholism per 100,000 m Work partially supported 
by the Lab for by state. Computer Graphics and Spatial Analysis, Harvard University. 70 the base map 
and heights and then fed into a general hidden surface routine. The only previous published solution 
did just this. Tobler [12], took at least O(N 2) time, and could only process a few hundred edges. This 
algorithm solves the problem of displaying a discretely varying 3-D surface of a function of two variables. 
Hidden surface contouring algorithms such as ASPEX [7] handle the continuous case. This algorithm adapts 
the concept of a horizon line r developed by 1967 for the continuous case by Hens and Tobler [8] in the 
ASPEX program. Although problems like this are not that well known in the computer science community, 
there have been attempted solutions for several years by cartographers and geographers. Even though three 
dimensional plots are more appealing, because of their difficulty, various two dimensional methods have 
heretofore necessarily been used.  3.0 THE ALGORITHM  3.1 Definition Prism: A polyhedron that is the 
extension of a polygon in the XY plane, into the Z direction. The top face is congruent to, parallel 
to, and straight above the bottom face. The side faces are vertical rectangles. If the 2-D polygon has 
N sides then the prism has 2N vertices, 3N edges, and N+2 faces. A simple polygon and the prism derived 
from it are shown in Figure 3.  3.2 Basic Al~orithm The algorithm is basically this:  I. Read the 
input map and normalize it. 2. Write its edges to a file, one edge per record.  3. Sort the file by 
minimum ¥ value of each edge.  4. Process the resulting file with a local processor that:  I. Reads 
edges in order, into memory, 2. Reorders them while in memory so that if  edge E I hide~ (defined later) 
E2, then E I occurs before E 2.  3. Writes them out.   5. Repeat the following as often as desired, 
once per plot:  /  Figure 3: A simple polygon and the prism derived from it. I. Read the set of prism 
values or heights into memory. 2. Read the final sorted file and as each edge is read, draw part of 
the plot.  The steps will now be explained in more detail.  3.3 Innut The map consists of points, 
lines and polygons. However the only explicit datatype is a set of straight edges or line segments that 
form a planar graph. The polygons, marked by unique identification numbers, can be built from the edges. 
Each edge, Ei, represents a quadruple (Ai, Bi, Li, Ri). A i and B i are the coordinates of the two endpoints. 
L i and R i are the two polygons, on the left and right of E i (looking from A i towards Bi). The nonexistent 
polygon on the exterior is numbered zero.  3.4 Normalization The map can be observed in perspective 
in two dimensions from some general point (X,Y) in the plane. It is rotated, scaled and perspectively 
transformed to make the viewpoint be at (0, -infinity). So now the projection is orthogonal. For the 
actual 3-D scene, the viewpoint is in 3-space with a line from it to the origin forming a given altitude 
angle with the horizontal. [11] gives a thorough description of 3-D transformations and projections. 
 3.5 First Sort The first sort is by the minimum Y coordinate of each edge. It is very simple and can 
be done quickly enough by any reasonable external sorting algorithm, such as Knuth [6]. !  Figure 4: 
The "hiddenness" relation among map edges.  3.6 The Partial Order 3.6.1 The Partial Order In 2-D - 
 Definition: Edge A on the input map directly hides edge B iff there exists a vertical llne which intersects 
both A and B with the B intercept being higher, and with no other edges intersecting that line between 
the A and B intercepts. The vertical line can intersect either edge at an endpoint. This means that at 
that line, A obscures B as seen from the viewpoint and that no other edge is between them at that point. 
 Definition: A indirec$1¥ hideg B iff there is a sequence of N>2 edges C i with A=Ci, CN=B , C i directly 
hiding Ci+1, and A does not hide B directly Definition: A hides B iff A directly hides B or A indirectly 
hides B. Notice that "hides" is closed under transitive completion. Thus "hides" is a partial order 
on the edges of the input map. In Figure 4, A directly hides B but doesn't hide C, directly or indirectly. 
Note that A can indirectly hide B even though there is no vertical line intersecting both A and B. Hiding 
induces a partial order in 2-D because there cannot exist a finite sequence of edges, each hiding the 
next and the last hiding the first. This is not true in 3-D since three general oblique rectangles, A, 
B, and C, can be arranged so that A directly hides B, B directly hides C, and C directly hides A.  3.6.2 
The Partial Order Extended Into 3-D - The prisms' tops and sides do not, in general, satisfy the partial 
order but they can be transformed until they do. Figure 5 shows hew a prism top is split into several 
slices by dropping lines from some of its vertices. After each prism top is split into several smaller 
polygons, the new set of polygons can be arranged into a partial order. In fact, the 3-D order can be 
easily formed from the 2-D order. As Figure 5 shows, each top slice is related to one edge of the original 
polygon. Not all edges, but only the "top edges", induce prism top slices They are dashed in the ! 2 
: 4%% ~X   : __.N ! figure. Thus the complete 3-D partial order can be formed by sorting the edges 
in 2-D. Then every edge causes a side polygon of a prism and some edges cause top slices also in the 
proper place in the order. The top slice polygon caused by any edge in placed immediately before the 
side polygon from that edge in the 3-D order. Now given that the prism map's polygons can be ordered 
as described above, a possible hidden surface algorithm would be to paint them in order onto an initially 
blank screen, taking care to paint only blank parts of the screen and never to overpaint anything. But 
first the partial ordering has to be calculated. 3.7 The Final Sort The algorithm for the final sort 
is given here briefly Although it is conceptually simple, it is the most difficult part of the whole 
prism-map algorithm. The details are given in [5]. I. Run a scan line up the screen, from the bottom 
to the top. 2. As the scan line rises above the bottom of an edge, E, read it into memory.  3. When 
E is read into memory, compare it against the edges adjacent to it on the scan line to determine if it 
directly hides them or them it. If one, say A, hides another, say B, add a link between A and B so each 
knows about the other.  4. If the scan line rises above the top point of E, then:  I. If E is has been 
determined to be hidden by any edges still in memory, then do nothing 2. Otherwise write E to the final 
sorted edge file.  5. If E was written, possibly there are some edges that were remaining in memory 
only because they  dUlUb qnl n ,e o~t°" : "1"  i' ! } o-" ~ ..." | "'" .......... .~ ..~........~" 
~'~I~7 "~Polygon A " .- . . . . ~ Edge E ~,b"°-6.. * tJo ~'.° Polygon B  Figure 5: Dividing a prism 
top into slices Figure 6: The plot lines derived from one by dropping lines down from vertices map edge 
 induced by two or more edges of the map. were hidden by E and no other edges. If so, write Nevertheless 
it is drawn only once since after the them out, and repeat the process until there are no first time 
it is drawn, the horizon llne is raised edges completely below in the scan line remaining high enough 
that it is not drawn again. in memory unless they are hidden by some edge still in memory. 3.8 Makin~ 
The Plot The sorted edge file that was produced in the previous section can now be used with any set 
of prism heights to produce a plot. The basic algorithm uses a concept of a horizon line that has been 
used previously to draw hidden surface plots of net representations of bivariate functions. See references 
[7] and [8]. A horizon line is a function Y=F(X,T) where X and Y address the plotter screen and T is 
the elapsed time. The line stretches across the plot from left to right and since it is a function never 
doubles back on itself. At T=O, it lies along the bottom edge of the plot and it increases with T. At 
any time, it cuts the plots into two regions: The area below has been calculated and plotted while the 
area above has not been touched yet. As a new part of the plot is calculated, the horizon line is raised 
above it to include it. Thus this is simply an implementation of the simple algorithm mentioned above. 
 To produce the plot, the prism heights are read and stored in memory in a hash table indexed by polygon 
number. Then the sorted edge file is read, and each edge induces part of the plot. Consider for example 
edge E in Figure 6. It has polygon A on its left and B on its right. E causes four lines to be drawn 
-the dashed lines in the figure. They are two vertical edges common to the two prisms and a top edge 
of each prism. The heights at which to draw the lines are known since each edge knows the polygons on 
each side. If the horizon line should cut across the lines, only the part above the horizon line is drawn. 
This is the way hidden edges are prevented from being drawn. After the lines are drawn, the horizon line 
is rased above them. Figure 7 shows Figure 2 halfway through its plot with the current horizon line sketched 
in. In Figure 6, the left prism is higher than the right one. If it were lower, then only one top edge 
would be visible to be drawn, since the higher right prism would hide the left one. Also note that every 
vertical edge of a prism can be  3.9 Shadin~ The last section described how the plot was drawn and 
how hidden lines were calculated; this section describes how it is shaded. Two different types of shading 
are possible: contour lines or vertical shading that assumes an imaginary light source. In either ease, 
extra lines that were not part of the original plot are added to highlight it.  3.9.1 Contour Lines 
- These lines run along the sides of the prisms and in the original 3-D scene would be horizontal. If 
the prisms were cut from thick layers of plywood, the contour lines would be the joins between the plies. 
They are equidistant and enable the user to count up the side of the prism to determine its height. 
Contour lines may produced by not drawing the top edges of the prisms immediately. Instead the top edge 
is raised gradually from the bottom edge in increments of the contour spacing until its proper value. 
The complete calculation involving the horizon line is performed for each contour line. The edges are 
still processed in order: all the contour lines for each edge are drawn before the next edge is read. 
This seems slow but is necessary to determine which parts of the contour lines are visible. Figure 8 
shows per capita public school expenditures by state with the contour lines at multiples of $50. For 
comparison, Figure 9 shows relative illiteracy, by state. It is shown from the north since the higher 
southern states would otherwise hide the northern states.  Figure 7: The horizon line when the plot 
is Figure 8: Public school expenditures, in progress. dollars per capita; showing contour lines in a 
prism map. When the contour lines are drawn, it is usually desirable to draw only some of the vertical 
edges, those that are in some sense "silhouette edges". 3.9.2 Vertical Shading - The sides of each prism 
can be shaded with vertical hatch lines that create a grey scale approximating illumination from a light 
source. However, the intent here is not to approximate physical reality, (for which see Newell [10]), 
but to suggest contrasts so as to make the plot easier to understand. As an analogy, it is easier to 
learn to recognize a person from a skilled caricature than from a photograph since the cartoon emphasizes 
the features, be they a large nose or whatever, that are not average and plays down the normal ones. 
Here it is desired to highlight the indentations in the boundaries. To do this, a cosine law raised to 
a power is used. With a cosine law, the shading on a face is directly proportional to the cosine of the 
angle between the normal to the face and the direction of an imaginary light source. Raising the cosine 
to a power increases the amount of very light and very dark areas at the expense of the middle intensity 
grey areas that would normally cover most of the plot. that shading down from the top edge of A shades 
precisely that part of the side face of A which is above B. There are various details to handle if the 
shading is to be attractive. For instance, the rectangles along an edge are not being shaded in consecutive 
order so the shading must be designed to blend smoothly from one rectangle to its neighbours. Also a 
rectangle may be narrower than the shading spacing in which case it randomly gets either zero or one 
shade lines so that its expected shading density is correct. 4.0 RESOURCES REQUIRED BY THE ALGORITHM 
 4.1 Time To analyze the time required by this algorithm, it is necessary to know the distribution 
of the relevent characteristics of the input scenes as they get bigger. A useful statistic is the average 
length of the edges as the number of edges, N, increases. This also controls the number of edges that 
intersect an average scan line which is the number of edges in memory at any time during the final sort. 
The dependency can be obtained either theoretically from first principles, or experimentally, by measuring 
actual maps. In Figure 6, edge E induced two areas to be shaded. They are a vertical side face of prism 
A and a slice of the top of prism B. The areas in each case are precisely the area between the corresponding 
top edge and the current horizon line. The top edge of B is drawn first and then the top of B below the 
edge down to the horizon line. Since the other edges of B that are below E have already been processed, 
the horizon line cannot be below the bottom of B's top. Thus shading down from the top edge doesn't cause 
a streak down. to the bottom of the plot. After the top edge of B has been drawn, E causes the top corresponding 
top edge of A to be processed. By now the horizon line is at the top edge of B so 3 ulO 0 Figure 9: 
Percent illiteracy, by state, viewed from the northeast.  For a theoretical analysis, the borders of 
a map fall into two categories: natural and man-made. Mandlebrot [9], and others have hypothesized that 
natural coastlines and river beds are fractional dimensional curves that are scale invariant. This is 
almost impossible to analyze. Manmade boundaries cannot be handled theoretically since they may be straight, 
or be smoothly curving along parallels of latitude, or be gerrymandered without rhyme or reason. One 
useful way to consider a bigger map is as four smaller maps placed side by side and scaled to half the 
size. This gives the average number of edges crossing a scan line as proportional to SQRT(N). For more 
analysis, see Chrisman [2]. A heuristic analysis was done by considering national borders from the World 
Data Bank II [I], generalized [3] to different levels of accuracy containing from 2409 to 14378 edges. 
Here the average number of edges crossing a scan line was proportional to N 0"15. Then a map of the USA 
with the state boundaries (4641 edges) was rotated to six different angles to check the stability of 
the n~nber of edges crossing a scan line under rotation. The average number was always within one of 
15. Under these assumptions and measured relationships on the input data, the theoretical time required 
by the algorithm is O(N*log(N)) which is quite satisfactory for a hidden surface algorithm.  4.2 Storage 
 The whole input file is never in memory at any one time. During the preprocessing stage, three edges 
need be in memory together. One is being processed and the other two are its neighbours that are needed 
to set the various bits stored with the edge for shading. The external sorting runs better the more storage 
it gets, but only needs a small constant amount. The only variable part of the algorithm is the final 
sort during which all the edges crossing the scan line must be in memory. This is O(N "'~) edges or for 
the 4641 edge USA map, an average of 15 and a maximum of 32. The final plotting requires a constant amount 
of storage. 5.0 IMPLEMENTATION  This algorithm has been implemented at the Lab for Computer Graphics 
at Harvard. It is a 6000 line machine independent FLECS program. (FLECS is a Fortran preprocessor adding 
block structure and in-line routines). It takes 36+7K words on a DEC PDP-IO when compiled with Fortran 
10 with no optimization or overlaying. User input is by a pseudo-English interactive command language 
with about 40 commands. The language was developed by Dougenik [4]. There are many optional parameters 
to give the user more flexibility that assume reasonable default values if they are not set. PRISM is 
documented by an extensive users' guide and a program logic manual. Plotting the USA map with 4641 points 
takes 130 seconds while each successive plot with a presorted edge file takes 26 seconds. PRISM-MAP has 
been used on maps of up to 12000 edges, with 36000 edges in the 3-D scene.  6.0 REFERENCES  [I] Anderson, 
Delmar E. &#38; Angel, James L. &#38; Gorney, Alexander J. World Data Bank II: content, structure &#38; 
application. An Advanced Study Symposium on Topological Data Structures for Geographic Information Systems, 
Oct 16-21, 1977, Laboratory for Computer Graphics and Spatial Analysis, Graduate School of Design, Harvard 
University. [2] Chrisman, Nick. Concepts of space as a guide to cartographic data structures. An Advanced 
Study Symposium on Topological Data Structures for Geographic Information Systems, Oct 16-21, 1977, Laboratory 
for Computer Graphics and Spatial Analysis, Graduate School of Design, Harvard University. [3] Dougenik, 
James. LINGUIST: A table driven language model for Odyssey. An Advanced Study Symposium on Topologiea] 
Data Structures for Geographic Information Systems, Oct 16-21, 1977, Laboratory for Computer Graphics 
and Spatial Analysis, Graduate School of Design, Harvard University. represent a digitized line or its 
caricature. Canadian Cartographer, Dec 1973. [5] Franklin, Wm. Randolph. Combinatorics of  hidden surface 
al~orithms. Harvard University, Center for Research in Computing Technology, Technical Report, 1978. 
 [6hi Knuth, D. E. The Art of computer Dro~ramminz. vol. 3. Sorting ~nd Searching, Addison-Wesley, 1973. 
 [7] The Lab for Computer Graphics and Spatial Analysis, Harvard University. ASPEX users' reference manual, 
(Jan. 1978). [8] The Lab for Computer Graphics and Spatial Analysis, Harvard University. SYMVU manual, 
(1977). [9] Mandlebrot, Benoit. Fractals: form. chan~e and dimension. WH Freeman and Co., San Francisco, 
1977. [10] Newell, M. E. The progression of realism in computer generated images, ACM 1977 National 
Conference. [11] Newman, W. M. &#38; Sproull, R. F. Principles of interactive computer ~raDhics. McGraw-Hill, 
1973. [12] Tobler, Waldo. A Comouter Program to Draw Perspective Views of Geographic Data. Cartographic 
Lab Report, #I, Dept. of Geography, U. of Michigan. FRESNO per'cen toge   h,gh school grod~j ~ ~_~ 
~ ~----"-"-"--"--~ 10 4 mIO I Figure I0: Percentage of high school graduates in Fresno, by census tracts; 
contours every 5%. No vertical edges at all.  [4] Douglas, David &#38; Peueker, Tom. Algorithms for 
the reduction of the number of points required to 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807374</article_id>
		<sort_key>76</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[A high performance graphics system for the CRAY-1]]></title>
		<page_from>76</page_from>
		<page_to>81</page_to>
		<doi_number>10.1145/800248.807374</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807374</url>
		<abstract>
			<par><![CDATA[<p>This paper describes the design and implementation of a state-of-the-art interactive vector graphics system connected to the CRAY-1 supercomputer. The primary design goal for this graphics system is that it support large hydrodynamic computer programs used in weapons design calculations. The interactive use of these programs requires displays consisting of up to 20,000 vectors, extensive interaction tools, and high-bandwidth communication rates. The major system components selected for this project were an Evans and Sutherland Picture System 2 and a Digital Equipment Corporation (DEC) PDP-11/70 and PDP-11/34 running the UNIX operating system.</p> <p>This paper presents the system design goals and performance criteria. The hardware/software systems chosen for this project are reviewed, and the integration of this system into the Los Alamos Scientific Laboratory's (LASL) Integrated Computer Network (ICN) is described. This implementation involved most areas of applied computing, including computer graphics, communications, distributed processing, and computer security. The level of effort required for this implementation is described, and the results and benefits are presented. Future plans for this system are also briefly described.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[CRAY-1]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[High performance graphics system]]></kw>
			<kw><![CDATA[Picture system 2]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>C.5.1</cat_node>
				<descriptor>CRAY-1</descriptor>
				<type>P</type>
			</other_category>
			<other_category>
				<cat_node>C.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011123.10011674</concept_id>
				<concept_desc>CCS->General and reference->Cross-computing tools and techniques->Performance</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010575</concept_id>
				<concept_desc>CCS->Computer systems organization->Dependable and fault-tolerant systems and networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003033.10003079</concept_id>
				<concept_desc>CCS->Networks->Network performance evaluation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P244769</person_id>
				<author_profile_id><![CDATA[81100608071]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Ewald]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Los Alamos Scientific Laboratory, Los Alamos, New Mexico]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P332123</person_id>
				<author_profile_id><![CDATA[81100193030]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lynn]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Maas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Los Alamos Scientific Laboratory, Los Alamos, New Mexico]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baskett, F., Howard, J. H., and J. T. Montague, "TASK Communication in DEMOS," LA-UR-77-826, Los Alamos Scientific Laboratory report, February 1977.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[CULC, "Description of CULC FORTRAN IV PLUS," Commercial Union Leasing Corportion, New York, 1977.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Ferrin, T., "Picture System 2 Driver," Computer Graphics Laboratory, University of California, San Franciso, CA, December 1977.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Kellner, R., Reed, T., and A. Solem, "An Implementation of the ACM SIGGRAPH Proposed Graphics Standard in a Multi-system Environment," LA-UR-78-1427, Los Alamos Scientific Laboratory report, 1978.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Maas, L. D. and F. Gama-Lobo, "The Application of Interactive Graphics to Large Time-Dependent Hydrodynamics Problems," LA-UR-75-763, Los Alamos Scientific Laboratory report, 1975.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA["PDP-11 FORTRAN Language Reference Manual," Digital Equipment Corporation, No. DEC-11, LFLRA-C-D, Maynard, MA, 1975.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA["Picture System 2/PDP-11 Reference Manual," Evans and Sutherland Computer Corporation, Salt Lake City, Utah, November 1976.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA["Picture System 2 Users' Manual," Evans and Sutherland Computer Corporation, Salt Lake City, May 1977.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Reed, T. N., "The Common Graphics System - An Implementation of the ACM/SIGGRAPH Proposed Graphics Standard," LA-UR-78-1105, Los Alamos Scientific Laboratory report, 1978.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Ritchie, D. M., and K. Thompson, "The UNIX Time-Sharing System," Bell Laboratories, Murray Hill, NJ, 1974.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Rottman, J. N., "A Guide to the UNIX FORTRAN System," Princeton University, September 1975.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A HIGH PERFORMANCE GRAPHICS SYSTEH FOR THE CRAY-I Robert H. Ewald Lynn D. Haas Los Alamos Scientific 
Laboratory Los Alamos, New Hexico 87545 ABSTRACT This paper describes the design and implemen- tation 
of a state-of-the-art interactive vector graphics system connected to the CRAY-I supercom- puter. The 
primary design goal for this graphics system is that it support large hydrodynamic com- puter programs 
used in weapons design calcula- tions. The interactive use of these programs re- quires displays consisting 
of up to 20,000 vec- tors, extensive interaction tools, and high- bandwidth conu~unication rates. The 
major system components selected for this project were an Evans and Sutherland Picture System 2 and a 
Digital Equipment Corporation (DEC) PDP-11/70 and PDP-I1/34 running the UNIX operating system. This 
paper presents the system design goals and performance criteria. The hardware/software systems chosen 
for this project are reviewed, and the integration of this system into the Los Alamos Scientific Laboratory's 
(LASL) Integrated Computer Network (ICN) is described. This implementation involved most areas of applied 
computing, includ- ing computer graphics, communications, distributed processing, and computer security. 
The level of effort required for this implementation is described, and the results and benefits are presente~. 
Future plans for this system are also briefly described. Key Words: Computer Graphics, High Performance 
Graphics System, Picture System 2, CRAY-I. CR Categories: 8.2 INTRODUCTION The Los Alamos Scientific 
Laboratory (LASL) is engaged in many areas of scientific research, including laser fusion, plasma physics, 
and weapons design. These applications perform exten- sive computer simulations that aid in understand- 
ing these topics. These simulations use approxi- mate%y 90% of the LASL computer time. To a~d researchers 
in runping these computer programs, a refresh graphics system was developed (Sanders Graphics System) 
that allows users to interac~ with their large simulation programs [Gama-Lobo and Haas, 1975]. Thi~ interaction 
allows informa- tion to be graphically displayed and modified. The benefits derived from this system 
were, and continue to be, great. The operating system that supports this graphics system will be replaced 
in October 1978. There was no question about the usefulness of the Sanders Graphics System, so when the 
decision was made to change operating systems, a decision was also made to replace the Sanders Graphics 
System. It was this decision that led to the acquisition of the High Performance Graphics System (HPGS). 
In this paper the goals of the HPGS, system selec- tion, system components, integration, resulting system, 
and future plans for the HPGS will be dis- cussed. Goals of HPGS When the decision was made to replace 
the Sanders Graphics System, it was decided that the new system should take advantage of new technology 
as well as new techniques, and would be a more general-purpose system to satisfy the needs of a greater 
portion of the work being do~e at LASL. This required a stand-alone capability with siz- able calculational 
power. A major design goal was to provide for distributed processing to remove the small calculational 
tasks from the large machines and place them in a more suitable and hospitable environment. "Timely" 
responses from tasks in other worker computers, as well as a rea- sonable process-to-process communications 
path between computers, were recognized as necessities for efficient distributed processing. Other goals 
included a relatively high bandwidth (> 1 megabit/second) to other worker computers, a high level of 
local interaction, ca- pability to display up to 20,000 0.5-inch connect- ed vectors, and m graphics 
processor that would perform as many operations by hardware as possi- ble. System Selection The selection 
of the major HPGS components was influenced by many factors. The final ~elec- tiOn consisted of an Evans 
and Sutherland Picture System 2 graphics processor and associated peri- pherals, a Digital Equipment 
Corporation (DEC) PDP-I1/70 computer, a DEC PDP-11/34 computer, and  76 the UNIX [Ritchie and Thompson, 
1974] operating system running on both computers. Figure 1 shows the HPGS configuration and system components. 
 The Picture System 2 was selected because of its ability to perform manipulative graphics operations 
quickly, its high-speed vector genera- tor, and the hardware architecture. The DEC PDP-II/70 was chosen 
as the general- purpose computer for several reasons. Included in these reasons are the calculational 
speed of the computer, the ease (and cost) of interfacing it to the Picture System 2, and the ease (and 
cost) of interfacing it to the ICN. When the system was designed, it appeared that a 32-bit computer 
ar- chitecture would be better suited to the applica- tions that are to be run on the HPGS, but monetary 
and time constraints prevented the acquisition of that class of computer. The DEC PDP-II/34 computer 
was required for economic, security, and expansion reasons. It will be located in the users' work area 
and will serve as a graphics concentrator. The UNIX operating system was chosen because of ease of use, 
the time-sharing nature of the system, and the benefits derived from having software available from other 
UNIX systems in the ICN. These reasons were sufficient to override the fact that support software for 
the Picture System 2 would have to be written since Evans and Sutherland does not currently support UNIX. 
 INTEGRATION  The integration of the hardware and software is being accomplished in three phases. The 
first phase involved the direct connection of the PDP-II/70 to the CRAY-I. This link can operate at speeds 
up to 4 megabits/second and was used for the initial development of the communication pro- tocol and 
task synchronization. Phase 2 of the project involves connecting the PDP-II/34 into the system and "remoting" 
the PDP-II/34 and Picture System 2 to the users' work area. Phase 3 (shown in Fig. 2) comprises connecting 
the HPGS PDP-I1/70 to the LASL ICN as a worker machine. When this work is completed, the system will 
be able to com- mnnicate with any of the large worker computers in the LASL computing network. The ICN 
provides computer services for a wide variety of Laboratory projects. The major worker computers are 
the CRAY-I, four CDC 7600s, two CDC 6600s, and a CDC Cyber 73. In addition, other computers support such 
things as a Common File System (CFS), File Transport (FT) between worker computers, and terminal access 
to the ICN. Currently, the ICN is supporting over 900 termi- nals throughout the Laboratory. These include 
 CRAY- 1  4 Mbits/s Connection to ICN I P06 Disk DEC  I 9-Track Tape Local I PDP-II/70 Terminals 
 I 'Versatec Printer/ DEC Tapes Plotter 2 Mbits/s  Tablet I 4 RK05 Disks E&#38;S ~Keyboard PS2 Switches 
DEC 9-Track Tape PDP-II/34 Dials High-Speed Tektronix Ports (307 kbits/s each) Versatec Printer/ plotter 
 Fig. 1. HPGSConfiguration. SUPPORT PROCESSOR LTSS S(21) 7600 LTSS R(26)  CRAY--1 DEMOS V(27) I'I 
PDP-11/70 UNIX F I PDP-11/70 UNIX HPGS G I 7600 LTSS T(14) I IBM 1360 ]PHOTOS'TORE k___ IBM 370/148 
CFS I CYSER 73 NOS N(24) 6660 NOS L(2) ~ CBT I1'$ RCC FOR REMOTE66OO COMPUTERSNOS M(O) Fig. 2. Future 
ICN Configuration. hard-copy, alphanumeric CRT, Tektronix graphics, and intelligent terminals. Since 
it was decided to run UNIX on the PDP-II/70, it was necessary to develop software to drive the Picture 
System 2 under UNIX. Since most of the potential users of the system were very familiar with FORTRAN, 
a FORTRAN implementation was selected. A Picture System 2 UNIX I/O driver, written in the "C" language, 
was obtained from the University of California, San Francisco, [Ferrin, 1977]. It was determined that 
the standard UNIX FOR- ~RAN would not provide the necessary support, so a FORTRAN compiler from Princeton 
University was ob- tained. Interface routines between the FORTRAN system and the I/O driver were developed 
in assem- bly language. After considerable deliberation, it was decided to provide a set of FORTRAN-callable 
 routines with the same names and calling sequences as those normally provided by Evans and Sutherland 
 [Evans and Sutherland, 1977]. These routines pro- vide windowing, viewporting, transformation, ma- 
 trix generation, vector generation, device con- trol, and interaction facilities. This software package 
provides the same facilities and user in- terface as other Picture System 2 installations. A FORTRAN 
IV PLUS compiler [CULC, 1977] was ob- tained and all software was converted. When using the FORTRAN IV 
PLUS compiler, execution times were decreased about two times compared to the Prince- ton compiler. 
LASL is developing an operating system called DEMOS for the CRAY-I [Baskett, 1977], so the com- munication 
link with the CRAY-I has proceeded in several steps. To enable IIPGS development to proceed concurrently 
with DEMOS development, the HPGS was connected directly to the CRAY-I using hardware built by LASL. A 
FORTRAN communications package was then developed on the IIPGS that al- lowed the HPGS to send and receive 
files, set and read CRAY-I sense switches, and set and read por- tions of CRAY-I memory. These preliminary 
facili- ties enabled a FORTRAN program running on the CRAY-I to communicate with a FORTRAN program run- 
ning on the PDP-II/70. A communication protocol between the two machines was developed using a reserved 
portion of CRAY-I memory as a communication area. A large  changes in UNIX, the I/0 drivers, the graphics 
TABLE 2 software, and system utilities.  The HPGS project has followed a phased development scheme, 
and the software, hardware, and communication links have been constantly up- graded. Table 1 gives a 
rough outline of the im- provements in the HPGS system as certain hardware and software was installed 
or updated. TABLE I RELATIVE EFFECTS OF IMPLEMENTATION STAGES Descriytion Performance* I. Initial 
system -no graphics software 0 2. Mesh Application under Princeton FORTRAN I  3. Software segmentation 
added (objects) 1.2 -1.5  4. Graphics software converted to FORTRAN IV PLUS compiler 5. Communication 
software con- verted to FORTRAN IV PLUS and RP06 disk installation   *Note: The numbers in the performance 
column in- dicate improvements in performance relative to item 2 (the first usable system). The integration 
and development of the HPGS project has involved a large software development effort. Certain software 
was adopted from other development activities, and the effort involved in implementing this software 
cannot be accurately reported. However, the effort required to design, implement, and document certain 
parts of the HPGS is given in Table 2. This table is presented only in the interest of giving future 
system designers and implementors some idea of the time required for certain tasks. RESULTING SYSTEM 
 A primary goal of the HPGS project is to pro- vide an effective replacement for the Sanders graphics 
system. The Sanders is connected direct- ly to a channel on a CDC 7600, which provides a very high bandwidth 
(3.2 megabits/second) link. All graphics processing is performed by the 7600, a comparatively powerful 
graphics processor. The HPGS system is approaching the Sanders in capability. The Picture System 2 has 
operated in a stable fashion, allowing very complex displays to be generated. Pictures containing up 
to 14,000 vectors have been generated with no picture degra- dation. The interaction facilities are handled 
locally in the HPGS and provide facilities that are comparable to the Sanders. EFFORT FOR CERTAIN TASKS 
 Effort Task (Person-month) I. UNIX familiarization 1-2 2. Picture System 2 Software  3. FORTRAN-callable 
CRAY-I communication package  4. Security within UNIX  5. HPGS Monitor Program 1  6. HPGS Mesh Display 
Program 4  7. System Documentation 2  8. Consulting 2  8 3 6 It should be noted that the HPGS 
provides some additional benefits. The HPGS will be able to operate with any of the ICN worker machines, 
thus allowing more flexibility when a machine failure occurs. It can process graphical and problem data, 
relieving the large worker machines of these tasks, and allowing more efficient use of machines. The 
HPGS also provides a general- purpose, stand-alone graphics capability that can be used by other Laboratory 
projects. FUTURE The HPGS has just begun to be used in the production environment. As its production 
usage increases, several development projects continue. Among these projects are the completion of the 
network link to enable connection to any other network machine and to the file storage machines. As more 
graphics devices are supported on HPGS, the software support will be unified using the LASL Common Graphics 
System. In the hydrodynamics application, more work will be done in the dis- tributed processing area 
to more efficiently use the HPGS and CRAY-I. In the hardware area, it is envisioned that additional 
graphics terminals will be connected to the system. A high-speed Tektronix interface has been designed, 
and Tektronix terminals capable of running at 307 kilobits/second will be installed. Current planning 
indicates that additional Picture System 2 type terminals will be acquired. CONCLUSION The ttPGS project 
has covered most areas of applied computing, including computer graphics, operating systems, telecommunications, 
distributed computing, security: and application programming. The resulting system can be used effectively 
in weapons design. The system provides a high- bandwidth communication link to the CRAY-I, allows  complex 
images to be generated, and provides for user interaction. The cost effectiveness of the system cannot 
be readily measured. The hardware for the entire HPGS project cost approximately $250,000, and about 
three person-years of effort have been ex- pended. However, when the cost of a single under- ground test 
is considered, the cost of the }[PGS project is less significant. The weapons designers who have used 
the system indicate that it is a necessity in their work. It has allowed them to speed the design process 
by as much as ten times and to do complex design calculations that otherwise could not have been attempted. 
 ACKNOWLEDGMENTS  The HPGS project has involved the effort and cooperation of several groups at LASL. 
We would like to thank everyone who has been concerned with the project for their support and excellent 
tech- nical work. In particular, we would like to thank the following groups and individuals: (C-6) Clifford 
Plopper and Howard Demuth for graphics software support; (C-3) Alex Marusak for the mesh display program; 
(TD-9) F. Gama-Lobo and Lewis Lowe for the application codes; (C-II) Paul Iwanchuk and James Brewton 
for the CRAY-I communi- cation package; and (C-9) Donald Tolmie, Andy Spencer, David Bailey, and Dottye 
Camille for the special hardware and security aspects. We would also like to thank Jeanne M. Hurford 
and Susan Wilhelm for their usual excellent word processing skills. REFERENCES Baskett, F., Howard, 
J. H., and J° T° Montague, "TASK Communication in DEMOS," LA-UR-77-826, Los Alamos Scientific Laboratory 
report, February 1977. CULC, "Description of CULC FORTRAN IV PLUS," Com- mercial Union Leasing Corportion, 
New York, 1977o Perrin, T°, "Picture System 2 Driver," Computer Graphics Laboratory, University of 
California, San Franciso, CA, December 1977. Kellner, Ro, Reed, To, and A. Solem, "An Implementation 
of the ACM SIGGRAPH Pro- posed Graphics Standard in a Multi- system Environment," LA-UR-78-1427, Los 
Alamos Scientific Laboratory report, 1978° Maas, L. Do and F. Gama-Lobo, "The Application of Interactive 
Graphics to Large Time- Dependent Hydrodynamics Problems," LA-UR-75-763, Los Alamos Scientific Laboratory 
report, 1975. "PDP-II FORTRAN Language Reference Manual," Digi- tal Equipment Corporation, No. DEC-If, 
LFLRA- C-D, Maynard, MA, 1975. "Picture System 2/PDP-II Reference Manual," Evans and Sutherland Computer 
Corporation, Salt Lake City, Utah, November 1976. )'Picture System 2 Users ) Manual, )' Evans and Sutherland 
Computer Corporation, Salt Lake City, May 1977. Reed, To N., "The Common Graphics System -An Implementation 
of the ACM/SIGGRAPH Pro- posed Graphics Standard," LA-UR-78-1105, Los Alamos Scientific Laboratory report, 
19780 Ritchie, Do Me, and Ko Thompson, "The UNIX Time-Sharing System," Bell Laboratories, Murray Hill, 
NJ, 1974. Rottman, J. N., "A Guide to the UNIX FORTRAN System, )) Princeton University, September 1975. 
  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807375</article_id>
		<sort_key>82</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Computer graphics in support of Space Shuttle simulation]]></title>
		<page_from>82</page_from>
		<page_to>86</page_to>
		<doi_number>10.1145/800248.807375</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807375</url>
		<abstract>
			<par><![CDATA[<p>Electronic scene generation plays an important role in simulation of the Space Shuttle at the Johnson Space Center in Houston, Texas. Simulators for astronaut training, system integration and engineering development utilize both a moving camera/map board system as well as computer generated images. Launch, on-orbit, payload handling and landing tasks are simulated with shaded computer graphics to provide realtime visual feedback. An overview of these simulators is presented.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Simulation]]></kw>
			<kw><![CDATA[Space Shuttle]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.2</cat_node>
				<descriptor>Aerospace</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.6.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010366</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation support systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010433</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Aerospace</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31099180</person_id>
				<author_profile_id><![CDATA[81100638369]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Weinberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lockheed Electronics Company, Inc., Houston, Texas]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Space Shuttle, NASA SP-407, National Aeronautics and Space Administration, Washington, D.C., 1976.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bunker, W. Marvin, "Visual Scene Simulation with Computer Generated Images", Progress in Simulation, Volume 2, Gordon and Breach, New York, 1972.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA["Improved Scene Generator Capability", Final Report, Contract No. NAS 9-14010, Evans and Sutherland Computer Corporation, Salt Lake City, Utah, October 1977.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Shohat, Murray and Florence, Judit, "Application of Digital Image Generation to the Shuttle Mission Simulator", 1977 Summer Computer Simulation Conference, July 18-20, 1977.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 COMPUTER GRAPHICS IN SUPPORT OF SPACE SHUTTLE SIMULATION Richard Weinberg Lockheed Electronics Company, 
Inc. Houston, Texas ABSTRACT Electronic scene generation plays an important role in simulation of 
the Space Shuttle at the Johnson Space Center in Houston, Texas. Simulators for astronaut training, system 
integration and engi- neering development utilize both a moving camera/ map board system as well as computer 
generated images. Launch, on-orbit, payload handling and landing tasks are simulated with shaded computer 
graphics to provide realtime visual feedback. An overview of these simulators is presented. KEY WORDS 
AND PHRASES: computer graphics, simula- tion, Space Shuttle CR CATEGORIES: 3.21, 8.1, B.2 INTRODUCTION 
 Since the United States committed itself to the manned exploration of space in the early 1960's, preflight 
simulation of space missions has played an important role in establishing functional and system requirements, 
evaluating system designs, validating system operations, establishing proce- dures, training astronaut 
and ground crews, and providing safe environments for testing equipment and ideas. During an actual space 
mission, the astronauts rely heavily on the visual cues they observe through the windows of the spacecraft. 
As the space program has developed, increasingly more sophisticated means have been employed to simulate 
these scenes in cockpit mockups on the ground. At the Lyndon B. Johnson Space Center in Houston, both 
computer generated image and camera/model systems are used in support of the newest manned venture into 
space: the Space Shuttle. THE SPACE SHUTTLE A new era in the exploration and exploitation of outer space 
will dawn early in the 1980's when the Space Shuttle becomes fully operational. The Space Shuttle consists 
of three basic systems: the Orbiter, two Solid Rocket Boosters and the External Tank. All are reusable 
except the Exter- nal Tank. Space Shuttle missions will begin with a vertical launch, with the Orbiter 
and Solid Rocket Boosters attached to the External Tank in "piggyback" fashion. After the Solid Rocket 
Boosters have spent their fuel, they will fall into the ocean to be retrieved, refurbished and reused. 
The External Tank, after its fuel is spent, will be destroyed upon reentry. The Orbiter, whose 60 foot 
long payload bay will be used to transport a variety of satellites, obser- vatories and the Spacelab 
into and back from space, may remain in orbit up to 30 days. Its mission accomplished, the Orbiter begins 
atmos- pheric reentry, landing without power on special airstrips. The reusable vehicle concept is ex- 
pected to reduce the cost of transportation into orbit enough to open the door to many new ventures, 
with the Space Shuttle providing routine access to space for the first time. [l.] The flight deck of 
the Orbiter is divided into functional areas. Of primary interest here are the forward-facing work stations, 
from which the commander and pilot will control launch, Solid Rocket Booster and External Tank separation, 
orbital insertion, atmospheric reentry and landing, and second, the aft-facing work stations, from which 
the on-orbit pilot and the payload and mis- sion specialists will control rendezvous, station keeping, 
and payload handling operations. The Remote Manipulator System (RMS), a mechanical arm mounted in the 
Orbiter's payload bay, will be available to aid in payload handling, and is operated from the aft station. 
 SPACE SHUTTLE SIMULATORS Four of the Space Shuttle simulators at the Johnson Space Center are equipped 
to provide real- time, color, "out-the-window" scenes to the aStro- nauts or engineers "flying" the Orbiter 
cockpit mockups. The Shuttle Dynamic Simulators (SDS), the Shuttle Engineering Simulator (SES) and the 
Shuttle Mission Simulator (SMS) each employ digital com- puters and special purpose electronic scene 
gene- ration electronics. In addition, the SMS and the Orbital Aeroflight Simulator (OAS) share a moving 
camera/map board system for simulating landing scenes. THE SHUTTLE DYNAMIC SIMULATOR The SDS, located 
in the Shuttle Avionics Integra- tion Laboratory (SAIL), supports the development, testing and verification 
of the on-board flight computers and avionics hardware and software for the Space Shuttle. The five 
on-board computers, B2 avionics and connecting cables are identical to those on the Orbiter, and are 
mounted in corres- ponding physical locations to ensure accurate simu- lation. The SDS is currently 
configured with a forward cockpit mockup, and has been an important tool for the checkout of the integrated 
Shuttle hardware, software and procedures. The forward cockpit of the SDS is provided with a computer 
generated color scene, including a tex- tured surface to represent the ground, along with computer generated 
solid objects. In 1964, the electronic realtime textured surface generator was delivered by General Electric 
to support the Apollo program. This textured surface generator, the first of its kind, simulates the 
scene one would see if he were flying over a textured surface com- posed of different sized squares of 
one color, on a background of a second color. In 1967, General Electric augmented the system with the 
first real- time color solid object scene generator. An impor- tant landmark in the development of computer 
graphics, this scene generator then had the capa- bility of displaying up to 40 objects, with its 240 
edge capability, along with the textured sur- face background. In 1971, the system was again augmented, 
to allow up to 320 edges, each of which could be part of more than one object. [2.] This electronic scene 
generator has been used in the Apollo program, the Apollo-Soyuz Test Project, and is now in daily use 
in support of the Space Shuttle program. Fig. l shows a typical scene generated by this system. THE 
SHUTTLE ENGINEERING SIMULATOR The SES, in NASA's Hybrid Computation and Simula- tion Laboratory, is 
currently used as a tool for evaluating and establishing techniques and proce- dures for use in the orbital 
phase of a Space Shuttle mission. The SES is currently configured with an aft cockpit mockup where rendezvous, 
sta- tion keeping and Remote Manipulator System opera- tions are being studied. Fig. 2 depicts the SES. 
 The aft work station of the Orbiter has two over- head windows, and two windows facing into the pay- 
load bay. The views from these windows are simu- lated in the SES by two independent, simultaneous realtime 
computer generated scenes. Depending on the mission being simulated, color CRT's along with virtual image 
projectors are placed in the appropriate windows of the cockpit mockup. The special optics of the virtual 
image projectors provide a realistic simulated view, similar to what the astronauts would see as they 
approached a satellite in orbit, or attempted to grapple it with the RMS. In addition, a simulated closed 
circuit television monitor is provided, to repre- sent the scene one would see via the closed cir- cuit 
television cameras placed at strategic loca- tions about the Orbiter. Pan, tilt and zoom operations are 
allowed for the cameras located on the Orbiter's forward and aft bulkheads, and the scene generator takes 
into account these para- meters, which can be changed in real time to suit the viewing needs of the pilot 
during the course of a simulation run. The SES uses one of the most advanced computer graphics systems 
in existence to generate these scenes. The NASA Visual System, built by Evans and Sutherland Computer 
Company, Salt Lake City, provides two independent, realtime, full-color, smooth-shaded channels of video 
output for viewing in the cockpit mockup. The high quality of these computer generated images, and the 
effect of the smooth shading can be seen in Fig. 3. Delivered in 1976, the NASA Visual System can display 
up to 900 polygons with an average of four edges each, in any of 256 software selectable colors, at a 
rate of 25 frames per second, with 625 lines per frame. [3.] In addition to the scene generation capabilities, 
 the NASA Visual System contains an auxilliary pro- cessing unit, the Collision Avoidance System, which 
monitors the movements of the simulated Orbiter, RMS and payloads, reporting back to the simulator's 
central computer if any objects of interest have collided within the current 40 millisecond frame time. 
 A typical simulation on the SES might proceed as follows: the Orbiter and a satellite are placed in 
an initial configuration, in which the locations, attitudes and initial velocities of each are speci- 
fied. The pilot then attempts to approach the satellite, without disturbing it as he fires the Orbiter's 
thrusters. Once the satellite is within range of the RMS, the astronaut must steer the end effector 
of the RMS into alignment with the grap- pling fixture on the satellite. For this task, he can peer out 
the mockup's windows and watch the computer generated arm move under his control, and he may select 
an appropriate closed circuit televi- sion view, from the forward or aft bulkheads, the center of the 
payload bay, or from a camera mounted on the end of the arm. During a simulation run, three SEL-32 digital 
com- puters and two Comcor 5000 analog computers model the equations of motion of the Orbiter, payloads, 
the RMS, jet plume impingement, aerodynamic drag, and the gravitational gradient effects, providing the 
pilot with instrument readings in real time. These digital and analog computers interface into a Sigma-5 
computer, the central controller of the simulation. The Sigma-5 synchronizes the system to the 40 millisecond 
simulation frame rate, and indi- cates to the NASA Visual System the current posi- tion and Euler angles 
of the Orbiter and payloads, the angles of each of the six movable joints of the RMS, and camera selection, 
pan, tilt and zoom data for the closed circuit television views. The NASA Visual System consists of three 
interconnected PDP-II computers, and special purpose electronic hardware for scene generation and collision 
detec- tion. A PDP-II/40, designated the Host computer, serves as the interface between the NASA Visual 
System and the rest of the SES. The Host is inter- faced to a PDP-ll/35, designated the Visual Compu- 
ter, and to a PDP-ll/45, the Collision Avoidance System. The Host computer receives the data describing 
the current scenes from the Sigma-5 and transmits it to the Visual computer and to the Collision Avoidance 
System. The Visual computer relays the current information to the visual pipeline, a special high speed 
processor, whose responsibility it is to generate a new pair of images every 40 milliseconds. To perform 
this task, the pipeline must take into 83 account the viewpoint of the observer, determine the proper 
perspective, decide which portions of the objects already stored in its memory are visi- ble in the current 
frame, smooth shade and color the visible objects, and generate the video signals for the displays in 
the cockpit. During that same 40 milliseconds, the Collision Avoidance System examines the current configuration 
of the models in the simulated world to determine if any have col- lided, an event which it would report 
back to the Sigma-5 through the Host computer. THE ORBITAL AEROFLIGHT SIMULATOR The OAS was the primary 
on-the-ground training simulator for the pilot and commander during the Approach and Landing Tests of 
1977. The OAS in- cludes a forward cockpit mockup on a moving base. As the simulation progresses, the 
cockpit rolls, pitches, or yaws to give the astronauts a sensa- tion of motion similar to what they 
would experi- ence performing the same maneuvers in the actual Orbiter. Immediate visual feedback during 
the simulated flight is provided by a system of closed-circuit television cameras mounted on a moving 
platform, aimed at a 24 by 56 foot relief mural of the Edwards Air Force Base lake bed area, where the 
Approach and Landing Tests have taken place. Con- trol signals from the commander, pilot and on- board 
electronics are interpreted by the associa- ted simulation computers to move the cameras along a miniature 
landing path providing realistic color out-the-wlndow views during the simulated landing. THE SHUTTLE 
MISSION SIMULATOR The Shuttle Mission Simulator, built by Singer/ Link, will be used for astronaut 
training in the Orbital Flight Test phase of Shuttle development and beyond. All of the flight deck work 
stations are present in its fixed base cockpit mockup so that any phase of a mission could be simulated. 
The SMS makes extensive use of computer graphics: ten out-the-window and three closed circuit tele- 
vision views will be available in the cockpit, provided in part by the moving camera system shared with 
the OAS, and in part by additional computer scene generators. The computer scene generators provide 
a model of the Earth and stars as well as of the Orbiter and payloads. [4.] Special effects such as clouds 
and haze are added to the scenes via video mixing. CONCLUSION The National Aeronautics and Space Administration 
 has been a leader in the use of electronic scene generation for realtime simulation. As the space program 
has been a drivlng force in the develop- ment of a myriad of technologies, so does it remain at the 
forefront in this area. Electronic scene generators are currently used throughout the world for training 
military, air- line and supertanker pilots. The attendant com- puters, cockpit mockups, special purpose 
elec- tronics and software development, along with the uniqueness of each installation spells very 
high costs, on occasion exceeding a million dollars, for these sophisticated systems. Now that many 
of the necessary techniques have been established, however, we should be able to antici ~ pate reduced 
costs for future systems. If the costs were reduced significantly, a vast new array of possibilities 
for computer scene generators would open up. For example, driver education clas- ses could begin with 
instruction in automobile mockups, with out-the-window scenes generated by computer. Before a student 
driver ever sped up his first freeway entrance ramp, he would already have logged hours of practice 
on a simulated freeway without denting a fender. As an educational or design instrument, the computer 
scene generator might provide the student or desig- ner with a world he can manipulate at will, experi- 
menting with shapes, colors, arrangements and motion. An architecture student might design a building, 
a landscape or a city interactively, and "walk" through his simulated world, poking his head around corners, 
or through doors, or flying aloft for a bird's eye view. ACKNOWLEDGEMENTS This paper is based on the 
author's experiences and observations while working at the NASA Johnson Space Center, first with the 
Hybrid Computation and Simu- lation Branch (HCSB) as a participant in the NASA Aerospace Intern Program 
and then in the Simulation Department of Lockheed Electronics Company, Inc., which supports NASA/HCSB, 
including the Shuttle Dynamic Simulator and the Shuttle Engineering Simu- lator. The author wishes 
to gratefully acknowledge information on the Orbital Aeroflight Simulator and the Shuttle Mission Simulator 
provided to him by the Mission Simulation Branch of NASA/JSC. REFERENCES [l] Space Shuttle, NASA SP-407, 
National Aeronau- tics and Space Administration, Washington, D.C., 1976. [2] Bunker, W. Marvin, "Visual 
Scene Simulation with Computer Generated Images", Progress in Simu- lation, Volume 2, Gordon and Breach, 
New York, 1972. [3] "Improved Scene Generator Capability", Final Report, Contract No. NAS 9-14010, Evans 
and Sutherland Computer Corporation, Salt Lake City, Utah, October 1977. [4] Shohat, Murray and Florence, 
Judit, "Applica- tion of Digital Image Generation to the Shuttle Mission Simulator", 1977 Summer Computer 
Simulation Conference, July 18-20, 1977. 84  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807376</article_id>
		<sort_key>87</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[System design and implementation of BGRAF2]]></title>
		<page_from>87</page_from>
		<page_to>92</page_to>
		<doi_number>10.1145/800248.807376</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807376</url>
		<abstract>
			<par><![CDATA[<p>BGRAF2 is a real-time interactive 2D graphics language. Its supporting system contends with an unusual combination of features: timing, events, parallelism, image manipulation, user interaction and procedural structures. This combination creates within the system many unpredictable interrelated tasks competing for execution.</p> <p>A BGRAF2 program is compiled into an object module consisting of a sequence of pure code blocks, tasks, and a set of data blocks. The real-time environment is a hierarchical structure, where the highest level is a Scheduler, and the next level is composed of the object module and five additional processors: Graphics Processor, Control Processor, Input-Output Processor, Real-Time Processor and Memory Manager. The Scheduler is an abstract monitor responsible for scheduling tasks in accordance with a multi-level priority from a multi-queue scheme.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Buddy system]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Concurrent processing]]></kw>
			<kw><![CDATA[Graphics language system]]></kw>
			<kw><![CDATA[Hard real time]]></kw>
			<kw><![CDATA[Hierarchical structure]]></kw>
			<kw><![CDATA[One-way barrier]]></kw>
			<kw><![CDATA[Scheduling]]></kw>
			<kw><![CDATA[Side-effects]]></kw>
			<kw><![CDATA[Slippage]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Languages</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.4.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010949.10010957</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Operating systems->Process management</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003128</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction techniques</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Languages</gt>
			<gt>Management</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P329054</person_id>
				<author_profile_id><![CDATA[81406594456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Arie]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Kaufman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ben-Gurion University of the Negev - Beer Sheva and the Hebrew University - Jerusalem, Israel]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>563300</ref_obj_id>
				<ref_obj_pid>563274</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bergman, S. &amp; Kaufman, A. BGRAF2: a real-time interactive graphics language with modular objects and implicit dynamics. Proc. SIGGRAPH'76, Phila. PA (July 1976) 133-138.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bergman, S. &amp; Kaufman, A. High-level language for real-time processes. Proc. 12-th Nat'l Conf. on Data Processing, Tel-Aviv (Sept. 1977) 179-189 (in Hebrew).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>540365</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Brinch Hansen, P. Operating system principles. Prentice-Hall, Englewood Cliffs NJ (1973).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Brinch Hansen, P. The programming language concurrent Pascal. IEEE Proc. on Software Eng. 1, 2 (June 1975) 199-207.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Dijkstra, E.W. Cooperating sequential processes. In "Programming languages" by F. Gennys (Ed.), Academic Press (1968).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>363143</ref_obj_id>
				<ref_obj_pid>363095</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Dijkstra, E.W. The structure of the T.H.E. multi-programming system. CACM 11, 5 (May 1968) 341-346.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Dijkstra, E.W. Hierarchical ordering of sequential processes. Acta Informatica 1, 2 (1971) 115-138.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Futrelle, R.P. &amp; Potel, M.J. The system design for GALATEA, an interactive real-time computer system for movie and video analysis. Computers &amp; Graphics 1 (1975) 115-121.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Hennessy, J.L. et al. TOMAL: a task-oriented microprocessor applications language. IEEE Trans. on IECI-22, 3 (Aug. 1975).283-289.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>361161</ref_obj_id>
				<ref_obj_pid>355620</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Hoare, C.A.R. Monitors: an operating system structuring concept. CACM 17, 10 (Oct. 1974) 549-557.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kaufman, A. &amp; Bergman, S. The definition of BGRAF2: a real-time interactive graphic language. Ben-Gurion Univ., Math. Dept., Tech. Rep. MATH-132 (Jan. 1976).]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Kaufman, A. Interactive real-time graphics language. Ph.D. Thesis (Aug. 1977), (in Hebrew, English Summary).]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>260999</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Knuth, D.E. The art of computer programming, vol. 1: Fundamental algorithms. Addison-Wesley (1968).]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>361623</ref_obj_id>
				<ref_obj_pid>361598</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Parnas, D.L. On the criteria to be used in decomposing systems into modules. CACM 15, 12 (Dec. 1972) 1053-1058.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Potel, M.J. An executive for event-driven systems. Quarterly Rep. 49, Univ. of Chicago (May 1976).]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SYSTEM DESIGN AND IMPLEMENTATION OF BGRAF2 Arie A. Kaufman Ben-Gurion University of the Negev - Beer 
Sheva and the Hebrew University - Jerusalem, Israel ABSTRACT BGRAF2 is a real-time interactive 2D graphics 
lan- guage. Its supporting system contends with an un- usual combination of features: timing, events, 
parallelism, image manipulation, user interaction and procedural structures. This combination creates 
within the system many unpredictable interrelated tasks competing for execution. A BGRAF2 program is 
compiled into an object module consisting of a sequence of pure code blocks, tasks, and a set of data 
blocks. The real-time environment is a hierarchical structure, where the highest level is a Scheduler, 
and the next level is com- posed of the object module and five additional processors: Graphics Processor, 
Control Processor, Input-Output Processor, Real-Time Processor and MemoryManager. The Scheduler is an 
abstract moni- tor responsible for scheduling tasks in accordance with a multi-level priority from a 
multi-queue scheme. KEY WORDS AND PHRASES: computer graphics, graphics language system, hard real 
time, concurrent processing, scheduling, hierarchical structure, side-effects, slippage, buddy system, 
one-way barrier CR CATEGORIES: 3.8, 4.1, 4.22, 4.3, 8.2 i. INTRODUCTION BGRAF2 is a higher-level 
programming language, designed for interactive real-time 2D graphics, and provides a convenient tool 
for describing computational, graphics and event-dependent asynchronous processes. A brief description 
of the language is given in Section 2, while a more extensive presentation appears in (i, ii, 12). 
 The BGRAF2 system which supports the language, is unique in its handling of an extraordinary combi- 
nation of features such as timing and clock mech- anisms, events, parallelism and concurrent proc- esses, 
user interaction, image manipulation and transformation, as well as ordinary procedural structures. 
This set of features creates within the This work was supported by a grant from '~if'al Hapayis" - 
The Pinchas Sapir Scholarship &#38; Research Grants Foundation system many interrelated processing 
tasks racing to be scheduled for "immediate" execution, which ideally shoul~ be executed asynchronously 
and in parallel. The system endeavors to cope with hard real-time constraints with unpredictable overloads, 
 concurrently presenting the time-dependent syn- chronized scenario. The utilization of the inter- rupt 
mechanism and of the concurrent and priority processing tools permits the co-existence of many pseudoparallel 
processing tasks within the system, some of which are triggered by user interaction. An analysis of 
the system processing concept is given in Section 3. In order to construct a reliable run-time environ- 
ment, the system is hierarchically structured. The highest level is an abstract monitor and the next 
level is composed of the object module produced by the Translator and five additional software process- 
 ors. This hierarchical structure is discussed in Section 4, and an account of the main concepts underlying 
each of the processors and their areas of responsibility is given in Sections 6-12. 2. THE LANGUAGE 
 The BGRAF2 is a special-purpose user-oriented lan- guage (i, ii, 12), emphasizing ease of use rather 
than of implementation. The structured ALGOL-like procedural statements allow straightforward compu- 
tation, the drawing and sketch primitives create a simple approach to graphics, the class-like graphic 
procedures encourage modular graphic programming, and the implicit structures lend autonomous dynam- 
ics to images. The clock and event data types in BGRAF2 facilitate the creation of parallel and synchronous 
actions and procedures which automatically act on the data structures, the display-files and the scenario. 
Automatic incrementation of the clocks results in real-time dependent objects which dynamically change 
their shape, position, size, orientation, and other properties. Variables defined as func- tions of clocks 
act as "pseudo-clocks", changing in real-time in accordance with any user-defined function, and thus 
real-time motion is trivially definable. An event is an impulse function of time, defining a sequence 
of time-instances at which the event is  said to "occur". An event may be triggered (caused to occur) 
explicitly by the programmer or implic- itly when a value is assigned to some variable. An asynchronous 
input is an external event which occurs when certain actions take place on a periph- eral unit with 
certain conditions fulfilled. These external events facilitate the interaction between the user and 
the program. Explicit and implicit event-driven non-procedural statements control the real-time and 
interactive processes in the language, while the procedural and graphic statements are used to initialize 
objects and data structures. The code blocks associated with an event-driven statement are secheduled 
for execution as soon as its associated event occurs. A graphic object is a time-, input-, and computa- 
tion-dependent instance of a graphic procedure defined in BGRAF2 programs. An object is composed of explicitly 
drawn graphic primitives (lines, points, characters), of sketches constructed from primitives, and of 
those objects created by hier- archical "calls" to other graphic procedures. A graphic procedure draws 
in its own coordinate system, defined in terms of its parent's coordinate  system. A call to a graphic 
procedure merely in- vokes a separate dynamic instance of that procedure; thus, many instances may be 
in effect simultane- ously, conceptually operating in parallel. An object is in an either active or 
passive state. Until all its procedural statements have been exe- cuted it is active, then it becomes 
passive. Its event-driven statements are executed from time to time as events occur and graphic images 
and data structures, which are geared to clocks and pseudo- clocks, change. The object remains passive 
until explicitly or implicitly terminated. The approach taken to effect real-time changes on screen 
differs in principle from the standard methods. The BGRAF2 language is based on what might be called 
"side-effects". Graphic objects or primi- tives may he defined in terms of program variables, and the 
visual elements created may change auto- matically in real-time as these variables change their values. 
Thus, once defined, a graphic element need not be referenced directly in order to be changed. The 
following is an example of a BGRAF2 program. Procedure DESCEND invokes an instance of procedure CHUTE, 
moves it down at constant velocity from its initial position on screen and at the same time rocks it 
back and forth in a pendulum-like motion. These motions are accomplished by defining the angle and 
position of CHUTE as pseudo-clocks, i.e., in terms of a clock K (ticking 5 times per second). The angle 
and position are relative to DESCEND's own coordinate system. CHUTE draws a parachute by calling an 
external routine ARC (not defined here) to draw an arc defined by three points, two of which are the 
end- points. CHUTE attaches eleven cords to an element drawn by invoking an instance of procedure PAYLOAD 
which is a square of side 50. The payload bounces up and down with respect to CHUTE and the cords rubber-band 
accordingly as defined by pseudo-clock Y. procedure CHUTE; real J, Y; clock C(5); Y = -300+10*sin(O.17*C); 
 '~efinition of Y as a pseudo-clock" <i00,0>; ARC((0,S00), (-i00,0)); <i00,0>; for J := -i00 __t° i00 
b__y_y 20 do_; ?(#J, 0); (0,Y) od; "rubber-banding cords" PAYLOAD(S0); end CHUTE; procedure PAYLOAD(L); 
integer L; <L/2,0>; <0,-L>; <-L, 0>; <0, L>; <L/2,0>; end PAYLOAD;  3. PROCESSING CONCEPT The concepts 
underlying the BGRAF2 system are interrupt and priority processing. These permit man-machine interaction 
from various devices as well as the concurrent occurrence of many real-time ranked events. The interrupt 
postpones the execu- tion of the current task, and the service routine of the event starts inHnediately. 
By handling the event as soon as it occurs, the system can act within the time constraints. GALATEA (8, 
15) is another graphics system also based on the interrupt concept. Another task-scheduling mechanism, 
known as "code- stripping", divides the object module into code slices where the estimated execution 
time of each slice is shorter than a small predetermined time unit. At the completion of the code slice, 
the control is passed over to the system which scans all the input-output devices and their event flags 
and schedules for execution the highest priority pend- ing task. This mechanism was implemented in TOMAL 
language (i0) - a language for microprocessor control applications. The code-stripping approach is simpler 
to implement, due to the system's serial mode using the divided code which periodically invokes the scheduler. 
In an environment of strict time-constraints, however, delayed response to external events cannot be 
tolerated. Moreover, there is a risk of real-time information being lost during the execution of lengthy 
tasks in between the time slices.  4. HIERARCHICAL STRUCTURE procedur O DESCEND; clock K(IO); "K 
ticks every i0 basic time units" ?(O, LO.4*K); '~ove beam dowrL from relative origin (0,0) determines 
position of CHUTE" CHUTE, an~lg: 0.5*sin(0.1*K); "draw (invoke) CHUTE at a pseudo-clock angle" end DESCEND; 
 A BGRAF2 source program, P, is compiled by the Translator, T, into an Object Module, O, consisting of 
a sequence of pure code blocks and a set of data blocks. This first phase can be performed on any computer 
as a cross-compiler. The second phase, the run-time environment, comprises the Object Module and six 
additional software processors: the Graphics Processor (G), the Control Processor (C), 88  the Input-Output 
Processor (I), the Real-Time Processor (R), the Memory Manager (M) and the Scheduler (S). Fig. 1 illustrates 
the two phases and the various modules of the system. The sequence of events inside the processors of 
the system is unpredictable and uncontrollable. The system is, therefore, structured hierarchically. 
At the highest level there is a monitor, the Sched- uler, which is responsible for scheduling lower- 
level tasks for execution. At the next lower level we find the abstract processors. Each processor is 
further subdivided in a hierarchical manner into its associated service routines. The processor, aided 
by the service routines, controls the events from the various resources positioned lowest. Fig. 2 describes 
this hierarchical structure of the system. This hierarchy is similar to that of T.H.E. system of Dijkstra 
(6), who proposed that an operating system be constructed as a structured sequence of levels. Each level 
uses lower levels to create a convenient abstract machine for the bene- fit of higher levels. The lowest 
level is the "naked" hardware, and the highest one is the user's program. The events inside the system 
are channelled bottom- up, according to the defined hierarchy. An event (usually an interrupt) is triggered 
at the external or the internal device (resource). Initial treat- ment is given by the appropriate 
service routine and the event is then sent to the processor, which relegates the responsibility to the 
Scheduler. The hierarchical structure ensures control over the large collection of parallel events and 
tasks and schedules them in order of priority. Over the years, operating system research was centered 
around structuring the system and pro- posing new abstract components, such as the monitor scheme (7, 
3, i0). The Concurrent PASCAL (4) was especially designed for structured and concurrent programming of 
operating systems, by using two new abstract tools: Process and Monitor. GALATEA system (15) employs 
similar concepts of Event- Monitor-Process structure. S. IMPLEMENTATION The BGRAF2 system was designed 
and implemented on a 24K DEC PDP 11/40 mini-computer at the Ben- Gurion University. Peripheral equipment 
includes: two RKO5 1.2 Mword disk cartridge drives; an LA30 DECwriter keyboard; a 50Hz KWII-L Line time 
clock; DLII asynchronous line connected to a CDC Cyber 73. The graphics unit includes a VTII Display 
Processor Unit having vector, point, character, jump, halt, setting properties and interrupt instructions, 
and driving a GT44 Refresh Display CRT and a 375 Light-Pen. The implementation was carried out in two 
consec- utive steps conforming to the two phases of the system: translation and execution. The execution 
 phase was written and debugged first, applying the step-wise refinement method and implementing Parnas' 
modularization ideas (14). The Translator was then formed in accordance with the structure and functions 
of the processors. 6. THE GRAPHICS PROCESSOR The Graphics Processor assumes responsibility for the 
graphics unit and for the graphical data structures. It maintains the dynamic display-file, performs 
transformations and modifications on the graphical information in the display records, and it is thus 
in fact a display-file compiler. The collection of routines comprising the processor are grouped in three 
classes: routines manipulating the display-file structure, routines producing graphical information 
and transformation routines. The display-file is a doubly-linked circular tree, whose links are actually 
the display-jump instruc- tions for the display processing unit. The "leaves" of the tree are the display 
records including only executable display instructions. Each node in the tree is a base record in the 
display-file and it is in fact a display-jump table, pointing to all of its "sons". A son is either 
a sequence of graph- ical components drawn directly by the object it- self (a leaf), or another graphic 
object which is a hierarchical son of the current object. The display processor executing the display-file 
actually traverses the threaded n-cry tree in preorder, using the direct jump instructions. This special 
tree structure enables the display processor to traverse the tree conveniently and facilitates the operations 
concerning the tree structure. 7. THE CONTROL PROCESSOR The Control Processor manipulates an auxiliary 
tree which models the existing hierarchy of graphic objects and their coordinate spaces and transfor- 
mations. A node in the tree contains the basic information of an object, its properties, coordi- nate 
system, transformations and pointers to its data blocks. Each object may have an unknown num- ber of 
"descendants", but the tree is represented as a binary triply-linked tree. The Control Proc- essor, called 
by the scheduled code blocks (tasks), manipulates the tree using three basic routines: INSERT a new node, 
DELETE -a sub-tree, and -  TRAVERSE a sub-tree in endorder (postorder). -  8. THE INPUT-OUTPUT PROCESSOR 
 The Input-Output Processor is responsible for I/O, interaction and communication with the user via 
a set of routines, controlling the peripheral de- vices. The processor handles the pseudo-parallel asynchronous 
events triggered at the external devices, (presented in the language for example by key: 'A'), as well 
as the procedural input and output statements. An input (output9 in a proce- dural mode is stored in 
a buffer for later proces- sing. If the device operates in an asynchronous mode, the service routine 
compares the input with the potential events within a doubly-linked-list. Each item in the list belongs 
to a specific graphic object and contains four fields: FORWARD and BACKWARD links; KEY - an information 
identifying the specific event; and a pointer - TASK -to a block of code - the event-driven block. When 
the input event and the KEY are found to be identical, the pointer TASK is entered into the appropriate 
queue of the Scheduler, (see Section Ii). [ ) Phase 1 Translation BGRAF2 source / I Phase program l 
P I l Translator I T l I Phase 2 I I Execution I I Phase t l l I J Graphics Control i/o Real-Time Memory 
Scheduler Processor Processor Processor Processor Manager M S Figure i: Phases and modules of the BGRAF2 
system event  RESOURCES event ) SERVICE ROUTINES event > PROCESSORS > MONITOR Display-file I Display 
file r[ Display unit compile; l I  Insert Tree of  objects i Delete I [Traverse I Output device i 
[ Output routine ~--~F-----1 i Input device i Input routine I Clock ] [ Clock routine [ I Allocate Memory 
I De-allocate F  I I I Datalblocks Code ~blocks L___3 F/ I ] I Figure 2: The hierarchical structure 
of the BGRAF2 system 90 In the specific implementation, the Processor controls three different devices. 
The keyboard (input) is an asynchronous input device as well as the standard serial input device. The 
keyboard (output) is the standard procedural output device, and the light-pen is an asychronous graphical 
in- put device. 9. THE REAL-TIME PROCESSOR The Real-Time Processor handles clock mechanisms and process 
timing. It updates the master clock, time, and the user-defined clocks. A 50Hz line clock synchronized 
with the external '~all clock" lies at the heart of the processor. Each tick of the line clock invokes 
an interrupt service routine, which increments the master clock and then scans the linked list of the 
user-deflned clocks, each of which is a part of the data structure of some object. Each clock is incremented, 
decremented or passive according to its frequency and state (running or suspended). The time- and clock-driven 
tasks are entered into queue 4 of the Scheduler, where 4 is the highest system priority. The Real- Time 
Processor and its derivatives are given high- est priority in the system, therefore time-events are immediately 
scheduled for execution, enabling the system to operate in real-time, (see Section ii). 10. THE MEMORY 
MANAGER The Memory Manager services the procedural code blocks and the processors by allocating and de- 
allocating memory. Each time a graphic procedure is invoked, a new data area is assigned to the newly-created 
object, and it is de-allocated when the object is explicitly or implicitly "terminated". Nodes within 
the object tree and graphic records within the display-file are also dynamically allocated. The memory 
management method must conform to the real-time constraints. The "garbage collection" philosophy (13), 
and the "boundary-tags first-fit" approach (13) are not suitable for real-time situations. We therefore 
adopt an approach based on Knuth's "buddy" system (13) which has the advantage of speed. Kunth's approach 
has been revised and improved to suit the requirements of the BGRAF2 system. The allocation routine in 
BGRAF2 endeavours to form a block of the desired size by coalescing smaller available blocks. If this 
fails, a larger available block is split, as in Knuth's method. The de-allocation routine merely returns 
the block to the list according to its size, not trying, as in Knuth's, to coalesce buddies. This approach 
was tested and compared with Knuth's, utilizing a simulation program. For more details see (12). ii. 
THE SCHEDULER The Scheduler is an abstract monitor responsible for scheduling tasks for execution according 
to a m~iti-level priority from a multi-queue scheme. The queues contain '~seudo-now" tasks, i.e., all 
the requests which must be executed "immediately". The procedural tasks, corresponding to the automatic 
 side=effects during the active state of new objects, are given lowest priority and are thus scheduled 
from queue i. Keyboard events are scheduled from queue 2, and light-pen events from queue 3. Pseudo-clocks 
are scheduled from the highest prior- ity - queue 4. Each of the processors described above inserts 
 into its corresponding queue the tasks for "immediate" execution, and the Scheduler schedules the 
first task in the highest priority queue. In this respect the Scheduler is similar to the exec- utive 
in digital simulation systems. There, the event-list is a future time-table, the clock is updated to 
the time of the next significant event and the intervening time periods are skipped over. A scheduler 
in real-time systems, however, sched- ules tasks to be executed "now", and the queues only contain tasks 
to be terminated before the end of the current time unit. ii.i "ONE-WAY BARRIER" The process of inserting 
into a queue is performed asynchronously and randomly by a remote processor as a result of an interrupt. 
At the same time the Scheduler may remove a task from the same queue, and thus the queue and its accompanying 
variables are "common (shared) variables" (3). The main mechanism to protect these variables is the "critical 
regions (sections)" (5,5). Well-known approaches for the implementation of critical regions are: Dijkstra's 
"semaphore" (5), monitors, and other semaphor-based approaches (3, i0). The implementation of the semaphore 
is paradoxical in the sense that a semaphore is required for implementing the non-atomic semaphore operationsl 
An alternative solution is therefore proposed for producer-consumer systems. A "one-way barrier" is suggested 
in place of the semaphore. This barrier prevents the consumer (the Scheduler) from enter- ing the critical 
region, while theproducers (the other processors) may interrupt the consumer and enter the critical region, 
causing neither side- effects nor conflicting situations. For more details see (12).  11.2 SLIPPAGE 
 The BGRAF2 system operates as a hard-real-time system in the sense that the tasks forming the next frame 
must be terminated by the end of the current time unit. During the real-time operation it may happen 
that the system cannot cope with this real-time constraint. The master clock ticks, the system has not 
completed the creation of the next frame, and the dynamic picture on screen is deficient and/or distorted. 
There is no absolute solution to this problem, known as "slippage" or "tempus fugit" (8), and the goal 
is to prevent it from happening and to inform the system of its occurrence. There are two main strategies 
to cope with slippage. One says that "the show must go on" and that synchronization with the "wall clock" 
must be kept, as opposed to "better late than never", where the quality of the picture must not be degraded 
even if a transient distortion in time exists. In  GALATEA (8), an animated computer-generated movie 
 is overlaid on an original film image running syn-  chronously with it, and therefore the first strat- 
 egy is adopted. In general graphics systems, how- ever, the second strategy is preferred: the system 
 is in a "wait and see" mode, its performances are  not deficient and the user will not even notice 
 the transient distortion. If, however, the accu- mulated distortion in time can be noticed or if no 
 distortion is permissible in the particular system, the first strategy must be adopted. In the BGRAF2 
system, slippage is detected and handled by the Scheduler. The Real-Time Processor informs the Scheduler 
of the commencement of each time unit, and inserts into every queue a special task, which when executed 
searches for other special tasks in the queue. The special task can, thus, inform the system of a slippage 
situation, the delay in time units, and the severity of the slippage according to the queue and priority 
in- volved. One optional strategy of the Scheduler in minimizing slippage is to unify the queue, elimi- 
nating duplicates and superseded code blocks - i.e., to degrade performance.  11.3 CAMERA/DEBUG MODE 
The mechanism of placing a special task at the rear-end of the queue allows the system to operate in 
a special mode for filming or debugging. The line-clock is disconnected from the system and the Scheduler 
empties its queues, signalling the com-pletion of the current frame. This signal either causes the camera 
lens to operate or gives notice to the user. Before proceeding, the Scheduler waits for a feedback signal 
from either the camera or the user. 12. THE TRANSLATOR The Translator operates once during a separate 
first phase. An experimental restricted version of the Translator is executed on the PDP 11/40. A more 
complete version is executed on the CDC Cyber 73 as a cross-compiler. The object module, output by the 
Translator, consists of a sequence of pure code blocks and a set of data blocks. Each time a procedure 
is invoked, a new data area is allocated for the newly created object, but the same re-entrant code is 
used. An example of the data structure of a simple variable is given in Fig. 3. A variable in a data 
area is represented by two fields, the first of which contains its value. The second refers to a variable-length 
linked list of point- ers, each of which identifies a block of code to be executed "in~aediately" every 
time a value is assigned to the variable, i.e., a desirable side- effect of the variable. 13. CONCLUDING 
NOTES The BGRAF2 system, which supports the BGRAF2 lan- guage deals with several features, each of 
which has a significant role in the development of graphics systems. Graphics, real-time and inter- 
 action are the underlying motifs of the language and the system, and other systems emphasizing even 
just one of these motifs can benefit from the ideas presented here. Three different extensions, inspired 
by and rely on these motifs, are cur- ently under development at the Ben-Gurion Univ.: a 3D real-time 
interactive language, a high-level language for real-time processes (2), and non-real- time interpreter 
version of BGRAF2. REFERENCES 1. Bergman, S. &#38; Kaufman, A. BGRAF2: a real-time interactive graphics 
language with modular objects and implicit dynamics. Proc. SIGGRAPH'76, Phila. PA (July 1976) 133-138. 
 2. Bergman, S. &#38; Kaufman, A. High-level language for real-time processes. Proc. 12-th Nat'l Conf. 
on Data Processing, Tel-Aviv (Sept. 1977) 179-189  (in Hebrew).  3. Brinch Hansen, P. Operating system 
principles. Prentice-Hall, Englewood Cliffs NJ (1973).  4. Brinch Hansen, P. The programming language 
con- current Pascal. IEEE Proc. on Software Eng. I, 2 (June 1975) 199-207.  5. Dijkstra, E.W. Cooperating 
sequential processes. In "Programming languages" by F. Gennys (Ed.), Academic Press (1968).  6. Dijkstra, 
E.W. The structure of the T.H.E. multi- programming system. CACM Ii, 5 (May 1968) 341-346.  7. Dijkstra, 
E.W. Hierarchical ordering of sequential processes. Acta Informatica i, 2 (1971) 115-138.  8. Futrelle, 
R.P. &#38; Potel, M.J. The system design for GALATEA, an interactive real-time computer system for movie 
and video analysis. Computers  Graphics 1 (1975) 115-121.  9. Hennessy, J.L.:et al. TOMAL: a task-oriented 
microprocessor applications language. IEEE Trans. on IECI-22, 3 (Aug. 1975).283-289.  i0. Hoare, C.A.R. 
Monitors: an operating system struc- turing concept. CACM 17, 10 (Oct. 1974) 549-557. ii. Kaufman, A. 
&#38; Bergman, S. The definition of BGRAF2: a real-time interactive graphic language. Ben-Gurion Univ., 
Math. Dept., Tech. Rep. bIATH- 132 (Jan. 1976). 12. Kaufman, A. Interactive real-time graphics lan- 
guage. Ph.D. Thesis (Aug. 1977), (in Hebrew, English Summary).  13. Knuth, D.E. The art of computer 
programming, vol. i: Fundamental algorithms. Addison- Wesley (1968).  14. Parnas, D.L. On the criteria 
to be used in de- composing systems into modules. CAf~4 15, 12 (Dec. 1972) 1053-1058.  15. Potel, M.J. 
An executive for event-driven systems. Quarterly Rep. 49, Univ. of Chicago (May 1976).  Figure 3: Data 
structure of a simple variable   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807377</article_id>
		<sort_key>93</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[Application of shape-preserving spline interpolation to interactive editing of photogrammetric data]]></title>
		<page_from>93</page_from>
		<page_to>99</page_to>
		<doi_number>10.1145/800248.807377</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807377</url>
		<abstract>
			<par><![CDATA[<p>The Integrated Photogrammetric Instrument Network (IPIN) is being designed and developed by the Defense Mapping Agency Aerospace Center in St. Louis, Mo. to meet database demands for terrain elevation information. IPIN is a network of computers and instrumentation dedicated to digitizing and editing photo-source terrain data [1]. Editing procedures are required because of digitizing errors inherent in the data-collection process. Some of these errors are random; others are systematic and predictable.</p> <p>The techniques of one of the editing procedures being developed may find application elsewhere. The procedure of interest here involves smoothing raw data that have been collected by the operator of an analytical stereoplotter. When digitizing geomorphic features from aerial stereophotographs, the double-line drain (DLD) presents special problems. The digitizing of a DLD (a relatively broad river or stream) requires specifying trlples (x,y,z) (latitude, longitude, elevation) at points spaced along the length of each shoreline. The drain boundaries thus collected usually have acceptable latitude and longitude values. The elevation values, however, require smoothing.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Bernstein polynomials]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Interactive graphics]]></kw>
			<kw><![CDATA[Interpolation]]></kw>
			<kw><![CDATA[Osculation]]></kw>
			<kw><![CDATA[Photogrammetry]]></kw>
			<kw><![CDATA[Spline]]></kw>
			<kw><![CDATA[Terrain data editing]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.4</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Splines</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.1.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003657.10003659</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Nonparametric representations->Spline models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003722</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Interpolation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39070925</person_id>
				<author_profile_id><![CDATA[81100440623]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[L.]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Deimel]]></last_name>
				<suffix><![CDATA[Jr.]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, North Carolina State University, Raleigh, North Caralina]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P329309</person_id>
				<author_profile_id><![CDATA[81332496500]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Doss]]></last_name>
				<suffix><![CDATA[II]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, North Carolina State University, Raleigh, North Caralina]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P333018</person_id>
				<author_profile_id><![CDATA[81100037060]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Fornaro]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, North Carolina State University, Raleigh, North Caralina]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39075701</person_id>
				<author_profile_id><![CDATA[81100125719]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[McAllister]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, North Carolina State University, Raleigh, North Caralina]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39062515</person_id>
				<author_profile_id><![CDATA[81100414536]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Roulier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Mathematics, North Carolina State University, Raleigh, North Caralina]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA["Integrated Photogrammetric Instrument Network (IPIN) Computer Network Software Specification," Technical Report ECE 76-1, October 1976, Electrical and Computer Engineering Dept., Clarkson College, Potsdam, NY.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Greville, T.N.E., Spline functions, interpolation, and numerical quadrature. In Mathematical Methods for Digital Computers. Vol. 2, A. Ralston and H. S. Wilf (eds.) Wiley, NY, 1967, Chapter 8.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Lanczos, C. Applied Analysis, Prentice-Hall, Englewood Cliffs, NJ, 1956.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[McAllister, D. F., Passow, E., and Roulier, J. A., Algorithms for computing shape preserving spline interpolations to data. Math. Comp. 31, 139 (1977), 717-725.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[McAllister, D. F. and Roulier, J. A., Interpolation by Convex Quadratic Splines. Math. Comp. (to appear).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Passow, E., and Roulier, J. A., Monotone and Convex Spline Interpolation. SIAM J. Num. Anal., 14, 1977, pp. 904-909.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 APPLICATION OF SHAPE-PRESERVING SPLINE INTERPOLATION TO INTERACTIVE EDITING OF PHOTOGRAMMETRIC DATA 
 L. E. Delmel, Jr.*, C. L. Doss, II*, R. J. Fornaro*, D. F. McAllister*, J. A. Roulier** North Carolina 
State University Raleigh, North Carolina 27650 Let the points {(xi,Yi)} ~ be decreasing (yi>Yi+l , l<_i<n-l) 
and let {Si} ~ satisfy Si~0, l<i<_n. An algorithm is presented for computing a (smooth) shape preserving 
quadratic spline f which satisfies f(xi)~y i and f'(xi)=Si, l<i<n. The computation of f on (xi,xi+ I} 
depends only on the points (xi,Y i) and (Xi+l,Yi+l) and the slopes S i and Si+ I. The algorithm is applied 
to the interactive editing of photogrammetric data representing river profiles. Key words and phrases: 
photogrammetry, interactive graphics, computer graphics, spline, interpolation, osculation, Bernstein 
polynomials, terrain data editing. CR Categories: 8.2, 5.13, 3.80, 3.23 I. INTRODUCTION The Integrated 
Photogrammetric Instrument Network (IPIN) is being designed and developed by the Defense Mapping Agency 
Aerospace Center in St. Louis, Mo. to meet database demands for terrain elevation information. IPIN is 
a network of com- puters and instrumentation dedicated to digitizing and editing photo-source terrain 
data [1]. Editing procedures are required because of digitizing errors inherent in the data-collection 
process. Some of these errors are random; others are systematic and predictable. The techniques of one 
of the editing procedures being developed may find application elsewhere. The procedure of interest here 
involves smoothing raw data that have been collected by the operator of an analytical stereoplotter. 
When digitizing geomorphic features from aerial stereophotographs, the double- line drain (DLD) presents 
special problems. The digitizing of a DLD (a relatively broad river or stream) requires specifying trlples 
(x,y,z) (lati- tude, longitude, elevation) at points spaced along the length of each shoreline. The drain 
boundaries thus collected usually have acceptable latitude and longitude values. The elevation values, 
however, require smoothing. II. THE DOUBLE-LINE DRAIN EDIT The double-llne drain edit involves modifi- 
cation of raw boundary data to meet two require- ments: the data must not show the river flowing uphill, 
and each point on a boundary most be at the same elevation as a corresponding location *Department of 
Computer Science **Department of Mathematics k "opposite" that point on the other shoreline. Although 
the latitude-longitude co-ordinates of drain boundaries can be obtained with acceptable accuracy from 
the analytical stereoplotters, elevation values so obtained are less reliable. For this reason, the boundaries 
must be edited to assure that the requirements are met. Data editing for IPIN is done by operators at 
edit stations using CRT graphics terminals. A mini-computer, shared by two edit stations, pro- vides 
most of the computational power needed for data editing. Unedited data are transferred to this edit mini 
from other units of the network and edited data are sent back. Although other computers are available 
for particularly time-consuming editing computation, it is desirable to do as much computing at the edit 
mini as possible. In light of this hardware configuration and the nature of the drain editing task, an 
editing technique is needed which i) does not substantially complicate the data-collection process, 2) 
uses the available data effectively to control the final boundary profiles, 3) allows the operator to 
direct the edit based on his best professional Judgment, and 4) does not impose a large computation burden. 
 Figures 1 and 2 illustrate typical DLD data. Figure 1 is a cartographic representation of a river segment. 
Figure 2 is an elevation profile plot of the river boundaries. Elevation values for two points opposite 
one another at one end of the river are plotted at x=0. Elevation values for successive points on each 
boundary in the downstream direction are equally spaced along the x-axls. Since the computer-assisted 
data-collectlon process spaces boundary points equally or very nearly so, the figure represents boundary 
elevation versus This work supported in part by Rome Air Development Center under contract no. F30602-75-C-0118 
and in part by NSF grant no. MCS76-0403. 93 distance downstream along each boundary. Notice, however, 
that the two boundaries may have different numbers of data points, since the river shorelines have different 
lengths. These boundary profiles should represent decreasing functions. Fig. I LEFT BOUNDARY BOUNDARY 
/~. Fig. 2 III. THE EDITING PROCEDURE  The DLD editing problem may be analyzed into two subproblems--l) 
the problem of associating opposite shoreline points and 2) the problem of assuring decreasing boundary 
profiles. A simple solution to both subproblems involves the estab- llshment of a set of special reference 
points called control points. These points allow identi- fication of opposing shoreline locations and 
pro- vide reference elevations through which a composite boundary profile may be interpolated. Consider 
the problem of matching opposite shorelines of the river shown in Figs. i and 2. A simple approach 
relies on the fact that over short distances, exact matching is not required. For a real river, of 
course, there is considerable uncertainty about which points are opposite one another. Where the drain 
is essentially straight (in the lower left portion of Fig. i, for example), if a single pair of opposite 
points were known, one expects that associating successive points on each boundary would be an acceptable 
strategy. Minor oscillations along one boundary should cancel  similar oscillations along the other 
boundary and keep the matched points opposite. Were this process continued for any great distance downstream, 
however, we would expect that significant errors would occur at the end of a segment. If pairs of opposite 
points at both ends of the segment were known, associating data points in a proportional fashion should 
be acceptable over the entire segment if the segment is relatively short and the boundaries do not oscillate 
severely. Suppose the drain segment has boundaries L and R consisting of points LO, LI, . . ., L m and 
points R0, RI, . .., Rn respectively. We assume that points L 0 and R 0 are opposite one another, as 
are points L and R . Hence, boundary L has length ms, m n and boundary R haslength ns, where s is the 
distance between successive points. If the two boundaries have similar shapes (by hypothesis, they are 
approximately parallel with only random deviations), then traveling a distance dL<ms downstream along 
L beginning at L_ should put one approximately oppo- site a pointUon R which is distance dR=(n/m)d L 
downstream along R from R 0. In fact, a~ analogous argument can be made even if the two boundaries do 
not have "similar" shapes, so long as each boundary behaves in a fairly uniform manner along the segment. 
For example, if the segment represents a single bend in a river, the inner shore will be shorter than 
the outer shore. If the shores are uniformly wavy (or smooth) over their lengths, however, proportional 
matching should associate pairs of points which define lines nearly perpendicular to each shoreline. 
 The above discussion suggests that if the drain is properly sectioned, it is relatively easy to match 
opposite shoreline points for each segment. In Fig. i, for example, good choices for sectioning are indicated 
by the short segments across the drain. Fig. 2 shows that the elevations collected are not always decreasing, 
however. Features such as cliffs and trees along the shoreline adversely affect the data collection. 
Unfortunately, elevation cannot be collected in the middle of the DLD because of reflection problems 
from the water. It is possible to obtain better elevation data if points are collected carefully in manual 
mode rather than semi-automatically, however. Collecting points in this manner sparsely along the drain 
provides a guide to the appropriate shape for boundary profiles and can be used to section the drain 
at the same time. The stereoplotter operator, who sees a 3-dimenslonal view of the terrain being mapped, 
is requested to collect a set of control points of strictly decreasing elevation for each DLD after he 
has collected the boundaries. These points are placed in the center of the drain between opposite shoreline 
points which are to define the end of a drain section. The elevations of the con- trol points are the 
elevations of the drain at the ends of those sections. When the edit is performed, control points are 
matched to the nearest boundary points to perform sectioning. A composite boundary profile is then interpolated 
through the control point elevations and projected on the collected boundaries. The control points provide 
a more reliable indication of drain elevations than do typical boundary points. On the other hand, boundary 
data does provide important, though noisy, information about boundary profiles. The authors have devised 
a technique which uses these control  94 elevations and information about the general trend slope S 
2. Let g be the continuous piecewise linear of the drain fall. The method is a variation of that devised 
by McAlllster and Roulier [5]. In the vicinity of each control point, a least-squares line is fit through 
the collected boundary profiles to generate a reference slope at that control point. (In cases where 
this slope is positive, it is set to zero.) A quadratic spline is then computed which gives a decreasing 
composite boundary profile, interpolates each control point, and whose first derivative interpolates 
the reference slopes at each control point. This interpolation is performed on successive pairs of control 
points. Depending upon the geometry, two or three quadratic Bernsteln polynomials are used to gengrate 
the desired curve. The object of the interpolation is to construct a composite boundary profile whose 
shape approximates the fall of the river along an imaginary "center line." The x-axis of this profile 
represents distance along this imaginary line; the y-axis represents elevation. It is assumed that the 
distance along the river between control points is proportional to the average number of data points 
on the two boundaries between the control points (proportional to (m+n)/2, using the notation above). 
 Slopes are computed accordingly. After a composite profile is constructed, elevation values are projected 
onto the scaled, collected boundaries. This gives the desired result, namely decreasing drain boundary 
profiles with matching elevations at opposite shoreline points. The details of the interpolation method 
are given in the following section. IV. THE SHAPE-PRESERVING SPLINE INTERPOLATION It is well known 
that Berx~stein polynomials inherit certain global properties of the function they approximate, including 
monotonicity and convexity [4]. We will use these properties to develop an algorithm for computing a 
smooth, osculating quadratic spline which preserves the monotonicity of given data. That is, if the data 
are strictly decreasing and the given slopes are non-positive, then the quadratic spline will be strictly 
decreasing between the data points. The technique uses only "local" information in con- structing the 
spline between two adjacent data points, namely the points and the slopes specified at those points. 
For this reason, it is easy to add and delete points and modify slopes without recalculating all information 
needed to specify the spline. Let P=(PI,Pg) and Q=(QI,Qg) be given points with P'<QI' and let g be 
a conEinuous function on t the ~nterval I=[PI,QI]. The n-th de~ree Bernstein polynomial of ~, Bn~g)~is 
defined ~s follows~." n Bn(g) (x) --(QI-PI)-n Z [g(Pl+(J/n) (QI-PI 1) j=O  (j) (x-P1)J (Ql-X) n-I] 
In particular, let W=(WI,W 2) be an arbitrary point satisfying PI<WI<QI , let L 1 be the llne passing 
 through the points P and W with slope SI, and let L 2 be the line through the points W and Q with 
function defined by the three points P, W and Q (see Fig. 3): t-  =iLl(X) for x¢[PI,WI] g(x) | 
LL2(x) for x~(WI,QI]  ~ Ol Fig. 3 If we let (*) n = F(QI-PI)/mln[ (wi-Pl) , (QI-WI) ]]  and # = 
B (g) n then ~ satisfies the following on I: (i) If g is increasing (decreasing) on I, then is increasing 
(decreasing on I.  (2) If g is convex (concave) on I, then is convex (concave) on I.  (3) ~ (PI) = 
P2'  ¢ (QI) = Q2' @ '(PI ) = s I , @ ' (QI) = s 2. Furthermore, if W I is the midpoint of I, then 
from (*), n=2 and ~ is-a quadratic polynomial. We will show that if the data to be interpolated are strictly 
decreasing (P2>Q2) and the associated slopes are non-positlve (SILO and S~0), then using the above 
properties of $, it is always possible to specify a strictly decreasing quadratic spline on I which 
interpolates P and Q, whose derivative interpolates S I and S 2 and requires at most two additional 
knots in I. Let P=(PI~P2) and Q=(QI,Q2 ) be points to be interpolated with PI<QI and P2<Q2 . Let S 
I and S be the slopes associated with P and Q, respectively, and L I and L 2 be the lines through P 
and Q with slopes S I and $2, respectively. We assume that SI<O and $2<__0. Let R be the set of points 
 95  R = {(x,y) IPI~X!QI, and Q2<_Y~P2 } - {P,Q}, that is, R is the rectangle described by the points 
Affi(PI,Q2), P=(Pl,P2), Bffi(QI,P2), and Qffi(QI,Q2 ) plus its interior and minus the points P and Q. 
Let M be the "midpoint line" segment determined by points F=((PI+QI)/2,Q 2) and G=((PI+QI)/2,P2). Let 
the points where L 1 and L 2 intersect the boundary of R be C and D, respectively. If L 1 and L 2 intersect 
in R, let Z=(ZI,Z 2) be a point of intersection. (See Fig. 4.) We show how to generate the desired quadratic 
spllne f. P S D B 2 R c A F O Fig. 4 Case I. L I and L 2 intersect at a point Z in R. (See Fig. 5.) 
P Z Z! C W I Q Fig. 5 Let (1) ~l = Z I, (2) V 1 (Pl+Xl)/2, V 2 = LI(VI) , (Vf(VI,V2) is the point 
on L 1 with abscissa VI.) (3) W 1 = (XI+QI)/2, and W 2 = L2(WI).  Let L be the llne through the points 
V and W, and define  (4) ~2 ffi ~(x-z) ' (5) ql to be the quadratic Bernstein pSlynomlal of the piecewlse 
linear function defined by the three points P, V, and X (--henceforth denoted by ql = B2{P'V'X})' and 
 (6) q2 ffi B2{X'W'Q}" Now define f as follows: f(~) = ~,~l(~) for ~C[Pl,g l] Lq2(x) for xe(X1,Q 1] 
Then f is a decreasin_~ smooth, osculatory quadratic spline with knot at X I such that f(Pl ) = P2' 
f(Ql ) = Q2' f'(Pl ) = Sl' and f'(Ql ) = s 2. It follows from the properties of Bern_stein polynomials 
that f interpolates P, Q, and X and that f' interpolates Sl, $2, and the slope of L at the points P, 
Q, and X, respectively. Hence, it suffices to show that f is decreasing. This, however, is an immediate 
consequence of the fact that a Bernstein polynomial of a monotone function is monotone in the same sense, 
and that the aforementioned piecewise linear functions are decreasing. We note that in this case the 
spllne f preserves the convexity of the piecewlse linear function defined by the points P, Z, and Q. 
 Case II. L 1 and L 2 do not intersect in R. We consider subcases where both, one, or neither L 1 nor 
L 2 intersect M. Case fla. Both L 1 and L 2 intersect segment  M. Inn thlns Case, we let ~ = F 1 and 
proceed as in Case I. (See Fig. 6.) G F Q Fig. 6a 96  p D G Define K to be the point of intersection 
of L1 and \,\' I, ' \ !  \i L  i ! \ i \ F C Fig. 6b The choice ofT. is not unique, but the above 
 I  choice insures a symmetry in the algorithm: if R were rotated, interchanging P and Q, the algorithm 
applied, and then the resulting graph rotated back, the function f would be the same as if the algorithm 
had been applied without rotating R. As incase I, we have that f is a smooth, oscu- latory quadratic 
spline. To show f is decreasing, it suffices to show that Y2>W2 . If L I lles above L 2 in R (see Fig. 
6(a)), then V2>W 2 is obvious. If L I lles below L? (see Fig. 6(b)) in R, then by cbnstructlon we'have 
V2>(G2+F2)/2>W2 , since both L 1 and L_ cross M on the interior of R. Hence z  is decreasing and therefore 
f is also. Case lib. Only one of L.I and L^z intersects M. Without loss of generality, assume L 1 is 
the line which does so. We construct two additional lines: ou.h. and Q so that C bisects segment AH. 
Define ~'i to be the line through P and H. (2) Let J be the point on th_~e segment PB such that D bisects 
segment JB. Let Lp be the llne through Q and J. (See Fig. -7.)  P J G D B Fig. 7  L2" (K lles in the 
interior of R.) Define T 1 = (KI+Q I)/2 and proceed in Cas e I. The knotT] can be chosen arbitrarily 
in the interval (KI,QII. The above choice insures symmetry in the algorithm as in Case fla. (We note 
that it is also possible to choose XI=KI, _although the resulting spline will have zero slope at X.) 
 To show that t__he line L is decreasing, we note that by choice of XI, we must have ^ __ V2=LI(XI) 
and ^ __ W2=L2(XI).  Since £'] lies above £-z to the right of KI, it follows that V2~W2, and hence 
f is decreasing. Case llc. Neither L 1 nor L 2 intersect M. This  is the_only case which requires that 
we add two knots X I and~ I in the interval [PI,QI ].  That there exists no quadratic spline with a 
single knot for this case follows from Theorem 1 of [6]. Among other things, the theorem shows that the 
tangent lines to any quadratic polynomial at the end points of a closed interval [a,b] must intersect 
at N = ~a + 5)/2. We also note that the lines L 1 and L 2 do not intersect in R, and the triangles PCH 
and QDJ have no points in common. (See Fig. 8.) For this case, we let: (i) __T =  l (PI+CI)/2, (2) 
V 1 = (PI+XI)/2, _~ = LI(V I) (3) x I = (DI~_I)/2 (4) W 1 ffi (QI+XI)/2, and W2 = L2tWI~, P J G D 
V  ~ [ i~ ~--L' thepoW.=~,Letnts(5)V As before, we deflne ~ to be the line through andyl i  A F C 
Q H 97 Y2 = L~(YI)' ~ (6) Z 1 = Xl, z 2 = E(z~) (7) E 1 = (XI+XI)/2 , and E 2 =  ~(EI). Let ql 
= B2{P'V'Y} q2 = B2{Y'E'Z}' and q3 " B2{Z'W'Q}" (Note that q2 is the llne L.) Finally, define ql(x) 
for x¢[PI,XI]  f(x) lq2(x) for Lq3(x) for xe(Xi,Ql ] That f is decreasing follows from the fact that 
 V2>(F2+G2)/2>W2 Hence, by construction and the fact that the second degree Bernsteln polynomial of 
a line is the line itself, it follows that f is a smooth, decreasing quadratic spllne which interpolates 
P and Q and f' interpolates S I and S 2. In the special case that D=G and C=F, although it is possible 
to have only a single knot (anywhere between PI and QI), the resulting spllne will have a zero slope 
at The knot, a condition which the authors wished to avoid. Hence, this case was treated using two knots 
instead of one. V. CONCLUSIONS A prototype DLD editing package is implemented on a DEC GT-II/40 graphics 
system at North Carolina State University. This system allows the operator to view profiles of the two 
sides of the DLD (scaled using the control points) and the interpolated com- posite profile. If necessary, 
the operator may control the shape of the composite profile by using the light pen to modify control 
point locations and associated slopes.* By so doing, he can easily produce an acceptable profile and 
adjust the ele- vations of the collected boundaries. Figure 9 shows a typical display seen by the operator. 
 (Labels have been added for clarity.) This display includes the generated profile and is derived from 
 data used to produce Figs. i and 2. In this figure, where a vertical llne would cross the original profiles, 
the corresponding data points are set to the elevation given by the composite curve. Thls matching of 
points appears to give quite satis-  factory results, in part due to certain natural properties of rivers. 
If the shorelines are particularly wavy, minor mismatching may occur. This mismatching Is not of great 
significance, however, as such wandering boundaries are only characteristic of slowly flowing drains. 
For such drains, elevations change slowly and mismatching can be tolerated. Figure i0 reproduces Flg. 
i with contours added,  thus illustrating the matching of points more clearly. LEFT BOUNDARY CONTROL 
POINT Fig. 9 Fig. i0 The curve-fltting technique used here has the advantages of being fast, relylag 
upon only local information, and producing curves guaranteed to be decreasing. There exist several other 
techniques which could have been used to determine the curve. Some, such as ordinary polynomial interpolation 
[3], cubic spllne interpolation [2], and trigono- metric interpolation [3] produce a smooth inter- polant 
but do not assure that the curve produced will be monotone decreasing. Convex spline inter- polation 
[4,5] guarantees that the curve will be monotone and smooth but the data must be sectioned into convex 
and concave segments. The interpolation described here requires only control points and associated slopes. 
Note that slopes could be derived from the data by some means other than that we have described. In fact, 
the edit station operator can alter these slopes at will. The fact that the interpolation uses only local 
information is very attractive because it allows control points to be edited individually without disturbing 
the entire composite profile. The DLD can be edited section by section and the composite profiles generated 
will fit together to produce a smooth continuous profile. ACKNOWLEDGEMENT The authors would like to 
thank David Scott, who did much of the programming necessary to implement and test the algorithms described. 
 *The edit station operator has information available to him not available to the stereoplotter operator. 
He can consult photographs and existing map sources and knows that the data-collector has flagged certain 
control points as having unreliable elevations. 98 REFERENCES  [i] "Integrated Photogrammetric Instrument 
Network (IPIN) Computer Network Software Specification," Technical Report ECE 76-1, October 1976, Electrical 
and Computer Engineering Dept., Clarkson College, Potsdam, NY. [2] Greville, T.N.E., Spline functions, 
interpola- tion, and numerical quadrature. In Mathematical Methods for Digital Computers. Vol. 2, A. 
Ralston and H. S. Wilf (eds.) Wiley, NY, 1967, Chapter 8. [3] Lanczos, C. Applied Analysis, Prentlce-Hall, 
Englewood Cliffs, NJ, 1956. [4] McAllister, D. F., Passow, E., and Roulier, J. A., Algorithms for computing 
shape preserving spline interpolations to data. Math. Comp. 31, 139 (1977), 717-725. [5] McAllister, 
D. F. and Roulier, J. A., Interpolation by Convex Quadratic Splines. Math. Comp. (to appear). [6] Passow, 
E., and Roulier, J. A., Monotone and Convex Spline Interpolation. SIAM J. Num. Anal., 14, 1977, pp. 904-909. 
 ~9   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807378</article_id>
		<sort_key>100</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[The effect of System Response Time on interactive computer aided problem solving]]></title>
		<page_from>100</page_from>
		<page_to>104</page_to>
		<doi_number>10.1145/800248.807378</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807378</url>
		<abstract>
			<par><![CDATA[<p>The effects of System Response Time, SRT, on interactive graphical problem solving were investigated for fixed SRT's of 0.16, 0.72 and 1.49 seconds. The object was to demonstrate the importance or otherwise of even small SRT values for interactive graphical problem solving of a type which often occurs in Computer Aided Design. A SRT of 1.49 sec was found to degrade performance by about 50%, measured by problem solution time, compared with that found for 0.16 and 0.72 seconds.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.8</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.2.9</cat_node>
				<descriptor>Time estimation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003490.10003491</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Management of computing and information systems->Project and people management</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10011254.10011258</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Algorithm design techniques->Dynamic programming</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010213</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Control methods</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Experimentation</gt>
			<gt>Management</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P333919</person_id>
				<author_profile_id><![CDATA[81332501426]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Goodman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Imperial College, London, England]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31097670</person_id>
				<author_profile_id><![CDATA[81100397330]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Spence]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Imperial College, London, England]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Cochran, W.G., Cox, G.M. 1957 Experimental Designs, John Wiley]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cox, D.R. 1958 Planning of Experiments, John Wiley]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Corley, M.R., and Allan, J.J. 1976 'Pragmatic Information Processing Aspects of Graphically Accessed Computer-Aided Design', IEEE Trans, Sys. Man. Cyb., Vol SMC-6, No. 6, pp 434-439.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Edwards, A.L. 1972 'Experimental Design in Psychological Research', 4th Edn, Holt, Rinehart and Winston, New York.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Foley, J.D. and Wallace,J.D. 1974 'The Art of Natural Graphic Man-Machine Conversation, Proc. IEEE, Vol 62, No 4, pp 462-471.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Grossberg, M., Wiesen, R.A. and Yntema,D.B. 1976 'An Experiment on Problem Solving with Delayed Computer Responses', IEEE Trans, Sys. Man. Cyb., Vol SMC-6, No 4, pp 219-222.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Hatvany, J., Newman,W.M., and Sabin,M.A. 1977 'World Survey of Computer-Aided Design', Computer Aided Des., Vol 9, No 2, pp 79-98.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Miller, L.H. 1977 'A Study in Man-Machine Interaction', National Computer Conf. U.S.A., pp 409-421.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Miller, R.B. 1968 'Response Time in Man-Computer Conversational Transactions', Fall Joint Comp. Conf. U.S.A., pp 267-277.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Sackman, H. 1968 'Timesharing Versus Batch Processing: the experimental evidence', Spring Joint Comp. Conf. U.S.A. pp 1-10.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Sackman, H. 1976 'Outlook for Man-Computer Symbiosis: Towards a General Theory of Man-Computer Problem Solving', Nato ASI Paper, Mati, Greece, September 1976.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Spence, R. and Apperley,M.D. 1977 'The Interactive-Graphic Man-Computer Dialogue in Computer-Aided Circuit Design', IEEE Trans. on Circuits and Systems, CAS-24, 2, pp 49-61(February 1977).]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Williams, E.J. 1949 'Experimental Designs for the Estimation of Residual Effects', Austr. J. Sc. Res. A, 2, 149-154.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 THE EFFECT OF SYSTEM RESPONSE TIME ON INTERACTIVE COMPUTER AIDED PROBLEM SOLVING T. Goodman and R. 
Spence Imperial College, London, England ABSRACT The effects of System Response Time, SRT, on interactive 
graphical problem solving were investigated for fixed SRT's of 0.16, 0.72 and 1.49 seconds. The object 
was to demonstrate the importance or otherwise of even small SRT values for interactive graphical problem 
solving of a type which often occurs in Computer Aided Design. A SRT of 1.49 sec was found to degrade 
performance by about 50%, measured by problem solution time, compared with that found for 0.16 and 0.72 
seconds. INTRODUCTION When creating a highly interactive computer- aided design facility, it is desirable 
for the system architect to be aware, where possible, of the effect that various system characteristics 
might have on the user. In particular, since one of the principal reasons for using a computer is to 
enhance productivity by increasing the speed of working, it is natural to ask how the user's performance 
is affected by delays introduced by the computer. It is the aim of this paper to go some way towards 
providing an answer for a particular problem type and medium of interaction. Specifically we shall be 
concerned with the effect of System Response Time (SRT), which we define as the time elapsing between 
a user's request for data -involving perhaps a calcula- tion -and its subsequent display to him. Within 
computer-aided engineering design there are many classes of users, problems and computer systems. The 
discussion which follows is concerned with very highly interactive graphic computer-aided design (CAD) 
systems inwhich the designer is attempting heuristically~o adjust the values of a number of parameters 
in order to obtain satisfactory performance from the artefact which he is designing. An example of the 
type of CAD system under consideration, and the one which principally motivated this study, is the MINNIE 
system for electronic circuit design (Spence &#38; Apperley, 1977). PREVIOUS WORK Despite the acknowledged 
importance of SRT effects (Hatvany et al, 1977; L.H. Miller, 1977; Sackman, 1968, 1975; R.B. Miller, 
1968) hard facts are few in number. Grossberg et al (1976) investigated problem solving with variable 
SRT's of fixed mean values. Their results seem to show that for the type of algebraic and matrix manipulation 
problems studied, mean SRT's of i, 4, 16, and 64 seconds had no effect on solution time. Foley &#38; 
Wallace (1974), also considering the psychological principles which might govern the design of SRT, advocated 
the idea of appropriate SRT, depending on whether user action initiating computer response fell into 
lexical, syntactic, or semantic categories, and suggested SRT's of 50 msec, 1 to 4 sec, and as much as 
iO secs, respectively, as being suitable values to aim at. Indeed, a semantic request such as the display 
of the minimal bond energy in a complex molecule could involve i0 seconds or more delay without the user 
losing his train of thought; in fact he would probably use the time to consider what to do with the result. 
 This conjecture would appear to be supported to some extent, over a large range of SRT's, by the results 
obtained by Grossberg et al. Corley &#38; Allen (1976), on the other hand, taking an information theoreti 
c approach to graphical interactive CAD, were of the opinion that consistency of SRT was what was needed 
by users, though any SRT variability should be assessed in the light of contextual expectancy in particular 
tasks. L.H. Miller's (1977) results on baud rate variability and performance tend to support the need 
for consistency, though the rate itself had no effect. EXPERIMENTAL MOTIVATION Our own experience of 
the possible bad effects of excessive SRT, together with the paucity of available information, led us 
to design an experiment to examine the effects of SRT on a multiparameter optimisation task simulating 
the heuristic adjustment approach common to many design activities. Solution time was used as the prime 
performance measure of practical interest. The Null Hypothesis was that there would be no effect on solution 
time caused by SRT. The Alternative Hypothesis was that significant and (in practical terms) large effects 
would be found. THE TASK Subjects were required to perform a multi- i00 parameter optimization task 
which consisted of adjusting a displayed graph* to lie wholly within a defined acceptance region (Fig. 
i) V//A ........  potentiometer i L EXlT ' ..... -J  Figure 1 Problem Display Initially the displayed 
graph intersected each of the three (cross-hatched) forbidden zones, and part of it lay within the clear 
solution region. The light-buttons numbered 1 to 5 represent the five parameters available for adjustment 
one at a time, each of which affects the form of the displayed graph. When selected with the light- pen, 
parameter buttons brighten to indicate that their value can be adjusted using the light-pen and the light 
potentiometer. The current value of the parameter selected is indicated by light arrow at the side of 
the light potentiometer. The exit button was used by subjects to stop the experiment when a solution 
had been obtained. To enhance the generality of any conclusions drawn from the experiment, the displayed 
graph was intentionally chosen not to be that describing the properties of an electrical circuit. The 
relation between the ordinate (y) and abscissa (x) values on the graph, in terms of the five parameters 
(Pl to p5 ) is y=pl+sin(4P2X + 1.5P3) + sin(8P4X + 1.5P5) The experiment was presented to subjects 
as an investigation into how people use computers, and no mention was made of System Response Time in 
the standard instructions given to all subjects. In the experiment, the SRT of interest was simulated 
by introducing a fixed delay between the selection of a new parameter value with the light- pen and 
the appearance of the new graph on the display. The values of SRT used in the experiment were 0.16, 0.72 
and 1.49 seconds. METHOD Subjects performed the task individually 3 times in immediate succession under 
a different SRT each time. They were instructed to try to finish the task reasonably quickly, and to 
make quite sure that the graph lay entirely inside the clear acceptance region before hitting the EXIT 
light button. The Eysenck Personality test was administered to each of the 18 undergraduate students 
after they had finished the 3rd attempt at solution. The three repetitions done by each subject formed 
the columns of a 3 x 3 Latin Square Crossover design (Cox, 1957; Cochran &#38; Cox, 1957; Williams 1949). 
 SUBJECTS The 30 volunteer subjects consisted of 18 undergraduate students, 6 postgraduate students 
and 6 staff of a university department of electrical engineering, and are a reasonably representative 
selection from a population which is likely to provide many users of highly- interactive CAD systems. 
 2500--2000-- ~, %%%% %% ", %% maximum 1" r-~ minimum 3" (~ mead T ~Z one standard deviation ~ ~_one 
standard error~ mean ~m 1~00--c 0 u E "~ 100C 50C 0.5 1.0 1.5 System response time, SRT secs. * The 
equipment used to generate the display and record data was a PDP-15 computer with VT-15 Figure 2 Solution 
Time (T) versus System interactive display and light-pen. Response Time (SRT) for 30 subjects. i01 
RESULTS  Fig. 2 shows various characteristics of the time to solution (T) as a function of SRT. Immediately 
obvious, and not unexpected, is the large range of T; also apparent is the substantially higher mean 
value of T for the highest SRT. Not obvious from the figure is the fact that, for a given individual, 
a low T at one value of SRT is not indicative of similar performance at other values. Fig. 3 shows the 
results of a pilot experiment using only 6 subjects and which suggested the use of a smaller maximum 
SRT in the main experiment. "i- maximum T minimum T 2=300 (~ mean T ~ one standard deviation .+ / 
 / s // ~DO0 / 10  E / SjSjfS~ T 8 s J s / i-/ se" s E f I r I .o I 1000 I 0 U~ I I I %  1 2 3 
System response time, SRT seconds Figure 3 Solution Time (T) plotted against SRT. Pilot experiment 
results, each mean resulting from 6 observations: 6 subjects used. An analysis of variance performed 
on the solution times showed that SRT had a very significant effect on T over the range studied. The 
effect was significant almost at the 1% level; in other words, the chances of the effect occurring due 
to random fluctuations in the experiment, even if there had been no real effect, is almost i00 to 1 against. 
No significant effects on Solution Time, T, due to learning or fatique or a combination thereof were 
detected over the three attempts at solution made by each subject. For the 18 undergraduate subjects, 
Fig. 4 shows the variation, with SRT, of what we have termed Elapsed Time T_L, being the difference 
between the total machine delay in any one attempt and the time-to-solution T. The appearance of there 
being no significant difference between the T E_ for the three SRT values is confirmed, at t~e 5% level, 
by analysis of variance. However, when the elapsed solution times (TEL) are analysed for the 18 undergraduate 
subjects by plotting them against period of attempt(i.e., the order of presentation of the 3 attempts 
to subjects) we obtain Fig. 5. Here, a greater TRL is required for solution in the first perio~ of presentation, 
than in the subsequent two. This effect was found to be significant at the 5% level by analysis of varianc~ 
 The correlations between the Eysenck personality measures and problem solving performance for the 18 
undergraduate subjects are given in the table. The correlations were not significant (at the 5% level). 
 Measure Correlated With Correlation Coefficient Pearson's r Extraversion] ~.1o Psychoticism -O.09 Neuroticism 
-O. 34 Using the 90 attempts made by the 30 subject~ a correlation of 0.82 (Pearson's r) was found between 
T and the number (N) of parameter selections (not parameter value selections) required to solution, this 
coefficient being significant at more than the 0.1% level. DISCUSSION OF RESULTS The alternative hypothesis 
-that SRT has a significant and large effect on time to solution (T) over the range studied -was strongly 
 A mean values  Z onestandard error of mean *-one standard 0 deviation  ~500 i i  ~400 i J 4~ r-.0 
300 --Zl 0 i  m 200 -i i i 10o tJJ I I % 0-5 1.0 1.~ System response time, SRT seconds Figure 4 Elapsed 
Solution Time (TEL) plotted against System Response Time (SRT) for 18 subjects  102 supported by the 
analysis of variance. The effect of SRT on T disclosed by this analysis was tested in two further ways; 
using a t-test with 3 means, and using Duncan's Multiple Means (Edwards, A.L., 1972) test on the first 
presentation only (a more powerful method of rejecting spuriously significant means). The t-test confirmed 
the result of the analysis of variance, but Duncan's test failed to confirm the result. However, the 
number of observations available for Duncan's test was only iO per mean, and the number of means tested, 
3, is the very bottom limit for which this test is designed. It seems reasonable to rely for the time 
being on the results of the analysis of variance as indicating a real difference due to SRT affecting 
 T. The longest SRT, 1.49 sec, produced on average a T about 30% larger than did the smaller two SRT's, 
a result which could be of practical significance if much multiparameter optimisation work was being 
undertaken. The relatively small difference in elapsed time (Fig 4) suggests that the effect of SRT 
may be on style of performance (although this has not been the main area examined by our study) rather 
than on the subject time required to solve the problem. As Fig. 5 taken in conjunction with Fig. 4 shows, 
the division of time between subject and computer varies greatly as between the first and subsequent 
attempts at solving the problem. At first, TEL , the elapsed solution time is larger. On the next two 
attempts, on average, TEL is smaller regardless of SRT, indicating that s~yle of performance is tending 
towards a more intensive interaction with the computer, in which it is waiting for input for less of 
the time. The strong correlation of 0.82 between T and N suggests that there is a characteristic rate 
of interaction defined by parameter selection, regardless of time taken to solve, but since the elapsed 
times do not differ much from one SRT to another, it would appear that in fact more interactions are 
required in the same subject time when solution time as a whole is longer. The task used in this experiment 
has a substantial component of visual/manual coordination skill required to use the light- pen rapidly 
and accurately. It is necessary to attend to the light potentiometer visually since it provides no tactile 
feedback whilst making adjustments, and hence only intermittent attention can be given to the graph, 
at least in the stages of initial kinaesthetic learning which will be necessary before familiarity with 
the light-pen allows a competent level of skill to be built up. Further work is required to determine 
if, in this case, it is the manual skill involved in light-pen use, and/or the shift in attention between 
curve and light potentiomenter which will occur in naive users, which interacts with SRT to produce an 
optimum level at about 1.0 seconds, below which there is little to be gained, using solution time as 
the performance measure. CONCLUSIONS In an interactive system of the type studied, worthwhile improvements 
in problem solving l i mean values + one standard error -of mean _+ one standard  deviation 500 -- 
400  i 300 v) _1 .tJ r-.0 0v) 20O 100 i 13 (:1. 0 t1 l2 I3 Period Figure 5 Elapsed Solution Time (TEL) 
plotted for the 18 subjects referred to in Fig. 4 against period of attempt at task. performance may 
be obtained by examining the effect of even a quite restricted range of SRT. However, the interpretation 
of experimental results is not straightforward and is likely to be highly task dependent, so that caution 
must be used in generalising from one type of task to another. ACKNOWLEDGEMENTS We are grateful to 
David Agnew, Jadwiga Dunn and Peter Verkroost for programming assistance. The research reported was supported 
by the U.K. Science Research Council and the Department of Electrical Engineering, Imperial College. 
 REFERENCES Cochran, W.G., Cox, G.M. 1957 Experimental Designs, John Wi~y Cox, D.R. 1958 Planning of 
Experiments, John Wiley Corley, M.R., 1976 'Pragmatic and Allan, J.J. Information Processing Aspects 
of Graphically Accessed Computer-  103 Aided Design', IEEE Trans, Sys. Man. Cyb., Vol SMC-6, No. 6, 
pp 434-439. 'Experimental Design in Psychological Research', 4th Edn, Holt, Rinehart and Winston, New 
York. 'The Art of Natural Graphic Man-Machine Conversation, Proc. IEEE, Vol 62, No 4, pp 462-471. 'An 
Experiment on Problem Solving with Delayed Compub~ Responses', IEEE Trans, Sy~ Man. Cyb., Vol SMC-6, 
No 4, pp 219-222. 'World Survey of Computer- Aided Design', Computer Aided Des., Vol 9, No 2, pp 79-98. 
 'A Study in Man-Machine Interaction', National Computer Conf. U.S.A., pp 409-421. 'Response Time in 
Man- Computer Conversational Transactions', Fall Joint Comp. Conf. U.S.A., pp 267- 277.  'Timesharing 
Versus Batch Processing: the experimental evidence', Spring Joint Comp. Conf. U.S.A. pp l-lO. 'Outlook 
for Man-Computer Symbiosis: Towards a General Theory of Man- Computer Problem Solving', Nato ASI Paper, 
Mati, Greece, September 1976. 'The Interactive-Graphic Man-Computer Dialogue in Computer-Aided Circuit 
Design', IEEE Trans. on Circuits and Systems, CAS- 24, 2, pp 49-61(February 1977). 'Experimental Designs 
for the Estimation of Residual Effects', Austr. J. Sc. Res. A, 2, 149-154.  Edwards, A.L. 1972 Foley, 
J.D. 1974 and Wallace,J.D. Grossberg, M., Wiesen, R.A. and Yntema,D.B. Hatvany, J., Newman,W.M., and 
Sabin,M.A. Miller, L.H. Miller, R.B. Sackman, H. Sackman, H. Spence, R. and Apperley,M.D.  Williams, 
E.J. 1949 1976 1977 1977 1968 1968 1976 1977   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807379</article_id>
		<sort_key>105</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[A sensor simulation and animation system]]></title>
		<page_from>105</page_from>
		<page_to>110</page_to>
		<doi_number>10.1145/800248.807379</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807379</url>
		<abstract>
			<par><![CDATA[<p>A shaded computer graphics system for sensor simulation and animation must possess extensive capabilities. Sensor simulation involves scenes that are viewed, environments that produce tones in the scenes, and sensors that image the scenes. Animation centers on image generation, but data input, motion specification, and tone specification routines are very important for an effective system.</p> <p>A unique system has been developed that models a variety of scenes, environments, and sensors. It possesses a balance of data input, motion and tone specification, and frame generation routines. The system possesses several user languages for data input. User defined sections of the scene can move. Visible, infrared, laser radar, and radar sensors have been modeled. The frame generator possesses advanced aliasing controls, textured shading, and a very fast list priority hidden surface algorithm. The system is used as a test bed for training simulators and sensor-based system simulation.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Animation]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Reflection modeling]]></kw>
			<kw><![CDATA[Sensor simulation]]></kw>
			<kw><![CDATA[Thermal modeling]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.4.8</cat_node>
				<descriptor>Sensor fusion</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.6.8</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10011310</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Simulation by animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010342</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Model development and analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010233</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Vision for robotics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P334091</person_id>
				<author_profile_id><![CDATA[81100561196]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Timothy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zimmerlin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Technology Service Corporation, Santa Monica, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P331571</person_id>
				<author_profile_id><![CDATA[81100650735]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stanley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Technology Service Corporation, Santa Monica, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334341</person_id>
				<author_profile_id><![CDATA[81100387718]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Warren]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stone]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Technology Service Corporation, Santa Monica, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Stathacopoulus, A. D., et. al. Review of mathematical models of air-to-ground target acquisition using TV and FLIR sensors. Contract N00123-75-C-0320, General Research Corporation, Santa Barbara, 1976.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807383</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Dungan, W., Stenger, T., and Sutty, G. Texture tile considerations for raster graphics. SIGGRAPH '78, 1978.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Torrance, K., and Sparrow, E. Theory of off-specular reflection from roughened surfaces. Journal of Opt. Soc. of Amer. 57, 9 (Sept. 1967), 1105-1114.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Maxwell, J., and Weiner, S. Polarized emittance (Volume 1): polarized bidirectional reflectance with Lambertian or Non-Lambertian diffuse components. Contract Report No. 154, Environmental Research Institute of Michigan, Ann Arbor, 1974.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Howell, N. Predicting average value scattering from smooth, corregated, or dielectric surfaces at radar or laser frequencies. IEEE-GAP 1978 International Symposium, 1978.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I., Sproull, R., and Schumacker, R. A characterization of ten hidden-surface algorithms. ACM Computing Surveys 6, 1 (March 1974), 1-55.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359869</ref_obj_id>
				<ref_obj_pid>359863</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Crow, F. C. The aliasing problem in computer generated shaded images. Comm. ACM 20, 11 (Nov. 1977), 799-805.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A SENSOR SIMULATION AND ANIMATION SYSTEM Timothy Zimmerlin John Stanley Warren Stone Technology Service 
Corporation Santa Monica, California ABSTRACT A shaded computer graphics system for sensor simu- lation 
and animation must possess extensive capabilities. Sensor simulation involves scenes that are viewed, 
environments that produce tones in the scenes, and sensors that image the scenes. Animation centers on 
image generation, but data input, motion specification, and tone specifi- cation routines are very important 
for an effective system. A unique system has been developed that models a variety of scenes, environments, 
and sensors. It possesses a balance of data input, motion and tone specification, and frame generation 
routines. The system possesses several user languages for data input. User defined sections of the scene 
can move. Visible, infrared, laser radar, and radar sensors have been modeled. The frame generator possesses 
advanced aliasing controls, textured shading, and a very fast list priority hidden surface algorithm. 
The system is used as a test bed for training simulators and sensor- based system simulation. KEY WORDS 
AND PHRASES: computer graphics, sensor simulation, animation, thermal modeling, reflection modeling. 
CR CATEGORIES: 8.1, 8.2, 5.12, 4.22 INTRODUCTION The design goals have centered on providing a single 
system to simulate any sensor, present or future, and any scene, outdoor or not. The design approach 
has been to model scenes independently of electromagnetic environments and sensors. The approach has 
also been to include user lan- guages to speed data input of the necessarily complicated model parameters. 
The overall philosophy was forged by experience: rely on powerful data structures, efficient frame genera- 
tion algorithms, and a modular software structure where a user selects sequences of basic routines. The 
Sensor/Animation System (SAS) includes a digi- tal data base and applications routines as blocked out 
in Fig. I. The data base and data base manage- ment system are the core of SAS. The modeled attributes 
of a set of scenes, environments, and sensors are stored here and passed to application routines. The 
application routines cluster around the data base. They are grouped by function into data input, motion 
specification, tone specifi- cation, and frame generation routines. The underlying models are presented 
now. Then, the four groups of routines are highlighted by their significant features. In trying to cover 
all of SAS, specifics have been ignored, but these are available in the general literature (see references 
here and in other papers). Instead, an overview of an advanced shaded graphics system is provided. BASIC 
MODELS A scene is composed of geometrical and tonal primi- tives which are the shape and shading elements 
composing the scene. In addition, electromagnetic models of reflection and emission provide the basis 
for specifying tones. Geometrical Model. The geometrical primitives are points, line segments, and planar 
polygonal-bounded surfaces. These extend the primitive shapes beyond most polygonal models, with a savings 
of up to lO percent in scene data base size and up to 20 percent in number of edges processed in a detailed 
scene model covering many square miles. A point can be a sphere, circle, or directional light. A line 
seg- ment can be a cylinder or a one sided tape (i.e., surface). A surface can be non-convex with mul- 
tiple holes. In addition to a shape, a primitive has a material type expressed in several parts as surface 
condition, surface cross-section, and visible band reflectivity. Surface conditions include painted, 
metallic painted, glazed, and bare. Surface cross-sections are the various structural cross-sections 
of walls, roofs, pavements, etc. Geometric primitives are collected into objects in a scene. An object 
is a locally coherent, dis- tinct feature composed of one or more primitives, with one or more level 
of detail (LOD) represen- tations. The object structure permits efficient tests of relevance and aliasing 
controls on the primitives within it. Underlying the use of object LOD's is the concept of detection, 
recognition, and identification ranges, hereafter called DRI ranges. Studies of sensors use DRI range 
measurements to evaluate performance (1). Viewing an unfamiliar 105 scene, an object is detected as 
a point or line segment when it subtends a pixel, recognized by its silhouette when it subtends 5 to 
IO pixels, and completely identified when its image subtends IO to 16 pixels. Objects are collected into 
assemblies. An assembly is the basic scale unit. It contains all LOD and masking priority information 
needed by the appli- cation routines. Tonal Model. Four different methods are used to apply a tone or 
intensity across a geometric pri- mitive, as determined by its feature code. They are constant shading, 
linearly varying (i.e., Gouraud) shading, textured shading, and range shading. Shading is distinct from 
the tone specification process which assigns an intensity based on an electromagnetic model. The shading 
method applies the previously assigned tones in a particular way across a surface. Texture has a major 
impact on the displayed surface, changing a plain, cartoonish surface into rich recognizable patterns. 
The texture technique is described else- where (2). Range shading is a special adaptation for range display 
active sensors. Range to each vertex is computed and inverted (i.e., I/Range). This new unit can be applied 
across a surface in constant increments on the display. The hyper- bolic nature of the perspective transformation 
dis- torts a planar surface so that range to the eye varies highly nonlinearly across the displayed surface. 
Electromagnetic Models. A Ray optics model of electromagnetic phenomena is used. This corres- ponds to 
almost all our common experience with visible and infrared wavelengths. Diffraction and surface wave 
phenomena, important in low frequency work and some high fidelity work, are not modeled. Polarization 
and phase cancelling can be incorporated to some extent in the model. Reflection. The simplest model 
of reflection is Lambertian (i.e., cosine law) diffuse reflec- tion. This is a constant radiance reflection 
over the hemisphere above the surface. Most shaded systems use this model. The next step is to add specular 
reflection so the model computes diffuse plus specular. Specular reflection can be modeled several ways. 
The standard way is to place the reflected ray at an angle equal to the angle of incidence. This specular 
model is a simplification of the more complex situation. Actually, each point on a surface reflects energy 
over the whole hemisphere above the surface, and each point can change the spectrum of the incident light. 
Some researchers have used a bi- directional reflection model based on Fresnel's law of reflection. This 
approach ignores local variations producing texture, but does deal with surface roughness, material conductivity, 
and dielectric constant. Torrance and Sparrow (3) seem to have first published the basic model. The Environmental 
Research Institute of Michigan (4) has generalized the model further. Al Howell (5), at Technology Service 
Corporation, has developed a new variation for active sensor models in SAS. Thermal Emission. Significant 
electromagnetic energy is radiated by all surfaces due to thermal emission. This forms the source of 
energy for infrared and radiometric passive sensors. An ide- ally emitting surface is called a blackbody. 
The spectrum of thermally emitted energy is related to blackbody temperature by Plank's Law. Radiation 
theory forms the basis for a thermal model for sensors of thermal radiation. Basi-cally, surface temperature 
at a frame time is computed; Plank's Law is integrated over the sensor band to obtain blackbody radiance; 
and, the black- body radiance is scaled down by the surface material's fractional emittance. The surface 
radiance is treated by the frame generation rou- tine just as radiance from reflected energy. An algorithm 
has been developed to compute surface temperature. It includes thermal memory and the environment's thermal 
paths to a surface. It involves a finite difference model that is con-structed for each material code. 
The architectural modeling of surface materials provides a framework to allow assignment of the finite 
difference models to surfaces. DATA INPUT SAS is equipped with three high level languages that allow 
the development of scene, environment, and material models. With the use of these languages, multi-sensor 
simulations can be conducted on com- mon models. This is possible because of the amount of relevant data 
stored about the scenes. SAS utilizes a set of complex data structures which are general enough to support 
the system require- ments placed upon them, so that whenever a new sensor is developed, it can be directly 
integrated into SAS without any time consuming modification of the models. Data Acquisition. The source 
material used to construct a model is a major factor in the quality of the final simulation. For this 
reason, the languages employed by SAS allow for data acquisi- tion from a variety of source material 
such as maps, blueprints, photographs, atmospheric measurements, sun locations and material cross-sections. 
The prime consideration in the ongoing development of SAS's modeling languages is to utilize as much 
useful data as possible. Figure 2 is a flow dia- gram showing the process used to create a scene model. 
Model Representation. Each scene model is totally independent of other models. They are controlled by 
a Master Index File which contains the linkages to their geometric, environmental, and material components. 
All these components are stored in a segmented ring structure. The geometric component of the model is 
by far the most complex component. It is divided into three sections: the Assembly Header List which 
controls range level processing and masking priority, the levels of detail which are geometric descriptions 
of the scene of varying resolution (from coarsest to finest), and the Subassemblies which contain 106 
 the actual geometric primitives. Points, line segments, solid planar surfaces, translucent planar surfaces, 
and planar surfaces with holes are all contained in the list of valid geometric primitives supported 
by SAS. The ability to add texture and shadows to already existing models is also supported. The environmental 
component is divided into two sections, the Environment Segment Record, which is used as a bookkeeping 
area (each data segment contains one), and the "At-time" Description Subrecords. Each subrecord can best 
be described as statistics about the environment at one instant. Each environment describes an electromagnetic 
and thermal volume surrounding a scene. The volume may simulate indoor, outdoor, or space conditions. 
The last component in the scene model is the ma- terial component. It is also divided into two sections 
and is similar to the environment com- ponent. The first section is the Material Segment Record which 
is also a bookkeeping area and the Material Description Subrecords. Each subrecord is in effect a behavioral 
description of a single material. In a complex situation, up to several hundred of these subrecords may 
have to be de- fined, one for each different type of material contained in the simulation. By breaking 
the scene models into these three basic components, SAS can mix components from any one model with those 
of any other model. Therefore, cross simulation between scene models can easily be performed. Figure 
3 is a flow diagram of the data schema used for the SAS scene models. TONE SPECIFICATION AND MOTION The 
sensors modeled are visible band, 1.06 micron laser, forward looking infrared, I0.6 micron laser, 3.2 
mm radar, and range radar sensors. When a user calls up a version of TONE (see Fig. ]), he specifies 
one of these sensor models. Each sensor produces its own effects on a scene. Figure 4 pre- sents several 
sensor modeled frames of the same scene, called the Hughes, Culver City, DDB. Texture is produced in 
a frame generation rou- tine by varying intensity of surface points about the computed average shade. 
Active Sensors. The active sensors are 1.06 micron laser, I0.6 micron laser, 3.2 mm radar, and ranging 
radar. The first three sensors present received intensity and the fourth pre- sents range. Each uses 
a scanning electro- magnetic beam to illuminate the scene one pixel at a time. This results in a monostatic 
reflection situation (i.e., both source and receiver are at the same location). This means that energy 
is reflected back to the receiver at the angle of incidence so that no shadows form. The only significant 
multiple reflections occur where two or three surfaces join together at right angles. The reflection 
model is a general bidirectional reflection developed by Howell (5). Passive Sensors. The passive sensors 
include both reflection and thermal emission models. The re- flection model is significantly less detailed 
for passive sensors because the illumination situation is considerably more complicated. The reflection 
model is diffuse at preseot, but will include diffuse plus simple specular reflection, with spreading 
and softening of the projected specular near its edges. This model allows direct and diffuse solar, diffuse 
sky, diffuse ground background, and other scene surface radiation sources for reflected energy. Shadow 
casting is performed in one version of tone specification. The thermal emission model is as described 
in the basic model section. The major computation is for the exterior temperature of each surface. This 
requires a finite difference model of each surface and a model of environmental thermal paths. Motion 
Specification. SAS permits a flexible approach to motion dynamics. At present, a user must write a new 
motion routine for each motion, but graphics tablet inputs will be used to drive a general motion routine. 
SAS needs a motion speci- fication language to provide users the dynamics that SAS supports. FRAME GENERATION 
Each SAS frame generator uses a powerful algorithm based on inherent masking priority, aliasing con- 
trols, and spatial coherence. Frame generation is here discussed along these issues. The Hidden Surface 
Problem. SAS uses a list prio-rity algorithm to solve the hidden surface problem (6). The set of all 
assemblies in a scene are sorted into masking priority based on eye position relative to masking priority 
planes defined among the assemblies. The subassemblies in each assembly are sorted by masking priority 
planes described in the assembly. The set of geometric primitives in a subassembly have already been 
listed in an inherent or constant masking priority list of elements when first stored. This solves the 
hidden surface pro- blem in three distinct steps, with each subassembly list computed only once at assembly 
construction time. Motion dynamics may require the redefinition of masking planes among assemblies or 
even the re- definition of two or more assemblies for some frames. This occurs rarely in present applications 
but happens relatively more often in animation. At some point, the present method may be generalized 
to recompute masking priority of special assemblies for each frame. This would apply only to a small 
fraction of a scene's assemblies in any case. Aliasin 9 Control. Alia~ing refers here to the mis- representation 
of a function, hence aliasing of information (7). Aliasing is sometimes represented in the frequency 
domain as a shifting of high fre- guancies down to lower frequencies. The full charac-terization of aliasing 
is based on the more general concept of functional representation and recon- struction. TSC has determined 
that for CRT displays, a pyramidal function centered on a pixel and ex- tending to the center of adjacent 
pixels is a good approximation to the optimal Gaussian point response function. The frame generation 
routine oversamples each pixe] and then sums the samples in the neigh- borhood of each pixel according 
to weights assigned by the pyramid point response function. This technique reduces aliased intensity 
to around 5 or lO percent maximum at any point and much less on the average. 107 A second aliasing control 
technique is the use of multiple object LOD representations. The appro; priate LOD is based on range, 
so that displayed surface size is maintained above the sampling interval. Use of Coherence. In order 
to save computation, use is made of statistical knowledge about a scene and display. There is spatial 
coherence in a scene so that grouping of geometric ele- ments into objects and assemblies saves compu- 
tation. For example, finding, fetching, de-termining relevance to a frame, displaying correct LOD, assigning 
motion are operations that proceed much more efficiently at assembly and object levels rather than at 
a geometric pri- mitive level. On a display, raster-to-raster coherence is used to provide an initial 
sort of edges from left to right along an observed raster. SAS uses a list priority, raster-oriented 
algorithm with filtering. SUMMARY This paper presents a system for shaded computer image generation, 
incorporating advanced CIG meth- ods. The major applications are training, sensor design and use studies, 
computer aided design, simulation of physical processes, and commercial animation. At present, grey and 
color scale visible, infrared, laser, and radar sensors have been simulated using several scenes and 
environ- ments. This system ultimately generates images of a user described scene and environment as 
viewed through a sensor described by the user. This approach is easy to use, flexible, and ex- tendable 
in terms of simulation complexity. The data structures are powerful; there are a variety of sensor models; 
and there are tools to construct large data bases. COMPUTER SAS SYSTEM FACILITIES ! ' D--ATA EDITOR 
INPUT | I"~TEXT ! I ! *DDL Data D I +DDB = Digital Data Base The division of the data base into scene, 
environ- ment, and sensor data structures provides flexi- bility. The choice of geometric and tonal primitives 
provides both powerful modeling tools and efficient algorithms. The list priority sort solves the hidden 
surface problem unambiguously and efficiently resolves visible parts of sur-faces. The total models of 
reflection and thermal emission, with shadowing, provide realism. Tex-tured shading (2) produces real 
textures across surfaces. Ultimately, user languages provide ease of data input and output, ease of reading 
data, and checks of data accuracy for effective use of SAS. REFERENCES I. Stathacopoulus, A. D., et. 
al. Review of mathe- matical models of air-to-ground target acquisi- tion using TV and FLIR sensors. 
Contract N00123- 75-C-0320, General Research Corporation, Santa Barbara, 1976. 2. Dungan, W., Stenger, 
T., and Sutty, G. Texture tile considerations for raster graphics. SIGGRAPH '78, 1978. 3. Torrance, 
K., and Sparrow, E. Theory of off- specular reflection from roughened surfaces. Journal of Opt. Soc. 
of Amer. 57, 9 (Sept.  i967)', 1105-1114. 4. Maxwell, J., and Weiner, S. Polarized emittance (Volume 
l): polarized bidirectional reflec-tance with Lambertian or Non-Lambertian diffuse components. Contract 
Report No. 154, Environ- mental Research Institute of Michigan, Ann Arbor, 1974. 5. Howell, N. Predicting 
average value scattering from smooth, corregated, or dielectric surfaces at radar or laser frequencies. 
IEEE-GAP 1978 International Symposium, 1978. 6. Sutherland, I., Sproull, R., and Schumacker, R. A characterization 
of ten hidden-surface algorithms. ACM Computing Surveys 6, 1 (March 1974), 1-55. 7. Crow, F. C. The 
aliasing problem in computer generated shaded images. Comm. ACM 20, II (Nov. 1977), 799-805.  FILTER 
FR _i CRT -I  DISPLAY -- DECODE 1 Figure I. The Sensor/Animation System 108 GEOMETRICSOURCE ENVIRONMENTSOURCE 
MATERIALSOURCE e Maps Blueprints e Photos e Digitized Data  Topographic Data  I I GEOMETRIC DESCRIPTION 
LANGUAGE DATASEGMENT ~ NI Figure 2. L LOD INDEX I SEGMENT ASSEMBLYA LOD 1 SUBASSEMBLIES ASSEMBLYA LOD 
2 SUBASSEMBLIES ASSEMBLYB LOD 2 SUBASSE]qBLIES MASTERINDEX FILE J t I. EM_L~__NT | MATERIAL ENVIRONMENTSEGMENT 
RECORD1 AT TIME 1 AT TIME 2 AT TIME 3 AT TIME 4 tl MATERIALSEGMENT RECORD1 MATERIAL 1 MATERIAL 2 MATERIAL37 
MATERIAL43 Figure 3. Time of Day Material Type e Sun Position Interior Condition e Direct Sun Radiance 
e Solar Absorp- o Diffuse Sun tlvltles Radiance (N,E,S,W e Sensor Band Emis-m Sky Temperature sivity 
 GroundTemperature o Ground/Sky  GroundCondition Absorptivity  Air Temperature m Time Increment  Wind 
Vector e LC ~trix  Precipitation Rage e QC Matrix e Precipitation Temp. Capacity Vector  I SAS TRANSLATIONI 
SYSTEMS I I MATERIAL DESCRIPTION DESCRIPTION ENVIRONMENT I LANGUAGE LANGUAGE I MATERIAL ] INDEX FILE 
 DATASEGMENTN2 ~° "" ~ DATASEGMENT NN ~-J Model Development Stages LOD 3 LOD 3 SUBASSEMBLIES SUBASSI~BLIES 
ASSEMBLYR ASSEMBLYR LOD 1 .I SUBASSEMBLIES ASSEMBLYG LOD 1 ,m- SUBASSEMBLIES ENVIRONMENTSEGMENT ENVIRONMENTSEGMENT 
RECORD2 RECORDN AT TIME 5 AT TIME 93 AT TIME 6 AT TIME 7 AT TIME 8 MATERIALSEGMENT RECORDN MATERIALZ6 
MATERIALMATEN,ALMATER,At322,23 :~'~: ~TERIAL lg~ECoRDSE~ENT  Data Schema for Scene Models 109   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807380</article_id>
		<sort_key>111</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[How to color in a coloring book]]></title>
		<page_from>111</page_from>
		<page_to>116</page_to>
		<doi_number>10.1145/800248.807380</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807380</url>
		<abstract>
			<par><![CDATA[<p>Children's coloring books contain line drawings which a child can fill in with a crayon to produce colored pictures. Two dimensional colored areas can be produced on a raster display by an analogous method. After drawing a closed curve with line drawing commands, the graphics system can fill the area bordered by the curve. This paper presents an algorithm for filling in areas of any size or shape. The area may be filled with any color, texture, or &#8220;wallpaper&#8221; pattern. The algorithm is simple, flexible and efficient, optimized to take advantage of the the memory organization of most current raster graphics systems.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Shading (or filling, flooding) closed curves raster graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP40025428</person_id>
				<author_profile_id><![CDATA[81100262805]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Henry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lieberman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Artificial Intelligence Laboratory, Massachusetts Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>804735</ref_obj_id>
				<ref_obj_pid>800143</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Lieberman, H., The TV Turtle: A Logo Graphics System for Raster Displays, ACM SigGraph/SigPlan Graphics Languages Symposium, April 1976]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Goldstein, I., Lieberman, H., Bochner, H., Miller, M., LLogo: An Implementation of Logo in Lisp, Logo memo II, MIT Artificial Intelligence Lab, March 1975]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Kahn, K., Lieberman, H., Computer Animation: Snow White's Dream Machine, Technology Review, October 1977]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Reynolds, C., A Multiprocess Approach to Computer Animation, MIT Master's Thesis, August 1975]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Moon, D. A., MacLisp Reference Manual, MIT Laboratory for Computer Science (formerly Project Mac)]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Learning Research Group, Personal Dynamic Media, Xerox Palo Alto Research Center technical report]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Negroponte, N., Raster Scan Approaches to Computer Graphics, Computer Graphics, Vol. 2, No. 3]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 How To Color In A Coloring Book Henry Lieberman Artificial Intelligence Laboratory. Massachusetts Institute 
of Technology CR Category: 8.2 (Computer Graphics) Keywords: Shading (or filling, flooding) closed curves 
raster graphics Abstract Children's coloring books contain line drawings which a child can fill in with 
a crayon to produce colored pictures. Two dimensional colored areas can be produced on a raster display 
by an analogous method. After drawing a closed curve with line drawing commands, the graphics system 
can fill the area bordered by the curve. This paper presents an algorithm for filling in areas of any 
size or shape. The area may be filled with any color, texture, or "wallpaper" pattern. The algorithm 
is simple, flexible and efficient, optimized to take advantage of the the memory organization of most 
current raster graphics systems~ 1. Introduction For years, the predominance of vector displays for computer 
graphics has limited computer generated pictures to drawings consisting solely of lines and points. Now, 
the development of raster displays allows pictures containing two dimensional solid and textured areas. 
What are good ways of describing regions of various sizes, shapes"and colors to the computer? This paper 
explores one answer to this question. The computer's display screen can be treated like a child's coloring 
booh. The coloring book supplies line drawings indicating the borders of areas to be filled in The child 
takes a crayon, picks a place in the interior of an area, and fills it in by continually expanding the 
colored area until it hits the boundary lines between areas. Most currently available computer graphics 
systems provide a wide range of facilities for making line drawings. These can be used to draw the outlines 
of regions to be filled in. The graphics system can be extended with a primitive called ,SHADE (FLOOD 
in some systems), which is given an interior point, and fills in the ~rea. A "crayon" of any color may 
be chosen, or textures, shading or wallpaper patterns may be used to fill the area in instead of a solid 
color. (See Figure [I] -Figure [2].) This provides a conceptually simple and flexible means of creating 
and manipulating two dimensional areas. The program doesn't have to know. the size or shape of the region 
in advance. Since it searches the screen to fincl the extent of Figure [l] Figure [2] Here's a simple 
example of the shading program at work. We start out with a line drawing of Snoopy, similar to the kind 
of drawing that might appear in a child's coloring book. We tell the system which area we want to fill 
by picking a point with the graphics cursor. A shading pattern tells the system how to fill the area. 
In this example, Snoopy's body is filled with diagonal lines, his" hat and scarf with random points, 
his arm with vertical lines. the area, it is not tied to a particular representation for the region's 
boundary. The outline of the region may be produced by a line drawing program, hand drawn by an artist 
using a tablet or other graphic input device, or taken from a photograph or television picture. This 
is a popular operation in "paint" programs, which allow a user to input line drawings on a tablet, outlining 
areas, and have the computer paint b~ number, filling in each area with a paint of a chosen color. Here's 
another way of thinking about the problem: Consider the task of building a robot vacuum cleaner. The 
robot should be able to vacuum a room of any size or shape, containing furniture or other obstacles. 
It should make sure to clean every spot on the floor, without getting stuck by hitting the walls or furniture. 
It must also avoid getting into an infinite loop cleaning the same spot over and over again, and must 
be able to tell when it is finished. Since computer vision systems are expensive and difficult to build, 
and the robot should be simple and cheap, a further restriction will be imposed that the robot will be 
blind -it won't have a TV camera to watch for obstacles. Instead, Jt will be equipped with touch sensors, 
so it will be able to detect when it hits something or brushes up against it. It can only tell whether 
there's an obstacle adjacent to it in front or on the side. Given these constraints, the procedure presented 
in this paper will enable the robot vacuum cleaner to efficiently get the job done. 9.. Description of 
the Algorithm The shad!ng process starts out with a point known to be in the interior of the figure to 
be shaded. (Of course, the process should not depend upo n which initial point is chosen.) The procedure 
determines the extent of the figure by continually e~camining points adjacent to known interior points. 
If a point adjacent to an interior pcdnt isthe same color as .the interior, it can also be considered 
an Interior point. If a color change is noted, then that point is part of' the boundary of the region. 
In what order shall the points on the screen be examined? This choice is crucial to the efficiency ~f 
the .resulting procedure. One possibility is to spiral out from the initial point, looking at points 
at ever increasing distance from the initial point. Another might be to have some procedure for following 
the boundary of a figure. ,Since the screen memory in most raster graphics systems is organized into 
words, where the memory representing, several horizontally adjacent points occupies a single word, the 
scan for the boundary of the figure should be made horizontall~ as much as possible. It is often the 
case that several points which are horizontally adjacent may be read or written ,with a single memory 
operation, whereas manipulation of points on separate lines may require a separate memory operation for 
each point. Further, the choice of using horizontal scans minimizes the amount of state information the 
procedure must maintain to keep track of what parts of the fig~Jre It has already covered. The result 
of scanning horizontally can be represented as the let~ and right X values and one Y value, rather than 
a list of points chosen in some arbitrary order. The procedure, then, will be built up out of horizontal 
Scans. Each scan starts at an interior point, looking to the left until a color change indicating the 
boundary of the figure has been reached, then looking to the right until the scan hits the boundary. 
This will yield a set of horizontally adjacent points known to lie entirely within the boundary of the 
.figure. Those points can be shaded by applying the' shading pattern. Let's consider what the shading 
procedure must do wnen it is moving from one .line to the next. The procedure mustnow scan vertically, 
picking a new interior point adjacent to the previously shaded line on the line above or below, and performing 
a horizontal scan from that point. ]f there are no such points, if all points adjacen t to the previously 
shaded line are boundary points, then it is an indication that the top or bottom of the region has been 
reached. The boundary then completely encloses the. area shaded, and the job has been completed. A simple 
figure such as a square or a circle could be shaded by starting two vertical scans from the initial point~ 
After performing a horizontal scan, the procedure would move up to the next line, continuing until the 
top of the figure was reached. It would return to the initial point, then shade downward to the bottom 
of the 'figure. However, this simple method would fail to work for more complex figures Figure [3] Figure 
[4] The next group of figures shows some of the control structure of the shading process as it fills 
a region. The picture consists of a large circle, with a hole in the middle and an overlapping circle 
at the bottom. The procedure must, of course, avoid shading inside the hole, and must shade around the 
overlapping circle. The procedure scans horizontally on each line, to the left and right until the boundary 
of the area is reached, then displays the shading pattern. It then moves down to the next line and continues. 
Eventually, it encounters the top of the overlapping circle. It continues down tt~e left side of the 
circle, but remembers that it has to return later and complete the right side. It saves an imaginary 
beundory llne from the top of the circle to the right side of the area on an agenda list. The imaginary 
boundary line allows the procedure to pretend that it .has already completed the area to the right of 
the small circle. Fig, ure [5] Figure [6] Upon completing the area to the left of the small circle, the 
procedure returns to the agenda list to see if anything more remains to be ~completed. it finds that 
both the right side of the circle and the area above the initial point need to be shaded. It picks the 
one going downward, as it always prefers to continue in the same direction as the last vertical scan. 
Now, the only task left is filling the area above the initial point. ~ The procedure proceeds upward, 
to the left of the hole. Two imaginary boundary lines are now placed on the agenda, one going upward 
from the bottom of the hole, one going downward from the top. At this point, the program can't tell that 
they would both attempt to cover the same area! Figure [7] F!gure [8] When the top of the large circle 
is reached, it slarts shading upward from the bo|lom of lhe hole. After finishing one horizontal line, 
it always checks to see if it hits an imaginary boundary line before moving up or down to the next line. 
Thus, the procedure will hit the line from the top of the hole. When that happens, the vertical scan 
is stopped, and the line with which it collided is also removed. Now, all of the figure has been shaded. 
There are no more lines left on the agenda, so the procedure stops. containing concave portions. If we 
tried to shade a U-shaped figure starting from the bottom, the procedure would go up one branch, and 
ignore the other one! After shadinga line, the procedure must then cover aN interior points adjacent 
to that line. Instead of stopping afte[ one horizontal scan, it must examine all points adjacent lo the 
shaded line, possibly yielding several more lines to be shaded, rather than just one. Further, after 
shading the new line, all points on the old line adjacent to the newly shaded line must be examined as 
well. If the new line is longer, there may be interior points adjacent to the new line, but separated 
horizontally from the old line by boundary points. The new interior points on the old line should start 
another vertical scan going in the opposite direction from the scan that discovered them, so these are 
called U-turns. The new points adjacent to the previously shaded line initiate anew scan in the same 
direction, and are called S-turns. If the system allows parallel processing, a new vertical scanning 
process can be started for each new line found. On a serial machine, one of the lines must be chosen 
to continue the current vertical .scanning process (by convention, we choose the leftmost line). The 
program then remembers the other lines on an agenda list, as a reminder that it must do another vertical 
scan. At the conclusion of the current scan, the agenda is checked to see if anything more remains to 
be done, and the program loops until the agenda has emptied. There's just one more problem to worry abou.~: 
What it the figure has a hole in it? As described'so far, the procedure would just keep circling around 
and around the hole forever! The process must therefore have some method for keeping -track of what areas 
of the screen it has already covered, and .~op whenever it retraces its footsteps. If we were limiting 
the program to shading in an area with a solid color, there would be no problem, as previously shaded 
arears would provide a barrier which would stop any other scan running into them. Allowing arbitrary 
patterns means, that the procedure cannot use the screen to record such information, Expensive solutions 
such as keeping an auxiliary array to record which points have been shaded are out of the question. If 
we think about all the vertical scanning processes running in parallel, the agenda represents a list 
of leading edges of-the scans as they proceed to shade more and more of the figure. The shaded area grows 
by shading new lines adjacent to previously shaded areas. We can recognize that the area shaded is always 
completely enclosed by the boundary of the figure, the current line being shaded and the lines on the 
agenda. Thus,. it is sufficient merely to check if the scan is colliding, with a line on the agenda to 
prevent it from shading an area already covered. The lines on the agenda serve as imagZnczry bourtdar~lines 
and stop the progress of the search as do.the real boundary lines of the figure. Once the process collides 
with an imaginary boundary line, the imaginary boundary is removed from the agenda, so that it will not 
start another scan itself. To minimize searching and comparisons, it is convenient to keep the agenda 
in the form of two lists, one of scans to be performed in the upward direction and one for downward scans. 
Each list is kept ordered by Y value, upward.scans from top to bottom, downward from bottom to top. The 
top level procedure, then, starts out with an agenda containing an upward scan and a downwarcl scan start!ng 
from the initial point. Each of the vertical scans might result. in other scans being added to the agenda, 
in both directions. The top level procedure does all t.he scans in one direction at. a time, then reverses 
direction and chooses scans.from the other list. Each time, the procedure chooses the highest scan if 
it is going upward (or lowest one if' it is proceeding downward). This insures that it is only necessary 
to check against the list of scans going in the opposite direction. That list is ordered in the direction 
of the current scan so 0nly the remainder of that list which lies beyond the current point need by checked. 
When both iist~; have been. exhausted, t'he region has been completely shaded, and the procedure is finished. 
3. Proof of the Shading Procedure Can we be .sure that the shading procedure act.,ally performs as intended? 
What follows is an informal sketch of:a proof that the procedure outlined above has the desired result. 
First, it is necessary to check that the ~hading procedure shades only points which lie in the interior 
of t-he figure. This is true sin.ce the procedure starts out at a point known to be in the interior of 
the figure, and at each step, only shades points which are not boundary points, and which are adjacent 
to points already known to be interior points. 1"  [] Interior points [] Boundary points [] hnaglnary 
boundary points [] Shaded points [] Scan in direction of arrow Figure [9] The next group of illustrations 
will show the operation of the shading procedure in more detail, down to the level of moving from point 
to point on the screen. Individual points (or pizel~) will be represented by one of five different types 
of boxes. Points in the interior of the figure will be shown as blank boxes. Boundary points, those of 
a different color surrounding the figure will be shown with cross-hatching. The points will start out 
as either interior points or boundary points. As the shading procedure passes over a point, it will either 
shade the point (which will then appear as a box with diagonal lines), or consider it as an im./~i..ry 
ho~n~.ry point (shown with dots). Imaginary boundary points are placed on an e~e.nde list to be shaded 
later. The current point being scanned is indicated by a box with an arrow pointing in the direction 
of the scan. I~ I I I I I-'1 I I I I~ Figure [10] We start shading a line of interior points, with two 
boundary points at either end. The scan starts rightward from the first point. IIII I~-";T/~-'~I "" ~ 
Figure [11] Points are shaded until the boundary point is reached. Figure [12] The scan then proceeds 
leftward from the initial point until the left boundary is reached. Figure [13] Figure [14] We will assume 
that the scan is proceeding vertically upward. A new point on the line above is chosen, the leftmost 
interior point adjacent to the previously shaded line.  ~//j;,-/i//2"/t,'/ip'//p'////t~'////J~l Figure 
[1.5] The horizontal scan continues shading to the left until a boundary point is reached. Now, the scan 
continues past the boundary, looking at points adjacent to the previously shaded line, since these are 
also part of the interior of the area. Figure [16] The procedure will defer shading these points until 
later. A notation is made on the ,gend, list that a new scanning process must be initiated shading upward 
from those points. This is called an S-turn, since the new process will shade in the same vertical direction 
as the one which discovered it. The points are marked as imaginary boztn~ary points. Any other scan which 
tries to shade past them will be stopped, since the area below has already been shaded. They stop the 
progress of the shading procedure as do the real boundary lines of the area. 1" 1" ~;/~,¢~::."I;:."..L:.:.~:::.+L::.'..L::.'..L::.'..I~ 
Figure [17] Another S-turn has been found. Now, the procedure shades points on the lower line which 
are adjacent to shaded points on the upper line, as these are also part of the interior. These start 
a new vertical scan going downward. Since these reverse the vertical direction of the scan which discovered 
them, they are called U-turns. Figure [18] A third line is now started, beginning from the leftmost 
interior point adjacent to the second line shaded. Figure [19] Two situations can terminate a vertical 
scan. If, after shading a line, every point adjacent to the line is found to be a boundary point, then 
the top or bottom of the figure has been reached and the vertical scan stops. Figure [20] If every point 
adjacent to the shaded line is an imaginary boundary point, this indicates that the region on the other 
side of the imaginary boundary has already been shaded earlier in the process. This situation arises 
when shading around holes in the area. There's nothing left for the vertical scan to do, so it stops. 
The imaginary boundary is also removed from the agenda, since it would normally start a new vertical 
scan downward, but this is no longer necessary. The procedure must be verified to shade all of the interior 
points. Suppose there's some point which has been missed by the shading procedure but is still inside 
the region. It must be adjacent to some point which has been shaded. We will show that this cannot occur, 
that if a point has been shaded, every interior point adjacent to it must also have been shaded. Each 
point, P, has four neighbors in the raster grid, one on each side horizontally, one on the line above 
and one below. Since each horizontal scan starts out on a leftmost interior point and proceeds rightward, 
the horizontal neighbors of P must be shaded if P h~s been. Consider the neighbor of P on the line above, 
its upstairs neigttbor. If there is no boundary "point between the start of the. horizontal scan on that 
line and P's upstairs neighbor, then the horizontal scan will cover it. But if there is, the part of 
~he shading procedure which detects turns will detect this situation and put a new scan on the agenda 
which will cover P's upstairs neighbor (in this case an S-turn, if we take the vertical scan to be going 
upward). A similar argument will show that the downstairs neighbor of P will be covered by a U-turn. 
The procedure never retraces a point which it has already shaded. This is true because the following 
property remains ino(lri(znt during the execution of the program. At all times, the area shaded by the 
procedure is completely botJnded by the boundary of the figure, the imaginary boundary lines on the agenda, 
and the line currently being scanned~ The procedure is designed so that it stops whenever th.e scan hits 
the boundary of the figure, or an imaginary boundary line, so the scan can never break through a real 
or imaginary boundary to retrace part of the area it has already covered. Finally, the procedure must 
be shown to terminate. Since it continually shades more and more points, never retracing a point that 
it has already shaded, and the number of mteriQr points is finite, the procedure eventually stops. 4. 
Shading Patterns How does the shading procedure decide what to display on the screen to fill the area 
once it's discovered where the boundary lies? The set of directions for filling the area, the shading 
pattern, is itself a procedure, to afford flexibility in choosing different methods of shading. The system 
supplies a small predefined set of patterns, which are usually sufficient for common uses of the shading 
feature to distinguish visually between several neighboring regions, like countries on a map. These patterns 
include solid, colors, horizontal, vertical and diagonal lines, and crosshatching. An interesting texture 
effect is created by turning on randoml~ chosen points within the area. Saved pictures, containing any 
mixture of lines, points, text, or other areas, may also be used as shading pattprns. The pictures are 
normally stored by the system as bit arrays or using run length encoding (called windows in [I]). If 
the region to be filled is larger than the saved picture, the picture is repeated "wallpaper" style as 
necessary. If the region is smaller than the boundary, it is clipped against the boundary of the figure. 
The ability to clip a picture against an arbitrary boundary is an operation .which is often useful in 
its own right. Alternatively, the user may provide his or her own function to do any specialized computation. 
For example, it might.be desired to check the distance of a point from a light source before deciding 
on the brightness of the point. The shading pattern function accepts coordinates on the screen, and is 
responsible for updating the display. Rather than apply the shading function once for each point, it 
is called to shade a whole line instead, to take advantage of the fact that accessing points horizontally 
is especially efficient. A further area of experimentation would be to create higher level means of specifying 
shading patterns, which would not b~ so closely tied to the coordinates of the place being shaded.. 5. 
Implementation The shading program is part of the TV Turtle, a graphics system for raster displays developed 
by the author and described in [I] and [2]. It is implemented in MacLisp [5] on the PDP 10, and can be 
used either from Lisp or our Lisp implementation of Logo. Implementations of a shading procedure for 
raster displays have also been developed at the MIT Architecture Machine Group, shown in [3], Xerox PARC 
[6], and several others, but details of the operation of these systems have not been previously published 
in the literature to my knowledge. For previous work concerned with the. somewhat different problem of 
shading a figure whose boundary is given by a vector display list, (which also forms the basis fqr many 
hidden surface algorithms) see [4]. We now present a sketch of an implementation of the algorithm. (Names 
of important functions and variables are capitalized.) Define SHADE: * The arguments to SHADE are: R 
The ORIGIN, an Interior point to start shading from, and * A SHADING-PATTERN to fill the area. * Let 
INTERIOR-COLOR be the color of the ORIGIN. Set the VERTICAL-DIRECTION to be UP.  * INITIALIZE-THE-AGENDA. 
Repeat until the agenda Is empty In both directions:  Vertical Shading Loop: * If f The agenda In the 
current VERTICAL-DIRECTION is empty, then * Switch directions.  * Choose a vertical scan from the agenda. 
 * SHADE-VERTICALLY in the  current VERTICAL-DIRECTION. End Vertical Shading Loop. Define INITIALIZE-THE-AGENDA: 
Enter a scan starting UPward from the ORIGIN. * Enter a scan starting DOWNward from the ORIGIN. 115 
Define SHADE-VERTICALLY: The arguments to SHADE-VERTICALLY are: * A VERTICAL-DIRECTION, either UP or 
DOWN, and * A. startlng POINT from which to begin shadlng. * Repeat until * either * All points adjacent 
to the previously shaded line are boundary points,  or * All such points are contained in lines on the 
agenda. Horizontal Shading Loop: * SHADE-HORIZONTALLY from the POINT. *' LOOK-FOR-TURNS.  * Move the 
POINT up or down,  In the current VERTICAL-DIRECTION." End Horizontal Shading Loop. Define SHADE-HORIZONTALLY: 
* Start at a POINT, known as an interior point. * Look at successive points to'the'LEFT until a color 
change occurs, indlcattng the boundary has been reached. * Look RIGHT until the boundary is encountered. 
 * Remember the points where the boundary was found as LEFT-BOUNDARY and RIGHT-BOUNDARY. * F111 in the 
SHADING-PATTERN on the line between the boundaries.  Define LOOK;FOR-TURNS: * LOOK-FOR-S-TURNS. * LOOK-FOR-U-TURNS. 
 Define LOOK-FOR-S-TURNS: If * There are interlor points on the new line adjacent to the previously 
shaded line, then * Add these as to the agenda a new imaginary boundary line, starting a scan going In 
the current VERTICAL-DIRECTION. Define LOOK-FOR-U-TURNS: * If * There are interior points on the previous 
line adjacent to the newly shaded line, then * Add them to the agenda as an imaginary boundary line 
going In the opposite direction to the current VERTICAL-DIRECTION. draft of this paper and discovered, 
an important bug in a previous version of the algorithm. Carl Hewjtt, Bruce Edwards, Ron Lebel, Gerhard 
Fischer, Andy Di Sessa and others at the MIT AI Lab and MIT Architecture Machine Group also deserve thanks. 
Bibliography. [I] Liebermanl H., The TV Turtle: A Logo Graphics Syste m for Raster Displays , ACM SigOraphlSigPlan 
Graphics Languages Symposium, April 1976 [2] Goldstein, I., Lieberman, H., Bochner, H., Miller, M., LLoKo: 
An Implementation of Logo in Lisp, Logo memo II, MIT Artificial Intelligence Lab,.March 1975 [3] Kahn, 
K., Lieberman, H., Computer Animation: Snow White's Dream Machine, Technology Review, October 19.7"/- 
"" [4] Reynolds, C., A Multiprocess Approach to Computer Animation, MIT Master's Thesis, August 1975 
[5] Moon, D. A., MacLisp Reference Manual, MIT Laboratory for Computer Science (formerly Project Mac) 
[6] Learning Research Group, Personal Dynamic. Media, Xerox Palo Alto Research Center technical report 
[7] Negroponte, N., Raster Scan Approaches to Computer.. Graphics, Computer Graphics, Vol. 2, No. 3 Acknowledgment 
s would like tO thank Ken Kahn for many stimulating discussions and helpful ideas. Ken has had a major 
influence on my thinking about graphics, and as a user of my graphics system, has put some of my ideas 
to a pracUcal test. Hal Abelson made insightful comments' on an.earlier 116  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807381</article_id>
		<sort_key>117</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[A microprocessor display controller for combining refresh and storage tube graphics]]></title>
		<page_from>117</page_from>
		<page_to>124</page_to>
		<doi_number>10.1145/800248.807381</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807381</url>
		<abstract>
			<par><![CDATA[<p>This paper describes a stand alone graphics system utilizing a microprocessor based display controller with the capability of combining refresh with storage tube graphics. This combination is accomplished by utilizing the Write-Thru feature of a Tektronix 4014 display terminal. The display controller is a typical Z-80 microprocessor system interfaced to the 4014 by a standard Tektronix parallel interface. A portion of the Z-80 memory is used as the display buffer, allowing it to be divided into store and non-store (refreshed) segments. The microprocessor performs the conversion from the simple integer X, Y coordinates in the display buffer to actual Tektronix drawing commands. A second Z-80 microprocessor is used to perform graphical transformations and transfer the data from the PDP-11 host to the Z-80 display controller. The operations performed by the second microprocessor include translation, rotation and scaling. These operations are implemented by matrix multiplication of the user data by a user specified transformation matrix. The stand alone capabilities of the graphics system is made complete with interactive devices such as a tablet, analog dials, and function switches interfaced directly to the host computer.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Microprocessor display controller]]></kw>
			<kw><![CDATA[Refresh display]]></kw>
			<kw><![CDATA[Storage tube display]]></kw>
			<kw><![CDATA[Vector graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Graphics processors</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010389</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics processors</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P333857</person_id>
				<author_profile_id><![CDATA[81100347503]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Satterfield]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Aided Design and Interactive Graphics Group, Division of Engineering and Weapons, Annapolis, Md.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31094176</person_id>
				<author_profile_id><![CDATA[81406599257]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Francisco]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rodriguez]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Aided Design and Interactive Graphics Group, Division of Engineering and Weapons, Annapolis, Md.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39030986</person_id>
				<author_profile_id><![CDATA[81100174598]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Rogers]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Aided Design and Interactive Graphics Group, Division of Engineering and Weapons, Annapolis, Md.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>63448</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Rogers, D. F., and Adams, J. A., Mathematical Elements for Computer Graphics, McGraw Hill Book Company, New York, 1976.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M., and Sproul, R., Principles of Interactive Computer Graphics, McGraw Hill Book Company, New York, 1971.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Grover, D., "Hardware for Visual Information", Computer Aided Design, volume 9, number 4, October, 1977.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[4014 Computer Display Terminal Users Guide, Tektronix, Inc., Beaverton, Oregon, 1974.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Display Buffer Instruction Manual, CM018-0109-00, Tektronix, Inc., Beaverton, Oregon, 1975.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Basil, M., "A Microprocessor Based Refreshing Buffer for Storage Tube Graphics Terminals", Computers and Graphics, volume 9, pp. 205-208.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563278</ref_obj_id>
				<ref_obj_pid>965143</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Thanhouser, Ned, "Intermixing Refresh and Direct View Storage Graphics", Computer Graphics, volume 10, number 2, Proceedings of SIGRAPH '76.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[PDP-11 Peripherals Handbook, Digital Equipment corporation, Maynard, Massachusetts, 1976.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Z-80 Technical Manual, Zilog, Inc., Cupertino, California, 1977.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Z80-MCB Hardware User's Guide, Zilog, Inc., Cupertino, California, 1977.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[4014 MOD 941Z Parallel Interface, Tektronix, Inc., Beaverton, Oregon, 1975.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Z80-PIO Technical Manual, Zilog, Inc., Cupertino, California, 1977.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[TRW LSI Multiplier-Accumulator Technical Description, Model: TDC1003J, TRW LSI Products, Redondo Beach, California, 1977.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Z80-CTC Product Specification, Zilog, Inc., Cupertino, California, 1977.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A Microprocessor Display Controller for Combining Refresh and Storage Tube Graphics Steven G. Satterfield 
 Francisco Rodriguez David F. Rogers Computer Aided Design and Interactive Graphics Group Division 
of Engineering and Weapons Annapolis, Md. 21402 ABSTRACT This paper describes a stand alone graphics 
system utilizing a microprocessor based display controller with the capability of combining refresh with 
storage tube graphics. This combination is accomplished by utilizing the Write-Thru feature of a Tektronix 
4014 display terminal. The display controller is a typical Z-80 microprocessor system interfaced to the 
4014 by a standard Tektronix parallel interface. A portion of the Z-80 memory is used as the display 
buffer, allowing it to be divided into store and non-store (refreshed) segments. The microprocessor performs 
the conversion from the simple integer X,Y coordinates in the display buffer to actual Tektronix drawing 
commands. A second Z-80 microprocessor is used to perform graphical transformations and transfer the 
data from the PDP-11 host to the Z-80 display controller. The operations performed by the second microprocessor 
include translation, rotation and scaling. These operations are implemented by matrix multiplication 
of the user data by a user specified transformation matrix. The stand alone capabilities of the graphics 
system is made complete with interactive devices such as a tablet, analog dials, and function switches 
interfaced directly to the host computer. Key words: Refresh Display, Storage Tube Display, Microprocessor 
Display Controller, Vector Graphics CR Classifications: 6.22, 8.2 I. Introduction Two types of CRT 
(cathode ray tube) devices for calligraphic or line drawing graphics are the storage tube and the refresh 
display tube. Traditionally, these displays have been separate devices each having their own particular 
advantages and disadvantages. Complete discussions of these and other graphical display devices may be 
found in references I, 2 and 3. However, it is possible to combine the two types of graphics into a single 
system utilizing a feature of the storage tube known as Write-Thru. Normally, graphics drawn on a storage 
tube display remains visible until the entire screen is erased. Write-Thru is a display option tha£ prevents 
vector storage while not disturbing the previously stored information. To make Write-Thru mode graphics 
visible requires that the data be "refreshed' or repeatedly re-drawn. Thus a graphics system can be developed 
that has the high density graphics capability of a storage tube and the dynamic motion capability of 
a refresh display. This paper describes a stand alone graphics system with Write-Thru capability developed 
by combining a general purpose mini-computer, two microprocessors, and a storage tube display. Interactive 
devices Providing various forms of user input are interfaced to the host mini-computer to complete the 
stand alone capabilities. The intended use for the refresh/storage (R/S) graphics system is applications 
involving a limited amount of refresh 117 graphics overlaying a fixed (store mode) background. II. 
Background The Tektronix 4014 display terminal (ref. 4) is a large screen (approximately 14 inches by 
10 inches) storage tube with Write-Thru capability. The 4014 has sufficient Write-Thru capacity to justify 
its use in applications that normally require a refresh display. The specific capabilities of the 4014 
Write-Thru mode are discussed in section IV of this paper. This section will discuss previous methods 
of combining refresh and storage tube graphics utilizing the 4014 display terminal and why an alternative 
approach has been taken. Tektronix offers an optional display buffer (ref. 5) that will allow the local 
storage and retrieval of 1024 characters sent to the terminal from a host computer. This buffer allows 
graphics data to be sent to the terminal at a slow rate, stored locally and then repeatedly displayed 
at the terminal's maximum writing speed. This capability is most useful for Write-Thru graphics in a 
timesharing environment where a dedicated computer is not available to maintain the required refresh 
rate. Since the control of the display buffer is by special characters from the host computer, the utility 
of the Tektronix display buffer is for graphics output. A paper by Basil (ref. 6) describes a scheme 
for adding a microprocessor to the internal hardware of the Tektronix 4014. The microprocessor thus adds 
local intelligence to the terminal for controlling Write-Thru graphics. This modified terminal is also 
used in a timeshared environment and provides capabilities similar to the optional Tektronix buffer. 
An additional capability provided by the microprocessor is to display characters entered by the keyboard 
in Write-Thru mode. This feature is useful in a timeshared environment since the storage tube display 
does not become cluttered with the dialogue between user and program. A third approach to combining 
 refresh and storage tube graphics is the Tektronix 4081. This graphics system differs from the two 
previous approaches because it is a completely integrated stand alone system utilizing a mini-computer 
to run the application program. The hardware and software design of the 4081 is described in reference 
7. The display tube used by the 4081 is a variation of the 4014 using Write-Thru to achieve the desired 
 refresh capability. The actual refreshing is done by a special purpose display controller that shares 
a portion of the mini-computer's memory for display list storage. The function of the Computer Aided 
Design and Interactive Graphics group at the U. S. Naval Academy is to provide technical support to midshipmen 
and faculty members in the areas of computer graphics and computer aided design. This support includes 
both hardware and software develonment. The hardware facilities include several storage tube displays 
driven from a timesharing system, a stand alone mini-computer driven refresh graphics system with graphical 
transformation hardware and a large flat bed plotter. The choice for acquiring additional refresh graphics 
capabilities was affected by the following guidelines: I) The desire to combine both storage tube and 
refresh graphics into a single system, 2) The desire for a stand alone system for maximum refresh performance, 
 3) The desire for comDatability with existing mini-computers, 4) The desire for a system that would 
allow future expansion and modification. The Tektronix 4081 comes closest by meeting two of the guidelines. 
The existing computers maintained by CADIG are Digital Equipment Corporation PDP-11's which are not used 
in the 4081. Since the 4081 is a fully integrated system, it would not be easily adapted to any future 
expansion or modification. Therefore, it was decided to build a graphics system utilizing a PDP-11 host, 
a Tektronix 4014 as a display and a microprocessor based display processor. III. A Functional Hardware 
Description .Figure I shows a block diagram of the R/S graphics system hardware components and interfaces. 
The hardware of the system may be categorized into the following three groups: I) The mini-computer 
host and associated peripherals, 2) The microprocessor display controller and storage tube display, 
 3) The microprocessor matrix multiplier and direct memory access (DMA) interface from the host mini-computer. 
 The host mini-computer may be any Digital Equipment Corporation PDP-11 118 R/S GRAPHICS SYSTEM BLOCK 
DIAGRAM EXPANSION BOX SWITCHES LIGHTS DIALS TABLET  I INTERFACE iii I MATRIXI I OISPLAYI TEKTRONI~ 
  l INTERFiCE MULTIPLIER PROCESSOR 4014 l I I I FIGURE I UNIBUS configuration. The specific configuration 
used is a PDP-11/34 with 32K words memory, two RKO5 disk drives and a Decwriter. The integrity of the 
computer system from a maintenance point of view is achieved by placing all interfaces in a standard 
expansion box which is connected to the PDP-I] through a single UNIBUS cable. Thus the expansion box 
provides a logical extension to the PDP-11 and a mechanical framework for hardware development. The 
interactive peripherals consisting of a digitizing tablet, control dials, function switches and function 
lights are also part of the host functional group since they are interfaced directly to the PDP-II. The 
function lights and switches simply consist of a set of sixteen lights representing sixteen bits of output 
data and a set of sixteen switches representing sixteen bits of input data. This set of input and output 
data is made available to the PDP-11 by a standard DR-11C parallel interface (ref. 8) from Digital Equipment 
Corporation. Eight control dials are interfaced to the PDF-II through an analog/digital converter. The 
dials generate a binary number that increases positively until it wraps around to most negative then 
continues to increase. Finally an eleven inch digitizing tablet surface with pen and control box are 
interfaced to the PDP-11 with a third parallel interface. The purpose of the host PDP-11 is to provide 
the tYDical capabilities of graphics aDPlication proKramming. It also provides control of the interactive 
peripherals at the user software level and master control of the DMA interface for passin~ graphical 
data to the display. The common uses for the interactive devices follow: I) Dials -Rotation, scaling, 
and translation. 2) Switches -Initiating/terminatin~ program action and entering any YES/NO type of 
input. 3) Lights -Reflecting the current state of the corresponding switch position. 4) Tablet and 
pen -X,Y digitizing, menu selection and cursor control. A Z-80 microprocessor system (ref. 9 and 10) 
is used for the display processor. This Z-80 system may be further broken down into a set of smaller 
hardware components as shown below: I) Z-80 CPU microprocessor, 2) PROM -permanent storage for control 
Drogram, 119 3) RAM -read/write memory for control program data and the display buffer, 4) Real time 
clock -refresh interval timer, 5) Input/output ports -hardware interfacing.  The purpose of this Z-80 
display processor is to transfer the graphical data from the display buffer to the Tektronix display 
screen. This transfer process requires that the Z-80 perform a conversion from the simple binary data 
of the display buffer to the special drawing codes required by the 4014. The display processor (Z-80) 
is also responsible for refreshing the data drawn in Write-Thru mode. The Z-80 and the 4014 communicate 
through a Z-80 I/O port connected to an optional Tektronix parallel interface (ref. 11). As previously 
discussed, the 4014 is a large screen storage tube display with Write-Thru capability. The particular 
4014 used has an optional enhanced graphics module that expands the normal screen resolution of 1024 
by 1024 to 4096 by 4096. Other features provided by this option include a point plot mode and a hardware 
dashed line mode. The matrix multiplier is implemented with a second Z-80 microprocessor connected between 
the DMA interface and the display processor. A standard DR11-B (ref. 8) from Digital Equipment Corp. 
is used as the DMA interface. The purpose of the matrix processor is to perform graphical transformations 
on the data as it is passed to the display processor. These graphical transformations are implemented 
by multiplying the user data by a user specified transformation matrix. References I and 2 have complete 
discussions concerning the application of matrix operations to perform graphical transformations. Both 
the matrix multiplier and the display processor are discussed further in Section V. IV. Limitations 
of Write-Thru T ...... ~--m ....  The number of possible refreshed vectors using the Write-Thru mode 
of the Tektronix terminal is determined by the following three factors: I) The rate at which the interface 
can operate, 2) A hardware limitation within the 4014 of 10,000 centimeters per second, 3) The rate 
at which the display controller can generate and output the 4014 display codes. The first limitation 
is an important factor in the more typical circumstances of connecting the 4014 to a host computer through 
a serial interface. The baud rate (bits per second) of serial communications usually limits the number 
of characters and graphics codes significantly. However, the parallel interface used in the R/S graphics 
system allows eight bit codes required by the 4014 to be directly transferred without the delay of a 
parallel-to- serial and then serial-to-parallel conversion. By also providing certain handshaking signals, 
the interface effectively allows direct communication to the internal electronics of the 4014 terminal. 
Consequently, the interface speed is not a limitation in the R/S graphics system implementation. The 
I0,000 centimeters per second limitation of the 4014 vector generation hardware must be accepted. Therefore, 
to gain full usefulness of the Write-Thru mode, the display controller must be able to generate and output 
the 4014 drawing codes at a rate approaching this limitation. Since the display controller used in the 
R/S graphics system is a Z-80 microprocessor, the speed of the display controller is dependent upon the 
Z-80 programming and the particular type of hardware used. The R/S implementation uses a Z-80 CPU chip 
having a clock rate of 2.5 megahertz (Mz). This clock rate yields a basic clock time (T cycle) of .4 
microseconds. Each Z-80 machine instruction has a specific number of T cycles (basic clock time) required 
for complete execution. Therefore, the speed of the Z-80 display controller is the sum of all T cycles 
required by the set of Z-80 instructions used to generate and transfer the 4014 display codes. A straight 
forward scheme which gets a binary number from the display buffer, converts it to 4014 codes, and then 
transfers it to the 4014 reauires approximately 330 T cycles. Thus the maximum number of vectors per 
second is 7575. A stable, flicker free picture drawn in Write-Thru mode requires that the picture be 
refreshed at least 30 times per second. So the Z-80 display controller has the capacity for generating 
stable Write-Thru mode picture containing 252 vectors at a refresh rate of 30 frames per second. For 
comparison purposes, if the I0,000 centimeter limitation is that also divided by 30, then the vector 
generator limit becomes 333 centimeters of non-flickering vectors. Since the time required by the Z-80 
display processor to convert the display buffer data to Tektronix graphics commands is independent of 
vector length, it is difficult to precisely compare the display processor rate with the vector  120 
 generator rate. However, the implication of the comparison is the the Z-80 can fully utilize the 4014 
capabilities if the average length of the vectors drawn is greater than 1.3 centimeters (333/252=1.3). 
 The above figures for the capabilities of the Z-80 display controller can be improved significantly 
by utilizing faster hardware. Z-80 hardware is available with a 4.0 Mz system clock which is approximately 
twice the speed of the Z-80 hardware previously discussed. V. Matrix and Display Processors Figure 
2 is a more detailed diagram showing the connections and various components of the matrix multiplier 
and the display processor. The mechanism for interconnecting the PDP-11, the 4014 and the two microprocessors 
is with the Z-80 parallel input output (PIO) port (ref.12). This technique allows each processor to independently 
perform its task. The primary task of the matrix multiplier is to apply graphical transformation in 
the form of matrix multiplications. The number of individual multiplications required for a matrix multiplication 
cannot be handled by a Z-80 alone. So a special 12 bit multiplier-accumulator chip (ref. 13) is added 
to the Z-80 matrix processor. The ability of the chip to perform a multiplication and to accumulate the 
results makes it well suited for matrix multiplication. The function of the associated Z-80 is to simply 
replace hard logic for moving the data between the PDP-11, the multiplier-accumulator chip and the other 
Z-80. In order to reduce the number of I/O operations, the multiplier-accumulator chip has access to 
data directly from the DMA interface. Thus the Z-80 can get data either directly from the DMA interface 
 (unchanged) or by way of the multiplier-accumulator chip (transformed). This data is then either 
passed along to the display or cycled back through the multiplier-accumulator chip to continue a matrix 
multiplication. The task of the display processor  Z-80 is to cycle through its display buffer, drawing 
refresh mode graphics or any new store mode graphics. Both store mode and Write-Thru mode data are 
stored in the display buffer providing a complete record of the visible graphics independent of the 
host computer. The display buffer is actually part of the Z-SO memory which allows it to be easily 
 manipulated and accessed. It is logically separated into a double buffer scheme that allows one buffer 
to be written into while the other buffer is drawn. Data is stored into the displav buffer on an interrupt 
basis by a PIO interrupt service routine. This allows the display processor to freely cycle through the 
current refresh buffer while filling the other buffer with transformed data passed bv the matrix processor. 
The PIO interrupt service routine also performs certain functions such as start/stop buffer cycling, 
switch the current display buffer and read the current display buffer back to the host. The display 
buffer is also logically segmented into refresh and store mode segments. The refresh segments are continually 
re-drawn by the Z-80 microprocessor in Write-Thru mode. The store mode segments are also saved in the 
display buffer, but are drawn only once when initially generated. Using this segmentation scheme allows 
a display to be composed of several logical segments such that only changing segments need to be re-generated 
 (transferred from host). This concept of segmentation is useful in store mode graphics in that after 
a complete screen erase, all the store mode segments can be automatically re-drawn by the Z-80 without 
the attention of the PDP-11 host. Using a fixed display buffer does provide a disadvantage for applications 
 requiring more store mode vectors than the buffer will hold. To relieve this problem a bypass mode 
is used where once the graphical data in a segment of the display is output to the display screen, 
 the segment is released to accept other graphical data. This mode is equivalent to the repeated re-generation 
of a store mode segment without an intermediate screen erase. VI. Software Overview The software 
of the R/S graphics system falls into three categories consisting of the PDP-11 user routines, Z-80 
matrix multiplier program, and the Z-80 display controller program. Each of these categories will be 
discussed in the following paragraphs. The PDP-11 software provides the lowest level of user interface 
to the R/S graphics system. This interface is a set of efficient user callable routines to perform 
the various system functions. These routines fall into the five following groups: I) Interactive peripheral 
routines, 2) Graphicsdisplay routines, 121  MATRIX MULTIPLIER AND DISPLAY PROCESSOR A .,, %.  e.~ 
PDP-ll U3 ms OMA --, INTERFACE   tNULTIPLIER~ F-~~ I ~' q_JINTERACTIVE  ,2 eITS I-l |PERIPHERALS 
' I i HOST COMPUTER MATRIX PROCESSOR ' I DISPLAY PROCESSOR FIGURE 2 Since the Z-80 is a Keneral  3) 
Display buffer segmentation routines, purpose microprocessor, it must contain a program to perform the 
desired 4) Display buffer control routines, function. Each of the Z-80 microprocessors contain their 
 5) Matrix processor control routines. corresponding Drograms stored permanently in read only memory 
such The interactive peripheral  that execution begins when power is routines allow the user program 
to read applied. This technique is often  appropriate values from the digitizing referred to as "firmware" 
since it tablet, analog control dials, and the effectively reduces the ~eneral purpose function switches. 
Visible graphics microprocessor to a specific hardware such as vectors, dots, and text are controller. 
 produced with the graphics display The firmware associated with the routines. The display routines 
also Z-80 matrix processor controls the flow include the ability to set dash line of data through 
the Z-80 system to mode and set blink mode for refresh type perform the matrix multiplication. The 
 graphics. The display buffer  following list summarizes the operations segmentation allows the user 
program to performed by the Z-80 system:  configure the display buffer into the desired number of store 
mode and refresh I) Pass data from the DMA interface to mode segments. These routines also the display 
processor,  provide for subsequent re-generation and deletion of existing segments. Display 2) Control 
the data path through the buffer control routines are used to multiplier-accumulator to effect a request 
the display processor to switch matrix multiplication,  the display buffer and to request that the 
current display buffer be 3) Load a new transformation matrix from transferred back to the PDP-11. 
The the DMA interface,  matrix processor control routines are used to specify the graphical data 4) 
Concatenate a matrix from the DMA manipulation to be performed by the interface with the current  
matrix processor. These routines are transformation,  used prior to the graphics output routine to 
transfer a desired matrix to 5) Save the current transformation the matrix multiplier. matrix. 122 
 6) Restore a previous transformation matrix. The provision to pass data unchanged is necessary to 
allow the host to communicate directly to the display processor or to pass control information. Display 
list control words must be passed unchanged to organize the display buffer into a list of moves and draws 
to form the picture. ASCII data must be passed unchanged to allow the 4014 to display text. Also, commands 
to the display processor such as to read the display buffer back to the host and set the refresh rate 
must be passed. The transformation matrix to be applied to the user data is loaded from the DMA interface 
under the control of the Z-80 firmware. This transformation matrix may either replace the existing matrix 
or be concatenated with the existing matrix. This concatenation capability allows complex transformations 
to be built from a series of simpler matrices. Finally, the ability of the firmware to save and restore 
a transformation is implemented in firmware as a push-down~pop-up stack. A matrix stack pointer is used 
within the firmware to point to the current transformation. The firmware associated with the Z-80 display 
processor is separated into two parts. The first part is the display list cycling routine that interprets 
the current display list to produce the visible graphics. The second part is the PIO interrupt service 
routine that receives data passed from the matrix and fills the alternate display buffer. Graphical 
data is stored in the display buffer as a list of command codes and associated values. The command codes 
determine what the Z-80 does as it cycles through the current display list. The command codes indicate 
actions such as draw a vector, move to a point, display text, erase the screen (store mode), and wait 
for the next refresh interval. In order to avoid flicker of the Write-Thru mode graphics, the refresh 
segments of the current display buffer must be drawn at least 30 times per second. The real time clock 
(a Zilog CTC, ref. 14) of the Z-80 system is used to determine the passage of each refresh interval. 
The drawing of the refresh segments is given highest priority. To provide time for drawing the store 
mode segments and to provide a consistent brightness of Write-Thru mode graphics, a display wait command 
code is used. When the display processor finds this command in the refresh segment, it suspends drawing 
of Write-Thru mode graphics until the next refresh interval controlled by the CTC. During this off time 
the store mode segments are output to the 4014. This displav wait controls the display intensity by maintaining 
a constant cycle time independent of the segment length. VII. Conclusion This paper has described the 
design of a stand alone graphics system that has the capability of combining storage tube graphics with 
refresh graphics. This capability becomes very useful for applications involving a small amount of dynamic 
motion (refresh) overlaying fixed (storage) background graphics. The feasibility of using microprocessors 
as a mechanism for distributing the tasks of an interactive system has been shown. Also, the use of generally 
available hardware provides a foundation for future development, including the adaptation to other host 
mini-computers. VIII. References  I. Rogers, D. F., and Adams, J. A., Mathematical Elements for Computer 
  ~p--6"-f~'~T-i~F~-~i"I'~-E6'o--"~-~panv, New York, 1976. 2. Newman, W. M., and Sproul, R., Principles 
of Interactive Computer Graphics, McGraw Hill Book-Company, New ~, 1971.  3. Grover, D., "Hardware for 
Visual Information", Computer Aided Design, volume 9, number 4, October, 1977.  4. 4014 Computer Display 
Terminal Users Guide, Tektronix, Inc., Beaverton, O-regon, 1974.  5. Display Buffer Instruction Manual, 
CMO18-0109-O0, T@ktronix, inc~, Beaverton, Oregon, 1975.  6. Basil, M., "A Microprocessor Based Refreshing 
Buffer for Storage Tube Graphics Terminals', Computers and Graphics, volume 9, pp. 205-208.  7. Thanhouser, 
Ned, "Intermixing Refresh and Direct View Storage Graphics ~', Computer Graphic@ volume 10, number 2, 
Proceedings of SIGRAPH '76.  8. PDP-11 Peripherals Handbook , Digital Equipment corporation, Maynard, 
Massachusetts, 1976.  9- Z-80 Technical Manual, Zilog, Inc., Cupertino, California, 1977.  123 10. 
Z80-MCB Hardware User's Guide, Zilog, Inc., Cupertino, California, 1977.  11. 4014 MOD 941Z Parallel 
Interface, Tektronix, Inc., Beaverton, Oregon, 1975.  12. ZSOTP~IO_Tecehn~£a~_Manua!, Zilog, Inc., Cupertino, 
California, 1977.  13. TRW LSI Multiplier-Accumulator Technical Description, Model: TDCIO03J, TRW LSI 
Products, Redondo Beach, California, 1977.  14. ZSO-CTC Product Specification, Zilog, Inc.,Cupertino, 
Califo~6i&#38;, 1977.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807382</article_id>
		<sort_key>125</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[A fast and economic scan-to-line-conversion algorithm]]></title>
		<page_from>125</page_from>
		<page_to>129</page_to>
		<doi_number>10.1145/800248.807382</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807382</url>
		<abstract>
			<par><![CDATA[<p>In order to generate cartographic data bases, it is necessary to digitize a large number of existing base maps. One way of replacing the error-prone and very time-consuming manual digitization by an automatic method is scanning the map and extracting the linework from the resulting binary matrix. A sufficiently fast and economic scan-to-line-conversion algorithm has to be developed for the line extraction.</p> <p>The algorithm presented operates with a skeletonization technique which is further developed from known line thinning methods, so that the scan lines are now skeletonized in a single pass and that only a small number of scan lines has to be held in core storage. The result of this process is equivalent to a multi-pass skeletonization which utilizes a quasi-parallel line thinning in four partitions of the binary matrix for each pass.</p> <p>The data produced by the extraction algorithm following the skeletonization have two important advantages over data produced by manual digitization: First, the nodes corresponding to the line end points are exactly determined and, second, the correction phase is shortened since the automatic process is less error-prone.</p> <p>Time and storage requirements of the implemented algorithm applied to some typical scan data show that the conversion for even a complex line structure can be carried out within the time of scanning and the economic use of core storage makes it possible to implement the algorithm on a minicomputer with an on-line scanner.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Automatic digitization]]></kw>
			<kw><![CDATA[Line following]]></kw>
			<kw><![CDATA[Pattern recognition]]></kw>
			<kw><![CDATA[Raster scanning]]></kw>
			<kw><![CDATA[Scan-to-line-conversion]]></kw>
			<kw><![CDATA[Skeletonization]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Digitizing and scanning</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.1</cat_node>
				<descriptor>Cartography</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10010479</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Cartography</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010506</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Document scanning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P96786</person_id>
				<author_profile_id><![CDATA[81100406547]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gerd]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Woetzel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Gesellschaft f&#252;r Mathematik und Datenverarbeitung (GMD), D-5205 St. Augustin 1, West-Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1138376</ref_obj_id>
				<ref_obj_pid>563732</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Boyle,A.R., The present status of automated cartography. Computer Graphics (ACM-Siggraph), 9(1975), pp.260-266]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Gray,S.B., Local properties of binary images in two dimensions. IEEE Trans. Computers C-20(1971), pp. 551-561]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Kansy,K., Capture and encoding of area-oriented geographic maps. To appear in: the 3 rd Jerusalem Conference on Information Technology (JCIT) 1978.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Klein,K.H., Kreifelts,Th., Pick,K., Woetzel,G., Erfahrungen mit der Digitalisierung von rasterm&#228;&#223;ig erfa&#223;ten Linienstrukturen II. GMD-Mitteilungen Nr. 37, St.Augustin,West Germany,1976.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Kreifelts,Th., Pick,K., Wisskirchen,P., Woetzel,G., Erfahrungen mit der Digitalisierung von rasterm&#228;&#223;ig erfa&#223;ten Linienstrukturen I. GMD-Mitteilungen Nr. 30, St.Augustin, West-Germany,1974.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kreifelts,Th., Woetzel,G., Extraktion von Linienmustern aus Bin&#228;rbildern. To appear in: Kazmierczak,H.(ed), Maschinelle Bildverarbeitung, Springer Heidelberg-Berlin-New York.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>321644</ref_obj_id>
				<ref_obj_pid>321637</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Mylopoulos,J.P., Pavlidis,T., On the topological properties of quantized spaces I. J.ACM 18 (1971) pp.239-246.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>321570</ref_obj_id>
				<ref_obj_pid>321556</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Rosenfeld,A., Connectivity in digital pictures. J.ACM 17(1970), pp.146-160.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Tomlison,R.F.,(ed.),Geographical Data Handling. Int.Geographical Union Second Symposium on Geographical Information Systems, Ottawa,Canada, 1972.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Woetzel,G.,Linien- und Knotenextraktion aus Rasterbildern, GMD-Mitteilungen Nr. 44, St.Augustin, West-Germany,1978.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A FAST AND ECONOMIC SCAN-TO-LINE-CONVERSION ALGORITHM Gerd Woetzel Gesellschaft fHr Mathematik und 
Datenverarbeitung (GMD) D-5205 St. Augustin 1 West-Germany ABSTRACT In order to generate cartographic 
data bases, it is necessary to digitize a large number of existing base maps. One way of replacing 
the error-prone and very time- consuming manual digitization by an automa- tic method is scanning the 
map and extract- ing the linework from the resulting binary matrix. A sufficiently fast and economic 
 scan-to-line-conversion algorithm has to be developed for the line extraction. The algorithm presented 
operates with a skeletonization technique which is further developed from known line thinning methods, 
so that the scan lines are now skeletonized in a single pass and that only a small number of scan lines 
has to be held in core storage. The result of this process is equivalent to a multi-pass skeletonizat- 
ion which utilizes a quasi-parallel line thinning in four partitions of the binary matrix for each pass. 
 The data produced by the extraction algorithm following the skeletonization have two important advantages 
over data produced by manual digitization: First, the nodes corresponding to the line end points are 
exactly determined and, second, the correction phase is shortened since the automatic process is less 
error-prone. Time and storage requirements of the im- plemented algorithm applied to some typi- cal 
scan data show that the conversion for even a complex line structure can be carried out within the 
time of scanning and the economic use of core storage makes it possible to implement the algorithm 
on a minicomputer with an on-line scanner. KEY WORDS AND PHRASES: automatic digiti- zation, raster 
scanning, skeletonization, scan-to-line-converslon, line following, pattern recognition. CR CATEGORIES: 
3.14, 3.63. INTRODUCTION In order to generate cartographic data bases, it is often necessary to digitize 
a large number of existing base maps, i.e. to code the line structure of a map in coordinate form. Conventionally 
this is done by manually following the lines on a digitizer. This process is error-prone and very time 
consuming, especially with irregularly shaped lines. One way of replacing manual digitization by an 
automatic method is scanning a map and extracting the linework from the re- sulting binary matrix. The 
problem here is to develop a sufficiently fast and economic scan-to-line-conversion algorithm. Such an 
algorithm is to encode the various lines and nodes in the map as lists of line and node coordinates. 
The nodes are relevant for reconstructing the global connectivity of the line structure. In addition, 
this facilitates the generation of polygons in land use maps and the detection of errors in contour maps. 
 In the past, various scan-to-line-convers- ion algorithms have been developed (see e.g. chapters 6,7 
and 16 of (9)). Most of them are similar to the one described in this paper in that they apply local 
image transformations prior to the actual line extraction. The advantage of our algo- rithms shows in 
the quality of its results which is due to the application of a skeletonization technique, and in the 
swiftness of its operation. A comparison between the different scan-to-line-con- version algorithms is 
difficult because the necessary information is not readily found in the literature. SUMMARY OF THE ALGORITHM 
 The method we have developed divides up into three processes which are applied to consecutive scan 
lines (Fig.l). I. The scan lines coming from a scanner tape or from an on-line scanner are read in by 
a skeletonization program. They are prepared for the real feature extraction by skeletonizing the objects 
in the binary matrix, i.e. reducing them to one pixel 125 width. Simultaneously each pixel is marked 
according to its significance: O=background 1=end point (of a line), 2=(inner) line point, 3=node point. 
In order to make this process efficient, known line thinning methods were further developed so that the 
scan lines are now skeletonized in a single pass and that only a small number of scan lines has to be 
held in core storage. This number depends on the thickness of the lines in the binary matrix. The program 
does not operate on more than k+3 consecu- tive scan lines, where k is the maximal line thickness in 
raster points. The result of this process is equivalent to a multi- pass skeletonization which utilizes 
a quasi-parallel line thinning in four parti- tions of the binary matrix for each pass. 2.The skeletonized 
and marked scan lines are turned over to the node extraction program. Connected sets of node points 
are recognized as nodes of the underlying line structure. The sets of coordinates of the adjoining line 
points are the output of the node extraction and represent the nodes. The adjoining line points are then 
marked as end points and the node points themsel- ves are erased, i.e. marked as background. 3. The 
scan lines are then passed to the line extraction program. Apart from back- ground points they contain 
only end points (one neighbour) and line points (two neighbours). In this way an unambiguous line extraction 
is ensured, which results in strings of line coordinates from end point to end point. SKELETONIZATION 
 The process of skeletonization will be described first as it is applied to the whole raster matrix 
in a quasi-parallel fashion. The sequential equivalent of this process will be treated later. To allow 
for the desired marking, every pixel of the raster matrix A may take on four possible values, i.e. 
aije{O,1,2,3 ~. The skeletonization starts with a matrix which contains only O-pixels (background) 
and 3-pixels (linework). This matrix repre- sents the result obtained by scanning the original line 
drawing. A skeletonization process which is to prepare such a matrix for the real line and node extraction 
should have the following properties (apart from efficiency): -- Preservation of connectivity. The 
connectivity of a line structure re- presented in a raster matrix can be de- fined in terms of neighbourhood 
relat- ions for pixels, e.g. (7,10): Two pixels aij and aiJ j, are neighbours, iff (i) aij=O , ai,jFO 
and li-i'i + lj-j'~1, or  (ii) aij+O, afj~O and li-i'l~ I, lj-j'l~1-  IMap with I Drum Scarme: } 
rows of raster matrix ~ Skeletoni-I  zation , I rows of skeleton ~0de ile (~0 rows of node extracted 
skeleton  Line ine Extraction ~ "I free memory Fig.1 Scan-to-line-conversion How this and other 
neighbourhood relations lead to the notion of connectivity can be found in the literature (2,7,8,10). 
 -- Generation of a marked skeleton. The skeletonization should produce a raster matrix with the following 
properties: (i) has less than two neigh- ai3=1~ aij bours (end point of a line).  126 (ii) has exactly 
two neigh- aij=2 <=> aij bouts, which are not neighbours of each other (inner llne point). (iii) aij=3 
~--> aij has more than two neighbours, and eras- ing aij (i.e. putting aij=O) alters the connectivity. 
(point of a node). Such a raster matrix is called a marked skeleton. -- Recognition of end points of 
lines. End points of lines in the marked skeleton should correspond as much as possible to end points 
of lines in the original line drawing. The skeletoniza- tion should neither produce "spikes" (additional 
short lines) nor should it shorten lines. -- Lines in the skeleton should correspond to the centre of 
the lines in the origi- nal. The first requirement leads to the use of known line thinning algorithms 
for the skeletonization (2,6). These algorithms have been developed for binary matrices and operate with 
local transformations,i.e. the transformation of a pixel uepends only on its neighbourhood. The preservation 
of connectivity is guaranteed. A local trans- formation for raster matrices A with a..6 {O,I,2,3,) can 
be defined in a similar 13 fashion, so that the global connectivity is preserved under this transformation 
and the desired marking of the raster ma- trix is carried out. For the definition of f we need a classification 
of the possible neighbourhoods of a 3-pixel, which is repre- sented in Fig.2 (apart from symmetry). 
f(aij):=aij ~ aij#3 or aij has a neigh- bourhood of class K or I. ~> a..=3 and a.. has a neigh- f(aij):=2 
 13 13 bourhood of class L. f(aij):=1 <=> aij=3 and aij has a neigh- bourhood of class E 2 or P. -<=> 
a..=3 and a.. has a neigh- f(aij):=O 13 13 bourhood of class E 3 or U. XOX XXO XXO XOX OXO XOX XOX 
XXO XXO XOX K: X30 030 030 030 X30 030 X3X X30 030 X30 OOO OXO OOX OOX OOX OXO OOO OOX OXX OOX OXX 
XOX XXO XXX XXX XXX XXX XXX XXX XXX X30 030 O3X 030 030 X30 030 030 O3X 030 OOX XOX XOX OOX OXO OOX OXX 
XOX XOX XXX OXO XXO XXX XXO XXX XXX XOX OXO OXO I: X3X X3X X3X X3X X3X X3X L: 030 030 030 OXO OXO OXO 
OXX OXX XXX 000 OOX OXO XOO 020 200 OOO 030 030 E2:030 030 P: 030 E3:030 OOX O00 OOO OOO OOO 300 XXO 
OXO XXO XXX OXX OXO XXX XXO 030 U: 030 X30 X30 030 X30 X3X X30 X3X 000 0OO OO0 000 O00 O00 000 000 O00 
 XXX XXO OXO XXX XXX XXO OXO XXX XXX XXX x3x 03x x3x 03x x30 x3x x3x x3x x30 x3x ~0 oox oox oox oxo 
oox xox oox oxx xox  x~{2,3~ Fig.2 Classes of neighbourhoods. Just as in the case of binary matrices 
one can prove that the application of the local transformation f to a pixel does not change the global 
connectivity. Therefore this holds also for the sequential applica- tion of f to different pixels. Moreover, 
it can be shown if all pixels of a raster matrix remain constant under f, this raster matrix is a marked 
skeleton in the above sense. The last two requirements for a skeletoni- zation process are therefore 
criteria for the order in which f should be applied to the plxels of the raster matrix. A quasi- parallel 
procedure (10) has proved parti- culary favourable. The pixels are divided up into four partitions so 
that pixels of one partition cannot be neighbours of each other: P1={aijli odd, j even} 2121212121 .... 
4343434343 P2={aij|i odd, j odd ~ 2121212121 P3={aij~i even, j even} P4=[aijli even, j odd 7- Within 
a partition the order of applica- tion of f is arbitrary. For a skeletoniza- tion step, f is applied 
first to the pixels of PI' the to P2' P3 and P4" These skele- tonization steps are repeated until no 
pixel has been changed in a step, i.e. the number of 3-pixels has remained the same. It can be shown 
that the number of skele- tonization steps which are necessary for the production of a skeleton is bounded 
by half the maximal line width in raster points. The order of the partitions within a skeletonization 
step influences the re- sulting skeleton. Our experience shows that other orders produce more "spikes" 
and zig-zag-lines.  127 SEQUENTIALIZING THE SKELETONIZATION The above akeletonization algorithm is 
not suited for practical purposes, since the raster matrix is so large (up to 25 million pixels) that 
it has to be read in or stored intermediately several times. However the order in which the local transformation 
f is applied can be changed without changing the result of the whole skeletonization process. First, 
the processing of partitions PI' P2 and P_, P. respectively within one row (scantling) ri=(aij,aij 
.... ain) of the raster matrix is combined to a row skele- tonization F: F(ri): DO FOR j=l TO n STEP2 
BEGIN ai,j+ I := f(ai,j+1); aij := f(aij ) ; END  According to this, f is applied consecuti- vely 
to ai2 , all , ai4 , ai3 .... If F is applied first to all odd numbered rows and then to all even numbered 
rows, the result is the same as with one of the above skeletonization steps. Moreover, one gets the same 
skeleton also with a row or- dering rl;r 3 r 2 r1! r 5 r 4 r 3 r 2 rl; ....  for the row skeletonization 
F because the mutual dependence is preserved. The number of row transformations which must be applied 
to a row to achieve a complete skeletonization, is not greater than the number of skeletonization steps 
necessary for the same purpose. Therefore, rows with smaller indices don't have to be transformed after 
a certain time. In this way a maximal number of k+3 consecutive rows have to be kept in main storage 
for the skeletonization, where k is the maXi- mal line width (Fig. 3). The skeletoni- zation algorithm 
now looks like this: skeletonize: k:=1; 1:=I; r 0 :=(O,O,O..O); DO WHILE (l~k) BEGIN read rows rk,rk+l; 
DO FOR i=k TO 1 F(ri); IF r I complete THEN BEGIN put row rl; 1:=1+I; END IF not end of file THEN 
 k:=k+2; END OOO O OOO OO O!O OOO 020 O10 020 020 row~l rows put 020 020 out to 020 020 node 
or 020220 line ex- 00300 traction o_Ioo 020 0020 rows currently 00300 processed 032O20 by the 
 030 030 skeletoni- 333 333 \ zation 333 333 \ \program row#19 333 333 Fig. 3 Sequential skeletonization 
 NODE AND LINE EXTRACTION The node extraction program gets the rows of the skeleton from the skeletonization 
program. To simplify the node extraction, all pixels in a row which belong to class I (Fig. 2), are erased. 
To avoid lines which consists of one point only all 1- pixels without neighbours are erased and all 2-pixels 
with two 3-pixel neighbours are themselves transformed into 3-pixels. OOO OOO 300 300 O10 -POOO 020 
~ 030 OOO OOO 003 003 The node extraction proceeds for a given row in five steps. In previous rows the 
program may have started the extraction of nodes which have to be continued or completed by further 3-pixels 
of the given row. (i) For every node whose extraction has not yet terminated neighbouring 2- pixels 
are searched. These are set to I and the corresponding coordina- tes are put in a list, which is associated 
with this node.  (ii) For every node the neighbouring 3- pixels are searched. The coordina- tes are 
stored for the continuation of the node in the following row. The pixels themselves are erased.  (iii) 
The extraction of every node which did not receive additional coordina- tes in step (ii) is terminated 
and the list of line end points, which is associated with such nodes, is put out to the node file. Nodes 
which received equal coordinates for con- tinuation in step (ii) are united.  128 (iv) The remaining 
3-pixels in the row are erased and their coordinates are attached to newly created nodes, de- pending 
on connectivity.  (v) All nodes which were created during step (iv) are treated as in step (i).  After 
having been processed by the node extraction program, a row is transfered to the line extraction program. 
This program works similarly to the node extraction program. First, all lines which are alrea- dy known 
to the program are continued, connected, or put out to the line file, the latter when the line following 
is termina- ted for a certain line. Then the row is scanned for starting points of new lines (1-pixels). 
The new lines are continued and put out if possible. When following lines the corresponding pixels are 
erased. Finally, the remaining 2-pixels are extrac- ted, creating additional new lines. After this the 
storage for this row can be used again by the skeletonization program for reading in new rows of the 
raster matrix. PROGRAM PERFORMANCE The data produced by this algorithm have two important advantages 
over data produ- ced by manual digitization: First, the nodes are exactly determined by the corresponding 
line end points and, second, the correction phase is shortened because the automatic process is less 
error-prone (4,3). On the other hand, a new error type is characteristic of the raster scan method: 
The introduction of nodes by merg- ing of lines which nearly touch in the original and the introduction 
of small gaps. The latter errors can be corrected automatically, but it is preferable to have good quality 
in the original line drawing and to avoid this type of error. The programs have been executed for about 
 20 maps. For some typical examples storage requirement, CPU-time,and computing costs are listed in 
Table I. The results presen- ted are taken from an implementation on a SIEMENS 4OO4/151 computer (same 
instruc- tion set as for an IBM/360-50, and roughly twice the sFeed). The tasks were run in a time 
sharing environment. Sanning was done off-line with an OPTRONICS P-IOOO scanner with a 5Ox52 cm drum. 
 CONCLUSION Tests of the whole program have shown that the conversion for even a complex line structure 
can be carried out within the time of scanning. Moreover, the economic use of core storage makes it 
possible to implement our algorithm on a minicomputer with an on-line scanner. Yype of nap =ont.ouz" 
28x48 SO 62.60 5096 1017 93 110.20 (169) =ounty ~OUndaz'¥ 30x4S 100 12.90 1026 235 53 25.50 (517) ~unty 
40x43 100 13.00 984 27S 56 29.80 boundary (687) :o~lunlty SOxSO 100 65.20 16616 1115 67 120.80 ~oundary 
(10500) land ume 50x46 100 28.60 1930 393 59 42*60 (1225) 1SIRENS 4004/151 ¢~ter (8~e instructions 
met as an I8M/360-50, an roughly twice the 8pe~) 2£ncl, pz~ (35 ~¥te) wit~ut ~lay, Table l:Results 
of scan-to-line-conversion algorithm. REFERENCES I. Boyle,A.R., The present status of auto- mated cartography. 
Computer Graphics (ACM-Siggraph), 9(1975), pp.260-266 2. Gray,S.B., Local properties of binary images 
in two dimensions. IEEE Trans. Computers C-20(1971), pp. 551-561  3. Kansy,K., Capture and encoding 
of area- oriented geographic maps. To appear in: the 3 rd Jerusalem Conference on Infor- mation Technology 
(JCIT) 1978.  4. Klein,K.H., Kreifelts,Th., Pick,K., Woetzel,G., Erfahrungen mit der Digi- talisierung 
von rasterm~Big erfa~ten Linienstrukturen II. GMD-Mitteilungen Nr. 37, St.Augustin,West Germany,1976. 
 5. Kreifelts,Th., Pick,K., Wisskirchen,P., Woetzel,G., Erfahrungen mit der Digi- talisierung von rasterm~Big 
erfaBten Linienstrukturen I. GMD-Mitteilungen Nr. 30, St.Augustin, West-Germany,1974.  6. Kreifelts,Th., 
Woetzel,G., Extraktion yon Linienmustern aus Bin~rbildern. To appear in: Kazmierczak,H.(ed), Maschinelle 
Bildverarbeitung, Springer Heidelberg-Berlin-New York.  7. Mylopoulos,J.P., Pavlidis,T., On the topological 
properties of quantized spaces I. J.ACM 18 (1971) pp.239-246.  8. Rosenfeld,A., Connectivity in digital 
pictures. J.ACM 17(1970), pp.146-160.  9. Tomlison,R.F.,(ed.),Geographical Data Handling. Int.Geographical 
Union Second Symposium on Geographical Information  Systems,Ottawa,Canada, 1972.  10. Woetzel,G.,Linien- 
und Knotenextraktion aus Rasterbildern, GMD-Mitteilungen Nr. 44,St.Augustin, West-Germany,1978.  129 
   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807383</article_id>
		<sort_key>130</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[Texture tile considerations for raster graphics]]></title>
		<page_from>130</page_from>
		<page_to>134</page_to>
		<doi_number>10.1145/800248.807383</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807383</url>
		<abstract>
			<par><![CDATA[<p>As a technique for rendering texture in images, texture tiles meet the subjective criterion of visual acceptability. A texture tile is a digital array of stored texture information that is replicated on a surface within an image. The purpose is to give the surface a textured appearance. The repetitive pattern inherent in the tiling approach can be suppressed. A texture tile must not exhibit macropatterns to avoid this problem. Properties that the mapping algorithm must include are oriented toward controlling aliasing. The tile is stored and accessed at several different levels-of-detail. The accessing technique is based on the size of the footprint the sample projects onto the surface to be textured. Aliasing is further controlled by a combination of increased sampling per pixel and filtering. Several textured images are presented, produced by the texture tile technique. These images show the realistic effect that is added by texture tiles.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Aliasing]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Footprint]]></kw>
			<kw><![CDATA[Level-of-detail]]></kw>
			<kw><![CDATA[Sampling]]></kw>
			<kw><![CDATA[Shading]]></kw>
			<kw><![CDATA[Texture]]></kw>
			<kw><![CDATA[Texture tile]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.4.7</cat_node>
				<descriptor>Texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010240.10010243</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision representations->Appearance and texture representations</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P334393</person_id>
				<author_profile_id><![CDATA[81100442844]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dungan]]></last_name>
				<suffix><![CDATA[Jr.]]></suffix>
				<affiliation><![CDATA[Technology Service Corporation, Santa Monica, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P329044</person_id>
				<author_profile_id><![CDATA[81100270942]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Anthony]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stenger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Technology Service Corporation, Santa Monica, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P330496</person_id>
				<author_profile_id><![CDATA[81332530601]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sutty]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Technology Service Corporation, Santa Monica, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Arbib, M. A., and E. M. Riseman, Computational Techniques in Visual Systems: Part I. The Overall Design, Tech. Rep. 76-10, Dept. of Computer and Information Science, U. of Mass., Amherst, Mass., Jul. 1976.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Busacker, R. G., and T. L. Saaty, Finite Graphs and Networks: An Introduction with Applications, McGraw-Hill, New York, 1965.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Davis, L. S., "Understanding Shape: Angles and Sides," IEEE Tran. Comput., Vol. 3-26, No. 3, Mar. 1977, pp. 236-242.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Davis, L. S., "Shape Matching Using Relaxation Techniques," Proc. of the IEEE Conf. on Pattern Recognition and Image Processing, Jun. 1977, pp. 191-197.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Feng, H. Y., and T. Pavlidis, "The Generation of Polygonal Outlines of Objects from Gray Level Pictures," IEEE Transactions on Circuits and Systems, Vol. CASS-22, No. 5, May 1975, pp. 427-439.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Fischler, M. A., and R. A. Elschlager, "The Representation and Matching of Pictorial Structures," IEEE Tran. Comput., Vol. C-21, No. 1, Jan. 1973, pp. 67-92.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Freeman, H., "Techniques for the Digital Computer Analysis of Chain-Encoded Arbitrary Plane Curves," Proc. of the National Electronics Conf., Vol. 17, Oct. 1961, pp. 421-432.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356627</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Freeman, H., "Computer Processing of Line Drawing Images," Computing Surveys, Vol. 6, No. 1, Mar. 1974, pp. 57-97.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Freeman, H., "Analysis of Line Drawings," Proc. of the NATO Advanced Study Institute on Image Processing, Jun. 1976.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Freeman, H., and L. S. Davis, "A Corner Finding Algorithm for Chain-Encoded Curves," IEEE Tran. on Computers, Mar. 1977, pp. 297-303.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Furtado, A. L., "Characterizing Sets of Data Structures by Graph Grammars," Proc. of the Conf. on Computer Graphics, Pattern Recognition, and Data Structure, May 14-16, 1975, pp. 103-107.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806005</ref_obj_id>
				<ref_obj_pid>800196</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Gray, J. C., "Compound Data Structure for Computer-Aided Design-A-Survey," Proc. of the ACM 22nd National Conf., 1967, MDI Publications, Wayne, Penn., pp. 355-365.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hanson, A. R., and E. M. Riseman, A Progress Report on Visions: Representation and Control of Visual Models, Tech. Rep. 76-9, Dept. of Computer Science, U. of Massl, Amherst, Mass., Jul. 1976.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Haralick, R. M., L. S. Davis, A. Rosenfeld, and D. L. Milgram, Reduction Operations for Constraint Satisfaction, TR-560, Comp. Science Center, U. of Md., College Park, Md., Aug. 1977.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Haralick, R. M., and L. G. Shapiro, The Consistent Labeling Problem, Center for Research, Inc., U. of K., Lawrence, Ks., Feb. 1978.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Haralick, R. M., and L. G. Shapiro, "Decomposition of Polygonal Shapes by Clustering," Proc. IEEE Conf. on Pattern Recognition and Image Processing, Jun. 6-8, 1977, pp. 183-190.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>321956</ref_obj_id>
				<ref_obj_pid>321941</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Horowitz, S. L., and T. Pavlidis, "Picture Segmentation by a Tree Traversal Algorithm," JACM, Vol. 23, No. 2, Apr. 1976, pp. 368-388.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[IEEE Computer Society, Proc. Workshop on Picture Data Description and Management, Apr. 31-22, 1977.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Johnson, T. E., "Sketchpad III, A Computer Program for Drawing in Three-Dimensions," AFIPS Spring Joint Computer Conf., 1963.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Kelly, M. D., "Edge Detection in Pictures by Computer Using Planning," Machine Intelligence 6, 1971, pp. 379-409.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Klinger, A., "Data Structures and Pattern Recognition," Proc. First Int'l. Joint Conf. on Pattern Recognition, Washington, D. C., IEEE, New York, 1973.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Klinger, A., "Regular Decomposition and Picture Structure," Proc. 1974 Int'l. Conf. SMC, Dallas, Tex., IEEE, N.Y. 1974, pp. 307-310.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Klinger, A., and C. Dyer, "Experiments on Picture Representation Using Regular Decomposition," CGIP, Vol. 5, No. 1, Mar. 1976, pp. 68-105.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Klinger, A., K. S. Fu, and T. L. Kunii, Data Structures, Computer Graphics, and Pattern Recognition, Academic Press, N.Y., 1977.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M., and R. F. Sproul, Principles of Interactive Computer Graphics, McGraw-Hill, N.Y., 1973.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Pavlidis, T., Structural Pattern Recognition, Springer-Verlag, Berlin, 1977.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Pavlidis, T., "Segmentation of Pictures and Maps through Functional Approximation," Computer Graphics and Image Processing 1, 1972, pp. 360-372.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Pavlidis, T., "A Minimum Storage Boundary Tracing Algorithm and Its Application to Automatic Inspection," IEEE Tran. SMC, Jan. 1978.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Pavlidis, T., and K. Steiglitz, "The Automatic Counting of Asbestos Fibers in Air Samples," Proc. Third Int'l Conf. on Pattern Recognition, Nov. 1977.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Rosen, C. A., and N. J. Nilsson, Application of Intelligent Automata to Reconnaissance, SRI Project 5953, Dec. 1967.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Shapiro, L. G., and R. M. Haralick, "Decomposition of Two-Dimensional Shapes by Clustering," to appear in IEEE Tran. Comput., 1978.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563742</ref_obj_id>
				<ref_obj_pid>563732</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Shapiro, L. G., "ESP: A High-Level Graphics Language," Proc. Second Annual Conf. on Computer Graphics and Interactive Techniques, Jun. 1975.]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Shapiro, L. G., and R. J. Bacon, "ESP3: A Language for Pattern Description and a System for Pattern Recognition," IEEE Tran. S. E., Vol. SE-3, No. 2, Mar. 1977, pp. 169-183.]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Shapiro, L. G., and R. M. Haralick, "A General Spatial Data Structure," to be presented at the IEEE Conf. Pattern Recognition and Image Processing, Jun. 1978.]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Sutherland, L. E., Sketchpad: A Man-Machine System, MIT Tech. Rep. No. 296, 1963.]]></ref_text>
				<ref_id>35</ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Tanimoto, S., and T. Pavlidis, "A Hierarchical Data Structure for Picture Processing," Computer Graphics and Image Processing 4, 1975, pp. 104-119.]]></ref_text>
				<ref_id>36</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359468</ref_obj_id>
				<ref_obj_pid>359461</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Tanimoto, S. L., and T. Pavlidis, "The Editing of Picture Segmentations Using Local Analysis of Graphs," CACM, Vol. 20, No. 4, Apr. 1977, pp. 223-229.]]></ref_text>
				<ref_id>37</ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Tanimoto, S. L., "An Iconic/Symbolic Data Structuring Scheme," Pattern Recognition and Artificial Intelligence, Academic Press, N.Y., 1976 pp. 452-471.]]></ref_text>
				<ref_id>38</ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Warnock, J. E., A Hidden Surface Algorithm for Computer Generated Halftone Pictures, Computer Science Dept., U. of Utah, TR 4-15, Jun. 1969. (See also Newman and Sproul, 1973.)]]></ref_text>
				<ref_id>39</ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Weingarten, N., and D. P. Greenberg, "Three-Dimensional Graphic Input Using Recursive Instancing," Proc. Computer Software and Applications Conf., Nov. 8-11, 1977, pp. 377-383.]]></ref_text>
				<ref_id>40</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356584</ref_obj_id>
				<ref_obj_pid>356583</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Williams, Robin, "A Survey of Data Structures for Computer Graphics Systems," Computing Surveys, Vol. 3, No. 1, Mar. 1971, pp. 1-21.]]></ref_text>
				<ref_id>41</ref_id>
			</ref>
			<ref>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Zahn, C. T., Jr., "Data Structures for Pattern Recognition Algorithms: A Case Study," Proc. Conf. on Computer Graphics, Pattern Recognition, and Data Structures, May 14-16, 1975, pp. 191-195.]]></ref_text>
				<ref_id>42</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 TEXTURE TILE CONSIDERATIONS FOR RASTER GRAPHICS William Dungan, Jr. Anthony Stenger George Sutty Technology 
Service Corporation Santa Monica, California ABSTRACT As a technique for rendering texture in images, 
 texture tiles meet the subjective criterion of visual acceptability. A texture tile isa digital array 
of stored texture information that is repli­ cated on a surface within an image. The purpose is to give 
the surface a textured appearance. The repetitive pattern inherent inthe tiling approach can be suppressed. 
A texture tile must not ex­ hibit macropatternsto avoid this problem. Pro­ perties that the mapping algorithm 
must include are oriented toward controlling aliasing. The tile isstored and accessed at several different 
 levels-of-detail. The accessing technique is based on the size of the footprint the sample projects 
onto the surface to be textured. Ali­ asing is further controlled by a combination of increased sampling 
per pixel and filtering. Several textured images are presented, produced by the texture tile technique. 
These images show the realistic effect that isadded by tex­ ture tiles. KEY WORDS AND PHRASES: texture, 
texture tile, computer graphics, shading, aliasing, level-of­detail, footprint, sampling. CR CATEGORIES: 
3.41, 5.12, 8.1 INTRODUCTION Present Computer Image Generation (CIG) displays use Gouraud or curved 
shading. This provides a good visual display through a computationally efficient algorithm. However the 
visual effect of textured shading adds another dimension, either artistic or realistic, to the resultant 
imagery. The motivation for this experimental work is the latter, specifically, to add real­ism to the 
CIG displays used for pilot training. The purpose of this paper is to present the textured imagery, along 
with the supporting concepts and algorithms. The approach we use to generate textured images maps a 
texture "tile" onto a surface within an image (1). A tile isa stored digital image of Sponsored by Air 
Force Human Resources Laboratory/ ASM, Wright Patterson AFB, Ohio, Contract F33615­77-C-0063. the texture 
which is then replicated, in perspec­ tive, over a surface in the fashion of tiles. The scene shown in 
Fig. 1 is typical of current CIG systems with smooth surface shading. The scene is taken from the data 
base which TSC generated of the Wright-PattersonAFB, Ohio. This scene and all those contained in the 
paper were generated by the computergraphic system developed by TSC (3). The black object isan untextured 
river. As a reference the building is 195 meters long. The same scene as itappears inFig. 2 depicts 
the texture "tile" concept. Here a synthetic tile has been generated and replicated inperspective onto 
the surface of the scene. Finally realistic tiles are added to the scene inFig. 3. Here the tree and 
grass tiles fill out the entire image. The scale of the tiles isthe same inFigs. 2 and 3: 15 meters for 
the grass tile and 150 meters for the tree tile. NATURE OF A TILE A texture tile may consist of any 
material, real or imagined, so long as it can be represented as a two-dimensional image. The surfaces 
of an object may be tiled to give the appearance of three­dimensionality. Clearly opposite edges of 
the tiles touch. Thus, inorder to match correctly, the scale and perspec­tive of adjoining edges must 
be the same. Ina photograph this occurs when the lens line-of-sight is parallel to the surface normal, 
straight down to a level surface. The texture tile then appears consistent independent of rotation. Another 
obvious assumption is that the texture pattern of adjoining edges must match. A close comparison of 
Figs. 2 and 3 will reveal the tile boundaries. The natural texture patterns do not match at the edges. 
It would have been difficult to make them match. The edge matching problem can be a subclass of the 
more general requirement that a texture tile must not exhibit macro-patterns. Edge mismatch is generally 
a macro-pattern if the gradient of shade across the boundary is discontinuous. Figure 2 exhibits edge 
matching, but still displays the obvious tiling effect. When the albedo of any local area of a texture 
tile differs significantlyfrom that of the tile as a whole, and this macro-pattern is unrelated to the 
texture, a linear pattern appears as an artifact of the tiling effect. The first images of tiled 130 
 tree texture exhibited this effect and was immedia­tely labeled "cabbage patch." Itcame complete with 
furrows between the rows. The tiles now are prefiltered expressly to reduce this effect. Inmost cases 
we want to break-up the tiling ef­ fect. Possible exceptionsmay be man-made objects such as a brick 
wall or agriculture field boun­ daries. But, even so, itmay be the overall tex­ tured surface that gives 
us the perception of tex­ ture rather than the microstructureof the texture. For instance, individual 
blades of grass are the microstructureof a field, yet a field may be per­ ceived without noticing its 
internal parts. When the resolution required to satisfy the tex­ tured image does not depend on the 
individual elements, but only on the overall texture, edge matching isnot necessary. The first texture 
tiles were created from aerial photography taken by the Air Force of the Stockbridge test range. While 
the photography was well suited to aerial reconnaissance, itwas not taken with the express purpose 
of providing good texture tiles. The altitude was too high so that the resolutionof the pictures was 
less than that required for a good tile. Inaddition the areas within the scene contained imperfections. 
Photo­ negative pinholes and dust particles during the negative digitization process also contributed 
to the effect of macro-patterns. Thus, TSC undertook its own photography of texture, first from a low-flying 
aircraft and then from a helicopter. The tree tile used here was taken at Chino, California (Fig. 4). 
Obtaining an accep­table photograph of grass proved more difficult. Grass always exhibited the macro-patternsfrom 
the way it was cut or from different growth patterns. The grass tile used here was taken under controlled 
 conditions of a board covered with "railroad model" grass, Fig. 5. It,too, showed evidence of macro­patterns 
which had to be removed by filtering. The model grass provided by far the greatest recog­nition as a 
tile; but, at the 1000 feet altitude of Figs. 1, 2, and 3, individual blades of grass are not realisticallyresolvable. 
As a result of our search for texture, we feel that simulation, or even synthesization,to be more viable 
approaches to creating texture tiles. THE ALGORITHM The texture tile technique uses memory to store 
 the image data. The fact that these texture tiles are generated off-line is fundamental indevelop­ing 
a fast algorithm. A simple memory access re­trieves the picture element value from the texture tile data. 
Memory size isthe limiting factor in the complexityand diversity of textured imagery, with this approach. 
 To calculate the correct memory address within each texture tile requires a mapping algorithm. First 
of all, each textured surface must be identified with regard to texture material. In order for the texture 
to remain fixed to a surface, a permanent cartesian coordinate system must be applied to the surface. 
One unit square of the surface coordinate system represents one texture tile. The tree surface of Fig. 
3 has a larger tile than the grass surface for this reason. Two surface points and the surface unit 
normal are sufficient to provide the required permanent coordinate system. One point isthe origin. 
The normalized vector from the origin to the second point is the x-axis unit vector. And the cross 
 product of the x-axis with the normal vector establishes the y-axis unit vector. Ifthe re­ lationship 
of the set of surface points remains unchanged from image to image, the texture pattern will remain 
positionally fixed to the surface in­ dependent of orientation within the images. Sampling isdone by 
projecting the pixel line-of­ sight onto the surface. The point at which the line-of-sight intersects 
the surface must be cal­ culated inthe surface coordinate system as a dis­ tance along the surface x-axis 
and the corresponding distance along the surface y-axis. The dot product of a vector from the surface 
origin to the point of intersection with either unit length axis vector will yield the required distances. 
 Since each unit square on the surface is the same texture tile, only the fractional distance above 
 the next lower integer is required to access the proper memory address within the texture tile. The 
texture tile data retrieved is attenuated so that the albedo of each point of the underlying surface 
ismaintained. All that is required is that the underlying surface shade and the average texture tile 
shade are known. Inthis manner a surface with a shade gradient, perhaps to simulate rolling hills, 
maintains the shading macro-pattern. An image generated using this technique displays a phenomena called 
aliasing (2). Aliasing, in this case, results from sampling the texture tile at too low a rate in the 
image at far range. The image can be improved by projecting the pixel extent onto the texture tile 
data and performing a weighted average to arrive at a single pixel value (1). Or, the texture tile 
image data can be stored at dif­ ferent resolutions, levels-of-detail, and from the correct resolution 
of the texture tile only one value is retrieved as the sample value. We chose to follow the second 
course, trying to main­tain the speed of the algorithm, but increasing the memory requirement. The levels-of-detail 
range from the finest resolution required in the image to a single average texture tile value at the 
coarsest level-of-detail. The resolution of each level-of-detail differs from the next by a power of 
two. The proper level-of-detail isdependent on the area on the surface projected by the pixel, the sample 
"footprint." The size of this footprint and, there­fore, the resolution of the equivalent level-of­detail, 
is a function of range, surface orientation and the sampling interval. As an analogy, the range to 
the sun is relatively constant. At noon, an object has its smallest shadow. When the surface normal 
is parallel to the line-of-sight, the footprint size is smallest. Yet, at sunrise or sunset an object 
has a larger shadow. As the line-of-sight approaches being orthogonal to 131  Figure 4. Basic Tree 
Tile Figure 1. Untextured Image Figure 2. Image with Synthetic Texture Figure 5. Basic Grass Tile  
Figure 7. Low Altitude View 132 Fiaure 3. Image with Natural Texture Figure 8. Landing Approach Figure 
9. Hilltop Overview 133 the surface normal, the footprint size grows if range isheld constant. The footprint 
isjust the conic section that the surfaces slice through the pixel projection, Fig. 6.  The footprint 
has a minor axis, fa, and a major axis, fb. The proper level-of-detail isthe one whose resolution isclosest 
to the average footprint size, f = (fa + fb)/2, Table 1. Ifboth fa and fb were used to index the proper 
level-of-detail, this would increase the data storage requirement by a factor of the number of levels-of-detail. 
  APPLICATIONS The images of Figs. 7,8,and 9 are of the Wright- Patterson data base from various positions. 
The trees of Fig. 3 are the same patch appearing in Fig. 7,the building isleft of center. The trees blend 
inthe distance to a uniform color. The hills to the right are also tiled with trees, but because of the 
distance, as inthe real world, no micropattern of the trees isvisible. Figure 8 depicts a landing approach 
to the runway, giving a good overall view of the data base. Many tiles, both grass and trees of various 
levels-of- No immedi­ detail, are mapped onto the ground plane. ately obvious patterns appear. To the 
left, in the patch of trees, a staggered line of trees is recognizable. Ifthe criterion for a patch 
of trees isthat no three trees may form a straight line, this pattern should disappear. Surfaces of 
different orientationreflect differing amounts of sunlight, as isclearly shown inFig. 9. From the top 
of a hill the plane below isuniform incolor, but the tree covered slopes appear tex­tured. The hill ismade 
of triangular planar sur­ faces. The tiling does not match at surface boun­daries but the edges only 
stand out because of the surface shade due to reflected sunlight. CONCLUSIONS Textured images can be 
realisticallyproduced using the technique of texture tiles. The texture tile image must not exhibit 
macropatterns. Some form of special processing must be undertaken to reduce aliasing. The combination 
of level-of-detail and filtering isan effective approach. Images that use the texture tile concept and 
the processing techniques described here, possess an added artis­ tic or natural dimension. REFERENCES 
 1. Blinn, James F.and Newell, Martin E. Texture and reflection inComputer Generated Images.  Comm. 
ACM 19, 10 (Oct. 1976), 542-547.  2. Crow, Franklin C. The aliasing problem in ComputerGenerated Shaded 
Images. Comm. ACM 20, 11 (Nov. 1977), 799-805.  3. Zimmerlin, T., Stanley, J., Stone, W. A sensor simulation 
and animation system. SIGGRAPH '78.   134 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1015088</article_id>
		<sort_key>135</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[Algorithms for image/vector conversion]]></title>
		<page_from>135</page_from>
		<page_to>139</page_to>
		<doi_number>10.1145/800248.1015088</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1015088</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15026587</person_id>
				<author_profile_id><![CDATA[81502761971]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Azriel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rosenfeld]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Univ. of Maryland, Colege Park]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>356627</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Freeman, H. Computer processing of <b>line</b> drawing images. <i>Computing Surveys 6</i> (1974), 57-97.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Milgram, D. L. Constructing trees for region description. Technical Report 541, Computer Science Center, University of Maryland, College Park, MD, June 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>578095</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Rosenfeld, A., and Kak, A. C. <i>Digital Picture Processing</i>. Academic Press, New York, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1015089</article_id>
		<sort_key>140</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[Data structures for picture processing]]></title>
		<page_from>140</page_from>
		<page_to>146</page_to>
		<doi_number>10.1145/800248.1015089</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1015089</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP48024580</person_id>
				<author_profile_id><![CDATA[81100431840]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Linda]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Shapiro]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Kansas State Univ., Manhattan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[1. Arbib, M. A., and E. M. Riseman, <i>Computational Techniques in Visual Systems: Part I. The Overall Design</i>, Tech. Rep. 76-10, Dept. of Computer and Information Science, U. of Mass., Amherst, Mass., Jul. 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[2. Busacker, R. G., and T. L. Saaty, <i>Finite Graphs and Networks: An Introduction with Applications </i>, McGraw-Hill, New York, 1965.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[3. Davis, L. S., "Understanding Shape: Angles and Sides," <i>IEEE Tran. Comput.</i>, Vol. 3-26, No. 3, Mar. 1977, pp. 236-242.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[4. Davis, L. S., "Shape Matching Using Relaxation Techniques," <i>Proc. of the IEEE Conf. on Pattern Recognition and Image Processing</i>, Jun. 1977, pp. 191-197.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[5. Feng, H. Y., and T. Pavlidis, "The Generation of Polygonal Outlines of Objects from Gray Level Pictures," <i>IEEE Transactions on Circuits and Systems</i>, Vol. CASS-22, No. 5, May 1975, pp. 427-439.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[6. Fischler, M. A., and R. A. Elschlager, "The Representation and Matching of Pictorial Structures," <i>IEEE Tran. Comput.</i>, Vol. C-21, No. 1, Jan. 1973, pp. 67-92.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[7. Freeman, H., "Techniques for the Digital Computer Analysis of Chain-Encoded Arbitrary Plane Curves," <i>Proc. of the National Electronics Conf.</i>, Vol. 17, Oct. 1961, pp. 421-432.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356627</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[8. Freeman, H., "Computer Processing of Line-Drawing Images," <i>Computing Surveys</i>, Vol. 6, No. 1, Mar. 1974, pp. 57-97.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[9. Freeman, H., "Analysis of Line Drawings," <i>Proc. of the NATO Advanced Study Institute on Image Processing, Jun. 1976</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[10. Freeman, H., and L. S. Davis, "A Corner Finding Algorithm for Chain-Encoded Curves," <i>IEEE Tran. on Computers</i>, Mar. 1977, pp. 297-303.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[11. Furtado, A. L., "Characterizing Sets of Data Structures by Graph Grammars," <i>Proc. of the Conf. on Computer Graphics, Pattern Recognition, and Data Structure</i>, May 14-16, 1975, pp. 103-107.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>806005</ref_obj_id>
				<ref_obj_pid>800196</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[12. Gray, J. C., "Compound Data Structure for Computer-Aided Design-A-Survey," <i>Proc. of the ACM 22nd National Conf.</i>, 1967, MDI Publications, Wayne, Penn., pp. 355-365.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[13. Hanson, A. R., and E. M. Riseman, <i>A Progress Report on Visions: Representation and Control of Visual Models</i>, Tech. Rep. 76-9, Dept. of Computer Science, U. of Massl, Amherst, Mass., Jul. 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[14. Haralick, R. M., L. S. Davis, A. Rosenfeld, and D. L. Milgram, <i>Reduction Operations for Constraint Satisfaction</i>, TR-560, Comp. Science Center, U. of Md., College Park, Md., Aug. 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[15. Haralick, R. M., and L. G. Shapiro, <i>The Consistent Labeling Problem</i>, Center for Research, Inc., U. of K., Lawrence, Ks., Feb. 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[16 Haralick, R. M., and L. G. Shapiro, "Decomposition of Polygonal Shapes by Clustering," <i>Proc. IEEE Conf. on Pattern Recognition and Image Processing</i>, Jun. 6-8, 1977, pp. 183-190.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>321956</ref_obj_id>
				<ref_obj_pid>321941</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[17. Horowitz, S. L., and T. Pavlidis, "Picture Segmentation by a Tree Traversal Algorithm," <i>JACM</i>, Vol. 23, No. 2, Apr. 1976, pp. 368-388.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[18. IEEE Computer Society, <i>Proc. Workshop on Picture Data Description and Management</i>, Apr. 31-22, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[19. Johnson, T. E., "Sketchpad III, A Computer Program for Drawing in Three-Dimensions," <i>AFIPS Spring Joint Computer Conf.</i>, 1963.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[20. Kelly, M. D., "Edge Detection in Pictures by Computer Using Planning," <i>Machine Intelligence</i> 6, 1971, pp. 379-409.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[21. Klinger, A., "Data Structures and Pattern Recognition," <i>Proc. First Int'l. Joint Conf. on Pattern Recognition</i>, Washington, D. C., IEEE, New York, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[22. Klinger, A., "Regular Decomposition and Picture Structure," <i>Proc. 1974 Int'l. Conf. SMC</i>, Dallas, Tex., IEEE, N.Y. 1974, pp. 307-310.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[23. Klinger, A., and C. Dyer, "Experiments on Picture Representation Using Regular Decomposition," <i>CGIP</i>, Vol. 5, No. 1, Mar. 1976, pp. 68-105.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[24. Klinger, A., K. S. Fu, and T. L. Kunii, <i>Data Structures, Computer Graphics, and Pattern Recognition</i>, Academic Press, N.Y., 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[25. Newman, W. M., and R. F. Sproul, Principles of <i>Interactive Computer Graphics</i>, McGraw-Hill, N.Y., 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[26. Pavlidis, T., <i>Structural Pattern Recognition</i>, Springer-Verlag, Berlin, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[27. Pavlidis, T., "Segmentation of Pictures and Maps through Functional Approximation," <i>Computer Graphics and Image Processing 1</i>, 1972, pp. 360-372.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[28. Pavlidis, T., "A Minimum Storage Boundary Tracing Algorithm and Its Application to Automatic Inspection," <i>IEEE Tran. SMC</i>, Jan. 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[29. Pavlidis, T., and K. Steiglitz, "The Automatic Counting of Asbestos Fibers in Air Samples," <i>Proc. Third Int'l Conf. on Pattern Recognition</i>, Nov. 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[30. Rosen, C. A., and N. J. Nilsson, <i>Application of Intelligent Automata to Reconnaissance</i>, SRI Project 5953, Dec. 1967.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[31. Shapiro, L. G., and R. M. Haralick, "Decomposition of Two-Dimensional Shapes by Clustering," to appear in <i>IEEE Tran. Comput.</i>, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563742</ref_obj_id>
				<ref_obj_pid>563732</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[32. Shapiro, L. G., "ESP: A High-Level Graphics Language," <i>Proc. Second Annual Conf. on Computer Graphics and Interactive Techniques</i>, Jun. 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[33. Shapiro, L. G., and R. J. Bacon, "ESP<sup>3</sup>: A Language for Pattern Description and a System for Pattern Recognition," <i>IEEE Tran. S. E.</i>, Vol. SE-3, No. 2, Mar. 1977, pp. 169-183.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[34. Shapiro, L. G., and R. M. Haralick, "A General Spatial Data Structure," to be presented at the <i>IEEE Conf. Pattern Recognition and Image Processing </i>, Jun. 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[35. Sutherland, L. E., <i>Sketchpad: A Man-Machine System</i>, MIT Tech. Rep. No. 296, 1963.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[36. Tanimoto, S., and T. Pavlidis, "A Hierarchical Data Structure for Picture Processing," <i>Computer Graphics and Image Processing</i> 4, 1975, pp. 104- 119.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>359468</ref_obj_id>
				<ref_obj_pid>359461</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[37. Tanimoto, S. L., and T. Pavlidis, "The Editing of Picture Segmentations Using Local Analysis of Graphs," <i>CACM</i>, Vol. 20, No. 4, Apr. 1977, pp. 223-229.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[38. Tanimoto, S. L., "An Iconic/Symbolic Data Structuring Scheme," <i>Pattern Recognition and Artificial Intelligence</i>, Academic Press, N.Y., 1976, pp. 452-471.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[39. Warnock, J. E., <i>A Hidden Surface Algorithm for Computer Generated Halftone Pictures</i>, Computer Science Dept., U. of Utah, TR 4-15, Jun. 1969. (See also Newman and Sproul, 1973.)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[40. Weingarten, N., and D. P. Greenberg, "Three-Dimensional Graphic Input Using Recursive Instancing," <i>Proc. Computer Software and Applications Conf.</i>, Nov. 8-11, 1977, pp. 377-383.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356584</ref_obj_id>
				<ref_obj_pid>356583</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[41. Williams, Robin, "A Survey of Data Structures for Computer Graphics Systems," <i>Computing Surveys</i>, Vol. 3, No. 1, Mar. 1971, pp. 1-21.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[42. Zahn, C. T., Jr., "Data Structures for Pattern Recognition Algorithms: A Case Study," <i>Proc. Conf. on Computer Graphics, Pattern Recognition, and Data Structures</i>, May 14-16, 1975, pp. 191- 195.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1015057</article_id>
		<sort_key>147</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[Computer Generation of Texture Using a Syntactic Approach]]></title>
		<page_from>147</page_from>
		<page_to>152</page_to>
		<doi_number>10.1145/800248.1015057</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1015057</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40025273</person_id>
				<author_profile_id><![CDATA[81100244803]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Fu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Purdue University, West Lafayette, Indiana]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P685939</person_id>
				<author_profile_id><![CDATA[81100052841]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[S.]]></first_name>
				<middle_name><![CDATA[Y.]]></middle_name>
				<last_name><![CDATA[Lu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Syracuse University, Syracuse, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[1. Zucker, S. W., "Toward a Model of Texture," <i>computer Graphics and Image Processing</i>, 5, 1976, pp. 190-202.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[. Haralick, R. M., K. Shanmugan and I. Dinstein, "Textural Features for Image Classification," <i>IEEE Trans. on Systems, Man and Cybernetics</i> Vol. SMC-3, No. 6, Nov. 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[3. Weszka, J. S., C. R. Dyer and A. Rosenfeld, "A Comparative Study of Texture Measures for Terrain Classification," <i>IEEE Transaction on Systems, Man and Cybernetics</i>, Vol. SMC-6, No. 4, April 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>578853</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[4. Lipkin, B. S. and A. Rosefeld, Eds., <i>Picture Processing and Psypictorics</i>, Academic Press, 1970, pp. 289-381.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[5. Carlucci, L., "A Formal System for Texture Languages," <i>Pattern Recognition</i>, Vol. 4, 1972, pp. 53-72.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[6. Fu, K. S. and B. K. Bhargava, "Tree Systems for Syntactic Pattern Recognition," IEEE Trans. on <i>computers</i>, Vol. C-22, No. 12, 1973, pp. 1087-1099.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[7. Lu, S. Y. and K. S. Fu, "A Syntactic Approach to Texture Analysis," <i>Computer Graphics and Image Processing</i>, Vol. 7, June 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[8. Brodatz, P., <i>Texture</i>, Dover Publications, New York, 1966.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[9. Tsai, W. H. and K. S. Fu, "Image Segmentation and Recognition by Texture Discrimination: A Syntactic Approach," submitted to the Fourth International Joint Conference on Pattern Recognition, Nov. 7-11, 1978, Kyoto, Japan.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[10. Lu, S. Y. and K. S. Fu, "Stochastic Tree Grammar Inference for Texture Synthesis and Discrimination," <i>Proceedings of IEEE Conference on Pattern Recognition and Image Processing</i>, May, 1978, Chicago.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[11. Knuth, D. E., <i>Sorting and Searching</i>, Addison-Wesley, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807384</article_id>
		<sort_key>153</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[Three-dimensional representations for computer graphics and computer vision]]></title>
		<page_from>153</page_from>
		<page_to>160</page_to>
		<doi_number>10.1145/800248.807384</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807384</url>
		<abstract>
			<par><![CDATA[<p>Representing complex three-dimensional objects in a computer involves more than just evaluating its display capabilities. Other factors are the uses and costs of the representation, what operations can be performed on it and, ultimately, how useful it is for computer recognition or description or three-dimensional objects. Many of the questions which are posed arise from the joint consideration of computer graphics and computer vision, and a specific representation hierarchy is proposed for complex objects which makes them amenable to display, manipulation, measurement, and analysis.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Computer vision]]></kw>
			<kw><![CDATA[Curved objects]]></kw>
			<kw><![CDATA[Data structures]]></kw>
			<kw><![CDATA[Object modelling]]></kw>
			<kw><![CDATA[Representation coversions]]></kw>
			<kw><![CDATA[Representation hierarchy]]></kw>
			<kw><![CDATA[Three dimensional representations]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Graphics data structures and data types</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010394</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics file formats</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15038213</person_id>
				<author_profile_id><![CDATA[81452608047]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Norman]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Badler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer and Information Science, The Moore School of Electrical Engineering, University of Pennsylvania, Philadelphia, Pennsylvania]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15028312</person_id>
				<author_profile_id><![CDATA[81100289199]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ruzena]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bajcsy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer and Information Science, The Moore School of Electrical Engineering, University of Pennsylvania, Philadelphia, Pennsylvania]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Agin, G.J., and Binford, T.O. Computer description of curved objects. Proc. IJCAI (1973), 629-640.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Badler, N.I. An interactive programming system for three-dimensional discrete topology. Unpublished report, University of Toronto (1972).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Badler, N.I., and O'Rourke, J. A representation and display system for the human body and other three-dimensional curved objects. University of Pennsylvania, Department of Computer and Information Science, Technical Report (February 1977).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Badler, N.I., and O'Rourke, J. A human body modelling system for motion studies. University of Pennsylvania, Department of Computer and Information Science, Technical Report (August 1977).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Badler, N.I. and O'Rourke, J. Decomposition of three-dimensional objects into spheres. IEEE Pattern Recognition and Artif. Intelligence Workshop, Princeton, New Jersey (1978).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Bajcsy, R., and Soroka, B. Steps towards the representation of complex three-dimensional objects. Proc. IJCAI (1977), 596.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Bajcsy, R., and Bourne, D. Computer Reconstruction of continuous morphology from discrete slices - the interpolation problem in anatomy. IEEE Pattern Recognition and Artificial Intelligence Workshop, Princeton, New Jersey (1978).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Bajcsy, R., and Winston, I. A computer system for reconstruction and display of the macrostructure of brain from radiographs of serial sections. Proc. BIOSIGMA '78 (April 1978), Paris, 262-266.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>578776</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Barnhill, R.E., and Riesenfeld, R.F. Computer-Aided Geometric Design. Academic Press, New York, 1974.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Baumgart, B.G. Geometric modelling for computer vision. Stanford University, Department of Computer Science, Technical Report (October 1974).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Bezier, P. Numerical Control Mathematics and Applications. John Wiley and Sons, New York, 1972]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. personnal communication, 1977.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Blum, H. A transformation for extracting new descriptors of shape. In Models for the Perception of Speech and Visual Form, Dunn, Walthen (Ed.), MIT Press, Cambridge, Mass. (1967), 362-380.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Blum, H. Biological shape and visual science. J. Theor. Biology 38 (1973), 205-287.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Blum, H., and Nagel, R. Shape description using weighted symmetric axis features. Proc. IEEE Pattern Recognition and Image Processing Conf., Rennselaer Polytechnic Inst. (June 1977), 203-215.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360727</ref_obj_id>
				<ref_obj_pid>360715</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Braid, I.C. The synthesis of solids bounded by many faces. CACM 18 (April 1975), 209-216.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>569952</ref_obj_id>
				<ref_obj_pid>800193</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Catmull, E. A system for computer generated movies. Proc. ACM Annual Conf., vol. 1 (1972), 422-431.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Catmull, E. Computer display of curved surfaces. Proc. IEEE Conf. on Computer Graphics, Pattern Recognition, and Data Structure, Los Angeles, California (May 1975), 11-17.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Clark, H.H. Space, time, semantics and child. In Cognitive Development and the Acquisition of language, Moore, T.E. (Ed.), Academic Press, New York, 1973, 27-144.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360354</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Clark, J.H. Hierarchical geometric models for visible surface algorithms. CACM 19 (October 1976), 547-554.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>321468</ref_obj_id>
				<ref_obj_pid>321466</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Comba, P.G. A procedure for detecting intersections of three-dimensional objects. JACM 15 (July 1968), 354-366.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Duda, R.O., and Hart, P.E. Pattern Classification and Scene Analysis. John Wiley &amp; Sons, New York, 1972.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Falk, G. Interpretation of imperfect line data as a three-dimensional scene. Artificial Intelligence 3 (1972), 101-144.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Fetter, W.A. A human figure computer graphics development. Proc. Eurocomp Congress, Online, Brunel, England (May 1974) 476-488.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[French, A.S. Computer simulation of space-filling molecular models. IEEE Trans. Computers C-26 (1977), 1026-1028.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359846</ref_obj_id>
				<ref_obj_pid>359842</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H., Kedem, Z.M., and Uselton, S.P. Optimal surface reconstruction from planar contours. CACM 20 (October 1977), 693-702.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Goldstein, R.A., and Nagel, R. 3-D visual simulation. Simulation 16 (January 1971), 25-30.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Gouraud, H. Continuous shading of curved surfaces. IEEE Trans. Computers C-20 (June 1971), 623-629.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Gray, S.B. Local properties of binary images in two and three dimensions. Information International Report (1970).]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Herbison-Evans, D. Animated cartoons by computers using ellipsoids. Proc. 6th Australian Computer Conf., Sydney, Australia (May 1974), 811-823.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Horn, B.K.P. Shape from shading. MIT, Project MAC Report TR-79 (November 1970).]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Kelly, M.D. Edge detection by computer using planning. Machine Intelligence 6 (1971).]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Knowlton, K., and Cherry L. ATOMS - A Three-D Opaque Molecular System - for color pictures of space-filling or ball-and-stick models. Computers and Chemistry 1 (1977), 161-166.]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360355</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Levin, J. A parametric algorithm for drawing pictures of solid objects composed of quadric surfaces. CACM 10 (October 1976), 555-563.]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Levinthal, C., and Ware, R. Three-dimensional reconstruction from serial sections. Nature 236 (March 1972), 207-210.]]></ref_text>
				<ref_id>35</ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Marr, D., and Nishihara, H.K. Representation and recognition of the spatial organization of three-dimensional shapes. MIT, AI Memo 377 (1976).]]></ref_text>
				<ref_id>36</ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Miller, G., and Johnson-Laird, P. Language and Perception. Belknap Press of Harvard University Press, Cambridge, Mass., 1976.]]></ref_text>
				<ref_id>37</ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Nevatia, R. Depth measurement by motion stereo. Computer Graphics and Image Processing 5 (1976), 203-214.]]></ref_text>
				<ref_id>38</ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[O'Rourke, J. Representation and display of three-dimensional objects with spheres. University of Pennsylvania, Department of Computer and Information Science, Technical Report (August 1977).]]></ref_text>
				<ref_id>39</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563884</ref_obj_id>
				<ref_obj_pid>965141</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Parent, R.E. A system for sculpting 3-D data. Computer Graphics 11 (Summer 1977), 138-147.]]></ref_text>
				<ref_id>40</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Phong, Bui Tuong. Illumination for computer generated images. CACM 18 (June 1975), 311-317.]]></ref_text>
				<ref_id>41</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563747</ref_obj_id>
				<ref_obj_pid>964963</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Potter, T.E., and Willmert, K.D. Three-dimensional human display model. Computer Graphics 9 (Spring 1975),102-110.]]></ref_text>
				<ref_id>42</ref_id>
			</ref>
			<ref>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Roberts, L.G. Machine perception of three-dimensional solids. In Optical and Electro-Optical Information Processing, Tippell, J.T., et al. (Eds.), MIT Press, Cambridge, Mass., 1965, 159-197.]]></ref_text>
				<ref_id>43</ref_id>
			</ref>
			<ref>
				<ref_obj_id>63448</ref_obj_id>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Rogers, D.F., and Adams, J.A. Mathematical Elements for Computer Graphics. McGraw-Hill, New York 1976.]]></ref_text>
				<ref_id>44</ref_id>
			</ref>
			<ref>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Graf/Pen Sonic Digitizer. Science Accessories Corporation, Southport, Conn. 1970.]]></ref_text>
				<ref_id>45</ref_id>
			</ref>
			<ref>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Tanimoto, S., and Pavlidis, T. A hierarchical data structure for picture processing. Computer Graphics and Image Processing 4 (1975), 104-119.]]></ref_text>
				<ref_id>46</ref_id>
			</ref>
			<ref>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Voelcker, H.B., and Requicha, A.A.G. Geometric modeling of mechanical parts and processes. Computer 10 (December 1977), 48-57.]]></ref_text>
				<ref_id>47</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359848</ref_obj_id>
				<ref_obj_pid>359842</ref_obj_pid>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[Wu, Sheng-Chuan, Abel, J.F., and Greenberg, D. An interactive computer graphics approach to surface representation. CACM 20 (October 1977), 703-712.]]></ref_text>
				<ref_id>48</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 THREE-DIMENSIONAL REPRESENTATIONS FOR COMPUTER GRAPHICS AND COMPUTER VISION* Norman Badler** Ruzena 
Bajcs~* University of Pennsylvania Philadelphia, Pennsylvania 19104 Key words and phrases; Computer 
graphics, computer vision, three dimensional representations, data structures, object modelling, curved 
objects, representation hierarchy, representation conversions. Computing Reviews categories: 3.69, 8.1, 
8.2. ABSTraCT Representing complex three-dimensional objects in a computer involves more than just 
evaluating its display capabilities. Other factors are the uses and costs of the representation, what 
oper- ations can be performed on it and, ultimately, how useful it is for computer recognition or description 
or three-dimensional objects. Many of the questions which are posed arise from the joint consideration 
of computer graphics and computer vision, and a specific representation hierarchy is proposed for complex 
objects which makes them amenable to display, manipulation, measurement, and analysis. THREE-DIMENSIONAL 
REPRESENTATION ISSUES While a realistic computer graphics image is easily interpretable by a human observer, 
we would like a computer to understand a real visual scene. The latter problem has proved the more diffieult, 
and indeed, computer vision research has been concerned with bow to discover and structure the knowledge 
people might use to understand an image. We can enumerate some of the oonmon issues faced by both computer 
graphics and three- dimensional (3D) computer vision: * What are the primitives used to model an object? 
 * What is the storage cost and complexity associated with a 3D representation?  * What operations 
on the representation are natural? Which are difficult?  How can one representation be converted into 
another, and what might be (computable) criteria for choosing when and where such conversions ought to 
be made?  * How is 3D data obtained for a particular representation?  Research partially supported 
by NSF Grants MCS-76-19464 and MCS-76-19465. Department of Computer and Information Science, The Moore 
School of Electrical Engineering. * How can objects be described and recognized? Our reasons for this 
investigation stem primarily from attempts to model natural three- dimensional objects, basically anatomical 
in form. Such objects include the human body as a whole (4), various body parts such as the skull (7), 
the brain (8), or the heart (6), and microstruetures such as neurons or blood vessels (35). In this context 
many of the issues are exposed since no single existing representation is appropriate for all objects. 
This complexity of form is quite different from a multiplicity o-f s--~-ple forms. The limitations on 
modelling man-made objects are primarily physical (storage and processing time), while those on natural 
objects conceptual: what is a reasonable representation of significant shape?-- In our discussions, we 
shall not try to propose answers to all the issues, nor is our intent an exhaustive survey of previous 
work, but rather we will be trying to examine these questions in a new light. PRIMITIVES Two fundamental 
classes of object modelling techniques can be distinguished: surface repre- sentations and volume representations. 
Repre- sentations from both groups have been proposed for computer graphics and for computer vision, 
so that no distinction between them can be made on these grounds. A 3D object may be modelled by storing 
its surface as: i. A set of three-dimensional surface points. 2. A polygonal network.  3. Curved surface 
patches (of various kinds).  4. Quadrie patches.  Surface points are represented by a list of coordinate 
triples and an optional indication of which direction is the "outside." Data of this type is often obtained 
from digitizers (45), reconstructed from perspective projection (44), or derived from serial sections 
(35,26). Figure i shows the outlines (3D surface points) of several slices of a neuron. Scene analysis 
may be viewed as the reconstruction of a 3D object from partial sets of surface points -- usually the 
visible edges and vertiees. A polygonal network is a decompo- sition into arbitrary planar polygon patches. 
They have been extensively used for computer 153 graphics and have also been proposed for scene analysis 
purposes (10). Curved surface patches (Fig. 2) are normally used in the context of computer aided design 
(9,44); at least a half dozen variations exist, but distinctions between them are not relevant here. 
Quadric patches represent surfaces by non-parametric forms (34). Alternatively, the object volume or 
its decomposition into volumes may be stored: 5. Cellular spaces.  6. (Convex) polyhedra.  7. Geometric 
forms.  8. Ellipsoids.  9. Cylinders. I0. Spheres.  Volume representations based on an extension 
of two-dimensional digitized images are called cellular spaces since each cell represents some identical 
cubical volume. They store complete information about an object since the interior (even of "solid" portions) 
is explicitly available. Figure 3 shows a human brain represented as successive tomographic scans (7). 
The scan planes are slightly separated to show the interior structures. Polyhedral decompositions are 
best exemplified by Roberts' classical scene analysis system(43) where a small number of primitive convex 
polyhedra are defined. Geometric forms such as transformations of spheres, cylinders, cones, and simple 
polyhedra have been used to model complex man-made objects (21,27). Several systems employing a single 
geometric primitive exist: ellipsoids (30), cylinders or generalized cylinders (1,6,36), and spheres 
(3). Figure 4 is a wire- frame drawing of a humanoid form modelled with cylinders (6). There are two 
alternatives with spheres: either the objects to be represented are themselves spherical (25,33), or 
else are arbi- trary eurved volumes decomposed into overlapping spheres. Figure 5 shows a human body 
modelled by overlapping spheres (3). Some systems incorporate hybrid represen- tations to advantage. 
One technique is to conceptually manipulate volumes which are actually represented as a set of cylindrical 
and planar patches (16,47). A program for displaying ball and stick molecular models uses spheres and 
cylinders (33). These combinations may be motivated either by application (the molecular models), by 
convenience of certain operations (interseetion and union), or by natural hier- archies (volumes have 
surfaces). We shall return to hybrid representations in a later section. STORAGE COST AND COMPLEXITY 
 There are several questions which can be asked about a partieular representation: How many instances 
of a primitive are required to represent certain (classes of) objects? * Is there a natural data hierarchy? 
 * How much physical space is requried to store a primitive?  How complex is the modification process 
 (insertion, deletion, or substitution) of a primitive? Since visual complexity is related to the number 
of primitives required to represent some scene, it is easy to assume that choosing a '%high level" primitive 
will reduce this cost, for example, by using curved surface patches rather than a polygonal network for 
curved objects. As Clark has shown, however, there is a visual hi~hy of primitives such that only the 
sufficiently informative one need be chosen at a given visual resolution (20). Image analysis has realized 
(at least since 1971 (32)) that varying visual resolutions could be used to advantage by reducing the 
number of primitives (for example, two-dimensional regions) proeessed at one time. Such "pyramid" data 
structures (46) are now cmming under widespread study, but have not yet resulted in any hierarchies for 
3D object recognition. The absolute space associated with each primitive is related to how much information 
it stores about its neighbors. Various polyhedral networks (for example, the "winged edge" represen- 
tation (10)) incorporate numerous adjacency relations. Volume models trade neighbor relations for compact 
descriptions as object instances, thus modification becomes simple and context-independent. For example, 
comparing Goldstein's volume models (27) with Braid's (16) (which are really stored as networks of curved 
and planar patches), the cost associated with addition in the former is trivial, while in the latter 
it is dependent upon (and even restricted by) intersecting surfaces. Among volume models, cellular spaces 
are apt to be too costly for complex objects in terms of actual storage for large (256x256x266) arrays. 
Conceivably, small portions of an object with considerable localized complexity might be stored in smaller 
cellular arrays, although a set of surface points may suffice since rotation and dilation is easier. 
Many biological structures have axes and are acceptably modelled by small numbers of generalized cylinders. 
At least 80 cylinders would be needed to model an articulated human body (60 of these are just for fingers 
and toes. ) An alternative is to decompose the object into (overlapping) spheres. While more primitives 
will be required than for other volume methods (though fewer than cellular spaces), there are additional 
compensating factors: spheres are invariant under rotation (aiding a matehing process), avoid end closure 
problems inherent with cylinders (6,42), permit simple articulation of joints (compare with the polygonal 
network hand by Catmull (17)), and offer a simple, shaded, hidden-surface-removed image generation algorit~ 
(3). The human body shown in Fig. 5 is modelled with just over 300 spheres. To appreciate its simplicity, 
however, note that Fuchs uses about that many polygons to achieve a shaded rendering of a human head 
(26), and Fetter uses about 3000 surface points for a reasonably detailed line rendering of the whole 
body (24). 154 It is important to realize that absolute realism is an end to itself, and is not necessary 
when additional factors such as storage cost and processing time are considered. Although curved patches 
might be the most storage-efficient representation for an accurate human body model (12), the display 
cost (18) and the difficulty in controlling deformations at joints are serious problems. OPERATIONS 
 Operations which can be performed on a representation can be classified into a few groups: Measurement: 
Topology; Surface area; Surface derivatives; Vol~ne. Transformation: Translation, rotation, dilation; 
Interpolation (to change resolution); Algebraic (intersection, union, difference); Defor- mation (skew, 
stretch, bend, push, mold). Table i summaries each group of operations with respect to eaehrepresentation 
type. Finding the topology consists of counting the number of components, cavities, and holes ("handles"). 
For a cellular space there are linear algorithms (2,29), but for 3D surface points the computation is 
impossible since connections between each point are unknown. All the other cases are complicated by the 
fact that sets of primitives may enclose vacant volumes. Surface area can be estimated for 3D surface 
points by converting them into a polygonal network by triangulation to nearest neighbors or by Fuchs' 
algorithm (26) if the points lie in parallel sections. The other surface representations yield exact 
areas. The surface area of a cellular object can be estimated by counting cells bounding non- object 
cells. Other volume representations present problems since the surface area is dependent upon computing 
the intersections of the instance primitives. Computing surface derivatives (usually in order to find 
the surface normal) depends on whether the primitive is used to approximate, rather than exactly match, 
the object; for example, polyhedral representations have exact derivatives whiehmay only approximate 
those of the intended object (28,41). 0nly for surface points or cellular spaces are deri- vatives truly 
approximate (39). Surface normals are used in graphics to establish surfaee shading, but are important 
in image analysis since they allow the direct computation of a volume model (31). Somewhat surprisingly, 
volume measurements are generally easier in surface rather than volume representations. The latter again 
suffer from the difficulty of characterizing the volume conmon to several primitives. Volume is easiest 
to measure in a cellular space (just the number of points), so a natural (but expensive) solution is 
to convert the given representation into cells. Polyhedral and curved surface representations admit piecewise 
integration techniques for volume measurement. All representations are transformable by translations, 
rotations, and dilations, except for cellular spaces where rotations and dilations are awkward. Changing 
the resolution of the represen- tation is related to dilation, causing a similar problem to arise for 
cellular spaces: increasing the resolution of the original data requires an estimation of the distribution 
of boundary points in the new cells. All other representations can be refined by interpolation, sub-division, 
or parametric substitution (altering the step of the parameter controlling the bounding curves). The 
algebraic operations of union, inter- section, and difference are local point operations in the cellular 
domain and geometric computations in polygonal and polyhedral domains (10,40). Curved patches and volume 
representations are more difficult to manipulate. Although volumes are easy to combine algebraically 
for a display (27), the results of these operations are not generally primitive and must remain represented 
in an algebraic form. One solution to this problem is to actually represent the volumes by their surfaces 
 (16,47), so that admissible algebraic operations create explicit surface forms. In a 3D volume representation 
for computer vision, a visually- presented object must decompose into a reasonable algebraic combination, 
and this may prove quite difficult (6,23). Deformability, usually considered a desirable property for 
computer-aided design, translates into the ability to recognize (and "re-form") distorted objects. Surface 
points, polygonal networks, and curved surface patches deform easily, and generalized cylinder axes are 
flexible. If the size ratio between the object and the instance primitives is large enough, then deformations 
of the object are actually realized as differential translation of the primitives. Spheres are the best 
examples of a volume representation with this property. CONVERSIONS BETWEEN REPRESENTATIONS Converting 
an object description in one representation into a description in another is motivated by several factors: 
 * A desired operation may be easier to perform in another representation. The data may have been obtained 
(by design or chanee) in a form different from that desired or required in the particular application. 
 Display requirements may make it efficient to simplify a representation at low resolution.  The first 
factor was already encountered in discussing volume measurement, and other appli- cations will be indicated 
later in this section. The second factor is often forced upon the user by the availability of a particular 
input medium. The last has been considered in the case where the user provides explicit, and possibly 
varying descriptions of an object at different display 155 resolutions (20). Table II shows possible 
or h~own methods for converting between each representation. Since these are too numerous to discuss 
individu- ally, we will try to examine trends and implications of a more global nature. Checking through 
the columns of Table II, it can be seen that there are certain "universal recipient" representations 
into which a de- scription in any other system may be converted. Both cellular spaces and 3D surface 
points enjoy this property, with cellular spaces having the simplest, most efficient, and most uniform 
conver- sion process: variations on a spatial filling algorithm which detects cells between object surfaces 
or inside object volumes. (For surface representations an additional post-process may be used to fill 
completely enclosed cavities, but fortunately the topology of cellular spaces is readily computed.) 
Conversions into 3D surface points can proceed as for cellular spaces (but no filling is performed), 
or by a variety of methods including interpolation between surface vertices of a polygon network or 
curved surface patch, analytic solution of quadric patch surface formulas, or detection of points on 
the surface of one primitive volume not contained within any other. The next "universal recipient" is 
the polygonal network. This is reasonable since the network resembles a set of surface points where connection 
information is retained. The methods again range from simple interpolation to polyhedral union, often 
for some pre-determJmedpolyhedral network for a geometric form (40). There is a second set of "universal 
recipients" consisting of curved surface patches and spheres. These are distinguished by being accessible 
primarily through 3D surface points, that is, an intermediate conversion is required. The curved patches 
are obtained by numerically fitting patches to data points (11,44,48), but segmentation of the object 
into patches may be difficult. Spheres, however, offer a different approach based on an iterative algorithnwhich 
fits spheres to surface points (5,39). Spheres are fit so as to be tangent to at least one surface point 
but not contain any other surface point. The maximum and minimum sizes of the spheres and the tolerance 
of fit can be specified by the user. Figure 6 shows one possible decomposition of an upright cone into 
overlapping spheres. Conversions from surface models into volume models, when attempted, are often based 
on scene analysis techniques. A spherical representationmay offe~ a less ad hoc alternative, since suitable 
clusters of spheres may be extracted and described in terms of the desired volume models. For example, 
by associating overlapping spheres whose centers lie along a straight line, a generalized cylinder (I) 
may be obtained whose cross-section (the sphere radii) varies along the axis. Allowing the center line 
to depart from a straight line yields a generalized cylinder with a curved axis. By interpolating between 
the contributing radii, the boundary can be described by a piecewise linear function, or fit to a cubic 
or spline curve. It is interesting that there are no "universal donors," that is, representations easily 
converted into any other. In general, the volume models are preferred since their surfaces are readily 
converted by a table look-up to a canonical polygonal network, curved patch decomposition, or set of 
surface points. Most of these conversions involve a loss of information since volume models are "higher 
level" descriptions. IMPLICATIONS FOR COMPUTER VISION For computer vision there are three primary sources 
of real 3D data: * 3D surface points  * 3D cells  * 2D (parallel) sections  For example, 3D surface 
points may be obtained by cameras and range finders (i), perspective or stereo reconstruction (22,44), 
or motion parallax (38). Cellular data (Fig. 4) may be obtained from tomographic scanners (35). Surface 
points may also be obtained from successive, parallel 2D sections through an object, where the object 
boundaries are extracted automatically or by hand (Fig. i). Suppose this data represents a curved, irregular, 
or otherwise complex object, and further suppose that 3D cellular data is available. A possible strategy 
for the description of this object would be to convert the cellular description into 3D surface points, 
use these to compute a spherical deeomposition, and finally match sets of spheres to a vocabulary of 
geometric forms such as generalized cylinders and ellipsoids in order to capture the shape properties 
of the object. This hierarchy allows us to choose an appropriate representation for each particular operation 
desired. Taking the union of the rows in Table I corresponding to these four representations ,the hierarchy 
yields considerable ease and flexibility in measurement and manipulation. Moreover, since each of the 
conversions is reversible (though not without a certain amount of information loss), not all need be 
stored. A reasonable trade-off in storage cost is to keep the spheres and the higher level volumes, reconstructing 
the cellular or surface data when necessary. (It is more expensive to find the spheres from the surface 
data than vice versa. ) Given another data source for 3D surface points, the same arrangement can be 
used since only the lowest level representation (3D cells)is lacking. It is a simple matter, however, 
to reconstruct this level directly from the spheres by filling appropriately scaled cellular space. 
The basis for this pivotal role of the spherical representation is that it generalizes the two-dimensional 
medial axis transform (13,14, 15) to three-dimensional, non-discrete (non- cellular) spaces. The 2D transform 
may be defined as the locus of centers of all maximal discs within the object (Fig. 7); the 3D transform 
is the locus of centers of all maximal spheres within the object. In two dimensions the medial axis is 
either a point or a curve; in three dimensions it  156 is either a point, curve, or surface. Because 
the medial surface is unique for each object shape, a spherical decomposition represents a one-to-one 
mapping from surface points (shape) to volume and vice-versa. Although the three-dimensional generalization 
of the medial axis to the medial surface was also recognized by Blum (14), no algorithm was proposed 
for its extraction. Limits on the medial transform primarily arose from the cellular spaces in which 
the objects were embedded. The sphere decomposition algorithn removes this limitation by dealing with 
real- valued data points. Figure 8 (5) shows points on the medial surface of an upright cone. The linear 
sequence of points lies along the axis of the cone and the "flare" surface arises from the flat base. 
 Another way to look at the hierarchy of representations is to examine the psychological findings. Miller 
and Johnson-Laird (37) describe object primitives in terms of surface properties, such as convex, concave, 
planar, corner, and edge. The volume representation involves features in space which are ~variant under 
translation, rotation, and dilation. The medial surface is one such invariant feature, although psychologists 
 (19) talk about symmetry planes: a horizontal ground plane and two vertical planes: right-left and front-back. 
 The basic tendency in human vision is to prefer regularity, for both its transformation invarianee and 
its data reduction capabilities. For descriptive purposes, people seem to prefer to use single labels 
as a shorthand notation describing complex structures. Thus for a round object, a sphere may provide 
a coarse description~ while for an elongated object a cylinder would be preferred. The description therefore 
depends upon the degree of detail to be preserved or eliminated, and this depends upon the basic resolution 
of the data and the accuracy desired in the description. The choice of representation is therefore dictated 
by the intended use, just as display is the intended use and motivation in Clark's hierarchic system 
(20). CONCLUSIONS We have presented an overview of several different three-dimensional object modelling 
schemes and have compared them on the basis of operations which can be performed on themand conversions 
which can be made between them. The division into volume and surface models proves useful in relating 
the different levels of representation that are often found in a scene analysis system. Certain representations, 
such as cellular spaces, surface points, spheres, and geometric forms, are distinguished for certain 
roles. Many interesting connections between computer graphics and computer vision have been demonstrated, 
additional conversions are suggested, andmore automatic representation may become possible. ACKNOWLEDGEMENTS 
 Many of these ideas arose from lengthy discussions with our students: Joseph O'Rourke, Barry Soroka, 
and David Bourne. The authors also wish to gratefully acknowledge the support of NSF Grants MCS-76-19464 
and MCS-76-19465. REFERENCES I. Agin, G.J., and Binford, T.O. Computer description of curved objects. 
Proc. IJCAI (1973), 629-640. 2. Badler, N.I. An interactive progran~/ng system for three-dimensional 
discrete topology. Unpublished report, University of Toronto (1972).  3. Badler, N.I,~ and O'Rourke, 
J. A representa- tion and display system for the human body and other three-dimensional curved objects. 
University of Pennsylvania, Department of Computer and Information Science, Technical Report (February 
1977).  4. Badler, N.I., and O'Rourke, J. A human body modelling system for motion studies. University 
of Pennsylvania, Department of Computer and Information Science, Technieal Report (August 1977).  5. 
Badler, N.I. and 0'Rourke, J. Decomposition of three-dimensional objects into spheres. IEEE Pattern Recognition 
and Artif. Intelli- gence Workshop, Princeton, New Jersey (1978).  6. Bajcsy, R., and Soroka, B. Steps 
towards the representation of complex three-dimensional objects. Proc. IJCAI (1977), 596.  7. Bajcsy; 
R., and Bourne, D. Computer Recon- structlon of continuous morphology from discrete slices - the interpolation 
problem in anatomy. IEEE Pattern Recog~nition and  Artificial Intelligence Workshop, Princeton, New 
Jersey (1978).  8. Bajcsy, R., and Winston, I. A computer system for reconstruction and display of 
the macrostructure of brain from radiographs of serial sections. Proc. BIOSIGMA '78 (April 1978), Paris, 
262-266.  9. Bamnhill, R.E., and Riesenfeld, R.F. Computer- Aided Geometric Design. Academic Press, 
New York, 1974.  i0. Bam]zart , B.G. Geometric modelling for computer vision. Stanford University, 
Department of Computer Science, Technical Report (October 1974). II. Bezier, P. Numerical Control Mathematics 
and Applications. John Wiley and Sons, Jew York, 1972 12. Blinn, J. personnal conmunication, 1977. 
 13. Blum, H. A transformation for extracting new descriptors of shape. In Models for the Perception 
of Speech and Visual Fopm,--- Dunn, Walthen (Ed.), MIT Press, Cambridge, Mass. (1967), 362-380.  14. 
Blum, H. Biological shape and visual science.  J. Theor. Biology 38 (1973), 205-287. 157  15. Blum, 
H., and Nagel, R. Shape description 32. using weighted symmetric axis features. Proc. IEEE Pattern Recognition 
and Image Processing Conf., Rennselaer Polytechnic Inst. (June 33. 1977), 203-215.  16. Braid, I.C. 
The synthesis of solids bounded by many faces. CACM 18 (April 1975), 209-216.  34.  17. Catmull, E. 
A system for computer generated movies. Proc. ACMAnnual Conf., vol. i (1972), 422-431.  18. Catmull, 
E. Computer display of curved 35. surfaces. Proc. IEEE Conf. on Computer Graphics, Pattern Recognition, 
and Data Structure, Los Angeles, California (May 1975), 11-17. 36.  19. Clark, H.H. Space, time, semantics 
and child. In Cognitive Development and the_Acquisition of language, Moore, T.E. (Ed.), Aeademde Press, 
New York, 1973, 27-144. 37.  20. Clark, J.H. Hierarchical geometric models for visible surface algorithms. 
CACM 19 (October 1976), 547-554. 38.  21. Comba, P.G. A procedure for detecting inter- sections of three-dimensional 
objects. JACM 15 (July 1968), 354-366. 39.  22. Duda, R.0., and Hart, P.E. Pattern Classifi- cation 
and Scene Analysis. John Wiley "&#38; Sons, New York, 1972.  23. Falk, G. Interpretation of imperfect 
line 40. data as a three-dimensional scene. Artifi- cial Intelligence 3 (1972), 101-144.  41.  24. 
Fetter, W.A. A human figure computer graphics development. Proc. Eurocomp  Congress, Online, Brmmel, 
England (May %76-488. 42.  25. French, A.S. Computer simulation of space- filling molecular models. 
IEEE Trans. Computers C-26 (1977), 1026-1028. 43.  26. Fuchs, H., Kedem, Z.M., and Uselton, S.P. Optimal 
surface reconstruction from planar contours. CACM 20 (October 1977), 693-702.  27. Goldstein, R.A., 
and Nagel, R. 3-D visual 44. simulation. Simulation 16 (January 1971), 25-30.  28. Gouraud, H. Continuous 
shading of curved 45. surfaces. IEEE Trans. Computer s C-20 (June 1971), 623-629.  46.  29. Gray, 
S.B. Local properties of binary ! images in two and three dimensions. Informa- tion International Report 
(1970).  30. Herbison-Evans, D. Animated cartoons by 47. computers using ellipsoids. Proc. 6th Australian 
Computer Conf., Sydney, Austra~/ia (May 197'~), 811-823.  48.  31. Horn, B.K.P. Shape from shading. 
MIT, Project MAC Report TR-79 (November 1970).   158 Kelly, M.D. Edge detection by computer using 
 planning. Machine Intelligence ' 6 (1971). Knowlton, K., and Cher~ L. ATOMS - A T~ee-D Opaque Molecular 
System - for color pictures of space-filling or ball-and-stick models. Computers and Chemistry i (1977), 
161-166. Levin, J. A parametric algorithm for dmawing pictures of solid objects composed of quadric 
surfaces. CACM i0 (October 1976), 555-563. Levinthal, C., and Ware, R. Three-dimensional reconstruction 
from serial sections. Nature 236 (March 1972), 207-210. Marr, D., and Nishihara, H.K. Representation 
 and recognition of the spatial organization of three-dimensional shapes. MIT, AI Memo 377 (1976). 
Miller, G., and Johnson-Laird, P. language and Perception. Belknap Press of Harvard University Press, 
Cambridge, Mass., 1976. Nevatia, R. Depth measurement by motion stereo. ComPuter Graphics and Image 
Processing 5 (1976), 203-214. O'Rourke, J. Representation and display of t~ee-dimensional objects with 
spheres. University of Pennsylvania, Department of Computer and Information Science, Technical Report 
(August 1977 ). Parent, R.E. A system for sculpting 3-D data. Computer Graphics ii (Sun, her 1977), 
138-147. Phong, Bui Tuong. Illumination for computer generated images. CACM 18 (June 1975), 311- 317. 
 Potter, T.E., and Willmert, K.D. Three- dimensional human display model. Computer Graphics 9 (Spring 
1975),102-110. Roberts, L.G. Machine perception of three- dimensional solids. In Optical and Electro- 
 Optical Information Pro6-ess~ng, Tippell, J.T., et al. (Eds.), MIT Press, Cambridge, Mass., 1965, 
159-197. Rogers, D.F., and Adams, J.A. Mathematical Elements for ComPuter Graphics. MeGraw-Hill, New 
York 1976. Graf/Pen Sonic Digitizer. Science Accessories Corporation, Southport, Conn. 1970. Tanimoto, 
S., and Pavlidis, T. A hierarchical data structure for picture processing. Computer Graphics and Image 
Process'_~ng 4 (1975), 104-119. Voelcker, H.B., and Requicha, A.A.G. Geometric modeling of mechanical 
parts and processes. Computer i0 (December 1977), 48-57. Wu, Sheng-Chuan, Abel, J.F., and Green~,D. 
 An interactive computer graphics approach to surface representation..CACM 20 (October 1977), 703-712. 
 *Depends on finding cavities formed by composite objects. **Depends on method of computing union. ***Depends 
on method of computing intersection. ****Result may not be primitive; may be represented in another 
form. o b-t u3 ~2 o o3 2: o H o o co I i )O  i i. ~ 4 fj I H )<3 coho i o[M r--I~ ~u I~q O Z o  
H P~ W u3  54 a -7 O H Z O  H 5 5 o9 0 o~ >1 (D D. 0 O3 D Z~ ~M O E~ I--4 O9 f-'-t H CO 
 O9 i!2 ° 159  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807385</article_id>
		<sort_key>167</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[On display of space filling atomic models in real-time]]></title>
		<page_from>167</page_from>
		<page_to>172</page_to>
		<doi_number>10.1145/800248.807385</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807385</url>
		<abstract>
			<par><![CDATA[<p>Earlier work on real-time display of planar polygonal three-dimensional object scenes is extended to the inclusion of repetitive curved surfaces. In earlier work the visible scene components were calculated and reduced to scan line encoded image segments to generate real-time cartoons. That work was limited to visible planar surface elements because of the display algorithms employed. Display time is limited to 33 ms so that scan-interlaced TV may be used. Curved surfaces would normally be approximated by a large number of facets; however, Mach effect's faceting of the surface will occur for all but the simplest cases. Point by point curved surface shading is examined in detail so that special hardware may be defined for displaying the visible surface parts in 33 ms. The hardware concepts employed can be extended to other simple curvatures that appear repeatedly in a visible scene. CONTENT INDICATORS: 3.13, 6.22, 6.35, 6.4, 3.89.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39083938</person_id>
				<author_profile_id><![CDATA[81100545248]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Staudhammer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Electrical Engineering Department, North Carolina State University, Raleigh, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Staudhammer, "Computer generation of real-time colored three-dimensional objects", Proc. 7th Hawaii Conf. on Inf. Sci., January 1974.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J.F. Eastman and J. Staudhammer, "Display of 3-D object images", Proc. 2nd Symp. on Comp. Arch., January 1975.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D.J. Ogden and J. Staudhammer, "Computer graphics for 3-D object images", Comp. &amp; Graphics, vol. 1, #1, June 1975.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Staudhammer, "Display of multi-dimensional objects (Four and higher dimensions)", Computer Graphics, vol. 9, #2, Summer 1976.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563283</ref_obj_id>
				<ref_obj_pid>965143</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A.J. Myers, "A digital video information storage &amp; retrieval system", Comp. Graphics, vol. 10, #3, Summer 1976.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J.F. Eastman, "An efficient scan conversion and hidden surface removal algorithm", Computers &amp; Graphics, vol. 1, #2/3, 1975.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J.N. England, et.al., "A display-optimized processor", Proc. 2nd Symp. on Comp. Architecture, January 1975.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Staudhammer, "Software for real-time image generation", Proc. COMPSAC-77, November 1977.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563870</ref_obj_id>
				<ref_obj_pid>965141</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[R.J. Hackathorn, "ANIMA-II: A 3-D color animation system", Computer Graphics, vol. 11, #2, Summer 1977.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[C. Csuri, "3-D Computer animation", Advances in Computers, Acad. Press, 1977.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>965141</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J.F. Blinn, "Models of light reflection for computer synthesized pictures", Comp. Graphics, vol. 11, #2, Summer 1977.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J.N. England, "Interactively generating computer graphics descriptions of physical curved surface objects", Proc. of this conference.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[H. Gouraud, "Computer display of curved surfaces", Univ. of Utah, UTEC-CSc-71-113, June 1971.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807363</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[T. Whitted, "A scan line algorithm for computer display of curved surfaces", Proc. of this conference.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[E.A. Catmull, "Computer display of curved surfaces", Proc. IEEE Conf. on Comp. Graphics, May 1975.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[B.T. Phong, "Illumination for computer generated images", Comm. ACM, vol. 18, #6, June 1975.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[O. Kennard et.al., "Molecular structures and dimensions", Crystallographic Data Centre, Univ. Chem. Lab, Cambridge, England, 1972.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[A. Rich and S.H. Kim, "The 3-D structure of transfer RNA", Sci. Amer., Jan 78.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>906110</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[W.V. Wright, "An interactive computer graphics system for molecular studies", PhD diss., Univ. of NC, Chapel Hill, 1972.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[J.J. Batter and F.P. Brooks, Jr., "GROPE-1: A computer display to the sense of feel", Proc. IFIP, 1972.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>908596</ref_obj_id>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[E.G. Britton, "A methodology for ergonomic design of interactive computer graphic systems and its application to crystallography", PhD diss., Univ. of NC, Chapel Hill, 1977.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[H.R. Luxenberg and R.L. Kuehn, "Display systems engineering", McGraw-Hill, Book Co., 1968.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ON DISPLAY OF SPACE FILLING ATOMIC MODELS IN REAL-TIME* John Staudhammer Electrical Engineering Department 
North Carolina State University Raleigh, NC 27650 Abstract Earlier work on real-time display of planar 
polygonal three-dimensional object scenes is extended to the inclusion of repetitive curved surfaces. 
In earlier work the visible scene components were calculated and reduced to scan line encoded image segments 
to generate real-time cartoons. That work was limited to visible planar surface elements because of the 
display algorithms employed. Display time is limited to 33 ms so that scan- interlaced TV may be used. 
Curved surfaces would normally be approximated by a large number of facets; however, Mach effect's faceting 
of the surface will occur for all but the simplest cases. Point by point curved surface shading is examined 
in detail so that special hardware may be defined for displaying the visible surface parts in 33 ms. 
The hardware concepts employed can be extended to other simple curvatures that appear repeatedly in a 
visible scene. CONTENT INDICATORS: 3.13, 6.22, 6.35, 6.4, 3.89. i. Introduction Over the past several 
years we have been concerned with the representation, manipulation and display of three-dimen- sional 
objects, with the production of realistic display effects with minicom- puters combined with television 
technology and with the exploration of algorithms necessary for the quick production of such images. 
This work has resulted in static image displays of high complexity using a large minicomputer and a simple 
scan- line generator [1,2,3,4]. A continuation of that work led to the design and construction of a much 
faster device capable of producing real-time animated image sequences recordable on a normal television 
recorder and displayable on a normal color TV monitor [5]. Work has continued on the exploration of special 
algorithms and hardware [6,7] necessary for fast display of complex scenes. Using the hardware developed 
in this work, a system for interactively generating color- TV cartoons was developed and demonstrated 
 [8,9,10]. All of the scenes produced by this work were limited to objects made up of collections of 
opaque planar polygons [1,3]; special software packages were developed for the creation of these con- 
structs [3] and for their motion in 3-space [5]. In these routines the visible scene is calculated not 
in real-time, and *This work was supported by Grant MCS75- 06599, Div. of Computer Systems Design, National 
Science Foundation. the visible parts are encoded as a set of color bars of constant hue values which 
are expanded to a recordable TV signal by a special scan-line generator [5,7]. Generally curved surfaces 
must be approximated by a large number of facets and this surface approximation must be passed through 
the established display process. Since the execution time for the hidden surface elimination and scan 
line conversion algorithms depend strongly on the number of facets that must be handled, the number of 
approximating facets will have a very marked effect on the speed of the display generation process. To 
achieve realistic surface approximations objects are often described by several hundred facets [3,9,10]. 
 An extension of this earlier work to the display of atomic models is described here. The impetus for 
this work came from results achieved in the Molecular Graphics Laboratory of the University of North 
Carolina [19-21] in aiding the visualization of large complex organic molecules. The work in that laboratory 
concentrated on interactive modeling of the molecule displayed as a set of inter- atomic bonds. In that 
work a vector drawing display was quite adequate. How- ever, the resultant molecular models are difficult 
to visualize; a far better visualization may be obtained from a space-filling model, such as the one 
shown in Figure 5 [18]. This latter model is 167 built mechanically and photographed for the illustration. 
A computer-display rendering of such models needs to generate the shading required by many spherical 
 surface segments. The work reported here concerns the rendering of such models by computer. Additionally, 
the images are to be dis- played (but not necessarily calculated) in 33 ms so that video technology can 
be used to generate an animated sequence for aiding in the visualization of the molecule. The system 
described is general in nature so that arbitrary molecular structures may be displayed. Data for these 
models may come from standard crystallographic sources [17]. These may also contain stereo-image pairs 
which can immediately be used to verify the degree of correctness of the input data. The display process 
is made compatible with a more general animation system [14] and allows the intermixing of spherical 
curved surfaces with the display of planar polygon objects [3,10]. Various illumina- tion models may 
be employed [11,16] for enhancing visual effects. The 3-D display space is characterized by: x - Axis: 
from left (-) to right (+); y - Axis; from bottom (-) to top (+); z - Axis: from the observer who is 
located in the direction of the negative z-zxis. The display space for the molecular model will be 
the cube limited by +i and -i in all three axes. The scan display used is a nominal 512x512 scan-interlaced 
color TV with a color resolution of 5 bits each in Red, Green and Blue (giving a total of 32,768 possible 
colors). An idea of the desired image complex- ity may be gleaned by examining Figure 5. This image 
occupies approximately 400 scan lines at an average of 230 display points occupied by the atomic model. 
There are about 1000 spheres visible; they occupy 92000 points of the available 262,144 (=512x512) points. 
The "average atom" spans about i0 scan lines and is i0 pixels wide. On the average there are 20 atoms 
on a scan line. Since a scan line repeti- tion rate is approximately 63 ~s, there are about 3 ~s allowable 
for outputting data for each atom to the scan line generator if each scan line is indepen- dently defined. 
 2. Faceted Objects The vast majority of curved surface rendering techniques currently in use involve 
approximating the surface with many facets. A sphere of about 100 pixels in diameter having about i00 
facets exhibits a markedly mottled surface, appearing similar to a golf ball [i]. A smooth surface can 
be attained only when an unreasonably large number of facets are employed. The reason faceted objects 
are used so extensively in computer graphics is largely due to the fact that visibility may be calculated 
for planar polygons with rela- tive ease [6]. Regardless of the spatial orientation of a visible polygonal 
surface its color will be uniform over its entire visible projection; hence on a given scan line a polygon 
yields a bar of unchanging coloring. This fact was used to advantage in creating a fast display system 
[3] which ultimately was developed to create real-time TV imagery of complex faceted object scenes [5,9,10]. 
 However, the representation of spheres by a set of color bars requires too many facets. Basically the 
human eye is a very good differentiator of rather minute color changes. The eye will perceive an edge 
where two surfaces having very nearly equal colors meet. This effect, known as the Mach effect [22], 
works directly against using a limited number of color bars in rendering a spherical surface. Even though 
approximating the spherical surface with i00 facets is probably inade- quate [i], the molecular model 
shown in Figure 2 would require about 1800 facets, or about 6000 edges, or about 18,000 words (of 16 
bits each) for description. Clearly this is a very complicated data structure for such a relatively modest 
molecule. The use of faceted objects does, however, yield visible object scenes describable by color 
run-lengths on each scan line. Moreover, even for fairly complicated scenes the number of color bars 
is small enough to be passed to the scan line generator at rates consistent with the TV signal repetition 
rate (30 times a second.) The facets of a polygonal object description represent surface primitives which 
can be expanded to a visible scene with modest hardware (chiefly counters, see [2,7]). The representation 
of atoms by spheres leads to circle-arcs as the visible surface primitives and used in a simple scan-line 
generator. The basic data required by a faceted- object scan-line generator are color and run-length 
combinations. Color is normally pre-stored in a 256 byte RAM (one for each primary color); run-lengths 
may be limited to 256 pixels or less. Hence it is possible to define a run-length encoded color bar with 
two bytes of data. 3. Linear Shading A large improvement over the run- length encoded constant color 
images is obtained by linearly interpolating shades of color between a starting hue value and an end 
hue value. This technique was used by Gouraud [13] to restore a measure of smoothness to images of curved 
surfaces approximated by many near-planar polygons. While the surface may appear smoothly shaded, the 
surface boundaries remain 168 polygonal. Also any silhouettes formed by the objects are also polygonal. 
 A constant color corresponds to a constant surface slope in th~x-z plane; a linear color change between 
two points corresponds roughly to a quadratic surface. Hence linear color interpolation represents roughly 
an approximation of the surface by quadratic functions. Two methods of approximation may be used easily: 
develop- ment of approximating linear color-change functions for given surfaces, and adapta- tion of 
polygonal surface patches to linear shading. The scan line is generated in left-to- right order. Three 
cases must be distin- guished in smoothing facets of one object together: (i) the facet is on the left 
edge of the visible part; (2) the facet has a left neighbor and a right neighbor; and (3) the facet is 
on the right edge of the visi- ble part. In case 2 the shading is varied linearly between the centers 
of the adja- cent facets; in the other cases the shading is varied linearly between the edge of the visible 
part and the center of the interior facet of the object. Of course tags must be used in the data description 
to smooth only the required facets. For example, in Figure 2 care must be taken not to smooth together 
parts of the two identically colored spheres ("atoms") lying on the same scan line. In essence linear 
shading requires two sets of counters --one for the run-length, the other for the variation of the 
color during this run-length. The color and run- length combination still requires two bytes of data; 
the color changes are usually subtle and also require two bytes of (microcoded) data. Hence unless 
half as many or fewer linear color changes are sufficient to represent a surface as well as a faceted 
description, the linear scheme is no more efficient in representing the curved object. 4. Spherical 
Surfaces A spherical surface is the easiest doubly-curved surface to display. For every scan line only 
the shading for a circular arc lying in the x-z plane need to be calculated. The shading of the surface 
is a function of the angle of the surface normal with the z-axis (the direction to the observer.) The 
variation in shading on every scan line is the same function at every scan line scaled to the diameter 
of the great circle formed by the plane of the scan line parallel to the x-z plane. Hence one may pre-calculate 
the shading function of a unit circle (scaled here to 256 pixels) and then select the appropri- ately 
scaled points. The absolute value of the color is then obtained by multfply- ing this shading function 
for each of the primary colors with the color of the pixel lying at the meridian closest to the obser- 
 ver. Since this shade will also vary from the equator to~.ard the poles, this display system requires 
that the meridian color be specified for each visible circular surface segment. Because the color of 
the meridian can vary but slightly from scan line to scan line, the variation is specified as a multiplier 
to the object color (the color looking at the surface normally.) This object color is obtained from a 
color palette which is loaded with the components of the primary colors corresponding to the atom-number 
used in making up the molecular structure list. Visibility of the spherical segments is calculated for 
each scan line separate- ly. The molecule is defined by three space coordinates of its atoms and each 
atom is specified by its diameter and a display color. Initially the molecule is placed in proper orientation 
using an interactive vector drawing system. At this stage each atom is represented by a planar figure 
in three-space simulating the outline and appearance of a sphere. No attempt is made to calculate visibility. 
 The spatial orientation could be aided by a stereoscopic image pair [12]. Here the atoms should be represented 
by half-shells, similar to a nut shell, which is oriented full head-on to the observer. Use of such a 
shell (for example one-half of a regular dodecahedron) helps in main- taining a simple, yet effective, 
display simulating a sphere. Once the molecule is oriented properly a scan conversion process is invoked 
to calculate the visible parts of the display. The display manipu- lation and scan-image production system 
is outlined in Figure i. The entire molecular structure is sorted in y-order first re- sulting in a list 
of atom numbers which must be considered at each scan line. Next the depth (z-value) for each pixel location 
for each active atom (those in the y- sorted list) is calculated. Visibility of each point is determined 
by a z-buffer which compares the depth of the newly calculated point with the currently- closest point 
saved in the buffer. If the new point is closer (i.e., it is visible) the color for the new point is 
calculated and stored in the visible-point buffer to- gether with the atom-number. when all atoms intersecting 
the given scan line have been calculated the z-buffer contains the visible points of the image scan line. 
These are then displayed directly. An associated buffer contains the atom-numbers of the visible points. 
Each portion of each visible atom may then be scaled to a circle-arc (pre-computed shading function) 
with the following parameters: (i) the atom-color; (2) the meridian color, a multiplier for the atom- 
color; (3) the number of visible points; (4) the starting coordinate for reading out the circle-arc 
shading function; and  (5) the increments to be taken in the  169 shading function (a 256 point function). 
 Additionally Item 1 will contain a flag indicating a circle-shading function to distinguish from a 
polygonal surface color-bar and run-length. Each of these parameters can be represented by one byte 
 of data. For the molecular model shown in Figure 5 there would be about i00 bytes of data required 
for the average scan line. Since the figure occupies about 400 scan lines, there are 40,000 bytes re 
cg/ired for the entire image. A representative single frame of the display is shown in Figure 2. The 
image shows a surface shading function represen- ting diffuse lighting. One can also vary the surface 
shading to include other lighting schemes. For example, adding highlights to the same display results 
in the image shown in Figure 3. Stereoscopic image pairs could be generated to further enhance depth 
percep- tion of the molecular model. 5. Visualization with Motion One of the strongest depth cues for 
an object is relative motion of its parts as the object is moved relative to a fixed- position observer. 
To produce an animation sequence without photography a real-time TV signal is produced which can generate 
a monitor display of the model. As in the polygonal-object animation hardware [8,9, i0] the image complexity 
must be limited to data rates compatible with the transfer rates attainable from a mass storage device. 
 Basically animation is achieved by the same scheme as used in the ANIMA system [9]. The motion of the 
object is composed using a vector drawing representation of the molecule on an interactive vector display. 
Translations, rotations and size changes (zooming) can be readily checked and com- posed. Since all 
atoms are drawn in this mode a very busy and confusing image may result and great care must be exercised 
in interpreting such drawings. As the number of atoms in the molecular model increases the representation 
of parts of the molecule (either the atoms themselves or groups of atoms) may have to be changed to 
be able to draw an understandable image. For example the molecule (Mg Ni3 B~)3 represented in Figure 
2 may use dodecahedron half-shells without introducing much confusion or slow- ing the display rate. 
On the other hand, the yeast phenylalanine transfer-RNA mole- cule [18] shown in Figure 5 can represent 
each atom by at most a single dot in this drawing mode. A file of the animation primitives (translations, 
rotation, size changes) is built at this time and stored in an anima- tion file as shown in Figure 
i. Typical frames of the animation sequence may be viewed (and photographed, as was done for Fig. 2). 
For playback of the animation sequence in real-time the five parameters indicated in the previous section 
are determined for each visible part of each atom on each scan line. A file of these is the Visible 
Segment File; the overall scheme is indicated in Figure 4. The Visible Segments reside on a disk with 
a nominal transfer rate of 1 Megabyte/ second. Hence the maximum number of seg- ments that may be transferred 
to a scan line generator in 33 ms is 6600. For molecules of the complexity shown in Figure 2 there are 
no difficulties; that molecule shows 14 atoms with an average width of 70 pixels; the maximum number 
of atoms on a scan line is 4. Hence, in the worse case 20 bytes of circle-arc data must be transferred 
to a scan-line generator which must run with a repetition rate of 63 ~s. This gives an average transfer 
rate of 3 ~s/byte for the most crowded scan line. Obviously such transfer rates are very easily attained. 
 On the other hand, the tRNA molecule of Figure 5 has an average of 20 atoms/ scan line and requires 
a data rate of 600 ns/byte. The crowded display lines con- tain about 35 atoms and require a data transfer 
rate of 360 ns/byte. The entire image is made up of about 1000 atoms and requires about 50,000 bytes 
of data. At the disk data transfer rate of 1 Mbytes/ second the data stream needs 50 ms for transfer. 
Hence images of such complex atoms cannot be displayed in real-time; rather every other image frame may 
be changed only. This "double exposure" animation is used frequently to produce cheaper cartoons and 
is often acceptable for viewing. Of course a double buffering scheme is used to allow asynchronous data 
refresh and image display. The animation requires 750 Kbytes of storage for each second; a minute's worth 
of motion needs a storage capacity of 45 Mbytes. 6. Hardware for Curved Surface Imagery The foregoing 
considerations led to the design of a curved surface image generator depicted in Figure 6. The Visible 
Segment File contains a mixture of curved surface commands (see Sec. 4) and run-length codes as alluded 
to in Section 2. By using a set of memories a number of curved surface shading functions may be pre-stored. 
During display generation the appropriate function is selected. This scheme allows a quite flexible system 
for rendering different curved surfaces. For generating solid-sphere models one func- tion (the only 
one used here) has to be a circle arc. Each function is normally scaled to 256 points. 170 To maintain 
an inter-pixel time of 100 ns, the generator in Figure 6 is a pipelined device. Particularly the shading 
function memory and the three multipliers (one each for Red, Green and Blue) in the direct shading calculations 
must be no slower than i00 ns. Since the shading is an 8 bit value these 8 bit by 8 bit multipliers are 
con- figured as one stage of the pipeline; another is comprised of the shading function memories. The 
system is compatible with other hardware for displaying faceted objects and with other schemes of curved 
translucent surface generation hardware [14] being a special-purpose display generator with some flexibility 
for representing a wide class of curved surface images. 7. Summary The system described in this paper 
can generate the visible parts of a non-trivial atomic model in real-time. A data struc- ture was defined 
to allow the fast display of spherical surfaces and extended to arbitrary intersection curves for scan-line 
rendering of curved objects. The system allows the intermixture of curved and planar surfaces and represents 
an evolution in creating pleasing animated cartoons interactively. References [1] J. Staudhammer, "Computer 
generation of real-time colored three-dimensional ob- jects", Prec. 7th Hawaii Conf. on Inf. Sci., January 
1974. [2] J.F. Eastman and J. Staudhammer, "Dis- play of 3-D object images", Prec. 2nd Symp. on Comp. 
Arch., January 1975. [3] D.J. Ogden and J. Staudhammer, "Compu- ter graphics for 3-D object images", 
Comp. &#38; Graphics, vol. i, #i, June 1975. [4] J. Staudhammer, "Display of multi- dimensional objects 
(Four and higher dimensions)", Computer Graphics, vol. 9, #2, Summer 1976. [5] A.J. Myers, "A digital 
video informa- tion storage &#38; retrieval system", Comp. Graphics, vol. i0, #3, Summer 1976. [6] J.F. 
Eastman, "An efficient scan conversion and hidden surface removal algorithm", Computers &#38; Graphics, 
vol. i, #2/3, 1975. [7] J.N. England, et.al., "A display- optimized processor", Prec. 2nd Symp. on Comp. 
Architecture, January 1975. [8] J. Staudhammer, "Software for real- time image generation", Prec. COMPSAC-77, 
November 1977. [9] R.J. Hackathorn, "ANIMA-II: A 3-D color animation system", Computer Graphics, vol. 
ii, #2, Summer 1977. [10] C. Csuri, "3-D Computer animation", Advances in Computers, Acad. Press, 1977. 
 [ii] J.F. Blinn, "Models of light reflec- tion for computer synthe~d pictures", Comp. Graphics, vol. 
ii, #2, Summer 1977. [12] J.N. England, "Interactively genera- ting computer graphics descriptions of 
physical curved surface objects", Prec. of this conference. [13] H. Gouraud, "Computer display of curved 
surfaces", Univ. of Utah, UTEC-CSc- 71-113, June 1971. [14] T. Whitted, "A scan line algorithm for computer 
display of curved surfaces", Prec. of this conference. [15] E.A. Catmull, "Computer display of curved 
surfaces", Prec. IEEE Conf. on Comp. Graphics, May 1975. [16] B.T. Phong, "Illumination for compu- ter 
generated images", Comm. ACM, vol. 18, #6, June 1975. [17] O. Kennard et.al., "Molecular struc- tures 
and dimensions", Crystallographic Data Centre, Univ. Chem. Lab, Cambridge, England, 1972. [18] A. Rich 
and S.H. Kim, "The 3-D struc- ture of transfer RNA", Sci. Amer., Jan 78. [19] W.V. Wright, "An interactive 
computer graphics system for molecular studies", PhD diss., Univ. of NC, Chapel Hill, 1972. [20] J.J. 
Batter and F.P. Brooks, Jr., "GROPE-l: A computer display to the sense of feel", Prec. IFIP, 1972. [21] 
E.G. Britton, "A methodology for ergo- nomic design of interactive computer gra- phic systems and its 
application to crys- tallography", PhD diss., Univ. of NC, Chapel Hill, 1977. [22] H.R. Luxenberg and 
R.L. Kuehn, "Dis- play systems engineering", McGraw-Hill, Book Co., 1968. ~splay File~ Segment Generator 
1 I Compaction  (For each Frame) L Figure 4 171  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807386</article_id>
		<sort_key>173</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[Hidden line removal for vector graphics]]></title>
		<page_from>173</page_from>
		<page_to>180</page_to>
		<doi_number>10.1145/800248.807386</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807386</url>
		<abstract>
			<par><![CDATA[<p>A system for removing hidden edges in line displays of three dimensional scenes is described. The hardware system is relatively low cost, and operates on several hundred vectors in real-time. The system consists of a graphics peripheral connected to a PDP 11/55 computer and a software package to drive the peripheral.</p> <p>As each convex object is displayed, the occlusion hardware extracts the silhouette and retains it in a one-plane &#8220;matte memory&#8221;. As subsequent objects, taken from a priority ordered list, are displayed, the vector generator tests the contents of the frame buffer at the coordinates along the vector. The contents of the matte memory determine which portions of the vector should be intensified.</p> <p>To produce the priority ordered list of objects, the software algorithm uses three ordering techniques applied selectively to different potions of the scene. One technique, used for ordering unconstrained pairs of objects is described in detail.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Clipping]]></kw>
			<kw><![CDATA[Display processor]]></kw>
			<kw><![CDATA[Hidden line removal]]></kw>
			<kw><![CDATA[Interactive graphics]]></kw>
			<kw><![CDATA[Object ordering]]></kw>
			<kw><![CDATA[Real time graphics]]></kw>
			<kw><![CDATA[Vector graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Hidden line/surface removal</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39085241</person_id>
				<author_profile_id><![CDATA[81100294917]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wein]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National rresearch Council Canada, Ottawa, Ontario K1A OR8]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14024873</person_id>
				<author_profile_id><![CDATA[81100035891]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[P.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tanner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National rresearch Council Canada, Ottawa, Ontario K1A OR8]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P330328</person_id>
				<author_profile_id><![CDATA[81100454984]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[G.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bechthold]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National rresearch Council Canada, Ottawa, Ontario K1A OR8]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P204438</person_id>
				<author_profile_id><![CDATA[81100067748]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[N.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Burtnyk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National rresearch Council Canada, Ottawa, Ontario K1A OR8]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F. Model of light reflection for computer synthesized pictures. SIGGRAPH-ACM Computer Graphics, 11,2 (July 1977), 192.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563743</ref_obj_id>
				<ref_obj_pid>563732</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Burtnyk, N., and Wein, M. Computer animation of free form images, SIGGRAPH-ACM Computer Graphics, 9,1 (June 1975), 78.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Burtnyk, N., and Wein, M. Towards a computer animating production tool. Proc. the European Computing Congress (May 1974), 1971.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Catmull, E. Computer display of curved surfaces. Proc. of the Conference on Computer Graphics, Pattern Recognition and Data Structure (May 1975).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Loutrell, P.P. A solution to the hidden-line problem for computer-drawn polyhedra. IEEE Trans. on Computers, C-19,3 (March 1970), 205.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Newell, M.E., Newell, R.G.,and Sancha, T.L. A new approach to the shaded picture problem. Proc. ACM National Conf. (1972), 443.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Newmann, W.M., and Sproull, R.F. Principles of interactive computer graphics. McGraw-Hill, 1973.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Critical design review data package for the SIMFAC scene generator subsystem. RCA Ltd., Government and Commercial Systems Division, Ste Anne de Bellevue, Quebec. Project 3501-B6.3 (April 1976).]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Roberts, L.G Machine perception of three-dimensional solids. MIT Lincoln Laboratory, TR315 (May 1963).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Schumacker, R.A., Brand, B., Gilliland, N., and Sharp, W. Study for applying computer-generated images to visual simulation. AFHRL-TR-69-14, U.S. Air Force Human Resources Laboratory (Sept. 1969).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360802</ref_obj_id>
				<ref_obj_pid>360767</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I.E., and Hodgman, G.W. Reentrant polygon clipping. ACM Communications, 17, 1 (Jan. 1974), 32.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I.E., Sproull, R.F., and Schumacker, R.A. A characterization of ten hidden-surface algorithms. Computing Surveys, 6,1 (March 1974), 1.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563865</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Szabo, N. Real time digital image generation. SIGGRAPH-ACM Computer Graphics, 11, 12 (July 1977), 35.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 HIDDEN LINE REMOVAL FOR VECTOR GRAPHICS M. WEIN, P. TANNER, G. BECHTHOLD, N. BURTNYK NATIONAL RESEARCH 
COUNCIL CANADA OTTAWA, ONTARIO. KIA OR8 ABSTRACT A system for removing hidden edges in line displays 
of three dimensional scenes is described. The hardware system is relatively low cost, and operates on 
several hundred vectors in real-time. The system consists of a graphics peripheral connected to a PDP 
11/55 computer and a software package to drive the peripheral. As each convex object is displayed, the 
occlusion hardware extracts the silhouette and retains it in a one-plane "matte memory". As subsequent 
objects, taken from a priority ordered list, are displayed, the vector generator tests the contents of 
the frame buffer at the coordinates alonq the vector. The contents of the matte memory determine which 
portions of the vector should be intensified. To produce the priority ordered list of objects, the software 
algorithm uses three ordering techniques applied selectively to different portions of the scene. One 
technique, used for ordering unconstrained pairs of objects is described in detail. Key Words and Phrases: 
clipping, display processor, hidden line removal, interactive graphics, object ordering, real time graphics, 
vector graphics. CR Categories: 8.2, 6.35. I. Introduction. in either hardware or software cost. The 
problem of eliminating hidden lines and The purpose of this development is to provi-surfaces from three 
dimensional scenes has been de a demonstration for an enhancement of an exist- under study since the 
early 1960s. The early ing engineering simulation facility. This simu-work concentrated on line drawings 
using vector lator is used at SPAR Aerospace Ltd. for the displays [5,9]. This was the "Hidden-Line" 
development of the Remote Manipulator System for problem. With the advent of shaded graphics NASA's Shuttle 
Orbiter. (The R.M.S., commonly using raster scan displays, the direction called the "space arm" is being 
built in Canada of research changed and the "Hidden-Surface by SPAR Aerospace.) The scene generation 
sub-Problem" became important. During the 1970's, system presents to the operator four views on advances 
in shaded graphics tended to be in one independent vector displays in real time. At of two areas: one 
with a goal of real time, the present the only enhancement over a transparent other striving for realism 
in pictures. The vector presentation is the removal of back edges research in real-time systems [10,13] 
led to which is done in software. simulation packages which produce effective dynamic, colored, and shaded 
images, but at 2. System Overview. a high cost. The realism research [1,4] has made great strides in 
the quality of computer A system consisting of a special purpose generated images, but at the cost of 
considera-processor and the supporting software was develop-ble processing time for each picture. The 
ed, in which hidden-line removal is achieved in original area of computer graphics -vector hardware, 
in real time. The system runs on a graphics -has received less attention. PDP-II/55 mini computer. The 
processor traverses repetitively through a display file stored in the Although line drawings produced 
by the PDP-II memory, and produces a refreshed image on vector graphics system are inferior in quality 
a random deflection vector display. During the to the realistic shaded, colored images obtain- display 
the visibility of each section of a able on raster displays, these former systems vector is determined 
by the contents of a are considerably less expensive, and require "blocking matte"-a memory array (x 
by y by 1 less computing power than do raster systems. bit). The contents of each element indicate the 
The subject of this paper is a technique to remo-presence of a nearer, and hence blocking object ve hidden 
lines in real time from scenes dis-at the corresponding point in the picture. played on such systems, 
without a large increase 173 d) matte update logic. A X Y Z (b) ,c, SJ (e) i 9 Fig.l a) transparent 
objects b) display of object A c) matte memory after display of A. d) display of A and B e) matte after 
display of A and B Fig.] depicts the functioning of the matte memory in context of displaying objects 
A and B shown in Fig. la. While the display processor traces object A on the screen (Fig.lb) the sil-houette 
of the object is extracted. This sil-houette is translated into an area matte and merged into the matte 
memory (Fig.lc). Object B is displayed next, but whenever the object enters a blocked portion of the 
screen, as determined by the contents of the matte memory, the display beam is blanked (Fig.ld). The 
silhouette of B is then used to update the blocking matte for the next object (Fig. le). To facilitate 
the matting process, the soft-ware translates the description of the 3D scene into a list of convex objects, 
ordered by visibi- lity priority. The requirement that more complex objects be broken down into convex 
objects is imposed by the method used in hardware for updating the blocking matte. The concept of the 
system has evolved from the software techniques used in 2½D film anima-tion where a complete image is 
composed of a series of layers or planes each containing a 2D drawing [2]. The hierarchy of the planes, 
and hence the object ordering, is defined expli-citly by the animator. Since the entire process is carried 
out in a software, the silhouettes of each layer are not restricted to simple convex shapes. 3. Hardware. 
The hardware display processor (Fig.2) consists of the following components: (a) a line generator; (b) 
a high-speed matte memory; (c) a file of register pairs, a pair for every y value;  max ~/iew 1 onto$ 
 clipping Iof ~__ e at r hori back edge line I removal segments I End-of -object Update of rno te Fig.2 
System Overview The processor displays the objects in the order they occur in the edge table. The line 
gene-rator drives a vector display through a pair of digital-to-analog converters (DAC's) using the matte 
memory to control the intensity of the line. As each line is generated, the XY values along the vector 
are interpreted as row/column bit addresses for the matte memory. These bits, if set, signify that the 
object is occluded and the intensity is turned off. At the same time, the silhouette of the object being 
drawn is captured in a register file. This file contains a pair of registers for each Y value, one for 
the minimum X and one for the maximum X. During vector plotting the current X value is compared with 
the contents of both the maximum and minimum X registers that correspond to the current Y value. If the 
X value is outside the range presently stored in the registers the appropriate register is updated. After 
the last edge of an object is displayed, the matte update logic uses the information stored in the min/max 
registers to generate a blocking matte for the object just completed. This matte represents the portion 
of the screen that is covered by this object. The min/max registers corresponding to each Y value are 
tested and the portion of the matte memory representing that portion of the scene between the minimum 
X and maximum X is set. Subsequently, the matte memory contains the combined matte for all objects dis-played 
so far. The method of storing the sil-houette as a set of horizontal extents requires that each object 
be convex. 3.1 Resolution. We have recognized early in the animation work that in line images the start 
and end points of partially occluded lines need not be determined with as high an accuracy as the basic 
resolution of the display [3]. The only requirement is that the newly introduced end-point lie on the 
original line. In the software techniques used in the ani-mation work we had used a basic screen resolution 
of 1024 or 4096, whereas the blocking matte was computed on a 256-grid. In the hardware implemen-tation 
we have gone one step further and are using a 128-grid for the matte memory; the basic display uses a 
resolution of 1024. These values are re-flected in the widths of data paths shown in Fig. 3. The X,Y 
buses are I0 bits wide to the D-A converters but only 7 bits wide in the rest 174 relationships among 
the various register strobes are determined by bit positions in the micropro- gram stored in the ROM. 
Changing these relation- ships is achieved simply by reprogramming the bipolar ROM chips. X Intenslty 
2 ~ _ oJi r ................  Blank / Bright DAC' --( Silhouette II ~Vector tO I Extraction I I I0 
7 I/0 /Column Select ~doto 7 7 Row ry 7 7 Select 28Xl Vector draw and Blocking test Row Reod/Merge 
/Write egisfer I Bit propagotion J ond fill neiwork ~,sB I End-of-object Update 8RM-binary rate multiplier 
/ line generator Fig.3 Simplified Block Diagram of the system. These data paths conceptually re- present 
the data flow in the processor. The actual physical hardware paths are somewhat more elaborate in order 
to achieve a reasonable compro- mise between speed and complexity. The matte memory organization as seen 
by the occlusion testing circuit appears logically as 128 by 128 by l at the first port. The other port 
that is used for updating must have as wide a path as practical, up to the full row (128 bits), in order 
to achieve a rapid update rate. In actual fact, the memory is organized as 512 words of 32 bits each, 
so that four words are used to represent each row. The row/ column addressing is directly and easily 
trans-lated to word address and bit-in-word selection. The only disadvantage of this organization is 
that the end-of-object update must perform four iterations for each row. Left and right carry bits are 
used to propagate the matte value between adjacent words. 3.2 Control and Timing. The controller for 
the display processor performs complex sequential control functions and therefore must have capabilities 
equivalent to software loop execution and implied condi-tional branching. The controller was imple-mented 
as a sequencer driven by a microprogram in read-only memory (ROM). The controlling ROM is 48 bits wide 
and is executed at a clock period of 150 nsec. Bit fields in the 48-bit instruction are decoded in a 
conventional manner to control the data paths in the display. The ROM controller is equivalent to a simplified 
version of the control portion of a microprogrammed central processor. This approach to arranging sequential 
controllers has the obvious advantage of simplifying the organi- zation, as well as offering flexibility 
in resol-ving timing conflicts. For example, time The execution times for the operations at the microprogram 
level are shown in Table I. Taking into account the fact that the matte is tested every eighth iteration 
of the line genera-tor, the time to plot a full-screen vector is approximately 300 ~sec. This value should 
be compared to 200 ~sec for the VT-II, a low cost vector graphics peripheral available for the PDP-II 
computer. Using the values in Table I, one is able to establish a frame rate for the typical scene that 
we are using in the demonstra- tion. The scene consists of 21 objects, each occupying I/3 screen area 
and 300 edges each on average I/4 screen width. The time to display one frame is 30.2ms. Thus a frame 
rate of about 30 frames/sec can be sustained. TABLE 1 Execution Times Clock intervals Time Vector generator 
per raster unit 2 300ns Matte test per 8 raster units (includes update of min/max registers) 3 450ns 
Average plot raster unit time per 350ns End of object proces-sing access time per 32 bit matte memory 
word 6 900ns Clear matte, time per matte memory word 3 450ns While the rate is adequate, it has turned 
out to be somewhat slower than what we had initially hoped for. At the expense of a slight increase in 
complexity of the controller it is possible to shorten the plotting times to 200ns/ point. At the time 
of writing this enhancement is not being planned. 4. Software. The system was built primarily to remove 
hidden lines from the display of the Remote Manipulator System, (space arm), (Fig. 4, ref.8), a cylindrical 
payload, and a background scene. The manipulator and payload are dynamic, while the background is static. 
Restrictions on both the structure of the scene (many connected objects, linearly separable objects), 
and the derived data base,(convex objects, planar poly- gons), have a significant effect on the design 
of the software. The use of convex objects is neces-sitated by the silhouette extraction method used 
by the display processor. 175   END .EFFEGTOR--/~ A"ou o  SUPPORT . Fig.4 The Remote Manipulator 
System. The target scene is composed of the manipulator, payload, and a static background represen-ting 
the shuttle orbiter. The software must perform the following gra-phics computations: I) Point transformation, 
2) Perspective projection, 3) Back edge removal, 4) Object ordering, 5) Clipping to screen boundaries. 
 Most of these operations are, of course, well known [7]. However, the object ordering routine requires 
a novel approach to satisfy the need for high speed. 4.1 Object Ordering. The algorithm implemented in 
hardware requi- res that objects to be displayed be sorted such that any object which fully or partially 
obs-cures another object must have precedence in the object list. The order in the object list determines 
the order of vectors in the display list. The generation of these "priority lists" is described in Sutherland, 
Sproull and Schumacker {12]. To generate priority lists, one must be able to answer the question "is 
object A obscured by object B?". There are several known tech- niques which, under different conditions, 
pro- vide answers to this question. The type of ordering technique used to order a pair of objects depends 
on the existence of "cons-traints" in the relative physical motion bet- ween the objects. Pairs of convex 
objects that make up a larger object have the constraint that they do not move relative to each other; 
other pairs of objects are joined such that their relative motion is very limited. Pairs of objects that 
have no known constraints in their relative position must be ordered by more complicated and time consuming 
ordering techniques than those by which pairs of objects with rigid constraints are ordered. Three ordering 
techniques are used in our implementation: a point method, use of sepa-rating planes, and a general routine. 
Two oblong objects that are pivoted to each other, eg the upper arm and lower arm in Fig. 4, may be ordered 
using "order points". A point internal to each object is preselected such that two points are equidistant 
from the pivot. The closer object of the pair is the one containing the order point closer to the viewpoint. 
Although this method is rapid, its applicability is restricted. A useful object ordering short cut is 
the use of cluster ordering; determining the relative ordering between two "clusters" or two groups of 
objects. One advantage of the point method is that the same procedure may be used to order ei-ther two 
clusters or two objects. A second ordering method, suggested by Schumacker et al. [I0], uses preselected 
planes to determine relative ordering. If object A and object B are constrained such that there exists 
a plane that separates the two objects, then the object on the side of the front face of the plane cannot 
be obscured by the other object. Little computation is needed with this method. This technique is limited 
to pairs of objects or clusters with known separating planes. The general method is used to order any 
pair of objects having no constraints in their relative motion that would allow the use of either of 
the above methods. The structure of this routine is based on an approach taken by Newell, Newell and 
Sancha [6]. Newell et al. were concerned with ordering polygons rather than objects; parts of their algorithm 
are inappropriate for this routine. To order a pair of objects, this method per- forms a series of increasingly 
complex tests (Table 2) until one test is successful. The successful test will lead to one of five conclu-sions 
concerning the relative ordering of objects A and B. CI) A obscures B C2) B does not obscure A (either 
Cl or C3) C3) A and B do not overlap C4) A does not obscure B (either C3 or C5) C5) B obscures A. Note 
that C2 and C4 are weaker conclusions than the others; they include the possibility of overlapping. In 
most cases, these weaker con- clusions are sufficient. The first four tests are self-explanatory. The 
description of the more complicated tests, 5-7, may be clarified by a discussion of sil-houette lines 
(Table 2). The silhouette lines of a convex object, when displayed on the screen, form a convex poly- 
gon. Since each silhouette line borders on one front-facing and one back-facing polygon, these lines 
are easily identifiable. As the clipping 176  TABLE 2 TEST ACTION IF TEST RESULT TRUE POSSIBLE CONCLUSIONS: 
 I) MIN-Z-of-A > MAX-Z-of-B 2) MIN-Z-of-B > MAX-.Z-of-A 3) No X OVERLAP 4) No Y OVERLAP 5) Silhouette 
intersections exist? 6) A surrounded by silhouette of B? 7) B surrounded by silhouette of A? 8) All other 
conditions routine must distinguish between silhouette lines and non-silhouette lines (see below), little 
extra computation is needed for that routine to keep a record of the silhouette lines of each object 
for use by the general sorting routine. The silhouette intersection test (test 5), the most time consuming 
portion of the routine, computes intersections between silhouette lines from object A and the silhouette 
lines from object B in screen coordinates (Fig. 5a). If such an intersection is found, the depth at the 
intersecting point in each object is used to determine the priority. If there are no silhouette intersections, 
then either one object is surrounded by the other, or they do not overlap at all. If the test on the 
X,Y object extrema indicates the possibility of a surrounding co--o-ndTtion, the surrounder test is tried. 
 fx: Px Ns I A (a) (b) Fig.5 General Purpose Ordering Technique a) Silhouette intersection found at 
P. Order determined by comparison of depths at P. b) Z coordinate at P on object A com- pared with computed 
Z at P on line RS interior to object B. The surrounder test, (Fig. 5b) first selects a random point 
from the object that may be sur- rounded. Designate this point P with coordinates PX and Py, the potentially 
surrounded object A, and the possible surrounding object B. Intersections between the lines X.P x and 
each silhouette line of B are computed. Due to the convex nature of the silhouette, and the fact that 
the B is known to cross X=P X (from the extrema test), two such A does not obscure B B does not obscure 
A A and B do not overlap A and B do not overlap Z comparison A obscures B or B obscures A Z comparison 
A obscures B or B obscures A Z comparison A obscures B or B obscures A A and B do not overlap intersections 
that are internal to the silhouette lines will be found. If both intersections are to one side of P, 
then B does not surround A. However, if the two intersections occur on opposite sides of P, then B does 
surround A; the objects do overlap. In this case, it is possible to use the intersec- tion points computed 
above to compute the Z of a point at (Px,Py) internal to object B. This can be compared to the Z coordinate 
of P to determine the object priority. The advantage of this general method is, of course, its universality; 
any convex object in the scene may be compared to any other convex object. It does have two major drawbacks. 
It is much more time consuming than the other routines outlined above, and ordering pairs of object clusters 
though possible, is awkward. When it is desirable to order clusters with this technique, the method used 
is to compare pairs of objects, one object from each cluster, until an object that definitely obscures 
a portion of another object is discovered. If the clusters are linearly separable, it may then be concluded 
that the cluster containing the masked object is itself obscured by the other cluster. 4.2 Structured 
Object Ordering. So far, three time-saving alternatives to the general purpose ordering routine have 
been des- cribed: point object ordering, plane object ordering, and cluster ordering using one of the 
object ordering methods. These alternatives may be used only when the relationships among the objects 
allow their use. What is needed then, is a structure to control the ordering routine. This structure 
determines which objects to order, by which method, and when to use clusters of objects. Such a structure 
is completely scene dependent, a different structure (although based on the same ideas) would be needed 
for each scene. Figure 6 gives a diagrammatic representation of the hierarchical ordering tree structure 
that might be used to control the ordering of a sample six object scene. The leaves of this tree repre-sent 
objects and the nodes represent ordering methods. These nodes order the objects and/or clusters that 
are passed to them from the nodes/ leaves on the previous level, and the resulting ordered cluster of 
objects is passed on to the next level. Taking the figure as an example, node 4 represents the use of 
a separating ~lane to order objects A and B. If it is determined that B may not be obscured by A, node 
4 passes the ordered cluster {A,~ to node 3. Node 3 uses 177 another separating plane to determine ordering 
between C and {A,B}. Note that the only two pos- sible clusters that node 3 can pass to node 2 are {C,A,B} 
or {A,B,C}. Suppose the former is the case. Node 5 must order object D and E before node 2 can be processed; 
let's say that {E,D} is the result. If node 2, using the point method decides that {E,D} may obscure 
{C,A,B}, we have a partial priority list {E,D,C,A,B}. IPOtNT I PLANE , I NODE I J NODE 3 i, 5 PDINT ORDER,NG 
SEPARATION PLANE ORDERING " # I \ I \ -- Fig.6 Scene specific control structure employed to order a 
six object scene. Node 1 is a much more complicated node. When building the structure, it was determined 
that object F must be ordered independently with cluster {A,B,C} and cluster {D,E}. In the current example, 
the final priority list could be {F,E,D, C,A,B}, {E,D,F,C,A,B} or {E,D,C,A,B,F}. To describe this situation, 
node 1 contains pointers back to the nodes responsible for producing the ordered clusters with which 
F must be ordered. In this example, the first cluster appearing in the partial priority list {E,D,C,A,B} 
is {E,D}. As signified in the node description, a separating plane is used. If it is determined that 
F possibly obscures {E,D}, the final priority list is {F,E,D,C,A,B}, otherwise F is compared to the next 
cluster. In this case the point technique is used to determine whether or not F may obscure {C,A,B}. 
If it does, our final list is {E,D,F, C,A,B}. If not {E,D,C,A,B,F} is the result. It should be noted 
that assembling such a structure for a particular scene may be a diffi- cult job. At this stage, the 
structure is de-termined manually after careful investigation of the properties of the scene. A physical 
model of the scene, embodying the constraints among the objects may be of assistance. The scene for 
which the system was built consists of a foreground containing 21 convex objects, 216 points, 146 polygons, 
and 318 vectors, (Fig:4). The fixed background consists of approxi-mately I00 vectors. Two test programs 
to display the scene were tried. These programs differed only in their ordering algorithm. The first 
program used the ordering method described above while the second program used only the general purpose 
ordering technique without regard for structure in the scene. The time taken to genera-te a priority 
list on a PDP 11/55 using 300 ns memory was 25ms for the structure dependent pro- gram and 150ms for 
the structure independent trial.  4.3 Clipping. The discussion of the clipping routine is not intended 
to describe the complete clipping algorithm, but only to point out differences between this method and 
the clipping routines described by Newman and Sproull [7] and Sutherland and Hodgman [II]. These differences 
have come about by a desire for simplicity and speed in the routine, and a need to treat sil-houette 
lines in a unique fashion. The clipping is performed on the screen X,Y coordinates of the vectors after 
the perspective projection has been performed. This allows the use of the very simple and standard 2D 
clipping routine to deal with non-silhouette lines, and simplifies the clipping of silhouette lines. 
To enable the min-max registers of the hard- ware to function correctly each object must contain a closed 
convex polygon in screen X,Y coordinates that completely encloses the other lines. These silhouette lines 
will occur automatically if an object is fully on screen, a "polygon clipping" routine will ensure that 
this is the case with objects only partially on screen. However, when the clipping routine is progressing 
through the data during the clipping of an object, the silhouette lines appear in a random order. Use 
of the Sutherland-Hodgman polygon clipping algorithm would necessitate the sorting of the silhouette 
lines into an ordered sequence. To avoid this sort, an alternate, but similar polygon clipping method 
was introduced. The "Squash Clip" is a very simple algorithm. Any line that is partially off screen is 
broken into on-screen and off-screen portions. All off-screen lines and off-screen portions of lines 
are "squashed" to just outside the edge of the screen. Figure 7 shows this diagrammatically. Note that 
this method produces significant off-screen "glitches" (Fig.7b); the resulting sil-houette is not convex. 
However, the number of on screen X intercepts for each Y scan line cannot exceed 2, so the hardware can 
operate successfully. 4.4. Software Performance. Using the 318 vector picture described above, again 
on the PDP 11/55 with bipolar memory, the software is able to generate a new table of edges every 165ms, 
thus achieving a rate of six frames per second. This includes the time taken to transform the points, 
remove back edges, perform the perspective projection, clip, and order the objects. During this 165ms, 
the hardware refreshes the display several times from the double buffered display file. The frame rate 
 178 a) (a) \ ' (c) Fig.7 Squash Clip (a) single vector cliping (b),(c) -clipping of multiple vectors 
forming polygons; off screen polygon eliminated for the same picture without taking advantage of the 
structure is approximately 3 frames per s~-cond. One could assume from this test that other dynamic scenes, 
similarly complex, could be updated at a rate between 3 and 6 frames per second. 5. Conclusion. The quality 
of the visual display produced by this system is generally acceptable for applications such as the display 
of the space arm (Fig. 8). Minor deficiencies are produced by the low resolution of the matte memory 
where lines that are up to four pixels distant from a silhouette edge may be blanked. Small objects are 
especially susceptible to over-blanking, (end effector in Fig. 8a), although this is not necessarily 
disadvantageous for vector displays. When moving objects pass in front of a sta- tionary object, the 
intercepted lines change length in noticeable increments. For applica- tions where this is objectionable, 
the effect can be greatly reduced by the use of a higher resolution matte memory. Although the hardware 
runs in real time, the scene update rate is limited in our demons-tration by the computational rate of 
the PDP 11/55. This limitation does not exist in the scene generator subsystem for the space arm simulation 
facility because an array processor is used to perform the calculations. Even without the array processor, 
this hidden line technique significan- tly extends the capabilities of existing vector graphics systems 
b) // Fig. 8 Display presentation with hidden lines removed. References. 1. Biinn, J. F. Model of light 
reflection for computer synthesized pictures. SIGGRAPH-ACM Computer Graphics, 11,2 (July 1977), 192. 
 2. Burtnyk, N., and Wein, M. Computer animation of free form images, SIGGRAPH-ACM Computer Graphics, 
9,1 (June 1975), 78. 3. Burtnyk, N., and Wein, M. Towards a computer animating production tool. Proc. 
the European Computing Congress (May 1974), 1971. 4. Catmull, E. Computer display of curved surfaces. 
Proc. of the Conference on Computer Graphics, Pattern Recognition and Data Structure (May 1975). 5. 
Loutrell, P.P. A solution to the hidden-line problem for computer-drawn polyhedra. IEEE Trans. on Computers, 
C-19,3 (March 1970), 205.  6. Newell, M.E., Newell, R.G.,and Sancha, T.L. A new approach to the shaded 
picture problem. Proc. ACM National Conf. (1972), 443. 7. Newmann, W.M., and Sproull, R.F. Principles 
of interactive computer graphics. McGraw-Hill, 1973.  179 8. Critical design review data package for 
the SIMFAC scene generator subsystem. RCA Ltd., Government and Commercial Systems Division, Ste Anne 
de Bellevue, Quebec. Project 3501-B6.3 (April 1976). 9. Roberts, L.G Machine perception of three- dimensional 
solids. MIT Lincoln Laboratory, TR315 (May 1963).  lO. Schumacker, R.A., Brand, B., Gilliland, N., and 
Sharp, W. Study for applying computer- generated images to visual simulation. AFHRL-TR-6g-14, U.S. Air 
Force Human Re- sources Laboratory (Sept. 1969). II. Sutherland, I.E., and Hodgman, G.W. Reentrant polygon 
clipping. ACM Communications, 17, l (Jan. 1974),32. 12. Sutherland. I.E., Sproull, R.F., and Schumacker, 
R.A. A characterization of ten hidden-surface algorithms. Computing Surveys, 6,1 (March 1974), I. 13. 
Szabo, N. Real time digital image generation. SIGGRAPH-ACM Computer Graphics, II, 12 (July 1977), 35. 
 180    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807387</article_id>
		<sort_key>181</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[A chip for low-cost raster-scan graphic display]]></title>
		<page_from>181</page_from>
		<page_to>186</page_to>
		<doi_number>10.1145/800248.807387</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807387</url>
		<abstract>
			<par><![CDATA[<p>Lowering the cost of graphic display units for use in personnal computers and as time-sharing consoles suggests the use of TV sets. Display electronics for such a raster-scan unit will include a screen memory containing the state of all displayable points, that is up to 256 Kbits for 512 &#215; 512 B&amp;W display and more for colour applications. Technological advances in NMOS memories make such memory sizes cheaper and cheaper. The control part ensuring screen refresh, memory management, vector and character generation, and computer coupling remains very complex. A microprocessor-oriented Large-Scale-Integrated circuit including all these functions has been designed at the Ecole Normale Sup&#233;rieure.</p> <p>Versatility has guided the design, as well for screen memory organization as for microprocessor interface. Display resolution from 64 &#215; 64 to 512 &#215; 512 are possible, with any number of colours or grey levels, depending only upon the memory size. Microprocessor interface is standard: an eight bits bidirectionnal data bus, a four bits address bus, a read-write signal and an interrupt request. These signals control the vector and character generators which execute microprocessor's commands during the idle phasis of the display controller. This permits an always clean diplay and yet a decent average speed of one point every 1.3 &#956;s.</p> <p>In addition, a light-pen or crosshair circuitry allows interactive graphic use.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Character generator]]></kw>
			<kw><![CDATA[Colour graphic]]></kw>
			<kw><![CDATA[Graphic and microprocessor]]></kw>
			<kw><![CDATA[Graphic display]]></kw>
			<kw><![CDATA[Integrated circuit]]></kw>
			<kw><![CDATA[Low cost graphic]]></kw>
			<kw><![CDATA[Raster-scan display]]></kw>
			<kw><![CDATA[Screen buffer management]]></kw>
			<kw><![CDATA[Vector generator]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Input devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>B.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010391</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010600</concept_id>
				<concept_desc>CCS->Hardware->Integrated circuits</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP309599000</person_id>
				<author_profile_id><![CDATA[81546062756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Philippe]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Matherat]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ecole Normale Sup&#233;rieure, 45 Rue d'Ulm 75005 PARIS]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Kay, A. C., Microelectronics and the personnal computer. Scientific American, 237 (Sept. 1977), 231-244.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Ramtek 9000 Series, Graphic and imagery display systems.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Op Het Veld, S. J., Microprocessor-controlled video games, Euromicro 1977.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Matrox TV controller family.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Motorola catalog, VDG 467 circuit.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Matherat, P., Conception d'un circuit int&#233;gr&#233; pour la visualisation graphique, th&#232;se de 3&#232;me cycle, Institut de Programmation de Paris, Mai 1978.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Oberman, R. M. M., A flexible rate multiplier with uniform pulse distribution output, IEEE trans. on Comp., Vol. C-21, (1972), 896.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Bresenham, J. E., Algorithm for computer control of a digital plotter, IBM systems J.4, (1965), 25-30.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Horn, B. K. P., Circle generators for display devices, Computer graphics and image processing 5, (1976), 280-288.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A CHIP FOR LOW-COST RASTER-SCAN GRAPHIC DISPLAY Philippe MATHERAT, Ecole Normale Sup~rieure 45 Rue 
d'Ulm 75005 PARIS ABSTRACT Lowering the cost of graphic display units for use in personnal computers 
and as time-sharing consoles suggests the use of TV sets. Display electronics for such a raster-scan 
unit will inclu- de a screen memory containing the state of all dis- playable points, that is up to 256 
Kbits for 512 x 512 B&#38;W display and more for colour applications. Technological advances in NMOS 
memories make such memory sizes cheaper and cheaper. The control part ensuring screen refresh, memory 
management, vector and character generation, and computer coupling re- mains very complex. A microprocessor-oriented 
Large-Scale-Integrated circuit including all these functions has been designed at the Ecole Normale Sup~rieure. 
 Versatility has guided the design, as well for screen memory organization as for microprocessor interface. 
Display resolution from 64 x 64 to 512 x 512 are possible, with any number of colours or grey levels, 
depending only upon the memory size. Microprocessor interface is standard: an eight bits bidirectionnal 
data bus, a four bits address bus, a read-write signal and an interrupt request. These signals control 
the vector and character ge- nerators which execute microprocessor's commands during the idle phasis 
of the display controller. This permits an always clean diplay and yet a de- cent average speed of one 
point every 1.3 ~s. In addition, a light-pen or crosshair circui- try allows interactive graphic use. 
 KEYWORD S Integrated circuit; Graphic display; Raster- scan display; Colour graphic; Screen buffer 
ma- nagement; Vector generator; Character generator; Graphic and microprocessor; Low cost graphic. Classification: 
3.81; 6.35; 8.2. INTRODUCTION Due to technological improvements in the field of logical integrated 
circuits, one can foresee home use of cheap and nevertheless powerful compu- ters. Such computers will 
be handled by non- experts using very high level programming langua- ges, most probably graphic oriented 
as it is a na- tural method for man-machine communicatipn (i). As for now, use of graphic systems has 
been hampered by their high cost, which includes as much software development as hardware costs. Nevertheless, 
a first step towards increased use of graphic systems is the existence of a low cost graphic display 
unit allowing a wide diffusion. Such units will today permit the expansion of graphic uses of time-shared 
computers and will tomorrow be part of the home computers. Dramatic lowering of display unit cost can 
be achieved by the use of widely used parts (as TV sets) and/or very cheap parts (as LSI circuits). 
A TV set is a raster-scan unit. The curve followed by the spot does not depend on the dis- played picture. 
This accounts for the higher so- phistication of the command electronics, which ex- plains that the raster-scan 
solution has been re- jected until recently except for a few high-cost high-quality displays (2). Improvements 
in IC technology makes this solution very attractive as it is highly suited to digital implementation. 
Raster-scan has got a number of advantageous featu- res: -no limitation on the number of displayed vectors 
 -selective vector erasure capability -easy implementation of grey shades or colours -light-pen facility. 
 Moreover, a very interesting feature is that, whatever the future improvements in display screen technology 
may be (such as solid-state flat screens based on LCDs, LEDs, plasmas...), they will be adapted to TV 
requirements, due to the very large market. Graphic display units using standard TV sets will benefit 
at once of these improvements, without the least expenditure. The main reason for the complexity of 
the com- mand elctronics of raster-scan display units is that the video signal sent to the TV receiver 
is the value of the logical function "The current po- sition of the spot belongs to the displayed figu- 
re". For a 500-points horizontal resolution, this function must be evaluated in less than a hundred nanoseconds. 
This fact prevents the refresh memo- ry from being organized as a vector list, or any other structure 
of comparable complexity. For ge- neral purpose graphic units, the only solution is to have a buffer 
containing a point by point des- cription of the screen. Generating the video si- gnal then merely consists 
of sequentially reading the whole buffer once per frame. It should be no- ted that this solution can 
be avoided for special applications where the image displayed is made of repetitive patterns without 
zoom nor rotations~ It is then possible to represent the picture as two 181 lists (3): -point by point 
description of basic patterns -and coordinates of pattern occurencies. This brings an improvement only 
for very specia- lized applications. Besides the display and refresh logic, an image updating logic 
is necessary. Some display units (such as made by MATROX (4) or MOTOROLA (5)) in- clude in this logic 
only the ability to modify point by point the display. The processor control- ling the display must then 
include programmed vec- tor and character generators. In these conditions, the writing time is very high 
in comparison with the hardwired analogic generators available in cur- ent display units. All this leads 
to the definition of the control unit functions permitting the use of a standard TV set as graphic display 
unit. These functions will be implemented on a single LSI chip, excluding the image buffer and will consist 
in: (Fig.l) -image buffer reading for video signal generation -TV synchronization -wired vector and 
character generation -light-pen circuitry. Moreover, this IC should be versatile so as to lend itself 
to various applications. Screen format This chip will be processed using MOS N-channel Si-gate technology 
and should be commercialy avai- lable by mid-79. For application developments, a model simula- ting 
the logical function of the IC has been made, using standard TTL MSI chips. SCREEN BUFFER MANAGEMENT 
 Current state-of-the-art in technology makes the use of high-density sequential-access memory devices 
(65 K CCDs) rather attractive for realiza- tion of the screen buffer. But the impossibility of fast random 
writing of new points for image up- dating when using such devices has led us to pre- fer the dynamic 
Random Access Memory (now 16 Kbits per chip) which are especially suited to random writing associated 
to sequential reading (because of the need of a periodic refresh of these memo- ries). The maximum power-of-two 
resolution for a standard TV set is 512 x 512 points. For black and white pictures, this needs 16 packages 
of 16 Kbits each. For colour or grey shades applica- tions, this number of packages is to be multiplied 
by the base-two-logarithm of the number of diffe- rent states of each point. The time between two horizontaly 
neighbouring Fig.l video signal to and from TV set synchro signal li~t-pen | ,. I I vector character 
I i generator generator i I I X and Y registers ~I screen adresses buffer / x, i ........ iii I I 
g I I refresh controller I  L synchro F generator ~ I ~light-pen ~ | _j will allow 64 x 64 to 512 
x 512 points resolution. It will permit any number of colours or grey shades and will allow separate 
images to be overlaid on the display screen, with only a modification of screen buffer size. Microprocessor 
coupling capa- bility will give full versatility for linking the display unit to various processors. 
 With all these points in mind, an LSI chip has been designed at the Ecole Normale Sup~rieure. It has 
2,000 gates equivalent complexity (6). Topo- logical layout and mask design is made by SESCOSEM. points 
of the screen (512 x 512:70 ns; 256 x 256:140 ns) is usually lower than the minimum cy- cle time of 
the RAMs (around 350 ns). Thus, it is imperative to parallely read a block of memory points differing 
only by the lower bits of their horizontal address, and load them in a fast shift register for serialization. 
The screen buffer is organized in words the length of which is the num- ber of bits of the shift register: 
4 bits for 256 x 256 (=four 16 Kbits packages), 8 bits for 512 x 512 (=eight pairs of 16 Kbits packages). 
The chip outputs memory addresses in multiplexed format ac-  182 chip selects E~  F data in 4 x 
16 Kbits | write enable memories addresses jl format Ju D  "white forcing synchro sync J 4 bits 
shift-regist.~ black forcing clock seria~ output I CE video~.~ <  Fig.2:256 x 256 B&#38;W application 
I+4 carr~ fQc OU 4 to i | I . decode  I 11,1 I en ANDs read data in "~-~-t~eenable 16 x 16 Kbits 
memories ===~addresses buffer forcing black forcing 8 bits shift register  cK white 'CK serial 
carry +8 load ~K video Fi~.3:512 x 512 B&#38;W application 14 MHz synchro 183 cording to the normalized 
specification of the 16 K RAMs (and 4 K RAMs for small applications, as 64 x 64). These addresses can 
come from the display lo- gic or from the write system (Fig.2,3). On the contrary, when writing new 
points in the memory, each bit of a word must be individually ac- cessible. Four complementary address 
signals are used for this purpose, decoded for 256 x 256 and lower resolutions, and coded for 512 x 512. 
The distinction is made by the chip according to the FORMAT input. This input also modifies the functi- 
onning of the synchronizing generator, as frames must be interlaced in 512 x 512 format, and non- interlaced 
in 256 x 256 and lower resolutions. DISPLAY LOGIC Internally, the image display controller is con- 
stituted of an 18 bits counter, 15 outputs of which directly addresses the RAMs. The normalized syn- 
chronization signal is a combinatorial function of the state of the counter. WRITING SYSTEM Screen 
image refresh uses only 57% of the time (64 cycles out of 112 cycles of the external conti- nuous clock). 
The remaining time is free for wri- ting and updating the image. It is possible to write one point per 
free cycle, which gives an ave- rage time of 1.3 ~s per point (Fig.4). L~II2 cycles ~I '-- 64 Us --I 
sY c n f] [3 J Write \ I_~ ~I. Read _I  IXg -164 I ~ cycles cycles Fig.4: Detail of a line The write 
address is made of two 12 bits re- gisters, X and Y coordinates, giving an addres- sing capability of 
4096 x 4096 points. Only a part of this space is memorized and displayed, de- pending upon memory organization 
and FORMAT input pin. Points written outside the displayed area are ignored. This virtual addressing 
scheme is never- theless interesting as it automatically solves most simple window-clipping problems: 
as all figures can be described by relative addresses, changing the position of the displayed window 
consists only in changing the origin of coordinates (Fig.5). The X and Y registers are externally accessi- 
ble. All write operations are relative to the ad- dress contained in these registers which are auto- 
matically updated when using vector and character generator. VECTOR GENERATOR Vectors are defined by 
their horizontal and vertical components AX and AY, with IAXI<~255, and IAYI<-~-255. IAx I and IAYI 
are two externally acces- sible 8-bits registers. Vectors are drawn by sen- Fi~.5: Window-clipping 
I I ! actual scneen ! | addressable ~ screen ding to the chip a command specifying signs for AX and 
AY. It is also possible to draw small vectors (without modifying IAKI and IAYI) by using a sin- gle command. 
 Let us describe the method used to draw vec- tors in suP(IAXI,IAYI) cycles. In order to sim- plify, 
let us assume: (AX~Y~O {Ax#o and[Xo=Y0=0 as vector origin. Let f. be the clock frequency. Vector is 
 in drawn by incrementlng X at f. frequency and Y at frequency, with Ay In lout f =~f. .out ~LX. 
l~ The drawing time is thus mmnlmal and equal to AX. The frequency divider f. +AY/AX f. is inspired 
by in in the one presented by Oberman (7): A modulo-AX counter is incremented by AY at each clock 
cycle (AY-tuple counter). The coun- ter's overflow occurs with f _ frequency, and is as evenly distributed 
as pos~le with a digital system, as the time between two successive over- flows is q or q+l, q being 
the integer quotient of AX by AY. Such a counter can be implemented using a re- gister, 2 adders and 
a multiplex. The register is incremented by AY at each cycle excepted when overflow occurs, where it 
is incremented by AY-AX. Oberman has shown that the register should be ini- tialized to -AX/2 (Fig.6). 
 It is very interesting to compare this method with the now classical vector generation algorithm of 
Bresenham (8) (9) (Fig.7): nAx:=0 ; y:=0;' a:=-AX/2; X do plot(x,y); x+:=l; a+:=AY; if a~ then y+:=l; 
a-:=AX fi od end The a variable in this algorithm is exactly the register of the counter. We can thus 
deduce from this that the counter generates the same vec- tors than the algorithm and that all generated 
 184 Fig.6: Oberman's divider Fig.7: Bresenham's algorithm fo i I ~ AY Kin logical AX (l's complement) 
f.in CK Ay (=13 AX (=19) ~-I x)Y CK X CK Y 'CK register adder CK multiplexer Fig.8: Our vector generator 
r~Yl>I~xf out "-/ IAYI adder logical "I" IAX[ (l's complement) 185 points lie between the two lines 
of equation: X(AY)=(Y-1/2)(AX) X(AY)=(Y+I/2)(AX) Starting from Oberman's design, we have tried to 
make the roles of AX and AY sy~netrical, so as not to have to swap IAX] and lAY I when [AY]>IAX I . This 
is done by using one's complement of all va- lues in this case. The counter becomes a IdXJ-tuple modulo 
lAY I decounter. The register then contains a value from 0 to AY -i. The carry from the adder calculating 
AY -AX is used as the comparison signal that changes working mode. A full logical description is given 
in Fig.8. The signs of AX and AY are used only as con- trois for up/down signals of the X and Y counters. 
 Vectors can be drawn in four kinds of line: normal, dotted, dashed, and dot-dashed. CHARACTER GENERATOR 
 The character generator draws the 96 printable characters of full ASCII code as 5x7 dot matrices to 
which are applied scale factors in X and Y, using p and q ratios in X and Y respectively, p and q going 
from I to 16. Character generation is made by zig-zag scan- ning the 5px7q points (Fig.9). The spot 
goes from (X0,Y0) to X0+6p,Yo) and is thus positionned for a new character. Using 512 x 512 resolution, 
maxi- mum screen capacity is 64 lines of 85 characters. It is also possible to draw two kinds of rectan- 
gles: -an alphanumeric rectangle of 5px7q, -a graphic rectangle of 4px4q after which the spot is at 
location (X0+4p,Y0). .~- 5p points r~i ! ! i -i'nft~al" p;siti;;" of- the spot Vectors and characters 
can be drawn with spot on or off and writing or erasing points. This per- mits selective erasure and 
eases the progranm~ing of moving pictures. It is also possible to clear or preset the who- le screen 
memory. LIGHT-PEN The light-pen itself is made of a phototransis- tor the output of which is connected 
to the LIGHT- PEN input of the chip. When a light-pen com~nand is entered, the following frame is forced 
to white and the value of the addresses of the currently dis- played point is stored in two special registers 
on the rising edge of the LIGHT-PEN input. With the same basic circuitry, it is possible to use an ex- 
ternally generated crosshair. In this case, the frame is not forced to white. MICROPROCESSOR COUPLING 
 The bus structure is the classical 8-bits mi- croprocessor's one: 8-bits bidirectionnal data bus, 4-bits 
address bus, Read/Write signal, timing Chip- Enable and interrupt line. There are three causes of interrupt: 
frame completion, writing ready, end of light-pen. The chip is oriented on memory mapped I/0 and uses 
13 memory locations selected by the micropro- cessor's address bus and used as follows: -4 locations 
for X and Y -4 locations for vectors and characters specifi- cations ]AXI, IAYI, p, q -2 locations 
for light-pen registers -i location for a control word specifying type of line, spot and interrupt -i 
location used as write only for commands, and read only for status -I location in order to simplify colour/grey- 
shade application. REFERENCES i. Kay, A. C., Microelectronics and the person- nal computer. Scientific 
American, 237 (Sept. 1977), 231-244. 2. Ramtek 9000 Series, Graphic and imagery display systems.  3. 
Op Her Veld, S. J., Microprocessor-controlled video games, Euromicro 1977.  4. Matrox TV controller 
family.  5. Motorola catalog, VDG 467 circuit.  6. Matherat, P., Conception d'un circuit int~gr~ pour 
la visualisation graphique, th~se de 3~me cycle, Institut de Program~nation de Paris, Mai 1978.  7. 
Oberman, R. M. M., A flexible rate multiplier with uniform pulse distribution output, IEEE trans, on 
Comp., Vol. C-21, (1972), 896.  8. Bresenham, J. E., Algorithm for computer con- trol of a digital plotter, 
IBM systems J.4, (1965), 25-30.  9. Horn, B. K. P., Circle generators for display devices, Computer 
graphics and image proces- sing 5, (1976), 280-288.  186   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807388</article_id>
		<sort_key>187</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>33</seq_no>
		<title><![CDATA[Conversion of complex contour line definitions into polygonal element mosaics]]></title>
		<page_from>187</page_from>
		<page_to>192</page_to>
		<doi_number>10.1145/800248.807388</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807388</url>
		<abstract>
			<par><![CDATA[<p>A simple algorithm is presented for processing complex contour arrangements to produce polygonal element mosaics which are suitable for line drawing and continuous tone display. The program proceeds by mapping adjacent contours onto the same unit square and, subject to ordering limitations, connecting nodes of one contour to their nearest neighbors in the other contour. While the mapping procedure provides a basis for branching decisions, highly ambiguous situations are resolved by user interaction. The program was designed to interface a contour definition of the components of a human brain. These brain data are a most complex definition and, as such, serve to illustrate both the capabilities and limitations of the procedures.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Continuous tone displays]]></kw>
			<kw><![CDATA[Contour data]]></kw>
			<kw><![CDATA[Mapping]]></kw>
			<kw><![CDATA[Serial sections]]></kw>
			<kw><![CDATA[Surface reconstruction]]></kw>
			<kw><![CDATA[Three dimensional computer graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>G.1.2</cat_node>
				<descriptor>Approximation of surfaces and contours</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010918</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Approximation algorithms</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31074654</person_id>
				<author_profile_id><![CDATA[81339494380]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[H.]]></first_name>
				<middle_name><![CDATA[N.]]></middle_name>
				<last_name><![CDATA[Christiansen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Brigham Young University Provo, Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39041117</person_id>
				<author_profile_id><![CDATA[81100400673]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Sederberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Brigham Young University Provo, Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Keppel, E. Approximating complex surfaces by triangulation of contour lines. IBM Journal of Research and Development, v. 19 (Jan. 1975), 2-11.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359846</ref_obj_id>
				<ref_obj_pid>359842</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H., Kedem, Z.M., and Uselton, S.P. Optimal surface reconstruction from planar contours. Comm. ACM 20, 10 (Oct. 1977), 693-702.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Christiansen, H.N. Applications of continuous tone computer-generated images in structural mechanics. Structural Mechanics Computer Programs - Surveys, Assessments, and Availability. University Press of Virginia, Charlottesville 1974, 1003-1015.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Christiansen, H.N., and Stephenson, M.B. Movie. byu - a general purpose computer graphics display system. Proceedings of the Symposium on Applications of Computer Methods in Engineering, University of Southern California, Los Angeles, v. 2 (Aug. 1977), 759-769.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 CONVERSION OF COMPLEX CONTOUR LINE DEFINITIONS INTO POLYGONAL ELEMENT MOSAICS H. N. Christiansen and 
T. W. Sederberg Brigham Young University Provo, Utah Abstract A simple algorithm is presented for process- 
ing complex contour arrangements to produce poly- gonal element mosaics which are suitable for line drawing 
and continuous tone display. The program proceeds by mapping adjacent contours onto the same unit square 
and, subject to ordering limitations, connecting nodes of one contour to their nearest neighbors in the 
other contour. While the mapping procedure provides a basis for branching decisions, highly ambiguous 
situations are resolved by user interaction. The program was designed to interface a contour definition 
of the components of a human brain. These brain data are a most complex defi- nition and, as such, serve 
to illustrate both the capabilities and limitations of the procedures. Key Words and Phrases: Continuous 
tone displays, contour data, serial sections, surface reconstruc- tion, three dimensional computer graphics, 
mapping. CR Categories: 3.12, 8.2 INTRODUCTION There is a disparity between the conventional method 
of describing topographical surfaces (i.e. contour line definitions) and the format of surface description 
most often used in continuous tone com- puter graphics (i.e. panel definitions). The two differ enough 
that conversion from contours to panels is not a trivial problem. Thus, a program that effectively performs 
such a conversion greatly facilitates the display of topographical surfaces. This problem has previously 
been addressed by Keppel (i), and Fuchs et al (2) who have both used graph theory and optimization procedures 
in approach- ing the triangulation problem. Keppel introduced the highly systematic approach to search 
for panel arrangements which maximized the volume enclosed by convex surfaces. Fuchs produced additional 
gener- alizations and provided an example problem which minimized surface area. While this approach might 
be extended to include branching, the authors of this paper (confronted with an extremely complex data 
system) decided to explore a relatively simple triangulation scheme (which avoids searches alto- Also 
affiliated with the University of Utah where a contract with the Office of Naval Research provided funding 
for this work. gether) and to augment the resulting capability with mapping procedures and user interaction. 
 A LIMITED TRIANGULATION ALGORITHM A contour line can be viewed mathematically as the intersection of 
an arbitrary surface and a plane. In topography, the plane is generally hor- izontal at a specified elevation. 
If the surface is closed, its contour lines will likewise be Qlosed loops. A set of these serial sections 
on evenly spaced parallel planes comprises a contour definition of a surface. Contour lines of an irregular 
surface, such as found in nature, do not lend themselves to curve fitting, or other attempts at precise 
mathematical description. The most convenient numerical descrip- tion of a contour line is, perhaps, 
one where the line is approximated as a string of straight line segments. This digitized contour line 
offers two pieces of information: nodal coordinates and connec- tivity of nodes. Connectivity is implied 
by the sequence in which the nodes are listed. Triangulation -the process whereby a panel definition 
is extracted from a contour definition - is facilitated by observing the connectivity inher- ent in contour 
data. This connectivity leads to an obvious rule in triangulation: If two nodes of the same contour are 
to be defined as nodes of the same triangle, they must neighbor each other on their contour line. Also, 
no more than two vertices of any triangle may be recruited from the same contour line (except, of course, 
in the special case where the entire area enclosed by that contour is to be capped). This surface reconstruction 
is most logically carried on between pairs of adjacent contour lines. Consider this pair of contour loops 
T (top) and B (bottom). Fig. i: Contour Pair Prior t~ Triangulation 187 Two requirements must be met 
before triangula- tion can commence. First, the connectivity of both loops must proceed in the same rotational 
direction, and second, the first nodes of each loop must be proximate. Both rules are met by the loops 
shown in Fig. I. The process commences by defining diagonal it-lb. Since contour connectivity requires 
it-2t and ib-2b as bases of triangles, there are only two candidates for the first triangle: it-lb-2t, 
and it-lb-2b as shown in Fig. 2. ib Fig. 2: Commencing Triangulation Triangle it-lb-2b is selected 
on the basis of the shortest diagonal and the routine moves on to consider the second triangle, it-2b-2t 
or it-2b-3b. This time it-2b-2t is selected as a consequence of ~ts shorter diagonal. The completed triangulation 
based upon this shortest diagonal merit function is shown in Fig. 3. Fig. 3: Triangulated Contour Pair 
 This "shortest diagonal" algorithm is easily implemented, is very fast, and works well as long as the 
two loops are mutually centered and are reasonably similar in size and shape. Note that there is no requirement 
placed on the number of nodes in either contour loop. MAPPING Alas, the basic "shortest diagonal" algorithm 
fails for mildly complex cases. A typical example is given by offset contours shown in Fig. 4. Here, 
the shortest diagonal test results in a cone. Rather than abandoning the algorithm, consider modifications 
of the loops to make them more acceptable. As mentioned, the algorithm pre- fers contour pairs to be: 
I) mutually centered, 2) of similar size, and 3) of similar shape. The first two requirements are met 
by mapping the loops onto a unit square prior to triangulation. (Mapping also tends to make the shapes 
more uniform, though not always enough. This problem is addressed in the next section.) Each contour 
is mapped consecutively in the Fig. 4: Failure Example following manner: I. Define the rectangular 
window which en- closes the contour.  2. Calculate AX, AY, X, and Y. (See Fig. 5)  3. Map onto a unit 
square centered at (0,0) by translating and scaling the contour such that its window matches the unit 
square's window. The equations for this are:  X' = (X-X)/AX, Y' = (Y-Y)/AY The resulting mapped contour 
is shown in Fig. 6. Fig. 5: Contour Line and Window Parameters y, --_X' Fig. 6: Mapped Contour Line 
 188 With both contours thus mapped, they are easily handled by the original algorithm. A fringe benefit 
of mapping is that the resulting triangles tend to align themselves with diagonals that are biased in 
the direction of the offset. This creates a desir- able longitudinal texture. AMBIGUITY Since there 
are a number of panel systems which can be utilized to triangulate between two adjacent contour lines, 
a certain degree of ambiguity exists. When the two loops are similarly shaped, the ambi- guity is negligible 
and the reasonable solutions will be similar. However, as the respective shapes of the serial sections 
become increasingly divergent, the ambiguity becomes increasingly pronounced. The convolution shown in 
Fig. 7 provides such an example. Both solutions are reasonable, but are represent- atives of differing 
surface conditions. Clearly, information beyond the two contour lines in ques- tion, is required to resolve 
the problem. tion take place over three segments. Further, it is specified that the counter-clockwise 
segments containing nodes it-6t be triangulated with nodes ib-7b, that 6t-12t be connected with 7b-12b, 
and that 12t-lt be joined with 12b-lb. The mapping procedure is optional during this process. I~ the 
results are unsatisfactory, further subdivision may be specified. The shape developed in Fig. 7b (from 
the same top and bottom contours as in Fig. 7a) can probably be obtained by triangulation of it-7t with 
ib-6b, 7t-12t with 6b-12b, and 12t-lt with 12b-lb. This appears to be the proper panel system for a column 
with a spiraling indentation. BRANCHING An important feature of this algorithm is the capability to 
handle branching. Consider a simple case where one contour loop branches into two as shown in Fig. 8. 
 Fig. 8: Simple Case of Branching An economical, and quite general, approach to 2blb v branching is 
easily obtained. The concept is to Fig. 7: Non-Synonymous Interpretations (b) There are at least two 
ways to provide the needed information. First, one could require the contour planes to be close enough 
together that there is minimal variation between adjacent contour lines. This approach has the advantage 
of tending toward an exact description, and the disadvantage of being uneconomical. Further, the data 
may not be available. The second approach (adopted here) is to request user interaction to guide the 
tri- angulation over cases of excessive ambiguity. User control is achieved by the option to specify 
that triangulation should take place between specific segments of the upper and lower contours. For example, 
the shape developed in Fig. 7a (which appears to be a transition section between prismatic columns) is 
achieved by specifying that triangula- treat all branches as one continuous closed line in the following 
manner: i. Introduce a new node midway between the closest nodes on the branches. The Z coordinate of 
this new node is the average of the Z coordi- nates of the two contour levels involved. 2. Renumber 
the nodes of the branches and the new nodes such that they can be considered as being one loop (see Fig. 
9). This means that the new nodes and their immediate neighbors are num- bered twice. Fig. 9: Triangulation 
Scheme for Branching 189 3. Triangulate as usual. This scheme works well for any number of branches. 
 Often, there are several contour loops on adja- cent planes, posing the problem of loops connectiv- 
ity. Which loops should be triangulated one-on-one and which ,are cases of branching? Judgment, in clear 
cut cases, can be made on the basis of window overlap. f BIT2~____~ Fig. I0: Typical Problem in Connectivity 
 On the basis of window overlap, it is clear (in Fig. I0) that T I and B 1 go together, and that B^branches 
into T 2 and T~. Window overlap is best z found by default. That is, if they don't not over- lap, they 
do overlap. Fig. II: Difficult Case of Branching Fig. 12: Possible User Guided Solution 190 In extreme 
situations (see Fig. ii, where B 1 branches into T 1 and T2) it may be difficult to define a satisfactory 
new midway node. A possible user guided solution, Fig. 12, is to triangulate ~ with a single contour 
at the T level consisting the outer loop containing (in order) points A, B, C, D, E, and F. Then a flat 
patch can be devel- oped between T 1 and T_ by directing that segment BHD triangulate with ~egment AGE. 
 ECONOMIZING If a data base has too fine a resolution, it is desirable for reasons of economy to eliminate 
the less essential nodes. This may be done by re- jecting nodes where the line segment to the next node 
is either short or the direction change is minimal. It is also desirable to join pairs of adjacent triangles 
together into quadrilaterals. This decision is based on the amount of warping of the resulting quadrilateral. 
That is, the angle by which the two triangles are out of plane. This angle is quickly found using vector 
algebra. The parameters limiting segment length, change in line direction, and quadrilateral warp are 
all user defined, Entire contour levels may also be skipped. HUMAN BRAIN CONTOUR DATA The brain data 
to be used for example purposes in this paper has an interesting history. In 1967, the first of several 
movies was made of a human brain at the University of California at San Diego. Using the process of cinemorphology, 
an entire haman brain was placed in a microtome capable of shaving off a slice 25 microns thick. After 
each slice, a frame of movie film was shot. The entire brain was sliced through, with each successive 
newly.exposed surface recorded on film. Every nth frame of the movie was exploded photographically and 
outlines traced of each brain structure. Fig. 13 shows a typical cortex contour. In all, 22 separate 
structures were recorded. The contour outlines were laid on an acoustic tablet and a graduate student 
(of course!) selected appropriate nodes. The resulting data base is massive -total- ing 78,651 nodes. 
 DISPLAY EXAMPLES This section presents examples of the finished product.. It is difficult to judge 
how true to life the images are, due to the highly esoteric nature of the subjec£ matter. Nonetheless, 
it is generally evident that the triangulation algorithm has per- formed reasonably. The images presented 
were pro- duced using MOVIE.BYU (3, 4), a Tektronix terminal and hard copy unit for the line drawings, 
and a Comtal display system for the continuous tone images. The line drawing was hand traced. The first 
structure presented is the brain stem which was a strightforward triangulation prob- lem. There are no 
branches, and there is no serious variation in the shape of its respective contours. The entire surface 
reconstruction was handled auto- matically. Fig. 14 shows a llne drawing representation of the brain 
stem, with the corresponding continuous tone image illustrated in Fig. 15.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807389</article_id>
		<sort_key>193</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>34</seq_no>
		<title><![CDATA[Comparing figures by regression]]></title>
		<page_from>193</page_from>
		<page_to>195</page_to>
		<doi_number>10.1145/800248.807389</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807389</url>
		<abstract>
			<par><![CDATA[<p>A procedure is described to obtain an empirical transformation regressing an independent plane configuration against a similar dependent configuration. As implemented the procedure constructs the mapping by estimating two bivariate tables, with arguments on a square lattice interpolated from the irregularly arranged original observations. The tables are constructed so that the transformation has smooth derivatives and so as to agree, as nearly as possible, with the empirical data. The curvilinear regression coefficients are represented a spatially varying, but coordinate invariant, second order tensor field. Bidimensional regression can automatically be illustrated by a warped coordinate grid, by comparison of the original configuration and the regression estimate, by a field of displacement vectors, by a diagram of the principal strains, and by a contour map. Intermediate configurations and extrapolations are also available.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Bidimensional regression]]></kw>
			<kw><![CDATA[Geometric transformations]]></kw>
			<kw><![CDATA[Graphics]]></kw>
			<kw><![CDATA[Numerical analysis]]></kw>
			<kw><![CDATA[Statistics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>G.3</cat_node>
				<descriptor>Correlation and regression analysis</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Hierarchy and geometric transformations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010240.10010244</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision representations->Hierarchical representations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003691</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Regression analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010309.10010313</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Factorization methods->Canonical correlation analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P334309</person_id>
				<author_profile_id><![CDATA[81100506704]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[W.]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Tobler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Geography Department, Univ. of California, Santa Barbara]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[F. Bookstein, "The Measurement of biological shape and shape change", thesis, Ann Arbor, Michigan, 1977.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Durer, The Human Figure, W. Strauss, ed., New York, Dover, 1972.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D'Arcy Thompson, On Growth and Form, Cambridge, University Press, 1917.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[W. Tobler, "D'Arcy W. Thompson and the Analysis of Growth and Form", Papers, Mich. Acad. Sci., Arts, and Literature, SLVIII (1963), pp. 385-390.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[W. Tobler, "Computation of the Correspondence of Geographical Patterns", Papers, Regional Sci. Assn., 15 (1965), pp. 131-139.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[W. Tobler, "Medieval Distortions" The Projections of Ancient Maps", Annals Assn. Am. Geographers, 56, 2 (1966), pp. 351-360.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[W. Tobler, "The Geometry of Mental Maps", pp. 69-81 of R. Golledge, C. Ruston, eds., Spatial Choice and Spatial Behavior, Columbus, Ohio State University, 1976.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[W. Tobler, "The Comparison of Plane Forms", Geographical Analysis, X, 2 (1978), 154-162.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 COMPARING FIGURES BY REGRESSION W. R. Tobler Geography Department, Univ. of California, Santa Barbara, 
93106 ABSTRACT A procedure is described to obtain an empirical transformation regressing an independent 
plane :on- figuration against a similar dependent configura- tion. As implemented the procedure constructs 
~he mapping by estimating two bivariate tables, witi~ arguments on a square lattice interpolated from 
the irregularly arranged original observations. The tables are constructed so that the transfomm- tion 
has smooth derivatives and so as to agree, as nearly as possible, with the empirical data. The curvilinear 
regression coefficients are represe1~ted by a spatially varying, but coordinate invarian1~, second order 
tensor field. Bidimensional regre~sion can automatically be illustrated by a warped co.r- dinate grid, 
by comparison of the original conf:g- uration and the regression estimate, by a field of displacement 
vectors, by a diagram of the prin- cipal strains, and by a contour map. Intermediate configurations and 
extrapolations are also avail- able. Keywords: Numerical analysis; geometric trans- formations; statistics; 
graphics; bidimensional regression. Computing Reviews categories: 5.13, 5.15, 8.2. There are many situations 
in which it is of interest to compute the degree of resemblance between two plane figures. Suppose we 
have pictures of the faces of t~ people, for example. Can we measure the degree of similarity of these 
faces? Or of two signatures? Or of two leaves? Or of two geographical maps? These questions are here 
approached by an analogy to regression analysis, as practiced in elementary statistics. Bidimensional 
regression is an extension of ordinary regression to the case in whidh both the independent and dependent 
variables are two dimensional. The biological and evolution- ary speculations so imaginatively presented 
by D'Arcy Thompson in his classic On Growth and Form are probably the most famous realiza- tions of transformations 
of the type under discussion. But the proportionate studies of Albrecht D~rer must also be cited. For 
unidimensional regression one has an indepen- dent variable X and a dependent variable Y and e~ch consists 
of N numbers. Every x is associated wi~h a particular y and we can construct a scatter di~- gram relating 
the two. The objective is now to relate Y to X by a function Y = f(X) in such a manner that the mapping 
X ÷ Y is, as nearly as possible, the same as the observed association X ÷ Y. In particular we wish to 
be able to assign a y when given a value of x when there was no observation at that location, or when 
there were several y's observed at that location, or when we suspect that the y measured at that loca- 
 tion contains an error. Or we would like to know the general rate of change of y with respect to x given 
only discrete observations, or would like to know a most probable value for y when given an x. "As nearly 
as possible" is usually taken to mean that we minimize the mean square error. In order to find this minimum 
we must chose a model by deciding on a relation to be used for f(x). The degree of success is measured 
by the ratio of the explained to the total variance. In effect it indicates how much better is our estimate 
of y than would be the guess using the average y of the Y observations no matter what is the value of 
X. In the bidimensional case one has an independent variable Z and a dependent variable W and each consists 
of N pairs of numbers: Z W xlY I UlV 1 x2Y 2 u2v 2 x3Y 3 u3v 3 XnY n UnV n These are the "landmarks" 
in the two figures. Thus every x,y is associated with a particular u,v, and we can construct a scatter 
diagram relating the two 7 /2-- X tl 193 or, although misleading since the origin and rota- tion are 
arbitrary: + (v k -g(xk,Yk))2J," \ x  or !7 u 1 yorv The objective is now to relate W to Z by 
a functipn W -f(Z) in such a manner that the mapping Z + W is, as nearly as possible, the same as the 
observed association Z + W. In particular we wish to be able to assign a W when given a value of Z when 
there was no observation at that location, or when there were several u,v observed at that location, 
or when we suspect that the u,v measured at that location contain an error. Or we would like to know 
the general rate of change of u,v with re- spect to x,y when given only discrete observa- tions, or would 
like to know a most probable u,v when given an x,y. As nearly as possible is usually taken to mean that 
we minimize the mean square error. In order to find this minimum we must chose a model by deciding on 
a relation to be used for f(Z). The degree of success is measured by the ratio of the explained to the 
total variance. In effect is indicates how much better is our estimate ~, ~ than would be the guess using 
the average ~, ~ of the observations W. In the bidimensional case each variable has two components. 
Thus the mapping Z ÷ W is equiva- lent to (x,y) + (u.v) but would most commonly be written as two separate 
real functions u = f(x,y), v = g(x,y). These functions f and g are not independent. For the mapping to 
be one- to-one it must satisfy J > 0. ~x ~y ~y ~x Thus, when the transformation is formulated in least 
squares terms we minimize K K E[(u k _ ~)2 + (v k _ ~k)2] = E [(u k -f(xk,Yk))2 k=l k=l REFERENCES 
 subject to J > 0. In this statement use has been made of the partial derivatives of the mapping. It 
is therefore already implicit that some conti- nuity and differentiability properties are required And 
the bidimensional regression coefficients, as strain tensors, are computed as the eigenvalues of the 
matrix of partial derivatives of the mapping A necessary stipulation therefore is that the map- ping, 
and its derivatives, be smooth. The linear cases (Euclidean, affine, or projective transforma- tions) 
are easily calibrated by least squares but are not sufficiently general to capture the phenom- ena of 
interest. My experience has been that para- meter estimation using specific mathematical func- tions, 
such as algebraic or trigonometric (real or complex) polynomials, etc., is not satisfactory if one wishes 
to pick up the details of the figures to be compared. Instead an empirical double bivar- late interpolatory 
stretching of one image to fit the other is performed, after the two figures have been brought into maximal 
correspondence by a least squares similarity transformation. The procedure, in brief, is as follows. 
Each observed point in the x,y image must be moved by some amount in order to make it correspond to its 
u,v image point. Position a square mesh of appropriate fineness over the x,y domain. Then, at each node 
of the mesh, estimate by how much that node would need to be moved so that when x,y points interior to 
a cell of the mesh are pulled along with the mesh they cor- respond as nearly as possible with their 
u,v image points. Linear interpolation is here used within each mesh. The displacement of mesh points 
is fur- ther constrained to satisfy the biharmonic equation with appropriate boundary conditions. The 
lattice of mesh points is thus smoothly deformed, and the partial derivatives of the transformation can 
be estimated by finite differences. The appropriate combination of these derivatives yields an estimate 
of the regression "slope", in this case a tensor field which varies from point to point in the domai 
since the mapping is curvilinear. The curvilinear regression coefficient is estimated using the resi- 
 dual variance in the normal manner. A number of examples have been computed. Current efforts are directed 
at extending the method to compare distri- butions, rather than single pairs, of figures.  F. Bookstein, 
"The Measurement of biological shape and shape change", thesis, Ann Arbor, Michigan, 1977. A. Durer, 
The Human Fisure, W. Strauss, ed., New York, Dover, 1972. D'Arcy Thompson, On Growth and Form, Cambridge, 
University Press, 1917. W. Tobler, "D~Arcy W. Thompson and the Analysis of Growth and Form", Papers, 
Mich. Acad. Sci., Arts, and Literature, SLVIII (1963), pp. 385-390. W. Tobler, "Computation of the Correspondence 
of Geographical Patterns", Papers, Regional Sci. Assn., 15 (1965), pp. 131-139. W. Tobler, "Medieval 
Distortions" The Projections of Ancient Maps", Annals Assn. Am. Geographers, 56, 2 (1966), pp. 351-360. 
 194 W. Tobler, "The Geometry of Mental Maps", pp. 69-81 of R. Golledge, C. Ruston, eds., Spatial Choice 
and Spatial Behavior, Columbus, Ohio State University, 1976. W. Tobler, "The Comparison of Plane Forms", 
Geosraphical Analysis, X, 2 (1978), 154-162. 195  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807390</article_id>
		<sort_key>196</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>35</seq_no>
		<title><![CDATA[Computer generated images for medical applications]]></title>
		<page_from>196</page_from>
		<page_to>202</page_to>
		<doi_number>10.1145/800248.807390</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807390</url>
		<abstract>
			<par><![CDATA[<p>Two computer graphics systems for the presentation of biomedical information for diagnosis and treatment planning are described. Both systems presented utilize computer tomographic (CT) data as input. One of the systems produces three-dimensional surface representations of organs and anatomical features found within the body. The other system is a radiation treatment planning aid which uses tomographic data in its computations.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Radiation treatment planning]]></kw>
			<kw><![CDATA[Smooth-shaded color displays]]></kw>
			<kw><![CDATA[Three-dimensional surface representation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Medical information systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010447</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Health care information systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P328942</person_id>
				<author_profile_id><![CDATA[81100339824]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alexander]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sunguroff]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P68460</person_id>
				<author_profile_id><![CDATA[81100196982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Greenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Ashkar, G.P. and Modestino, J.W., "The Contour Extraction Problem with Biomedical Applications," Proceedings of 1977 IEEE Conference on Pattern Recognition and Image Processing, pp. 216-221, Troy, NY (1977).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Blinn, James J., "Models of Light Reflection for Computer Synthesized Pictures," Proceedings SIGGRAPH, 1977, pp. 192-198.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Budinger, T.F. and Gullberg,G.T. "Three-Dimensional Reconstruction in Nuclear Medicine Emission Imaging," IEEE Transactions on Nuclear Science, Vol. NS-21, No. 3 (June 1974).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Catmull, Edwin A., A Subdivision Algorithm for Computer Display of Curved Surfaces, Dept. of Comp. Sc., Univ. of Utah, UTEC-CSc-74-133, Dec. 1974. Also, Computer Display of Curved Surfaces, Proc. Conf. on Comp. Graphics, May 1975 (IEEE Cat. No. 75CH0981-1C), 11-17.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cho, Z.H., "General Views on 3-D Image Reconstruction and Computerized Transverse Axial Tomography," IEEE Transactions on Nuclear Science, Vol. NS-21, No. 3 (June 1974).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[DeClemented, A., Mohan, R., Reddy,M.T., Holt, J.G., "The Memorial Hospital External Beam Treatment Planning Program." Memorial Hospital New York, NY (Nov. 1971).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Gordon, W.J., "Spline-Blended Surface Interpolation through Curve Networks," J. Math. Mech. Vol. 18, No. 10 (1969).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Gouraud, Henri, Computer Display of Curved Surfaces, Dept. of Comp. Sci., Univ. of Utah, UTEC-CSs-71-113, June 1971. Also IEEE Transactions on Computers, Vol. TC-20, June 1971.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Lane,K., Bloch, P., Davis, L.W., "Computer Generated Isodose Curves for High Energy X-Ray Machines," American Journal of Roentgenology, Radium Therapy and Nuclear Medicine, 121(4), pp. 865-872, Springfield, Ill. (Aug. 1974).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Liu, H.K., "Two- and Three-Dimensional Boundary Detection," Computer Graphics and Image Processing, 6:2, pp. 123 (1976).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Meredith, W.J. and Massey, J.B., "Fundamental Physics of Radiology," John Wright Sons Ltd., Bristol (1968).]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Neilson, I.R., Slater, J.M., Crispens, J.W., Chu, T., and Carlsen, E.N., "Interactive Computer/Ultrasound System for Radiation Treatment Planning," in Medinfo 74, North-Holland Publishing Co. (1974).]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Newton, C.M., Ryden, K., Nelson,R. and Johnson, J., "Remote Graphics Treatment Planning (RAD-GRAF)," in UCLA Health Sciences Computing Facility UCLA, Los Angeles, Calif.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>906872</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Riesenfeld, R.F., "Applications of B-Spline Approximation to Geometric Problems of Computer Aided Design," PhD Thesis, Syracuse Univ. (1973).]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Riseman, E.M. and Arbib, M.A., "Computational Techniques in the Visual Segmentation of Static Scenes," Computer Graphics and Image Processing 6:3, pp. 492-501, NY (1977).]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Rosenfeld, A., "Iterative Methods in Image Analysis," Proceedings of 1977 IEEE Conference on Pattern Recognition and Image Processing 14-18, Troy, NY (1977).]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Rosenfeld, A., "SURVEY, Picture Processing: 1976," Computer Graphics and Image Processing Vol. 6, No. 2, pp. 157-183 (April 1977).]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Torrance, K.E. and Sparrow, E.M., Theory for Off-Specular Reflection from Roughened Surfaces, J. Opt. Soc. Am., Vol. 57, No. 9, Sept. 1967, pp. 1105-1114.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Tuong-Phong, Bui, Illumination of Computer-Generated Images, Dept. of Comp. Sci., Univ. of Utah, UTEC-CSs-73-129, July 1973.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359848</ref_obj_id>
				<ref_obj_pid>359842</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Wu, S.C., Abel, J. and Greenberg, D.P., "An Interactive Computer Graphics Approach to Surface Representation," Comm. of ACM (Oct.1977).]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 CO~UTER GENERATED IMAGES FOR MEDICAL APPLICATIONS by Alexander Sunguroff and Donald Greenberg Program 
of Computer Graphics Cornell University ABSTRACT Two computer graphics systems for the presentation 
of biomedical information for diagnosis and treat- ment planning are described. Both systems presented 
utilize computer tomographic(CT) data as input. One of the systems produces three-dimensional surface 
representations of organs and anatomical features found within the body. The other system is a radiation 
treatment planning aid which uses tomographic data in its computations. COMPUTING REVIEWS CLASSIFICATION: 
3.34, 8.1, 8.2 KEYWORDS: Computer Graphics, Three-Dimensional Surface Representation, Radiation Treatment 
Planning, Smooth-shaded Color Displays i, INTRODUCTION This paper describes two computer graphics systems 
separate parts. One part is devoted to computation for the presentation of biomedical information for 
of beam dosage levels while the second part is con- diagnosis and radiation treatment planning. The 
cerned with the graphical communication and inter- three-dimensional reconstruction system is divided 
action with the user of the system. into three parts. The first part is used to ex- tract contours 
of various objects found in tomo- The system has been developed to allow the user to grams. The second 
part then uses this contour create interactively a treatment plan by generating information to produce 
a three-dimensional mathema-indiv{dual radiation beams and by computing the tical representation of 
each object. The final part cumulative result. The area to be treated and the then uses these descriptions 
to create smooth-dosage levels are displayed to the user by means of shaded color perspectives for medical 
diagnoses and a color display monitor that depicts the radiation treatment planning. levels as colored 
areas superimposed upon a tomo- gram. The user is able to specify target and source The contour extraction 
module produces contours position, divergence, width, frequency, and initial either with the aid of 
an edge-following algorithm intensity profiles for each beam and place filter- or interactively under 
user control. Contour defi-ing devices such as lead wedges in the path of the nitions are constructed 
for each of the objects of beam. Beams are positioned until an adequate dos- interest on each of a set 
of tomograms. Such ob-age pattern covers the tumor area. If a beam leads jects as the skull surfaces, 
ventricles or tumors to undesired results, it may be removed and then can be defined. regenerated with 
suitably modified parameters. When all of the tomograms have been processed, the There are several major 
advantages which this sys- information is sent to a surface forming program. tem offers, including the 
following: B-splines are used for representations of the sec- tional contours and then Cardinal splines 
are used A. Various treatment strategies can be selected to form the three-dimensional surfaces by lofting. 
and easily modified under user control until The resulting surfaces can be dynamically viewed as an 
efficient plan is obtained. wire-line drawings. B. The actual density information obtained from the 
CT scan is used to compute the radiation The final module of the system creates smooth- dosage levels. 
 shaded color images of these objects for visual C. Radiation dosages are depicted using pseudo- presentation 
to the physician. One is able to color displays, and each beam is super- assign different colors and 
transparencies to each imposed on the actual tomogram. of the component objects in order to best distin- 
D. The visual feedback of the displays allows guish them and to make the total image most under-for 
irm~ediate comprehension of the complex standable. spatial phenomena. E. The digital output can be 
put in a form The radiation treatment planning system is an in-which can be used to control the actual 
teractive computer graphics program composed of two radiation treatment. 196 2. THREE-DIMENSIONAL RECONSTRUCTION 
SYSTEM The three-dimensional reconstruction system was developed to satisfy two objectives. The first 
was to provide a precise mathematical definition of complex three-dimensional biological organs. The 
 second was to enhance the visual feedback mechan- isms available to the physician to enable a more comprehensive 
understanding of the spatial rela- tionships. Both objectives contribute to improving diagnostic techniques 
and treatment strategies. The three-dimensional reconstruction system is divided into three portions: 
a contour extraction module, a surface representation routine and a color display section. A. Contour 
Definition The contour extraction module is an interactive system used to provide the initial definition 
of the contours. This is either done interactively by digitizing or by initiating an "edge detection" 
program. The edge-follower is used wherever possi- ble. If it does not produce a satisfactory result, 
at any stage or for any portion of the contour, a hand drawn contour may be substituted. Automatic construction 
of a boundary of an object is generally performed in a hierarchical manner such that information extracted 
at one level is then combined to form information at a higher level. Long edge and boundary detection 
is accom- plished by combining information about various smaller features such as short edges, edge 
frag- ments and edge points. Most edge detection procedures usually first deter- mine a spatial derivative 
or gradient of the orig- inal picture intensity. This derivative character- istic has been proven most 
likely to remain more constant along the length of a contour than the measurement of the primary quantity 
itself and, thus, is useful for edge detection algorithms. Edge points become those points in the image 
that neighbor on other points with similar values for the derivative quantity. Connecting such edge points 
results in edge fragments. Edge fragments, which may be separated by gaps, are then connec- ted to form 
long edges, boundaries or contours. The combination procedures can be categorized into sequential and 
parallel schemes. In the sequential procedures, an edge or boundary is extended one element at a time. 
In order to produce the best possible contour, sequential algorithms may use techniques such as "back-tracking" 
in which an edge is erased to some pgint from which an alternate path may be taken. i0 Parallel combination 
schemes mix information from each of the local elements. The parallel scheme that has received much attention 
in the last few years has been the relaxation method devised primarily by Rosenfeld~l-6T I-7- In relaxation 
methods of edge detection, values of the neighbors of a point change the probability of that point as 
a candidate for an edge point. Other procedures are a mixture of the two methods and explore a number 
of sequential paths in a paral- i lel manner. Excellent surveys on picture process- ing and computational 
techniques for feature ex- traction, including extensive bibliographies, ap- pear in the Journal of Computer 
Graphics and Image Processing,15,17 and thus a comprehensive bibli- ography is not included herein. 
Our edge-follower uses a simple gradient detector and travels at right angles to the direction of the 
maximum gradient. It may be set to follow various predefined types of boundaries such as bone/tissue 
 or tissue/water (cerebral spinal fluid) or opaque- dyed (tumor) tissue/normal tissue. Due to the sim- 
plicity of the current follower which has neither automatic back-tracking capability nor uses proto- 
 type information, the edge detection currently works best on the bone/tissue boundaries. Signifi- cantly, 
however, the system is interactively con- trolled by the user who can stop, backup and restart the 
detector manually. Figures 1 and 2 show the original tomogram of a patient with large ventricles and 
the tomograms with the skull and lateral ventricles outlined. The skull was outlined automatically and 
the ven- tricles by digitizing. The same type of contour definitions can be constructed for any object 
of interest on each cross section of a standard set of eight to ten tomograms. In this manner, it is 
 possible to define such objects as the outer sur- face of the skull, the inner and outer surfaces of 
 the brain, tumors, ventricles, etc. B. Surface Representation An interactive computer graphics method 
for the rapid generation of arbitrarily shaped three-dimen- sional surfaces has been developed at Cornell's 
Laboratory of Computer Graphics. 20 The method is a synthesis of spline theory and algorithms, inter- 
active procedures for man-machine communication and software for static or dynamic graphics display. 
Complex shapes can be created by the combination of a number of surfaces that have been separately gen- 
erated and automatically joined. The system is presently operational and has been successfully utilized 
for three-dimensional representations of the inner and outer skull surfaces, as well as tumors and the 
ventricular cavities of the brain. The basic technique employed is a modified lofting method in which 
sectional curves are represented by uniform B-splines, and the surface is inter- polated between sections 
by Cardinal splines. 7 The splines are used because of their ability to repre- sent complex shapes with 
a minimum amount of data. 14 The sectional curves need not be parallel and may consist of any combination 
of open or closed curves. One of the major advantages of this system are fea- tures which enable interactive 
modification of the B-spline representation of the sectional curves. This allows the contour information 
to be entered in either of the two modes previously described. The physician can "trace" in the desired 
contour based on his interpretation of the enhanced tomo- gram, or the boundary contours can be determined 
automatically, using image processing techniques. For both input modes, the contour will be simul- taneously 
displayed with the original tomogram. At 197 this stage, a B-spline curve is automatically gene- rated 
to represent the digitized contour. By using a unique inversion procedure which forces the B- spline 
representation to pass through a predefined number of points on the original contour, a very D close 
mathematical approximation can be obtained. Furthermore, since standard editing routines for manipulation 
are included, the physician can inter- actively modify the contour and match any existing information. 
At all stages of the process, the spatial information is graphically displayed to the user. The efficiencies 
necessary for this inter- action are obtained by the use of difference equa- tions which enhance the 
speed of the repetitive calculations. After the B-spline sectional con- tours have been defined and 
the surface created, one can then view the resulting objects as a wire- line mesh drawing that can be 
rotated dynamically providing a complete three-dimensional representa- tion (Figure 3). This figure was 
created from the same series of tomograms shown in Figure i. The model illustrates the amount of information 
that is attainable even though the amount of data along the axis of the CT scanner is minimal (i.e., 
the lat- eral ventricles appear on only five of the tomograms in the series). C. Smooth-Shaded Image 
Generation Algorithms to simulate-smooth shading have been used for image synthesis during the past 
eight years. In 1971, Gouraud used a simple model to generate smoothly shaded images of surfaces approx- 
imated by small planar polygons. 8 In his approach, a weighted or average normal was computed at each 
vertex of the polygonal surface. A color intensity was selected, based on the cosine of the angle be- 
tween the surface normal and the light ray. The surface was then shaded using a linear interpola- tion 
process which first determined edge inten- sities and then scan line intensities. Phong im- proved on 
Gouraud's method by interpolating surface normals rather than colors and also included a specular reflection 
component. 19 Blinn used an improved specular reflection simula- tion algorithm based on the Torrance-Sparrow 
model of light reflection. 2,18 Surfaces are modeled by many mirror-like facets that mask and shadow 
each other. Parameters that control the facet distribu- tion account for different specular characteristics 
of surfaces. The results compare favorably with photographs of real surfaces, particularly at shallow 
angles of incident light. More accurate models of curved surfaces can be ob- tained by displaying patches. 
This numerical des- cription allows an exact surface normal to be com- puted at each point in parametric 
space. Catmull used this approach by recursively subdividing the patch down to the ras~er level and 
generated very sophisticated images. ~ Problems at the silhouette edges and surface intersections, 
inherent with polygonal methods, were elminated, but the compu- tation time for a single image was 
greatly increased. On our system, the polygon descriptions of the ob- jects to be smooth-shaded are 
obtained using the sectional techniques previously described. The resulting geometric description has 
a major advan- tage for smooth-shaded images when compared to standard polygonal techniques. Most continuous 
shading methods approximate the vertex normal vec- tors by averaging the continuous polygon normals. 
However, using the spline technique, a continuous surface is interpolated, and thus an exact surface 
normal is obtained at each vertex. Intermediate normals are then interpolated from the exact values at 
the vertices. This provides the basis for simu- lating the effects of specular and diffuse reflec- tion 
as well as transparency. The resulting shaded image accurately represents the object being simu- lated. 
 The final module of the medical image reconstruc- tion system uses this approach to create full color, 
smooth-shaded images of the lofted surfaces. One is able to assign different colors and transparen- cies 
to each of the component objects in order to obtain maximum clarity in presentation. Figure 4 shows the 
left lateral view, and Figure 5 shows the front view of the same brain with ventricles, as is shown in 
the previous figures. The ventricles are depicted as shiny opaque objects within a trans- parent outer 
surface of the brain. Different colors are used for the ventricles--the right lateral ven- tricle is 
red, the left one blue, and the third and fourth ventricles green. Finally, Figure 6 shows information 
from the same series of tomograms but showing different objects. Here the outer surface of the brain 
(blue) and the eyes (red) are imbedded in the skull (transparent). It is evident that the three-dimensional 
color dis- plays can provide an excellent visualization and comprehension of complex structures. Furthermore, 
 all of the posit%onal and volumetric information is numerically available. The potential uses of these 
techniques have not yet been fully explored. 3. RADIATION TREATMENT PLANNING SYSTEM An x-ray beam passing 
through a substance is gov- erned by an exponential decay determined by the radio-opacity of the substance 
being transversed. Energy removed from the primary beam eventually is converted into heat, usually 
after existing as some form of secondary radiation (scattering, anni- hilation, etc). Dosage for treatment 
depends on the total energy level of all these types of radi- ation. Since the removal of energy from 
a beam (its atten- uation) is dependent on the density of the sub- stance, quantification of the density 
is important for correct computation. For the different sub- stances occurring in tissue, the composition 
and density substantially affect the attenuation co- efficients. It is impossible to obtain density 
information from conventional radiographs since they only provide a superimposition of objects in the 
path of the beam and not the actual placement of the objects along the axis of the beam. However, with 
the prolifera- tion of the computerized tomographic (CT) scanners, it is now possible to readily obtain 
an accurate description of the internal densities of a cross section through a patient. 3,5 This ability 
to know the actual density values within the patient 198  through use of CT scans has greatly increased 
the accuracy of the dosage values that can be computed using a model of the radiation and target. 
In the last few years, a number of systems which compute primary and secondary radiation levels have 
been developed and are used clinically.6, 9 These calculate accurate dosage patterns but do not use tomographic 
data in the computation. Several other projects have developed an inter- active mode of operation. 
12,13 However, in gen- eral, radiation planning systems have not ap- proached the capability and power 
that such sys- tems could theoretically provide. An interactive computer graphics system has been developed 
at Cornell for radiation treatment plan- ning. The system uses tomographic data, offers an improved efficiency 
for the therapist and enhances treatment accuracy and capability. The program is composed of two separate 
parts: the first part is devoted to computation of beam dosage levels, while the second part is concerned 
with the graph- ical communication and interaction with the user of the system. The dosage computation 
component, though not presently implementing a complete model of radiation transmission, does address 
itself to all the physical mechanisms involved and thus pro- duces meaningful results for the interactive 
plan- ning process. A. Dosage Computation The initial state information plus the density in- formation 
of the tomogram is used to compute the dosage levels. The current attenuation model used is essentially 
an exponential decay dependent on the density along the path, in addition to an in- verse square decay 
dependent on distance from the source. II In mathematical form, this is expressed by -u..Ax. ie, 1.1 
1) Iij = li-l'J (i + Ax./x.) 2 1 1 where Ioj = source intensity for the jth beam  I.. = intensity of 
the ith point of the 13 jth beam u.. = attenuation constant for the ith lJ interval of the j th beam 
 Ax. = the interval between the i-i th and i ith points x. = ith distance from the source (x.= i 
+ Ax.) i xi-i 1 The computations are performed for a number of ad- jacent component beams since the 
total beam is much wider than the density variations across its path. This is illustrated in Figure 7. 
The initial in- tensity profile determines how the initial inten- sities of these component beams vary 
from the maximum intensity. This is used to model the effects of collimation and initial filtering of 
the beam. The exponential decay due to transmission uses the density information of the tomogram in small 
increments along the path of the component beam. The current version of the system does not compute secondary 
radiation though provision has  been made for calculating this in the future. This can be accomplished 
by considering points along the primary beam to be sources with parallel and per- pendicular components 
determined by the frequency of the beam. B. Interactive Graphical Communication The system has been 
developed to allow the user to create interactively the treatment plan by generat- ing individual radiation 
beams and by computing the cumulative result. The area to be treated and the dosage levels are displayed 
to the user by means of a color display monitor that depicts the radia- tion levels as colored areas 
superimposed upon a tomogram. The user is able to specify target and source positions, divergence, width, 
frequency, and initial intensity profiles for each beam. One may also place filtering devices such as 
lead wedges in the path of the beam. The system uses a storage tube console, a color television display 
and a pen/tablet combination. Most information is communicated to the user via the color display while 
the user graphically con- trols the system primarily through use of the pen/ tablet combination. A 
session using the Radiation Treatment Planning System consists of selecting and positioning beams until 
an adequate dosage pattern covers the tumor area. After the contours have been defined, the user graphically 
selects a target point and a source point by movement of the pen (Figure 8). One can next give the command 
to generate the beam, either with default values for the beam parameters or by specifically defining 
them. The beam is then computed and the results displayed. The radiation levels are coded using both 
variations in color and different intensities of color. Figure 9 shows the generated beam. One can also 
adjust the width and the divergence of the beam (Figures i0 &#38; ii). This is accomplished by using 
the pen and interactively "dragging" the lines that demark the limits of the beam. (a) b) 1 2 3 ~ 5 
6 J Figure 7.a)lllustration of manner in which radia- tion beam is divided into adjacent component beams. 
b) Graph of typical profile of initial intensities across the component beams.  200  It is also possible 
to add filtering devices if desired For example, one may expose the treatment area through a lead wedge 
in order to achieve a particular penetration pattern. Figure 12 shows two beams traversing lead wedges 
with different source points. As additional beams are placed, the results are combined and the cumulative 
dosage levels displayed. If a beam leads to undesirable results, it may be removed and then regenerated 
or positioned with suitably modified parameters. The session is com- plete when an adequate dosage pattern 
covers the treatment area. In this case, Figure 13 may be judged to be adequate. 4. CONCLUSION The 
ability to obtain a complete mathematical des- cription of complex three-dimensional biological organs 
has been presented. By combining edge find- ing methods with a unique surface representation approach, 
all positional and volumetric information can be obtained from a standard tomographic section. The resulting 
surfaces can be displayed in color to provide an excellent visualization and comprehension of these complex 
structures. The numerical informa- tion can be used for both diagnosis and control of treatment strategies. 
 A radiation treatment planning system has been des- cribed which uses actual density information ob- 
tained from tomographic scans to compute the radia- tion dosage. The graphical system provides visual 
feedback to the physician and enables an interactive development of the treatment plan. Although the 
two-dimensional treatment planning system provides a powerful tool for the radiation therapist, the potential 
implications are even greater. The sys- tem should be expanded to allow treatment strategies to be developed 
on arbitrary cross sections. We are currently working on combining the three-dim- ensional reconstruction 
system with the radiation treatment planning system to provide full three-dimensional capacity. ACKN 
OWLED GEMENT S The authors gratefully acknowledge t~he support of the Whitaker Foundation and Cornell 
University who jointly sponsored this work. The systems described are a collaborative effort between 
Cornell Medical School and the Cornell Program of Computer Graphics. The surface representation algorithms 
were developed by Sheng-chuan Wu, and the smooth-shading display routines were created by Doug Kay, both 
graduate students at Cornell. The medical imaging and con- sulting were provided by Dr. Gordon Potts 
of Cor- nell Medical School REFERENCES i. Ashkar, G.P. and Modestino, J.W., "The Contour Extraction 
Problem with Biomedical Applica- tions," Proceedings of 1977 IEEE Conference on Pattern Recognition and 
Image Processing, pp. 216-221, Troy, NY (1977). 2. Blinn, James J., "Models of Light Reflection for 
Computer Synthesized Pictures," Proceedings SIGGRAPH, 1977, pp. 192-198.  3. Budinger, T.F. and Gullberg,G.T. 
"Three- Dimensional Reconstruction in Nuclear Medicine Emission Imaging," IEEE TransactioNs on Nuclear 
Science, Vol. NS-21, No. 3 (June 1974).  4. Catmull, Edwin A., A Subdivision Algorith m for Computer 
Display of Curved Surfaces, Dept. of Comp. Sc., Univ. of Utah, UTEC-CSc-74-133, Dec. 1974. Also, Computer 
Display of Curved Sur- faces, Proc. Conf. on Comp. Graphics, May 1975 (IEEE Cat. No. 75CH0981-IC), 11-17. 
 5. Cho, Z.H., "General Views on 3-D Image Recon- struction and Computerized Transverse Axial Tomography," 
IEEE Transactions on Nuclear Science, Vol. NS-21, No. 3 (June 1974)  6. DeClemented, A., Mohan, R., 
Reddy,M.T., Holt, J.G., "The Memorial Hospital External Beam Treatment Planning Program " Memorial Hospital 
New York, NY (Nov. 1971).  7 Gordon, W.J. , " ' Spllne-Blended Surface Interpo- lation through Curve 
Networks," J. Math. Mech. Vol. 18, No. i0 (1969).  8. Gouraud, Henri, Computer Display of Curved Sur- 
faces, Dept. of Comp. Sci., Univ. of Utah, UTEC-CSs-71-113, June 1971. Also IEEE Trans- actions on Computers, 
Vol. TC-20, June 1971.  9. Lane,K., Bloch, P., Davis, L.W., "Computer Generated Isodose Curves for High 
Energy X-Ray Machines," American Journal of Roentgenology, Radium Therapy and Nuclear Medicine, 121(4), 
pp. 865-872, Springfield, ili. (Aug. 1974).  i0. Liu, H.K., "Two- and Three-Dimensional Boundary Detection," 
Computer Graphics and Image Pro- cessing, 6:2, pp. 123 (1976). ii. Meredith, W.J. and Massey, J.B., 
"Fundamental Physics of Radiology," John Wright Sons Ltd., Bristol (1968). 12. Neilson, I.R., Slater, 
J.M., Crispens, J.W., Chu, T., and Carlsen, E.N., "Interactive Com- puter/Ultrasound System for Radiation 
Treatment Planning," in Medinfo 74, North-Holland Pub- lishing Co. (1974).  13. Newton, C.M., Ryden, 
K., Nelson,R. and Johnson, J., "Remote Graphics Treatment Planning (RAD- GRAF)," in UCLA Health Sciences 
Computing Facility UCLA, Los Angeles, Calif.  14. Riesenfeld, R.F., "Applications of B-Spline Approximation 
to Geometric Problems of Computer Aided Design," PhD Thesis, Syracuse 15niv.(1973).  15. Riseman, E.M. 
and Arbib, M.A., "Computational Techniques in the Visual Segmentation of Static Scenes," Computer Graphics 
and Image Processing 6:3, pp. 492-501, NY (1977).  16. Rosenfeld, A., "Iterative Methods in Image Analysis," 
Proceedings of 1977 IEEE Conference on Pattern Recognition and Image Processing 14-18, Troy, NY (1977). 
 17. Rosenfeld, A., "SURVEY, Picture Processing: 1976," Computer Graphics and Image Processing Vol. 
6, No. 2, pp. 157-183 (April 1977).  18. Torrance, K.E. and Sparrow, E.M., Theory for Off-Specular Reflection 
from Roughened Sur- faces, J. Opt. Soc. Am., Vol. 57, No. 9, Sept. 1967, pp. 1105-1114  19. Tuong-Phong, 
Bui, Illumination of Computer- Generated Images, Dept. of Comp. Sci., Univ. of Utah, UTEC-CSs-73-129, 
July 1973.  20. Wu, S.C., Abel, J. and Greenberg, D.P., "An Interactive Computer Graphics Approach to 
Sur- face Representation," Comm. of ACM (0ct.1977).   202  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807391</article_id>
		<sort_key>203</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>36</seq_no>
		<title><![CDATA[Spatial management of information]]></title>
		<page_from>203</page_from>
		<page_to>209</page_to>
		<doi_number>10.1145/800248.807391</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807391</url>
		<abstract>
			<par><![CDATA[<p>Methods of spatially managing data are currently under study at the Architecture Machine Group. Management concepts are drawn from everyday examples of paper and document handling. However, the work elaborates data types to include: animation, movies, and sound-sync computer graphics.</p> <p>Beyond the application of management information systems, the paper portrays a sophisticated surround of keyboardless, interactive, and large scale graphics. Computer graphics, image processing, and broadcast are viewed as one. The system includes three frame buffers, four minicomputers, two touch sensitive displays, an octophonic sound system, and an MCA Optical Videodisc.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Man-machine interfaces]]></kw>
			<kw><![CDATA[Management information systems]]></kw>
			<kw><![CDATA[Multimedia databases]]></kw>
			<kw><![CDATA[Raster scan computer graphics]]></kw>
			<kw><![CDATA[Spatial data management]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.2</cat_node>
				<descriptor>SDMS</descriptor>
				<type>P</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Spatial databases and GIS</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003236</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Spatial-temporal systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010887</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Geographic visualization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Human Factors</gt>
			<gt>Management</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P334392</person_id>
				<author_profile_id><![CDATA[81100276084]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Donelson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Architecture Machine Group, Massachusetts Institute of Technology, Cambridge, Massachusetts]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Batter, J., and Brooks, F., Jr., (description of a force-feedback device), Information Processing, Vol. 71, (1972), p. 759]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bolt, Richard A., Spatial Data Management, Interim Report., MIT Architecture Machine Group, November, 1977.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Donelson, William C., Spatial Management of Data., M.S. thesis, Massachusetts Institute of Technology, August 1977.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Herot, C. F., et al, Preliminary Design for a Spatial Data Management System., report to Defense Advanced Research Projects Agency, April, 1978.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Neisser, U., Cognition and Reality., San Francisco: W.H. Freeman, and Co., 1976.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Noll, A.M., Man-Machine Tactile Communication. Ph. D. thesis, Polytechnic Institute of Brooklyn, (1971); J. Soc. Information Display, Vol. 1 Number 2, (1972).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Stewart, Lawrence, Xerographic Output for a Color Raster Scan Display., B.S. thesis, Massachusetts Institute of Technology,(1976)]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Spatial Management of Information William C. Donelson Architecture Machine Group Massachusetts In.stil~ute 
of Technology C:.ambridge, Massachusetts 02139 Methods of spatially rlana~Jnp data arecmrently under 
study at tile Architecture Machinv Group. Management concepts are drawn from evel yclay exantples of 
paper and d.ocument handling. However, the work elaborates data types to include: animation, movies, 
and sot,nd-sync comput.er graphics. Beyond the application of mana vement in(ormation systems, the paper 
portrays a sol,histicated surround of keyboardless, interactive, and l;,i~,e scale [,,raphics. Computer 
graphics, image proce~qn~.~, and broadcast are viewed as one. The system includes three frame buffers, 
fo.ur minicomputers, two touch sensitive dlsplay$, an octophonic sound system, attcl an MCA Optical VJdeodisc, 
Key Words: Spatial Data Manasenleut. Management Information Systems, Multimedia Databases, Raster Scan 
Computer Graphics, Man-machine Interfaces. 1.0 INTROI)UCTION The most common form of data management 
is not ill tile reahll of compuler scientists, or evert in the sometimes gigantic file systems ttsed 
by large organizations. Data Manag:ement occtns most flpquently in the personal wa')'s in which we organize 
our own collections of information, be they invoices, accotrn.ting statemeffls or the memos on our desks. 
This information is rno~t often or?,~nized spatially, that is we t.end to create stacks of similar information, 
with each stack placed in some convenient or easily remembered location. One's desk toll is a ~:c, od 
example of thi~ management strategy. Atttom;~lJon has transformed this n~tural spatial system into ~ 
symbolically accessed compendium of data. The user of sttch a system nmst remember tile set theoretic 
combinations needecl to retrieveeach piece of information. Although this allows access of inform~lJon 
in new ways, it has given up many of the clues by which people organize their own data. such as: remend-?ling 
the memo to your secretary because it was next to the telqd~one, locating a stack of letters 'by r~'membet:inB 
that yoti have to strelch out your right at:m, or findJnga book by Hotin~ its l,ro×mtity to the large 
red one. In our research at the Architecture Machtm. Group we are' concentrating nit those qualities 
of interactive s.ystems which may bc ~..~Zo!i understood by a user. By this we mean that we will draw 
open those experiences and concepts abea,dy famfllar to the user. A data base management system, the 
Spaual Data Mana[,ement System (SDMS), has been developed to adches~ many of the above notions of spatiality, 
hlthis system we have enlisted the user's a priori understanding of sp~ce tel the p,,rposes of managing 
a very large data base, accessed in a comfo)table and HatUl'al nlanner, and drawin~ npOll the sam," w'rceptual 
;~hilities t, sed by humans to remember and tt, naw[,,ate al~ollt tile real world. These include tile 
visual, am:al. sl,alial, and hal)tic perceptions of tile user. The system i~ driven from all instrumented 
chair containing pressttre-setlsjlJvl- joysticks which allow the user to'drive throu.gh't(le .data b¢~sp 
much as a pilot flies an airplane, The chair also contains two touch seosilive tablets which are used 
for gesture recognitJorL atld a di?Jlal lapboard is available for hand annotation of lhe ima~es. The 
cl~ta base itself consists of alphanumeric, ~lapl, ic, photo.p.ral,hic and filmic information which is 
presented to the user on a six foot by eight foot rear-projected color televiqon ,:, The work reported 
herein has been funded in total by the Cybernetics Technology Office of the Defense Advanced Research 
Projects Agency (Contract # M.DA-903-77-C-0037, Nicholas Negroponte Principle Investigator). di.~play. 
Sywlchronous, multi-'channel sound . Jnfornlation., "located" at v;irious points'on the color images 
of the data base, ate presented to theuser over an oct.ophonic sourld'system. Fhesp devices alld systems, 
located in a sr~ecial "media. room" (Ftf,,. I), a3e inlended to generate an ".information surround" and 
to l:,J,?vicle a forum for the exploration of appliecl and 2.0 PERCEPTUAL SPAGES Management o.f data 
in SDMS is accomplished through tile t,set's familiarity with three perceptual spaces: visual space. 
~uditory space and hal)tic space (the.space of tactile sensations). In many ways this management strategy 
is similar to tha-t a person might use in a,ranging a bt, l.letin board or papers on a de.~k, in storin:F, 
and retrieving objects in a closet, or in navjgalmo arotmd a familiar city. An excellent reference on 
the human perception of space is F~ivenin (5). 2.1 T_hc\.//i.~,J~lSpace Vision is the most common and 
possibly the most important means by which people, access t.heir personal do'to bases. Clues as to 'the 
location of information in thespace may take or] .such visual aspects as position, shape~ color or texture. 
These clues. used irtdepenclently or in .combination with other sen.sory data, will allow for various 
types of searches for information in the data base. 203  lhe l,d,' of position in the search for particular 
lit'ms ill lhe space mav take either all absolute form, as in "the uF, l,er M, fillllpr flf lhe desk," 
or a relative form where location I~ ,, fnnflltln ,~f <.,ii¢i,, olher item, as in "next to the tell, 
phone," el "tllidel the cai,,nclar." Vision is often used in coniunCllOll wllll the Sl)<,lial illl'nlory 
of item's IocatioD,i.e. lhe aitentioii is fiisi locllr.ed oil the r,<,nlenlbere.d spatial position, and 
then a visual cealcll el lhal general area is made to.determine the item's exact l,-,cation. Even if 
there is no spatial memory of the localion el the ilern, an exhausli.ve visual search may be made rapiglly 
by il~lil{{ the chics'of color, texture, or shape. Visual location o1 information often takes on associative 
aspect~ This hal,l,ens wheel a search is made for data which is kllowl, to l,e connected with the desired 
item in some way. A,, example: looking for the card catalogue in a library becaus, - you want to know 
wbere to find a particular book. In ,gI)MS. viulal spatiality has been achieved orl the sell~O,y h, vel 
by allowing the user to "fly" around the information sp~res nf the data base. The effect of flying is 
cr~2ated through u~'l curttrol of two joysticks located in the arms of.the chair. "lh~,se joysticks direct 
th.e tr.anslation andscaling of intag'es on the scref'n. <~o The AuditoLy-Space ~.,G . .................... 
 Alil,ot~{,h vision is a directed perception, the sense of hearin r( i, ,mll,iluecent and nlay be exploited 
for its special qnality of lint haviug a t.,eTM. As a rlavigational aid, sound has great poleritial for 
relaying information independent cff t.he aitentlrUl l'If Onl eyes, It,would be very helpful if, for'examFile, 
"ivhen scanuii,?, a map for a subway station one could actnally, hear th,' ~r,llll(lq i'll llallIS jilllning 
at approl~riate points on the chap, tu when scalchin?, for all airport one could' hear the sound of au 
a u plane m diiect our attel-ltioli to that area. In St)MS, stuind is used both as a data type and as 
a naviganonal aicl. When an information space co.ntams souml as data. the sounds will be "displayed'"at 
a vohl.nle which is i u opel tioual [o their distance from. the edges of the l.a rg'e screen If the dala 
a~sociated with athletics were to the right of the scleen, tl)e uver might hear ihe.sound of cheering 
crowds growmp, h,,,d,Tr when rnovin.g in that direction. 2.3 "l-h," I {all!it ._qpace_e l lal,tlr space 
i~ that space in which physical sensations siich a'. tOlich ai,d kn,esthetic perceptions occtlr. These 
are vr'ly inll,Oliarii sensations used during.otlr everyday lives which often <p,o urinolicod. They involve 
situations such as localiri{, a nlenlo l'ly renlenlbeliing the stretclTin.g of a41 arrn to tim left, 
I.,), the feel of a rouffh;exture as you'put d/owna book, and in ih," muscular reflexes neded to operate 
an automobile.. In SLIMS. the haptic space includes .the user's tactile perceptlr,i,s when tr,uchmg the 
ancillary displays and when usirl E the ioysticks to fly around the information space. Exalnl,les ot 
systems which explore, some aspects of haptic space n/ay |u, found iu wcu L' on force feedback systems 
(I,.6). 3C TIlE ltSI..I~ I-NVIRONMENT In atlptnl,ln]p, tr, create as efficient and comfortable a user 
ellVllOnlliel.lt as iS possible for "SDMS, we have built what we call the"hledni P, oom." Physically' 
it'is a room 18 feet wide by II feet deep, and about 11'.112 feet high, as slmwn in Fig. I. 'lhe wall~ 
ate crwerer.l with about tw.o inches of grey fnam rubl,el whkh i~ used for soundproofing as well as providing 
a nentlal visual sut round. On'e wa.ll of the room contains a la,f.(e six fqr,, by eight foot lelevJsion 
screen. The room also contains twin olhm cli~l,lay~ (both touch sensitive.),.an 0ctophonic sound Syslelll, 
a data tablet, and the usei"s control chair. 3.1 The I,a,ee Scleen Display The lai?.e displ.ay is a rear 
projection screen ripen which a Genelal Electric l.ight Valve may project full color P.G P, el NTSC encoded 
video images. This system is, used to display Ihe varlt~us photographs, movies, animated' sequences, 
and textual It,'ms of the SDMS data b~lse. 3.2 "F.12_e-_A.L~c.ilLaLy Displays The tw,, smaller raster 
scan systems located to .th.e left and ri?.hl of tlle crmttol chair are used for navigation about Lhe 
data base. OHe disl,lay, called, the "world view monitor," Js nsed to show the usm"s current position 
in the data space. The sgccm.d nm,,iml ,~ nsed to display information about data the user i~ l,elusiu.p., 
and is referred to as the "key maps monitor." I~oth displays a,e 12" diagol)al Tektronix color monitors 
which have been r,'nofined with touch sensitive surfaces I to allow the 'user IO inleracl directly with 
the information they present.  3.3 ~l'ljs' ~;.)g!opl!r:![}ic Sound System An el r,.l,t d,annel sound 
system is used to "clisplay" the so,md- sync i,orlinus rff the data base'through tile e~ht speakers in 
the nl;pdia lento. IJsing this system, sounds may be presented to t.he user from varimlsdirections and 
special effects, including Dol,ph.'r shifts, may be produced under computer control. 3.'I iF_Jjff' i_r 
.C~j!jJ_Jjo{_Cl_la  SDMS is driven from an instrumented control chair located ;1hour ei?ht fret from 
the. large'display.s~:reen. The chair is well upholsleled arm very comfortable, and allows the user .freedom 
of movenmnl a,ld vision as well as a~:cess to the a.ncillary monitcns Each arm of the chair has been 
modffjed toc.ontam a pr,ssure SpllSilJve joystick a!id a 3" square, touch sensitive tablet called a ,{r~yl~ad. 
''2 A I0" square Summagrapl~ics tablet ? and stylus ale available to the user for hanc l a.nn.otation. 
The lablet has been t,,sl,in,,ed for.use as a lapboard, and may be stored ou a table It, the Ir'ft of 
the chaiF when not in use. 4.0 AC.CI:.SSING DATA SPACE Ill,on siltin,r,, down in the control chair the 
user may be I),esr'nler{ wllb a variety ofimages and sounds. The irriapje r,I, the la,r.,e sc,een shows 
a small portion of the verylarp~ '"data surface." the filmament upon which all SD.MS data items a,e Iocatecl. 
"l'his planar surface is the geometry upon which SI )M'. <', spatially ol[,,at,izes its da.ta. Since, 
the data st!rface is !ypically huIICll'erAs of times the size of the large screen,.a navipatirmal air{ 
i~ lU,~virlr'd to assist in user orientation. This aid, the "woIH vi,'w 1110111101,"located to the right 
of the user, shows a shvNnL,:u ima?,e of the entire data surface complete with a smftll. hif, hlif, h/ed 
"you are here" rectal-lgle indicating tile large ~Cl con's Wllldow onto'the data surface, 41 MgyCn,en! 
?!:~.eJtlt the Large Data Sn,face There are two ways of moving about the SDMS. data surface I"Joypad" 
is a registered trademark of I Incorporated, 73.5 Addison Street, Berkeley, California 84710. 2A tablet 
based on magnetostrictive ranging produced by'the Summagraphics Corporation, 35 Brentwood Ave., Fairfield, 
Connecticut. 3The touch sensitive screen.is manufactured by the   ELOGRAPHICS Corporation of Oak Ridge, 
Tennessee. The surfaces we use for the ancillary monitors are made of a flexible plastic which allows 
them to be wrapped.around the cylindrical tube of the Tektronix, significantly.rt~duci-ng parallax problems. 
205  Oue is via tile pressure-sensitive joystieks located in each arm (,I tile control than. The other 
is via the.tot~ch-sensi.tive screen of the world view monitor. 't.1:1 The Joysticks Two juysticks are 
used to control t.he user's "fligi~t" around lhe large data surface. The right hand joystick controls 
the lateral (x ~nd y) motion and the left hand' stick controls "zoomin.i,," towards.and away from the 
data surface. Tile rate of movement in hoth cases is directly proportional to the p~;r'ssure exmn'd For 
example, if the user pressed lightly leeward on the i:~,hl hand stick, the large scre.en would apl)ear 
to be moyin~ slowly towards the north. If he pressed also to his left, the motiou would swing towards 
the northwest. If he then pressed forward on the left hand stick, the screen would appear to dive iu 
towards the data surface. 4.1.'2. Rapid Transit Another form of movement about the' data surface is 
via tlie touch sensitive screen of the wor[d view mon.itor. This movement, which we call "rapid transit," 
allows the user to quickly pnsition the large screen over any portion .of the data surface by merely 
touching the desired position on the wotld view scleen. The large screen's .image would then'be immediately 
changed to show its new position on the data st, elate. 4.2 D:)ta.~ryj~es and Perusal A user moving 
over the data surface will see various ph0tograldls, icons, and graphics, These items represent data 
which hns been placed on the. data surface. This data may. take the form of: -Photographs, diagrams, 
and full color slides -I ligh quality text -Movie,~ and animated sequences -Sound, bolh as a data type 
and as a navigational aid -l.laud written and verbal annotations 4.2.1 Photogral)hs, Diagrams, and Full 
.Color Slides Photographic data may be stored at any point on the data surface, and may be accessed 
by zoomin~ and panning. As the user ;,oc, ms in toward .th~ photographic image, levels .of increasing 
resolution are added until the resolution of the ori~inal digilization is reached. In this way a photo?3-~.l-,h 
may be stored a~ a small, low tesolution item on t.he data surface..bul with higher resolution versions 
a~:cessible by zooming. ,t.?.2 Textual Data Certain of tile items on the data surface may represent 
text. A~ the user zooms in, the image on the large screen is rel)la~.ed wlth the first page of the text: 
This text comes fronl.a standard ASCII lext file stored on d[sk, and is form,atted, justified, and disphyed 
in high quality font on the screen. The user may fli U pages of the text by making a "flipping" motion 
on one of the joypads located in the arms of the contr.ol chair..The fhpl~in!,. motion is a diagonal 
line which is "finger painted" on the joypad. A flip from rigllt to left ",~ill direct the system to 
sliow the next page of text, while a flip inlthe other direction will return to the previous page. A 
series of quick flips allows the user to rapidly skim the text file. Tile key map monitor to the user's 
left will show a list el chapters or headings along with an arrow indicating which section of the text 
file the user is reading. When the user is done with the text, he pulls back on the left hand .joystick 
to return tn the data surface. 4.2.3 Movies and Animated Sequen(es As in tile ra~e of photographic add 
t.e, xtual d~ta, both movff". at|d aninl~tions may be viewed by' diving into the item ou flu' data stuface 
which represents the desired sequence. When lh,' user lonnls h/Io olle of these items the in)age oll 
the lar?e sc~ een is swit(hod to ~, video recording of the movie or auimatinn ou the M('.A VJdeodisc 
system. The key maps monitor will dial,lay a clock face showing tile e,[apsed time of.the sequence beirut 
viewed ~ a i)loport.ion to the total time. The user may use the touch sensitive surface of this monitor 
to s[ov4 down, reverse, freeze frame, or high speed sca.n the s.equence, by directly manipulatin[,~ the 
hand on the'clnck. "1.2.'ISf,uud-Sync Data As sound is also a data type in SDM.S, tile user may dictatf 
 o~ record somld data and then "place" it at any position on the dat~ surface. Suhsequently, this data 
will be displayed owTr the al)propri~te speakers, at a volume which is propJortional t.o il~. distaltce, 
including zoorh;'from the user. "l.2.b HaudwHtten and Verbal Armotations At auy time wilde pelusing tile 
I~hOtogral)hic.and.textual dala types, the laphoard tablet and stylus may be used to annolate (Ile jnla?es 
ill either transpa.rent or opaque colored ink. "l J~l'~ ink is scale sensitive it] that an a'l).proximateiy 
constant .width litm is dlawn,independent of how far the user has zoom.cd IHh~ the image. In this way 
the user may annotate small details with flue ink hy zooming in, and .may' "highlight" areas, such as 
text, with blood ink by zoomhlg out. Vml)al annotations may be created with the lapboardand slylu~ hy 
l~ninting at the location on the data. su.rface wheze the annotation is to be place~}. When the user 
presses the pen ou the lapboard tablet, an FM transducer pi~:ks up his Sl)Okml annotation and relays 
it toth.e digitizin[{ har.dware of the smmd system.  5.n IMPI.FA~4I.~NIA'I'ION AND HARDWARE SI)MS i~ 
currently centered around a network of foul miniccunl,uters. These machines handle the tasks of system 
control aud file manlier, lotion, intejprpcess.ol. communicatir~ll. usF, r illlmactiolls, sound gen!eration 
and synch,onizatlo.n, aud color raster so;u) displa.y. This network .is shown m Eip;. 2. . ---) /  
-~if~ GE Light Valve Fig. 2 -The SDM$ Minicomputer Network 206  5.1 Tim Central hlachine "l-l,r, t-,~111Dal 
machine in tl?e network, an lnterdata model' 717.?, handlos all l:UO.~/ram and file manipulaHon for SIgMS, 
as wr,ll a~ containing tlw hardware and software for commt,nicalion wit!i the olher machines ill the 
network. A 300 Megabyte-DMa St,u,: thsk (Control Data Corpora!ion) is used for central file and lUo?ram 
stnrap~e. Only the sol,tware and control files of &#38;])M..S are stored on Ibis disk, with the actual 
data base bein!,. clistribul,'d a,non~!; the disks of the outer thr~'e processors, l-he` re,nilel nlachine" 
also contains the int~ifaces for the control chall'S ir, yslicks and joypads, tile Summagrap,hics l;Dl,board 
raldr.l, and tlm ~.IC';A Videodisc. The coqtrol program of ,Sl)hlS contmur, usly ~r,acls the state of 
the control chair clevtcrs anr.l .'.ell(iS afllnll requests to the appropriate machin.es, For examl,l,'. 
whvu lhr` nser l,ushes on a joystick to move across the data sm flu,:, the, coul'rol machine requests 
the update of the irnal,,.e~ on lhr, laq,.e and ancillary screens and also directs the sound pz c,(e~s(, 
to adjust tile display of any sound-sync data. 5,'2. Tim V Irlual Frame Bul,l,er Fhr` virtual frame buffer, 
hsed.to drive the large scre,~n's display of IIw SUMS data surface, is based on a display d,r'viro (allr'd 
lhr, "lu,',,el v,,mdow" which is connected to a nlicto-codahlr, minicomputer, the ]nterdata 85.. This 
device was or~mally rlnsJ~llr'cl tO work in tandem with a Xerox 65Q0 crdor cop.ir,r l? ptoclnce color 
hardcopy of images in its frame buffe~ (7). l,-he lUxr,l window has two features which have allowed us.to 
Inll,l,,ulr,n! the virtual frame buffer, system for disl)lay of vr,ly lal[,.e im;q,,es: the ability to 
start each faster of tide inm,?.e frond any pnlnt in the frame buffer memory (done thr:ot.lgh a rasu,i 
m~l-,imL~, ,' table of 't80 addresses, one address for each ra~ter on th, ~ screr`n a~ in Fig. 3) and 
the ability to repeat pixel~ horizontMly on r,ach raster.These t-wo features allow the rr`al time, srahng 
;,nd translation of any image !n the l,ranle buffr`r Illenloly, nmlr,ly by settin~ I.II~the proper values 
in the rastr,r mapl:~hv tahh,, and by settiqg the pixel repeat count. ~ Window Vild;lay Ram ter Address 
 Picture Mapping  Memory Table Fig-.. 3 -The Pixel Window. Rasters. may be drawn from various addresses 
in the picturememory. hi orclr'r to achieve the very large data sin:face of the-,Sl)hls (our curlent 
data surface consists of over 'I0 million pix.els) wr` h~ve flevD~*d a scheme by which the pixel window's 
?Igk l)ylv fl-~mr, hullr,r nlay be toroidally reused. That i.s, when some of the clala sul l.ace image 
moves off'one side of the screen chlrin?. nlovemenl, the mr.nlory is "wrapped around" to tlfe other side 
oi, the sct evn and the continuation of the" large data surface in)ape` (stored on cli~k) is read ill. 
We have, in .effect, n)apped the, frame buffer memory into a torus, or doughnut (Fig. "I.). tJs ]p this 
system we are able to continuously %troll the I;D?r` .~crr`en window overan image whose size is limited 
only by disk cal.mciry, thus tide name: 'Virtual ]:Tame Buffer. I picture[-~ 5 ~'-/ memory ~ extent-- 
1 i 2 i 31 large----~ 4 i 5 , 6 [ screen ~- ~ -" -: ..... ~--- ~'" to roi-dal I L?~8 .-~9 J memory mapping 
Data Surface image (on disk)  Fig. 'l -The toroidal mapping scheme for reuse of'.the picture memory. 
In practice, memory moving off screen is remapped into the area where the eontinutation of the image 
will be. This image is scrolled, from the'model 85's disk.  5.3 hjc.A Opucal Videodisc The, optically 
reacl videodisc isa recent addition to St)MS: l~,ecanse of this, it has been used primarily for tile 
animatron and luovio data types and its potenti'al as a single, frame m:,~< sireage` mrd'iun-t has been 
only superficiial!y explorecl "at thi~ date. With ll,r, viclr'odisc a user has access to 54,000 full 
color frame,s, v,,ilh a worst case access time of three se~:onds. The cor~cel.~tu;~l impact i~ oue of 
Very Large Data Base (VI-DB). :VI,I)P, aSl,r,cls of 5l)h.l,.S have not been ex.tens'ively studied at 
lh,~  Wl ilin?,. The` frarnr,~ of tide videod, isc may be concatenated, into m,,vW sr,queucv~, played 
forwarcls or backwards, at higli speed, in slew nlotion Ol leal lime and accompanied by two channels 
of anrho. At this time we have had two discs manufa,ctured. C)ne colDlains 5"I,0(I0 separate slides of" 
travel, archit.ectuve, art ~.nd peJsonal snapsots. The other is a. collection of soils (6000) and movies 
of MII ~ for the p'urposes of surrogate travel about thf' Institute. 54 The Snnnd lhocessor "l-he, so,rod 
processor is an lnt.erdata model 7/32 which is interfaced Io a 2314 type disk drive and the sound reprodnctir,n 
aw.I rvcordmg hardware. This system is .capable of retrJevJn}:~ four di~:itally recorded souud signals 
from disk which m,ly tlmn be, reproduced octophonJca'lly. The combinatorial .scheme i~ shnwn m Fig. 5. 
This scheme is used to play. the fou: sounds which are` located closest to the posiUon of the large screen 
oveD the, data surlace. ,.Sounds may also be recorded by the u.ser and "placr,d" orDto the data surface 
at any time. 5.5.Wg!Jd.:.View.?_nd Key Map Displays "[lie fomth m;,chme, also all lnterdata 7/32, is.used 
to drive Ihr world view and key map monitors and their toL~ch sensitive screr,ns. "lhe 7/32 is interfaced 
to'a Ramtek'R-M-9300 frame bufl,er and display system, which contains picture..memory fo a 640 by 4,£0 
pixel image of 12 bits per pixel. Eight bits of this ima.[~e are devoted to the shrunken version of the 
,SDMS data surface. (we bits are allocated for two iran~parent inks whicl, are used for aunotations on.tile 
world view display, and two bits (four cokus) are u.sed to drive the independent key map display. The 
wc, rld view image is static with tile exception of tide ,?'h ?btf'd "you are here" rectangle indicatiLl[,~'th~ 
la ~e srrrr,n's i.,sition over tbedata surface. The key m.apdisplay is loaded from a 231"1 type disk 
connected to the 7t32 and is drivetl .by commands from the control maohine. 207 Amplifier Channels 
Input 1 2 3 4 5 6 7 Signals 3-~" 4-'~ Outputs Fig. 5 -The sound generation hardware. Outputs ~re the 
weighted sums of the four input signals. Each position in the matrix may be set with the desired volume 
of that signal to be played on that channel. B.0 HIST()RV AND USER EXPERIENCE Ihe .ql)MS implementation 
desert.bed in this paper is actually the' third version implemented since M.archof'1977. The f,lq version 
wa¢. ;i prototype and included only the l)hoto~;rald-Hc data lyl,'. The second version, as de scri.b.ed 
in (2, 3) w,~ completed i~i August of 1977 and included the phot.o~,?,rald~i(. sottnd-sync, and annotation 
d'ata types. This secon.d syslem i~. worthy of note ill that it t, fed a hierarchical structule of photographs 
Io store the images of the data base. All of. lhr,~,' imaKes were slored as the nodes of a tree (Fig. 
6) with certain areas of each image being the "ports" by which lov4er bra.che~ of the tree were tlaversed'. 
  TOpLevel Structure 2nd Level ~~2nd Level /~ 3rdL~ ~ ~d Level~ &#38;#169; "("Jn~" i ccalls tile 
Boston CommoD, and its network of towpaths. Createa flat pasture, and the cows will lake ca re of the 
lest. Break up the pasture into a .multi-lflatw. terrarf' :~yslenl, and you must make provision for budclin,p~ 
~ malty bridges as there are.two-way links to anticipale where any. cow (us,?r?)may tare to wander." 
(2) In fact. the large flat cow pasture, is the exact solution we cho~o hl thr,'olrrent versioll of 
SDMS. The user .of the large surface spieads lhr, data out into a moro spatial rel~.resentation, lhll¢, 
,~liminatin~( the need for manycomplicate.d leyels o['Irierarchy. A seco.d major problem was in the ll.~e 
of ,%OllUd a.~ a navi!,aliollal aid. In tile second version of SlJMS,.som,,l w;.~ only diH,l:wcd stereol,honically. 
This resulted in dirocllr,n:,l aml,i,9.uily fro soun.ds above .and below the large screeu. In addiliolL 
only two sounds could be retrieved from di~k, mixr,,.l. and l~hyed at one time. This limited the. user 
to hearmi,, o~dy two SOmlrl¢.. even if three or four were within hearing dislallce. 7.0 CONCI]RRENT WORK 
SI)MS is a two year project, started in October 1976, funderl by the Cyl,et netir_s Technology Office 
of AR'PA. l.q Oclobf'r 1977, ARPA al~o flmded an overlapping two year SDMS effort, aimrd at C.~l,ilahTinf 
~ on tile experience of the contract at MIF. Thi~ conHact was awarded to the Computer Corpmation of America. 
Their effort, like the one at MIT,'will include tlle visual (lala tYl,es hilt wall not focus on the issues 
of sync-sound or animalr'0 sequences and movies. Their system will be desk top.bat, ed, aud will irfflude 
joysticks, digitizing tablets, and three small or,lot monitors for data interaction as in Fig. 7. q'he 
CCA cffrqt places eml,ha~is on a.finar product of'modest cosi and e:~sy replication, preferably based 
on commer~:iall.y availal,le hardware ('t). " " ( ...... ) Fig. 6 -The tree model of the second version 
of the SDMS data base. The major problems with this sy~,tem were in navigation ab(,n the tree structured 
hierarc.hy, and in its lack of si'ze and flexibility. Our experience with this system raised several 
speciHc issues with regard to navigation. First., as a usrl zoounod farther down into tile tree structure 
of the data bliso oricntalion became all almost impossible task. For example, if the us~'r had roomed 
down to a particular image node on th," third level of the tree aud then wanted to go to some othe! nod," 
on another branch of the tree, there was no easy way to affcct that transfer. Certainly not spatially, 
as the tree-structure wa~ only a "Jo.f.,~icaJ" space. In addition, several.attempts to define navif,.ational 
aid for this process becar0e boondo~.gled .m trymp. to map the t~ee structure.o( a ht.mdred image nodes 
onto a two dimensional-display screen. O O  Fig. 7 -A possible desktop based .SDMS. (Courtesy CCA) Ol~e 
inteJesting difference between the two contracts i~ C('A'~ mteresl in co~struc.ting a system which inter'faces 
to a symbohr. Data l~ase .Management System (DBMS), ill this case th~ INGRES system. This SDMS would 
permit the t,ser to acces~ data bolh Sl)atiMly antl symbolically. 8.0 FUTIJRE WORK Our fllture efforts 
at MIT will fqcus on several issties; one of whi(h is arl attempt to spatially organize the 5'1,000 slldes.on 
lht, MCA Videodisc. One concept being studied is.'called "lOl,lCM Sl)atiality" arld involves on-the~fly 
crea'tion of' a data sulfate 208 speelhea]l 7' tailored tO a user's request. Consider Ollr cur!elH vid~'odisc, 
li contains over sixteen thousand slides of archileclural inlelest about Europe, and covelin~ a riuri11~r?.r 
eft ci'llllll'Ir'~. This collection is "indexed" by cquDtry, elate, style, tYl,C (¢hiuch, municipal builging, 
monumen.t, etc.). If the tlsel were Io i f'qur'st, for example, to see specific buildinl.~ types over 
lhe sllan rd y,'ars 1300 to 1750, then a 2-D data surface call l.,, coinl,cPsed Willl [i111e as the horizontal 
axis, and with sca.le el ctril1~-llllClirill (till" exa.mple) arranged 011 the vertical axis. I h,' ur.r.r 
w,-,lild then find Baroque and ecclesiastical slrilclures in. the N(lll heasl. Annlh,'r lopic of iilterest'Js 
in the area' of "prr4cess as data." hHtial wr~rk has been done on this project and sev.eral icons rJti 
the data surface repres.ent subsystems. These are mana~:ed spatially, jus.t as are the other data types, 
and include such e×anlll]es ag: - a l,,Or.:ram for pamting and for pro- c.cs~in~, idlotogt'aphic images, 
and one for creating data icons,  - a l,lO!~Iam to digitize (via vidicon c;,mela) photographs and tp 
place them ¢ff-llO the data surface,  - i,IOg,,ram~ to modify the control structure of SDMS i.tself.. 
 Also under consideration are subsys.lems such. as: -ree,,ivers for live televisio.n and I adio, . animati,~n 
systems, both two and duee dimensional, operatln~ system routines S~dch as coml~ders and editors, graphic 
digplays of file systems, etc., -coimeciions to other computer, s.yslems via the ARPAnet, and lhoughls 
of .integrating 9tl~er" lescarch projects for demonstraiJoh l,lirposes, i.e. the latest demos !ruder 
~lWcial icons. Aficr thi~ work however, .the real question seems to .be. olle of. suitahihty: IIow well 
do other processes'fit intoSDMS? Is thig method of process management truly convenient? What about the 
tral]sferral of information between these sltbsystems? "I"hele are no {,.,~netal answers to these questions 
yet. For r, ow, subsysiems will be implenlel~ted as d.emand indicates and judged on an individual basis. 
 9.0 CONCI~.US1ONS hl lhis paper we have attbmpt.ed to "present the ct, rrenrly imldetnr'nrcd features 
of t.he SDMS and to touch upon some of our ideas for the future. Although the current iml~lementatiOll 
is flow. usel response to SDMS has confie.med spatial ril,"illTiPrllit'llt Of j:llfolmatJon as an Otltstanding 
eolicr'pt A', ~i sl)alial systern it encotll'agJes the laser to employ the sit; It3 slraterws in which 
we are all proficient. The ability of SI)/~|S to malqi.ill a complex array of multimedia dev'ices alld 
syst,mls in a f.~,hmn lhal is exceptionally easy to use, and is emmil]ei~tly comp,ltil.He with lhe human 
percTeptual system, (s an excelleli! featllre. We note Ihat experienced users fly around the dat.a bate 
with case, exhibitillg all of the behavior one..wot~ld expect of .a person familiar with a p, articularenviron'mbnt. 
Naive users and even chiklren rapidly acquire the necessar,y analogues to. their own ur,terstanding of 
space. They are able to move throu?h the data l,as~' quickly and.efficignlJy; they very rapidly refer 
l~J data as beitq,, in the West, below the green square, the it,~tn which is imisy. They have mastered 
the "~Command Langila<{,,e" of ,.%[)]VIF, wilhin two minutes of sitting down. This is. lhe flUe, success 
of SI.)M5. ACI< NOWI.EDGMENT This work has heen conducted in close collaboration .with lh. Richard Bolt, 
who has lead the research sta'ff of SI)MS. The co autholshil~ of ideas is reflected in his early publication 
(2). ACKNOWLEDGMENTS This work has been conducted in close collaboration with Dr. Richard A. Bolt, who 
has lead the research and development staff of SDMS. Implementation and development of the systems and 
concepts described in this paper have been under the direction of the author. Special thanks are due 
to Ben McCann, Joseph Rice, Steven Tufty, and Rimas Ignaitis. REFERENCES I. Batter, J., and Brooks, F., 
Jr., (description of a force-feedback device), Information Processing, Vol. 71, 0972), p. 759 2. Bolt, 
Richard A., Spatial Data Management, Interim Report., MIT Architecture Machine Group, November, 1977. 
 3. Donelson, William C., Spatial Management of Data.,  M.S. thesis, Massachusetts Institute of Technology, 
August 1977. 4. Herot, C. F., et al, Preliminary Design for a Spatial Data Management System., report 
to Defense Advanced Research Projects Agency, April, 1978. 5. Neisser, O., Cognition and Reality., San 
Francisco: W.H. Freeman, and Co., 1976. 6. Nell, A.M., Man-Machine Tactile Communication. Ph. D. thesis, 
Polytechnic Institute of Brooklyn, (1971); J. Soc. Information Display, Vol. 1 Number 2, (1972). 7. 
Stewart, Lawrence, Xerographic Output for a Color Raster Scan Display., B.S. thesis, Massachusetts Institute 
of Technology,(1976)  209  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807392</article_id>
		<sort_key>210</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>37</seq_no>
		<title><![CDATA[One-point touch input of vector information for computer displays]]></title>
		<page_from>210</page_from>
		<page_to>216</page_to>
		<doi_number>10.1145/800248.807392</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807392</url>
		<abstract>
			<par><![CDATA[<p>The finger as a graphical stylus enjoys a coefficient of friction with glass sufficient to provide input of direction and torque as well as position from a single point. This report describes a pressure-sensitive digitizer (PSD) capable of accepting these force inputs, and discusses a set of five simple input applications used to assess the capabilities of this device. These applications include techniques for specifying vectors, and pushing, pulling, dispersing and reorienting objects with a single touch. Experience gained from these applications demonstrates that touch and pressure sensing open a rich channel for immediate and multi-dimensional interaction.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Force input]]></kw>
			<kw><![CDATA[Kinesthetic input]]></kw>
			<kw><![CDATA[Pressure sensing]]></kw>
			<kw><![CDATA[Pressure sensitive digitizer]]></kw>
			<kw><![CDATA[Tactile input]]></kw>
			<kw><![CDATA[Touch input]]></kw>
			<kw><![CDATA[Touch sensitive digitizer]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.1.2</cat_node>
				<descriptor>Human information processing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Input devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Spatial databases and GIS</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003236</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Spatial-temporal systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010887</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Geographic visualization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010391</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010216.10010217</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Philosophical/theoretical foundations of artificial intelligence->Cognitive science</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P47676</person_id>
				<author_profile_id><![CDATA[81100434357]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Christopher]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Herot]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Corporation of America, 575 Technology Square, Cambridge, Massachusetts]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P330592</person_id>
				<author_profile_id><![CDATA[81100087391]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Guy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Weinzapfel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Architecture Machine Group, Massachusetts Institute of Technology, Cambridge, Massachusetts]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Nicholas Negroponte. On being creative with computer aided design. In Information Processing 77, B. Gilchrist, Editor, IFIP, North-Holland Publishing Co., New York, 1977.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Dr. Richard A. Bolt. Spatial data - management - interim report. Architecture Machine Group, M. I. T. Cambridge, Massachusetts, November, 1977.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807391</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[William Donelson. Spatial management of information. SIGGRAPH '78, Proceedings of the Fifth Annual Conference on Computer Graphics and Interactive Techniques. Atlanta, 1978.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Guy Weinzapfel. Mapping by yourself. Proceedings of the conference Interactive Techniques in Computer Aided Design, Bologna, Italy, 1978.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A discussion of various TSD technologies is provided by Dr. Richard A. Bolt. Touch sensitive displays. Architecture Machine Group, M.I.T. Cambridge, Massachusetts, September, 1976.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[TSD work is continuing under the aegis of ONR Contract Number N00014-75-C-0460 with Elographics Corporation furnishing a transparent sensing medium laminated to a Tektronix 650 display.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Several "kinesthetic" systems, that is systems incorporating force feedback, are summarized by Frederick P. Brooks, Jr. The computer "scientist" as toolsmith - studies in interactive graphics. In Information Processing 77, B. Gilchrist, Editor, IFIP, North-Holland Publishing Co., New York, 1977. However, none of the systems summarized in this paper correlates physical and graphical feedback at a common locus.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>907929</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[P.J. Kilpatrick. The use of a kinesthetic supplement in an interactive graphics system. Ph.D. dissertation, University of North Carolina, Chapel Hill, N.C., 1976.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A.M. Noll. Man-machine tactile communication. Ph.D. dissertation, Polytechnic Institute of Brooklyn, Brooklyn, N.Y., 1971.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[The display used for this project is an IMLAC PDS-1 dynamic CRT. This display may be driven by any of the laboratory's several Interdata minicomputers (models 70, 85 or 7/32). The operating system (MAGIC) and the display software are both of Architecture Machine Group design.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A more complete technical description of the TSD is provided in the reference cited in (5) above.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[A general discussion of task performance related to diminished and augmented feedback is provided in Paul M. Fitts and Michael I. Posner. Human Performance. Brooks/Cole Publishing Co., Belmont, California, 1967.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Subsequent to this study, it was learned that Robert Anderson and Ivan Sutherland, working at Rand Corporation had explored a pressure-sensing device to locate the x,y position of a touch. Though the Rand device used a considerably different mounting configuration, the calculated touch point migrated as the touch pressure was varied. To minimize this problem, positions were calculated using a low pressure threshold.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
   3.0 PRINCIPLES OF OPERATION. The PSD employs eight strain gauges, two each secured to mounting 
rings centered on the four sides of the TSD. Of the two gauges secured to each ring, one measures force 
perpendicular to the glass and the other measures shear parallel to the glass. These eight measurements 
are then used to derive the three force and three torque outputs which are used by the routines described 
in the previous section.  3.1 MOUNTING AND STRAIN GAUGES. The TSD is secured to the CRT by means of 
 four specially machined, octagonal, aluminum rings. All forces exerted on the TSD are transmitted to 
these rings, thus causing deformations which in turn flex the strain gauges secured to them. The two 
gauges are cemented to each ring as shown in the adjacent figure. Their placement insures that the forces 
which they sense are orthogonal to one another. Shear Sensing Guage a Force Sensing Guage  3.2 ELECTRICAL 
DESCRIPTION. The PSD utilized nine BLH (SPB3-35-500) semiconductor strain gauges. Semiconductor gauges 
were selected because of their sensitivity to miniscule strains. However, as semiconductor devices, 
they are also very sensitive to changes in temperature. Accordingly, a ninth gauge mounted such that 
no strain could be exerted upon it is employed to provide a reference output to which all other gauges 
can be compared. The gauge outputs, which vary between plus and minus 10 millivolts peak to peak, are 
 each connected to preamplifiers which impart a gain of 50; the resultant "raw" output is .5 volts 
peak to peak. The "raw" voltages from the strain gauge preamplifiers are combined by sum and difference 
networks to produce outputs which correspond to X force, Y force, X moment, Y moment, and Z moment. The 
sums of opposite torque gauges are used to provide the torques about each axis. X-Torque X-Foroe (About 
X Axis} Y-Force  Q Y-Torque [About y Axis) Z-Force Z-Torque (About Z Axis) It happens that the 
thickness, and hence flexibility of these rings is critical to the sensitivity of the gauge's measurements. 
Unfortunately, the rings machined for this implementation were designed to accommodate very subtle pressures; 
the fact that the TSD necessitates high finger pressures was not taken into account in their design. 
Nor was the vibration from nearby machinery foreseen as a problem. As a result, development of the five 
input routines was somewhat hampered by vibration and pressures which exceeded the output range of the 
gauges and related circuitry. Were the equipment to be rebuilt, heavier rings would greatly improve 
its performance. Alternatively, load cells, rather than strain gauges might be used. Load cells measure 
pressure without deformation. However, these devices are significantly more expensive than the strain 
gauges used for this implementation. The six force and torque outputs are converted to digital signals 
by a Burr-Brown 8DM853 data acquisition system (DAS) . The inputs to the DAS are limited to 6.2 volts 
to prevent overloading the A/D converters. The DAS produces a 12 bit output for each of the 6 analogue 
inputs.  3.3 DIGITAL INTERFACE. The outputs from the DAS are stored in a buffer, allowing the DAS 
to assemble the next sample while waiting for the computer to read the current values. The computer 
interface allows program selection of either byte or halfword mode. In byte mode, only 8 most significant 
bits  of each force and torque are used, allowing fast and easy access to the data. In halfword mode, 
the programing is a bit more complicated, but all of the data bits 214 are available. Due to the influence 
of vibration on low order bits, the device was operated primarily in byte mode for the experiments described 
here.  3.4 SYSTEMS SOFTWARE. The PSD is equipped to interrupt the computer When data is available. 
However, since the PSD is always used in conjunction with the TSD, the interrupt circuitry of that device 
was used. When the TSD detects the finger touch, the program reads the position from the TSD and the 
forces and torques from the PSD. Since hysteresis of the strain rings and uncompensated temperatre drift 
often cause the untouched PSD to produce non-z ero readings, it is additonally important that the TSD 
interrupt be used. When the software detects that the device is not being touched, it reads the values 
of the forces/torques so as to use them as zero references the next time the PSD is touched. Drift due 
to temperature changes generated problems for the initial input routines. This was overcome by adding 
software to sample the force and torque readings when the TSD was not being touched. The latest readings, 
then, were used as offsets for subsequent inputs. However, this software compensation was made at the 
expense of the system's overall response range: the offsets biased the device unpredictably. A zeroing 
circuit was designed to correct for temperature drift in hardware. This circuit was not installed due 
to the short duration of the study and the anticipated cost associated with its installation. Third, 
the input routines were used to determine if a pressure-sensitive device could convey more natural perceptions 
of virtual objects. While limited success was achieved in conveying the differential weights of objects, 
the quality of such perceptions is only marginally improved by the use of the PSD. It would be misleading 
to rely upon the device as a mechanism for providing passive force feedback. Finally, the PSD and its 
routines were developed to explore any un fores een benefits which might accrue from the implementation 
of such a device. Here, two definite advantages can be identified. First, the PSD/TSD combination affords 
 engaging and facile interaction which attracts and maintains the participation of all who witness 
its use. Second, the device has proven innately simple to use. By capitalizing on natural skills, the 
PSD enables users to take advantage of virtually all its capabilities within minutes. At a recent 
open house it was astounding to see four-and five-year-old children pointing at words with the vector, 
turning the knob about and shooting ducks with obvious glee. Of course, the PSD's ultimate advantage 
is its ability to collapse activities which otherwise require several disjoint commands into single, 
natural, tactile actions.  4.0 CONCLUSIONS. Development of the PSD and related input routines was 
undertaken in order to determine answers to several questions. First, we wished to know if it was technically 
feasible to measure finger pressures on a sheet of glass and to decompose those pressures into their 
X, Y, Z force and torque components. That question has been answered in the a f firmative. Second, the 
work was conducted to determine if force and torque inputs could be applied with sufficient accuracy 
and control to be useful for man-machin e communication. All of the input routines indicate that accuracy 
presents no serious problem, especially where continuous, real-time, graphic feedback is provided (as 
in the Force Cursor and Rotation routines). Vector History indicates that flexible, easily controlled 
interaction is possible as well. However, this routine also shows that force input is more suited to 
the modulation of velocities than for the control of accelerations. ACK NOWLED GME NTS. The work has 
been very much a group project, initially launched by experiments with touch sensitive display (TSD) 
 devices, conducted by Richard Bolt and under ARPA contract numb er MDA- 903- 76-C- 0261, April I, 1976, 
to September 30, 1976. During that period, William Donelson, a graduate student, speculated that translational 
and Z-forces could be sensed by strain gauges. William Kelley, assisted by Robert Hoffman, John Soltes, 
and Harry Boadwee, constructed the hardware outlined in Section 3.0. Peter Clay, building upon earlier 
TSD software by Rimas Ignaitis, implemented the input routines outlined in Section 2.0. Finally, Michael 
Naimark made the film which is to be shown at SIGGRAPH 1978. This long story attributes the conjoint 
efforts of our laboratory, as encouraged by Dr. Frank Moses of the Army Research Institute.  215 FOOTNOTES/REFERENCES 
 1. Nicholas Negroponte. On being creative with computer aided design. In Information Processin~ 77, 
B. Gilchrist, Editor, IFIP, North-Holland Publishing Co., New York, 1977.  2. Dr. Richard A. Bolt. Spatial 
data-management -interim report, Architecture Machine Group, M. I. T.  Cambridge, Massachusetts, November, 
1977 .  3. William Donelson. Spatial management of information. SIGGRAPH "78, Proceedings of the Fifth 
Annual Conference on Compute__rr Gr__~hics and Inter~t-~ Techniques u Atlanta, 1978. 4. Guy Weinzapfel. 
Mapping by yourself. Proceedings of the conference Interactive T_eechniques in Computer Aided Design, 
 Bologna, itaTy, l~'/r. 5. A discussion of various TSD tech- nologies is provided by Dr. Richard A. 
Bolt. Touch sensitive displays. Architecture Machine Group, M.I.T. Cambridge, Massachusetts, September, 
1976. 6. TSD work is continuing under the aegis of ONR Contract Number N00014-75-C-0460 with Elographics 
Corporation furnishing a transparent sensing medium laminated to a Tektronix 650 display. 7. Several 
"kinesthetic" systems, that is systems incorporating force feedback, are summarized by Frederick P. 
Brooks, Jr. The computer "scientist" as toolsmith - studies in interactive graphics. In Information 
Proeessinc[ 77, B. Gilchrist, Editor, IFIP, North-Holland Publishing Co., New York, 1977. However, none 
of the systems summarized in this paper correlates physical and grahical feedback at a common locus. 
 8. P.J. Kilpatrick. The use of a kinesthetic supplement in an interactive  9. A.M. Noll. Man-machine 
tactile commu- nication. Ph.D. dissertation, Polytechnic Institute of Brooklyn, Brooklyn, N.Y.,  graphics 
system. Ph.D. dissertation, University of North Carolina, Chapel Hill, N.C., 1976. 1971. i0. The display 
used for this project is an IMLAC PDS-1 dynamic CRT. This dislay may be driven by any of the laboratory's 
several Interdata minicomputers (models 70, 85 or 7/32 ). The operating system (MAGIC) and the display 
software are both of Architecture Machine Group design. ll. A more complete technical description of 
the TSD is provided in the reference cited in (5) above. 12. A general discussion of task performance 
related to diminished and augmented feedback is provided in Paul M. Fitts and Michael I. Posner. Human 
 Performance. Brooks/Cole Publishing Co., Belmont, California, 1967. 13. Subsequent to this study, it 
was learned that Robert Anderson and Ivan Sutherland, working at Rand Corporation had explored a pressure-sensing 
device to locate the x,y position of a touch. Though the Rand device used a considerably different mounting 
configuration, the cal- culated touch point migrated as the touch pressure was varied. To minimize this 
problem, positions were calculated using a low pressure threshold.  216  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807393</article_id>
		<sort_key>217</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>38</seq_no>
		<title><![CDATA[Interaction with a color computer graphics system for archaeological sites]]></title>
		<page_from>217</page_from>
		<page_to>221</page_to>
		<doi_number>10.1145/800248.807393</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807393</url>
		<abstract>
			<par><![CDATA[<p>Our goal was to design and implement an interactive system using a color video display to assist an archaeologist in the task of analyzing the spatial distribution of various objects from an excavated site. The existing system configuration required controlling the display over a slow communications line from the mainframe CPU, and there was little local intelligence in the minicomputer display driver. The user of the system was expected to be computer-naive. Certain design principals evolved which should be applicable to graphical database query systems in other domains.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Archaeology]]></kw>
			<kw><![CDATA[Color graphics]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Design principals]]></kw>
			<kw><![CDATA[Information retrieval]]></kw>
			<kw><![CDATA[Interactive experimentation]]></kw>
			<kw><![CDATA[Interactive systems]]></kw>
			<kw><![CDATA[Three-dimensional data]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.8</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Query formulation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.2</cat_node>
				<descriptor>Archaeology</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010432.10010434</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Archaeology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003325</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Information retrieval query processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Management</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP95043390</person_id>
				<author_profile_id><![CDATA[81452608047]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Norman]]></first_name>
				<middle_name><![CDATA[I.]]></middle_name>
				<last_name><![CDATA[Badler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Toronto, Toronto, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334208</person_id>
				<author_profile_id><![CDATA[81100637276]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Virginia]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Badler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Badler, Norman and Badler, Virginia. SITE: A color computer graphics system for the display of archaeological sites and artifacts. Dept. of Computer and Information Science, University of Pennsylvania, Technical Report No. 77-76, (August 1977).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Badler, Virginia and Badler, Norman. A new analysis of Thermi. Archaeological Institute of America, 79th Annual Conference Abstracts, Atlanta (December 1977), 38.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Miller, Lawrence H. A study in man-machine interaction. AFIPS Conference Proceedings, Vol. 46 (1977), AFIPS Press, Montvale, N.J., 409-421.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Status Report of the Graphic Standards Planning Committee of ACM/SIGGRAPH, Computer Graphics 11, 4 (Fall 1977).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Wheeler, Sir Mortimer. Archaeology from the Earth. Penguin Books, Baltimore, 1966.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 INTERACTION WITH A COLOR COMPUTER GRAPHICS SYSTI~ FOR ARCHAEOLOGICAL SITES *Norman I. Badler, University 
of Pennsylvania, Philadelphia, PA Virginia R. Badler, University of Toronto, Toronto, Canada Key Words 
and Phrases: Interactive systems, computer graphics, color graphics, information retrieval, three-dimensional 
data, archaeology, design principals, interactive experimentation. Computing Reviews categories: 3.36, 
3.49, 3.70, 8.2 ABSTRACT Our goal was to design and implement an interactive system using a color video 
display to assist an archaeologist in the task of analyzing the spatial distribution of various objects 
from an excavated site. The existing system configu- ration required controlling the display over a slow 
con~nunications line from the mainframe CPU, and there was little local intelligence in the minicomputer 
display driver. The user of the system was expected to be computer-naive. Certain design principals evolved 
which should be applicable to graphical database query systems in other domains. INTRODUCTION Archaeological 
excavation is by nature a destructive process. At their best, current excavation techniques seek to remove 
occupation layers, one at a time, and thereby establish what is contemporaneous and what is not (5). 
Individual layers can vary in depth and thickness, but a layer lying above another (barring any disturbance) 
is assumed to be later in time. 0nly when chronological context is known can cultural developments be 
traced. Unfortunately, this method of excavation has not always been practiced, either because the excavation 
preceded the technique, or because the excavator was ignorant of it. There are many important excavations 
which lack careful records of object locations and therefore the chronology of the site cannot be reconstructed 
with confidence. There is, however, a group of sites falling inbetween these extremes, where the excavators 
were more diligent in recording object placement vertically and horizontally but clear occupation layers 
were not established. The analysis of the material from the latter type of site is a formidable task 
for an archaeologist, since it requires that J_nferences be made regarding the three-dimensional arrangement, 
distribution, and context of all objects. Manual techniques cannot efficiently establish these * Department 
of Computer and Information Science, The Moore School of Electrical Engineering/D2. relationships, most 
of which crucially depend upon visualization of large subsets of the data. In particular, questions such 
as the following might arise: How many distinct cultural periods are there? Is a period evident over 
all or only part of a site? Are there any occupational gaps at the site? Are all objects of one kind 
localized or are they distributed evenly over the site? In what period (context) does a particular object 
cm object characteristic appear? It should be noted that none of these questions is peculiar to a poorly-excavated 
site, only more difficult to answer. AN INTERACTIVE SOLUTION Our approach to solving these problems 
was to design and implement an interactive computer graphics system which could be used by a computer- 
naive archaeologist. The purpose of the program is to assist the archaeologist in formulating and visualizing 
the three-dimensional relationships between objects in a database. The system performs no analyses itself; 
it only presents color images to the archaeologist who supplies his or her own interpretation. It is 
therefore a tool to be used with a scientific method: an hypothesis is proposed, the data distribution 
examined, and the hypothesis confirmed or refuted. The hypothesis can be easily altered by interactively 
changing the set of objects selected for the display. Program design began in January 1977 and the first 
version was operative May 1977. After observing its use a modified system was implemented by August 1977 
(i). Results of archaeological significance were obtained and reported at the Archaeological Institute 
of America Annual Conference in December 1977 (2). Some of the observations which we made during this 
time may prove useful to designers of other systems based on color video displays and used by non-progranmers. 
 217 Our hardware environment supplied many constraints. The Moore School of Electrical Engineering 
at the University of Pennsylvania runs a UNIVAC 90/70 computer under a virtual memory operating system 
with a primary emphasis on inter- active terminals. Attached to the 90/70 as a terminal running at 2400 
baud is a PDP 11/05 driving a RamtekGX-100B color video display (Fig. i). This is a mediumresolution 
system (240 x 320) with 12 bits of color information (4 each of red, green and blue). It incorporates 
an older shift- register architecture rather than a random access bit map, and has no video lookup table. 
The Ramtek display includes a trackball to position a cursor on the video screen. The trackball is used 
as a button, pick, or locator in the graphic standards sense (4). There is little local intelligence 
in the PDP/ 11-05. It controls an alphanumeric display terminal and keyboard and buffers messages between 
the Ramtek and the 90/70, perfor~ning no processing other than decoding packed Ramtek instructions from 
the 90/70 and passing trackball location information (on a trackball interrupt) or keyboard characters 
back. Every interaction with the display is handled by the 90/70; likewise, it must generate all displays 
on the Ramtek. In this environment, our user generally observed low variability in the response time 
to a cor~nand (3). Thus either all responses were nearly instantaneous, or else all were equally slow 
(when the 90/70 was heavily loaded). Our design attempted to use the slow eo~nunications rate as a feature 
whenever possible. Aftering defining the system capabilities, we shall be able to describe the specific 
design deeisions these constraints proscribed in terms of command menus, information labelling, numerical 
inputs, error handling, graphical information retrieval, and information display. SYSTEM CAPABILITIES 
 The archaeology system presents three scenarios to the user: site plans, vertical sections, and legends. 
A plan is a vertically- oriented, right-circular cylindrical volume described by two depths, a center, 
and a radius. A section is a vertical slice of arbitrary thic~ through a plan. The database consists 
of objects with six attributes, each object attrlb--lb~having one value from a set of up to forty discrete 
choices. Figure 2 shows a possible set of values for one attribute. This table (called a legend) contains 
values for an attribute called "class" which has been used to list the possible cultural periods associated 
with an object from stylistic evidence. The colors down the center are the choices which may be assigned 
to any subset of the values; one such assignment is shown. Besides attribute values, each object has 
a spatial location and extent represented by a vertically-oriented, right-circular cylindrical volume, 
since real objects have some spatial extent or uncertainty. An object can be anything which is adequately 
modelled by (sets of) cylinders: a pot, a sherd, a floor, or even an assemblage of other objects. The 
fundamental operation is the display of the spatial arrangement of objects in plan or section. We shall 
call this operation a query. Queries are formulated by first defining the desired legends, picking a 
plan or section, selecting a particular attribute and marker type, and then starting the data display. 
Retrieved objects intersecting the plan or section having an attribute value colored in the legend are 
displayed as colored markers: on a plan as discs proportional to the object radius, small squares, or 
dots; on a section as rectangles or crosses proportional to the object depth range, small squares, or 
dots. The layouts of the two displays are different so that they become inmediately distinguishable. 
Plans (Fig. ~) display in a square viewport while sections (Fig. 4 ) are scaled to fit a rectangular 
viewport exactly, thus emphasizing their vertical scale. Besides a global menu to select a legend, plan, 
or section, these are the only screen formats presented to the user. Among the capabilities available 
to the user on a plan (Fig. 5) are: start the object display, erase the object display, overlay various 
two- dimensional line drawings, create a new overlay, display the sections currently in the section directory, 
mark a new section to be placed in the section directory, print the legend at the terminal (so that 
the plan need not be erased), find and locate a particular object, print the query result in tabular 
form on the line printer (hard copy), "zoom" (scale) the current display, alter the plan depth range, 
rotate the plan, select the marker type, and select the attribute for retrieval. Figure 5 shows the result 
of retrieving objects according to the "class" legend of Fig. 2. Two- dimensional plan overlays are included 
(the virgin soil excavation boundary and the coastline) for reference. From this query, the archaeologist 
might note the relatively even distribution of objects over the part of the site excavated to virgin 
soil (lavender overlay) from both sets of class values. Sections have a similar conmand set (Fig. 6): 
erase, zoom, print, start, legend, find, marker type, and retrieval attribute, plus move forward or backward 
to parallel sections by a given increment, adjust the thickness of the section, pick a section from the 
directory, and save the current section in the directory. Both displays also permit the inquiry of a 
displayed marker to disambiguate overlapped markers and provide access to individual object entries in 
the database. Figure 6 shows the result of retrieving objects according to the legend in Fig. 2. The 
archaeologist can observe the apparent layers formed by the two sets of object class values: the lower 
in red, the upper in blue (and lavender where they overlap). The use of graphics in the query definition 
and display process permits an inmediate visualization of the spatial contexts, arrangements, and distributions 
of objects in the site. Textual queries and responses cannot provide this capability. Interaction also 
encourages formula- tion, testing, and refinement of hypotheses which would be otherwise difficult or 
laborious. We 218 shall now detail the specific design decisions which were made or forced upon us 
by our hardware and user environment. COMMAND MENUS Since a substantial plan or section display area 
is desired, the limited screen resolution restricts the number of possible menu light buttons. The slow 
communication rate prevented the display of icons or symbols, since the existing ASCII character set 
is much more efficient to generate. The user does not readily forget the functional association of a 
well-chosen phrase or abbreviation. At the start of a plan or section display, all meaningful options 
are presented. When a command is selected, the other conmands are not erased because the menu redraw 
time would be excessive. Instead the selected item is highlighted and the conmand suffix changed from 
"?" to "!" until the invoked process is completed. Any options or messages generated by the selected 
conmmnd are written in the secondary message viewport (Fig. 3; overlay names in Fig. 5). Further interaction 
is restricted to this viewport until the commamd is completed. The secondary viewport is extremely valuable 
because it avoids erasure of disabled menu items (which would be a distraction) and instead directs attention 
to a specific part of the screen. INFORMATION LABELLING Information labelling is also restricted by 
the screen resolution. We used this to advantage by color-coding the marker symbols with the attribute 
values defining the query. The resulting plan or section displays are thus free from data labels. Such 
information can be retrieved and displayed in the secondary viewport by picking the marker. Numeric 
information (such as plan depths, section length, and number of objects displayed) is conveyed by the 
position and color of the number. In a plan the depth dimensions is portrayed by a linear potentiometer 
scaled to the overall site depths and marked by red and green cursors at the current user-defined limits. 
The lower depth limit is red and the upper limit is green; these also label the depth range values on 
a section. The length of a section appears in the lower right corner of the section display viewport. 
Depths are drawn with a marking increment chosen to avoid crowding the numeric labels. The number of 
objects actually displayed appears at the top at the completion of the retrieval process. Other numerical 
data desired from a plan or section is obtained from the hard copy produced by the "print" conmand. 
NUMERICAL INPUTS Because the user did not know (nor care to remember) the coordinates of the site, numeric 
inputs are reduced to a minimum. (The first version of the program requested coordinates and radii for 
plan zoom and an angle for plan rotate and users either avoided these options or failed to understand 
their effect. ) Non-numeric, but understandable, selection methods can be found: for example, plans 
are zoomed by locating a center and a radius point, and are rotated by picking a center point and another 
point which is to lie visually above the center. Both techniques emphasize the visual result, rather 
than (unfamiliar) numeric transformations. Plan depths are selected on the depth potentiometer. Sections 
 are defined by locating endpoints, picking an existing section off a plan display, or zooming a section 
by locating two corner points. Section thickness and the increment between parallel sections may be 
entered numerically through the keyboard, but are easier to mark directly on a plan display. ERROR 
HANDLING Since our user is computer-naive, it is essential that nothing which is done wrong causes the 
program to fail. Illegal trackball inputs elicit no response. The lack of system confirmation of a traekball 
interrupt is enough of an "error message." (Fortunately, the response time of our system is fast enough 
to permit this technique to work since every conmmnd is aeknowledged with a second or two. ) The user 
interface is designed to process all keyboard inputs as character strings. Illegal characters eannot 
cause FORTRAN I/O errors. Input routines buffer all keyboard inputs and parse the string to determine, 
for example, its legitimacy as a number. Illegal inputs result only in a "retype" request (since so few 
keyboard inputs are required). Most errors are simple typing mistakes. The system is therefore completely 
insulated from illegal command sequences. GRAPHICAL INFORMATION RETRIEVAL Most of the preceding observations 
could be extended to other application systems subject to the same hardware constraints. Now we shall 
mention some charaeteristics of our archaeological application which results in a particular usage of 
the color and slow speed of the display. As we have indicated, the intent of the system is to permit 
an archaeologist to query a database of objects excavated at a site. Attribute values for a query are 
displayed as a table (Fig. 2) with a sequence of color "paint pots" down the center. By "inking" the 
cursor with a color (or the black rectangle at the bottom to "erase" colors) various values are selected 
to create a legend. The color choices are deliberately limited to the primary colors (red, green, and 
blue) and gray' values. (The gray values are useful for producing black and white prints for publication. 
) We limited the legend colors to the primaries because the overlap of colors on the plan or section 
display produces predictable composite colors, and because the composites can be used to structure Boolean 
queries of more than one attribute. The first point is easy to motivate. If the user sees a purple area 
on a display, the source is known to be the overlap of a blue and a red color. The user can select any 
object marker to disambiguate the overlap: the colors are separated into the contributing components 
in the secondary viewport. 219 The second point deserves more explanation. Attribute value colors permit 
the simple construction of Boolean queries by transforming the conjunction or disjunction of selected 
value sets into color combinations. Objects with a conjunction of attribute values may be found by successive 
queries. First one attribute is chosen and the objects displayed according to that legend. Suppose the 
selected values in the legend are all red. Then, without erasing the screen, another attribute is chosen 
and the object display begun again. Suppose the selected values in the legend for the second attribute 
are all blue. Then objects which have colored values in both attributes will appear in purple. A third 
attribute could be selected and its desired values colored green; then an object with all three will 
appear white. (While some of the color mixing may be coincidental, the attribute values of superimposed 
color markers can be displayed on the alphanumeric terminal by selecting the marker.) Disjunctive queries 
are even simpler to define: the desired attribute values are assigned the same, rather than contrasting 
colors. A side effect of color mixing is that partial matches appear. If we immgine the three queries 
defined above, then an object having only two of the three attributes will appear in purple, yellow, 
or green-blue, rather than white. The archaeologist can therefore examine other objects which may be 
related to the attributes queried. Other informmtionretrieval systems only explicitly list those objects 
satisfying the conjunctive query; our system shows partial matches as well. INFORMATION DISPLAY The 
slow communications line was used to advantage during the actual data display process. Objects are displayed 
from the deepest level of the site to the highest, subject to the section or plan depth limits. This 
"feature" makes it possible to visualize the "chronological" order of objects, especially on a plan where 
the instantaneous presentation of a display would be less effective in ascertaining two- dimensional 
development patterns. On sections, the object display from the bottom to the top indicates the relative 
progress of the query, much as the sliding cursor on the depth potentiometer of the plan display indicates 
its progress. It seems much easier for the user to assimilate the large amount of data presented when 
it appears on the screen animated at a moderate rate. Although we allowed the user to abort a (lengthy) 
query in the first version of the system, we removed that capability in the second since it slowed all 
queries, most of which were of reasonable duration. The zooms and plan depth can be used to control query 
time. CONCLUSIONS We have presented the constraints and design decisions incorporated into a computer 
system for the visualization of three-dimensional archaeological site data. Among the most important 
features for user interaction, the following observations may be applicable to other systems which query 
a graphical database: i. No a priori knowledge of the coordinate system is required. 2. Menus use text 
light buttons, redundant eon~mnd confirmation, and nonerasure of remaining co~smnds.  3. The user's 
attention is guided to a secondarymessage area to avoid excessive erasure and redraw.  4. Color is used 
to label information whenever possible.  5. Keyboard input is interpreted to insulate the user from 
the operating system.  6. The slow communication line is used to emphasize a particular feature and 
display information at a rate at which it can be assimilated.  7. Partial matches to a database query 
are portrayed by color mixing, providing additional contextual information,  In fact, there is no archaeological 
"knowledge" built into the system at all: the objects have arbitrary identities and the attribute tables 
contain arbitrary values. Not only can the system be applied to different archaeological sites by simply 
supplying a new database, but it can even be applied to other domains which require the visualization 
of spatially localized entities, for example, geological structures, space planning or well water levels. 
The plans alone provide significant capabilities for constructing maps, including interactively drawn 
overlays. Interaction encourages experimentation, speculation, and hypothesis formation: activities 
central to the scientific method. We have offered some guidelines to designers of interactive color video 
systems in the hope that they will lead to other fruitful collaborations with professional but computer-naive 
users. REFERENCES i. Badler, Norman and Badler, Virginia. SITE: A color computer graphics system for 
the display of archaeological sites and artifacts. Dept. of Computer and Information Science, University 
of Pennsylvania, Technical Report No. 77-76, (August 1977). 2. Badler, V.irginia and Badler, Norman. 
A new analysis of Thermi. Archaeological Institute of America, 79th Annual Conference Abstracts, Atlanta 
(December 1977 ), 38.  3. Miller, Lawrence H. A study in man-machine interaction. AFIPS Conference Proceedings, 
Vol. 46 (1977), AFIPS Press, Montvale, N.J., 409-421.  4. Status Report of the Graphic Standards Planning 
Committee of ACM/BIGGRAPH, Computer Graphics ii, 4 (Fall 1977).  5. Wheeler, Sir Mortimer. Archaeology 
from the Earth. Penguin Books, Baltimore~ 1966.  220 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807394</article_id>
		<sort_key>222</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>39</seq_no>
		<title><![CDATA[Making nested rotations convenient for the user]]></title>
		<page_from>222</page_from>
		<page_to>227</page_to>
		<doi_number>10.1145/800248.807394</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807394</url>
		<abstract>
			<par><![CDATA[<p>Subimage motion in a three-dimensional computer graphic system is much easier for the user to control if the subimage moves the same direction as his hand while he manipulates the control device. The implementation of such coordinated motion of hand and subimage implies modification of the normal procedure for calculating transformations. The convenience of such manipulation also depends on appropriate selection or design of the input device.</p> <p>This paper reviews the relevant attributes of locator devices and presents an approach to selection. It presents the mathematics of transformation nesting and &#8220;compensation&#8221; to preserve motionsynchrony. Finally, it offers a case history of an interactive graphic system whose human factors were improved by these techniques.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Analog input devices]]></kw>
			<kw><![CDATA[Coordinate transformations]]></kw>
			<kw><![CDATA[Ergonomics]]></kw>
			<kw><![CDATA[Human factors]]></kw>
			<kw><![CDATA[Kinesthetic correspondence]]></kw>
			<kw><![CDATA[Man-machine interaction]]></kw>
			<kw><![CDATA[Molecular graphics]]></kw>
			<kw><![CDATA[Nested rotation]]></kw>
			<kw><![CDATA[Three-dimensional computer graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Input devices</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.1.2</cat_node>
				<descriptor>Human factors</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010391</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics input devices</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P330069</person_id>
				<author_profile_id><![CDATA[81539175456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Edward]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Britton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39079779</person_id>
				<author_profile_id><![CDATA[81100198109]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Lipscomb]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P198449</person_id>
				<author_profile_id><![CDATA[81100365016]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Pique]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Barry, C.D., Ellis, R.A., Graesser, S.M., Marshall, G.R. CHEMAST: a computer program for modelling molecular structures, Proc. IFIP 1971, 1552-1558.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>908596</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Britton, E.G. A Methodology for the Ergonomic Design of Interactive Computer Graphic Systems, and its Application to Crystallography. Ph.D. dissertation, Department of Computer Science, University of North Carolina, Chapel Hill, N.C., 1977.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Brooks, F.P., Jr. The computer "scientist" as toolsmith: studies in interactive computer graphics. Proc. IFIP 1977, 625-634.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Foley, J.D., and Wallace, V.L. The art of natural graphic man-machine conversation. Proc. IEEE 62, 4 (April 1974), 462-471.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Hansen, W.J. User engineering principles for interactive systems. Proc. AFIPS FJCC, 39, 1971, 523-532.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>907929</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kilpatrick, P.J. The Use of a Kinesthetic Supplement in an Interactive Computer Graphics System. Ph.D. dissertation, Department of Computer Science, University of North Carolina, Chapel Hill, N.C., 1976.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Konopinski, E.J. Classical Descriptions of Motion. W.H. Freeman, San Francisco 1969.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Lipscomb, J.S. Three-dimensional Display of Molecular Models. M.S. thesis in progress, Department of Computer Science, University of North Carolina, Chapel Hill, N.C.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Newman, W.M., and Sproull, R.F. Principles of Interactive Computer Graphics. McGraw-Hill, New York, 1973.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Pique, M.E. Nested Dynamic Rotations for Computer Graphics. M.S. thesis in progress, Department of Computer Science, University of North Carolina, Chapel Hill, N.C.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>63448</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Rogers, D.F., and Adams, J.A. Mathematical Elements for Computer Graphics. McGraw-Hill, New York, 1976.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Tountas, C., and Katz, L. Interactive graphics in molecular biology: real-time three-dimensional rotations of images and image fragments. Proc. Summer Computer Simulation Conf. 1: session II-2.7 (1971), 241-247.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Tsernoglou, D., Petsko, G.A., McQueen, J.E., and Hermans, J. Molecular graphics: application to the structure determination of a snake venom neurotoxin. Science, 197, 4311 (30 September 1977), 1378-1381.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Woodson, W.E. and Conover, D.W. Human Engineering Guide For Equipment Designers, Univ. of Calif. Press, Cambridge Univ. Press, 1964.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>906110</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Wright, W.V. An Interactive Computer Graphic System for Molecular Studies. Ph.D. dissertation, Department of Computer Science, University of North Carolina, Chapel Hill, North Carolina, 1972.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 MAKING NESTED ROTATIONS CONVENIENT FOR THE USER Edward G. Britton James S. Lipscomb Michael E. Pique 
 University of North Carolina at Chapel Hill ABSTRACT Subimage motion in a three-dimensional computer 
graphic system is much easier for the user to con- trol if the subimage moves the same direction as his 
hand while he manipulates the control device. The implementation of such coordinated motion of hand and 
subimage implies modification of the nor- mal procedure for calculating transformations. The convenience 
of such manipulation also depends on appropriate selection or design of the input de- vice. This paper 
reviews the relevant attributes of locator devices and presents an approach to selec- tion. It presents 
the mathematics of transforma- tion nesting and "compensation" to preserve motion- synchrony. Finally, 
it offers a case history of an interactive graphic system whose human factors were improved by these 
techniques. Key Words and Phrases: three-dimensional com- puter graphics, coordinate transformations, 
nested rotation, ergonomics, human factors, analog input devices, man-machine interaction, kinesthetic 
cor- respondence, molecular graphics CR Categories: 3.13, 8.2 I. INTRODUCTION Many interactive computer 
graphic systems can present an object from different viewpoints and can move some parts of a picture 
with respect to oth- ers. The system designer decides which moving and viewing operations to provide 
the user. The de- signer should implement these operations in forms This research was partially supported 
by NIH Biotechnology Research Resource grant #RR00898, NSF grant #GJ-34697, AEC contract #AT-(40-I)-3817, 
and the IBM Corporation. Authors' present addresses: E.G. Britton, De- fense Communications Engineering 
Center, 1860 Wiehle Avenue, Reston, VA 22090; J.S. Lipscomb and M.E. Pique, Department of Computer Science, 
Univer- sity of North Carolina, Chapel Hill, NC 27514. that facilitate the user's accomplishments. Since 
moving and viewing pictures cua pictures is the user's method, but rarely his goal, he should feel he 
is manipulating the objects rather than their images. The user should command an interactive system 
by manipulating devices in ways related to his thoughts by kinesthesia or convention. Hansen (5) says 
to use "muscle memory --make actions mechani- cal not thoughtful." The user should move images by moving 
knobs or joysticks, not pushing buttons or typing. We suggest that when the user's hand moves a de- 
vice, the image controlled by the device should move the same direction. We call this similarity of paths 
kinesthet~ cor~esoondence. In our labo- ratory we have observed that such correspondence increases user 
productivity. 2. MEANINGFUL SUBIMAGE MOTION 2.1 CONTROL DEVI~E DESIGN The application model's motions 
may be rotations or translations, and may be confined to certain di- rections or be unconstrained. Selecting 
a control device requires examination of available devices in light of the application's requirements. 
 Fig. I summarizes some important physical device properties that we now describe. Not all of the combinations 
of alternatives are possible. Woodson &#38; Conover (14) discuss other properties important to good human 
factors. The user operates a rotation device by turning it about one or more axes, and a translation 
device by moving or pushing it in a straight line. Each is best used to control its own type of motion, 
but when limited to small movements each may effec- tively masquerade as the other. A bounded device 
has mechanical limits beyond which it may not move. All translation devices are bounded, but rotation 
devices may be bounded to less than 360 degrees, bounded to more than 360 de- grees (as multiturn potentiDmeters 
are), or un-  3. ALGORITHM DESIGN rotation vs. translation bounded vs. unbounded homogeneous vs. 
distinguished position spring vs. no spring return return Figure I: Physical Device Properties bounded. 
Bounded devices can effectively control unbounded motions if a clutch, when disengaged, logically disconnects 
the device and allows it to be moved back from its bound without moving the im- age. A homogeneous device 
presents no indication of its current position to the user, and has no posi- tions with special significance. 
Unbounded devices are homogeneous unless they have a position-indi- cating pointer. Bounded devices have 
distinguished positions at their bounds. A spring-return device has a distinguished posi- tion to which 
it returns when released. Such a de- vice is generally unsuitable for direct position- ing, but works 
well to control a motion rate. Rate control benefits from super-llnear response (e.g., x * ABS(x)), and 
a dead band that remedies mechani- cal inaccuracy inthe return: values near zero are considered zero. 
  2.2 AXIS COMPENSATION When nested transformations contain rotations, the control algorithm may need 
to perform axis com- Densation to allow kinesthetic correspondence. This compensation is a rotation transforming 
the movement from the user's reference space into the rotated space. For example, imagine the user has 
a spring-return two-axis joystick that controls the rate of translational motion of a small square in 
a picture, and a knob that rotates the picture in the plane of the screen. The square is nested within 
the rotation: when the knob is turned, the square follows as the picture turns. To achieve kinesthe- 
tic correspondence, the two-axis joystick should move the square in the direction the joystick is pushed, 
regardless of the picture's orientation. Such kinesthetic correspondence is achieved by rotating the 
vector representing the joystick mo- tion backwards by the over-all orientation angle and adding the 
result to the square's position (de- scribed in the rotating space). Accomplishing meaningful subimage 
motion in three dimensions requires the ability to construct a rotation about an arbitrary axis, modify 
that ro- tation properly, and nest the resulting transforma- tions. Every nesting of transformations 
may be de- scribed as a tree, with the outermost space as the root and nested spaces as the other nodes. 
We con- sider the outermost space an unmoving reference; every other space has a father space immediately 
above it in the tree. The arc between two nodes represents the relationship between the spaces; we describe 
this relation in the father space's coor- dinate system. Allpicture elements of a subimage are transformed 
by the same transformation. 3.1 ROTATIONS ABOUT ARBITRARY AXIS VECTORS A 3x3 matrix can describe any 
rotation about an axis through the origin of the coordinate system. As in Newman &#38; Sproull (9) we 
use a right-handed coordinate system, treating vectors (underlined) as row vectors and post-multiplying 
them by rotation matrices, i.e., VECTOR = (VECTOR) (MATRIX).  If scalars x, y, and z are components 
of a unit-vector along the specified rotation axis vec- tor, VECTOR, whose length, 8, is the amount of 
right-hand rotation of the image (counterclockwise when the axis of rotation points at the observer) 
with respect to its father space, then the matrix function describing this rotation, ROTN_.ABOUT_AXIS(VECTOR), 
is x2+c( 1-x 2 ) xy-cxy+sz xz-cxz-sy xy-cxy-sz y2+c( 1-y 2) yz-cyz+sx [ ] xz-cxz+sy yz-cyz-sx z ~+c( 
1-z 2)  where s = sin @, and c = cos @. Derivations of this may be found in Rogers &#38; Adams (11) 
and Konopinski (7). To follow the convention that clockwise rotations are positive, transpose the ma- 
trix given here. The algebraic arrangement shown (Barry et al. (I)) is suited for fixed-point com- puting 
because it avoids intermediate terms exceed- ing unity in magnitude.  3.2 ROTATIONS ASOPERATORS A rotation 
matrix can either specify the orien- tation of one coordinate space with respect to an- other, or describe 
a change in orientation of a single space. In the latter case the new orienta- tion is produced by multiplying 
the old orientation matrix by the change matrix: new orient. = (old orient.) (change matrix). 223 
This allows the modification of an orientation by any amount around any axis through its origin. For 
dynamic motion one can iterate the process over time. Computational error, however, will soon cause the 
image to skew into a pancake shape and eventually shrink out of sight. Tountas &#38; Katz (12) have proposed 
a renormalization of the new orientation matrix to eliminate this problem. In our laboratory we control 
it by a Gram-Sehmidt orthonormalization of one pair of columns with each iteration. 3.3 TRANSFORMATION 
NESTING  The following mnemonic notation for designing transformations identifies a transformation by 
a capital letter, and indicates the two spaces that it relates by small letters. For example, trans- 
formation 'S' between spaces 'c' and 'b' is cSb. This represents a single relationship comprising the 
orientation of space 'c' with respect to space 'b' oRb, and the origin of 'c' in 'b' cTb. In the usual 
process of drawing the picture only one transformation is applied to each picture ele- ment, the transformation 
relating the picture ele- ment to the reference space. If a space 'c' is nested in another space 'b', 
then when 'b' is ro- tated, the origin and orientation of 'e' with re- spect to the reference space must 
be changed to maintain the nesting. In this discussion we assume the nested space pivots independently 
only about its own origin. The following expressions nest one space, 'c', inside another, 'b'; that 
is, given the relation- ship cSb between 'c' and 'b', and bSa between 'b' and reference space 'a', they 
compute the relation- ship cSa between 'c' and 'a'. I. The orientation of space 'c' with respect to 
space 'a' is a 3x3 matrix product: era = (oRb) (bRa).  2. The origin of 'c' with respect to 'a' is 
a Ix3 matrix product followed by a vector sum: eTa = (cTb) (bRa) + bTa. We use the symbol '<>' for 
this nesting algo- rithm: cSa = cSb <> bSa.  The small letters between the two transformations must 
match for the algorithm to nest the spaces. Multiple levels of nesting require serial appli- cations 
of the algorithm. For example, to nest a space 'd' in a space 'c', and 'c' in 'b' , the algo- rlthm would 
be applied twice: dSa = dSc <> cSb <> bSa.  Assoeiativity permits evaluation of this to produce an 
intermediate result of either space 'd' with re- spect to space 'b' , or 'c' with respect to 'a'. Using 
two small letters per transformation, any nesting may be designed keeping in mind that the innermost 
space appears on the left of the list and the outermost on the right. If vectors are treated as column 
vectors and pre-multiplied by the matrices, the direction of nesting is reversed and the subscript letters 
for each transformation must be interchanged to pre- serve the adjacent-letter guideline.  3.4 TRANSFORMATION 
INVERSES We can write the inverse of cSb, (cSb) -! , as bSc, which describes the orientation and origin 
of 'b' with respect to 'c'. The rotation and transla- tion components of (cSb~ ! are: bRc = (oRb) "! 
= transpose(oRb) bT~ = (~Tb) -! : -(cTb) (bRc).  3.5 CONTROSINROTATED SPACES To provide kinesthetic 
correspondence in uncon- strained subimage rotation and translation the al- gorithm must compensate for 
the nesting when it changes the relation between a space and its fa- ther. Suppose space 'c' is nested 
in space 'b' but ro- tates about an axis defined in a third space 'd'. We want to find the transformation 
relating 'c' to 'b' after the rotation. Let 'ROTNd' be the axis vector defined in space 'd' about which 
'e' is to be rotated and whose length is the amount of rota- tion. This vector can be rotated into space 
'b' by ROTNb = ROTNd dRa (bRa) -! = ROTNd dRa aRb = ROTNd dRb. The result is an equivalent vector defined 
with re- spect to space 'b', the father space of the one to be rotated. The matrix describing the new 
orientation of 'c' is (new orb) = (old orb) (ROTN_ABOUT__AXIS(ROTNb)). Similarly, a translation defined 
in space 'd', TRANd, can translate space 'e' by: TRANb = TRANd (dRb), (new cTb) = (old cTb) + TRANb. 
  ters on a side. This device was given to us by Bell Telephone Laboratories through the courtesy of 
 A. M. Noll. Through software a clutch (section 2.1) permits movements beyond the box's bounds. The user 
simply slides the control handle in the direction he wishes the substructure to move; the kinesthetic 
correspondence between the translation control and the substructure's motion allows easy positioning 
of the substructure. We now believe a spring-return rate control would be more convenient because it 
would not re- quire a clutch and the handle would always be in the same place when the user reached for 
it. Foley &#38; Wallace (4) mention the difficulties with devices whose locations change. The user's 
having to look for the handle of a large joystick distracts him as much as searching for a lightpen. 
 We use a spring-return device to control the substructure's rate of rotation. This has worked well. 
The joystick used has three degrees of free- dom: push, lean, and twist. Through software we provide 
super-linear response and a dead band.   4.3 CONSTRAINED MANIPULATION DESIGN The constrained manipulations 
(twists of chemi- cal bonds) required by our users are multiple con- current single-axis rotations nested 
in the uncon- strained manipulations. Some of these rotations are nested in others, depending on the 
molecular model. Mechanical difficulties seem to preclude complete kinesthetic correspondence, because 
the constraint axes rotate with the viewing control. We use a set of unconnected single-axis knobs. 
Our analysis indicated that the user would often want to leave some of the angles in the substruc- ture 
unchanged during each fitting operation. We therefore provide self-zeroing knobs whose setting is taken 
to be zero each time a fitting is begun. We use knobs with a 300-degree range, and scale their response 
so they can rotate each subimage through somewhat more than 360 degrees, a reduction rarely noticed. 
This is consistent with Kilpat- tick's experience (6) with an enlarged kinesthetic space for translations. 
We suggest that although motions on the screen should correspond in kind to those of the control device 
(e.g., provide rotary control for rotary response) they need not in mag- nitude.  4.4 ~NOTES Our program 
traverses a linked list to update the transformation describing the orientation and location of each 
dynamically-controlled subimage. From control device values the relation of each space to its father 
is either calculated afresh or modified. Then its relation to the reference space is computed and encoded 
into transformation orders for the display unit. The list of transformation spaces is processed in the 
preorder traversal of the nesting tree to ensure that no space is calcu- lated before its father. A 
schema of a typical nesting is: (b2a, c3a) <> alm <> mMv <> vHh <> hVu  where 'V' represents viewing 
vertical rotation, 'H' represents viewing horizontal rotation, 'M' repre- sents unconstrained manipulation, 
and 'I', '2', and '3' are three constrained manipulations ('2' and '3' nested in 'I'). Outermost space 
'u' ('user') is the unmoving reference space. We now consider calculation of the unconstrained manipulation 
node as an example. Each time the user selects a substructure for fitting, the following operations 
are performed ex- actly once (':=' indicates assignment): I. vTu := offset of origin of viewing space 
from center of screen, a constant. 2. mTv := initial relation between manipu- lated substructure origin 
(pivot) and viewing pivot. Initially the substruc- ture is placed at its pre-fitting posi- tion.  3. 
mRv := Identity matrix. Initially there is no difference between the substruc- ture's orientation and 
that of the sur- rounding structure.   At each update, the node uses information pre- pared by higher 
nodes: I. Manipulation control vectors~ and ROTN DEVICEu defined in the user's space. 2. The viewing 
orientation space with re- spect to the user, vRu.  At each update, the unconstrained manipulation node 
is processed: I. uRv := vRu "l = transpose(vRu) 2. TRAN DEVICEv := TRAN DEVICEu uRv ROTN DEVICEv := 
ROTN DEVICEu uRv  These rotations compensate the user's mo- tions into the viewing space, the manipu- 
lation space's father (see section 3.5).  3. mTv := mTv + TRAN DEVICEv  This adds the rotated translation 
device motion to the manipulation translation vector.  4. CHANGEv := ROTN_ABOUT_AXIS(~L0_~) mRv := orthonormalize(mRv 
CHANGEr)  This rotates the manipulation space about the user-specified axis.  5. mTu := mTv vRu ÷ vTu 
mRu := mRv vRu  These nest the manipulation in the view- ing rotation, making the subimage follow the 
motion of the viewing rotation con- trol device (see section 3.3).  226 Some steps are skipped if a 
device has not moved since the previous update. In the two and a half years that GRIP-75 has been in 
production 27 chemists from 15 institutions have logged over 1700 hours of work on 16 mole- cules, with 
11 published papers so far. Users generally agree that kinesthetic corre- spondence eases their work, 
and several of them have reported difficulty using dynamic manipula- tions in comparable systems that 
lacked kinesthetic correspondence. 5. CONCLUSIONS  We believe that careful control-device selection 
and kinesthetic correspondence increase user prod- uctivity. We base this upon personal observation rather 
than controlled experiment. Nevertheless, we maintain that the benefits of kinesthetic corre- spondence 
justify its low computational cost. 6. ACKNOWLEDGEMENTS  We appreciate the advice and guidance given 
us over the past several years by Frederick P. Brooks, Jr., and William V. Wright. We are grateful to 
James D. Foley and Victor L. Wallace for stimulat- ing our work in human factors. We thank P. Jerome 
Kilpatrick for sharing with us his ideas about ro- tations. We thank S. Bellovin, P. Calingaert, G. 
Frank, and D. Tolle for their criticism of this paper in draft. 7. REFERENCES I. Barry, C.D., Ellis, 
R.A., Graesser, S.M., Marshall, G.R. CHEMAST: a computer pro- gram for modelling molecular structures, 
Proc. IFI~ 1971, 1552-1558. 2. Britton, E.G. A Methodology for the Er-  Design of Interactive Computer 
Graphic Systems, and its Application to Crvstallo~raphv. Ph.D. dissertation, De- partment of Computer 
Science, University of North Carolina, Chapel Hill, N.C., 1977.  3. Brooks, F.P., Jr. The computer "scien- 
tist" as toolsmith: studies in interac- tive computer graphics. Proc. IFIP 1977, 625-634.  4. Foley, 
J.D., and Wallace, V.L. The art of natural graphic man-machine conversa- tion. Proc. IEEE 62, 4 (April 
1974), 462-471.  5. Hansen, W.J. User engineering principles for interactive systems. Proc. AFIPS FJCC, 
Rg, 1971, 523-532.  6. Kilpatrick, P.J. The Use OfA Kinesthe- tic SuvDlement in an Interactive Computer 
Graphics System. Ph.D. dissertation, De- partment of Computer Science, University of North Carolina, 
Chapel Hill, N.C., 1976.  7. Konopinski, E.J. Classical DescriPtions  of Motion. W.H. Freeman, San 
Francisco, 1969.  8. Lipscomb, J.S. Three-dimensional DisPlaY of Molecular Models. M.S. thesis in progress, 
Department of Computer Science, University of North Carolina, Chapel Hill, N.C.  9. Newman, W.M., and 
Sproull, R.F. Princi- Ples of Interactive Computer GraDhics. McGraw-Hill, New York, 1973.  10. Pique, 
M.E. Neste4 Dynamic Rotations for Computer Graphics. M.S. thesis in prog- ress, Department of Computer 
Science, University of North Carolina, Chapel Hill, N.C.  11. Rogers, D.F., and Adams, J.A. Mathemati- 
cal Elements fo~ Computer Graphics. McGraw-Hill, New York, 1976.  12. Tountas, C., and Katz, L. Interactive 
graphics in molecular biology: real-time three-dimensional rotations of images and image fragments. Proc. 
Summer Computer Simulation Conf. I: session II-2.7 (1971), 241-247.  13. Tsernoglou, D., Petsko, G.A., 
McQueen, J.E., and Hermans, J. Molecular graph- ics: application to the structure deter- mination of 
a snake venom neurotoxin. Selene@, 197, 4311 (30 September 1977), 1378-1381.  14. Woodson, W.E. and 
Conover, D.W. Human Enzineerinz Guide For Equipmen~ Design- ers, Univ. of Calif. Press, Cambridge Univ. 
Press, 1964.  15. Wright, W.V. An Interactive Computer Graphic System fo~ ~ Studies. Ph.D. dissertation, 
Department of Com- puter Science, University of North Caro- lina, Chapel Hill, North Carolina, 1972. 
  227 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807395</article_id>
		<sort_key>228</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>40</seq_no>
		<title><![CDATA[User performance under several automated approaches to changing displayed maps]]></title>
		<page_from>228</page_from>
		<page_to>233</page_to>
		<doi_number>10.1145/800248.807395</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807395</url>
		<abstract>
			<par><![CDATA[<p>State-of-the-art computer displays seldom have sufficient resolution and size to show usable detail for a large map. One solution is to satisfy user needs by designing map display systems that present sequential map segments. The utility of two types of presentation conditions was evaluated: (a) continuous map scanning, and (b) discrete map segments using three different amounts of border overlap (0%, 25% and 50%). The task was to determine the fastest road routes between cities. A 19 in. color television monitor displayed 6&#215;8 km map segments (1:50,000 scale) within a 60&#215;80 km map region; participants viewed the larger map area by changing the displayed segments. Solution time, number of map segments viewed, and quality of route solutions were recorded by 24 participants on each of 12 problems divided among presentation conditions. Results showed that different presentation conditions did not significantly affect the quality of routes chosen. Problems took the least time when map segments with 50% overlap were used although 25% overlap produced similar data. Overall, the participants who changed map segments more often took less time working problems. Discrete map segments with around 25% overlap would contribute to an efficient design for a sequential map display system.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Display design]]></kw>
			<kw><![CDATA[Graphic display applications]]></kw>
			<kw><![CDATA[Map displays]]></kw>
			<kw><![CDATA[Map/computer interaction]]></kw>
			<kw><![CDATA[Military systems]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Ergonomics</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.1</cat_node>
				<descriptor>Military</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010406</concept_id>
				<concept_desc>CCS->Applied computing->Enterprise computing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10010478</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Military</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10011738</concept_id>
				<concept_desc>CCS->Human-centered computing->Accessibility</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10011748</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Empirical studies in HCI</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P330285</person_id>
				<author_profile_id><![CDATA[81100068853]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Franklin]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Moses]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[US Army Research Institute, 5001 Eisenhower Avenue, Alexandria, VA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P333288</person_id>
				<author_profile_id><![CDATA[81100427583]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Maisano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[US Army Research Institute, 5001 Eisenhower Avenue, Alexandria, VA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>563892</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Berman, R., and Stonebreaker, M. GEO-QUEL - A System for the manipulation and display of geographic data. SIGGRAPH '77 Proceeding (published by Computer Graphics), 11, (1977), 186-191.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Carlson, E., Bennett, J., Giddings, G., and Mantey, P. The design and evalution of an interactive geo-data analysis and display system. Proceedings IFIP Congress (1974), 1057-1061.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cooper, G., Moore, M., Halpin, S. MOVANAID: An analytic aid for Army intelligence processing. Proceedings, Thirteenth Annual US Army Operations Research Symposium (1974), 696-707.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Layman, R. S. An experimental comparison of two map display modes. Human Factors, 10(5), (1968), 497-503.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Moellering, H. Interactive cartographic design, American Congress on Surveying and Mapping Proceedings, (1977), 516-530.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Shimron, J. On learning maps. Center for Human Information Processing, UCLA San Diego (ARPA Order No. 2284), 1975.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 USER PERFORMANCE UNDER SEVERAL AUTOMATED APPROACHES TO CHANGING DISPLAYED MAPS 1 Franklin L. Moses 
2 and Richard E. Malsano 3 US Army Research Institute ABSTRACT State-of-the-art computer displays seldom 
have sufficient resolution and size to show usable detail for a large map. One solution is to satisfy 
user needs by designing map display systems that present sequential map segments. The utility of two 
types of presentation condi-tions was evaluated: (a) continuous map scanning, and (b) discrete map segments 
using three differ- ent amounts of border overlap (0%, 25% and 50%). The task was to determine the fastest 
road routes between cities. A 19 in. color television moni- tor displayed 6x8 km map segments (1:50,000 
scale) within a 60x80 km map region; participants viewed the larger map area by changing the displayed 
segments. Solution time, number of map segments viewed, and quality of route solutions were recorded 
by 24 participants on each of 12 problems divided among presentation conditions. Results showed that 
different presentation conditions did not significantly affect the quality of routes chosen. Problems 
took the least time when map segments wlth 50% overlap were used although 25% overlap produced similar 
data. Overall, the participants who changed map segments more often took less time working problems. 
Discrete map segments with around 25% overlap would centribute to an efficient design for a sequential 
map dis- play system. KEY WORDS AND PHRASES: map/computer interaction, graphic display applications, 
computer graphics, display design, map displays, military systems CR CATEGORIES: 3.36, 3.72, 8.2 INTRODUCTION 
 The computer's capability to display geographical information is a potentially valuable component of 
information retrieval systems. Such displays allow a user to study and plan resource alloca- tions (e.g., 
fire department services), analyze geographically related problems (e.g., crime; IThe views expressed 
in this paper are those of the authors and do not necessarily reflect the views of the United States 
Army or the Department of Defense. 2,3 5001 Eisenhower Avenue, Alexandria, VA 22333 drug traffic), 
study route planning (e.g., traf- fic flow; transportation design), modify cartog- raphic images (e.g., 
design maps), and so on [1,2,3,5]. An Army application for such displays is the use of map information 
for determining optimal traffic routes for military units. The present research examined alternative 
displays for support of the Army application. Algorithms [3] are available for assistance in this type 
of route selection problem. How- ever, the focus of the present research was on user performance under 
exposure to alternative conditions of automated change from one displayed map area to another. Therefore, 
participants were asked to perform unassisted route selection tasks. An Army officer choosing a route 
manually may need from five to fifteen minutes for a single problem, depending on its complexity. The 
proce- dure often requires numerous hard-copy maps cov- ering a large geographical area and emphasizing 
various aspects of terrain and road character- istics. Selecting the optimum route involves close examination 
of several similar possibil- ities and detailed consideration of road types, population densities and 
other obstacles to quick travel. A computer display system could assist in making relevant information 
more readily avail- able without the need for extensive hard-copy map storage. A major problem in using 
displays for map infor- mation is the limitation in state-of-the-art screen size and resolution. (The 
availability of an adequate map data base is not a concern for this paper.) The fineness of detail is 
illustrated by hard-copy maps which are designed not for accurate display by electronic devices, but 
for reading by the human eye. For example, one grid box (about 4 square cm) of a standard military map 
requires all of a 525 llne color television screen in order to show the smallest printed details. For 
many tasks, users require a larger map area in more detail than is electron- ically possible. The likelihood 
is that elec- tronic display resolution and size will only slowly catch up with such requirements. Methods 
are needed for displaying segments of maps with- out unduly isolating one segment from another. 228 
 These methods must help users to integrate indi- vidual map displays into a cohesive picture of the 
 total interest area. There are at least three approaches for developing better map displays. One approach 
is to determine what detail (if any) can be sacrificed to make present maps more compatible with current 
display technology. A second approach is to provide for changing the scale of a displayed map so that 
more or less detail can be presented as required. A third approach, considered here, is to sequen- tially 
display limited map segments with enough detail to satisfy many of the user's needs. The problem of 
using map segments for convenient presentation is not new. Hard-copy maps represent only subdivisions 
of larger areas. For many tasks, the user often requires several map sheets to satisfy his needs. For 
example, for long- distance driving in the United States, a traveler may use several state and city highway 
maps. In military applications, there is a need to have map-to-map continuity of various features, includ- 
ing roads and topography. Several alternatives for maintaining orientation from one map sheet to another 
are available to the user. One map sheet can be placed next to another, or related points marked on adjacent 
sheets, or sheets flipped back and forth, and so on. Looking at map sheets one after the other rather 
than simulta- neously is quite challenging because of the burden of remembering related factors on adjacent 
sheets. Two research projects [4,6] have investigated some of the issues in remembering map details. 
Shimron asked participants in a study to learn a simple line-drawing map. The map showed a river, a mountain 
range, three major roads and ten cities. Cities were located at road inter- sections and roads were given 
names. Participants remembered local connections between map elements (e.g., most northern city; city 
in the mountains) after even a short slx-mlnute learning period. However, overall integration of map 
units such as naming the order of cities along a particular road or remembering the orientation between 
cities (e.g., What city is south of city A?) produced only 50% accuracy after 12 minutes learning time. 
One implication is that integrating information across the boundaries of map sheets presented sequentially 
requires considerable cognitive processing time. Research by Layman [4] supports the idea that map segments 
are harder to use than single maps of an entire area. He asked participants to use a map for locating 
an aer- ial photograph and the position of a particular photographed object. The time to perform the 
tasks increased significantly when map seg- ments rather than a single map sheet had to be used. Layman 
suggests that the primary problem occurs when the area of interest lles along the border of two adjacent 
map segments which cannot be viewed simultaneously. The user re- quires more time for map reading when 
depending on memory of a map segment not in view. A computer display of map information is the electronic 
equivalent to using a hard-copy map segment. The ease with which map information can he retrieved and 
the provision for continuity of one map display with another are important human factors issues. Using 
discrete sources of maps in the form of slides is a convenient way to store and retrieve such information. 
However, the user has trouble combining infor- mation across boundaries of disparate map seg- ments. 
One possibility for improving map presen- tations is to allow some percentage of map area to overlap 
between adjacent segments. This could provide better user orientation than non- overlapping segments. 
An alternative is to allow continuous map scanning where the display is a "window" for a large map area. 
The user could explore the map and stop on any area of interest. In this report, the two basically different 
map presentation conditions are referred to as "discrete" and "continuous." Intuitively, the continuous 
condition might seem to be the most flexible and promising for the future. On the other hand, the user 
might be served more .quickly, less expensively and equally well by discrete map displays. The purpose 
of the re- search reported in this paper was to test the ease and accuracy of map use with (a) displays 
 of discrete predetermined segments with both overlapping and non-overlapplng areas; and (b) displays 
allowing continuous map scanning. METHOD Task. The task was to use 6x8 km map segments (1:50,000 scale) 
within a 60x80 km region to determine the fastest road routes between cities. Participants were required 
to solve four sets of three problems where each set was combined with one of four display presentation 
conditions: continuous map scanning, or viewing of discrete segments (Fig. i) with 0%, 25%, or 50% 
overlap. Map scale was kept constant and standard military coordinates (universal transverse mercator) 
were used as a reference system. Each problem spec- ified a city of origin, a destination city, and 
 the relative map location of each, using the general form: "You are presently at (city name), (map 
coordinates) and have to go to (city name), (map coordinates). What roads would get you there fastest?" 
Participants solved problems by using a computer-interfaced trackball to mark roads electronically 
on a 19 in. raster scan color CRT (Conrac, Inc). 4 Participants were asked to work quickly but to consider 
the effects of road quality as well as intervening cities and towns on choosing a "best" route. Design. 
Participants were 24 Army officers with military map reading experience, divided into four groups of 
six. Each of the six partici- pants was assigned randomly to one of four unique sequences of problem 
sets combined with map change conditions, The problem sets were constructed to be similar in length and 
difficulty by use of an optimal path algorithm [3] designed for Army applications. The apparatus used 
in the present research caused a delay of about eight seconds between map changes in the discrete presentations; 
a similar wait after a move request in the contin- uous condition insured that the elght-second 4Trade 
names are used only for precision in reporting and do not constitute endorsement. 229 I I I I ,'~'--UIJ~ 
J " .... ,-~'-., ; " "=~ , ~ ~, ~ ,-~. I I '-~ ~ f -"...4 ~ i ., !~"~,~:-31, :/ . , ~ ;A.~-~i£l"~ r£ 
}, ~ !I., I, ~,.,~4 ~,, i,-~ lll~~-~--,~l, " :,-~.-~,~q i, ,' ,, ~4.,,.,~.,,,';...... I ~>~ : , , .: 
.i".l~:' ! , -. " ' " '- ,,,.,,,~..',, . "X'--- -,'I" #--- ---..~.'.'-, . ~ I! ~'. ", ~~,~*~)~!.,~-".,, 
-.<. ,..,I " "-~' ~> t..-"~" :i~.,; -~ ~ [ ~ .. ~" .,;..:,v,,',~", ,.~" ~.;~. ; d c t ~ ~ ~'~, I ' , 
-1 ~.,,,,~. ~'~i ".._...~L ' .  ~ :~-~ ~,.~,_-'.~....' ~,' ~,' ' ~ , ""~' ;t ., .......... , ~,, ,, 
 ~.~ : [~-';-, J :,, fd -Ut, %. ~ [ ..,-?'.~ jl f j / J j J J f f J i ! 25%- Figure I. Map photographs 
(not to scale) and diagrams illustrating the discrete overlap conditions. Only one segment appeared on 
the CRT at a time. interval was constant for all presentation con- ditions. The delay strained immediate 
memory e,wvA~e but was considered reasonable for laboratory VE~TICAL SUReACe evaluation of a map display 
system. In order to ~ ~ M°~°n{FOR MAP) xr v "4"~ ~ control any other time, practice and presentation 
effects, the problem sets and map change condi- tions were counterbalanced in the design. Apparatu s 
. The principal apparatus is shown DRIVE/CLUTCH- in Fig. 2. Participants used the keyboard to TRACt(BALL 
control changes in displayed map area and the trackball cursor to mark road routes. The com- puter system 
(Anagraph by Amcomp, Inc.) generated displays of all alphanumeric and graphic infor- mation except the 
map. The map image was trans-  Figure 2. Block diagram of major apparatus mitted to a display by a color 
television camera components. (GBC CTC 3XP) and could be combined with computer- generated images. The 
stationary camera framed a segment of the entire map which was glued against a 4x6 ft movable vertical 
surface. This surface Procedure. Each participant sat in front of the was equipped with a separate 
motor, clutch, and CRTs. The left-hand CRT showed map segments drive system for movement along both 
x and y axes, with roads marked by black dots at intervals with digital encoders to read the board's 
position along their length. The right-hand CRT (Fig. 3) on each axis, and with a control system interfaced 
 had two purposes: (a) the top was reserved for with the computer. The research station also presenting 
each problem; (b) the rest of the provided the participant with a booklet of in- screen showed a grld 
and coordinate system repre- structions, a participant-experimenter intercom, senting the total map 
area of interest. When the and pencil and paper for notes. The experimenter left screen showed a map 
segment, the right screen had CRTs linked to the participant's displays so used a red rectangle to 
show a segment's location that problem solutions could be monitored. on the grid and an arrow to show 
the direction of  230 YOU ARE PRESENTLY AT (CITY NAME), (MAPS COORDINATES) AND NAVE TO GO TO (CITY 
NAME), (MAP COORDINATES). WHAT ROAOS WOULD GET YOU THERE FASTEST? !  I I I I I I PB QB I TS US I I 
I ----I ------ I I I I PA QA I TR I UR I I I ~. i~-~I  I I I I I I I I I I Figure 3. Right-hand CRT 
display (not to scale) shown here in black and white. The darkened rectangle represents a 0% overlapping 
condition. the last map change. Dashed lines and letter codes designated the map coordinate system. 
Instructions for the task were supplemented by displayed information, by practice problems and by hands-on 
practice until the participant was comfortable with the hardware necessary for solving problems. The 
map board in front of the TV camera moved for both the continuous and discrete conditions for changing 
map displays. The map was always readable for continuous displays. However, between discrete map presentations, 
while the map was moving, the display was completely cov- ered by a computer-generated blue mask. Map 
changes were controlled by four direction keys N oriented W S E on the participant's keyboard. Entering 
"N," for example, was a request to look at the map north of the current display. Angular moves were not 
allowed because, for a controlled research project, the times and distances of such moves would have 
been difficult to equate with x-y changes. The computer con- trolled the amount of change during discrete 
conditions, but the participants controlled starting and stopping the map during the contin- uous condition. 
Participants were told what change method would be used for a problem set and how much overlap a particular 
discrete condi- tion had. Participants were instructed to mark only the black dots on red (primary) 
and red-dashed (secon- dary) roads in the process of determining the best problem solutions. They learned 
to use the trackball cursor for marking each dot along a chosen route with a green asterisk. An added 
feature was that green asterisks could be replaced ("erased") by a red asterisk to show that a spot 
had been abandoned. The research session lasted between 4 and 7 hours with rest and lunch breaks. Any 
equip- ment malfunction could be reported using the partlcipant-experimenter intercom. Performance Measures. 
Performance measures were (a) time needed to solve problems, (b) number of map changes necessary per 
problem, and (c) quality of route selected. The solution time equaled the overall time for a problem 
solution minus the time waiting for new map information to appear. Since the screen was blacked out during 
map changes in the discrete conditions, these times were not considered to be part of solution time. 
In the continuous scan condition, the participant could view the map as it moved. These intervals were 
part of solu- tion time. The time delay before scanning began, however, was subtracted from overall time. 
Num- ber of map changes equaled participant requests to move the map in any of the four directions available. 
Thus, a very limited area could be viewed with many map changes. Quality of solution was determined 
by finding the percent of corre- sponding points along road sections between routes selected by participants 
and "ideal" routes selected by a computer algorithm [3] for each problem. The algorithm calculates the 
fastest road sections between points on the map network. Calculations include considerations of average 
travel speeds along different types of roads and the effects on travel speeds of cities and terrain factors. 
A final source of data was responses to a written questionnaire. These opinions were sought after a session 
was over and the project's purpose had been discussed. RESULTS AND DISCUSSION A user-efficient system 
for sequentially display- ing maps should be accepted easily and should allow quick problem solutions 
of high quality. In current results, participants expressed a first-place preference for continuous scanning 
of maps and a second-place preference for 25% over- lapping segments. Performance data showed over- lapping 
segments to be most efficient. A compro- mise weighted toward performance suggests that designers and 
developers of such systems should use discrete presentations with about 25% over- lapping map segments. 
Data trends indicate that the actual overlap could vary somewhat without any meaningful effect on performance. 
 Not all performance data differentiated among the four map change conditions. Research measure- ments 
of the quality of road route solutions were about equal. However, an analysis of vari- ance showed significant 
performance differences for solution time (F = 4.23; df = 3.60; p < .01) and for frequency of map changes 
(F = 2.78; df = 3.60; p < .05). These trends are evident in the summary of results (Table i). An analysis 
of the performance differences (Newmann Keuls tests of means) revealed that: (a) the number of map changes 
with the 25% and 50% overlapping conditions is about .15 times greater than with the zero overlap or 
the continuous scan condi- tions; and (b) the shortest solution time, by a factor of about .25, was produced 
by map seg- ments with 50% overlap, although a 25% overlap 231 produced similar data. Overall, an increase 
in the frequency of map changes necessary to solve a problem is associated with decreased problem solution 
times. MAP CHANGE CONDITIONS ~% DISCRETE 25% DISCRETE 50% DISCRETE CONTINUOUS SOLUTION TIME (IN SECS) 
607.2 547.1 898.7 672.4 STANDARD DEVIATION 295,2 186.3 165,9 246.1 RANGE 1409.3 002.7 578,3 648.4 NO. 
OF MOVES 21.7 24.9 27.4 21.8 STANDARD DEVIATION 19.5 13.4 13.4 10.2 RANGE 34.7 48.7 49.3 39.7 SOLUTION 
QUALITY (PERCENT) 82.1 48.8 48.9 52.0 STANDARD DEVIATION 14,6 11.3 12.7 16,3 RANGE 01.7 42.5 43.5 71.4 
 Table i. Data summary for different map changes conditions. Measures of route quality averaged only 
about 50% because of the stringent scoring rule used. The routes chosen by participants were Judged by 
how well they corresponded with the algorithm's ideal solution, not by whether they offered a reasonable 
alternative solution. Parts of routes which were similar or even parallel to the ideal one were scored 
as incorrect. The nature of problem solutions was visible on road routes where: (a) participants often 
marked a route compatible with the algorithm's solution and later erased it and (b) the alternate solutions 
chosen by many participants were identical. The important point was that route quality remained consistent 
in the research while performance time and frequency of map changes systematically varied. Performance 
Strategies. One consideration for optimizing use of a map change system is redun- dancy between adjacent 
segments. Built-ln over- lap aids the user in integrating information from one map segment to the next 
and may have partly accounted for the lower solution times in the discrete conditions with 25% and 50% 
overlap. In contrast, the 0% overlap and the continuous scanning conditions allowed the user to see more 
map area with fewer moves. An increase in solu- tion time in the 0% overlap condition was probably due 
to the demand on memory for combining new information with information from previously seen displays 
and from the need to go over routes to check work. The continuous condition, where users can scan new 
map areas easily, was not expected to take as much time as discrete conditions. However, the problem-solvlng 
stragegy most participants adopted for this condition seemed to increase their solution time. Participants 
spent much longer explorlngposslble routes during continuous scanning than during any discrete condition. 
Large areas were first viewed with a single map change to try to locate the best route. Later, once a 
route was defined, participants tended to move the map only far enough to keep the last marked point 
(green asterisk) in view. The outcome was few map changes, long performance times and no improvement 
in the quality of problem solutions. The strategies adopted by subjects in the three discrete conditions 
(0%, 25% and 50% overlap) also may have contributed to the resultant time and map change data. Participants 
exposed to the 25% and 50% overlap conditions usually proceeded from the origin to the destination without 
first exploring the whole route. They would continue along a path as long as it proved useful. When it 
stopped going in the right direction, they tried another route. Having any overlap usually enabled participants 
to keep at least one previously marked node (green asterisk) in view when they changed map segments. 
This seemed to provide necessary orientation and allowed participants to make choices without having 
to search. Thus, in the 50% overlap condition, less overall area was viewed than in the 25% conditions. 
In both these conditions, less overall area was viewed than for the 0% overlap condition. Zero overlap 
produced fewer moves than either the 25% or the 50% condition, but a completely new area appeared with 
each move. This completely new information created a problem of orientation. Most partici- pants dealt 
with the orientation problem by carefully studying a display of new information, and sometimes reversing 
to view the previously seen segment. This reversing occurred mainly when a path was not obvious and the 
participant wished to check his work. Overall, results suggest that using a discrete method with overlap 
is important for minimizing time for problem solutions. Participant Opinions. A final source of results 
was the written questionnaire completed after the research and returned by 24 participants. User opinion 
should be considered in selecting display system charcteristics, although many biases not related to 
performance may quickly disappear with use. Responses showed that 19 participants preferred continuous 
scanning and five preferred discrete changes. Three partic- ipants preferred discrete changes with 25% 
overlap and 12 others made it their second choice. There was only one second choice preference for contin- 
uous scanning. Participants" comments indicated that continuous scanning provided quicker under- standing 
of the relevant map area and easier orientation as displays were changed. This opinion contrasts with 
data which showed that the continuous condition resulted in the highest average problem solution time. 
The opinion agrees, of course, with the extensive map explo- ration that participants tended to do under 
continuous changes. The discrete change condition with 25% overlap was liked almost as well because it 
provided continuity without too much or too little redundancy. In addition, 25% overlap resulted in a 
near tie for shortest problem solution time. The implication is that many users could accept a discrete 
system with some overlap. Preference data suggests thlt discrete changes with around 25% overlap would 
be a good choice for displaying map information. Never- theless, the strong preference expressed for 
a system where the user can scan the map should not be ignored. System DesiBn Tradoffs. In general, 
the results show how designers of military map change systems can give strong consideration to efficient 
user performance in tradeoffs with equipment character- istics and user satisfaction. One set of trade- 
 232 offs revealed by in the present research was between performance times and hardware require- ments 
for changing map segments. The most cost- effective and durable hardware design probably would minimize 
the percent of overlap and the number of changes needed to encompass a map. By using 25% as a guideline 
for overlapping segments, the demands on equipment should he reasonable without negative effects on user 
performance. Another set of tradeoffs involves user performance data vs. user satisfaction with a map 
change system. In spite of the efficient performance times with overlapping map segments, the majority 
of participants made continuous scanning their first choice, with 25% overlapping discrete seg- ments 
their second choice. The extensive map exploration possible with continuous scanning seemed to improve 
confidence in problem solutions while lengthening performance time. Users could perhaps be taught to 
work more rapidly with continuous scanning. However, the effect of such training on user preference, 
number of map changes, and even solution accuracy is not known. In addition, the training costs and even 
the system development costs for continuous scanning may be higher than for discrete presentations with 
overlapping map segments. Based on the current research, a discrete system which uses about 25% overlapping 
map segments has better overall support than any other tested alternative. Alternative Tasks. A key 
question about the research is whether the task was demanding enough to cause differences in performance 
quality among the four map change conditions. The task was chosen because deciding on a road route requires 
several different map reading skills, such as locating map positions, discriminating road types, determining 
travel directions, and understanding terrain and city impacts on ease of traveling a road. However, when 
a map is segmented, the roads often are the easiest fea- tures to llne up and follow. They have a natural 
continuity, unlike, for example, the location of one city relative to another. Such road continuity could 
minimize the performance effects of different methods for changing displays from one map segment to an 
adjacent one. Perhaps the task should not have been limited to finding a quick route "from here to there." 
One possibility would have been to ask for the best route for traveling to several cities in an optimal 
sequence. This would require inte- gration of scattered information across boundaries of map segments. 
Another way to increase problem difficulty would be to place obstacles (e.g., bridge out; flooding) which 
would make remembering bad routes and choosing good routes more chal- lenging. Changing the map area 
displayed by use of a zoom capability also could lead to difficult problems for the user to solve. Changes 
in map magnification would allow emphasis to be placed on interpreting map details. Alter- natively, 
map overviews could be used for concep- tualizing difficult road network problems. A task that exploits 
map detail as well as overview would provide a challenging test of automated map display methods. CONCLUSION 
 To optimize user performance time, the designer of a map display system for military use should begin 
with discrete map segments that overlap by about 25%. The percentage can vary somewhat without affecting 
performance. The 25% guideline considers user preference but requires fairly frequent map changes which 
increase demands on hardware. Performance criteria, user satisfaction and equipment design all have a 
place in deter- mining the most appropriate map display system. REFERENCES I. Berman, R., and Stonebreaker, 
M. GEO-QUEL - A System for the manipulation and display of geographic data. SIGGRAPH "77 Proceeding (pub- 
lished by Computer Graphics~, II, (1977), 186- 191. 2. Carlson, E., Bennett, J., Giddings, G., and 
Mantey, P. The design and evalutlon of an interactive geo-data analysis and display system. Proceedings 
IFIP Congress (1974), 1057-1061.  3. Cooper, G., Moore, M., Halpin, S. MOVANAID: An analytic aid for 
Army intelligence processing. Proceedings ~ Thirteenth Annual US Army Operations Research Symposium (1974), 
696-707.  4. Layman, R. S. An experimental comparison of two map display modes. Human Factors, i0(5), 
(1968), 497-503.  5. Moellerlng, H. Interactive cartographic de- sign, American Cpn~ress on Surveying 
and Mapping Proceedings, (1977), 516-530.  6. Shimron, J. On learning maps. Center for Human Information 
Processing, UCLA San Diego (ARPA Order No. 2284), 1975.  233  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807396</article_id>
		<sort_key>234</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>41</seq_no>
		<title><![CDATA[Characterizing non-ideal shapes in terms of dimensions and tolerances]]></title>
		<page_from>234</page_from>
		<page_to>238</page_to>
		<doi_number>10.1145/800248.807396</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807396</url>
		<abstract>
			<par><![CDATA[<p>A geometric model of a shape is extended so as to represent not only its nominal dimensions but also tolerance information and surface specifications. The data structure defining an object is visualised as a pin-jointed, infinitely elastic wire frame covered by elastic membranes. Constraints corresponding to the dimensions of technical drawings are applied to the structure, either by the designer or by an automatic dimensioning algorithm. The validity of the resultant scheme can be checked and then drawn using drawing office conventions. The data structure can handle dimensions fixing various types of curved surface; other types can easily be added by following the same rules. A method of changing the nominal shape of an object is demonstrated. These results provide a systematic account of the ill-defined art of dimensioning and tolerancing, and should make the draughting process more amenable to computation.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer-aided design]]></kw>
			<kw><![CDATA[Dimensioning]]></kw>
			<kw><![CDATA[Draughting]]></kw>
			<kw><![CDATA[Geometric modelling]]></kw>
			<kw><![CDATA[Graphics]]></kw>
			<kw><![CDATA[Mechanical components]]></kw>
			<kw><![CDATA[Tolerances]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P333039</person_id>
				<author_profile_id><![CDATA[81100005193]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Hillyard]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Cambridge]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P113807</person_id>
				<author_profile_id><![CDATA[81100024019]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[I.]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Braid]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Cambridge]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>807158</ref_obj_id>
				<ref_obj_pid>872738</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Braid, I.C. and Hillyard, R.C., Geometric modelling in ALGOL 68, ACM SIGPLAN notices, vol. 12, no. 6, pp. 168-174, 1977]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Hillyard, R.C. and Braid, I.C. The analysis of dimensions and tolerances in computer-aided shape design, Computer Aided Design, vol. 10, pp. 161-166, June 1978]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Requicha, A.A.G., Dimensioning and tolerancing, Report TM-19, Production automation project, University of Rochester, 1974]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Sutherland, E., 'Sketchpad': A man-machine graphical communication system, 1963]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 CHARACTERIZING NON-IDEAL SHAPES IN TERMS OF DIMENSIONS AND TOLERANCES R. C. Hillyard I.C. Braid University 
of Cambridge Abstract: A geometric model of a shape is extended so as to represent not only its nominal 
dimensions but also tolerance information and surface specifications. The data structure defining an 
object is visualised as a pin-jointed, infinitely elastic wire frame covered by elastic membranes. Constraints 
corresponding to the dimensions of technical drawings are applied to the structure, either by the designer 
or by an automatic dimensioning algorithm. The validity of the resultant scheme can be checked and then 
drawn using drawing office conventions. The data structure can handle dimensions fixing various types 
of curved surface; other types can easily be added by following the same rules. A method of changing 
the nominal shape of an object is demonstrated. These results provide a systematic account of the ill-defined 
art of dimensioning and tolerancing, and should make the draughting process more amenable to computation. 
 Keywords and Phrases: Computer-aided design, dimensioning, draughting, geometric modelling, graphics, 
mechanical components, tolerances. C.R. Categories: 3.2, 3.54, 8.2  i. Introduction  The earliest 
engineering drawings evolved from pictures, more or less to scale. They were sufficient for a single 
craftsman to work from, and for some purposes, are still adequate today. As the volume of production 
increased, manufacture was divided into stages. For example, components were made separately, and later 
assembled. No doubt difficulties in assembly arose and the job of fitter was born. The same difficulties 
also led to the addition of dimensions to the pictures. Now a new problem appeared -that of redundancy. 
Dimensions could be in conflict with the picture or with one another. The first conflict was solved by 
giving dimensions precedence over the picture. Later, it became This work was supported in part by the 
Science Research Council, U.K. Authors'address: Computer Laboratory, Corn Exchange Street, Cambridge 
CB2 3QG, England. customary to add enough dimensions to define all lengths and angles, leaving the picture 
to convey only the arrangement (or topology) of the shape. Stern warnings -"Do not scale" -were stamped 
on every drawing. Conflict between dimensions demanded a more subtle response. The rule was that the 
dimension scheme should be just suffieient to define the shape. One dimension more or less would be wrong, 
and even if the total number of dimensions were correct, an inappropriate choice could leave a shape 
over-defined in one region and under-defined elsewhere. The matter was further complicated by various 
short cuts that allowed 'obvious' dimensions like right-angles to be omitted, or capitalised on symmetry 
or patterns. Thus in practice, the formal rules were often disobeyed, especially in the case of non-trivial 
 shapes. Sometimes the intelligence and experience of the reader could resolve conflicts or supply missing 
information but often mistakes were made. For any given shape, there is a multitude of correct dimensioning 
schemes that differ only in their choice of lengths and angles to be given (i.e. dimensioned) and those 
to be derived. This extra information is put to good use as a means of stressing certain lengths and 
angles (those that are given) at the expense of others, thereby conveying to the maker or inspector of 
a shape those parts of the shape that are significant for assembly or function. The addition of tolerances 
adds further information by specifying how close a given length or angle should be to its nominal value. 
A problem that designers sometimes face is to find the effect of tolerances on a derived length or angle, 
and much tedious calculation may be needed. Existing computer systems for handling shape information 
are mostly at the picture stage. They model shapes but give no precedence to particular lengths or angles, 
nor do they characterize precision explicitly. For many practical purposes, a linear analysis of dimensions 
is sufficient. The PADL system [3] applies such a technique to rectilinear shapes, treating each orthogonal 
axis independently. In general however the axes interact and engineering components are not recti- linear. 
Hence, a more elaborate analysis is required. In [2], the authors have shown how dimensions and tolerances 
can be added to a shape description, how a dimension scheme can be checked for incompleteness and redundancy, 
and how tolerance calculations can be automated. The 234 results, for polyhedra, are su/nmarised below. 
 This method is reminiscent of the Sketchpad system [4] and its handling of constraints. Further possibilities 
will be explored in this paper. These are the automatic generation of dimensioning schemes, the treatment 
of curved surfaces, and the use of dimensions as a design variable, that is, as a means of changing 
stored shape descriptions in a natural and easily comprehended way. We shall assume that the precision 
of the computer representation and operations is much finer than the tolerances being manipulated. But 
it may be observed in passing that problems of redundancy and consistency in computer models of shape 
are analogous and could perhaps benefit from a similar treatment. 2. Analysis of dimensions and tolerances 
 The underlying method in analysing dimensions and tolerances is to set up equations relating shape geometry, 
that is, the equations of curves and surfaces, and the positions of vertex points, to the dimensions 
shown or implied in the drawing. When the dimensions vary within their tolerances, the shape alters simultaneously. 
Because tolerances are small in relation to dimensions, we can neglect second and higher order small 
quantities and make the equations linear. The variables of shape geometry must be chosen carefully so 
as to be independent. Two surfaces intersecting in a curve define the curve. If more than three surfaces 
meet in a vertex point, then only three of the surfaces are fully independent. A dimensioning scheme 
cannot settle this choice and any program to handle dimensions and tolerances must make a somewhat arbitrary 
decision. In [2], the vertex points are chosen as the unknowns. Consequently, a planar face with more 
than three vertices implies that the vertices are not independent. Every dimension gives rise to one 
or more equations, and the fact that a correct number of dimensions is present can be established by 
checking that there are as many independent equations as unknowns. The right- hand side terms in the 
system of equations are the variations in any dimension as permitted by the tolerances. For a given set 
of variations, we can solve to find the vertex positions provided the equations are well-conditioned. 
If not, we conclude that the dimensioning scheme is poor and that the shape is ill-defined; at worst, 
it may be a mechanism, that is a non-rigid shape. In the well-conditioned case, we may also invert the 
equations to obtain vertex coordinates as a function of the dimension variations. This is precisely what 
is needed when analysing dimensioning and tolerance schemes. For example, we can find the resulting tolerance 
on an undimensioned length and moreover can discover the proportion contributed by each given tolerance. 
The system of equations can be represented in matrix form by R d = u where R is called the rigidity matrix 
and u and d are vectors of the variations and vertex displacements respectively. In practice we begin 
with a stored shape model made with a program such as BUILD [i]. The model must explicitly contain the 
shape topology; that is, all faces, edges and vertices must be present, together with details of their 
inter- connections. It is convenient if the shape geometry is also present since a designer need only 
indicate the face, edge or vertex at each end of a dimension and the program can compute the nominal 
size. The designer will normally supply the tolerances, however. The shape model is regarded as a frame 
structure whose members correspond to the edges of the object. The members are initially unconstrained 
in length, and meet at pin joints corresponding to object vertices. For every dimension fixing a distance 
or angle, or declaring a face to be planar, a corresponding stiffener termed a strut, web or plate, is 
added to the frame. Struts, webs and plates prevent strain, shear or torsion in parts of the frame, and 
each gives rise to one or more equations as detailed in [2]. Some dimensions are conventionally not shown 
on a drawing but have to be inferred: these include struts of zero-length, right-angled webs and plates. 
 3. Automatic dimensioning An object which has been described by means of a geometric modeller has enough 
inherent information to generate its own dimensioning scheme. However, for a modeller that describes 
only ideal shapes, for example BUILD, the tolerance information is missing and so the dimensioning scheme 
must necessarily be incomplete. The nature of an engineering drawing is that it shows the salient features 
of an object in a form which corresponds either to the design or to the manufacture or preferably to 
both. An automatic dimensioning algorithm will therefore never be able to reconstruct perfectly the designer's 
thoughts. For these reasons complete automatic dimensioning will always produce inferior results to manual 
dimensioning. The ideal strategy is one in which the designer dictates the important dimensions and 
those with significant tolerances, and leaves the algorithm to note and fill in missing dimensions. The 
resulting scheme can then be checked for consistency with respect both to itself and to the original 
description. One method of checking whether or not a scheme is admissible has been referred to above, 
and while it is an acceptable method for schemes that succeed, for those that fail the test it gives 
no indication Of where extra dimensions may be positioned or of the number required. The time taken by 
this algorithm is proportional to the cube of the number of vertices; one which improved on this would 
be preferable for complex objects. An analysis of the properties of three- dimensional shapes leads 
to a faster method for checking dimensioning schemes, although this method cannot in general distinguish 
between good and very good schemes. It does however suggest a method of generating dimensions that emulates 
the checking, and therefore always yields at least 235 good schemes. Solid objects can be characterized 
by two properties: if all the vertices of an object are trihedral, that is they are at the intersection 
of exactly three faces (and three edges), then the object is simple; if all the faces of an object are 
bounded by exactly three edges (vertices), then the object is simplicial and is called a deltahedron. 
Simple objects and deltahedra are topological duals; that is every face or vertex in one has a corresponding 
vertex or face in the other. Most real objects, however, have neither of these properties. The tetra- 
hedron is the only object which has both properties. Any general object can be converted into either 
simple or deltahedron form by adding new faces, Most engineering objects tend towards the simple; indeed, 
all engineering objects may be considered simple because although the designer may think in terms of 
having four intersecting planes meeting at a point, this condition cannot in general hold true. Four 
surfaces cut, for example, by a milling machine will always be non- intersecting if measured to a sufficiently 
fine tolerance. Similarly, by the duality described above, a face of more than three vertices cannot 
in general be planar even though it may have been so designed. It can be shown that, under, certain 
conditions, a deltahedron is rigid; hence one way of dimensioning an object is notionally to split each 
face into triangles and ensure that each triangle is rigid. This method has the disadvantage that, for 
a simple object, it substitutes struts or webs for plates and so makes the resultant drawing less tidy 
and, more importantly, does not produce a scheme which models the original design. Another possibility, 
the dual of the last method, which is suitable for simple objects is to define the lengths of all the 
edges of an object and to constrain the faces to be planar. For non-prismatic objects, this process defines 
the solid angles at the vertices thereby making the whole rigid. An r-fold prism, defined as one whose 
base is a two-dimensional (r-l)-fold prismatic polygon, has 0,2,3 shear axes and 0,1,3 torsion axes for 
r = 0,1,2, respectively. A 0-fold pri'sm is a non- prismatic polyhedron; a 2-fold prism is a 3-fold prism. 
For any axis, the shear can be controlled by fixing the two-dimensional rigidity of a face through which 
the axis passes and for a torsion axis, it is necessary that at least one adjacent face to any face through 
which the axis passes is planar. The algorithm which is used to dimension simple objects, those with 
many parallel faces which are not necessarily prismatic, runs as follows: (i) the faces are arranged 
into sets, each set containing a group of parallel faces;  (ii) struts are set up between adjacent faces 
in a set;  (iii) webs are set up between the first faces of adjacent sets; (iv) for prismatic objects, 
the tests on the shear and torsion axes are performed to verify that the object is rigid. If the total 
number of items of information provided by the dimensions is not enough then it is necessary to continue 
by following the algorithm for deltahedron-like objects below. If the object is preprocessed such that 
any non- trihedral vertices are truncated and replaced by faces (of zero size) then this last step should 
not be necessary. In (iii), other webs will be implied (the secondary webs of [2]) some of which will 
be redundant; these will not contribute to the total. The algorithm for dimensioning objects which 
can be easily converted to deltahedron form is as follows: for each face check that it is rigid in a 
two- dimensional sense, though not necessarily planar, adding dimensions where necessary to make it 
rigid. In practice if all faces are made two-dimensionally rigid except one which is made planar then 
the object will still be rigid. The views of fig.3 constitute an automatically dimensioned drawing of 
a die used in a manufacturing process. 4. Dimensioning of curved objects For curved objects, we proceed 
as before to set up equations relating shape geometry to dimensions. It is now no longer possible to 
express the shape entirely in ter~s of vertex coordinates, as was done for polyhedra since the presence 
of curved surfaces introduced extra degrees of freedom. In principle, the coefficients of the equations 
of curves and surfaces could be chosen as the shape variables. However, these do not have an obvious 
relation to the shape as seen or intended by the designer. Instead we shall make use of quantities such 
as the radius of an arc or its centre or other information that appears on a drawing. As with polyhedra, 
we shall again find inferable dimensions: tangency conditions, for example, are seldom shown explicitly 
but we must still derive equations for the constraints that they apply. The example in fig.l (overleaf) 
shows a two- dimensional shape that contains a curved edge dimensioned in two different ways. The object 
has eleven degrees of freedom in total, an x and y coordinate at each vertex, plus the radius of the 
circular arc. After fixing solid body position and rotation, we have eight degrees of freedom to be supplied 
by the dimensions. In the first case shown in fig.l (i), the curved edge is defined by its radius and 
the vertices at its ends. The appropriate unknowns are thus the x and y coordinates at each vertex and 
the radius. In the second example, we introduce the coordinates of the centre of the arc as additional 
unknowns and omit one coordinate (x in one case, y in the other) at the vertices at the ends of the arc. 
 For other kinds of curve and surface, for example B-splines and surfaces, one can imagine schemes in 
which the defining polygons or polyhedral meshes were dimensioned. In this case it would be natural to 
use the positions of the polygon or polyhedron vertices as the variables in an analysis of shape. This 
remains a subject for further investigation. 236 c) solve the equations to find the new displacements; 
 d) the product of the norms of the variations and displacements is greater than the finishing criterion 
 do add the displacements to the vertex (i) coordinates od Fig.2 shows an example of the alteration 
of a two-dimensional figure. The two solid outlines denote, as indicated, the initial shape of the pentagon 
and its final shape (obtained by increasing one length and decreasing one angle as shown.) A three-dimensional 
object can be altered in exactly the same way.  T initials ape  finalshp (ii)  138 - ,~53: ~ 7 8~ 
 ± 148 Fig. 1 Dimensioning a curved edge 5. Design alteration The fact that the constraint equations 
can be solved to yield the displacements of vertex positions, curves or surfaces for a given set of variations 
in the dimensions leads to the attractive Sdea of using the same technique to change the shape of an 
object through its dimensions. This allows an object to be altered without recourse to a complete re-evaluation 
of the shape from scratch. However many of the constraint equations will have been derived under the 
assumption that the variations in the dimensions are small and so in general it will be necessary to 
employ a relaxation technique to find the consequent displacements. The technique is as follows. (i) 
Set the elements of the displacement vector to zero;  (ii) set the variation vector to the difference 
of the required dimensions and the present dimensions;  (iii) while a) construct the rigidity matrix 
according to the present coordinates; b) subtract the product of the rigidity matrix and the dis- placements 
from the variations; Fig. 2 Pentagon altered by relaxation  The relaxation process just described leads 
us to consider the possibility of optimising a design according to some criterion ~ and a set of bounds 
on the independent variables. We require a hill-climbing algorithm of the type used by linear programmers. 
The hills rest on a plane which is in fact an m-dimensional space: m is the number of independent quantities 
which we wish to be able to vary, and m ~ 3v-6 for an object of v vertices. We can use a geometric modeller 
to provide procedures to evaluate derivatives of the criterion with respect to the vertex coordinates. 
We employ the chain rule in matrix form;  A = B F where a. ~ = -- (the derivative with l ~x.3 respect 
to the jth variation), and b. 1 ~ = -- ~v. 1 (the derivative with th respect to the i vertex coordinate), 
~v. and f.. = 1 x3 3x. 3 The optimisation process then is one which tries to find a point where all 
the ~xx. are zero.  1 Both the relaxation and optimisation techniques must guard against non-convergence 
and location of minima and local maxima instead of global maxima. 237 Conclusion References: The research 
described in this paper began as i. Braid, I.C. and Hillyard, R.C., Geometric a quest for ways of attaching 
dimensions and modelling in ALGOL 68, ACM SIGPLAN notices, tolerances to shape descriptions. We have 
found vol. 12, no. 6, pp. 168-174, 1977 that the problem goes much deeper than that. It concerns, firstly, 
the avoidance of redundancy in 2. Hillyard, R.C. and Braid, I.C. The analysis shape descriptions, whether 
as drawings or as of dimensions and tolerances in computer- computer data structures. Secondly, it requires 
aided shape design, Computer Aided Design, that we regard shape descriptions as dynamic vol. i0, pp. 
161-166, June 1978 mechanisms rather than as static entities. Although our prototype system is as yet 
under- 3. Requicha, A.A.G., Dimensioning and developed, we can already see how engineering tolerancing, 
Report TM-19, Production designers will be able to build a nominal shape automation project, University 
of Rochester, and derive from that an irredundant description 1974 by supplying dimensioning and tolerancing 
information. They will be able to interrogate the 4. Sutherland, E., 'Sketchpad' : A man-machine description 
to find derived geometric quantities graphical communication system, 1963 and variations and will be 
able to assess the quality of the irredundant scheme. Designers will surely welcome the facility of changing 
shapes merely by altering dimensions, and production engineers too will be able to discover the tolerance 
information needed for the planning of manufacture. k,.-d I+d k,.4 I II t T- I -.t ,J " Y k-,;4 1B8 ,J 
i ~ 118  ~35 "4 Fig. 3 Automatically dimensioned moulding die 238 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807397</article_id>
		<sort_key>239</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>42</seq_no>
		<title><![CDATA[Object models for computer aided design]]></title>
		<subtitle><![CDATA[An overview]]></subtitle>
		<page_from>239</page_from>
		<page_to>244</page_to>
		<doi_number>10.1145/800248.807397</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807397</url>
		<abstract>
			<par><![CDATA[<p>A computer aided design system must deal with large amounts of both spatial and non-spatial data. It must also provide quick graphic response to user interaction. If the CAD system is to support real time graphic interaction, it must be able to respond within at most a few refresh cycles. If the data base is structured and accessed at a record level, it becomes very difficult to guarantee this real time response. For this efficiency reason, and for clarity reasons, we will introduce a new level of data structure called an &#8220;object&#8221; which is a linked structure of record level structures called &#8220;attributes&#8221;. The data structures for a CAD support system which provides support both for large data bases and real time graphic response will be described.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer aided design]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Data base management]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P325389</person_id>
				<author_profile_id><![CDATA[81100235348]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Russell]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Athay]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Colorado State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>908598</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Athay, R. J. Object Models for Computer Aided Design, University of Utah doctoral dissertation, 1978.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356664</ref_obj_id>
				<ref_obj_pid>356662</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Fry, J. P., Sibley, E. H., Evolution of Data-Base Management Systems. Computing Surveys, Vol. 8, No. 1, (March 1976).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356666</ref_obj_id>
				<ref_obj_pid>356662</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Taylor, R. W., Frank, R. L., CODASYL Data-Base Management Systems. Computing Surveys, op. cit.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 OBJECT MODELS FOR COMPUTER AIDED DESIGN: AN OVERVIEW Russell J. Athay Colorado State University 
Abstract Data Structures for CAD A computer aided design system must deal with large amounts of both 
spatial and non-spatial data. It must also provide quick graphic response to user interaction. If the 
CAD system is to support real time graphic interaction, it must be able to res- pond within at most a 
few refresh cycles. If the data base is structured and accessed at a record level, it becomes very difficult 
to guarantee this real time response. For this efficiency reason, and for clarity reasons, we will introduce 
a new level of data structure called an "object" which is a linked structure of record level structures 
called "attributes". The data structures for a CAD support system which provides support both for large 
data bases and real time graphic response will be described. Key Words and Phrases: computer graphics, 
computer aided design, data base management. CR Categories: 3.14, 4.33, 4.34, 8.2 Computer Aided Design 
Support Systems The goal of a CAD support system is to pro- vide a general framework and a set of support 
faci- lities so that the cost and development time for a CAD application system will be much less than 
if that application were developed from scratch. The purpose of this paper is to describe such a system 
which has grown out of the author's research and experience over the last several years. For the purposes 
of this paper, the require- ments for a CAD support system will be partitioned into four groups. i. 
interactive data structures 2. data base management  3. interactive graphic con~nunication  4. operator 
function selection. It is important to realize that the goal here is computer aided design and not just 
computer aided picture generation. For example, a system for cir- cuit design must be able to deal with 
both spatial (e.g. a resistor symbol) and non-spatial (e.g. value, tolerances, part numbers, etc.) in 
order to be able to specify and analyze a circuit. While it is tempting to simplify problems 1 and 2 
by restric- ting the data structures to graphic information the resulting system is far too restrictive 
for a gen- eral CAD support system. Most "modern" programming languages (e.g. Pascal) provide a set 
of data types with which one can implement the general data structures needed to support interactive 
design and modeling. These types include i. unstructured data types (e.g. integers, reals, etc.) and 
arrays (i.e. non- homogeneous collections of i) 2. record types (i.e. non-homogeneous collections of 
1 and/or 2) 3. pointer types (i.e. addresses of record) For any given CAD application, one could define 
a set of interactive data structures which were suit- able and provide a graphic interface to those structures. 
For example, one might represent a mine excavation with the linked record structure shown in Figure i. 
 This approach would work fine for a single pro- gram where all the data can be maintained in the program 
workspace. Of course, a CAD application invariably includes many programs which perform in- terrelated 
operations on large files of common in- formation. We are thus faced with a major data base problem, 
and until that problem is solved, our CAD support system will remain a toy. Data Bases for CAD In order 
to minimize confusion, redundancy, and inconsistency in a data base, the following facilities must be 
provided by a data base manage- ment system. I. There must be a common definition of the form (e.g. 
record format) of the data base. This format description is called a "schema". 2. There must be some 
way to structure the records in the data base. Data base sys- tems are often categorized on the basis 
of their structuring methods (e.g. hier- archic, network, relational [2]).  3. There must be facilities 
for accessing and manipulating the data base.  There is no problem in mapping the records of Figure 
1 into a data base system, except for the pointer fields. Almost no data base system will allow arbitrary 
linked structures of records. To fulfill requirement 2, a data base system must, however, provide some 
structure of records within the data base. One must, therefore, transform the 239 Inamexcavation I 
design ~ ....... ~ number I polyhedron I  info. info. of rings* volume ring face number number < 
 to ring structure I edge use * rings are sub-volumes of  the excavation °°indicates a variable 
number I edge of this reco~ype Note: details of non-pointer fields not shown point point Figure 1 
Y x Mine Excavation Representation using Records and Pointers z Excavation name Note that several records 
from Figure 1  have been collapsed into a single record design here. reserves number of  rlngs polyhedron 
 volume ring face description face/ edge/ edge point  single record nub nub Owner .I Member 0 
or more records  Figure 2 Mine Excavation Representation Using DBTG Data Base Structure. 240 main 
memory data structures into data base struc- tures. Data base structures are usually restricted to specific 
mechanisms. For example, the network  structures defined by the DBTG committee of CODASYL [3] are interconnected 
rings called "owner-coupled sets." A possible representation of the polyhedron in a network system is 
shown in Figure 2. (The "nubs" in Figure 2 are necessitated by the restric- tion that a record may only 
be a member of one in- stance of a given set type.)  Aside from the "nubs", the structure in Figure 
2 seems reasonable. However, there is a massive change of scale between Figure 1 and Figure 2. In Figure 
i, we are dealing with records which must be identified and referenced (i.e. pointed to) in a memory 
"space" which is typically limited to a few thousand records. These records are usually ac- cessed at 
memory speeds through simple run time routines. In Figure 2, we are dealing with records which must be 
identified and referenced in a "space" of millions or tens of millions of records. These records are 
accessed at disk speeds through a large and complex data base system. The fact that these two structures 
are logi- cally equivalent is of little comfort to an opera- tor waiting to see the results of his or 
her last interaction, nor to the programmer who must "navi- gate" a large and complex data base. The 
problem which the author has attempted to solve is to pro- vide data base support for CAD applications 
which will be implemented on a small computer and support real time interactive graphics. In this environ- 
ment, the efficiency problems of using a data base system which is structured and accessed at the rec- 
ord level are overwhelming. Objects As in many situations of this kind, a change of scale requires 
a change of technique. There are two critical design decisions for a data base  system. i. Into what 
kind of data items should the data base be partitioned? 2. How should these data items be struc- tured 
within the data base? Rather than partition the data base into record level data items, we will partition 
it into larger units called "objects." Since objects are further partitioned into record level units 
called "attri- butes", we have introduced a new level of data structure into the system. After describing 
these concepts in more detail, we will consider the mo- tivations for this design. An object is defined 
as a linked structure  (i.e. directed graph) of attributes. For the sys- tem to be able to process objects 
completely and independently (e.g. transfer an object to the data base) these attribute structures must 
be connected  (i.e. every attribute which belongs to the object must be reachable by some path which 
begins at the object header) and disjoint (i.e. an attribute in one object must not be reachable by a 
path which begins in another different object). To insure these properties and to aid processing, it 
would be advantageous to require the object's internal struc- ture to be an n-ary tree. However, a tree 
does not allow sharing (e.g. of the corner points of a poly- hedron) so a less restricted graph structure 
seems  appropriate. To solve the dilema caused by these contradicting requirements, we will provide 
two different structures which coexist in the object. The first is an underlying tree structure. This 
is implemented by i. defining an "object header attribute" for each object which is the root of a tree 
 2. defining pointer types called "attribute list header" and "attribute list link"  3. requiring that 
every attribute (except the object header attribute) be linked into exactly one attribute list.   The 
second structure is an arbitrary directed graph structure which is implemented by i. defining a pointer 
type called "attribute pointer" 2. allowing an attribute pointer to reference any attribute in the same 
object.  These concepts are illustrated in Figure 3 which illustrates how the mine excavations of Fig- 
ures 1 and 2 might be represented as an object. Note that we have had to make only minor changes to the 
structure of Figure 1 in order to link the edge and point attributes into attribute lists. The data 
base must be structured at the object level. At this level, the tree structure is not needed, so we provide 
only an arbitrary graph structure. This is implemented by i. requiring each object to have a "key" which 
is defined as a set of fields in the object header which uniquely identify the object 2. defining an 
"object link" data type which is a set of fields whose value matches the key of (and thus identifies) 
some object.  This mechanism is similar to the key/foreign key mechanism of relational data bases. Note 
that the object link refers to an object as a whole rather than to a particular attribute in that object. 
 Attributes An attribute is defined as the cartesian pro- duct (i.e. record-like structure) of a set 
of fields. Every attribute has two mandatory fields. i. an attribute link field for linking into an 
attribute list 2. a type field which identifies the type  of the attribute Requiring a type field in 
each attribute might seem like an unneccesary overhead, but the yield in flexibility from this investment 
is tremendous. The type field makes the data structure "self- describing" and allows one to construct 
mixed lists and to write very general routines which can ex- amine attribute types and take appropriate 
actions depending on type. The type field of the object header attribute defines the object type. An 
object type is defined by naming and de- fining the data types for a set of fields. Each field may be 
of any one of the following types: i. unstructured types 1.1 integer 1.2 real 1.3 character  241 
 ~- object header attribute iEXCan~tion i Note: thethe struct.......~lyetituteSron II%1 key fields object.entire 
 design reserve nun~ber of volume  info. infq. rings i ? i ~ each °f these bl°eks I i .~'i"  is an 
attribute r ng number &#38;." to ring object  ) attribute list link (or header) .... @ attribute pointer 
Note: each of the rings ....... ~ object link has been separated  into an object. Figure 3 Mine Excavation 
Representation using objects and Attributes. ..~ these are attribute list edge use [| ~ edge ~.%1 
 point point x Y z Figure 4 Mine Excavation Design 242 1.4 scalar (in the Pascal sense) 2. sub-range 
types of 1  3. structuring types (pointers)  3.1 attribute list header 3.2 attribute pointer 3.3 
object links  4. array types  4.1 fixed length array (i.e. length specified at attribute definition) 
of i, 2, or 3 4.2 variable length array (i.e. length specified at instance generations) of i, 2, or 
3 Note that "attribute" is not a recursive data type (i.e. a field cannot be an attribute), since this 
would not allow us to maintain our structuring rules for attribute structures. Design Considerations 
 The motivations that led to this design are efficiency and clarity. The data base is structured and 
accessed at the object level. Since a typical object contains on the order of i00 attributes, we have 
drastically reduced the number of data items with which the data base system must deal. It is thus far 
easier to identify and efficiently access (e.g. through hashing tables) objects than it would be for 
a system structured and accessed at the record level. Furthermore, since the data base is stored on secondary 
storage, such as disk, it is much more efficient to access an object (with all internal attributes) than 
it would be to access the attributes separately. Once an object is in the program work space, it is, 
of course, possible to access all of the attributes within that object at memory speeds. A typical CAD 
application program would begin by accessing a set of objects (usually a relatively small number). Once 
the objects are in main memory they can be displayed and the operator can interact with them in a design 
and analysis loop. When the operator is finished, the objects which have been changed can be updated 
on the data base. In this manner, real time graphic interaction can be sup- ported. Aside from these 
considerable efficiency ad- vantages, the structure described here provides useful and flexible tools 
for designing and imple- menting modeling systems for CAD and scientific modeling. In CAD we are dealing 
with either an existing or proposed environment which we tend, both linguistically and in our design 
methods, to partition into discrete objects. It has generally been possible in the author's experience 
to design object data structures to correspond closely with these real world objects. Furthermore, it 
is us- ually possible to design the attribute structures so that they correspond naturally with the proper- 
ties of the real world objects. While experience has shown that these concepts are useful design tools 
and lead to efficient im- plementations, they are not panaceas. In order for the concept of an object 
to be effective, the object must fit into the program work space. This imposes a size restriction on 
objects (e.g. 8K bytes) which sometimes forces one to arbitrarily partition an object into pieces. This 
does not restrict the representation power of the system, but sometimes makes it more cumbersome than 
it would otherwise be. The restriction that forces objects to be dis- joint (i.e. an attribute in one 
object cannot point to an attribute in another object) results in a less general linkage capability than 
provided by a system structured at the record level. In a record level system any record can reference 
any other record in the whole data base (within the structur- ing constraints). The assumption that leads 
to the concept of objects is that one can partition the environment being modeled into disjoint collections 
of data which correspond to physical objects. A common attribute can always be extracted into a common 
object referenced by those objects which share it. However, if the average size of objects shrinks to 
only a few attributes, the advantage of this approach vanishes and the system reduces to a record level 
data base. However, the author has not yet come across a case where the approach breaks down, either 
because the objects became too large or too small. Graphic Interface The graphic interface is built 
on top of, rather than into, the basic modeling system. This is done by i. defining a standard set of 
"graphic" attri- bute types which contain transformation or drawing information. 2. implementing a graphic 
processor which recognizes and interprets the graphic attributes and drives the graphic hardware. The 
set of graphic attributes and the communication routines (e.g. pointing, positioning, etc.) con- stitute 
a virtual graphic machine. This allows one to change graphic hardware simply by reimplementing the graphic 
processor to drive the new hardware. Applications Time and space limitations prohibit a descrip- tion 
of the operations which must be provided to support the data structures we have described. There have, 
however, been two systems which have been implemented and used for major applications based on these 
concepts. The first system was im- plemented to support a mine engineering system at the Kidd Creek Mine 
of Texasgulf, Inc. This system which became operational early in 1974 was imple- mented on a PDP-II/45 
with 120K 16-bit words and an Evans and Sutherland LDS-2. The application system is used for the following 
interactive functions I. interpret the ore body from diamond drilling 2. design complex 3D excavations 
to fit the ore body  3. sub-divide these excavations into the "rings" that are the basic mining units 
 4. calculate the reserves (tons and ore  grade) for excavations or rings (non-interactive)  5. monitor 
and schedule production  (non-graphic) Figure 4, which was compiled from slides by Roger Harris of 
Texasgulf, illustrates these functions. The second system is described in detail in [I]. It was implemented 
on a PDP-II/70 with 64K 243 words and an Evans and Sutherland Picture System 2. This system includes 
a full schema definition capa- bility, which the first system lacked, and provides several other important 
enhancements to the earlier systems. Both systems are implemented mostly in PDP- ii assembly language 
and appear to the user as a set of Fortran callable subroutines. The second system is providing support 
for a protein modeling application which the author is currently developing with Allen Edmundson and 
his colleagues at the Biochemistry Department of the University of Utah. Conclusions A CAD support 
system is designed to be a tool. It is a tool to aid in the development of CAD appli- cations. After 
the best theoretic analysis we can make, the final verdict on the effectiveness of a tool comes through 
its use (or disuse). While two is hardly an adequate sample, the fact that these concepts have worked 
for two such diverse applica- tions as mine engineering and protein modeling is very encouraging. The 
keys to these successes have been the efficiency and clarity provided by the con- cepts of objects and 
attributes and the flexibility provided by the self-describing (i.e. typed) data structures. Acknowledgements 
 The work reported in this paper has spanned several years, several roles, and several hundred thousand 
miles in airplanes. Particular acknow~ ledgment is due to Roger Harris of Texasgulf, Profs. Elliott Organick 
and Richard Riesenfeld of the University of Utah, Computer Science Department, and Drs. Allen Edmundson 
and Enrique Abola of the Biochemistry Department of the University of Utah. References i. Athay, R. 
J. Object Models for Computer Aided Design, University of Utah doctoral disserta- tion, 1978. 2. Fry, 
J. P., Sibley, E. H., Evolution of Data- Base Management Systems. Computing Surveys, Vol. 8, No. i, (March 
1976).  3. Taylor, R. W., Frank, R. L., CODASYL Data-Base Management Systems. Computing Surveys, o__p_p.cit. 
  244 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807398</article_id>
		<sort_key>245</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>43</seq_no>
		<title><![CDATA[Clipping using homogeneous coordinates]]></title>
		<page_from>245</page_from>
		<page_to>251</page_to>
		<doi_number>10.1145/800248.807398</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807398</url>
		<abstract>
			<par><![CDATA[<p>Clipping is the process of determining how much of a given line segment lies within the boundaries of the display screen. Homogeneous coordinates are a convenient mathematical device for representing and transforming objects. The space represented by homogeneous coordinates is not, however, a simple Euclidean 3-space. It is, in fact, analagous to a topological shape called a &#8220;projective plane&#8221;. The clipping problem is usually solved without consideration for the differences between Euclidean space and the space represented by homogeneous coordinates. For some constructions, this leads to errors in picture generation which show up as lines marked invisible when they should be visible. This paper will examine these cases and present techniques for correctly clipping the line segments.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Hierarchy and geometric transformations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010240.10010244</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision representations->Hierarchical representations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P131722</person_id>
				<author_profile_id><![CDATA[81100294395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Blinn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech/JPL]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39076490</person_id>
				<author_profile_id><![CDATA[81100391172]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Martin]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Newell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[XEROX/PARC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Barr, S., Experiments in Topology, Thomas Y. Crowell Co., New York, 1964.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Riesenfeld, R. F., "Homogeneous Coordinates and Projective Planes in Computer Graphics", JACM, to appear.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Roberts, L. G., "Homogeneous Matrix Representation and Manipulation of N-Dimensional Constructs", MIT Lincoln Laboratory, MS 1405, May 1965.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360802</ref_obj_id>
				<ref_obj_pid>360767</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. E., and Hodgman, G. W., "Reentrant Polygon Clipping", CACM, Vol 17, No 1 (Jan 1974), pg 40.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 CLIPPING USING HOMOGENEOUS COORDINATES James F. Blinn Caltech/JPL Martin E. Newell XEROX/PARC Ab6tract 
 Clipping is the process of determining how much of a given line segment lies within the boundaries of 
the display screen. Homogeneous coordinates are a conveni- ent mathematical device for representing and 
transforming objects. The space repre- sented by homogeneous coordinates is not, however, a simple Euclidean 
3-space. It is, in fact, analagous to a topological shape called a "projective plane". The clip- ping 
problem is usually solved without consideration for the differences between Eu- clidean space and the 
space represented by homogeneous coordinates. For some con- structions, this leads to errors in picture 
generation which show up as lines marked invisible when they should be visible. This paper will examine 
these cases and pre- sent techniques for correctly clipping the line segments. 1. INTRODUCTION Homogeneous 
coordinates have long been used in computer graphics as a convenient mathematical dev- ice for representing 
and transforming objects [3]. However, in spite of the uniformity of representa- tion and operation afforded 
by homogeneous coordi- nates, they are not often exploited to the full. This is probably due to a lack 
of publications ex- plicitly directed at clarifying the use of these techniques. Sutherland and Hodgman 
[4] provide one of the very few discussions on this topic as an ap- pendix to their paper on Polygon 
Clipping. The present paper presents techniques for using homo- geneous coordinates to represent three 
dimensional objects, and shows how the homogeneous representa- tion can be carried through transformation 
and clipping in a consistent way. It is largely a re- iteration of the appendix of [4] and an expansion 
of the ideas presented there. While it is assumed ~hat the reader has some knowledge of homogeneous 
coordinate representa- tions, the following sections are included beth as a review and to introduce basic 
techniques and ter- minology used in the remainder of the paper.  I.i Homogeneous Coordinates The representation 
and transformation of ob- jects in 3 dimensions is usually performed in ana- lysis in a Cartesian coordinate 
system. Tnus three coordinates (X,Y,Z) are sufficient to represent a point in three dimensions. A transformation 
such as rotation or scale is then represented by a 3x3 matrix. Multiplication of the position vector 
by this matrix yields a transformed position vector. Certain points (notably points at infinity) and 
certain transformations (notably translations and perspective projection) are not representable in this 
scheme. The notation called "homogeneous coordinates" has been devised which will encompass all points 
and transformations Of interest. In this scheme, each point is represented in a redun- dant manner by 
4 coordinates. These four coordi- nates will be named, in this discussion, as lower case letters (x, 
y, z, w). The redundancy is ex- pressed in the convention that any (non-zero) mul- tiple of all components 
of the homogeneous repre- sentation of a point is another homogeneous repre- sentation of the same point. 
To get from the homo- geneous representation to the more conventional re- presentation the redundancy 
is removed by dividing each component by w, unless w=Z. This yields a vector which, by the homogeneous 
convention, still represents the same point but has a w component of i. The first 3 components are then 
the convention- al components of the point, named with upper case letters (X,Y,Z).  (x,y,z,w) -> (x/w, 
y/w, z/w, i) -> (x,Y,z) All hoi~ogeneous points with w=l are already in this conventional form. In fact, 
unless there is a good reason to do so, points on objects to be modelled are usually initially specified 
with w=l. Certain transformations performed on these objects might, however, generate points with w~ 
i. Tne division operation can be thought of as a projection of a point in 4-space onto the plane w=l 
by a line through the origin. We show this by examining a section of the (x,y,z,w) space where y=z=0. 
The remaining x and w coordinates appear as in figure i. w Po,., (x~y, ~,w) /. ,// / -w-I //' '~ Pr,j 
ec/'s *0 PD;.t " _ (' x/,,,,Y/,.,., el,.., 0 x --(X-,Y, z, 0 Figure 1 - A Homogeneous Point 245 All 
homogeneous points (x,y,z,w) which represent the same real point (X,Y,Z) lie on the line through the 
origin and (X,Y,Z,I). 1.2 Homogeneous Transformations A point, P, represented in homogeneous coordi- 
 nates (x,y,z,w) is linearly transformed into an image point, P'=(x',y',z',w') by multiplication by a 
4x4 matrix M. P' =PM TO interpret the effect of this matrix on the 3D image of the point let M be partitioned 
as: The 3x3 partition, denoted by r, represents rota- tion and scaling. The ix3 partition, denoted by 
t, represents translation. The 3xl partition, denoted by p, represents perspective. As with points, any 
 (non-zero) multiple of a homogeneous transformation matrix represents the same transformation. Tnerefore 
the ixl partition, denoted by s, has the same meaning for transformations as the w component does for 
points.  1.3 Line Segments Line segments will be represented here in a parametric form as the weighted 
sum of the two end- points P~=(x,,y,,z4,w,) and P,=(x~,y,,z~,w,). P = (l-a) P, + a Pz  0 <= a <= 1 
 As the parameter "a" varies from 0 to 1 the gener- ated point moves linearly from P, to Pz. To find 
the conventional coordinates of points on this seg- ment, each point on the line is projected onto the 
w=l plane. This is illustrated in figure 2.  P. .~/,'/Ho, megen~.u.¢ F, ." Line /,/ ~" M m x Figure 
2 - A Homogeneous Line Segment  For segments defined with both endpoints having w=l all the interpolated 
w values are 1 and the line segment and its projection are the same. For seg- ments defined with each 
endpoint having a positive value of w (as in figure 2) a similar line appears. However for segments defined 
with opposite signs of w on each endpoint a more unusual situation occurs. The segment generated by the 
linear interpolation in 4-space is quite ordinary. The segment generat- ed by projecting each point of 
this onto w=l must pass through infinity at the point where the 4-space segment passes through w=~. This 
is illus- trated below with the points P, and -P~. The end- points represent the same projected points 
as those in figure 2. The projected line segment, however, starts at P, and goes in the direction away 
from P~, passes through infinity and comes back to meet P~ from the other side. This is illustrated 
in figure 3. W, P,.oje,-+s ,.*D ..~/ h~*.j EXternJl Sc~me.'t," S , .,;-~.:;--- '~"" ---X Hem~je,,.eevs 
L.I"n £ Figure 3 -An External Line Segment This line segment consists of the cfm~plement of th set of 
points in the example of figure 2. It il lustrates an alternative way of connecting point (X,,Y,,Z,) 
and (X2,Yj,Zz). It will be called a "external line segment" in contrast to the "inter nal line segment" 
of figure 2. These types o lines can show up in practical applications as result of perspective transformations 
and as a re sult of some co,mPnly used methods for definin curves. It is these external line segments 
whic can cause trouble in clipping algorithms. 2. CLIPPING Clipping is the operation of removing portion 
of a line segment which are outside the scree boundaries. We will begin by examining a simpl clipping 
algorithm. This algorithm will work cot rectly only for the region w>0 so we will initiall concern ourselves 
with this region. TO simplify the arithmetic, it is convenier to clip to the boundaries -I<X<+I and 
-I<Y<+I. T~ viewing transformation can be adjusted to map ar desired object window to this region. Tne 
clippir boundaries are thus the planes X=-I (left) X=+I (right) Y=-I (bottom) Y=+I (top) In the homogeneous 
representation these become: x/w=-i x/w=+l y/w-~l y/w=+l or the four homogeneous planes W+X=0 W-X--0 
W+y=0 W-y=0  Looking at the left and right boundaries in the xw plane we have figure 4. W / o~ .¢~:rceot 
ir iX / Figure 4 - The Visible Screen Region  The region on the w=l plane between x=-i and x=+l represents 
the visible region in X after the homo- geneous division has been performed. Any points in the cross 
hatched area will project onto this re- gion and are thus visible. A point is visible if w+x > and w-x 
>  Note that all points within the cross-hatched area satisfy this condition. If a line segment lies 
partly inside and part- ly outside the screen it will penetrate one of the homogeneous clipping planes. 
We need to find the point of intersection. Tnis can be expressed as a value for "a" in the parametric 
definition of the line segment. P = (l-a) P, + a Pz  Suppose the line Segment crosses the w+x=~ plane. 
The value of "a" at which this occurs is ((l-a)w,+(a)wz] + [(l-a)x,+(a)xz] =  or a = (w,+x.) I ((w.+x,J 
-(w,+x,)) The quantity w1+x , is proportional to the distance from the point P, to the plane x+w=0. 
Therefore it may be interpreted as a transformed coordinate of P~ relative to the boundary x+w=~. For 
this reason it will be called a "Boundary Coordinate". For any point there is a boundary coordinate for 
each clip- ping boundary. BL = w+x (left) BR = w-x (right) BB = w+y (bottom) BT = w-y (top) These are 
defined so that a positive value indi- cates that a point is on the visible side of the clipping plane. 
If a line (l-a)P,+aP, crosses, for example, the left boundary it does so at a=BL,/(BL,-BLz). A similar 
expression holds for  the other boundaries. 3. THE HOMOGENEOUS PERSPECTIVE TRANSFOIgM External line 
segments first appear when using the perspective transformation. A perspective pro- jection essentially 
causes division of X and Y by the Z distance in front of the eye. The homogene- ous perspective transformation 
makes clever use of the homogeneous division (which must be done any- way) by merging the Z division 
with it. The sim- plest form models the eye at (0,0,-i). To achieve a perspective projection the X and 
Y should then be divided by Z+I. In homogeneous terms x/w and y/w should be divided by z/w+l=(z+w)/w, 
becoming x/(z+w) and y/(z+w). This can be expressed in ma- trix form as The effect of thistransformation 
is to change the boundaries of a "view cone" radiating from the eye into the same parallel clipping 
boundaries that were used for' orthographic projections. Points with z/w=0 are unchanged. Points with 
z/w>0 are scaled down while points with -l<z/w<0 are scaled up. See figure 5. Fo,-¢ ~ -| ' :' ' Eyo 
a~    I~ye S i IL ='I'l ~ / // . Figure 5 - Perspective Transform in XZ The process of effectively 
clipping to the view cone for perspective pictures is performed by first applying the homogeneous perspective 
transformation and then clipping to the same boundaries defined previously. Indeed, this interpretation 
of the perspective transformation explains the use of post-perspective transformations to achieve special 
viewing effects such as projection onto an oblique viewing plane. Such a projection can be considered 
as a conventional perspective projection followed by a translation of the required part of the pro- jection 
to the clipping region. It may be verified that composition of two such transformations yields one which 
correctly maps the boundaries of the ob- lique viewing cone into the sane clipping planes used above. 
 Although the Z coordinate of a point might not seem immediately useful after perspective projec- tion, 
it is necessary for hidden line/surface com- putations and for depth cueing. This transform has the 
important property that it includes z such that straight lines romain straight. Examining the zw plane 
we see that the transformation is merely a skew along the w axis, figure 6. Note that objects originally 
defined in the w=l plane become distorted when, after transformation, they are projected back into the 
new w=l plane. The eyepoint transforms into (0 0 -I 4), a point infinitely distant in the minus z direction. 
Points infinitely far away in the positive z direc-  247 ! ! ! !1 IW ,'" i //. J B el:o,,-e ','! I 
~2"," ,, oi=ie,:#-s ~t-£ = ÷ ,,o fe_.___~ FIf / .++',.~;,,/ F>,<>j<=+,-z--, ;' : ! " Pill oBie#..'i's 
uivally , ."P---yel~ }"~iilF,i.li~;i plil.l- o, W=l k / ,'l I ~- --iil I . "'" '"'" . "" ,=re project-t.o 
Ll'l .... ii niz~ Figure 6 - Perspective Transform in zw tion transform into z/w=l. Note the effect 
of the transformation on the three cross-hatched regions of figure 6. In general the following transforma- 
tions of regions in z have taken place before after -~< z/w < -I 1 < z/w < +~ -i < z/w < 0 -~< z/w < 
0 0 < z/w < +~ 0 < z/w < +i Points that were behind the eye have "wrapped ac- ound" through - and are 
now at z/w > i. Let us now consider the effect of the perspec- tive transformation on line segments 
and how they are clipped. For segments which are totally in front of the eye nothing very unusual happens. 
Consider, however, a segment from a point in front of the eye to a point behind the eye (a perfectly 
reasonable occurrence when arbitrary viewing posi- tions are allowed). After the perspective trans- formation 
this becomes an external line segment. It starts out at some Z<I, proceeds in the negative Z direction 
past the eye (at -~in Z), wraps around to positive Z and ends at some Z>I, see figure 7. t w I   / 
/_z "<" I p~+, h,re. Figure 7 - Perspective Transform of Line Segment If the two endpoints are projected 
back onto the w=l plane both endpoints could quite possibly lie within the visible region of the screen 
in X and y. This is despite the fact that the point behind the eye is quite obviously invisible. Furthermore, 
 these points should be connected by an external line segment rather than an internal one. This case 
is difficult to distinguish from the case of two ordinary visible points which started out in front 
of the eye. (It can be detected by noting that the endpoints of external line segments strad- dle the 
z/w=l plane). These problems can be re- solved by clipping all segments in the homogeneous space prior 
to projectingback onto w=l. In the present case, the line passing by the eye would be clipped at the 
X edge of the screen before it even passed the eye, see figure 8. w Figure 8 - Clipping of External 
Segment The portions of the external segment which give trouble are clipped off by one of the left, 
right, bottom or top planes. The X,Y clipping process is sometimes augment- ed by a clipping operation 
in Z. This is done pri- marily for the purpose of restricting the range of the Z coordinate. Points between 
the eye and the Z=0 plane (i.e. the screen) take up a small por- tion of the real world, but after perspective 
transformation they stretch from -~ to 0. To avoid the need to represent points with infinite Z coor- 
dinates we can clip away those with z/w less than some amount using a "near" clipping plane. In ad- dition, 
to further restrict the range of Z values a "far" clipping plane is sometimes included. Z clipping can 
be standardized just as X,Y clipping by defining the visible region in Z to be 0<Z<+I. The actually desired 
locations of the near and far boundaries can be incorporated into the transforma- tion matrix as a scale 
and translation of the z coordinate. ThUS we have two now clipping planes and two boundary coordinates. 
 BN = z (near) BF = w-z (far) A point is visible with respect to the z clipping planes if both these 
quantities are positive. The main point of this section is, then, that  for our first exposure to external 
line segments, those formed by the perspective transform, the ori- ginal clipping algorithm still works. 
We have seen that the clipping algorithm works correctly for lines which r~nain in the w>0 region and 
for those which dip into the w<0 region due to the perspec- tive transformation. The clipping should 
be per- formed before the homogeneous division, however. The addition of Z clipping is useful to restrict 
the range of Z values after the perspective trans- form, but is not necessary to the correct elimina- 
tion of line segments behind the eye. 5. RATIONAL PARAMETRIC CUI~VES Tnis section introduces a standard 
modelling technique which happens to generate lines which are not correctly clipped. This is the technique 
of modelling curved lines parametrically with rational polynomial functions. To illustrate the problem 
it is only necessary to consider two dimensional pla- nar curves. We will therefore assume the Z coordi- 
nate is always zero and not include it in subse- quent matrix equations. The simplest, non-linear, parametric 
curves are the conic sections. It is possible to repre- sent any conic section by X = P(ti/R(t) Y = 
Q(t)/R(t) or x = P(t) y = Q(t) w = R(t) where P(t), R(t) and S(t) are quadratic polynomi- als. To 
prove this we start with the simple para- bola X=Y . This can be represented parametrically in homogeneous 
coordinates as (x y w) = (t~ t i) By the homogeneous convention, any non-zero scalar multiple of each 
point on the parabola also lies on the parabola. The locus of all such points in hom- ogeneous space 
is the cone (x/w)= (y/w) 2 . The para- bola is the intersection of this cone with the w=l plane. This 
cone, incidentally, is an elliptic cone rather than a circular cone, as shown in fig- ure 9. ¢>,,  
 jl ~X Figure 9 - Elliptic Cone Note that this matches the classical defenition of a parabola as the 
intersection of a cone with a plane parallel to one of its sides. Now by various rotations of the parabola 
(and thus the cone) about the origin (representable by a 3x3 matrix) we can change the relative orientation 
of the plane of in- tersection and thus generate different conic sec- tions. The multiplication of the 
vector (t 2 t i) by a 3x3 matrix yields 3 general quadratic polyno- mials. (x y w) = (tz t i) M = (P(t) 
Q(t) R(t)) For example, by rotating 45 degrees around the y axis we can make the axis of the cone perpendicu- 
 lar to the intersecting plane (w=l) and generate an ellipse (since the cone is elliptic). Then, by 
 scaling by 3~ in y the ellipse turns into a cir- cle. (X y W) = {t 2 t 1)  I': ':1 l-*//7 o ~//~J 
X = (ti-l)/(t i kl) Y = ( 2t )/(t~+l) The reader can verify that X~+Y2=I independent of the value of 
t. Alternatively, by rotating -45 degrees around y, the axis of the cone will become parallel to w=l. 
Such an intersection yields a hyperbola. {x y w) = It 2 t i)   1/,/-2 o -1/d~ I 0 i 0 X = (t ~ + l)/(l-t 
~) Y = (t r~-)/(l-t') How does the clipping process work when ap- plied to this hyperbola? This curve 
happens to lie wholly outside the standard clipping region so we will scale it down by a factor of 2 
to make the problem interesting. When projected onto the w=l plane, it appears as in figure 10. t~--! 
J£=O °l,o  -i.6 ~,t,~ -I Figure 10 - Parametric Hyperbola Thus, two brandles should be visible on 
the resul- tant display. To draw the curve we evaluate the x, y, and w ft~ctioD~ at equal steps in t 
and connect the points with straight line segments. This traces out the rotated and scaled parabola in 
homo- geneous space. This parabola appears as in figure ii.  249 w/ ~N=.I ...."" X ./ . " "'"  
Figure ii .- Side View of Rotated Parabola Note that only one branch falls within the visible region 
in the sense we have defined it so far. The clipping algorithm will remove an entire branch of the hyperbola 
which should have been visible. 6. CLIPPING WITH N~GATIVE W  To p~operly clip such objects we must 
re-examine the definition of the "visible" region. For example, for the left clipping boundary a point 
is visible if X = x/w > -I. This implies two pos- sible sets of conditions for visibility. That is w>0 
and w+x>0 or  w<0 and w+x<0 A point must be tested against two planes, w+x=0 and w--0. Two planes 
are necessary because of the topological properties of the space represented by homogeneous coordinates. 
Riesenfeld [2] points out that this space is not the usual Euclidean 3-Space. It is, in fact, a space 
whose properites are anala- gous to a shape known as a "projective plane". The important difference is 
that, for a projective space, a single (infinitely extended) flat plane does not divide space into two 
distinct regions. Just placing a plane between two points does not separate them. There is always an 
alternate path (perhaps through infinity) connecting them. In order to separate two regions in homogeneous 
space it is necessary to use two dividing planes. Tnis is shown very nicely in Bare [i]. The complete 
visible region in the x dimension is formed by the intersection of the newly defined left and right visible 
regions. Note that each point in the new visible region, when projected onto the w=l plane falls within 
the -I<X<+I region. The two visible regions are shown labelled A and C in figure 13. Points in region 
C would all be marked invisible by the original algorithm because they occur on the "invisible" side 
of both the w-x=0 and w+x=0 planes. It is in just this region that the points lie for the missing branch 
of the hyperbola, see figure 12. //   \\ "X ion C Figure 12 - Complete Visible Region In xw One 
interesting case that can occur is when an external line segment has one endpoint in region A and the 
other in region C, as shown in figure 13. W  "~v is"%!~./s nen~J /e' / Figure 13 - Multiple Visible 
Segments The segment in homogeneous space intersects the clipping surface at two points. Two disjoint 
poe- tions of the segment will be mapped into the visi- ble screen region. This is precisely what happens 
with the hyperbola for the line segment between parameter values t =.9 and t=l.l. At t =.9 one branch 
is just approaching its asymptote going to infinity towards the upper right. At t=l the point on the 
curve passes through infinity. At t=l.l it has wrapped around and is coming in from the lower left. See 
figure 14. Any complete clipping algor- ithm which works in homogeneous coordinates must, therefore, 
be able to generate two output segments for one input segment. Y t.,//Is ..... ." ! bo~.d4vy  ':"'"I 
Figure 14 - Multiple Segments of Hyperbola  One effect of the inclusion of the visible re- gion at negative 
w is that the z clip is no longer optional in order to remove objects behind the eye. Before, when using 
only the region for positive w, a line passing behind the eye was correctly clipped off where it left 
the screen. With the complete visible region, if it extends far enough behind the eye it may penetrate 
the negative w visible region and re-appear on the screen in the same manner as multiple segments of 
a hyperbola. This problem is solved by including a "far" clip bounded by the planes w=0 and w-z=0, keeping 
points with Z<I. This just states that the perspective view cone must be closed off by the plane at infinity, 
which transforms to the plane z/w=l after the perspective transform. See figure 15. Figure 15 - Complete 
Visible Region In xzw 7. ALGORITHMS Given the new definition of the visible re- gion, we turn to the 
question of how, algorithmi- cally, we can clip to this region. The big problem is that two output segments 
may be generated from one input segment. The basic control structure of most clipping algorithms allows 
only one output segment. Sutherland and Hodgman solved the problem of two disjoint clipping regions by 
transforming and clipping each object twice, once the transfor- mation matrix intact and a second time 
after multi- plying the matrix by -i. This effectively uses only the positive w clipping region but mirrors 
the line segments about the w--4 plane to generate the missing lines. This approach, while not complicat- 
 ing the control structure, requires each point to be transformed twice. We would like to avoid this. 
 The next step up from this would not require doubly transforming the object but would place a processor 
between the transformation and clipping stages. It would do a simple test against the w=0 plane. If a 
segment was totally above it would be passed directly to the clipper. If it was com- pletely below it 
would be mirrored and passed to the clipper. If it straddled the w=0 plane it would be passed to the 
clipper twice, once mirrored and once not. In this case also, the clipper it- self works only with the 
positive w portion of the clipping region. Double output segments come from two calls to the clipper. 
 A general solution to the problem would be to invent a clipper which actually handles disjoint clipping 
regions. The first step necessary is to redefine the boundary coordinates to accurately re- flect the 
visibility of points. Each is formed as the product of the equations of the two planes de- fining that 
boundary. These would be BL = w(w+x) BR = w(w+x) BB = w(w+y) ST = w(w-y) BN--wz BF = w(w-z)  They 
are, again, chosen so that they are positive in both visible regions. Clipping is then per- formed one 
boundary at a time with the surviving portions of the segment being passed on to the next boundary. This 
requires two plane intersection tests for each boundary. For reasons of economy we can merge the left 
and right clipping regions into one global x clipping surface by definining BX = (w+x) (w-x|  An incoming 
line segment would be tested against each of these component planes. If it intersected only one, the 
visible portion would be retained and passed to the y clip. If it interrsected both, the signs of (w+x) 
and (w-x) would determine if it was the center section or the two end sections that was visible. The 
y and z visible regions are similarly defined by BY = (w+y) (w-y) BZ = w (w-z)  It is not clear whether 
a disjoint clipper would be superior to the simpler mechanism of mir- roring the line segments. 8. CONCIDSIONS 
 This paper has shown that, under certain cir- cumstances the clipping r6~jion traditionally used in 
cGmputer graphics is incomplete. There is an additonal such region mirrored about the w--0 plane. Points 
are generated in this region usually only for certain modelling techniques, such as rational polynomial 
par~eteric curves. In order to proper- ly clip such curves the clipper must be capable of generating 
two output segments for one input seg- ment. REFERENCES [i] Barr, S., Experiments in Topology, Thomas 
Y. Crowell Co., New York, 1964. [2] Riesenfeld, R. F., "Homogeneous Coordinates and Projective Planes 
in Computer Graphics", JACM, to appear. [3] Roberts, L. G., "Homogeneous Matrix Represen- tation and 
Manipulation of N-Dimensibnal Con- structs", MIT Lincoln Laboratory, MS 1485, May 1965.  [4] Sutherland, 
I. E., and Hodgman, G. W., "Reen- trant Polygon Clipping", CACM, Vol 17, No 1 (Jan 1974), pg 40. 251 
  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807399</article_id>
		<sort_key>252</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>44</seq_no>
		<title><![CDATA[On storing and changing shape information]]></title>
		<page_from>252</page_from>
		<page_to>256</page_to>
		<doi_number>10.1145/800248.807399</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807399</url>
		<abstract>
			<par><![CDATA[<p>A data structure for modelling engineering components and assemblies is described. It is shown how the same structure, slightly extended, can also be used to represent a single component defined as boolean combinations of more primitive shapes. This leads to a unified method of handling both the concise boolean description and the longer explicit description in terms of faces, edges and vertices. The technique permits close control of evaluation from boolean to explicit description, and facilitates saving of partly evaluated results and back tracking.</p> <p>The data structure is built up and evaluation is controlled through a geometrical language embedded in Algol 68. The language is intended for the construction of computer-aided design systems, for simulating engineering production processes, or for any application in which shapes and changes to shapes must be recorded and manipulated.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computational geometry]]></kw>
			<kw><![CDATA[Computer-aided design]]></kw>
			<kw><![CDATA[Computer-aided manufacture]]></kw>
			<kw><![CDATA[Geometric languages]]></kw>
			<kw><![CDATA[Geometric modelling]]></kw>
			<kw><![CDATA[Mechanical components]]></kw>
			<kw><![CDATA[Polyhedra]]></kw>
			<kw><![CDATA[Shape synthesis]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>G.1.1</cat_node>
				<descriptor>Spline and piecewise polynomial interpolation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Digitizing and scanning</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010506</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Document scanning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003657.10003659</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Nonparametric representations->Spline models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003722</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Interpolation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P113807</person_id>
				<author_profile_id><![CDATA[81100024019]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[I.]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Braid]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Cambridge]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baumgart, B.G., Geometric modelling for computer vision, Stanford Artificial Intelligence Laboratory report STAN CS-74-463, (1974).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Braid, I.C., Lang, C.A., Computer-aided design of mechanical components with volume building bricks, proc. PROLAMAT '73 (published as Computer Languages for Numerical Control by North Holland, Amsterdam), (1973).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Braid, I.C., Designing with volumes, Ph.D. Thesis, Cambridge University, England, (1974).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Braid, I.C., Six systems for shape design and representation - a review, proc. CAM-I Int. Seminar, Bournemouth, England, report P-75-MM-ol, pp. 60-67, (1975).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807158</ref_obj_id>
				<ref_obj_pid>872738</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Braid, I.C., and Hillyard, R.C., Geometric modelling in ALGOL 68, ACM Sigplan Notices, vol. 12, no. 6, pp. 168-174, (1977).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Gnatz, R., Higher graphic languages. In: Nake, F. and Rosenfeld, A. (Eds.) Graphic Languages, North Holland, Amsterdam, pp 302-320, (1972).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Hagen T., et al, The intermediate language for pictures, Proc. IFIP '77, (pub. North-Holland), pp. 173-178, (1977).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kleene, S.C., Introduction to Metamathematics, p 334, D. Van Nostrand Inc., New York, (1952).]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>1096493</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Lindsey, C.H. et al, Informal Introduction to Algol 68 (revised) North-Holland, (1976).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Okino, N. et al, TIPS-1: Technical information system for CAD, drawing and manufacture, proc. PROLAMAT '73 (see above), (1973).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Voelcker, H.B. et al, An introduction to PADL, Report TM-22, Production Automation Project, University of Rochester, N.Y., (1974).]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Williams, R. and Krammer, G., EX.GRAF: an extensible language including graphical operations, CGIP, vol.1, no.4, pp 317-340, (1972).]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ON STORING AND CHANGING SHAPE INFORMATION I.C. Braid University of Cambridge Abstract: A data structure 
for modelling engineering components and assemblies is described. It is shown how the same structure, 
slightly extended, can also be used to represent a single component defined as boolean combinations 
of more primitive shapes. This leads to a unified method of handling both the concise boolean description 
and the longer explicit description in terms of faces, edges and vertices. The technique permits close 
control of evaluation from boolean to explicit description, and facilitates saving of partly evaluated 
results and back tracking. The data structure is built up and evaluation is controlled through a geometrical 
language embedded in Algol 68. The language is intended for the construction of computer-aided design 
systems, for simulating engineering production processes, or for any application in which shapes and 
changes to shapes must be recorded and manipulated. Keywords and phrases: computational geometry, computer-aided 
design, computer-aided manufacture, geometric languages, geometric modelling, mechanical components, 
polyhedra, shape synthesis. C.R. Categories: 3.2, 8.2  i. Introduction  In recent years, the idea 
of building up three-dimensional shapes by combining simple shapes together has become increasingly popular, 
numerous systems have been built (for example, [2,10,11]), and a few have reached the point of practical 
application in industry. However, these systems tend, like operating systems, to be large, intricate 
and prone to error. Although some of the difficulties will yield to structured programming, use of high-level 
languages and simply good programming practice, others are intrinsic to the subject and ought to repay 
closer scrutiny. This work was supported in part by the Science Research Council, U.K. Author's address: 
Computer Laboratory, Corn Exchange Street, Cambridge CB2 3QG, England. In this paper, an aspect of data 
structures in geometric modelling is examined. Two kinds of data structure commonly occur [4]. One is 
an implicit, unevaluated description of a shape stored by designating the constituent shapes, noting 
the rotation, translation or scaling operations to be applied to them, and prescribing the type and sequence 
of set operations to be performed upon them. The description may be in the form of a string of commands, 
or may have been transformed into a tree-structure whose terminal nodes are either complete primivite 
shapes such as cubes, cylinders and prisms, or are individual surfaces, for example, the half-spaces 
of the PADL system [ii]. The second kind forms an explicit, evaluated description of a shape in a graph-based 
data structure that records how the faces, edges, and vertices of a shape are connected (known loosely 
as the shape topology), together with geometric information describing the surfaces and curves in which 
faces and edges lie, and the positions of the vertices. Both kinds of data structure can be discerned 
in any system using set operations on shapes. In fact, the second kind is the result of evaluating the 
expressions represented by the first. However, systems to date have tended to stress one kind at the 
expense of the other, either performing an immediate evaluation whenever a boolean command is given (the 
'steady state' method), or delaying all evaluation until a final stage is reached (the 'big bang' approach). 
In the latter case, the explicit data structure finally produced is sometimes specialized if only a picture 
or numerical control output is wanted, thereby to some extent simplifying and speeding up a lengthy computation. 
 The thesis of this paper is that the specification of the set operations should be decoupled from their 
evaluation. It should be possible to start evaluation at various places in the tree at different times 
and observe the results during a succession, so to speak, of little bangs. The user of the system can 
then be given much better control over the progress of his design as he sets up volumes, checks them, 
combines them and backtracks. A further advantage of this approach arises if the system is being used 
to model a manufacturing process such as 252 machining. In this case, it is the path taken to the final 
goal that is of interest as much as the goal itself, and hence control of progress along that path is 
vital. We begin by describing a simple data structure for assemblies and components and show how it 
can be generalised to cover implicit and explicit descriptions. At the risk of taxing readers, we have 
used Algol 68 [9] to specify the data structures. We can then go on to show how operators defined in 
the language can be made to generate the data structure and to control evaluation. This is important 
if the complexity of hierarchical data structures [3, Ch.4] is to be controlled and comprehended by the 
user. Even so, we regard the compiled input as better suited to writers of special-purpose CAD systems 
that will use the underlying kernel of procedures, rather than to engineering designers. 2. A shape 
model for assemblies Assemblies consist of items which are either individual components or sub-assemblies. 
An assembly is modelled as a tree with components at the terminal nodes, and sub-assemblies at the non-terminal 
nodes. As there are frequently several occurrences of an item in an assembly, we allow an assembly to 
contain instances of other assemblies, and permit assemblies to be instanced more than once: the tree 
is now a directed graph. An assembly must not contain an instance of itself or of an ancestor as this 
would imply an infinite assembly. In other words, the directed graph must be without cycles (a semi-tree). 
To simplify deletion of assemblies, we also keep a count of the number of times an assembly is instanced. 
 A three-valued logical entity records the type of the assembly. For finished assemblies, the type will 
always be collective, that is, the items in the assembly are simply juxtaposed and collected together. 
As will be explained below, assemblies can also be of type conjunctive or disjunctive. Three-valued quantities 
are of mode kleen, named after S.C. Kleene [8]. They are widely used in the system, for example, to convey 
the result of a test to determine if a point is inside, on or outside a closed boundary. An assembly, 
then, is declared by mode assembly = struct ( union (ref instance, ref component) item #either a component 
or the first of a chain of instances of (other) assemblies in this assembly# , kleen type #3-valued 
logical entity# , int used #number of times this assembly is instanced# ). Note that modes (int, real, 
transformation, ref assembly, etc.) are always,underlined in the Algol 68 examples. System words (mode, 
struct, union, proc , op, etc.) are also underlined, as are operators with alphabetical names (evaluate, 
draw - see below). Sequences of the form "(" "," ... ",.... )" are aligned horizontally or vertically. 
 The structure for an instance must contain a reference to the assembly instanced (the prototype) and 
a reference to the next instance in the chain. For convenience, a reference to the assembly containing 
the instance (the owner) is included as well. We also store in the instance a transformation so that 
the instance can be moved, rotated and scaled. Thus we have mode instance = struct ( ref assembly prototype, 
owner , transformation trans ref instance next ). Every path from the base of the semi-tree to a terminal 
node denotes the presence in space of a solid, that is, of the cemponent at the terminal node transformed 
successively by each transformation along the path. The structure is best handled using recursion. For 
example, given a procedure ("draw component") to draw a transformed component and an operator "*" to 
multiply two transformations together, an assembly may be drawn by proc draw assembly = (ref assembly 
a,transformation t) ref assembly: case item of a #test whether item is instance or component# in (ref 
instance i): #non-terminal node -draw instances# for all instances (i , ( ref instance j) void: draw 
assembly (prototype of j, trans of j * t) ) , (ref component c): draw component (c,t) esac. A further 
procedure "for all instances" of mode proc (ref instance proc (ref instance) void) void applies the argument 
procedure (in the example above not named but given explicitly) to each instance in a chain of instances. 
 This example shows how attributes, in this case a transformation, can be passed along a path. Different 
attributes with different rules for their combination could be devised. Such an approach has been used 
in computer graphics [7] for handling transformations, line styles and other graphic information in a 
general graphical data structure and language for picture processing. 3. Types of assembly The data 
structure developed for assemblies may be used to represent the implicit and explicit forms of shape 
description if we allow assemblies to be of three different types: collective, conjunctive or disjunctive. 
A collective assembly has already been explained above. If, however, the solids are going to be combined, 
the assembly is marked as conjunctive or disjunctive depending on whether a set union or intersection 
is envisaged. Note that as the same boolean operation is to be applied to all items in a given assembly 
considered together, the order in which it is actually performed on the items is immaterial. 253 To 
obtain the set difference operation, we need to be able to complement some of the items in a disjunctive 
assembly. An extra boolean field might have been added to the instance mode. Instead we choose to place 
the boolean in the definition of a transformation, that is, mode transformation = struct ( matrix mat 
#a 4x4 matrix to record rotation, scaling and translation# bool neg #if true, negate the transformed 
entity# ). The multiply operator for transformations can now be given: o p * = (transformation p,q) 
transformation: (mat of p * mat o_ff q, neg of p ~= neg of q) where an operator * for matrix multiplication 
is employed. Having shown how the implicit form of shape description is handled, we now consider briefly 
the explicit form. This occurs at the terminal nodes of the semi-tree, which are occupied by assemblies 
containing a single component. The storage of faces, edges and vertices of the component is based on 
Baumgart's winged-edge data structure [i], extended to handle multiply- connected faces. A description 
of the structure in a simplified form is given in [5]. Evaluation of set operations is carried out by 
an operator formally defined as op evaluate = (ref assembly a) ref assembly: the details of which will 
be described elsewhere. It takes and returns an assembly. Often the resulting assembly will be a single 
component. If, however, a set difference cuts a component into pieces, then these are easily returned 
as a new assembly. Thus the data structure is able to represent an assembly, or an implicit, unevaluated 
description of a component (or assembly), or the evaluated result. The evaluate operator need not be 
applied at the base of the semi-tree; it can be applied to any sub-assembly when its effect will be confined 
to the instances in that assembly and their descendants. Like drawing, evaluation is carried out recursively. 
With care, it is possible to ensure that only a minimum of change is made to the semi-tree in order to 
model the effect of evaluating set operations. For example, the conjunction of disjoint solids produces 
no change in the tree. The same procedures for drawing or saving an assembly on backing store can be 
used for unevaluated, or partly- or fully- evaluated descriptions; hence saving of semi- finished shapes 
is easily arranged and an automatic back-up can be provided if desired. 4. Compiled shape descriptions 
 Having described the form of the data structure, we now show how examples of it can be constructed by 
means of compiled statements in Algol 68. Perhaps the greatest advantage of the language in shape processing, 
apart from the ability to declare new modes, is that it allows operators to be defined. In principle, 
operators are not much different from procedures that take one or two arguments and deliver one result. 
Yet, as will be seen below, their use makes shape descriptions much easier to write and understand and 
is probably essential if full advantage is to be derived from the data structure proposed. In effect, 
the operators allow a language for shape processing to be embedded in Algol 68, and that language also 
enjoys the power of Algol 68 in addition to its geometric and topological features. Others have similarly 
constructed graphical languages [6,12] based on extensible programming languages. In shape processing, 
rather than work in terms of lines and points in a graphical language, we prefer instead to devise a 
language in the problem domain where the language can be made more concise and more powerful. Doubtless 
this is true for many applications and suggests that it is extensible programming languages that should 
be encouraged rather than special-purpose languages for particular applications or techniques. In Algol 
68, dyadic operators are given priorities so that the order of evaluation is defined. The reader need 
not be concerned with priorities for the purpose of this paper, but should remember that monadic operators 
are always evaluated before dyadic operators, and that repeated occurrences of the same operator are 
evaluated from the left. The data structure will be built up in a global area (the heap) which exists 
independently of the flow of control through the block structure of the program. Although we shall sometimes 
speak of operators taking arguments, and delivering results such as assemblies, the arguments are in 
fact references to the assemblies, rather than the assemblies themselves. We shall make use of diagrams 
for illustration in which an assembly is shown by a circle and an instance by a square. If the assembly 
has an instance chain for its items, it appears as whereas if it is a terminal node with an explicit 
data structure attached, it appears as where the triangle denotes the winged-edge data structure. 
The basic tree-building operator ( + ) creates a new instance of the assembly given by its right-hand 
argument, adds it to the instances already attached to the assembly given by the left-hand argument, 
and returns the new instance. An alternative definition with a left-hand argument of mode instance adds 
the new instance after the given instance. Thus a + b + c is parsed as (a ÷ b) + c 254 which creates 
 and returns instance i. A check is made to ensure that adding an instance does not create a cyclic result. 
 Also needed is a monadic operator ne___gg declared for instances op neg = (ref instance i) ref instance: 
(neg of trans of i := ~ neg of trans of i; i). The operator neg is also declared for assemblies which, 
if non-terminal, have all their instances negated, and, if terminal, have their explicit shape description 
negated by reversing the stored boundary orientation. We shall make use of a procedure "mka" that constructs 
an assembly with no instances, and monadic operators conjunctive, disjunctive, collective that return 
true when applied to assemblies of the given type. Three more operators setconj, setdisj, setcoll force 
an assembly to be the given type; owner finds the assembly that contains the given instance. We may 
now define the operators +, !, &#38;, - and use them to form collections, unions, inter- sections or 
set differences, respectively. The monadic operators +, ! and &#38; each create a null assembly and force 
it to be the appropriate type before adding an instance of the given assembly; they then return the newly-created 
assembly. The dyadic operators first inspect the assembly given in the left-hand argument. If it is of 
the required type, the assembly given by the right- hand argument is simply added as a further instance. 
If the type of the left-hand argument is different, that assembly is first instantiated using a monadic 
operator, and the right-hand argument is added as a further instance in the newly-created assembly. This 
arrangement ensures that extra levels in the semi-tree are only created when necessary. o p + = (ref 
assembly a) ref assembly: owner (setcoll mka ÷ a); o_P_P + = (ref assembly a,b) ref assembly: owner 
 begin if collective a then a else +a fi ÷b end ; o_PP ! = (ref assembly a) ref assembly: owner (setconj 
mka ÷ a); o_~ ! = (ref assembly a,b) ref assembly: owner begin if conjunctive a then a else !a fi 
 ÷b en__dd; o_~ &#38; = (ref assembly a) ref assembly: owner (setdisj mka + a); o p &#38; = (ref assembly 
a,b) ref assembly: owner begin if disjunctive a then a else &#38;a fi ÷b end; o_~ -= (ref assembly 
a) ref assembly: neg &#38;a; o19 -= (ref assembly a,b) ref assembly: owner : neg begi n if disjunctive 
a then a else &#38;a fi +b end. For example, +b + b ! c &#38; (d-e) will be parsed as (+b) + (b ! 
(c &#38;(d-e))) and will produce the structure shown in fig.l. We now have a means of creating the non- 
terminal nodes of the tree but have also to set the terminal nodes and the transformations in the instances. 
A terminal node contains a single component in explicit form. Procedures such as "make cube" and "make 
cone" construct the primitive components using the methods of Baumgart. Sweeping operators are provided 
for constructing prismatic shapes or objects of revolution. Where a primitive is to be referenced more 
than once, like "b" in the example Fig. 1 An assembly 255 above, we would first declare "ref assembly 
b = make cube" before writing down the expression for the semi-tree. Instances have their transformation 
initially set to unity. Two operators, ÷ and *, allow a transformation in an instance to be replaced 
or modified by another transformation. An assembly can be transformed by op * = (ref assembly a, transformation 
t) ref assembly: case item of a in (ref instance i): for all instances (i, (ref instance j) void: 
 trans of j := trans of j * t) (ref component c):transform component(c,t) esac. Sometimes it may be 
necessary to transform a particular instance in an assembly. To assist in locating instances, two further 
operators are provided. One "ni", used as in "a ni b", delivers the first instance of "b" in "a". If 
there are several instances of "b" in "a" , the other operator "II '! will select the nth instance in 
the instance chain. Thus "a ni b II 2" finds the second instance of b in a. Various monadic operators 
construct simple transformations by moving, scaling or rotating an assembly. For example, mx 3.5 delivers 
a transformation for a move by 3.5 units along the x-axis. Thus to draw a cube pierced with an angled 
cylindrical hole scaled in z by 2 and rotated by 45 degrees about the x-axis , we could write draw evaluate 
(make cube - make cylinder * s__{z 2 * r__xx 45) The draw operator takes account of factors such as 
scale, line style, view point and projection, all controlled by the current "view style", a global quantity; 
it also makes use of the procedure "draw assembly" described above. The data structure before and after 
evaluation is cub~cylind~ f°re / ~ after 5. Conclusion A hierarchical data structure for shape descriptions 
offers a unified solution to the problem of specifying shapes in terms of volume elements and set operators, 
and of representing the final result as assemblies, sub-assemblies and components. By describing the 
hierarchies as compiled statements in a high-level language which allows operators to be defined, the 
complexities of the hierarchical approach can be managed. So far, input in the form of compiled statements 
has been used for testing the system, and for writing a command interpreter that gives the user the impression 
he is creating a simple one-level collection of solids in space whilst actually building and modifying 
a compact hierarchical description. We intend next to construct a specialized CAD system for a class 
of shapes, for example, pistons, and to evaluate the use of compiled shape descriptions in this more 
realistic context. References: i. Baumgart, B.G., Geometric modelling for computer vision, Stanford 
Artificial Intelligence Laboratory report STAN - CS-74-463, (1974). 2. Braid, I.C., Lang, C.A., Computer-aided 
design of mechanical components with volume building bricks, proc. PROLAMAT '73  (published as Computer 
Languages for Numerical Control by North Holland, Amsterdam), (1973).  3. Braid, I.C., Designing with 
volumes, Ph.D. Thesis, Cambridge University, England, (1974).  4. Braid, I.C., Six systems for shape 
design and representation -a review, proc. CAM-I Int. Seminar, Bournemouth, England, report P-75-~M-ol, 
pp. 60-67, (1975).  5. Braid, I.C., and Hillyard, R.C., Geometric modelling in ALGOL 68, ACM Sigplan 
Notices, vol. 12, no. 6, pp. 168-174, (1977).  6. Gnatz, R., Higher graphic languages. In: Nake, F. 
and Rosenfeld, A. (Eds.) Graphic Languages, North Holland, Amsterdam, pp 302-320, (1972).  7. Hagen 
T., et al, The intermediate language for pictures, Proc. IFIP '77, (pub. North-Holland), pp. 173-178, 
(1977).  8. Kleene, S.C., Introduction to Metamathematics, p 334, D. Van Nostrand Inc., New York, (1952). 
 9. Lindsey, C.H. et al, Informal Introduction to Algol 68 (revised) North-Holland, (1976).  i0. Okino, 
N. et al, TIPS-I : Technical information system for CAD, drawing and manufacture, proc. PROLAMAT '73 
(see above), (1973). ii. Voelcker, H.B. et al, An introduction to PADL, Report TM-22, Production Automation 
Project, University of Rochester, N.Y., (1974). 12. Williams, R. and Krammer, G., EX.GRAF: an extensible 
language including graphical operations, CGIP, vol.l, no.4, pp 317-340, (1972). 256 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807400</article_id>
		<sort_key>257</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>45</seq_no>
		<title><![CDATA[The PADL-1.0/2 system for defining and displaying solid objects]]></title>
		<page_from>257</page_from>
		<page_to>263</page_to>
		<doi_number>10.1145/800248.807400</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807400</url>
		<abstract>
			<par><![CDATA[<p>PADL (Part and Assembly Description Language) is a language for defining solid objects via constructive solid geometry, i.e. as (regularized) set-theoretical compositions of primitive solid &#8220;building blocks&#8221;. The current processor for Version 1.0 of the language accepts PADL statements either in batch or in keyboard-interactive mode and produces line drawings of objects on CRT's and plotting devices. A variety of drawing styles is available: dimensioned orthographics, perspectives, section views, interference drawings, etc.</p> <p>Novel characteristics of the PADL-1.0/2 system include 1) general combinational operators that may be applied to any part defined in PADL, 2) correct handling of &#8220;pathologies&#8221; that occur when (for example) two objects have partially coincident boundaries, 3) maintenance of consistent multiple representations of the same object, and 4) automatic posting on drawings of dimensions to reflect user-defined geometric relations between features of objects.</p> <p>This paper provides an overview of both the language and the current processor's capabilities and organization. Detailed discussions of the underlying mathematics, algorithms, and implementation are presented elsewhere.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[CAD/CAM]]></kw>
			<kw><![CDATA[Computational geometry]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Constructive solid geometry]]></kw>
			<kw><![CDATA[PADL]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>PADL-2</descriptor>
				<type>P</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Languages</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P330670</person_id>
				<author_profile_id><![CDATA[81332533732]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[H.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Voelcker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Production Automation Project, The University of Rochester, Rochester, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39082289</person_id>
				<author_profile_id><![CDATA[81100216726]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Requicha]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Production Automation Project, The University of Rochester, Rochester, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P330004</person_id>
				<author_profile_id><![CDATA[81100027762]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[E.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hartquist]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Production Automation Project, The University of Rochester, Rochester, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31047269</person_id>
				<author_profile_id><![CDATA[81100549963]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[W.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fisher]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Production Automation Project, The University of Rochester, Rochester, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P331041</person_id>
				<author_profile_id><![CDATA[81100460052]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Metzger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Production Automation Project, The University of Rochester, Rochester, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P333137</person_id>
				<author_profile_id><![CDATA[81332531917]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tilove]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Production Automation Project, The University of Rochester, Rochester, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P332558</person_id>
				<author_profile_id><![CDATA[81100124942]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[N.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Birrell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Production Automation Project, The University of Rochester, Rochester, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334265</person_id>
				<author_profile_id><![CDATA[81100258780]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[W.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hunt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Production Automation Project, The University of Rochester, Rochester, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P330322</person_id>
				<author_profile_id><![CDATA[81100466703]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>9</seq_no>
				<first_name><![CDATA[G.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Armstrong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Production Automation Project, The University of Rochester, Rochester, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P333909</person_id>
				<author_profile_id><![CDATA[81100303890]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>10</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Check]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Production Automation Project, The University of Rochester, Rochester, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P333082</person_id>
				<author_profile_id><![CDATA[81332516641]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>11</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Moote]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Production Automation Project, The University of Rochester, Rochester, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P331036</person_id>
				<author_profile_id><![CDATA[81100571795]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>12</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McSweeney]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Production Automation Project, The University of Rochester, Rochester, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. A. G. Requicha and H. B. Voelcker, "Constructive solid geometry", Tech. Memo. No. 25, Production Automation Project, Univ. of Rochester, November 1977.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[W. B. Fisher, A. A. G. Requicha, N. M. Samuel, and H. B. Voelcker, "Part and assembly description languages II: Definitional facilities in PADL-1.n and command facilities in the PADL-1.0/2 processor" Tech. Memo. No. 20b, Production Automation Project, Univ. of Rochester, 1978.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[W. B. Fisher, E. E. Hartquist, A. A. G. Requicha, and H. B. Voelcker, "The PADL-1.0/n processor: Overview &amp; system documentation", System Doc. No. 01, Production Automation Project, Univ. of Rochester, October 1977.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[H. B. Voelcker and A. A. G. Requicha, "Geometric modelling of mechanical parts and processes", COMPUTER, Vol. 10, No. 12, December 1977; also published as Tech. Memo. No. 23, Production Automation Project, Univ. of Rochester, October 1977.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[H. B. Voelcker and A. A. G. Requicha, "Boundary evaluation procedures for objects defined via constructive solid geometry", Tech. Memo. No. 26, Production Automation Project, Univ. of Rochester, 1978.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. A. G. Requicha and R. B. Tilove, "Mathematical foundations of constructive solid geometry: General topology of closed regular sets", Tech. Memo. No. 27, Production Automation Project, Univ. of Rochester, March 1978.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[A. A. G. Requicha, "Mathematical models of rigid solid objects", Tech. Memo. No. 28, Production Automation Project, Univ. of Rochester, November 1977.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. A. G. Requicha, "Representations of rigid solid objects", Tech. Memo. No. 29, Production Automation Project, Univ. of Rochester, 1978.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[R. B. Tilove, "A study of geometric set-membership classification", Tech. Memo. No. 30, Production Automation Project, Univ. of Rochester, November 1977.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA["Dimensioning &amp; Tolerancing", ANSI Standard Y14.5-1973, Amer. Soc. of Mech. Engineers, New York, 1973.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[H. B. Peirce and H. B. Voelcker, "Dissemination of the PADL-1.0/n processor", PADL Admin. Doc. No. 01, Production Automation Project, Univ. of Rochester, October 1977.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 THE PADL-I.O/2 SYSTEM FOR DEFINING AND DISPLAYING SOLID OBJECTS* H. Voelcker, A. Requicha, E. Hartquist, 
W. Fisher, J. Metzger, R. Tilove, N. Birrell, W. Hunt, G. Armstrong, T. Check, R. Moote, O. McSweeney 
 Production Automation Project The University of Rochester Rochester, New York ]2,627 ABSTRACT PADL 
(Part and Assembly Description Language) is a language for defining solid objects via con- structive 
solid geometry, i.e. as (regularized) set-theoretical compositions of primitive solid "building blocks". 
The current processor for Version 1.O of the language accepts PADL state- ments either in batch or in 
keyboard-interactive mode and produces line drawings of objects on CRT's and plotting devices. A variety 
of drawing styles is available: dimensioned orthographics, nerspectives, section views, interference 
draw- ings, etc. Novel characteristics of the PADL-I.O/2 system include i) general combinational operators 
that may be applied to any part defined in PADL, 2) correct handling of "pathologies" that occur when 
 (for example) two objects have partially coinci- dent boundaries, 3) maintenance of consistent multiple 
representations of the same object, and ~) automatic posting on drawings of dimensions to reflect user-defined 
geometric relations be- tween features of objects. This paper provides an overview of both the lan- 
guage and the current processor's capabilities and organization. Detailed discussions of the underlying 
mathematics, algorithms, and imple- mentation are presented elsewhere. KEY WORDS AND PHRASES: computer 
graphics, compu- tational geometry, constructive solid geometry, CAD/CAM, PADL. CR CATEGORIES: 3.26, 
8.2 INTRODUCTION PADL (Part and Assembly Description Language) is a language for defining and manipulating 
solid objects. It is primarily directed to~rds Me- chanical Engineering applications but may also be 
of interest in Architecture, Civil Engineering, Computer Vision and other fields where the geome- *The 
work described in this paper was sup- ported primarily by the National Science Founda- tion under grants 
GI-3&#38;27&#38;X and APR76-O103~. try of solids is important. The language is based on Constructive 
Solid Geome- try (CSG), a formal representation scheme in which complex solids may be defined as combinations 
of primitive solid "building blocks" via the regu- larized set operators. [I] (The regularized set operators 
are defined as the closure of the in- terior of their usual counterparts. Regularity plays a central 
role in the correct handling of operations on solids that have partially coinci- dent boundaries. ) 
This paper provides an overview of Version 1.0 of the PADL language (i.e. PADL-I.O), and of a PADL- 
1.O processor that produces drawings: see Fig. 1. Additional information on the language and proc- essor 
may be found in [2] and [3]. Applications of PADL in the context of design and manufacturing automation 
are discussed in [~], which also con- tains references to related work by others. Fi- nally, the underlying 
mathematics and the proces- sor's key algorithms are discussed in a suite of papers Ill, [5-9]. I STORED 
I DEF'NS OBJECT CRT DISPLAYS DEF'NS  DRAWINGS II COMMANDS (OTHER) INPUT MEDTUM PADL-I.¢ Figure 
i: The PADL-I.O/2 System OVERVIEW OF THE PADL-I.O LANGUAGE We shall open the discussion of the language 
with an example: the definition of the object shown in Fig. 2 via the PADL "program" shown in Fig. 3. 
(Statements preceded by semicolons are comments.) -~ LEN&#38;TH TOPLENGTH ~ M W ° I  ! I ! ! t I I 
i .~ I ~ L I I ] Figure 2: A Simple Object 002 ; OO&#38; ; FIRST DEFINE TWO BLOCKS TO FORM THE BASE 
006 ; AND TOP AND THEN UNION THEM. NOTE THAT O07 ; THE TWO BLOCKS INTERPENETRATE. (THE 008 ; ORIGIN IS 
THE DEFAULT LOCATION. ) 009 ; OlO &#38;BASE = SB(LENGTH, BASEHEIGHT, WIDTH) 020 LENGTH = 6 030 BASEHEIGHT 
= 1 O&#38;O WIDTH = 2 0~5 ; 050 &#38;TOP = $B(TOPLENGTH, HEIGHT, WIDTH) 060 TOPLENGTH = 2 070 HEIGHT 
= 2 O75 ; 1OO &#38;LSHAPE = &#38;BASE .UN. &#38;TOP 102 ; lO&#38; ; NOW DEFINE THE HOLE AS A SOLID, 
LOCATE IT 106 ; PROPERLY, AND DIFFERENCE IT FROM &#38;LSHAPE. 108 ; (NIL IS A NULL DISTANCE. ) 109 ; 
llO &#38;HOLE = $CY(DIAM, BASEHEIGHT) AT (LENGTH -' XLOC, NIL, ZLOC) 120 DIAM = 0.625 : PM(.OOS) 13o 
XLOC = 0.75 :. ~(.ool) iAO ZLOC = XLOC l&#38;2 ; 150 &#38;PART = &#38;LSHAPE . DIF. &#38;HOLE 152 ; 15&#38; 
; ASSIGN A DEFAULT TOLERANCE TO ALL DISTANCES 156 ; NOT EXPLICITLY TOLERANCED ABOVE 158 ; 160 $DEFTOL 
= PM(.OI) 162 ; 16&#38; ; NOW PRODUCE FIG. 2 VIA A DISPLAY COMMAND 168 ; 170 DISP(&#38;PART), 03R, 
DLAHEL: AUX(SECT(&#38;PART, SZ ,O .75 ) ) Figure 3: PADL Definition and a Display Command As the example 
indicates, PADL admits two kinds of statements: definitional statements in assign- ment format, and 
commands (Statement 170) in im- perative format. Statements lO, 50, and llO de- fine primitive solids. 
Numeric nominal values and tolerances are assigned to symbolic "dimensions" in Statements 20, 30, &#38;O, 
60, 70, 120, 130, and 140. Composite solids are defined via regularized set operations in Statements 
lO0 and 150. The following sections discuss the language "bot- tom-up" by first introducing the language's 
data types and operators, and then explaining how these are used to create definitional statements and 
comm~nds. Data Types Table I shows PADL's data types. An entity's type may be determined from its symbolic 
name by means of a prefix symbol. Names in PADL are not "vari- ables"; only one value may be associated 
to each name in a definition. The '~eaning" ("semantics") of data types other than d-chains (distance 
chains) should be evident. D-chains define locations; their semantics are discussed below. Table I Data 
Type Value Prefix number real # distance (non-negative real, (none) tolerance) distanceh sequence of 
chain directed distances tolerance (+real, -real) or (cannot be specification object Basic or Reference 
s olid , , named ) &#38; 258  Primitive Solids PADL-I.O offers two primitive solids: blocks and (three 
versions of) cylinders, whose axes must be parallel to the system's (X,Y,Z) master coordi- nate system. 
They are defined as follows. $B(<d-chain>,<d-chain>,<d-chain>) AT (<d-chain>,<d-chain>,<d-chain>) defines 
a block; the first three d-chains spec- ify the X, Y, Z "sizes" of the block while the AT arguments specify 
the location of a corner of the block. More orecisely, the AT <d-chain>'s specify the position of three 
planar faces of the block while the others define the position of the remaining three faces with respect 
to the first. X $CY(<distance ~<d-chain>) AT Z (<d-chain>,<d-chain>,<d-chain>) defines a cylinder; 
the "suffix" X, Y, Z specifies the direction of the cylinder's axis. The <dis- tance> is the diameter 
and the first <d-chain> is the length of the cylinder. The AT arguments locate the cylinder. The syntax 
above is a simplified version of the actual PADL syntax. Thus, e.g., PADL admits prim- itive arguments 
that syntactically are not <d- chain>'s but may be coerced into d-chain data types. Space precludes a 
discussion of the coer- cion rules [2] in this paper. Operators Four types of operators are available 
in PADL. I) Positional operators (rigid motions): MOV(<object>) BY (<d-chain>,<d-chain>,<d-chain>) 
 translates a solid by the specified <d-chain> arguments. (PADL-I.O does not contain a general rotational 
operator.) 2) Combinational operators on solids: the three regularized set-theoretical operators .UN., 
 .INT., .DIF., plus the assembly operator .ASB. which collects objects under a single name. Com- binational 
operators are written in infix form; assembly has precedence higher than the other three, which have 
their conventional set-theo- retical precedences. The regularized set oper- ators are general, and 
may be applied to prim- itives as well as to any parts defined in PADL. Assemblies may not be combined 
via the set oper- ators. 3) Arithmetic operators: the usual +, -, /, *, which operate on numbers (or 
other entities through type conversion). ~) Distance and d-chain operators: unary +' and -' and binary 
":". The unary operators assign a positive or negative direction to distances, which have positive "nominal" 
values per Table I. Di- rected distances are (simple) d-chains. More complex d-chains may be constructed 
by catenating simple (or complex) d-chains; syntactically, catenation is accomplished merely by writing 
the d-chains one after another (see LENGTH -' XLOC in Statement 110 of Fig. 3). The operator ":" con- 
structs a distance from a number and a tolerance specification; see Statement 130, which assigns a nominal 
value of 0.75 and a tolerance of plus or minus O.OO1 to the distance XLOC. Note that tol- erances are 
bound not to d-chains but to the indi- vidual distances which form d-chains, and thus the "uncertainty" 
or "tolerance zone" associated with a d-chain depends on the tolerances of its con- stituent distances. 
(In Mechanical Engineering this phenomenon is called "tolerance stacking".) Definitional Statements 
 There are two kinds of definitional statements: object definitional statements, and value assign- 
ment statements. Object definitional statements are of the form &#38;<name> = <oh j>  where <obj> 
is any expression that has a "solid" value. Statements 10, 50, lO0, llO, and 150 in Fig. 3 provide 
examples. Value assignment state- ments associate values with numbers, distances, and d-chains: see 
Statements 20, 30, ~O, 60, 70, 120, 130, and l%O. The order of definitional statements in PADL is 
immaterial; a name may be used (as in Fig. 3) before it has a value. The Semantics of D-chains Conventional 
(plus/minus) Mechanical Engineering dimension and tolerancing practices require that tolerances be 
associated with the "sizes" of ob- jects (e.g. the diameter of cylinder primitives) as well as with 
relative distances between object features. PADL's facilities for assigning toler- ances to its distance 
entities were discussed earlier. D-chains are the syntactical constructs used by the PADL-I°O language 
for representing relative positions. We shall explain the meaning of d- chains by means of a simple 
example: see Fig. 2. Observe that the hole in Fig. 2 is located rela- tive to the back and right surfaces 
of the L- shaped object. In the PADL-I.O system relativity of position is represented via "dimensional 
trees" whose nodes correspond to positional parameters of faces of the object and whose arcs are directed 
distances. Figure h shows the X-dimensional tree which corresponds to the object of Fig. 2. Each node 
of the dimensional tree has an associated d- chain constructed by traversing the tree from the origin 
to the node. Thus the X-location of the hole center in the example has the associated d- chain LENGTH 
-' XLOC. It is easy to see that by using appropriate d-chains as arguments of primi- tive solids and 
MOV operators one can define unique dimensional trees. Extensions origin (left-face) Desirable extensions 
of the PADL language may be  /~LENGTH categorized as follows. TOPLENGTH/ ~&#38; right-face right-face 
~_ of top 'XLOC --hole-center (X) Figure A: Dimensional Tree Commands Commands may appear anywhere 
in a PADL definition and are executed immediately if possible. PADL-I.O has three types of commands. 
 I) Utility commands, e.g. to SAVE andUSE files containing definitions. 2) Editing commands: editing 
is done in the style of BASIC, by replacing old statements with new statements having the same number. 
Note that simple edits may have far-reaching effects. For example if we make LENGTH = 3 in the definition 
 of Fig. 3 both the right face of the object and the hole move left by one unit. 3) Graphic commands: 
PADL's high-level graphic commands were designed to relieve users of the burden of specifying the multitude 
of parameters needed to ensure that displays fit on the screen, "look nice", etc. The basic syntax is 
 DISP(<graphic object>), <qualifiers> DRAW(<graphic object>), <qualifiers>. DISP indicates a CRT display 
and DRAW a hardcopy plotter output. Graphic objects may be named solids or two special constructs used 
to display sections and interfer- ence between parts in an assembly. PADL's section- ing capabilities 
are shown in Fig. 2; for an illus- tration of interference capabilities see [A]. Qualifiers may be strung 
together in any order; if they are omitted default values are used. Quali- fiers control the number and 
type of views (sin- gle- or three-view orthographics, perspectives, isometrics), the paper size, the 
magnification (zoom) factor, the posting of dimensions and tol- erances, the treatment of hidden lines, 
and so forth. The following two examples show the flavor of PADL commands. i) DISP(&#38;PART) displays 
a default wireframe per- spective on the CRT.  2) DRAW(&#38;PART), 03R, DLA~EL : AUX(SECT(&#38;PART, 
SZ, 0.75)) draws a three-view orthographic with right profile (03R) with dimensions labelled (DIABEL) 
nlus an auxiliary view, which is a default per- spective view of the object sectioned by a plane perpendicular 
to the z-axis and passing through the center of the hole. Figure 2 shows a hardcopy of a Tektronix AOlO 
display produced by the DISP ver- sion of this command. i) Nominal geometric coverage. A larger class 
of objects may be defined if one provides other prim- itive solids (cones, spheres, ...) and a rotation- 
al operator. 2) Modern ("geometric" or "true-position") di- mensioning and tolerancing facilities [iO]. 
PADL's modern D&#38;T facilities are tentatively spec- ified in [2] but have not been implemented yet. 
Essentially they amount to a scheme for ',na~dmg" object features and for assigning attributes to named 
features. These facilities will introduce additional data types: surfaces, edges, points, and datum systems. 
 3) User conveniences. The most important of these is probably the provision of "macro" fa- cilities 
to enable users to define objects with uninstantiated parameters: such parametric objects may be viewed 
as customized "primitives". Macros may be implemented in PADL by standard text-expan- sion techniques. 
Note that a PADL-defined para- metric object always corresponds to a valid solid regardless of the parameter 
values: the surface/ edge/vertex structures often used in Computer Graohics to represent solids do not 
possess this oroperty -- they may correspond to "nonsense solids" for certain parameter values. A processor 
for a version of the language with graphic input facilities (dubbed GPADL) is under development. One 
of the important requirements imposed on GPADL is that it be possible to trans- late, automatically and 
unambiguously, definitions cast in GPADL into PADL. OVERVIEW OF THE PADL-I.O/2 PROCESSOR F{gure 5 provides 
a high-level view of the current processor's organization. Rectangles denote rep- resentations (information 
structures), circles denote processes, and solid directed arcs indi- cate information flow. Users 
communicate with the system via PADL-lan- guage statements, which may be entered through any device that 
accepts strings, e.g. a terminal's keyboard or a card reader. The main module of the Input Processor 
is a table driven parser which converts PADL definitional statements into CSG representations [i]. The 
input processor has the follo~ing additional func- tions, i) It parses PADL commands, and sends DISPIAY/DRAW 
commands in parsed form to the Graph- ic Output Generator. 2) It stores input strings, and handles editing. 
3) It supplies appropriate information to the Definition Writer when section views or interference drawings 
are requested. The Definition Writer creates CSG representations for "sectioned" and "interference" 
objects. A sectioned object is obtained by intersecting the original object with a very large block, 
one of whose faces lies in the specified sectioning plane. Interference objects are the union of the 
pairwise regularized intersections of all of the parts in an assembly [3,&#38;].  260 &#38;P  1 
~ DISTANCES f I / I / t / I / i FTIEN~ ~ / ~ I D F'N R ~ I/I FILE I i PLOTTER &#38;BI = $B(,.,) oP, 
CRT ---USER ---' PADL-I,B/2 PROCESSOR "I Figure 5: PADL Processor CSG representations are essentially 
binary trees [1,3]. They are represented in the processor via postfix strings supplemented by tables 
of primi- tive solids, d-chains, and distances. An object's Boundary File ("Boundary Rep" in Fig. 
5) is a representation of the object's boundary (and hence of the object itself) in terms of its bounding 
"faces". PADL's Boundary Files are straightforward face/edge structures, with each edge linked to the 
two faces that "share" it. The union of the point sets which correspond to the bounding faces is the 
object's topological bound- ary: faces may (and often do) overlap. The Boundary Evaluator converts CSG 
representa- tions of objects into their corresponding Bound- ary Files. The boundary evaluation algorithms 
used in the processor are described in [5]; they are based on the notion of "membership classification" 
[9]. Briefly, each face of a primitive solid in an object's definition is "classified" to determine the 
subset of the face that is on the object's boundary (in the 3-D topology). A primitive face is classified 
by first generating a sufficient set of potential edges, and then classifying each edge to determine 
the subset of the edge lying on the boundary (in a surface topology) of a bounding face. The Dimension~ 
Tolerance, and Attribute (DTA) Processor constructs and tests dimensional trees from d-chain information. 
It consults Boundary Files to ensure that tree nodes correspond to faces physically present in the object 
(i.e. that no "phantom faces" are used as positional referen- ces). The Graphic Output Cenerator performs 
several dis- play-related functions: it allocates space for views in the drawing area, computes the projected 
views, and posts dimensioning and tolerancing in- formation on views. It also provides certain "em- bellishments" 
such as section-view hatching and back-surface elimination or "dashing". (Complete hidden-line capabilities 
are not provided.) The Graphic Output Processor creates certain lines not present in Boundary Files -- 
e.g. "profile" or "silhouette" lines for cylinders -- and ignores certain other lines in the Boundary 
Files --those which do not correspond to discontinuities in the gradient to the object's boundary. DISP 
commands elicit direct output to CRT displays, while DRAW commands output to Drawing Files which are 
subse- quently post-processed by plotter-specific pro- grams (not shown in Fig. 5). The Control Hierarch[ 
 Figure 6 shows the hierarchy through which the ap- plication of transformations is controlled. At the 
top is the system controller. ~en the sys- tem has been initialized by its Custodian, it al- ternates 
between "listening to the user" via the input sub-system and producing output via other sub-systems. 
These other sub-systems, each head- ed by a controller, correspond to the PADL sys- tem's major command 
capabilities. In the current system there is only one application controller (for graphics) because 
the only significant com- ~nds available are DISP and DRAW. Each major functional trm~sfor~tion shown 
in Fig. 5 appears as a process below the controller level, and each can be considered a controller of 
sub-processes. At the bottom of the hierarchy are several utili- ties and supporting systems.  SYSTEM 
 "" "" ~-v"" "\ FUTURE  (T ~ T'r~ .......... f ~pnNT'~ INPUT ( I GRAPHIC L IAPPLICATIONS / ~/ / ..... 
~ / ~ " ~ GRAPHIC ~AKDEF} IBEVAL} pTEVAL~ GOP }" OUTPUT ~ FORTRAN ~ DEVICE UT I L I T I ES L I BRARY 
HANDLERS Figure 6: The Control Hierarchy Implementation under the DEC RT-11 operating system into about 
160 Kbytes of overlayable executable code and 120 Portability was one of the primary criteria gov- Kbytes 
of data storage. The latter number is erning the implementation of the PADL processor. adjustable; 120 
Kbytes accomodate objects contain- Our imDlementational approach may be sunmm~ized ing not more than 
fifty primitive solids. as follows. Availability of the Processor  l) ANSI standard FORTRAN is the 
underlying imple- mentation language. We "enhanced" FORTRAN's con- The PADL~I.O/2.8 processor is available 
for a fee trol facilities by using a structured FORTRAN pre- from the Production Automation Project. 
Inter- processor -- FLECS, developed by T. Beyer at the ested organizations should order documents [3] 
University of Oregon -- and "augmented" the data and [11] which contain an overview of the system types 
available in FORTRAN by implementing (in and information on its dissemination. (The cost FLECS or in 
FORTRAN) several sub-routine packages: of the two documents is $4.00 total; please add STGPAK for strings, 
GPAK for vectors and transfor- $2.00 for overseas airmail. ) mations (L~c~ matrices), TPAK for trees, 
and BFILE for Boundary Files. The processor is being commissioned (by others) o~ a variety of machines: 
IBM 360/370, CDC 6600, 2) Computer, operating system, and CRT dependen- HP 3000, etc. The earlier PADL-I.O/I 
version cies are localized in small sets of low-level sub- (dated Autust, 1976) has been commissioned 
on a routines. A low-level package also manages large- PDP~II/70 at the University of Leeds. array storage, 
and plotter dependencies are segre- gated in post-processors. CONCLUDING RENJG~KS 3) The processor is 
modular; the subroutine call- The PADL system maintains several representations ing trees are broad but 
shallow to facilitate over- of solids: PADL strings, internal trees and ta- laying in small computers. 
bles, and boundary representations ( "b-files" ). It also maintains drawing files but these are rep- 
The PADL system was developed on a DEC PDP-11/~O resentations of drawings, rather than representa- computer 
with extended storage. The current PADL- tions of objects. We believe that the capability 1.0/2.8 version 
and its supporting packages con- of using multiple representations is a highly tain about 70,000 lines 
of source code, about ~5% desirable characteristic of geometric modeling of which are comments. The system 
translates systems, because no single representation appears to be "best" for all applications. B-files 
are well suited for the generation of line drawings, for supporting certain types of graphic interaction~ 
and so forth. CSG representations are more concise (by an order of magnitude) than b- files, are easy 
to store and transmit (as strings) over data links, and are convenient for the calcu- lation of certain 
non-graphic properties. We ex- pect them to play an increasingly important role in future extensions 
of PADL, which will be aimed (in part) at problems in manufacturing, design, and assembly automation 
[A]. The existence of multiple representations raises the important issue of representational consisten- 
cy, especially in the context of interactive edit- ing of definitions. In essence, one must guarantee 
that changes Fade to one representation are accu- rately reflected in the others. In the PADL system 
this problem is solved in a simplistic way: we only allow editing of PADL string definitions, and we 
propagate all changes "downward" through the system. We do not know of any general way of prop- agating 
changes "upward" from the b-file (or the drawing file) to the constructive definition. REFERENCES [1 
! A. A. G. Requicha and H. B. Voelcker, "Con- structive solid Eeometry", Tech. Memo. No. 25, Production 
Automation Project, Univ. of Rochester, November 1977. ~3 W. B. Fisher, A. A. G. Requicha, N. M. Samuel, 
and H. B. Voelcker, "Part and assembly description languages II: Definitional facilities in PADL-I.n 
and command facilities in the PADL-I.O/2 processor" Tech. Memo. No. 2Oh, Production Automation Pro- ject, 
Univ. of Rochester, 1978. [33 W. B. Fisher, E. E. Hartquist, A. A. G. Re- quicha, and H. B. Voelcker, 
"The PADL-I.O/n proc- essor: Overview &#38; system documentation", System Doc. No. 01, Production Automation 
Project, Univ. of Rochester, October 1977.  [&#38;3 H. B. Voelcker and A. A. G. Requicha, "Geo- metric 
modelling of mechanical parts and process- es", COMPUTER, Vol. iO, No. 12, December 1977; also published 
as Tech. Memo. No. 23, Production Automation Project, Univ. of Rochester, October 1977, [5] H. B. Voelcker 
and A. A. G. Requicha, "Bound- ary evaluation procedures for objects defined via constructive solid geometry", 
Tech. Memo. No. 26, Production Automation Project, Univ. of Rochester, 1978. [6] A. A. G. Requicha and 
R. B. Tilove, "Mathema- tical foundations of constructive solid geometry: General topology of closed 
regular sets", Tech. Memo. No. 27, Production Automation Project, Univ. of Rochester, March 1978. [73 
A. A. G. Requicha, "Mathematical models of rigid solid objects", Tech. Memo. No. 28, Pro- duction Automation 
Project, Univ. of Rochester, November 1977. [8J A.A.G. Requicha, "Representations of rig- id solid objects", 
Tech. Memo. No. 29, Production Automation Project, Univ. of Rochester, 1978. [gJ R.B. Tilove, "A study 
of geometric set- membership classification", Tech. Memo. No. 30, Production Automation Project, Univ. 
of Roches- ter, November 1977. [i0] "Dimensioning &#38; Tolerancing", ANSI Standard Y14.5-1973, Amer. 
Soc. of Mech. Engineers, New York, 1973. [113 H. B. Peirce and H. B. Voelcker, "Dissemi- nation of the 
PADL-I.O/n processor", PADLAdmin. Doc. No. O1, Production Automation Project, Univ. of Rochester, October 
1977.  263  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807401</article_id>
		<sort_key>264</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>46</seq_no>
		<title><![CDATA[A unified approach to geometric modelling]]></title>
		<page_from>264</page_from>
		<page_to>269</page_to>
		<doi_number>10.1145/800248.807401</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807401</url>
		<abstract>
			<par><![CDATA[<p>Whereas, historically, much of the effort on computer-aided geometric design has concentrated on the problems of representing so-called sculptured surfaces, there has recently been much interest in systems which can handle typical mechanical components by a volume modelling approach. The paper is concerned with the possibility of combining the two approaches and discusses the issues raised. A solution in terms of applying smoothing operators to a geometric coarse structure is proposed, with the added benefits of detecting and successfully handling anomalous regions in surfaces and leading to potential benefits in the analysis of geometric properties.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[B-spline surfaces]]></kw>
			<kw><![CDATA[Computational geometry]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Computer-aided design]]></kw>
			<kw><![CDATA[Recursive smoothing]]></kw>
			<kw><![CDATA[Sculptured surfaces]]></kw>
			<kw><![CDATA[Volume modelling]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Hidden line/surface removal</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP48025401</person_id>
				<author_profile_id><![CDATA[81100609818]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Forrest]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of East Anglia, Norwich, England]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>578776</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Barnhill, R.E. &amp; Riesenfeld, R.F. (Eds.) Computer Aided Geometric Design. Academic Press, New York, 1974.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Baumgart, B.G. Geometric modelling for computer vision. AIM-249, STAN-CS-74-463, Stanford University, October 1974.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[B&#233;zier, P.E. Mathematical and practical possibilities of UNISURF. In (1) above.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360727</ref_obj_id>
				<ref_obj_pid>360715</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Braid, I.C. The synthesis of solids bounded by many faces. Comm. ACM 18, 4 (Apr. 1975), 209-216.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Braid, I.C. Six systems for shape design and representation - a review. Cambridge University CAD Group, CAD Group Doc. 87, May 1975.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Braid, I.C. A new shape design system. Cambridge University CAD Group, CAD Group Doc. 89, March 1976.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807399</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Braid, I.C. On storing and changing shape information. These proceedings.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Catmull, E. &amp; Clark, J. Recursively generated B-spline surfaces on arbitrary topologicical meshes. To appear.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Chaikin, G.M. An algorithm for high-speed curve generation. Computer Graphics and Image Processing 3 (1974), 346-349.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>889976</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Coons, S.A. Surfaces for computer-aided design of space forms. Project MAC TR-41, M.I.T., June 1967.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Doo, D. A method of smoothing highly irregular polyhedrons. Interactive Techniques in Computer Aided Design Conference, Bologna, Spetember 1978.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Doo, D. Ph.D. dissertation, Brunel University, to appear.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Forrest, A.R. Curves and surfaces for computer-aided design. Ph.D. dissertation, Cambridge University, July 1968.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Forrest, A.R. Coons surfaces and multivariable functional interpolation. Cambridge University CAD Group, CAD Group Doc., Dec. 1971.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Forrest, A.R. The definition of surfaces. Ingenieurs de 1'Automobile 44, l0 (Oct. 1971) 521-527.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Forrest, A.R. On Coons and other methods for the representation of curved surfaces. Computer Graphics and Image Processing 1, (1972)]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Forrest, A.R. Computational geometry - achievements and problems. In (1) above.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Forrest, A.R. Notes on Chaikin's algorithm. University of East Anglia Computational Geometry Project CGP 74/1, (Dec. 1974).]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Forrest, A.R. Multivariate approximation problems in computational geometry. In Multivariate Approximation, D.C. Handscomb (Ed.), Academic Press, London, 1978.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Loeb, A.L. Space Structures. Addison-Wesley, Reading, Mass. 1976.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>906872</ref_obj_id>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Riesenfeld, R.F. Applications of B-spline approximation to geometric problems of computer-aided design. Ph.D. dissertation, Syracuse University, 1973.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Riesenfeld, R.P. On Chaikin's algorithm. Computer Graphics and Image Processing 4, (1975), 304-310.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Sabin, M.A. Numerical Master Geometry. British Aircraft Corporation, Weybridge (BAC) VTO/MS/146, (Aug. 1968).]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Sabin, M.A. Parametric surface equations for non-rectangular regions. BAC VTO/MS/147, (Oct. 1968).]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Sabin, M.A. Trinomial basis functions for interpolation in triangular regions (B&#233;zier triangles). BAC VTO/MS/188, (July 1971).]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Sabin, M.A. B-spline interpolation over regular triangular lattices. BAC VTO/MS/195, (Oct. 1972).]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Sabin, M.A. A triangular element giving slope continuity over all boundaries using piecewise cubic interior. BAC VTO/MS/198, (July 1973).]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Sabin, M.A. Two slope-continuous triangular elements constructed from low order polynomial pieces. BAC VTO/MS/199, (July 1973).]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Sabin, M.A. A B&#233;zier-like surface definition controlled by points joined in an arbitrary network. Kongsberg U.K. Ltd., (Sept. 1976).]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Sabin, M.A. The use of piecewise forms for the numerical representation of shape. Ph.D. dissertation, Computer and Automation Institute, Hungarian Academy of Sciences, 1977.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Sabin, M.A. Various private communications, 1976-1978.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_obj_id>908431</ref_obj_id>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Shamos, M.I. Computational geometry. Ph.D. dissertation, Yale University, (May 1978).]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I.E., Sproull, R.F. &amp; Schumaker, R.A. A characterization of ten hidden-surface algorithms. ACM Computing Surveys 6, 1 (1974) 1-56.]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563896</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Weiler, K. &amp; Atherton, P. Hidden surface removal using polygon area sorting. ACM SIGGRAPH Computer Graphics 11, 2 (Summer 1977).]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A Unified Approach to Geometric Modelling* A.R. Forrest University of East Anglia Norwich, England 
 Abstract: Whereas, historically, much of the effort on computer-aided geometric design has concentrated 
on the problems of representing so- called sculptured surfaces, there has recently been much interest 
in systems which can handle typical mechanical components by a volume modelling approach. The paper is 
concerned with the possibility of combining the two approaches and discusses the issues raised. A solution 
in terms of applying smoothing operators to a geometric coarse structure is proposed, with the added 
benefits of detecting and successfully handling anomalous regions in surfaces and leading to potential 
benefits in the analysis of geometric properties. Key Words and Phrases: computational geometry, computer-aided 
design, computer graphics, sculptured surfaces, recursive smoothing, B-spline surfaces, volume modelling. 
CR Categories: 4.34, 5.13, 8.2 I. Introduction In an earlier paper (17) the author suggested that a 
convenient way of class- ifying computer-aided geometric design systems was in terms of the complexity 
of the objects which the system could model. We may consider, for the sake of this paper, the complexity 
measure to have three components: embedding complexity, geometric complexity, and combinatorial complexity. 
Embedd- ing complexity is readily understood: it refers to the dimension of the euclidean space in which 
the modelled objects are embedded. Clearly two-dimen- sional objects are in some sense simpler to handle 
than fully three-dimensional objects such as car bodies or turbine blades. This has long been recognised 
in the context of computer graphics where it appears that there is an order of magni- tude increase in 
complexity between 2D and 3D. It is also apparent in the more recent work in computational geometry (32). 
 Component complexity refers to the geometry of a component. In practice we almost always have to treat 
objects as assemblies of components. * This work has been supported in part by the Science Research 
Council Grant B/RG/95834 Investigations in Computational Geometry. Author's address: University of East 
Anglia, School of Computing Studies, University Village, Norwich NR4 7TJ, England. Intuitively, a component 
described in terms of straight line edges or planar faces is geometric- ally simpler than one defined 
in terms of rational cubic curves or B-spline surfaces. A crude but convenient measure of this complexity 
might be the number of arithmetic operations required to evaluate a point on the component. Combinatorial 
complexity refers to the number of components in an assembly. If, as seems probable, many of the geometric 
operations we might wish to perform are O(n ~) in terms of the number of components involved (32), then 
combin- atorially complex objects will give rise to significant problems. Ignoring embedding complexity, 
if we look at the corpus of knowledge in geometric modelling we find a wealth of literature (1,3,10,]3,14,16,|9, 
21,23,30) concerned with the modelling of relativ- ely simple assemblies of geometrically complex components. 
That is to say, the field of sculp- tured surface modelling has been well explored and there are many 
practical systems in everyday use. Problems remain, as we shall see, but there is condiderable experience 
especially in the aero- space and automotive industries in the use of such techniques. Until recently, 
relatively little effort has been devoted to handling complex combinations of simple geometries. There 
are now several experimental systems based on what is usually termed the volume modelling approach (2,4, 
5,6,7). By and large, these systems model an object in terms of various combinations of simple volume 
primitives; but the geometry of the comp- onent volumes is generally restricted to simple planar or cylindrical 
faces, and more recently faces which are quadric surfaces (7). This paper addresses the problems associated 
with modelling complex assemblies of complex components. We can look at the goal as either the ability 
to handle complex assemblies of, say, sculptured surfaces, or the extension of the geometric types permitted 
in volume modelling systems. 2. Current Practice and Problems Most early sculptured surface systems 
permitted the user to construct surfaces as assemblies of surface patches. Mathematical considerations 
d-~ctate that the patches are almost always four-sided and that the assemblies are notionally regular 
rectangular arrays or subsets (sometimes sparse) of such arrays, Fig. I. In general, at most four patches 
 264 Patch arrays Figure ! meet at each vertex. Given such restrictions, a wide variety of sculptured 
surface elements is available (I,14,]6,21). Whereas much emphasis was placed on assembling patches and 
ensuring correct continuity, on a patch-by-patch basis, one of the advantages of more recent techniques 
such as B-splines is that potentially the user need not know about surfaces on a patch level but can 
manipulate arrays of patches as a single unit. In summary, then, most sculptured surface systems allow 
patches to be connected or associated in relatively simple structures. Such structures are surface structures 
and a=e not normally tied to a volumetric model of the desired object, thus refl- ecting the early interest 
in modelling car and aircraft exterior skins. One of the first practical surface design exercises tackled 
by the author was a portion of a telephone handset for Western Electric (]5). It soon became apparent 
that a regular or semi-reg- ular array of four-sided surface patches could not be used unless some local 
distortion and lack of smoothness was acceptable. In fact, the best solution appeared to be the embedding 
of a triang- ular surface patch in an otherwise rectangular assembly, Fig. 2. Other users have had a 
similar Portion of telephone handset Wing-fuselage blend Figure 2 experience: Sabin (24) observed the 
need for three and five-sided regions in aircraft, for example at the wing-fuselage blend, Fig. 2; and 
B4zier mentions similar problems with car bodies at Renault (3). The author has made a point of questioning 
users of practical systems as to whether anomalous re~ions as we shall call them arise: in most users" 
experience they do, and the solutions adopted range from remedies of a one-off nature to avoidance -"we 
just ensure that we don't machine in those areas" (anon) f Curiously, and encouragingly, difficulties 
are encountered in the same regions when employing manual methods. The solutions adopted by both Sabin 
(24-29) and B4zier (3) are highly specific to bicubic patches or B4zier-Bernstein patches respectively: 
indeed a general solution to the problem of anomalous regions, compatible with surrounding regions, appears 
to be impossible in analytic terms. Current research by Sabin and Doo (]1,12,31) in England, and Catmull 
and Clark (8) in the United States promises to yield more general solutions of an al$orithmic nature. 
The approach we shall outline later is to acknowledge that anomalous regions will occur, to recognise 
a priori where they will arise (19), and to handle the anomalies in a local but compatible manner. Since 
the anomalous regions tend to occur, as we shall see, where arrays of patches are joined (c.f. the wing- 
fuselage blend of Fig. 2), they are more likely to be present in complex assemblies of complex comp- 
onents than in the relatively simple assemblies hitherto employed in most surface systems. We have mentioned 
that the structures employed in sculptured surface systems are simple - one might almost say weak. 
In contrast, volume modelling systems tend to be rich in structure, whether explicit, as in BUILD (4,6,7), 
or implicit as in PADL and other systems (5). The core of a volume modelling system is generally the 
module which evaluates the intersection or union of two component volumes. A rich structure, containing 
information relating adjacent faces, edges and vertices, and explicitly relating the attributes of an 
enclosed volume is a fruitful source of the heuristics and rules which simplify the construct- tion of 
legal objects and the evaluation of inter- sections. This is important, both at the design stage and 
for the subsequent analysis or interr- ogation (e.g. sectioning) where geometric adjac- ency information 
is invaluable. Shamos (32) and Sutherland et al. (33) have demonstrated the importance of ordering in 
constructing efficient geometric algorithms. The hidden surface algor- ithms of Baumgart (2) and Weiler 
and Atherton (34) illustrate the gains to be made through exploiting the geometric coherence information 
which a struc- tured model contains. Since intersection calculation is crucial, it is essential that 
such computation should be efficiently and correctly performed. Whilst this is conceptually simple for 
simple geometries such as polygons and polyhedra, particularly if convex- ity is imposed (32), it becomes 
progressively more difflcult as the geometric complexity incr- eases. It should be noted, for example, 
that most surface-surface intersection algorithms currently in use cannot guarantee to find all possible 
intersections. 265 Summarising, current practice in sculptured surface modelling is to permit regular 
rectang- ular arrays of four-sided surface patches with few concessions to anomalous regions. The geometric 
structures used are simple and are surface rather than volume related. Volume modelling, on the other 
hand, lacks the ability currently to handle complex geometries but has highlighted the problem of efficient 
and correct geometric computation. We seek to develop a geometric modelling system which overcomes these 
difficulties and at the same time extends the capabilities both for sculptured surface design and volumetric 
modelling. 3. Coarse Structure Observation of where anomalous regions arise in practice has led the 
author to the conclusion that the occurrence of such regions can be predicted with considerable reliability 
by regarding curved objects as smoothed-off versions of simpler polyhedral or pseudo-polyhedral structures. 
We say that the simpler polyhedral structure is the coarse struct- ure of our smooth object. For example, 
the coarse structure of the two surfaces in Fig. 2 is shown in Fig. 3. We can imagine a model maker const- 
ructing a model from blocks of wood by a process J j I "-- ~ -~ ~j .I 7 ~--~-'~ Coarse structures 
 Figure 3 of smoothing convex edges with files and sandpaper and filling-in concave edges with 'plastic 
wood' to achieve the desired effect. The anomalous regions of Fig. 2 are now seen to be directly related 
to the number of edges meeting at the corresponding vertices of the coarse structure of Fig. 3 where 
smoothing is indicated by dotted lines. More generally, if we take a polyhedral structure and smooth 
it, we find that edges become strips which can readily be desc-'r-~Ibed by regular arrays of 4-sided 
patches. Vertices become regions requiring at least one nXsided patch or one point where n patches meet, 
n being the number of edges meeting at the vertex, or the valency of that vertex (20). Most anomalous 
regions found in practice arise from n-valent vertices. Faces, when smoothed, become arrays of surface 
patches. These patches will largely be 4-sided, but if the face has n edges (i.e. the face is n-valent) 
then once again an n-sided patch or n patches meeting at a point must be included. Fig. 4 shows how 3 
and 5 sided faces might be tesselated into largely 4-sided patches. This Face anomalies Figure 4 type 
of anomaly, the face anomaly, is less common in practice than the vertex anomaly and the anomalous region 
is commonly forced to occur at a vertex, giving rise to some awkward patch distrib- utions, Fig. 5a. 
We are advocating here a solution, Fig. 5b, which is not biased towards any (a) Biased solution (b) 
Unbiased solution Figure 5 particular vertex, so that gradations in patch size across all boundaries 
can be uniform rather than disjoint. (The coarse structure of aircraft, cars, etc. appears to consist 
of assemblies of rectangular parallelepipeds with edges running fore and aft, up and down, left and right; 
thus although we expect anomalous regions at 'corners', we have mainly 4-sided faces and hence few face 
anomalies.) We can thus relate our complex three-dimen- sional curved objects to underlying and geometric- 
ally simpler structures. Such structures might be polyhedra, or more generally pseudo-polyhedra where 
we relax the planarity conditions for the edges bounding a face. In fact, the crucial property we require 
is that the coarse structure should relate the faces, edges and vertices of a volume in a consistent 
manner. Such a consistent structure is the basis for volume modelling systems such as BUILD (7) and was 
suggested first by Baumgart (2). 266 There are several advantages in employing a able to locate them. 
Fortunately, a rather better coarse structure. Firstly, the structure, as we have mentioned, is the 
same as the structure used in some volume modelling systems. We have thus achieved some measure of unification. 
Secondly, we have found a method of detecting anomalous regions directly a priori. Thirdly, it should 
be possible rapidly to block out a design; in many cases an automatic smoothing of the coarse struct- 
ure will generate an acceptable shape without recourse to further design -it is an unfortunate feature 
of many sculptured surface systems that the user is expected to supply rather too much data and spends 
a lot of his time smoothing out his unintentional bumps. Fourthly, the coarse struct- ure provides a 
basis for geometric analysis and is a fruitful source of heuristics for such purposes. For example, we 
might be able to eliminate the possibility of many intersections between objects by testing simpler geometries 
based on the same coarse structure (e.g. straight line edges, planar faces, convex hulls, etc.). Clearly 
it is better to test line segments for intersection than to test for the intersections of cubic curves. 
Only if an intersection cannot be ruled out by a simple test should it be necessary to analyse the complex 
geometry associated with the coarse structure. In short, we are looking for heuristics based on the 
coarse structure which will provide practical rather than theoretical upper bounds on the numbers of 
intersections possible between two objects. 4. Smoothin$ the Coarse Structure Assuming that the strategy 
will be to construct a coarse structure and then smooth it, how then are we to perform the smoothing? 
The obvious choice is to use the mathematics of B~zier (],3) or the gener- alisation, B-splines (1,2]). 
If we look at curves first, then both these methods in effect generate curves by smoothing polygons, 
being variation diminishing methods. We could regard the polygons as the coarse structures of the curves. 
Similarly with surfaces, B-spline mathematics generates surfaces from meshes of polygons -regular rect- 
angular polygonal meshes we might term them. The behaviour of the resultant curves and surfaces can be 
predicted directly from the polygons and indeed the polygons constitute a simpler geometry on which to 
base geometric heuristics (]9) as ment- ioned in the previous section. Suppose we use such techniques 
to smooth the coarse structure. If we can construct polygonal meshes which are associated with faces 
of the coarse structure and polygons which are associated with the edges of the coarse structure~ then 
B-spllne mathematics will smooth the faces and edges. However, such mathematics cannot cope automatically 
with the anomalous regions whether at vertices or interior to faces. What we require is a method for 
hand- ling anomalous regions which will be compatible with B-splines. Note at this stage we do not envisage 
smoothing the coarse structure directly, although this would be possible; rather we proceed by tesselating 
the coarse structure to create polygonal meshes and then smooth the meshes. The inability of the B-spline 
method to cope with anomalous regions might have forced the use of implementation tricks to handle these 
regions, but at least the coarse structure would have been solution is emerging. Chaikin, in ]974, 
suggested a novel approach to curve generation which was algorithmic (9). He also expressed some difficulties 
in adapting his algorithm to generate space curves. The algorithm was rapidly analysed by Riesenfeld 
(22), Catmull (private cormnunication), and the author (18), and it was proved that the Chaikin curves 
were in fact quadratic B-splines -piecewise parabolae - explaining their planar nature. The significant 
point -that Chaikin's method was constructive, algorithmic, rather than analytic - was noted by Catmull 
and Sabin. Independently they have exten- ded the Chaikin approach to polygonal meshes, which need not 
be regular. Algorithms now exist which will generate quadratic B-spline surfaces where the polygonal 
mesh is regular and 4-valent, and compatible surface patches at the anomalous areas, giving overall slope 
continuity. Some constructions exist which yield cubic B-spline surfaces with curvature continuity for 
regular regions, with compatible anomalous regions, but the analysis is less complete and curvature cont- 
inuity in the anomalous regions is still uncer- tain. The anomalous patches themselves have no analytic 
or closed form and must be generated by algorithm. The subject is currently the scene of considerable 
activity with several papers and a thesis to appear (8,]1,]2,3]). Given such algorithms, and knowing 
that they generate B-spline surfaces in regular re ions, we can use the well-tried B-spline methods and 
their analytic forms in all but the anomalous regions where the algorithmic method must he employed. 
In Fig. 6 the smoothing achieved by a somewhat cruder algorithm starting from a simple block structure 
is indicated. .l Algorithmic smoothing Figure 6 5. Issues of Implementation Despite what has been 
said earlier, the prosoect of providing a fast, accurate surface-surface intersection module in full 
generality is daunting. It is probable that such a module will always be requi- red by some user, but 
he will have to pay a price. However, we hope to encourage the user to get his topology and coarse structure 
correct first in the hope that no re-design of either will be necessary after smoothing has taken place. 
It seems point- less, for example, for a designer to ask for a 267 a general surface-surface intersection 
and then to smooth the intersection curve in a fairly arbit- rary manner - better far to create the coarse 
structure and then smooth. The designer then controls both the intersection and its smoothing. The utility 
of geometric heuristics based on B-spline mathematics and coarse structure remains to be tested in practice. 
It is clear, however, that some gains must be sought from this source since the general intersection 
problem suffers doubly from component complexity and combinatorial complexity. Practical design problems 
will involve of the order of fifty or more components. Computational geometry in three dimensions is 
a major exercise. At the University of East Anglia the Comput- ational Geometry Project runs Braid's 
BUILD system (6) on a PRIME 300 minicomputer and is actively engaged in developing design systems which 
use BUILD for the coarse structure. Since BUILD is written in Algol68, the data structure facilities 
are extremely powerful and the basic structure of BUILD allows for the introduction of more sophis- ticated 
geometries than the straight lines- planes -polyhedrons of the original implementation. 6. Conclusions 
We have discussed the problems of developing computer-aided geometric design systems which can handle 
complex assemblies of complex components. By adapting the approach of smoothing a coarse structure the 
problem of anom- alous regions is reduced and a sytem unifying sculptured surfaces and volume modelling 
seems possible.  7. Acknowledgements The author wishes to thank Malcolm Sabin, Daniel Doo, Rich Riesenfeld, 
Ed Catmull, lan Braid, Alan MacRae and Terry Palmer for their help in formulating the ideas behind this 
paper. The generosity of Braid in allowing the Computational Geometry Project to use BUILD as a basis 
of its various implementations is greatly appreciated.  8. References  (I) Barnhill, R.E. &#38; Riesenfeld, 
R.F. (Eds.) Cgm~uter Aided Geometric Design. Academic Press, New York, 1974.  (2) Baumgart, B.G. Geometric 
modelling for computer vision. AIM-249, STAN-CS-74-463, Stanford University, October 1974.  (3) B~zier, 
P.E. Mathematical and practical possibilities of UNISURF. In (1) above.  (4) Braid, I.C. The synthesis 
of solids bounded  by many faces. Coven. ACM 18, 4 (Apr. 1975), 209-216.  (5) Braid, I.C. Six systems 
for shape design and representation -a review. Cambridge Univ- ersity CAD Group, CAD Group Doe. 87, May 
1975.  (6) Braid, I.C. A new shape design system. Cambridge University CAD Group, CAD Group Doc. 89, 
March ]976.  (7) Braid, I.C. On storing and changing shape information. These proceedings.  (8) Catmull, 
E. &#38; Clark, J. Recursively gener- ated B-spline surfaces on arbitrary topologic ical meshes. To appear. 
 (9) Chaikin, G.M. An algorithm for high-speed curve generation. Computer Graphics and  Image Processing 
3 (1974), 346-349. (I0) Coons, S.A. Surfaces for computer-aided design of space forms. Project MAC TR-41, 
M.I.T., June 1967. (ll) Doo, D. A method of smoothing highly irreg- ular poyhedrons. Interactive Techniques 
in Computer Aided Design Conference, Bologna, Spetember 1978. (12) Doo, D. Ph.D. dissertation, Brunel 
Univer- sity, to appear.  (13) Forrest, A.R. Curves and surfaces for computer-aided design. Ph.D. dissertation, 
Cambridge University, July 1968.  (14) Forrest, A.R. Coons surfaces and multivari- able functional interpolation. 
Cambridge University CAD Group, CAD Group Doc., Dec. 1971.  (15) Forrest, A.R. The definition of surfaces. 
Ingenieurs de l'Automobile 44, lO (Oct. 1971) 521-527.  (16) Forrest, A.R. On Coons and other methods 
for the representation of curved surfaces. Computer Graphics and Image Processing l, (1972)  (17) Forrest, 
A.R. Computational geometry - achievements and problems. In (1) above.  (18) Porrest, A.R. Notes on 
Chaikin's algorithm. University of East Anglia Computational Geometry Project CGP 74/I, (Dec. 1974). 
 (19) Forrest, A.R. Multivariate approximation problems in computational geometry. In Multivariate Approximation, 
D.C. Handscomb (Ed.), Academic Press, London, 1978.  (20) Loeb, A.L. Space Structures. Addison- Wesley, 
Reading, Mass. 1976.  (21) Riesenfeld, R.F. Applications of B-spline approximation to geometric problems 
of computer-aided design. Ph.D. dissertation, Syracuse University, 1973.  (22) Riesenfeld, R.P. On Chaikin's 
algorithm. Computer Graphics and Image Processing 4, (1975), 304-310.  (23) Sabin, M.A. Numerical Master 
Geometry. British Aircraft Corporation, Weybridge (BAC) VTO/MS/146, (Aug. 1968).  (24) Sabin, M.A. Parametric 
surface equations for  non-rectangular regions. BAC VTO/MS/147, (Oct. 1968).  (25) Sabin, M.A. Trinomial 
basis functions for interpolation in triangular regions (B~zier triangles). BAC VTO/MS/188, (July 1971). 
 (26) Sabin, M.A. B-spline interpolation over regular triangular lattices. BAC VTO/MS/195, (Oct. 1972). 
 (27) Sabin, M.A. A triangular element giving slope continuity over all boundaries using piecewise cubic 
interior. BAC VTO/MS/198, (July 1973).  (28) Sabin, M.A. Two slope-continuous triangular elements constructed 
from low order poly- nomial pieces. BAC VTO/MS/199, (July 1973).  (29) Sabin, M.A. A B4zier-like surface 
definition controlled by points joined in an arbitrary network. Kongsberg U.K. Ltd., (Sept. 1976).  
(30) Sabin, M.A. The use of piecewise forms for the numerical representation of shape. Ph.D. dissertation, 
Computer and Automation Instit- ute, Hungarian Academy of Sciences, 1977.  (31) Sabin, M.A. Various 
private communications,  1976-1978. (32) Shamos, M.I. Computational geometry. Ph.D. 268 dissertation, 
Yale University, (May 1978). (33) Sutherland, I.E., Sproull, R.F. &#38; Schumaker, R.A. A characterization 
of ten hidden-surface algorithms. ACM Computing Surveys 6, I (1974) 1-56. (34) Weiler, K. &#38; Atherton, 
P. Hidden surface removal using polygon area sorting. ACM SIGGRAPH Computer Graphics 11, 2 (Summer ]977). 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807402</article_id>
		<sort_key>270</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>47</seq_no>
		<title><![CDATA[Casting curved shadows on curved surfaces]]></title>
		<page_from>270</page_from>
		<page_to>274</page_to>
		<doi_number>10.1145/800248.807402</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807402</url>
		<abstract>
			<par><![CDATA[<p>Shadowing has historically been used to increase the intelligibility of scenes in electron microscopy and aerial survey. Various methods have been published for the determination of shadows in computer synthesized scenes. The display of shadows may make the shape and relative position of objects in such scenes more comprehensible; it is a technique lending vividness and realism to computer animation.</p> <p>To date, algorithms for the determination of shadows have been restricted to scenes constructed of planar polygons. A simple algorithm is described which utilizes Z-buffer visible surface computation to display shadows cast by objects modelled of smooth surface patches. The method can be applied to all environments, in fact, for which visible surfaces can be computed. The cost of determining the shadows associated with each light source is roughly twice the cost of rendering the scene without shadows, plus a fixed transformation overhead which depends on the image resolution. No extra entities are added to the scene description in the shadowing process. This comprehensive algorithm, which permits curved shadows to be cast on curved surfaces, is contrasted with a less costly method for casting the shadows of the environment on a single ground plane.</p> <p>In order to attain good results, the discrete nature of the visible-surface computations must be treated with care. The effects of dither, interpolation, and geometric quantization at different stages of the shadowing algorithm are examined. The special problems posed by self-shadowing surfaces are described.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer animation]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Hidden surface algorithms]]></kw>
			<kw><![CDATA[Shadows]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31101708</person_id>
				<author_profile_id><![CDATA[81100005753]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lance]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Williams]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Lab, New York Institute of Technology, Old Westbury, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>907242</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Catmull, E., "A Subdivision Algorithm for Computer Display of Curved Surfaces," PhD. thesis, Dept. of Computer Science, University of Utah, 1974.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>569954</ref_obj_id>
				<ref_obj_pid>800193</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Newell, M. G., Newell, R. G., and Sancha, T. L., "A Solution to the Hidden Surface Problem," Proceedings of the 1972 ACM National Conference.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Williams, L., forthcoming PhD. thesis, University of Utah.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[For the application of this representation to scene analysis, see: Levine, M. D., O'Handley, D. A., and Yagi, G. M., "Computer Determination of Depth Maps," Computer Graphics and Image Processing, No. 2, 1973.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563901</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Crow, F. C., "Shadow Algorithms for Computer Graphics," Siggraph 1977 Proceedings, Vol. 11, No. 2, Summer 1977.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F., "A Scan-Line Algorithm for the Display of Bicubic Surface Patches," PhD. thesis, Dept. of Computer Science, university of Utah, 1978.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>907952</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Crow, F. C., "The Aliasing Problem in Computer-Synthesized Shaded Images," PhD. thesis, Dept. of Computer Science, University of Utah, 1976.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356627</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Freeman, H., "Computer Processing of Line Drawing Images," ACM Computing Surveys, Vol. 6, No. 1, March 1974.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F., "Models of Light Reflection for Computer Synthesized Pictures," Siggraph 1977 Proceedings, Vol. 11, No. 2, Summer 1977.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I.E., "A Head-Mounted Three-Dimensional Display," Fall Joint Computer Conference 1968, Thompson Books, Washington, D.C., 757.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 CASTING CURVED SHADOWS ON CURVED SURFACES Lance Williams Computer Graphics Lab New York Institute of 
Technology Old Westbury, New York 11568 Abstract Shadowing has historically been used to increase the 
intelligibility of scenes in electron micros- copy and aerial survey. Various methods have been published 
for the determination of shadows in com- puter synthesized scenes. The display of shadows may make the 
shape and relative position of objects in such scenes more comprehensible; it is a tech- nique lending 
vividness and realism to computer an- imation. To date, algorithms for the determination of sha- dows 
have been restricted to scenes constructed of planar polygons. A simple algorithm is described which 
utilizes Z-buffer visible surface computation to display shadows cast by objects modelled of smooth surface 
patches. The method can be applied to all enviror~nents, in fact, for which visible surfaces can be computed. 
The cost of determining the shadows associated with each light source is roughly twice the cost of rendering 
the scene without shadows, plus a fixed transformation over- head which depends on the image resolution. 
No ex- tra entities are added to the scene description in the shadowing process. This comprehensive algo- 
rithm, which permits curved shadows to be cast on curved surfaces, is contrasted with a less costly 
method for casting the shadows of the environment on a single ground plane. In order to attain good 
results, the discrete na- ture of the visible-surface computations must be treated with care. The effects 
of dither, interpo- lation, and geometric quantization at different stages of the shadowing algorithm 
are examined. The special problems posed by self-shadowing sur- faces are described. Key words: shadows, 
hidden surface algorithms, computer animation, computer graphics. CRclassification: 8.2 Introduction 
 The Z-buffer visible surface algorithm, first pub- lished by Catmull [i], was the first method to make 
possible computer generated shaded pictures of hi- cubic surface patches. The algorithm is extremely 
general and quite simple to implement but requires substantial memory. 270 A "frane buffer," in the 
current computer graphics parlance, is a memory that stores a complete digi- tal picture. It may serve 
as an intermediary between the computer that produces the picture and a video driver which continuously 
refreshes a display. Some visible surface algorithms (e.g. [2]) require a frame buffer in order to compute 
an image. In this case, the frame buffer mediates the display process in a more substantial way. The 
Z-buffer is an extension of this mass-memory approach to computer graphics which resolves the visible 
surfaces in a scene by storing depth (Z) values at each point in the picture. As objects are rendered, 
their Z values are compared at each point with the stored Z values to determine visibility. Since this 
determination requires only that a meas- ure exist which orders the surfaces to be displayed, it is not 
too strong a statement to say that the Z-buffer algorithm provides a discrete solution to all scenes 
for which visible surfaces can be computed. Z-buffer visible surface computation is of particu- lar 
interest because it exhibits limiting-case pro- perties [3]. The objects to be rendered do not have to 
be sorted beforehand, so indefinitely com- plex scenes can be handled. At the pixel level, the Z-buffer 
implicitly executes radix sorts in X and Y and simple indexing in Z. In X and Y, the sorts are bucket 
sorts, the special case of the ra- dix sort where the radix encompasses the range of the keys, obviating 
all comparisons. In Z, the in- dex of the sort is reduced to one, necessitating only a single comparison 
for each item. Radix sorting is the only sorting method which grows only linearly in expense with the 
ntmber of randomly-ordered items to be sorted, and the Z- buffer is the only visible surface algorithm 
the cost of which grows only linearly with the average depth complexity of the enviror~ent (that is to 
say, with the total screen area of all surfaces rendered, whether visible in the final image or not). 
 Thus the Z-buffer algorithm enjoys two key advan- tages over all other existing visible surface algo- 
rithms: i. indefinitely large enviror~ents; 2. linear cost growth. In addition, the final image computed 
has an asso- ciated Z partition, a "depth map" [4] of the scene. This extra information permits a great 
many in- teresting post-processes on a computed image. Such algorithms are noteworthy because their expense 
does not vary with the size or complexity of the environment, but depends only on the image resolu- tion. 
The shadow algorithm described here is one attempt to exploit the Z partition. Shadow Information The 
display of shadows may make the shape and rela- tive position of objects in computer generated scenes 
more comprehensible. Shadows emphasize and may serve to clarify the three dimensional nature of the forms 
displayed. The shadows cast by a point source of light onto a flat surface represent, like a perspective 
transformation, a projection of the scene onto a plane. This simplified situation offers a con- venient 
way of understanding the information that shadows convey. A scene rendered with shadows con- tains two 
views in one image. If we are content to cast shadows on a single wall or ground plane, these two views 
are simple projections. In gen- eral, of course, shadows may fall across any sur- face in the scene. 
Two views are still sufficient to compute the shadows, however, if they are Z- buffer views. The proposed 
algorithm works as follows: i. A view of the scene is constructed from the point of view of the light 
source. Only the Z values and not the shading values need be com- puted and stored. 2. A view of the 
scene is then constructed from the point of view of the observer's eye. A linear transformation exists 
which maps X,Y,Z points in the observer's view into X,Y,Z coor- dinates in the light source view. As 
each point is generated in the observer's view, it is transformed into the computed view in the light 
source space and tested for visibility to the light source before computing its shad- ing value. If the 
point is not visible to the light source, it is in shadow and is shaded accordingly. Step (2) as defined 
is the "correct" form of the proposed algorithm, but in the ensuing discussion and pictures a modified 
procedure is ass~ned. The ccmplete scene is computed from the observer's viewpoint, and the point-by-point 
transformation to the light source space and consequent shadowing is undertaken as a post-process. This 
modified algo- rithm incorrectly shades the hilights in the scene, since they appear in the shading process 
and then are merely darkened if they are found to lie in shadow; hilights should not appear in shadowed 
areas at all. The modified algorithm may also suffer more severely from quantization problems, since 
the Z coordinates of the visible points will have been quantized to the resolution of the Z buffer (16 
bits in the cases illustrated here) be- fore transformation. On the other hand, the ex- pense of the 
transformation in the modified version does not depend on the complexity of the scene, as it does when 
all points are transformed as they are cGmputod. Operating as a post process, the transformation is 
applied only to the points that are visible in the final picture. The expense is thus dependent only 
on the resolution of the image. Like most point-by-point operations, expense creases with the square 
of the resolution. in- Limitations of Image Space The generalization to curved surfaces and the linear 
cost growth which distinguish the proposed algorithm are both attributable to the fact that all computations 
are performed in image space. This approach carries with it certain limitations, however, which must 
be weighed against the advan- tages. Since shadow determination is based on transforma- tion between 
two images, the user must take care to ensure that all objects which may cast a shadow in the observer's 
image be within the field of view of the light source image. The ass~nption is that points transformed 
into the light source space which lie outside the viewing vol~ne of the light source are illeminated. 
Shadows may only be cast within the viewing vol~ne of the light source. While it is not precisely true 
that the light source must lie outside the observer's field of view, it can cast shadows only within 
its own field. If a light source within the observer's viewing volt, he is to cast shadows in all direc- 
tions, its sphere of ill~nination must be sectored into multiple views as suggested by Crow [5]. Com- 
puting these views in the Z-buffer is only slightly more expensive than computing a single view con- 
taining all the objects in the scene. Transforming points from the observer's image into the light source 
space becomes more expensive, however. Ei- ther each point must be transformed into each light source 
view (the correct approach in computing sha- dows for multiple light sources) , or clipped against the 
light source viewing vol~nes in the observer's space and transformed into the coordi- nates of the light 
source view in which it falls. The major difficulty with this method is the in- creased memory required. 
 Severe perspective, either in the observer's view or required by a light source close to the scene, 
may increase the quantization problems attendant in transforming from one image to the other. In any 
case, quantization and aliasing are the chief draw- back of image space algorithms. The aliasing prob- 
lem must be addressed vigorously whenever image space techniques are applied. This is a large and cemplicated 
issue, outside the scope of this paper; for a general treatment of aliasing and visible surface algorithas, 
see [i], [6] , and especially [7]. [3] will treat the special topic of aliasing, geometric quantization 
and the Z-buffer. Self-shadowing surfaces rendered by the proposed technique constitute an excellent 
case study in im- age space sampling problems. When we transform a point from a surface in the observer's 
space onto a surface in the light source space, it should ideal- ly lie right on the surface of which 
it is a part. Due to the imprecision of machine arithmetic and more particularly to the quantization 
of Z-buffer surfaces, it will fall above or below the surface. Since we want the point to appear illt~ninated 
if it lies on a visible surface, we subtract a bias from 271  the Z value of the point after it has 
been transformed into the light source space (actually, of course, this bias is incorporated into the 
gen- eral linear transformation employed). The bias may move the shadow line slightly, but it has the 
desired effect of keeping surfaces from shadowing themselves where they are plainly visible to the light 
source. As a surface curves smoothly away from the light, however, it must ultimately shadow itself. 
This is not a problem with polygons, the sharp edges of which make shadowing a rather sharply defined 
pro- position. A smooth surface shadowing itself in a shallow curve may switch from light to dark on 
the strength of a least significant bit in the Z- buffer. Worse, it may switch back and forth as the 
quantizing error beats with the ssmpling grid, pro- ducing a vivid moire. Figures 1 and 2 illustrate 
a simple scene from the point of view of an observer and from the point of view of the light source, 
respectively. The Z bias subtracted from the transformed points in computing the shadows of figure 3 
has been deliberately re- duced to reveal the quantizing moire. The light source is at infinity, rotated 
one hundred degrees about the vertical axis to the left of the observer's bearing. Note that the quantizing 
error is greatest in two areas: at the edge of the vert- ical solid shadow line, and in a dark curved 
band to the left of it. These correspond to, respec- tively, the right edge of the spheres in the light 
source view, and the right edge of the spheres in the untransformed observer's view. These edges are 
aliased in the original views, discrete periodic sanples of non-bandlimited images. Another way of viewing 
the problem is that the edges are quantized in the original views, quantized to the nine bits of resolution 
available in X and Y. Clearly the problem is much greater than in Z, where sixteen bits are available. 
Unfortunately, extra lateral resolution is purchased at square law expense. Bandlimiting the Z partition 
before sampling, if it were practical, would not improve matters. Z values at the edges of the spheres 
would be a ~nooth blend of the depth of the edge and the depth of the far clipping plane, meaningless 
points as far as the scene is concerned. The aliasing ef- fects observed are local, however, and it is 
rea- sonable to treat the smooth surfaces within the ragged edges as correctly sanpled. This asst~nption 
implies that a filter to reconstruct the surface between samples is in order. Indeed, interpolating the 
Z values of the light source image to derive Z values at the exact X,Y coordinates of the transformed 
observer points (rather than using the Z value of the nearest neighbor for comparison) im- proves matters 
somewhat, reducing shadow noise in the form of isolated pixels. Treating shadow noise as a quantizing 
rather than an aliasing problem improves the image further. The error signal in a quantizing system correlates 
quite strongly with the signal. Addition of random noise in the range of a single quantt~ breaks up this 
correlation, reduces the resulting periodici- ties (moire) to which the hu~nan eye is so sensi- tive, 
and whitens the spectrt~n of the error. Fig- ure 4 illustrates the sphere shadows with increased negative 
Z bias and bilinear interpolation of light source Z values to the X,Y of the transformed ob- server 
points, which have been dithered by the ad- dition of normally distributed random values in the range 
-.5 to +.5. The shadow image is subsequently dejagged by an edge dequantizing filter similar to one advanced 
by Freeman [8], then low pass filtered to further smooth the contours and merge the dith- ered edge of 
self shadowing (figure 5). As a final, not unimportant observation, figure illustrates that the problem 
of self shadowing sur- faces may not be terribly significant in practice. Figures 3 through 5 were of 
the computed shadows alone; figure 6 displays the shaded surfaces with their shadows. Shading the spheres 
according to the position of the light source casting the sha- dows causes a ~nooth shadow transition 
which ob- scures the quantization error. In practice, translucent shadows (their translucency correspond- 
ing to the additive "a~bient" term in most surface shading formulations) generally look better than deep 
black shadows, and low pass filtering of the shadows before they are applied to the image sub- jectively 
approximates the soft penuabra cast real light sources. by Conclusions The algorithn described operates 
successfully on scenes of curved surface patches, and does so with a cost that increases only linearly 
with the com- plexity of the environment. The cost is roughly twice the cost of rendering the scene normally, 
plus the cost of transforming the points of the observer's image into the light source image. In the 
originally stated algorithm, the cost of transformation increases linearly with the depth complexity 
of the scene. The cost of transforma- tion in a modified version of the algorithm which performs shadowing 
strictly as a post- process is fixed by the resolution of the screen, and corresponds to a scene with 
an average depth com- plexity of one. The rendering cost is only "rough- ly" twice the cost of rendering 
the scene normally, since the light source view requires no shading computation. Depending on the complexity 
of the shading rules applied [9], this may represent a substantial savings. Speed does not directly 
correspond to "computation- al expense" when special hardware can be applied. The enormous interest in 
real-time graphics has led to the development of specialized transformation hardware, specifically, digital 
devices to multiply four by four transformation matrices by four ele- ment homogeneous point coordinates 
[i0]. The modi- fied version of the shadow algorithm, developed for animation purposes, is particularly 
suited to pipe- lining of the coordinate transforms. The intent at NYIT is to apply the Floating Point 
Systems API20-B array processor to such problems. The complexity of software necessary to implement 
the shadow algorithn is minimal if the necessary memory is available. Although it has long been suggested 
that two passes of a visible surface al- gorithm is sufficient to compute shadowing [5], relating the 
data provided by the two passes is very difficult for many algorithms. The Z-buffer provides a straightforward 
means of relating data in different views since the visible surfaces are three dimensional and hence 
subject to general 273 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807403</article_id>
		<sort_key>275</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>48</seq_no>
		<title><![CDATA[Polygon shadow generation]]></title>
		<page_from>275</page_from>
		<page_to>281</page_to>
		<doi_number>10.1145/800248.807403</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807403</url>
		<abstract>
			<par><![CDATA[<p>A general purpose method for generating shadows using a polygonal coordinate data base is presented. The method is based on an object space polygon clipping hidden surface removal algorithm. Output from the program is in the same three-dimensional polygon format as the input. Thus, a shadowed data environment may be easily created and viewed from any observer position with no additional depth sorting time required for the hidden surface removal process. Shadows can also be cast by more than one light source. Since the shadows are generated in object space, the results can be used for both visual display and numerical analysis.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Graphics]]></kw>
			<kw><![CDATA[Hidden surface removal]]></kw>
			<kw><![CDATA[Polygon clipping]]></kw>
			<kw><![CDATA[Shadow generation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Hidden line/surface removal</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P332877</person_id>
				<author_profile_id><![CDATA[81100484386]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Atherton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P161253</person_id>
				<author_profile_id><![CDATA[81100217340]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kevin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Weiler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P68460</person_id>
				<author_profile_id><![CDATA[81100196982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Greenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Appel, Arthur, The Notion of QuantitativeInvisibility and the Machine Rendering ofSolids, Proceedings ACM, 1967 National Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Atherton, Peter, Polygon Shadow Generation withan Application to Solar Rights, M.S. Thesis,Cornell University, February 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bessel, David H., Crane, Ted, Programmer'sGuide for Release I, Evans and Sutherland VideoFrame Buffer Programming Package, Manual, Programfor Computer Graphics, Cornell University,February 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>362739</ref_obj_id>
				<ref_obj_pid>362736</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bouknight, W. Jack, A Procedure for the Generationof Three-Dimensional Half-Toned ComputerGraphics Presentations, CACM, Vol. 13, No. 6,September 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bouknight, W.J., Kelley, Karl C., An Algorithmfor Producing Half-Tone Computer Graphics Presentationswith Shadows and Movable LightSources, 1970, SJCC, AFIPS, Vol. 36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563901</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Crow, Franklin C., Shadow Algorithms for ComputerGraphics, Proceedings of 4th Annual Conference,on Computer Graphics, Interactive Techniquesand Image Processing - SIGGRAPH 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Kelley, K.C., A Computer Graphics Program forthe Generation of Half-Toned Images with Shadows,M.S. Thesis, Univ. of Illinois, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Nishita, Tomoyuti and Nakamae, Eihaitro, AnAlgorithm for Half-Toned Representation ofThree-Dimensional Objects, Information ProcessingSociety of Japan, Vol. 14, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Rogers, Richard, Atherton, P., Nall, Daniel andGreenberg, Donald P., A Means for IncludingShadowing in a Building's Thermal Analysis,CAD '78.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Weiler, Kevin, Hidden Surface Removal UsingPolygon Area Sorting, M.S. Thesis, Program ofComputer Graphics, Cornell Univ., Jan. 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563896</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Weiler, K. and Atherton, P., Hidden SurfaceRemoval Using Polygon Area Sorting, Proceedingsof 4th Annual Conference on Computer Graphics,Interactive Techniques and Image Processing,SIGGRAPH 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 POLYGON SHADOW GENERATION by Peter Atherton, Kevin Weiler and Donald Greenberg Program of Computer 
Graphics Cornell University ABSTRACT A general purpose method for generating shadows using a polygonal 
coordinate data base is presented. The method is based on an object space polygon clipping hidden surface 
removal algorithm. Output from the program is in the same three-dimensional polygon format as the input. 
Thus, a shadowed data environment may be easily created and viewed from any observer position with no 
additional depth sorting time required for the hidden surface removal process. Shadows can also be cast 
by more than one light source. Since the shadows are generated in object space, the results can be used 
for both visual display and numerical analysis. COMPUTING REVIEWS CLASSIFICATION: 3.2, 4.9, 4.40, 4.41 
 KEYWORDS: Shadow Generation, Hidden Surface Removal, Polygon Clipping, Graphics I. INTRODUCTION A 
shadow is the darkness cast by an object inter­cepting light. It falls from the side opposite the source 
of light. Theoretically, when the obser­ver's position is coincident with that of the light source, no 
shadows are visible. Shadows become visible when the viewer's position moves away from the source of 
illumination. The addition of shadows to a perspective image vastly improves the depth perception of 
the display. Furthermore, shadows provide valuable positional information and improve the ability of 
the obser­ver to comprehend complex spatial environments. However, computation times and algorithmic 
complex­ ity for shadow generation have prevented many im­plementations. The shadow creation method pre­ 
sented is a natural extension of an object space hidden surface removal algorithm which uses poly­ gon 
area sorting and is described in the third section. A major advantage of this method is that both the 
input and output are in the form of a three-dimensionalpolygon data structure. This characteristicmeans 
that the shadow definitions can be used for the purposes of both display and analysis. II. SURVEY 
OF EXISTING ALGORITHMS Several classes of algorithms for shadow generation have been previously presented. 
Each of these approaches has inherent limitations which may re­strict their application and use. The 
raster scan method for shadow image creation was first imple­ mented in 1970 by Kelley and Bouknight4,5,7al­ 
though a similar procedure for line drawing images has been presented by Appel.1 Oriented to a raster 
type display scope, the Kelley and Bouknight method scans an object row by row to determine visibility. 
Each time a polygon boundary is crossed, a depth sort is made to determine which polygonal surface 
is nearest the observer (Figure 1). Since the color of a polygon does not change across its surface, 
the only display information necessary is the location of the "key squares," those raster units in 
each row where a color change takes place. Shadows may be added to an image simply by running two 
concurrent scanning operations, one to deter­mine visible surfaces and one in image space to determine 
shadow existence. Before scanning, a list is created for each polygon linking it to any other polygon 
that might cast a shadow upon it. In 1973 Nishita and Kakamae presented a method for shadow generation 
based on a convex polyhedron clipping algorithm. This programmaintained some of the benefits of the 
raster scan display method while improving on the accuracy and versatility of the shadow definitions. 
 The data input base consists of convex polyhedra, each of which may be composed of several convex polygons. 
Hidden surface removal from any chosen point of view is accomplishedby determining the silhouette contours 
of each polyhedron and using them to define its clipping border. Objects which lay behind a selected 
polyhedron are clipped to the window defined by the polyhedron's outside boun­daries. The generation 
of shadowed images by this poly­hedron clipping method is accomplished in two basic  Figure 1. Concurrent 
scanning method of shadow display. steps (Figure 2). In the first step, a view is taken in the direction 
of the infinite light source. Using the polyhedron clipper, all the hidden sur­ faces, which are surfaces 
that are in shadow, are found. The entire scene is then transformed to a selected view point, and all 
hidden surfaces are removed by a raster scan method similar to that used by Bouknight and Kelley. A 
third algorithm for generatingshadows is based on the concept of computing the surface defining the 
volume of space swept out by the shadow of an object, its umbra. The umbra surfaces are then added to 
the data and treated as invisible surfaces which, when pierced, cause a transition into or out of an 
object shadow. This shadow volume approach was presented by F. Crow in 1977.6 For any polyhedron, the 
shadow volume can be com­pletely described for a given light source posi­ tion (Figure 3). The contour 
edges of the original object, as seen from the light source, are first computed. Then all planes defined 
by the light source and the contour edges constitute the bound­ ing surface of the shadow volume. The 
"near" sur­ face of the shadow volume is defined by the sil­houette edges of the object casting the shadow. 
 The "far" surface is at an infinite distance. This volume is then clipped by the frustrum of vision 
 (or viewbox) and added to the environment data base. Any hidden surface algorithm can then be used to 
 create the display. The shadow data is treated in the same manner as the original data except that 
it is invisible. In the depth order calculations, any plane behind a front facing shadow surface is 
in shadow. The method can be coupled with several hidden surface algorithms and has the capability of 
effectively creating shadow volumes when the illuminating light source is placed within the ori­ ginal 
environment.  Figure 2. Polyhedra clipper and raster scan method of shadow display. 276 There are 
several restrictions with the shadow The hidden surface removal algorithm involves four image creation 
programs described. The major limi­tation of the double scanning method and the shadow volume method 
is that the shadow surfaces are not defined in object space. This precludes the use of the created shadows.for 
accurate computational pur­poses. Furthermore, scan-line algorithms based on raster display devices determine 
their depth prior­ity in image space. This limits output portability (e.g., vector displays) and will 
become less effi­cient as the display resolution increases. Addi­tional problems, unique to the individual 
algorithms, are the imposed limitations on the environment des­cription, the potentially large increases 
in the environment data base, the required maintenance of non-visible polygons as possible shadow casting 
elements, and the necessity for recalculating sha­dows for each image. To overcome these difficulties, 
a different approach to shadow image generation based on our hidden surface removal method using polygon 
area sorting has been developed.2,10,11 This can be accomplished with relative ease since the polygon 
 form of the output is the same as the polygon form of the input. III. POLYGON AREA SORTING HIDDEN 
SURFACE REMOVAL ALGORITHM A program to remove hidden surfaces by polygon area sorting has been developed 
at Cornell's Laboratory of Computer Graphics.10,11 The basic concept of a polygon sorting hidden surface 
removal algorithm is that all surfaces that lay behind each unique poly­ gonal area and within its borders 
are removed. The algorithm proceeds from front to back across the transformed object space, producing 
portions of the final image along the way and temporarily reversing direction only when an initial 
depth sort error is detected. Output from the algorithm never overlaps on the vertical image plane since 
 each visible area has had all polygons behind it removed. This polygonal area may itself be sub­ divided 
recursively if there is an error in the initial depth sort. basic steps: 1) a preliminary rough depth 
sort 2) a two-dimensional comparison of the currently most forward polygon, or template, to the remaining 
polygons 3) removal of polygons that exist behind the tem­ plate and within its borders 4) a recursive 
comparison when an error in the preliminary depth sort has occurred. At the heart of the hidden surface 
removal process is a polygon clipper. This algorithm considers two polygons at a time, a template or 
clipping polygon and a subject polygon. The two polygons are com­ pared and the surfaces of the subject 
polygon exist­ ing within the borders of the clipping polygon are designated. Even though the polygon 
clipper works essentially in two dimensions, all depth informa­ tion is accurately preserved maintainingthe 
pre­ cise three-dimensionalityof the polygons. The polygon clipper is capable of clipping a con­cave 
subject polygon with holes to the borders of a concave clipping polygon with holes. This gener­ality 
is necessary since even when a scene is re­stricted to convex polygons, a clipping sequence could quickly 
yield concave areas and holes. Sur­face details such as texture or color differences can be described 
as polygons within the boundaries of a parent polygon. These surface details will have a minimal effect 
on the hidden surface removal process. IV. POLYGON SHADOW ALGORITHM The procedure for creating an image 
containing sha­dows consists of two major parts. The first is the creation of the shadow descriptions 
as dictated by the particular object orientations and light source position. The second is the determinationof 
vis­ible surfaces with their associated shadow des­criptions and is dependent upon the observer's position. 
 Figure 3. Shadow volume method of shadow display. By using the general purpose polygon clippinghid­den 
surface removal algorithmpreviously described, the process of generatingshadowed images can be made 
relatively simple (Figure 4). Shadow descrip­ tions are found by viewing the environment from the position 
of the light source. A hidden surface re­moved view from the light source position will delineate the 
illuminated polygons which are those areas not in shadow. Once defined, these illum­ inated polygons 
are added to the original environ­ment and treated as surface details on their origi­nal source polygons. 
This general method is suit­ able for both point light sources and parallel light sources. This approach 
has several distinct advantages. First, since the polygonal output of the hidden surface removal routines 
is the same as the input, the same logic can be used for the shadow genera­tion and the image display. 
Second, by maintaining the three-dimensionalshadow polygon output, it is possible to compute shadow areas 
and thus their effect on such phenomena as energy utilization. Third, by adding the shadows to the data 
base in the form of details attached to "parent" planes, the computational time for the hidden surface 
re­moval sorting process does not increase. Fourth, many views can be generated requiring only one original 
shadow generation cycle. Lastly, shadow views with multiple light sources require only a single pass 
through the hidden surface removal pro­gram from the viewpoint of each light source. At present, the 
general polygon shadow generation pro­cedure is only limited by the requirement of a polygonal planar 
data base. It has proven to be flexible, device independent, and has run effi­ciently on a large variety 
of environments. For each display frame that is to be produced, there is a set of transformationmatrices 
which are used to manipulate the environment coordinate data. These transformationmatrices are of two 
types, view matrices and shadow matrices. The view matrices transform the environment to any selected 
view. There are two shadow matrices which are devoted to the creation of a shadow data base con­sisting 
of the original polygonal coordinate defin­itions and their associated lighted detail poly­gons (Figures 
4 and 5). The first of these shadow matrices is used to trans­form the entire object environment to 
the viewpoint of the light source. A copy of the transformed environment is made for later use. Hidden 
surfaces are removed from the object environment leaving only the illuminated polygons. The second shadow 
matrix is then used to transform the entire copy of the object environment to any environment orienta­tion 
including the original orientation. The lighted polygons are also transformedby the second shadow matrix 
and then added to copied polygonal data as lighted details to derive a shadowed coor­dinate data file. 
Once the shadowed data file is created, only one view matrix is needed to trans­form it to any desirable 
viewing position. V. FITTING THE ENVIRONMENT INTO THE VIEWBOX In performing the computations for the 
display of shadows, it is important that the object be en­ tirely contained by the frustrum of vision 
emanat­ing from the light source. Areas of the object that exist outside of the viewing area will be 
 clipped and removed, and thus falsely interpreted to be in shadow. Therefore, the entire object must 
be within the boundaries of the viewing area. By performing shadow calculations in object space with 
the polygon clipping method of hidden surface removal, the precision may be extended to the machine 
limits, rather than the display limits. If the coordinate values are stored in integer format, the 
maximum accuracy of the shadow calculations can be obtained when the following three criteria are met: 
 1) The boundaries of the viewbox of the frustrum of vision are set to correspond to the maxi­ mum machine 
limits (e.g., for a 16 bit com­ puter, this corresponds to +32,767). 2) The object environment is centered 
within the viewbox. 3) The object environment is then scaled as large as possible to fit within the 
viewbox. To accomplish this, the extreme three-dimensional coordinates of the original object are used 
to form the minimum rectangular solid containing the entire environment. The centroid of this volume 
is then centered in the viewbox and scaled as large as possible with the constraint that all portions 
of the bounding volume remain within the viewbox window. VI. DISPLAY OF SHADOWED IMAGES Since the three-dimensionalpolygon 
coordinate data is maintained to the limits of machine precision, images created by the hidden surface 
removal system can be displayed accurately on many different per­ipheral devices. The two basic types 
of displays used are hidden line removed vector displays and hidden surface removed halftone displays 
(Figure 4). The vector displays are only concerned with drawing the lines or borders of each polygon 
and are inher­ently faster than the halftone displays. Further­more, the display is more accurate due 
to the avail­able resolution of the standard vector displays. Details may be visualized easily, but the 
depth perception is not nearly as effective as with the halftone displays. For color raster displays, 
all visible surfaces of the environment must be rendered. This is achieved with the aid of a set of 
software routines which can render an arbitrary concave polygon with holes with a selected color. Colors 
and shades can be interactively selected or automatically computed for each polygon surface. For black 
and white images, the shade of gray selected for a particular polygon is dependent upon the angle between 
a ray extending from the light source to the polygon and the normal of the polygon. Strictly speaking, 
sha­ dowed surfaces would be rendered black. To aid in image visualization, the shadowed surfaces utilize 
 a darker gray range of the gray scale than that used for the lighted surfaces. To produce a color 
image, the same type of intensity scale is applied to the particular ratio of basic hues (red, green 
 278  Figure 4. Shadow Creation and Display Process Figure 5. Shadow Creation and Display Process (key). 
 and blue) defining the color. The ratio of the primary hues used remains the same and only the in­ 
tensity varies. VII. SHADOW DISPLAYS WITH MULTIPLE LIGHT SOURCES Shadowed images with more than one 
light source can be made by a single pass through the hidden surface removal program from each light 
source viewpoint. Shadow data files may be utilized in the same man­ner as any other polygon data file 
that can be used by the hidden surface removal system since the same coordinate polygonal data structure 
has been main­ tained. The shadow data file may be transformed by a single matrix to any desired viewing 
orienta­ tion. It may also be used as a data file to which an additionalset of shadows from another 
light source may be added (Figure 6 and 7). By main­ taining the polygonal data structure throughout 
the hidden surface removal system, new possibilities in the area of graphic shadow generation such 
as the casting of shadows through translucent surfaces and the study of multiple reflections of light 
can be accomplished. VIII. SHADOW APPLICATIONS Since the object space computations are carried out 
to the limits of machine precision, numerical ana­lysis of shadow areas is quite accurate and can be 
used for such important energy problems as measur­ing the effect of shadows on available solar energy 
or the reduction of air conditioning load. For a full yearly analysis, these effects need to be eval­uated 
on an hourly basis, requiring an immense amount of computation time for complex environ­ments.9 Methods 
are presently being developed to predict hourly shadow areas based on the calculated results for a limited 
number of known solar posi­tions. Used as a graphical tool, designers may visually "walk through" a 
simulated site and see exactly where the shadows may fall at various times and on different days (Figure 
8). This visual technique is much more effective than numerical output. The actual locations of shadows 
become obvious, and possible solutions to architectural design or light­ing problems are readily apparent. 
A designer may interactivelymove or change a structure and con­tinuously examine the results. IX. CONCLUSION 
 The polygon shadow generation approach presented is both accurate and versatile. It would seem appar­ 
ent that with the continuing advances in display hardware, the production of higher resolution ras­ 
ter scan programs will become more time consuming since their computations are directly related to 
the display resolution. Thus, it is important to refine this polygon approach in terms of speed and 
 portability as its acceptability and use should certainly increase. Shadows clearly enhance the depth 
perception and realism of computer generated images but several challenges remain. One problem still 
existing is the specification of the path through color space which should be used to depict the color 
changes due to shade and shadows. This aspect is particu­ larly importantwhen dealing with multiple 
light sources. Another problem involves finding a method for the modeling of light sources of finite 
size, such that the cast shadows contain an umbra and penumbra. Each of these problems are subjects 
for future investigations. ACKNOWLEDGEMENTS The research is part of a project sponsored by the National 
Science Foundation under grant number DCR74-14694 entitled "Development of Computer Graphics Techniques 
and Applications." The authors wish to particularly thank Ted Crane and David Bessel for their work 
in the implementation of the color display system. REFERENCES 1. Appel, Arthur, The Notion of Quantitative 
Invisibility and the Machine Rendering of Solids, Proceedings ACM, 1967 National Con­ference.  2. Atherton, 
Peter, Polygon Shadow Generationwith an Application to Solar Rights, M.S. Thesis, Cornell University, 
February 1978.  3. Bessel, David H., Crane, Ted, Programmer's Guide for Release I, Evans and Sutherland 
Video Frame Buffer Programming Package, Manual, Pro­gram for Computer Graphics, Cornell University, February 
1977.  4. Bouknight, W. Jack, A Procedure for the Genera­tion of Three-Dimensional Half-Toned Computer 
Graphics Presentations,CACM, Vol. 13, No. 6, September 1970.  5. Bouknight, W.J., Kelley, Karl C., An 
Algorithm for Producing Half-Tone Computer Graphics Pre­sentations with Shadows and Movable Light Sources, 
1970, SJCC, AFIPS, Vol. 36.  6. Crow, Franklin C., Shadow Algorithms for Com­ puter Graphics, Proceedings 
of 4th Annual Con­on Computer Graphics, Interactive Tech­niques and Image Processing -SIGGRAPH 1977. 
 7. Kelley, K.C., A Computer Graphics Program for the Generation of Half-Toned Images with Sha­dows, 
M.S. Thesis, Univ. of Illinois, 1970.  8. Nishita, Tomoyuti and Nakamae, Eihaitro, An Algorithm for 
Half-Toned Representation of Three-DimensionalObjects, InformationPro­cessing Society of Japan, Vol. 
14, 1974.  9. Rogers, Richard, Atherton, P., Nall, Daniel and Greenberg,Donald P., A Means for Including 
Shadowing in a Building's Thermal Analysis, CAD '78.  10. Weiler, Kevin, Hidden Surface Removal Using 
Polygon Area Sorting, M.S. Thesis, Program of Computer Graphics, Cornell Univ., Jan. 1978.  11. Weiler, 
K. and Atherton, P., Hidden Surface Removal Using Polygon Area Sorting, Proceedings of 4th Annual Conference 
on Computer Graphics, Interactive Techniques and Image Processing, SIGGRAPH 1977.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>639789</article_id>
		<sort_key>282</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>49</seq_no>
		<title><![CDATA[Spherical shading]]></title>
		<page_from>282</page_from>
		<page_to>285</page_to>
		<doi_number>10.1145/800248.639789</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=639789</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P436236</person_id>
				<author_profile_id><![CDATA[81100437425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Porter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Institutes of Health, Bethesda, Maryland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>359432</ref_obj_id>
				<ref_obj_pid>359423</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[1. Bresenham, J. E. An incremental algorithm for digital display of circular arcs; Communications of the ACM 20, 2 (February 1977), 100-106.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[2. Bui Tuong Phong. Illumination for computer generated pictures. Communications of the ACM 18, 6 (June 1975), 311-317.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[3. Catmull, E. A subdivision algorithm for computer display of curved surfaces. UTEC-CSc-74-133, U. of Utah, December 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>359869</ref_obj_id>
				<ref_obj_pid>359863</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[4. Crow, F. C. The aliasing problem in computer-generated shaded images. Communications of the ACM 20, 11 (November 1977), 799-805.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[5. Gouraud, H. Computer display of curved surfaces. UTEC-CSc-71-113, U. of Utah', June 1971.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[6. Jordan, B. W., Lennon, W. J., and Holm, B. C. An improved algorithm for generation of non-parametric curves. IEEE Trans. Computers C-22 12(December 1973), 1052- 1060.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[7. Knowlton, K., and Cherry, L. ATOMS--A threed opaque molecule system--for color pictures of space-filling or ball-and-stick models. Computers & Chemistry 1(1977), 161-166.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[8. Myers, A. J. An efficient visible surface algorithm. Report to the National Science Foundation, Grant Number DCR 74-00768A01, July 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[9. O'Rourke, J. Representation and display of three dimensional objects with spheres. Masters Thesis, U. of Pa, August 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[10. Watkins, G. S. A real time visible surface algorithm. UTEC-CSc-70-101, U. of Utah, June 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SPHERICAL SHADING Thomas K Porter National Institutes of Health Bethesda, Maryland Abstract Hidden 
surface algorithms in three-dimensional computer graphics have relied on polygons and patches as primitive 
objects. Spheres are shown to be computationally feasible for transforming and shading. A fast algorithm 
is presented for the shaded surface display of intersecting spheres. Problems of aliasing common to polygon­based 
images are resolved. The contribution to molecular graphics is demonstrated. KEY WORDS AND PHRASES: 
computer graphics, hidden surface removal, spheres, shading, aliasing, molecular graphics, raster displays 
 CR CATEGORIES: 3.12, 8.2 Introduction We are filling purpose interested in renditions of is to allow 
producing molecular molecular colored, space­models. biologists Our to visualize molecules interactively 
in a manner similar to that offered by plastic space-filling models. Using known techniques for the hidden 
surface elimination of polygonal objects along with new developments in drawing curved arcs, we shall 
exhibit a fast algorithm for shading spheres. Traditionally, polygons have been used as primitives 
in the rendering of shaded images. More recently, quadric and bicubic patches have been employed (3). 
The patches afford much higher quality in the displaying of curved surfaces, but do not lend themselves 
to fast computation. Polygons, on the other hand, are easy to transform and shade, but the resulting 
pictures suffer from various annoying artifacts of the polygons. This paper will demonstrate that spheres 
are computationally very easy to use as primitive objects in known hidden surface elimination algorithms. 
Although spheres are not as general as polygons in the modeling of three dimensional objects, they are 
appropriate in the realm of molecular graphics and recent work (9) suggests their use elsewhere. Background 
 Bresenham (1) provides a fast algorithm for drawing circular arcs on a rectangular grid. Arcs are drawn 
incrementallyby the careful choosing of mesh points closest to the true circle. Only elementary comparisons, 
shifts, and additions are employed. In order to trace a circle of radius r with a center at (0,0), we 
start at the point (x,y)=(0,r). Grid points along the arc in the first quadrant are chosen by monitoring 
the value of 2 2 2 [(x + 1) + (y -1) ] -r ,which is the differencebetween the squared radius at the 
mesh point diagonally adjacent and the squared radius of the true circle. Symmetry is used for choosing 
points in the second quadrant. Bresenham's routine is reinitialized (as discussed in (1)) for drawing 
the lower semi-circle. Figure 1 demonstrates that the algorithm produces an arc very close to the true 
circle.  282 Restricting ourselves to orthographic views, we see that Bresenham's algorithm may be 
used to draw the silhouette of an arbitrary sphere in the xy grid of the screen. Moreover, since the 
intersection between a sphere and the plane of view normal to the xy plane of the screen and containing 
a certain raster line is another circular arc, the algorithm may be used in the xz plane for calculating 
the depth of the sphere's surface at each raster point. This "cross-product" form of Bresenham's algorithm 
for producing a sphere lends itself best to a scan line algorithm for computing the image. Watkins (10) 
and Myers (8) have introduced scan line algorithms for the hidden surface elimination of polygons. The 
horizontal segments produced by Bresenham's method are similar in nature to the polygonal segments which 
these algorithms normally handle. Spheres can thus be added as primitives. The Myers algorithm computes 
the picture at each scan line by considering every primitive object which intersects the plane of view 
at this scan line. At each raster point along the intersection, the segment of the primitive is shaded 
and displayed if it is closer in depth than any segment previously written onto that raster point. A 
depth buffer for the raster line is retained for comparing depths. The Watkins algorithm avoids this 
writing and overwriting of the picture. However, we have chosen to use Myers' method here. The algorithm 
 is currently implemented on a frame buffer, a memory large enough to retain the entire image. The 
overwriteablenature of the frame buffer makes it well-suited to the more straightforwardMyers approach. 
 The Algorithm The algorithm for producing pictures of intersecting shaded spheres proceeds as follows: 
The list of relevant spheres, those which intersect the plane of view at the current scan line, is initialized. 
Now we consider one scan line at a time from the top down. First, the list of relevant spheres is updated. 
Spheres whose highest points are at the current line are included, while spheres whose lowest points 
were at the line above the current line are removed. For each sphere on the list of relevant spheres 
at this scan line, we determine the intersection of the silhouette of that sphere with the plane of view. 
Now we have two points (Xa,Z) and (Xb,Z) which delimit the segment which we must write into that scan 
line of the frame buffer. This new segment is determined from the previous (possibly null) segment by 
using Bresenham's algorithm in the xy plane. To generate that segment, we reapply Bresenham's algorithm 
to trace the intersection between the sphere and the plane of view. This is a circular arc in the xz 
plane. Because the back hemisphere is necessarily hidden, we need to treat only the front semi-circle. 
We are now computing intersection points (xl,zl),(x2,z2),... lying along the scan line. Because we allow 
intersecting spheres, we must check the depth of each point before writing it into the frame buffer. 
A scan line depth buffer is retained, initialized to an infinite background distance, to allow this depth 
check. If the depth of the new point is less than the current depth at this raster point, the new shade 
is written into the frame buffer. Note that we process each point of the segment even if it will eventuallybe 
hidden.  The time complexity of hidden line and surface algorithms is seldom easy to determine. Routines 
often depend on scene complexity, which is difficult to quantify, but the brute force approach taken 
here is relatively simple to analyze. Every point within the silhouette of every sphere is checked to 
see whether it is written out to the frame buffer. With this inner loop, the algorithm run-time is proportional 
to the total of the silhouetted areas of all spheres. Bresenham's routine works to keep the constant 
factor low. Working on a PDP11-70 under RSX-11M with a frame buffer of 512 by 480 resolution, black 
and white versions of the molecular models shown here in Figure 3 and Figure 4 take about 20 and 50 seconds 
to produce. A color version with limited shades for each color runs at the same speed. These figures 
were produced using color separation, taking up to three times as long. The algorithm is coded mainly 
in BLISS, with the shading computation done in assembly language. 283  FIGURE 3. Propellane molecule 
 FIGURE 4. Section of RNA Improvements Observers are acutely aware of the jagged border produced by Bresenham's 
algorithm. The current implementation includes a procedure for quellingthe effects of aliasing around 
the silhouette. Methods have been introduced (4) for achievingthis blending. In this case, we treat each 
pixelas representative of a finite area, so that we mayblend the overlapping portion of the sphere into 
the background at that pixel. As each horizontal segment of the sphere is generated, points on the border 
of the silhouetteare flagged. For segments at the center of each sphere, only the leftmost and rightmost 
points areon the side border. For segments toward the topand bottom of the sphere, adjacent points 'may 
be on the top or bottom border. Bresenham's algorithm can provide the fractional amount bywhich the sphere 
overlaps the pixel in question. The pixel is then overwritten by a linear combination of the shade of 
the sphere and the shade of the background. This procedure demands that the list of relevant spheres 
be kept in back-to-front order so that the background has been properly updated when the newsphere is 
written. Note that although spheres mayintersect (causing sorting difficulties) we areinterested only 
in silhouettes here and can therefore sort the spheres sufficiently by the Z coordinate of their centers. 
A second improvement is employed for smoothing theedges formed by intersecting spheres. This is accomplished 
by blending a sphere in with thebackground wherever its depth is within a certainepsilon of the previously 
written backgrounddepth. New spheres just in front are blendedheavily; new spheres just behind are blended 
lightly. Figure 5 demonstrates these improvements. This is a blowup (by a factor of 8) of the molecule 
in Figure 3. Note that many of the border rasterelements are blended into the background ratherthan colored 
directly. Intersecting atoms meetalong nicely smoothed edges. FIGURE 5. Atoms of propellane at 64x60 
resolution Our algorithm can also produce pictures of scenes with partially transparent spheres. At everyvisible 
point- of a transparent sphere, the previously written color-shade is multiplied bythe cosine of the 
angle between the direction ofthe light and the normal to the transparentsphere. This dims the background 
by a smooth function. The depth value retained at that pixelis not updated. All transparent spheres are 
handled after all opaque spheres in order to guarantee that thebackground is fully updated before the 
dimming begins. Attempts to draw all spheres in one back­to-front pass without retaining extra information 
284 will fail because intersecting spheres are allowed. A transparent sphere intersecting with an opaque 
sphere just in front of it would have tobe shaded first, but this is a mistake because the transparent 
sphere may have to overwrite the opaque sphere in certain places. The current implementation produces 
a flawed result only atpoints on the silhouette of an opaque sphere in front of a transparent sphere. 
The transparentsphere is not considered at those pixels, eventhough we assumed in blending the silhouette 
that the background was already done. Transparent spheres provide quite a useful effectfor demonstrating, 
for example, how one chain of a molecule is embedded. Figure 6 shows Immunoglobulin with the carbon alphas 
of the aminoacid chains colored orange, blue, and transparent. Conclusions We have described an algorithm 
for the display of three dimensional objects modeled as spheres. The algorithm provides an excellent 
basis for molecular modeling using raster displays. This algorithm improves the realism of the images 
overprevious efforts in molecular display by Knowltonand Cherry (7). We have used Bresenham's algorithm 
to trace the circular arcs. Recent work by Jordan, Lennon, and Holm (6) demonstrates more generalized 
techniques for the efficient tracing of curved arcs. Such techniques may prove useful in the display 
ofother curved solids. We have avoided the problemof perspective transformation here, but a more general 
arc drawing algorithm could be developed to handle the transformed spheres which would arise. Acknowledgments 
The author would like to thank Gary Knott and Chuck Bacon for discussions about the algorithmand the 
paper, and Richard Feldmann for the raison d'etre. References 1. Bresenham, J. E. An incremental algorithm 
for digital display of circular arcs; Communications of the ACM 20,2 (February 1977), 100-106.  2. Bui 
Tuong Phong. Illumination for computergenerated pictures. Communications of theACM 18,6 (June 1975), 
311-317. 3. Catmull, E. A subdivision algorithm for computer display of curved surfaces. UTEC­CSc-74-133, 
U. of Utah, December 1974. 4. Crow, F. C. The aliasing problem in computer­generated shaded images. 
Communications ofthe ACM 20,11 (November 1977), 799-805. 5. Gouraud, H. Computer display of curvedsurfaces. 
UTEC-CSc-71-113, U. of Utah', June 1971. 6. Jordan, B. W., Lennon, W. J., and Holm, B. C. An improved 
algorithm for generation of non-parametric curves. IEEE Trans. Computers C-22 12(December 1973), 1052­1060. 
 7. Knowlton, K., and Cherry, L. ATOMS--A three-d opaque molecule system--for color pictures of space-filling 
or ball-and-stick models.Computers &#38; Chemistry 1(1977), 161-166. 8. Myers, A. J. An efficient visible 
surface algorithm. Report to the National ScienceFoundation, Grant Number DCR 74-00768A01,  July 1975. 
9. O'Rourke, J. Representation and display ofthree dimensional objects with spheres.Masters Thesis, U. 
of Pa, August 1977. 10. Watkins, G. S. A real time visible surface  algorithm. UTEC-CSc-70-101, of 
Utah, June 1970. 285
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>507101</article_id>
		<sort_key>286</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>50</seq_no>
		<title><![CDATA[Simulation of wrinkled surfaces]]></title>
		<page_from>286</page_from>
		<page_to>292</page_to>
		<doi_number>10.1145/800248.507101</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=507101</url>
		<abstract>
			<par><![CDATA[Computer generated shaded images have reached an impressive degree of realism with the current state of the art. They are not so realistic, however, that they would fool many people into believing they are real. One problem is that the surfaces tend to look artificial due to their extreme smoothness. What is needed is a means of simulating the surface irregularities that are on real surfaces. In 1973 Ed Catmull introduced the idea of using the parameter values of parametrically defined surfaces to index into a texture definition function which scales the intensity of the reflected light. By tying the texture pattern to the parameter values, the texture is guaranteed to rotate and move with the object. This is good for showing patterns painted on the surface, but attempts to simulate rough surfaces in this way are unconvincing. This paper presents a method of using a texturing function to perform a small perturbation on the direction of the surface normal before using it in the intensity calculations. This process yields images with realistic looking surface wrinkles without the need to model each wrinkle as a separate surface element. Several samples of images made with this technique are included.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P131722</person_id>
				<author_profile_id><![CDATA[81100294395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Blinn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech/JPL]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Batson, R. M., Edwards, E. and Eliason, E. M. "Computer Generated Shaded Relief Images", Jour, Research U.S. Geol. Survey, Vol. 3, No. 4, July-Aug 1975, p. 401-408.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360353</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[James F. Blinn , Martin E. Newell, Texture and reflection in computer generated images, Communications of the ACM, v.19 n.10, p.542-547, Oct. 1976]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F., "Models of Light Reflection for Computer Synthesized Pictures", Proc. 4th Conference on Computer Graphics and Interactive Techniques, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807364</ref_obj_id>
				<ref_obj_pid>300248</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F., "A Scan Line Algorithm for Displaying Parametrically Defined Surfaces", Proc. 5th Conference on Computer Graphics and Interactive Techniques, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Catmull, E. E., "Computer Display of Curved Surfaces", Proc. IEEE Conf. on Computer Graphics, Pattern Recognition and Data Structures, Los Angeles (May 1975)11.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807363</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Whitted, J. T., "A Scan Line Algorithm for Computer Display of Curved Surfaces", Proc. 5th Conference on Computer Graphics ond Interactive Techniques, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SIMULATION OF WRINKLED SURFACES James F. Blinn Caltech/JPL Abstract Computer generated shaded images 
have reached an impressive degree of realism with the current state of the art. They are not so realistic, 
however, that they would fool many people into believing they are real. One problem isthat the surfaces 
tend to look artificial due to their extreme smoothness. What is needed isa means of simulating the 
surface irregularitiesthat are on real surfaces. In 1973 Ed Catmull introduced the idea of using the 
parameter values of parametricallydefined surfaces to index into a texture definition function which 
scales the intensity of the reflected light. By tying the texture pattern to the parameter values, the 
texture is guaranteed to rotate and move with the object. This isgood for showing patterns painted on 
the surface, but attempts to simulate rough surfaces in this way are unconvincing. This paper presents 
a method of using a texturing function to perform a small perturbation on the direction of the surface 
normal before using it in the intensity calculations. This process yields images with realistic looking 
 surface wrinkles without the need to model each wrinkle as a separate surface element. Several samples 
of images made with this technique are included. These two vectors define a plane 1. INTRODUCTION tangent 
to the surface at that point. Their cross product is thus a vector normal to the surface. Recent work 
in computer graphics has been devoted to the development of algorithms for N = Pu x Pv making picturesof 
objects modelled by other than the conventional polygonal facet technique. In particular, several algorithms 
[4,5,7] have been These vectors are illustrated in figure 1. Before using the normal in intensity calculationsit 
must devised for making images of parametric surface first be scaled to a length of 1.0 by dividing 
by patches. Such surfaces are defined by the values its length. of three bivariate functions: X = 
X(u,v) Y = Y(uv) Z = Z(u,v) as the parameters vary between 0 and 1. Such algorithms basically consist 
of techniques for inverting the X and Y functions. That is, given the X and Y of a picture element, the 
corresponding u and v parameter values are found. This parameter pair is then used to find the Z coordinate 
of the surface to perform depth comparisons with other objects. The intensity of the resultant picture 
element is then found by a simulation of the light reflecting off the Figure 1 -Definition of Normal 
Vector surface. Functions for performing this computationare described in [3]. Images of smooth surfaces 
made directly from The prime component in the calculation of the intensity of a picture element isthe 
direction of the patch description do not have the usual artifacts associated with polygonal facets, 
they the surface normal at that picture element. To do indeed look smooth. calculate the surface normal 
we first examine the In fact they sometimes look too smooth. To make them look less derivatives of 
the surface definition functions. artificial it is necessary to simulate some of the If the coordinates 
of a point on the patch is surface irregularitiesof real surfaces. represented by the vector P: Catmull 
 [5] made some progress in this direction with process called texture mapping. Effectively the = (X,Y,Z) 
color of the surface was defined as a fourth bivariate function,C(u,v), and was used to scale The partial 
derivativesof these functions form the intensity of the generated picture at each two new vectors which 
we will call Pu and Pv. point. This technique was good a generating picturesof objects with patternspainted 
on them. Pu = (Xu,Yu,Zu) In order to simulate bumpy or wrinkly surfaces one might use, as the defining 
texture pattern, a Pv = (Xv,Yv,Zv) digitized photograph of a bumpy or wrinkly  286 surface. Attempts 
to do this were not very sucessful. The images usually looked like smooth surfaces with photographs 
of wrinkles glued on. The main reason for this is that the light source direction when making the 
texture photographwas rarely the same as that used when synthesizing theimage. In fact, if the surface 
(and thus the mapped texture pattern) is curved, the angle of the light source vector with the surface 
is not even the same at different locations on the patch. 2. NORMAL VECTOR PERTURBATION To best generate 
images of macroscopicsurface wrinkles and irregularities we must actually model them as such. Modelling 
each surface wrinkle as a separate patch would probablybe prohibitivelyexpensive. We are saved from 
this fate by the realization that the effect of wrinkles on the perceived intensity is primarily due 
to their effect on the direction of the surface normal (and thus the light reflected) rather than their 
effect on the position of thesurface. We can expect, therefore, to get a good effect from having a texturing 
function which performs a small perturbation on the direction ofthe surface normal before using it in 
the intensity formula. This is similar to the technique used by Batson et al. [1] to synthesize aerial 
picutres of mountain ranges from topographic data. The normal vector perturbation is defined in terms 
of a function which gives the displacement of the irregular surface from the ideal smooth one. We will 
call this function F(u,v). On the wrinkled patch the position of a point is displaced in the direction 
of the surface normalby an amount equal to the value of F(u,v). The new position vector can then be written 
as: P'= P + F N/INI  This isshown in cross section in figure 2.  The partial derivatives involved are 
evaluated by the chain rule. So Pu' = d/du P' = d/du(P + F N/INI) = Pu + Fu N/INI + F (N/INI)u Pv' 
= d/dv P' = d/dv(P + F N/INI) = Pv + Fv N/INI +F (N/INI)v The formulation of the normal to the wrinkled 
surface is now in terms of the original surface definition functions, their derivatives, and the bump 
function, F, and its derivatives. It is, however, rather complicated. We can simplify matters considerably 
by invoking the approximationthat the value of F is negligably small. This isreasonable for the types 
of surface irregularitiesfor which this process is intended where theheight of the wrinkles in a surface 
is smallcompared to the extent of the surface. With this simplification we have Pu'  + Fu N/INI Pv' 
Pv + Fv N/INI The new normal is then N' = (Pu + Fu N/NI) x (Pv + Fv N/NI) = (Pu x Pv) + Fu (N x Pv)/INI 
+ Fv (Pu x N)/INI + Fu Fv (NxN)/lNI The first term of this is, by definition,N. The last term is identically 
zero. The net expressionfor the perturbed normal vector is then + where D = (Fu (N x Pv) -Fv (N x INI 
This can be interpreted geometrically by observingthat (N x Pv) and (N x Pu) are two vectors in the tangent 
plane to the surface. An amount of eachof them proportional to the u and v derivatives ofF are added 
to the original, unperturbed normal vector. See figure 3 Another geometric interpretationis that the 
vector N' comes from rotating the original vector N about some axis in the tangent plane to the surface. 
This axis vector can be found as the cross product of N and N'. 287 Invoking the vector identity Qx(RxS) 
= R(Q.S) -S(Q.R) and the fact that N.Pu = N.Pv = 0 this axis of rotation reduces to NxN' = INI(Fv Pu 
-Fu Pv) - IN A This vector, A, is just the perpendicular to the gradient vector of F, (Fu,Fv)when expressed 
in the tangent plane coordinate system with basis vectors Pu and Pv. Thus the perturbed normal vector 
will be tipped "downhill" from the slope due to F. Note that, since NxD=INI A and since N is perpendicular 
to D then = IDI so DI = Next, since the vectors N, D and N' form a right triangle, the effective angle 
of rotation is IDI/INI this is illustrated in figure 4. Figure 4 -Rotated Normal Vector In summary, 
we can now calculate the perturbed normal vector, N', at any desired u and v parameter value. This vector 
must still be scaled to a length of 1 by dividing by its length. The result is then passed to the intensity 
calculation routines in place of the actual normal N. 3. TEXTURE FUNCTION DEFINITION The formulation 
of the perturbed normal vector is in terms of the position functions X, Y, and Z and the bump displacement 
function F. To perform calculations we only need a means of evaluating the u and v derivatives of F(u,v) 
at any required parameter value. In this sectionwe discuss some ways that such functions have been defined, 
means of evaluating them and show some resultant pictures. The function F could, of course, be defined 
analytically as a bivariate polynomial or bivariate Fourier series. In order to generate a functionwith 
a sufficientamount of complexity to be interesting, however, an excessive number of coefficients are 
required. A much simpler way to define complex functions is by a table lookup. Since F has two parameters, 
this table takes the form of a doubly indexed array of values of F at various fractionalparameter values. 
If the array is 64 by 64 elements and the parameters are between 0 and 1 a simple means of evaluating 
F (using Fortran style indexing) at u and v would be FUNCTIONFVAL(U,V) IU = IFIX(64*U) IV = IFIX(64*V) 
 FVAL = FARRAY(IU+1,IV+1) (Wewill duscuss the problem of overflow of the indices shortly). This will 
yield a functionmade of a checkerboardof constantvalued squares 1/64 on a side. A smoother function can 
be obtained by interpolating values between table entries. The simplest interpolation technique is bilinear 
interpolation. Such an algorithm would look like This yields a function which is continuous in value 
but discontinuous in derivative. Since the function F appears in the calculation only in terms of its 
derivative we should use a higher order interpolationscheme which is continuous in derivative. Otherwise 
the lines between function samples may show up as creases in the surface. Third order interpolation schemes 
(e.g. B-splines) are the standard solution to such a situation, but their generality is not really needed 
here. A cheaper, continuous interpolation scheme for derivatives consists of differencing the (bilinearlyinterpolated) 
function along the parametric directions. The increment between which differencing occurs is the distance 
between function sample values. The function generated by this interpolation scheme has continuity of 
derivative but not of value. The values of F are not used anyway. Thus E = 1/64. FU= (FVAL(U+E,V )-FVAL(U-E,V 
))/ (2*E) FV = (FVAL(U ,V+E)-FVAL(U ,V-E)) / (2*E) This is the form used in the pictures shown here. 
It is about as simple as can be obtained and has proven to be quite adequate. In the above examples, 
the integer part of the scaled up parameter values were used directly as indices into the F array. In 
practive, one should protect against array overflow occurring when the parameter happens to be slightly 
less than 0 or greater than 1. In fact, for the bilinear interpolationcase, all parameter values between 
63/64 and 1 will attempt to interpolate to a table entry at index 65. The question of what is the function 
value at parametersoutside the range of the table can be answered in a variety of ways. A simple method 
isto make the function periodic, with the table defining one period. 288 This is easily accomplished 
by masking off all butthe low 6 bits of the IU and IV values. This also makes it easy to have'the table 
represent a unitcell pattern to be replicated many times perpatch. The function values U and V are merelyscaled 
up by the replication count before beingpassed to FVAL. Now that we know what to do with the table entries 
we turn to the question of how to generatethem in the first place. Some simple geometric patterns can 
be generated algorithmically. One such is a gridwork of high and lw values. The table entries of the 
F function for such a gridare shown plotted as a 3D line drawing in figure 5. The result when mapped 
onto a flat patch withone corner bent back is also shown. Figure 5 -Simple Grid Pattern Embossed letters 
can be generated by using abit-map character set as used to'display text on araster scan display. Such 
a texture array appearsin figure 6. This pattern was used to make thetitle on the ribbon on the logo 
of the cover ofthese proceedings.   Figure 6 -Embossed Letter Pattern 289 239 Another method of generating 
bump functionsderives from image synthesis algorithms which useZ-buffers or depth buffers to perform 
the hiddensurface comparisons [5]. The actual Z values left in the depth buffer after running such an 
algorithm can be used to define the table entries for a bump function. In figure 7 an image of asphere 
was generated using such an algorithm andthe resultant Z-buffer replicated several times togenerate the 
rivet-like pattern. This is the pattern mapped onto the cube on the cover logo. Similarly, a 3D character 
set was used with a Z-buffer algorithm to generate the pattern showingthe date also in figure 7. This 
was used on theribbon on the cover. Figure 7 -Z-Buffer Patterns The most general method of generating 
bump functions relies on video frame buffer technologyand its standard tool, the painting program.Briefly, 
a frame buffer is a large digital memorywith one word per picture element of an image. A video signal 
is continually synthesized fran thismemory so that the screen displays an image ofwhat is in memory. 
A painting program utilizes adigitizing tablet to control the alteration of thevalues in the memory to 
achieve the effect ofpainting on the screen. By utilizing a region ofthe frame buffer as the defining 
table of the Ffunction, a user can actually paint in thefunction values. The interpretation of the imagewill 
be such that black areas produce small valuesof F and white areas produce large values. Since only the 
derivatives of F are used in the normalvector perturbation, any area of constant intensity will look 
smooth on the final image.However, places where the image becomes darkerwill appear as dents and places 
where it becomes brighter will appear as bumps. (Thiscorrespondance will be reversed if the base patchis 
rotated to view the back side).The generationof interesting patterns which fit togetherend-to-end to 
form a continuous join betweenpatches then becomes primarily an artistic efforton the part of the drawer. 
Figure 8 shows some  sznple results that can be achieved with this technique. The first pattern, a hand 
drawn unit cell of bricks was mapped onto the sphere on the cover. Figure A- Hand Drawn Bump Funtions 
Figure 8 Hand Drawn Functions  4. DEPENDANCE ON SCALE One feature of the perturbation calculationis 
that the perturbation amount is not invariantwith the scale at which the object is drawn. If the X, Y, 
and Z surface definiton functions are scaled up by 2 then the normal vector length,INI, scaled up by 
a factor of 4 while theperturbation amount, IDI, is only scaled by 2.This effect is due to the fact that 
the object isbeing scaled but the displacement function F isnot. (Scale changes due to the object movingnearer 
or farther from the viewer in perspective space do not affect the size of the wrinkles, onlyscale shanges 
applied directly to the object.) Thenet effect of this is that if an object is scaledup, the wrinkles 
flatten out. This is illustrated in figure 9. norma l stretched Figure 9 -stretched Bump Texture This 
effect might be desirable for someapplications but undesirable for others. A scale invariant perturbation, 
D', must scale at the samerate as N. An obvious choice for this is D' = a D INI/IDI ID 1 = a INI 50 
 where a is independent of scales in P. The valueof a is then the tangent of the effective rotationangle. 
tan+' = ID'l/lNl = a This can be defined in various ways. One simple choice is a generalization from 
the simple, flat unit square patch X(u,v) = u Y(u,v) = v Z(u,v) = 0 For this patch the original normal 
vector perturbation gives N = (0,0,1) D = (-Fu,-Fv,0) tan+ = sqrt(Fu'+Fv') Here the value of a is purely 
a function of F.Use of the same function for arbitrary patchescorresponds to a perturbation of a = sqrt(Fu'+Fv.') 
D' = a D lNl/lDl N" = N + D' The texture defining function F is now no longerbeing used as an actual 
displacement added to theposition of the surface. It just serves toprovide (in the form if its derivatives) 
a meansof defining the rotation axis and angle as functions of u and v. 5. ALIASING In an earlier paper 
121, the author describedthe effect of aliasing on images made with colortexture mapping. The same problems 
can arise with this new form. That is, undesirable artifacts canenter the image in regions where the 
texture pattern maps into a small screen region. Thesolution applied to color textures was to average 
the texture pattern over the region correspondingto each picture element in the final image. The bump 
texture definition function, however, doesnot have a linear relationship to the intensity ofthe final 
image. If the bump texture is averagedthe effect will be to smooth out the bumps ratherthan average the 
intensities. The correct solution to this problem would be to compute the intensities at some high sub-pixel 
resolution andaverage them. Simply filtering the bump function can, however, reduce the more offensive 
artifacts -. of aliasing. Figure 10 shows the result of suchan operation. After 6. RESULTS Surfaces 
appearing in images made with thistechnique look quite convincingly wrinkled. Anespecially nice effect 
is the interaction of the bumps with calculated highlights. We must realize, however, that the wrinkles 
are purelyillusory. They only come from some playing withthe parameters used in intensity calculations. 
They do not, for example, alter the smooth silhouette edges of the object. A useful test ofany image 
generation algorithm is to see how wellthe objects look as they move in animation sequences. Sane sample 
frames from such an animation sequence appear in figure 11. The illusion of wrinkles continues to be 
convincingand the smoothness of the silhouette edges is notoverly bothersome. Some simple timing measurements 
indicate thatbump mapping takes about 4 times as long as Phongshading and about 2 times as long as color 
texture mapping. The pictures in this paper took from 3 to 7 minutes each to produce. The author would 
like to thank Lance Williams and the New York Institute of Technology ComputerGraphics Laboratory for 
providing some of the artwork and assistance in preparing the logo onthe cover made with the techniques 
described inthis paper.   REFERENCES [1] Batson R. M., Edwards, E. and Eliason, E. M. "Computer Generated 
Shaded Relief Images", Jour, Research U.S. Geol. Survey,Vol. 3, No. 4, July-Aug 1975, p. 401-408. [2] 
Blinn, J. F., and Newell, M. E., "Textureand Reflection in Computer Generated Images",CACM 19, 10, Oct 
1976, pp 542-547. [3] Blinn, J. F., "Models of Light Reflection forComputer Synthesized Pictures", Proc. 
4th Conference on Computer Graphics and Interactive Techniques, 1977. [4] Blinn, J. F., "A Scan Line 
Algorithm forDisplaying Parametrically Defined Surfaces",Proc. 5th Conference on Computer Graphicsand 
Interactive Techniques, 1978. [5] Catmull, E. E., "Computer Display of CurvedSurfaces", Proc. IEEE Conf. 
on ComputerGraphics, Pattern Recognition and Data Structures, Los Angeles (May 1975111. [6] Whitted, 
J. T., "A Scan Line Algorithm forComputer Display of Curved Surfaces", Proc. 5th Conference on Computer 
Graphics ond Interactive Techniques, 1978.  292 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807404</article_id>
		<sort_key>293</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>51</seq_no>
		<title><![CDATA[TIGS]]></title>
		<subtitle><![CDATA[An overview of the terminal independent graphics system]]></subtitle>
		<page_from>293</page_from>
		<page_to>297</page_to>
		<doi_number>10.1145/800248.807404</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807404</url>
		<abstract>
			<par><![CDATA[<p>TIGS is a general purpose subroutine package providing display generation and interaction capability for a general class of graphics terminals. The package is computer, operating system, and display device independent. Primary design objectives were transportability, maintainability, and ease of use.</p> <p>Features supported by TIGS include line, arc, multi-line plot, test and dot primitives with resettable attributes such as line style, character size, intensity, font, color, transformation matrix, etc. The package uses virtual devices such as locators, keyboards, picking devices and function keys which can represent a wide range of physical devices. TIGS supports modelling transformations, 2D and 3D viewing transformations for clipping and window to viewport mapping.</p> <p>Unlike the GSPC Core System, TIGS uses the interpretive approach which uses a device independent neutral display file. This neutral display file contains information describing all segments, pictures, windows, and viewports in a device independent manner. The file may be saved and used in a later job with a different display device. Additionally, all attributes such as line style, font, character size, etc., can be re-specified without re-defining the contents of a segment.</p> <p>In planning for expansion for distributed graphics applications, multiple independent user coordinate spaces are used. Each coordinate space is called a picture. This allows for re-specification of a window without re-defining the contents of it. A picture and all the segments contained therein can be manipulated as a group.</p> <p>Device independence was implemented by dividing TIGS into a device-independent pre-processor invoked by the applications programmer, and internal device drivers, one per display device. Part of the device driver may reside on a separate processor.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Device independent graphics]]></kw>
			<kw><![CDATA[Distributed graphics]]></kw>
			<kw><![CDATA[Graphics subroutine package]]></kw>
			<kw><![CDATA[Interactive graphics]]></kw>
			<kw><![CDATA[Neutral display file]]></kw>
			<kw><![CDATA[Satellite graphics]]></kw>
			<kw><![CDATA[Terminal independent graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Input devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Graphics packages</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Hierarchy and geometric transformations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010391</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010240.10010244</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision representations->Hierarchical representations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39077643</person_id>
				<author_profile_id><![CDATA[81339504406]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Heilman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Battelle Columbus Labs, Columbus, Ohio]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P331318</person_id>
				<author_profile_id><![CDATA[81100207570]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jean]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Marchant]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Control Data Corporation, Arden Hills, MN]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[TIGS V1.0 Reference Manual, Control Data Corporation, Publication No. 60455940.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA["Status Report of the Graphic Standards Planning Committee of ACM/SIGGRAPH", Computer Graphics, Vol. II, Number 3, Fall 1977.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563898</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Puk, R. F. General Clipping on an Oblique Viewing Frustrum. Computer Graphics, Vol. II, Number 2, 1977, pp 229-235, SIGGRAPH 77 Proceedings.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>804734</ref_obj_id>
				<ref_obj_pid>800143</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Wallace, V. L. "The Semantics of Graphic Input Devices". Proceedings ACM Synposium on Graphic Languages, 26-27 April 1976, Miami Beach, Florida, pp. 61-65.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563878</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Caruthers, L. C., van der Bos, J., van Dam, A. GPGS, A Device-independent General Purpose Graphic System for Stand-alone and Satellite Graphics. Computer Graphics, Vol, II, No. 2, 1977, pp. 112-119. SIGGRAPH 77 Proceedings.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 TIGS An Overview of the Terminal Independent Graphics System Robert L. Heilman Battelle Columbus Labs, 
Columbus, Ohio and Jean M. Marchant Control Data Corporation, Arden Hills, MN Keywords and phrases: 
interactive graphics, de- vice independent graphics, distributed graphics, satellite graphics, graphics 
subroutine package, terminal independent graphics, neutral display file CR categories: 8.2, 4.29 ABSTRACT 
 TIGS is a general purpose subroutine package pro- viding display generation and interaction capabil- 
ity for a general class of graphics terminals. The package is computer, operating system, and dis- play 
device independent. Primary design objec. tives were transportability, maintainability, and ease of use. 
 Features supported by TIGS include line, arc, multi-line plot, test and dot primitives with re- settable 
attributes such as line style, character size, intensity, font, color, transformation ma- trix, etc. 
The package uses virtual devices such as locators, keyboards~ picking devices and func- tion keys which 
can represent a wide range of phy- sical devices. TICS supports modelling transfor- mations~ 2D and 
3D viewing transformations for clipping and window to viewport mapping. Unlike the GSPC Core System, 
TIGS uses the inter- pretive approach which uses a device independent neutral display file. This neutral 
display file contains information describing all segments, pic- tures, windows, and viewports in a 
device indepen- dent manner. The file may be saved and used in a later job with a different display 
device. Addi- tionally, all attributes such as line style, font, character size, etC., can be re-specified 
without re-defining the contents of a segment. In planning for expansion for distributed graphics 
applications~ multiple independent user coordinate spaces are used. Each coordinate space is called 
 a picture. This allows for re-specification of a window without re-defining the contents of it. A 
picture and all the segments contained therein can be manipulated as a group. Device independence was 
implemented by dividing TICS into a device-independent pre-processor in- voked by the applications 
prograrmner, and internal device drivers, one per display device. Part of the device driver may reside 
on a separate processor. 1.0 INTRODUCTION  TIGS is a graphics package developed by Control Data Corporation 
(i) with the primary objective of supporting a reasonable n~nber of different graph- ics displays at 
a minimal user cost in software development in writing application programs. The design is such that 
the terminals that could be supported without application program changes range from plotters, storage 
tube terminals through high performance satellites. Additional design considerations have allowed for 
expansion to graphics systems where the terminal may option- ally disconnect, run stand-alone, and subsequently 
re-connect. The system is designed for easy learning by having a small number of parameters in the calling 
se- quence. The routine naming convention is divided into syrmnetrlc groups of routines and parameters. 
Default modes are always set if a routine is not called. Maintainability has been a prime objective 
and more than 90% of the code is ANSI FORTRAN. The system was designed and implemented for a very high 
degree of portability to 16 bit machines. TICS design is independent of machine~ operating system, device, 
and corm~unication lines. The design of TIGS has been influenced greatly by the sIGGRAPH proposed standard 
(2). However, since the design and implementation of TIGS and the development of the proposed standard 
were con- current processes, there are deviations. Examples of TICS deviations from the proposed standard 
are: i) 2D primitives (except for text) are not allowed in 3D segments 2) closed segments can be extended, 
copied, or emptied 3) window definitions may be changed without re-defining the segments 4) primitive 
attributes may be changed with- out re-defining the segments 5) an additional level of structure, called 
a picture~ is used to contain segments 6) valuators and image transformations are not yet supported 
 7) the application program may test to find how a feature is supported 8) an old neutral display file 
(NDF) is sup- ported  2.0 TIGS FEATURES 2~i General Features TIGS is a FORTRAN callable set of subroutines. 
Even though the subroutine package approach is awkward, any other type of implementation would have ignored 
the customer base. The virtual graphics device for which the design was targeted was very general. As 
mentioned ear- lier, the device could be on a computer which would be able to perform when disconnected 
from the main frame. This required the ability to keep an NDF on the remote (mini) computer. This also 
 led to having multiple independent user coordi- nate spaces (called pictures) so that a window could 
be specified for a limited set of segments, some of which may already be defined. This re- quirement 
of allowing for a distributed graphics system has become the one major basis for the more significant 
differences between TIGS and the SIG- GRAPH proposed standard. TIGS was designed as a very feature 
rich system. Currently 212 user-callable routines are in TIGS and possible plans for expansion include 
the dis- tributed processing facility, image transforma- tions, software characters (Hershey fonts), 
color, line width~ valuator support, and centered text. Included as primitives are lines, arcs, text, 
dots, and polyline with optional markers. These are available in 2D or 3D and in absolute or rela- tive 
coordinates. The viewing transformations give 2D or 3D windows and viewports with perspective and parallel 
pro- jections very similar to SIGGRAPH's proposed stan- dard. The implementation of the 3D windowing 
is from Puk (3) with slight modifications. A modeling transformation subsystem has been im- plemented 
with a high degree of separation from the rest of the graphics system. The user need never know about 
it or use it. But if it is used, then it gives the expected efficiency by concate- nating the modeling 
transformation with the view- ing transformation. So that the 2D applications programmer does not need 
to know anything about 3D, 2D and 3D transformations are maintained in separate stacks. User supplied 
transformation matrices are 2 x 3 and 3 x 4 instead of the more typical 4 x 4 so the user can't hurt 
himself so easily. Graphics features which are not included are image transformations~ instancing~ 
and animation. Since the first device handler was for the storage tubes~ image transformation support 
was not impl~-nented. Support for animation is not planned. Instancing is not currently supported, and 
is appears not to  be a very cost effective, useful facility in a de- vice independent environment. 
To be device inde- pendent, such restrictions needed to be placed on instancing that it became a toothless 
tiger with high development and maintenance costs in a pro- cessor independent environment. With such 
a large number of user-callable rou- tines, the names of the subroutines and parameters had to be designed 
for ease of learning and ease of use. A symmetric, meaningful set of routine names are used along with 
meaningful parameter names. Various conventions were defined and fol- lowed; e. g., all input variables 
appear before any output variables, names of logical variables always reflect their TRUE conditions, 
subroutine names with a noun and a verb always have the verb first.  2.2 Modes and Attributes In 
order to make TIGS easy to learn, the design depends heavily upon the concept of modality. The programmer 
can set or test for a large set of dif- ferent modes, all of which have a default. Thus,  if the user 
doesn't wish to do anything with a particular mode, the user need never learn or use the associated 
routines. Sesment modes become attributes of segments and can be set and tested. Segment modes are 
inten- sity, character size, character rotation, plot symbol, line style, transformation matrix (absol- 
ute, right-hand relative or left-hand relative), highlightability, visibility, picture limits, pic- 
ture identifier, action when picked (pickability), application specified information, and font. System 
modes are independent of segments; i.e., they do not become attributes of a segment. Sys-  tem modes 
are viewport, system viewport, intraseg- ment picking identifier, locator to use, and appli- cation-supplied 
error routine.  Both system and segment modes can be set and tested via the set mode and test mode routines, 
e.g., SMFONT and TMFONT set and test the font mode. When the first graphic primitive of a segment is 
defined, the current modal settings of all segment modes become s esment attributes of this segment. 
After a se@~nent is closed, the segment attributes can be tested and reset. Thus properties of a seg- 
ment such as intensity, character size, character rotation plot symbol, line style, etc may be modi- 
fied subsequent to the definition of the segment. Additionally segment mode settings may be changed within 
a segment definition, but users are warned that an attempt to reset the associated segment attribute 
may yield unpredictable, device dependent results. Due to the large number of routines that manipu- 
late modes and attributes, a symmetric naming con- vention was adopted to assist users in learning the 
subroutine names. Thus, for example SMFONT, TMFONT~ RAFONT~ TAFONT symbolize set mode font, test mode 
font, reset attribute font, and test at- tribute font.  294  2.3 Picture and Segment Operations  A 
collection of output primitives can be assigned an identification number to create an entity called a 
segment. Segments are defined by the ap- plication program to permit translation, deletion, subsequent 
selection by the operator, etc. A segment consists of primitives 9 possesses attri- butes, and belongs 
to a picture. Attributes are automatically inherited by the segment from the segment mode sets in effect 
when the first graphics output primitive is put in the segment. When a segment is opened~ it belongs 
to the cur- rent mode set picture. Therefore, a segment can belong to only one picture at a time. In 
the most basic case, a segment must be opened and the primitives can be defined without regard for pictures. 
In this case, the segment and its associated primitives would belong to the default picture. Calls exist 
to open, close, extend, de- lete, copy~ rename, and empty segments. (It should be noted that the SIGGRAPH 
proposal does not include the extend capability~ and that one of the major reasons for not including 
was due to the high possibility for error. ExperienCe sup- ports this. Approximately one fourth of the 
more difficult bugs were related to implementing the extend capability. However, it was found to be a 
very powerful user facility and worth its price when supporting old NDFs. Also the alternative of immediate 
visibility was considered to be of ques- tionable worth in a buffered environment with mul- tiple windows 
per segment being possible). When the application has a need to compose dis- plays from more than one 
source in different com- binations a set of pictures can be defined. Since pictures can contain either 
only 2D or only 3D primitives, different pictures must be created for 2D and 3D segments. Calls exist 
to open, close, extend~ delete, or change visibility of pictures. (Note that pickability is not modifiable 
on the picture. This is because another capability, called categories, is planned which would be more 
 powerful. Segments could be put in any category regardless of what picture they were in. The categories 
could have their plckabillty modified, thus modifying the plckability of all segments in the category). 
  2.4 Virtual Input Devices and Interaction  TICS has been designed to handle virtual input de- vices 
much along the lines of Wallace(4). Cur- rently supported are keyboards~ pick devices, lo- cators and 
buttons. A trivial extension would support valuators. Only one keyboard may be used and a call to KEYBRD 
reports back the text string and the n~nber of the characters. Since any pick device can simulate any 
locator and visa versa, they were grouped together so that the user may specify any of them as the 
mode set locator. This mode set locator is then used by the operator when the program next requests 
 locations or picks. The event processing subroutlne~ EVENT~ is called when the application program 
wants to allow the  operator to perform segment pick or function key press events. The terminal operator 
can select one or more segments or function keys. These selections are placed on a queue and are not 
re- ported to the application program until after a terminate action has been performed. A terminate 
action results upon the selection of a segment or function key that has previously been assigned the 
terminate action by the set mode action rou- tine, SMAC. Action types include ignore, recog- nize, and 
terminate (discussed further in section 4). Multiple calls to the event processing rou- tines must be 
made to obtain reports on all rec- ognize or terminate events which are on the event queue. Hmving a 
default of ignoring a pick was found to be extr~nely frustrating to our users. Thus after months of experience 
and frustration, the default for a pick was modified to be a ter- minate action. One or more sets of 
locations may be reported to the application program from a queue of locations. The location processing 
routine, LOGATEj waits for a device-driver defined termination signal before returning any locations 
to the application. Mul- tiple locations are obtained by repeated calls to LOCATE until the last location 
has been reported. If a call to LOCATE is made when the location queue is ~npty~ then a new queue is 
built up auto- matically, and the process continues. A major ef- fect of maintaining event and location 
queues in this manner is to allow for a dramatic reduction of co~nunlcation between processors in an 
intelll- gent satellite or distributed processing environ- ment. 3.0 NEUTRAL DISPLAY FILES  The definition 
of all pictures, segments, windows, and viewports is maintained in the NDF, This NDF would reside on 
either the mainframe, intelligent satellite or remote processor. Since it can be saved and reused later, 
it need not be re-built/ re-transmitted upon logging in at some later time. Additionally to define a 
new window from a host computer, only the new window limits and a few words of identification need to 
be defined/trans- mitted. The NDF could contain pre-deflned forms, last months weather maps, designs 
as of the last log- out, etc. Unlike GPGS (5) an attempt was not made to define the power of the possible 
terminals, and it was left up to the device driver implementor to deter- mine where to maintain the NDF 
and where to split the picture processing pipeline. Thus different device drivers for the same devlce 
might store the NDF on different processors. Each vlewport, w~ndow, picture, and segment defin- ition 
call causes a header to be established on the NDF. This header contains the internal point- ers needed 
to structure the NDF and parameters describing the entity being defined. The segment header also contains 
the current status of its segment attributes. As graphics primitive and set mode calls are made, the 
associated parameters and internal op-codes are added to the structure of the currently open segment. 
 4.0 PLANS FOR DISTRIBUTED GRAPHICS Use of a satellite's processing power will be achieved by use of 
terminal routines (i.e., the local portion of the application program). A seg- ment pick or function 
key press event can initiate the execution of a terminal routine. Segments and function keys may be assigned 
one of the following terminal actions: I. Ignore -do not report the action to the the terminal routines. 
 2. Recognize -report the action to the terminal routines by adding it to the event queue.  3. Terminate 
-report the action to the terminal routines by adding it to the event queue and terminate the building 
of this event queue.  4. Activate -activate the routine (resi- dent in the remote terminal) associ- 
ated wi~h this action.  The entire TIGS graphics package will be treated as a serially reusable resource. 
Thus, if a term- inal routine and the host application program are both active, only one can be making 
calls to TICS. A set of mutual exclusion primitives will be pro- vlded to allow the host and terminal 
to coordinate their use of TICS. Terminal routines and the host application will be able to cormuunlcate 
with one another using send and receive routines. The send routlne will put a string of 16 bit bytes 
in a 'mailbox' which can be retrieved by the other pro- cessor. Tests can be made to see if a message 
is available before waiting with a read request.  5.0 INTERNAL STRUCTURE AND MEASUREMENTS TICS has 
been implemented as a system with four distinct levels. Each level becomes increasing- ly terminal 
specific. The first level consists of user callable routines and their supporting utility routines. 
These are totally terminal in- dependent and represent 39% of the memory require- ments of the current 
code. The second level, which handles the interface be- tween TIGS and the NDF, will vary depending 
upon whether or not the NDF will reside on the host computer or on a remote (mini) computer. This level 
would, for instance, be the same for all terminals keeping the NDF on the host. This level represents 
38~ of the memory requirements. The third level, which processes data from the NDF and interfaces with 
the device handler, will vary with the class of device and the options therein. For example, dumb terminals 
that do not have view- Ing transformations, modeling transformations, arc generators, llne style options, 
text rotation, etc. will use the majorlty of what is currently coded. As the terminal becomes more intelligent, 
less of the code will be needed and different code will be needed to interface to the termlnal's cap- 
abilities. These capabilities are abstracted from particular devices at level three. This level represents 
17~ of the memory requirements using the dumb terminal as a basis for comparison. More intelligent 
terminals would find a corresponding decrease in memory requirements at this level. It should be noted 
that a device handler implementor need not take advantage of the variability at this level. If the 
implementor chooses to take the less efficient, low implementation cost technique, he could perform 
few, if any, modifications at this level and end up with a device handler inter- face that was inefficient, 
but low cost to imple- ment. Conversely, the implementor could try to take full advantage of the terminal's 
capabilities and incur a greater implementation cost. The fourth level, which is the device handler, 
is totally terminal dependent and will vary almost completely from terminal to terminal. The inter- face 
to this level is on the normalized device coordinate level with calls to routines to move, draw, display 
text, return a point from a locator, clear the screen, ring the alarm, and accept tex- tual type-ln. 
This level represents 6% of the code using the Tektronix 401X device handler as a basis. If an application 
program required all of TIGS to be loaded into memory, the TIGS code would require 20K decimal words 
on a CONTROL DATA CYBER. A more typical application would require 12K to 15K decl- mal words for the 
TICS code. Costs to run TIGS will, of course, vary from site to site. The data currently available cow, 
ares TIGS to a predecessor product, LCGT, which was both terminal and computer dependent and lacked many, 
many features that are in TICS; e.g., float- ing point coordinates, 3D, modeling transforma- tions, multiple 
vlewports and windows, the picture hierarchy, and segment attribute modification. The comparison cost 
data indicates that for appli- cations with large drawings and little or no in- teractlon, TIGS costs 
approximately 25% more than LCGT. For applications requiring numerous operator in- teractions the comparisons 
are not as good. TICS currently costs approximately 150% over LCGT costs. The reason for this discrepancy 
is based upon an implementation expediency which was taken. The current system does not compute or use 
segment bounds for nearness calculations in pick process- ing. This is currently being incorporated, 
and significant reductions will, of course, be forth- coming.  6.0 DEVICES SUPPORTED Version 1.0 of 
TICS has been implemented to run on CONTROL DATA 6000 series, CYBER 70 series, and CYBER 170 series 
computers under the NOS and NOS/ BE operating systems. The devices supported in version 1.0 are the 
Tektronix 4006, 4010, 4012, 4013, 4014 and 4015 terminals. Locators supported are the cross-halts and 
the tablet. Work on a CYBER 18 stand-alone version of TICS has begun. Other post-processors are in planning 
or develop- ment phases and will be announced as they become available.  296   7.0 CONCLUSION While 
only one device driver has been implemented thus far, the devlce-independent pre-processor portion of 
TIGS has been implemented to allow for support of a wide range of device drivers and to allow for ease 
of use by both novice and sophisti- cated users. In allowing for expansion to a dis- tributed graphics 
environment, it was felt that several features including pictures and resetting attributes not found 
in many of todays packages needed to be introduced. Additionally, features in existing systems such as 
windowing and event queuing could be modified to cause significant re- ductions in cormnunications. Also 
of importance is that this graphics system is hopefully a beginning in the offerings of large mainframe 
vendors in the area of terminal independent graphics systems.  8.0 ACKNOWLEDGEMENTS The external design 
of TIGS is the work of Robert Heilman, Jean Marchant and Carl Superko. The in- ternal design and code 
is the work of Pat Hansen, Robert Heilman~ Andy Holewa~ Jean Marchant~ Steve Piazza, Carl Superko, Ware 
Washam, and Dave Windmeier. Mike Collins, Jim Foley~ Rich Houston, Dick Puk, and Jack Washam are to be 
thanked for their roles of sounding boards and benevolent ad- versaries. REFERENCES (I) TIGS VI.O Reference 
Manual~ Control Data Corporatlon9 Publication No. 60455940.  (2) "Status Report of the Graphic Standards 
Plan- ning Cormmlttee of ACM/SIGGRAP~'~ Computer Graphics, Vol. II, Number 3, Fall 1977.  (3) Puk, R. 
F. General Clipping on an Oblique Viewing Frustrum. Computer Graphics, Vol. II, Number 2, 1977, pp 229-235, 
SIGGRAPH 77 Proceedings.  (4) Wallace, V. L. "The Semantics of Graphic In- put Devices". Proceedings 
ACM S~nposlum on Graphic Languages, 26-27 April 1976, Miami Beach, Florida, pp. 61-65.  (5) Caruthers, 
L. C., van der Bos, J., van Dam,  A. GPGS~ A Devlce-lndependent General Purpose Graphic System for 
Stand-alone and Satellite Graphics. Computer Graphics, Vol, II, No. 2, 1977, pp. 112-119. SIGGRAPH 77 
Proceedings. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807405</article_id>
		<sort_key>298</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>52</seq_no>
		<title><![CDATA[Core standard graphic package for the VGI 3400]]></title>
		<page_from>298</page_from>
		<page_to>300</page_to>
		<doi_number>10.1145/800248.807405</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807405</url>
		<abstract>
			<par><![CDATA[<p>Implementing the 1977 Core System standard proposal of ACM/Siggraph for a state-of-the-art microprogrammable refresh display system presents a number of design tradeoffs. Thus, there are areas of contention between a strict interpretation of the standards and the advanced capabilities of the display that led the user to purchase such a system in the first place. These methodological differences lead to a &#8220;loosely defined&#8221; Core system, which adheres to the spirit of the standards without sacrificing display performance.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Display system]]></kw>
			<kw><![CDATA[Graphics package]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Graphics packages</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Standards</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10011007.10011006.10011050.10011017</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Context specific languages->Domain specific languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010919.10010177</concept_id>
				<concept_desc>CCS->Computing methodologies->Distributed computing methodologies->Distributed programming languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P331800</person_id>
				<author_profile_id><![CDATA[81332512146]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ken]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Levine]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Vector General, Inc., Woodland Hills, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Status Report of the Graphics Standards Planning Committee of ACM/Siggraph. Proceeding of Siggraph 77, San Jose, July 77.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 CORE STANDARD GRAPHIC PACKAGE FOR THE VGI 3400 Ken Levtne, Vector General, Inc., Woodland Hills, CA. 
 ABSTRACT Implementing the 1977 Core System standard proposal of ACM/Stggraph for a state-of-the-art 
microprogram- mable refresh display system presents a number of design tradeoffs. Thus, there are areas 
of contention between a strict interpretation of the standards and the advanced capabilities of the display 
that led the user to purchase such a system in the first place. These methodological differences lead 
to a '~loosely defined" Core system, which adheres to the spirit of the standards without sacrificing 
display performance. Keywords and Phrases: Graphics Package, Display System CR Categories: 4. 39, 8. 
2 INTRODUCTION The main focus of this paper will be to address the problems encountered in implementing 
the 1977 Core System standard proposal of ACM/Slggraph for a mieroprogrammable calligraphic refresh display 
sys- tem. The advanced hardware features embedded in the display system require a liberal interpretation 
of the standards: that is, a strict interpretation would lead to an unacceptable loss of performance. 
Thus, we are lead to what may be termed a 'rioosely de- fined" Core system. It is believed that this 
approach retains the flavor, methodology and major advantages of the Core approach, while allowing the 
user to take advantage of the advanced features that led him to buy a '"nigh powered" display system 
in the first place. THE STATE OF THE ART The latest generation of refresh calligraphic display systems 
presents a variety of features that allows much of the work to be done in the display system hardware/ 
firmware that previously fell to the software package. These features allow the central processor-display 
processor interaction (i. e., the display list) to be at a higher level than was previously possible. 
Further-more, much of the interactive device communication and image transformation processing burden 
is re- moved from the domain of the central processor. So, the requirements of a display software package 
are at a different level than, for instance, one written for a plotter. The Vector General Series 3404 
is an example of such a display system. It provides facilities for not only graphic programming on the 
object/subobJect level, with full image transformations, including: rotation, displacement, scale, zoom, 
pan, clip, window, viewport, and perspective; but also full inter- active device support, requiring no 
central processor intervention, and a facility for defining display oper- ands to be (evaluated as) the 
value of a display regis- ter, device register, display list cell, or external (CPU memory) table entry. 
Other examples of dis- play systems that provide some of these facilities include the Evans and Sutherland 
Picture System 2 and the Adage 430. The software system, FGP34, which is oriented to the Core standard, 
may be divided into a device- independent level and a device-dependent level. The major design goal is 
for the user to be able to ignore such device-dependent features as display list construc tion, display 
processor instruction set and the device handler. Device independence promotes user program portability, 
and the package is implemented as a li- brary of FORTRAN-callable routines with the code breadboarded 
in FORTRAN to insure overall package portability. Although the requirements of interactive graphics require 
actual implementation in machine language, transporting the package to another family of computers requires 
only a recoding of the library and a new device driver. In the context of the demands of real-time interactive 
graphics, the above was determined to be the most favorable method of complying with the major Core objectives 
of program (and programmer) portability, device-independence and machine independence. Furthermore, FGP34 
is based upon the sixfold Core model of the graphics world: (1) the separation of input and output; (2) 
the use of a (floating point) world coordinate system, a (floating point) normalized de- vice coordinate 
system, and an (integer) device co- ordinate system; (3) the use of a display file; (4) the partition 
of a display file into segments; (5) the use of 298 viewing transformations to convert world coordinates; 
and (6) the use of image transformations on the device coordinate representation of display objects. 
This was attempted within the general programming principles of cleanliness, consistency, completeness, 
orthogon- ality and lack of (process) interaction and side effects. THE IMPLEMENTATION The bulk of FGP34 
is designed to conform with the Core system standard proposal. For example, the input primitives and 
functions defined in Chapter 6 of the proposal have been followed very closely, e.g., devices may be 
enabled, events may be flushed, asso-ciations may be defined between event-causing devices and sampled 
devices. The list of primitives and func- tions not actually implemented at this time is very short (e. 
g., no line width attribute and no markers ex-cept simple points). FG34 differs from the proposed standards 
in two important ways: divergence, for speed optimization and amplification for enhancement. Some features 
are implemented in such a manner as to conform with the display hardware, where doing so would allow 
the user to take advantage of the speed ad- vantages therein. The most notable example of this is the 
definition of perspective, which is couched in 3404 language (i. e,, a register is loaded which varies 
the view from parallel to 90 degrees divergent as the value is varied from zero to maximum). Another 
register may be loaded to vary the degree of intensity depth cueing (Z-axis modulation) from uniform 
density (value equals 0) to maximum intensity variation from bright frentto dim rear (value equals maximum). 
The second major area of difference is in the imple- mentation of features not supported by the proposed 
standards. These features have not been implemented by the proposed '"nooks and escapes" facility, for 
reasons of efficiency. The most important of these are facilities for picture building and editing, dynamic 
displayvariables, and the addition of a file mainten- ance package. PICTURE BUILDING AND EDITING I 
One may view the graphics display scene as being com- posed of a picture, this picture in turn is made 
up of sub-pictures, consisting of a set of images that, in turn, consist of groups of primitive elements. 
Further, image transformations may be applied to these sub- picture images and detection (,picking") 
may be done at the (group of) primitive(s) level. Judicious use of this model requires the ability to 
build sub-pictures, images and groups of primitives, with names being applied to these constructions. 
Such name constructs are natural candidates for further, later building (i. e., reopening), for replacement 
(i. e., emptying and rebuilding), and for deletion. The notion of images being composed of sub-images 
with further transformations leads to the concept of nesting of im- ages. Thus, a tree structure is defined 
with the picture at the root; descending the tree one composes trans- formations; with the '~eaves" of 
the tree being com- posed of the groups of primitives. FGP34 supplemente the proposed standard system 
by allowing grouping of (commonly named) primitives and allowing segments (l. e., images) to be reopened, 
emptied, and deleted, and by allowing segments (and their transformations) to be nested. It is felt that 
this "extension" to the standard is a pre- requisite to successful picture manipulation in a real- time 
interactive graphics application. DYNAMIC VARIABLES There are many circumstances in graphics program- 
ming where it is desirable to couple a display variable to the value of a device, a display processor 
parameter, or an entry in an external (i. e., CPU memory) table, etc. Examples of this include varying 
picture intensity depth cueing by the value of a valuator, or setting the center of a pick device window 
with the X and Y coor- dinates of a locater. The 3404 display system allows display list operands to 
be defined as the value of de- vice registers, display processor registers, and CPU memory locations. 
These values are automatically updated each "refresh cycle" (e.g., 60 Hz) by the dis- play processor. 
This facility allows the above require- ment to be satisfied with no CPU intervention. To implement this 
feature, FGP34 allows the user to define variables to be of the following types: display register, or 
device register or external, (much as FORTRAN defines variables to be integer or real). Subsequent usage 
of these variables in display calls will be translated by FGP34 into the requisite operands in display 
instructions to implement the desired feature. FILE MAINTENANCE PACKAGE The ability to create picutres 
of objects, save them on backing store, and later recall them is as fundamental to a graphics package 
as is the analogous facility in a program development system. The user may wish to save a given picture 
or one or more sub-picture objects to be later recalled by name. FGP34 implements suoh a facility; calls 
are defined to save a sub-picture object or a whole display scene and to recall such an object or scene. 
In addition, the ability to define sub-pictures and invoke them from the main picture (i. e., treating 
the picture as a graphics program and the invocations as "calls," analogous to calls in machine language) 
demands the ability to scan the present scene for calls to sub-pictures that exist in a library (this 
is analogous to dynamically loading by referencing library-based subroutines). The implementation of 
these features is in machine- independent ASCII format, allowing both the editing of saved pictures and 
portability to other installations. 299 APPENDIX: THE SERIES 3404 GRAPHICS DISPLAY SYSTEM The interface 
between the Series 3404 Display System and the host computer consists of a DMA channel for the transmission 
of the user's display list, a pro- grammed I/O channel to read/write device and display registers and 
status information, and an interrupt channel. The display list is interpreted by the Graphics Pro- cessor 
Unit (GPU) which outputs the refresh list to the Refresh Buffer Unit (RBU). The display list pro- cessed 
by the GPU consists of display programs that are accessed through an indexed directory resident in the 
host's memory. An object's display list consists of links to sub-pictures, local variables and actual 
dis- play code, followed by a return instruction that returns to the calling picture, or, at the top 
level, ends the frame. The display list is used to move the beam, create lines, characters, arcs and 
circles, cubic curves and rectangles, and to create arbitrary RBU code. One may also jump in list, call 
or return from sub-pictures, nest and push/pop display and trans- formation parameters, load display 
and device system registers, perform display image transformations, clip, window and viewport date, perform 
perspective and intensity depth cueing, and perform the mapping from user space to display space. The 
refresh list is accessed by the Display Control Unit (DCU) during each refresh cycle to recreate the 
displayed picture on the view surface. This may occur simultaneously with the generation of the now refresh 
list without display interference. The DCU processes the refresh list, routes the refresh data to the 
Vector Generator Unit (VGU), the Font Generator (FGU) and the Monitor Control Unit (MCU) and generates 
the control signals required to display these data. The VGU is a high-speed analog vector generator, 
which utilizes a smoothing technique during incre- mental vectors to draw curved lines of the display 
surface. The FGU uses a programmed ROM and "stroke" characters to provide full character and editing 
symbol support. The MCU is used to select the desired (one of 4 or 8) monitor and provides the unblanking 
and intensity signals required. Interactive devices supported by the Series 3404 Dis- play System include 
Alphanumeric Keyboard, Light Pen, Data Tablet, Function Switch Box with associa- ted lights, Control 
Dials and Joystick. The values input from these devices may be read by the host computer or used as arguments 
in the display list in- structions. The keyboard, light pen, data tablet and function switch box, as 
well as the DCU and GPU may generate interrupts to the host computer. The joy- stick and data tablet 
may be used as window control for the hardware "pick" feature. Selected elements may be highlighted or 
used to halt the display and in- terrupt the host CPU. Reference: Status Report of the Graphics Standards 
Planning Committee of ACM/Siggraph. Proceeding of Siggraph 77, San Jose, July 77. 300 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807406</article_id>
		<sort_key>301</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>53</seq_no>
		<title><![CDATA[DIGRAF&#8212;a FORTRAN implementation of the proposed GSPC standard]]></title>
		<page_from>301</page_from>
		<page_to>307</page_to>
		<doi_number>10.1145/800248.807406</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807406</url>
		<abstract>
			<par><![CDATA[<p>A machine-independent FORTRAN implementation of the GSPC proposed standard is presented. DIGRAF (<underline>D</underline>evice <underline>I</underline>ndependent <underline>GRA</underline>phics from <underline>F</underline>ORTRAN) has been designed to closely parallel level-3 of the 'CORE' system. The present implementation allows portability to any computer with a FORTRAN compiler and a word length of at least 16-bits.</p> <p>Several CORE system design issues are discussed from the implementor's viewpoint. A breakdown of the functional modules reinforces the portability aspects. Special features of the user interface are presented. A storage structure for retained segments is presented with a review of the memory management alternatives. The device-dependent interface for two common classes of devices is discussed. Finally, the design and data structure techniques used to implement several CORE functions is presented.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Device independence]]></kw>
			<kw><![CDATA[Machine independence]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Graphics packages</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Graphics data structures and data types</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Standards</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.3.2</cat_node>
				<descriptor>FORTRAN</descriptor>
				<type>P</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011050.10011017</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Context specific languages->Domain specific languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011008.10011009</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->General programming languages->Language types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010919.10010177</concept_id>
				<concept_desc>CCS->Computing methodologies->Distributed computing methodologies->Distributed programming languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010394</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics file formats</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Reliability</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31033284</person_id>
				<author_profile_id><![CDATA[81100234555]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Warner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Colorado Computing Center, Boulder, Colorado]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P332287</person_id>
				<author_profile_id><![CDATA[81100268828]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Margaret]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Polisher]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Colorado Computing Center, Boulder, Colorado]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P333427</person_id>
				<author_profile_id><![CDATA[81100227130]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[N.]]></middle_name>
				<last_name><![CDATA[Kopolow]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Colorado Computing Center, Boulder, Colorado]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Blinn, J., Goodrich, A. C., "The Internal Design of the IG Routines," Proceedings of SIGGRAPH '76, Philadelphia, PA, (SIGGRAPH Quarterly, Vol. 10, No. 2, Summer 1976).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Reed, T., "Intermediate File Structure," (available from T. Reed, LASL, Los Alamos, NM, 87545, 1978).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Ryder, B. G., "The PFORT Verifier," Computer Graphics, Vol 4, No. 4, 1974.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Sproull, R., "The OMNIGRAPH Graphics System," Xerox PARC, Palo Alto, CA.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Warner, J., "DIGRAF User's Reference Guide," University of Colorado Computing Center, Boulder, CO, 80309.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563881</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Wright, T., "Machine-Independent Metacode Translation," Proceedings of SIGGRAPH '77, San Jose, CA, (SIGGRAPH Quarterly, Vol. 11, No. 2, Summer 1977).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Wright, T., "BSR X3.9 FORTRAN '77: DPANS Programming Language FORTRAN," Technical Committee X3J3 - FORTRAN ANSI, June 1977.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Wright, T., "Status Report of the Graphics Standards Planning Committee," SIGGRAPH Quarterly, Vol. 11, No. 3, Fall 1977.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 DIGRAF --A FORTRAN Implementation of the Proposed GSPC Standard James R. Warner Margaret A. Polisher 
Robert N. Kopolow University of Colorado Computing Center Boulder, Colorado 80309 ABSTRACT A machine-independent 
FORTRAN implementation of the GSPC proposed standard is presented. DIGRAF (Device~ndependent GRAphics 
from FORTRAN) has been designed to closely parallel level-3 of the 'CORE' system. The present implementation 
allows portability to any computer with a FORTRAN compiler and a word length of at least 16-bits. Several 
CORE system design issues are discussed from the implementor's viewpoint. A breakdown of the functional 
modules reinforces the portability aspects. Special features of the user interface are presented. A storage 
structure for retained segments is presented with a review of the memory management alternatives. The 
device-dependent interface for two common classes of devices is discussed. Finally, the design and data 
structure techniques used to implement several CORE functions is presented. KEYWORDS: Device Independence, 
Machine Independence. I) INTRODUCTIO~ as the ability of a software system to run on a variety of different 
computers that support the DIGRAF ('D'evice 'l'ndependent 'GRA'phics from 1966 standard of ANSI FORTRAN 
IV. With certain, 'F'ortran) is the machine-independent system of localized, machine dependent modifications, 
DIGRAF FORTRAN-callable subroutines for generating and will run on any 16-bits-per-word (or greater) 
interacting with computer graphics imagery at the computer with 40,000 words of program memory. University 
of Colorado Computing Center (UCC). DIGRAF has been developed in accordance with the Several aspects 
of the current DIGRAF implemen- functional specifications for a standard, device- tation, as it relates 
to the GSPC standard, are independent graphics system (i.e., the 'CORE' discussed in the ensuing sections. 
Section II system) as presented in the 'Status Report of the overviews the design methodology and the 
basic Graphics Standards Planning Committee' (GSPC), of modules that make up the system. Section III 
con- ACM SIGGRAPH, July 1977 [8]. siders several factors of the user interface, including certain implementation 
issues not fully DIGRAF has been implemented with three basic clarified in the CORE. design criteria. 
Graphics device independence was the first objective. In the strictest sense this Section IV discusses 
alternatives for imple- implies that any FORTRAN graphics program that menting a segmented display file 
(SDF) and the invokes DIGRAF routines to build, view, and/or advantages and limitations of the actual 
SDF interact with a graphics image will run on any implementation within DIGRAF. supported graphics device 
without recompilation. Currently supported devices include a drum plotter The concent of separate sets 
of device depend- (CALCOMP 663), microfilm recorders (CDC 280/284; ent routines (DDR's or 'device drivers') 
for each III FR80), storage tubes (TEKTRONIX series; supported graphics device is presented in Section 
COMPUTEK 400/20), and graphics simulation on line- V. This section also discusses alternatives for printers. 
Concomitant to the goal of device- interfacing the DDR's to DIGRAF. The structure of independence was 
an effort to optimize the graphics two different drivers for passive and storage tube capabilities of 
all supported devices. devices is presented. Close adherence to the CORE specifications was Section 
Vl details the DIGRAF implementation of the second design goal. DIGRAF is currently several specific 
functions including: text, the implemented at level-3 (Interactive) of the CORE viewing transformation 
pipeline, pick-sensitive functional specifications. DIGRAF does not support segments and PICK-ID's, interactive 
input, error image transformations. processing, and a debugging facility. The final design objective 
was to provide a II) OVERALL STRUCTURE hlgh-level of machine-independence in the DIGRAF implementation. 
DIGRAF defines machlne-lndependence The modular implementation Of DIGRAF is shown in Figure II-I. User 
Interface Machine-Independent Routines __ ~ Initialization ~ . and (' J'-Mod~le) ~ / ~upport (' I' -Module) 
 Device SDF Driver Routines Routines ( ' DD' -Module) ( ' K' -Module) I Storage ] I Manipulation 
Ro u t ine s (' L' -Nodule) ] ! Machine-Dependent Initialization and Support I (' M' -Module) Figure 
II-I IMPLEMENTATION STRUCTURE OF DIGRAF The 'J'-module routines correspond to the func- tional capabilities 
of the CORE. A FORTRAN program invokes only those routines in this module. Addi- tional discussion of 
the user interface follows in Section III. The 'l'-module routines provide the computa- tional backbone 
for the user interface routines. Many of the 'J'-module routines simply CALL corresponding 'l'-module 
routines to carry out a CORE function. The primary objective of the 'l'-module is to make most of the 
computational burden and data structure coordination one level removed from the user interface. Utility 
func- tions such as output message handling, building the composite viewing transformation, and tracing 
the segmented display file are done within the 'l'-module. The 'DD'-module routines provide the device- 
dependent interface between the virtual graphics device the user sees and some physical graphics device. 
A separate 'DD'-module must be imple- mented for each supported device. All device drivers have the same 
entry point names. Actual implementation varies widely as a function of the device class (passive, storage 
tube, refresh). Device drivers are further discussed in Section V. The segmented display file ('SDF') 
is a data structure for retained segments. The 'K'-module is the implementation-independent interface 
between the 'J'-module or 'l'-module routines that store/ retrieve information about regained segments 
and the implementation-dependent storage structure that actually maintains the SDF (the 'L'-module). 
Section IV elaborates on the SDF constructs within DIGRAF. The Segmented Display File Routines store/ 
 retrieve segment information within/from fixed size blocks of main memory. The allocation and deallocation 
of these blocks is done within the 'L'-module. The implementation of this module will vary with the capabilities 
of the host computer, operating system, and run-time FORTRAN support routines. The simplest implementation 
is to partition a fixed size array into fixed size blocks. DIGRAF has adopted this scheme. Virtual-memory 
machines can amend this implementation to dynamically allo- cate and release blocks of memory. Memory-bound 
systems could alternatively implement a paging scheme directly within the 'L'-module. It is impractical, 
if not impossible to imple- ment a totally machine-independent large-scale subroutine package. FORTRAN 
data initialization protocols, character handling, and bit manipula- tion vary among computers regardless 
of any 'standardizing coding practices' followed by the implementor. The 'M'-module isolates all potentially 
machine- dependent procedures. Each implementor must review and modify the 'M'-module routines for compatibil- 
ity with the target machine. The 'M'-module also contains certain routines that, while implementable 
in standard FORTRAN, would be much more efficient if coded in assembly language. Many of the lower- level 
SDF manipulation routines fall into this category. III) THE USER INTERFACE Two fundamental criteria 
have governed the definition of the DIGRAF user interface: i) adhere as closely as possible to the functional 
capabili- ties description of the CORE; 2) provide easily remembered ~mnemonic routine names within the 
bounds of FORTRAN naming conventions. The sentinel character 'J' (hence, 'J'-module) was chosen to preface 
all user-callable DIGRAF routines. The GSPC report left the issue of segment naming to the discretion 
of the individual imple- mentors. Several conventions could be adopted. Literal names provide mnemonic 
segment identifi- cation and are thus quite useful in tracing and debugging. Unfortunately, prior to 
the 1977 ANSI FORTRAN standard [7], character manipulation within FORTRAN has been awkward and highly 
machine- dependent. Also, 16-bit machines can only store two characters per computer word, too few for 
meaningful mnemonic names. DIGRAF permits 15-bit positive integers as segment names. This representation 
is accepted and unambiguous on all computers. Beyond the issue of what are allowable segment names is 
who provides the names; the user or the graphics system. Explicit naming by the user is probably the 
more conventially accepted scheme. System naming allows a user program to run under (or in conjunction 
with) a monitor program, where both the user program and the monitor will create their own unique names. 
 DIGRAF provides both user naming and system naming via the following scheme. If the user 302 opens 
a retained segment by: CALL JOPEN (NAME) {0 < NAME < 30000} the NAME is used exactly as passed. NAME 
> 30000 is treated as an error. If the user opens a seg- ment by: NAME 1 = - CALL JOPEN (NAME) the 
system returns a unique name in the range: {30000 < NAME < 32768}. The above scheme implies that a 
user may explic- itly create only those segments < 30000, but may reference (e.g., query, change segment 
attributes, delete) any segment up to 32767. This does not preclude the user program from purging segments 
created by a monitor program, but it makes such an operation much more likely to be intentional, rather 
than accidental. DIGRAF defines the default normalized device coordinate (NDC) space as {-I.0 ~ (NDC-X,NDC-Y) 
! +i.0} vis-a-vis the CORE default of {0.0 ~ (NDC-X, NDC-Y) ~ +i.0}. The primary rational for {-I to 
+I} is that the user is most often inter- ested in the center of the display area and would prefer to 
correlate the origin of NDC-space with the center of the display. Splitting the virtual device into quadrants 
(a common Computer Aided Design operation) is more natural with a center- oriented display. It is also 
more common to scale the screen image (NDC-space viewport) about its center rather than the lower left. 
 IV) THE SEGMENTED DISPLAY FILE (SDF) The segmented display file is the data struc- ture for maintaining 
retained segments within DIGRAF. While the GSPC does not explicitly require a SDF, the CORE implicitly 
requires some means of storing retained segments. The SDF may be totally hidden from the graphics programmer. 
The programmer knows that non- retained segments are immediately output to the active display surface 
and are 'lost' when a new- frame-action occurs on the display. The programmer assumes that the retained 
segments are in some way stored and updated by the system. The programmer also would like to assume that 
any number of retained segments may be created and maintained without concern for the size of any internal 
segment data structure. In building a d~ta structure for retained segments, it seems logical to associate 
a fixed- size information block with each segment. Certain information must be maintained for each 
segment: I) the segment's name; 2) the current status of the visibility, detectability, and highlighting 
segment attributes. Depending on the capabilities of the active display surface and the mode in effect 
at the time of segment creation (e.g., within or out- side a batch-of-updates), additional information 
 may be required to facilitate efficient manipula- tion of retained segments: I) a flag indicating if 
 the segment is currently visible on the active display; 2) a flag indicating if the segment has been 
changed since the last time it was sent to the display; 3) the minimum and maximum NDC-space bounds 
of the segment (to simplify picking). At the time a segment is opened, the state of the global segment 
attributes and mode of display (e.g., batch-of-updates) will determine the initial values of parameters 
in the segment header block. Primitive attribute values are reset to their defaults. These default attribute 
values may optionally be stored as part of the segment header. The Segmented Display File within DIGRAF 
 The SDF within DIGRAF is a data structure of dynamically allocated, fixed-sized "blocks." Each block 
consists of an implementation-dependent number of 32-bit "words." Each word is composed of two 16-bit 
"nibbles" of data. The machine- dependent routines ('M'-module) allow the imple- mentor to map DIGRAF's 
"blocks, words, and nibbles" into the corresponding physical word size of the target machine. The layout 
of the retained segment header block is shown in Figure IV-I. The first nibble of the first word of each 
block ('NEXT' field) points to the next block (if any) within the segment. 'COLOR', 'INTENSITY', 'SPOTSIZE', 
'LINESTYLE', and 'PICK-ID' are the default primitive attributes that are to be in effect when the first 
output primitive is entered into the segment. NEXT COLOR I INTENSITY PLINK SLINK control SPOTSIZE 
PICK-ID I LINESTYLE bits XMIN XMAX YMIN YMAX control bits 0 -PICK 4 -CHANGE 1 -VISIBLE 5 -PICK-FLAG 
2 -HIGHLIGHT 6 -(unused) 3 -PAINT 7 -(unused) Figure IV-I RETAINED SEGMENT HEADER BLOCK 'PICK', 'VISIBLE', 
and 'HIGHLIGHT' are single- bit flags indicating the current values of the dynamic segment attributes. 
'PAINT' and 'CHANGE' are single-bit flags indicating if the segment is currently visible (e.g., 'painted') 
on the active display and if the SDF representation of the segment has been modified since the last time 
the segment was painted. 'PICK-FLAG' indicates if the segment contains any non-default PICK-ID's. 'XMIN', 
'XMAX', 'YMIN', and 'YMAX' define the NDC bounds of all primitives within the segment. These bounds improve 
efficiency of the pick func- tion at the segment level. 'PLINK' and 'SLINK' are used to implement the 
SDF as a two-way linked list. A segment name table is stored as a separate linked list. Each name entry 
in this table points to an associated segment header block. The segment header is built at the time 
of the CREATE-SEGMENT function ('JOPEN'). Information about the segment is added to the SDF when: i) 
an output primitive is invoked (move, line, polyline, marker); 2) a primitive attribute is changed (color, 
intensity, spotsize, linestyle, or PICK-ID); 3) a text primitive is invoked; or 4) the segment is closed. 
 Segment data is stored as one or more nibbles always beginning on a word boundary. Each parcel of information 
consists of either a 1-bit move/draw opcode or an optional 4-bit expanded opcode with associated data.Thls 
structure parallels the machine independent metacode developed by Tom Wright [6]. A comparable "Intermediate 
File Structure' has also been developed and adopted jointly by Los Alamos Scientific Labs, Sandia Laboratory, 
and Kirtland Air Force Base [2]. While the DIGRAF metacode representation has decided advantages in 
both ease of implementation and portability, several potential shortcomings should be noted. NDC values 
are mapped from the real domain {-I.0 ~ (X,Y) J +~.0} into the integer range {0 J (X,Y) j 32767}. These 
integer values are stored in the SDF. While this resolution will accommodate most devices, certain flat-bed 
plot- ters (with 0.001 inch resolution) and developing laser displays will accept greater precision. 
Note that while a two-dimensional NDC-space may be compactly represented with the above scheme, intermixing 
two- and three-dimensional coordinates could be awkward to represent. The fixed-size block data structure 
is probably the simplest mechanism for dynamically allocating and deallocating space for the doubly-linked 
SDF. However, pointer overhead can become an efficiency factor if the block size is chosen too small, 
while unused space within small segments may accrue if the block size is too large. The first time a 
text primitive is invoked with- in a segment, the current character size, spacing, and font are stored 
as primitive attribute changes. These are followed by the number of characters in the text string, and 
the string, itself. All characters are stored in 8-bit ASCII regardless of the host machine's character 
representation (e.g., CDC display code, EBCDIC). The SDF only supports absolute moves and draws. All 
relative moves and draws are converted to absolute locations in NDC-space before being stored. Polyline 
is a sequence of draws. V) DEVICE DEPENDENT ROUTINES As described above, DIGRAF generates images targeted 
for an idealized virtual device with NDC- space of {-i.0 ~ (X,Y) ~ +i.0}. The device- dependent routines 
('DD'-module or DDR's) map NDC primitives and primitive attributes onto a physic- al display. The DDR's 
also coordinate all logical input from interactive displays. Each supported device has an associated 
DDR. All DDR's have the same interface to the device- independent modules. Prior to execution of a graphics 
program, the user loads the DDR of the graphics device that will be used during the run. Subsequent runs 
will load different DDR's for dif- ferent graphics devices, without having to recom- pile the graphics 
program. The most important objective in developing the DDR's for DIGRAF was to maintain a uniform inter- 
face to the device-independent DIGRAF modules for all supported devices. As a result, new device drivers 
for a wide range of devices should be simple to design and implement. To keep the drivers simple while 
maintaining a uniform interface requires that the DDR's handle only device dependent functions. This 
requirement puts much of the computational burden on the device-independent modules, obviating certain 
opti- mization strategies that could take place in the driver. For example, high quality text is stroke- 
generated in the device-independent modules, such that the driver only sees a sequence of clipped moves 
and draws. Each DDR maintains a table of device character- istics such as display area aspect ratio, 
physical address space, and the class of the device (passive, storage tube, refresh). The device- independent 
modules can do some optimization and error checking based on these characteristics (e.g. treating a user's 
input request from a passive device as an error) without any additional intelligence in the drivers. 
 Two example drivers are briefly discussed below. I) FR80 Microfilm Recorder (class: High-Performance 
Passive) Like many passive devices, the FRSO normally runs off-line, using a mini-computer to process 
a device-dependent plot file. .The FR80 has its own metacode based upon 18-bit words. The device supports 
a full range of hardware primitive attri- butes, including intensity, spotsize, dashed lines, color, 
and 64 character sizes. The display surface has a resolution of 16384-x-16384. The format of the FR80 
driver is shown in Figure V-I. The 'DD'-interface to the device- independent routines is relatively simple. 
The 'DD'-routines map the 15-bit integer NDC's into the range for the device and invoke the FR80 metacode 
routines to build the device-dependent plot file. Some intelligence is required by the DD-routines for 
text conversion, computation of character size and spacing, and for mapping the 8-bit color attri- bute 
into the proper number of red, green, and blue color filter hits. The key aspect of the FR80 DDR is 
its division into two modules. The first module interfaces to the device-independent routines~ mapping 
NDC data and attributes into device-dependent data; the 304 second module formats this device-dependent 
data into the proper metacode for the device, builds fixed-size display code buffers, and outputs these 
buffers to the plot file on a secondary storage medium. The FR80 driver is highly portable with only 
a few assembly language routines for bit-manipulation efficiency. IDevice-lndependent Routines I ......,.......I.. 
..... ......... Device-lndependent I Interface ('DD'-Routines) I ~RS0 Metacode~ Display [ Routines 
I I Code Buffer Figure V-1 FR80 DDR 2) TEKTRONIX 4006/401x (class: S£orage Tubes) Like the FR80, 
the Tektronix series of drivers (Figure V-2) utilizes a support module of metacode routines that accepts 
integer display screen co- ordinates {0 ~ X J 1023; 0 < Y ~ 780} and ASCII characters from the higher 
level DD-module and builds a display code buffer that it outputs over standard communication lines to 
the graphics terminal. Operating system protocol and communi- cation line bandwidth will determine the 
size and format of the display code buffer. Ideally, the buffer will be small enough that the user experi- 
ences no significant delay as a buffer is trans- ferred from the host over communication lines to the 
terminal. Logical coordinate input (e.g., from the cross- hair cursors) is enacted by a READ from the 
termi- nal. The support module routines perform the READ and obtain the display screen coordinates. The 
DD-module then converts the display screen coordi- nates into normalized device coordinates and returns 
them to the device-independent modules. The pick function simply returns the integer NDC point that was 
picked. The device-independent routines are then responsible for traversing the segmented display file 
to resolve the segment and PICK-ID that were actually detected. Keyboard and button input are emulated 
by READ's from the terminal. Implementation dependencies may be isolated to the I/O routines within 
the support module. Cer- tain efficiency enhancements are implemented with- in the support module to 
utilize hardware vectoring capabilities in optimizing transmission (e.g., for vertical and horizontal 
lines.) The 4014 driver in extended graphics mode supports hardware dashed lines and multiple character 
sizes. The 4006 and other 401x drivers ignore all primitive attributes, except linestyle; dashed lines 
are always gener- ated in software by these drivers. [DeviC~o~ne~ndent I .. .... ....,..... ~....... 
,. j....... I Device-Independent I Interface ('DD'-Routines) I I Tektronix ~Graphics and I/O ! Buffer 
Routines .Figure V-2 Tektronix DDR  (VI) IMPLEMENTATION OF SPECIFIC FUNCTIONS This section describes 
certain design and data structure techniques used to implement several CORE functions within DIGRAF. 
 Text  Low quality text is implemented on a best-fit basis for character size and spacing using the 
hardware character generator of the active display. Medium quality text does a best-fit on size with 
explicit moves between each character to exactly adhere to the character spacing attribute. The SDF stores 
the font, size and spacing for both low and medium quality. Low quality then stores the number of characters 
in the string followed by the 8-bit ASCII representation of the characters. Medium quality uses the same 
metacode representa- tion as low-quality for text, but characters are stored individually. Each medium 
quality charac- ter is preceded by a 3-D move, corresponding to the character spacing attribute. The 
move is pro- cessed through the current viewing transformation and is stored in the SDF as a 2-D NDC 
move. With this scheme for medium quality text, exact 3-D spacing between characters and accurate string 
concatenation is guaranteed even with a perspective viewing transformation in effect. Following the 
theme that the user is thinking in terms of high quality text, DIGRAF always updates the CP as if high-quality 
text had been generated. This also removes any device dependency from the updating of the current position. 
 On almost all devices, high-quality text must be stroke generated in software and passed through the 
viewing pipeline to be manifested in full three-dimensionality, including character plane and perspective, 
on the active display surface. The only implemenetation question is whether this stroke generation is 
done at the device-independ- ent level or the DDR level. Two advantages favor the DDR-level: first, 
the SDF representation of high-quallty text is highly compacted in that only the ASCII characters are 
stored; second, the transmission can be substan- tially reduced on displays that can maintain a character 
stroke table within a satellite proces- sor. The primary disadvantage is that each DDR must now have 
access to the full 3-D viewing trans- formation matrix and character orientation matrix in order to map 
the relative moves and draws of the character stroke table first into transformed world coordinates, 
and finally into NDC moves and draws. Each DDR would have to perform essentially the same device-independent 
conversion function. While the DDR-level alternative has merit, the simplicity of having the actual 
strokes stored in the SDF has been chosen for implementing the high quality text within DIGRAF. Note 
that storage overhead exists only for retained segments. High quality text within non-retained segments 
is immediately output via transformed 3-D moves and draws to the active device without consuming any 
 storage. Viewing Transformation Pipeline  The virtual camera model of the CORE provides a flexible, 
complete scheme for viewing three-dimen- sional imagery from any point in the World coordi- nate system. 
As the user builds the viewing transformation by a series of mode setting calls, DIGRAF simply updates 
an array of viewing param- eters. Whenever a segment is opened, DIGRAF checks if the viewing specification 
has been altered since the last open segment (or initialization). If any parameters have been changed, 
the composite viewing transformation (a 4-x-4 matrix) and the viewing system clipping boundaries are 
recomputed. The composite viewing matrix is a concatenation of the user's modeling transformation matrix 
(if any) and the viewing matrix. This composite trans- formation remains in effect throughout the open 
 segment.  At the time a segment is opened, the 'dimen- sionality' of the viewing transformation is 
determined. By default, the viewing transformation is 2-D, that is, only a window to viewport mapping. 
The 2-D viewing pipeline is considerably more efficient than the full 3-D algorithm. Table VI-I lists 
those viewing parameter values thst alone, or in combinations, will force world-coordinate primitives 
through the 3-D pipeline. TABLE VI- 1 - Normal vector not equal (0.,0.,i.) - Up-vector not equal 
(0.,i.,0.) - View-site not equal (0.,0.,0.) -A perspective projection - An oblique parallel projection 
 - A modeling transformation in effect -Hither (i.e. front) clipping in effect -Yon (i.e. back) clipping 
in effect 3-D Viewin~ Determinants  By default the CORE defined NDC-space is square (-I to +i in DIGRAF). 
Unfortunately, the maximum viewable area on most graphics devices is nonsquare. Most storage tubes are 
rectangular, and drum plot- ters are "infinitely" large in the X-direction. By default, DIGRAF centers 
the default NDC-space onto the maximum incribed square that may be drawn on the display surface. This 
guarantees that the user's viewport boundaries are always within the visible region of the active display. 
 Before the first segment is opened, DIGRAF allows the user to redefine the boundaries of the NDC-space 
to be a subset of the default NDC-space, with the constraint that one of the dimensions (X or Y) must 
maintain the default bounds of (-I to +i). In the subsequent mapping of NDC's onto the active display, 
this subset rectangle is mapped onto the device so as to maximize the visible area of the screen. In 
other words, if the aspect ratio of the redefined NDC-space is the same as the aspect ratio of the visible 
region of the active device, then the entire display surface may be utilized. Pick-ID's PICK-ID's allow 
one level of primitive naming within a retained segment. Perhaps the most common application of PICK-ID's 
is to identify individual elements of an input menu. The menu is a single segment that is made visible 
or pick-sensitive in its entirety. The pick function returns the menu (segment) name and the menu item 
(PICK-ID) within the menu. Conceptually, PICK-ID's are straight- forward; the key implementation issue 
is to develop a resolution scheme for associating the NDC pick with a unique PICK-ID within a single 
element. Certain refresh devices, monitored by an intelli- gent satellite computer, can utilize the interrupt 
mechanisms of the satellite at the time of a light- pen hit to identify the exact primitive that was 
detected. However, all non-display buffered devices must resolve a unique segment and PICK-ID in software. 
 The SDF maintains minimum and maximum NDC bounds for each segment in the SDF. Minima and maxima are 
also maintained for each PICK-ID within the segment. The DIGRAF algorithm for picking first does a quick 
boxing check on each pick-sensi- tive segment to see if the pick-coordinates lie within the segment bounds. 
If only one segment contains the pick point, the algorithm then traverses the segment, checking to see 
if the pick point is within any of the PICK-ID boundary boxes. If the point is within only one PICK-ID 
segment, the boxing check has uniquely resolved the segment and PICK-ID. If more than one segment or 
more than one PICK- ID within a segment contains the pick point, the pick algorithm must do a primitive 
by primitive check to find the primitive within a PICK-ID that is closest to the pick point. Perhaps 
the simplest and most efficient method of proximity checking is implemented within IG [i] and has been 
adopted by DIGRAF. The IG algorithm essentially emulates light-pen picking in software. An arbitrarily 
small viewport is centered on the pick point. All primitives within the candidate PICK-ID's are then 
clipped against this viewport. The first primitive that passes through the viewport determines the desired 
PICK-ID. The clipping viewport is chosen large  306 enough to detect hits that are "close" to a primi- 
tive, yet small enough to minimize the probability of two primitives from two different PICK-ID's passing 
through the viewport. DIGRAF implements the five logical input func- tions of the CORE in a minimal 
way. Only one event or sample can physically happen at any instant. When a program requests input from 
a specific logical function, control is not returned tQ the calling program until the input value (PICK-ID, 
NDC-point, valuator reading, keyboard string, or button number) is available. At initialization time, 
one physical device is implicitly enabled for each logical input function. At any instant only one physical 
device may be enabled for each logical function (e.g., the user may not have two locators concurrently 
enabled). Error Processing and Debugging  DIGRAF assumes most of the burden of error- processing and 
recovery. All errors are assigned a severity level. The user's DIGRAF program deter- mines what level 
of error should cause program termination and communicates this level to DIGRAF. In subsequent execution 
all errors below the fatality level are logged on the error file, but do not abort the program. Some 
type of recovery action occurs and control is returned to the call- ing program. This approach is most 
useful during program checkout. The fatality level can be set to the maximum (no errors will be fatal) 
so the program may run to completion. The error file will then identify where all errors have occurred. 
As the production version of the graphics program evolves, the error level may be lowered. DIGRAF also 
utilizes the 'level' concept for debugging. The calling program may set the debug level to determine 
the verbosity of program traceback with messages being logged on the debug file. Program logic errors 
may be isolated by selectively enabling the debugging facility to obtain snapshots of program flow. 
Both the error and debugging levels may be enabled/disabled at any time during execution. The user also 
controls the logical file media where error and debug messages are to be logged. CONCLUSION The DIGRAF 
package for Device-Independent graphics based upon the GSPC standard has been discussed from the implementor's 
viewpoint. Several aspects of the current version have been reviewed, including the structure of the 
segmented display file and the implementation of device drivers. Continued development of DIGRAF is 
underway in the areas of a paged segmented display file and portable schemes for run-tlme selection of 
display surfaces. ACKNOWLEDGMENT S The authors wish to thank Mr. Bob Ewald of Los Alamos Scientific 
Labs, Mr. Andy Goodrich of the University of Michigan, Mr. Peter Bono of the Naval Underwater Systems 
Center, and Mr. Jim Michener of Intermetrics for their insights and criticisms during the development 
and implementation of DIGRAF. REFERENCES I) Blinn, J., Goodrich, A. C., "The Internal Design of the 
IG Routines," Proceedings of SIGGRAPH '76, Philadelphia, PA, (SIGGRAPH Quarterly, Vol. I0, No. 2, Summer 
1976). 2) Reed, T., "Intermediate File Structure," (available from T. Reed, LASL, Los Alamos, NM, 87545, 
1978). 3) Ryder, B. G., "The PFORT Verifier," Computer Graphics, Vol 4, No. 4, 1974. 4) Sproull, R., 
"The OMNIGRAPH Graphics System," Xerox PARC, Palo Alto, CA. 5) Warner, J., "DIGRAF User's Reference 
Guide," University of Colorado Computing Center, Boulder, CO, 80309. 6) Wright, T., "Machine-Independent 
Metacode Translation," Proceedings of SIGGRAPH '77, San Jose, CA, (SIGGRAPH Quarterly, Vol. 11, No. 
2, Summer 1977). 7) "BSR X3.9 FORTRAN '77: DPANS Programming Language FORTRAN," Technical Committee X3J3 
- FORTRAN ANSI, June 1977. 8) , "Status Report of the Graphics "Standards Planning Committee," SIGGRAPH 
Quarterly, Vol. ii, No. 3, Fall 1977. It is anticipated that DIGRAF will evolve with updates to the 
GSPC standard. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807407</article_id>
		<sort_key>308</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>54</seq_no>
		<title><![CDATA[An implementation of the ACM/SIGGRAPH proposed graphics standard in a multisystem environment]]></title>
		<page_from>308</page_from>
		<page_to>312</page_to>
		<doi_number>10.1145/800248.807407</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807407</url>
		<abstract>
			<par><![CDATA[<p>Los Alamos Scientific Laboratory (LASL) has implemented a graphics system designed to support one user interface for all graphics devices in all operating environments at LASL. The Common Graphics System (CGS) will support Level One of the graphics standard proposed by the ACM/SIGGRAPH Graphic Standards Planning Committee.</p> <p>CGS is available in six operating environments of two different word lengths and supports four types of graphics devices. It can generate a pseudodevice file that may be postprocessed and edited for a particular graphics device, or it can generate device-specific graphics output directly. Program overlaying and dynamic buffer sharing are also supported.</p> <p>CGS is structured to isolate operating system dependencies and graphics device dependencies. It is written in the RATFOR (RATional FORtran) language, which supports control flow statements and macro expansion. CGS is maintained as a single source program from which each version can be extracted automatically.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Device-independent graphics]]></kw>
			<kw><![CDATA[Portability]]></kw>
			<kw><![CDATA[Pseudodevice]]></kw>
			<kw><![CDATA[Standards]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Standards</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.4.1</cat_node>
				<descriptor>Multiprocessing/multiprogramming/multitasking</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011050.10011017</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Context specific languages->Domain specific languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010949.10010957.10010959</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Operating systems->Process management->Multiprocessing / multiprogramming / multitasking</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010919.10010177</concept_id>
				<concept_desc>CCS->Computing methodologies->Distributed computing methodologies->Distributed programming languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Management</gt>
			<gt>Standardization</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P333276</person_id>
				<author_profile_id><![CDATA[81100629691]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Kellner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Los Alamos Scientific Laboratory, P.O. Box 1663, MS-272, Los Alamos, New Mexico]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334015</person_id>
				<author_profile_id><![CDATA[81332522908]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Theodore]]></first_name>
				<middle_name><![CDATA[N.]]></middle_name>
				<last_name><![CDATA[Reed]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Los Alamos Scientific Laboratory, P.O. Box 1663, MS-272, Los Alamos, New Mexico]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P329019</person_id>
				<author_profile_id><![CDATA[81100242021]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ann]]></first_name>
				<middle_name><![CDATA[V.]]></middle_name>
				<last_name><![CDATA[Solem]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Los Alamos Scientific Laboratory, P.O. Box 1663, MS-272, Los Alamos, New Mexico]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[ACM. Status Report of the Graphic Standards Planning Committee of ACM/SIGGRAPH. Computer Graphics 11, 3, Fall 1977.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Conley, B., et al. Basic Graphics Package Intermediate File Format. LASL internal document, March 1978.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[General Purpose Graphics System. Katholieke Universiteit, Nijmegin, The Netherlands, 1975.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[GINO-F User Manual. Computer Aided Design Centre, Cambridge, England, 1974.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Kernighan, B.W. RATFOR - A Preprocessor for a Rational FORTRAN. Bell Laboratories, Murray Hill, NJ.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>578706</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kernighan, B.W., and Plauger, P.J. Software Tools. Addison-Wesley, Reading, MA, 1976.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 AN IMPLEMENTATION OF THE ACH/SIGGRAPH PROPOSED GRAPHICS STANDARD IN A MULTISYSTEH ENVIRONMENT Richard 
G. Kellner Theodore N. Reed Ann V. Solem Los Alamos Scientific Laboratory P.O. Box 1663, MS-272 Los 
Alamos, New Mexico 87545 ABSTRACT Los Alamos Scientific Laboratory (LASL) has implemented a graphics 
system designed to support one user interface for all graphics devices in all operating environments 
at LASL. The Common Graph- ics System (CGS) will support Level One of the graphics standard proposed 
by the ACM/SIGGRAPH Graphic Standards Planning Committee. CGS is available in six operating environ- 
ments of two different word lengths and supports four types of graphics devices. It can generate a pseudodevice 
file that may be postprocessed and edited for a particular graphics device, or it can generate device-specific 
graphics output directly. Program overlaying and dynamic buffer sharing are also supported. CGS is structured 
to isolate operating system dependencies and graphics device dependencies. It is written in the RATFOR 
(RATional FORtran) language, which supports control flow statements and macro expansion. CGS is maintained 
as ~ sin- gle source program from which each version can be extracted automatically. Key Words and Phrases: 
portability, stan- dards, computer graphics, device-independent graphics, pseudodevice. CR Categories: 
4.22, 8.2 1. INTRODUCTION Since 1957, the Los Alamos Scientific Labora- tory (LASL) has been involved 
in computer graph- ics, pioneering work in color computer output mi- crofilm and other areas. Currently, 
LASL has nine large-scale computers, several hundred Tektronix 4010-series graphics terminals, four computer 
out- put microfilm recorders, an Evans and Sutherland Picture System 2 graphics system, and numerous 
small computers and other graphics equipment. The computers are run 24 hours per day, 7 days per week, 
with a mixture of jobs, including ones that may consume all the available resources of a large computer 
for hours. for each operating system and graphics device. Software maintenance, application program 
mainte- nance and conversion) and user education have re- quired extensive effort that could be reduced 
by one unified graphics system. Because existing systems , such as GINO-F [4] and GPGS [3], were not 
suitable for our applications, we designed and im- plemented our own. Late in 1976, we began implementation 
of the Common Graphics System (CGS). By late 1977, CGS was operational in six operating environments, 
on computers of two different word lengths, and was supporting four types of graphics devices. Each operating 
environment differs in computer hardware, operating systems, and compiler subsys- tems) yet the graphics 
interface provided by CGS is identical.  2. CAPABILITIES CGS was patterned after the ACM/SIGGRAPH pro- 
posed standard for computer graphics software [I]. The proposed standard has four levels of capabili- 
ty: basic, huffered, interactive, and complete. The initial goal of CGS was to implement the basic level 
for the graphics devices at LASL. Subse- quent versions are planned to support the buffered and interactive 
levels, with a long-term objective of supporting all four levels. Included in the basic level of support 
are four classes of functional capability: output primitives and primitive attributes; viewing transformations 
for both two and three dimensions; control functions necessary to use the system; and non-retained segments. 
The subsequent levels of support will include: retained segments; dynamic segment attributes; input primitives; 
and image transforms. Additional capabilities are necessary to sup- port the more important LASL application 
programs. These are nongraphic control capabilities that must be provided as part of the graphics system. 
These are described below. The appendix contains a list of these control functions and the proposed SIGGRAPH 
control functions with which they in- teract.  The gradual development of graphics software 2.1 Program 
Overlaying at LASL has resulted in a large collection of dif - ferent capabilities and different user 
interfaces To allow application programs to overlay CGS 308 routines with the application program, we 
have provided two control functions. a. A function to force global variables to be allocated in the 
non-overlayed portion of memory.  b. A function to establish or sever linkage to a graphics device driver 
residing in an over- lay. With our implementation of CGS and our operating environments, it is necessary 
for the application program to establish linkage £o a graphics device driver upon entering an overlay 
and to sever linkage upon exiting the overlay. No view surface may be selected un- less it is associated 
with a graphics device that is linked.  2.2 Dynamic Buffer Allocation Application programs must be 
able to allocate graphics buffer space dynamically to make the memory space available to the program 
when it is not being used for graphics. Two functions have been provided for this purpose. a. A function 
to assign a buffer for use by a view surface. The buffer is unavailable for use by the application program 
when it is as- signed to the view surface.  b. A function to unassign a buffer. This forces the contents 
of the buffer to be written to disk or to an on-line graphics device. The view surface cannot be selected 
when a buffer is unassigned. The buffer becomes available for use by the application program.   2.3 
Additional Goals In addition to the above capabilities, the following were goals guiding the design 
and imple- mentation of CGS. a. To provide an identical interface to each of the graphics device drivers. 
 b. To load only the graphics device drivers "re- quested by the application program.  c. To maintain 
the graphics routines and all the graphics device drivers in the same object library.  d. To support 
a pseudodevice (i.e., a device- independent graphics file) [2] that could be postprocessed to any graphics 
device. This allows graphics to he previewed and edited before specifying a graphics device for final 
output.  3. STRUCTURE The structure of CGS (Fig. I) was affected by the above functional requirements 
and design goals.  3.1 Device-independent Graphics This module supports the functions described  in 
Level One of the SIGGRAPH proposal [I]. These routines generate graphics commands in a common USER APPLICATION 
PROGRAMS SC-4020 PLOTTING PACKAGE PACKAGES ~COMMON GRAPHICS SYSTEM// DEVICE INDEPENDENT "~GRAPHICS ~ 
Z %. DEVICE SELEC LTION 4, q ddd Ofvys PSEUDO DEVICE FRSO TEKTRONIX FILE COM TERMINALS Fig. i. Structure 
of CGS.  format for all the graphics device drivers, in- cluding the pseudodevice, and interface directly 
to the device selection control module. The world coordinates are processed by the viewing transform 
into normalized device coordinates in the range of the current normalized device coordinate space. They 
are then directed to the device selection control module. 3.2 Multiple View Surfaces CGS supports 
multiple view surfaces for mul- tiple devices, including multiple view surfaces for a single device, 
as provided for in the SIG- GRAPH proposal. Other graphics packages at LASL have allowed applications 
to generate a movie and slides for the same device at the same time. We have generalized this capability 
to generate in- dependent streams of graphics for various graphic devices, just as a program can have 
any number of independent input or output files for nongraphics devices. 3.3 Device Driver Linkage 
All the graphics primitive routines call a single module, the device selection control module, and pass 
the graphics command in a common format similar to the pseudodevice format [2]. This module calls the 
linked device drivers, pass- ing the pseudodevice command along. The applica- tion program must name 
all the device drivers that may he needed, and only those will be loaded. This is necessary because all 
of our loaders are static overlay loaders. The drivers may all re- side in memory at the same time, or 
the applica- 309 tion program may overlay drivers with other routines. Drivers not in memory must be 
unlinked; drivers in memory may be linked or unlinked. Since all device drivers may be in memory simul- 
taneously, all device driver routines have unique names. 3.4 Graphics Device Drivers  Each device driver 
generates device-specific information. It transforms the normalized device coordinates to the coordinate 
space of the graph- ics device. Each device driver checks for all view surfaces that are assigned to 
it and sends the plotting information to each view surface that is currently selected. This is accomplished 
by maintaining a separate workspace containing vari- ables and working storage for each view surface. 
Thus, "output-only" device drivers write to a separate file on disk for each selected view sur- face. 
This capability could also be used to drive several terminals of the same type if the operat- ing environment 
can support multiple terminals per job. 4. IMPLEMENTATION Important implementation considerations were: 
portability; maintainability; compatibility with an existing plotting package; and a modular imple- mentation. 
  4.1 Portability The biggest problem in portability was caused by the lack of any standards in system 
interfaces. Capabilities such as logical and shifting opera- tions, bit and byte packing, character set 
conver- sion, in-core formatted data conversion, and job and system inquiries, are system functions that 
are sufficiently well understood to warrant some standardization across operating environments. We developed 
one system-independent interface to the operating environments. To move to a new operat- ing environment, 
only the routines defining that interface need be rewritten. In addition to the system functions mentioned 
above, we defined a system-independent I/0 inter- face for creating a file; opening and closing a path 
from the program to a file or to an on-line graphics device; disposing a file to its ultimate destination, 
such as an off-line graphics device; and reading and writing any number of bits. At LASL we are required 
to generate a graph- ics file in one operating environment and read it in another operating environment. 
In order to eliminate conversions between these environments, all graphics files have the same format. 
Each file has an index indicating where physical record marks are to be inserted, because some graphics 
devices require a particular structure to the phy- sical records or to an input graphics tape. The index 
also records frame addresses to facilitate editing and postprocessing.  4.2 Maintainability CGS exists 
as one master source program, from which a version for each operating environment can be extracted. This 
ensures uniformity in the  graphics system in all operating environments. Two types of preprocessing 
are used to ex- tract each version from the master source. a. All system-dependent and device-dependent 
quantities, such as computer word size, graphics device command size, and output buffer size, are set 
with macros. Prepro- cessing with the right set of macro defini- tions causes all the quantities to be 
applied throughout the source program.  b. The modules that define the system- independent interface 
must be different for each operating environment. Those modules that have been optimized with in-line 
logical and shift operations also have to be dif- ferent. This conditional compilation is achieved by 
flagging each system-dependent statement with a system ID, and preprocessing to delete all lines that 
do not belong to the desired version.  We use the RATional FORtran (RATFOR) language from Bell Laboratories 
[5,6]. The RATFOR prepro- cessor outputs ANSI standard FORTRAN. It supports control flow statements, 
such as IF/ELSE and WHILE, and also has a limited macro capability. The project librarian generates 
the graphics system for all operating environments--compiling; building libraries and utilities; testing; 
saving all listings on microfiche; keeping records; releasing the new libraries and utilities for pub- 
lic use; and keeping backup copies. The librarian uses procedure files and macros so that each major 
step can be easily performed.  4.3 SC-4020 Emulation There is a tremendous investment at LASL in application 
programs that produce graphics output for the SC-4020 microfilm recorder. Conversion of these programs 
to run under CGS had to be mini- mized, so we rewrote the SC-4020 primitive routines to call the CGS 
primitives. Existing high-level routines and application programs have gained portability across operating 
environments and graphics devices with almost no conversion of the graphics portions of thefr codes. 
 4.4 Modular Implementation Our software implementation called for in- stalling a minimum version of 
CGS, suitable for use by production programs in all operating en- vironments. The first release of CGS 
was a two- dimensional system, which supported only the pseu- dodevice file, and included the SC-4020 
emulation routines. A postprocessor supporting several of our graphics devices was written utilizing 
exist- ing graphics software. Once operational, CGS was optimized and enhanced uniformly in all operating 
environments and implementation of device drivers suitable for use directly with CGS was begun. 5. CONCLUSIONS 
 Our initial objective was to implement device-independent graphics in a portable fashion to support 
existing application programs in new 310 and existing operating environments at LASL. The conversion 
of existing high-level graphics routines to use CGS brought widespread availabili- ty quickly and gave 
many existing application pro- grams access to a variety of graphics devices and operating environments. 
The resulting user feed- back has been valuable, especially in the areas of portable software and ascertaining 
user needs for improved high-level graphics. Writing the system with portability in mind and then looking 
at efficiency has resulted in several modifications to our portability tech- niques, primarily to improve 
efficiency. Level One of the SIGGRAPH proposal has been sufficient to support the majority of our existing 
applications. The additional device driver con- trol functions we have provided have enabled CGS to support 
several of our larger, more important applications. It will soon be necessary to sup- port a Level Three 
implementation to provide in- teractive graphics using CGS. As of early 1978, four and one-half man-years 
have been expended in the development, documenta- tion, and maintenance of a partial Level One im- plementation 
of the SIGGRAPH proposal in six operating environments. This also includes the conversion of 9000 lines 
of high-level graphics routines and many hours of user education and con- sulting. 6. APPENDIX 6.1 Initialization 
and Termination 6.1.1 ALLOCATE-GLOBALS ( ) This function allocates CGS global variables. The allocation 
occurs wherever the routine is loaded. This function may be called anytime. Errors: None.  6.1.2 INITIALIZE-CORE 
(LEVEL) This function initializes the core. Except for ALLOCATE-GLOBALS, it must be the first call made. 
 Errors: I. CGS was already initialized. 2. The specified level is not supported.  6.1.3 TERMINATE-CORE 
( ) This function releases all resources being used by CGS. Errors: 1. CGS was not initialized.  2. 
A view surface has not been terminat- ed.  3. A view surface has not been closed.    6.2 Device Selection 
and Control 6.2.1 OPEN-VIEW-SURFACE (SURFACE-NAME, BUFFER S I ZE ) -  This function associates a buffer 
with the specified view surface. Errors: I. The view surface was already open.  6.2.2 CLOSE-VIEW-SURFACE 
(SURFACE-NAME) This function disassociates a buffer from the specified view surface.  ~rrors: I. The 
view surface was not opened. 2. The view surface was not deselected.  6.2.3 LINK-DEVICE-DRIVER (DEVICE-NAME, 
DRIVER-ADDRESS) This function generates the link to the specified device driver in the device selection 
module. Errors: I. The device driver was already linked. 2. Unrecognized device name.  6.2.4 UNLINK-DEVICE-DRIVER 
(DEVICE-NAME) This function eliminates the link to the specified device driver in the device selection 
module. Errors: 1. The device driver was not linked.  2. Unrecognized device name.  3. A view surface 
assigned to the device was not deselected.   6.2.5 INITIALIZE-VIEW-SURFACE (SURFACE-NAME, DEVICE-NAME, 
DEVICE-OPTIONS) This function associates a view sur- face with a device driver. The device op- tions 
are used to select specific device capabilities. These options are used to initialize the view surface. 
 Errors: I. The view surface was already initial- ized. 2. Unrecognized device name.  3. The view 
surface was not opened.  4. The associated device driver was not linked.   6.2.6 TERMINATE-VIEW-SURFACE 
(SURFACE-NAME) This function terminates the speci- fied view surface. Errors: I. The view surface 
was not initialized. 2. The view surface was not deselected.  3. The view surface was not opened. 
 4. The associated device driver was not linked.   6.2.7 SELECT-VIEW-SURFACE (SURFACE-NAME) This 
function selects the specified view surface for subsequent graphic out- put. 311 Errors: I. The view 
surface was already selected. 2. The view surface was not initialized.  3. The view surface was not 
opened.  4. The associated device driver was not linked.  5. A segment is open.  6.2.8 DESELECT-VIEW-SURFACE 
(SURFACE-NAME) This function deselects the view sur- face. Errors: I. The view surface was not selected. 
 2. A segment is open. ACKNOWLEDGMENTS We would like to acknowledge Raymond Elliott of LASL for the 
support and encouragement he gave this project, as well as his many comments and suggestions. We would 
also like to thank Jeanne Hurford of LASL for word processing support. We also acknowledge the joint 
effort concern- ing graphics standardization between Sandia Laboratories at Albuquerque, the Air Force 
Weapons Laboratory at Kirtland Air Force Base, and LASL.  We are especially indebted to the many members 
of the ACM/SIGGRAPH Graphic Standards Planning Committee. Their report sets forth the first real hope 
that a standard for computer graphics software will be established. REFERENCES I. ACM. Status Report 
of the Graphic Standards Planning Committee of ACM/SIGGRAPH. Computer Graphics II, 3, Fall 1977. 2. 
Conley, B., et al. Basic Graphics Package In- termediate File Format. LASL internal document, March 1978. 
 3. General Purpose Graphics System. Katholieke Universiteit, Nijmegin, The Netherlands, 1975.  4. 
GINO-F User Manual. Computer Aided Design Centre, Cambridge, England, 1974.  5. Kernighan, B.W. RATFOR 
- A Preprocessor for a Rational FORTRAN. Bell Laboratories, Murray Hill, NJ.  6. Kernighan, B.W., and 
Plauger, P.J. Software Tools. Addison-Wesley, Reading, MA, 1976.  312   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807408</article_id>
		<sort_key>313</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>55</seq_no>
		<title><![CDATA[A microprocessor-assisted graphics system]]></title>
		<page_from>313</page_from>
		<page_to>317</page_to>
		<doi_number>10.1145/800248.807408</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807408</url>
		<abstract>
			<par><![CDATA[<p>GRAF80 is a small scale graphics system designed to demonstrate some of the capabilities offered by microprocessor-assisted graphics. As such, it employs both hardware and software techniques. The system implements in a microprocessor a subset of the features of the SIGGRAPH-ACM CORE (1) graphics package, including picture segmentation and a subset of the output primitives and primitive attributes.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.4.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245.10010247</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems->Image segmentation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245.10010248</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems->Video segmentation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P330584</person_id>
				<author_profile_id><![CDATA[81100294055]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Griffith]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hamlin]]></last_name>
				<suffix><![CDATA[Jr.]]></suffix>
				<affiliation><![CDATA[LASL, Los Alamos Scientific Laboratory of the University of California under U. S. Department of Energy Contract No. W-7405-ENG-36]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39070756</person_id>
				<author_profile_id><![CDATA[81100331573]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Crockett]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ICASE]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Computer Graphics (11,3) Fall 1977.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A Guide to PL/M Programming, Intel Corp., Santa Clara, California, 1973.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A MICROPROCESSOR-ASSISTED GRAPHICS SYSTEM Griffith Hamlin, Jr,, LASL** Thomas Crockett, ICASE ABSTRACT 
 GRAF80 is a small scale graphics system de- signed to demonstrate some of the capabilities offered by 
microprocessor-assisted graphics. As such, it employs both hardware and software tech- niques. The system 
implements in a microprocessor a subset of the features of the SIGGRAPH-ACM CORE (i) graphics package, 
including picture segmenta- tion and a subset of the output primitives and primitive attributes. INTRODUCTION 
 GRAF80 is a graphics system that uses inexpen- sive microprocessors to enhance the capabilities of a 
Tektronix storage tube display. For a frac- tion of the cost of a Tektronix 4014, several features can 
be added that considerably increase its usefulness. These features include a selective erase using the 
segmented display file concept of the SIGGRAPH CORE graphics package, and the ability to display a limited 
number of vectors in refresh mode using a high-bandwidth hardware interface between a microprocessor 
and the Tektronix 4014. HARDWARE The hardware consists of an IMSAI 8080 micro- processor, which forms 
the heart of the system; a Tektronix 4014 direct-view storage tube terminal, which is used as the graphical 
output device; and a host computer. The IMSAI 8080 acts as a dedicated device driver, and has software 
that supports picture refreshing and segmentation. Any one of several other available 8-bit microproces- 
sors could be used as well. Several possibilities exist for interconnecting the microprocessor, Tektronix 
terminal, and host computer. Figure 1 shows one possibility that uses commonly available equipment. 
 The Tektronix 4014 has a built-in serial interface that will support serial communications up to 9600 
baud with the microprocessor. This rate should be sufficient to provide interactive access to images 
stored in the microprocessor's segmented display file. It is not sufficient to refresh images using 
the write-through mode of the 4014. To remedy this, we have constructed a simple parallel interface to 
the 4014 and connected it as shown in Fig. 2. This interface consists of only nine 16-pin integrated 
circuits mounted and wire-wrapped on a blank Tektronix plug-in card. This provides one-way byte parallel 
transmission at the Tektronix 4014 MINIBUS@ speed (9 ~s/byte) from the microprocessor to the Tektronix 
4014. Communication from the Tektronix 4014 uses the normal serial interface in the 4014 and is con- 
nected directly to the host computer. Any machine capable of producing GRAF80 com- mands may be the 
host computer. This could be the same or another microprocessor, a minicomputer, or a large mainframe. 
In our case a PRIME-300 mini- computer is used. SOFTWARE Software for GRAF80 consists of two main com- 
ponents, one on each computer. The microprocessor Serial 9600- Serial Line. ' ' baud Line Data rate 
usually determined by host computer. Fig. i. Basic hardware configuration. Fig. 2. GRAF80 hardware 
configuration. This report was prepared as a result of work performed under NASA Contract No. NASI-14101 
while both authors were in residence at ICASE, NASA Langley Research Center, Hampton, VA 25665. Los 
Alamos Scientific Laboratory of the University of California under U. S. Department of Energy Contract 
No. W-7405-ENG-36. 313 component receives graphic commands, stores them in a segmented data structure, 
and interprets them to produce either a refreshed or a stored image on the 4014. The host computer 
software consists of a package of Fortran subroutines that issue the commands. Microprocessor Software 
Software for the microprocessor is written in PL/M, a high-level language designed for micro-processors 
(2). The software is designed to intercept and interpret a set of primitive graph- ical commands. It 
requires 4000 bytes of micro- processor memory plus buffers for the segmented display data structure 
generated from the commands. These commands consist of move and draw graphic- output primitives, along 
with commands to OPEN, CLOSE, DISPLAY, and ERASE individual image seg- ments. The complete list is given 
in Appendix A. They were selected from the SIGGRAPH-ACM CORE graphics package. The main program consists 
of a loop that con- tinuously monitors an I/0 subtask and a graphics subtask. (The term "task" is used 
to indicate that these two processes could be executed in parallel if properly synchronized, although 
they have been implemented sequentially here. The net effect would be similar in either case.) When the 
main loop determines that a particular task has work to be done, it transfers control to that task, which 
runs to completion and returns to the main loop. Input to the microprocessor is interrupt driven. A 
simple interrupt routine receives a character and stores it in a circular buffer. The job of the I/O 
task is to empty the buffer and evaluate its contents. In order to allow ordinary (nongraphical or graphical) 
use of the terminal, a "transparent" mode is defined. Transparent mode defaults until a special graphics 
notify character (ASCII ETB) is received. The I/0 task examines each character and sends it directly 
to the ter- minal until an ETB is encountered, at which time further data is considered to be graphical. 
The graphical input is filtered according to a pre- defined transmission format (Appendix B) and stored 
as a picture segment. When the input buffer is emptied, control returns to the main loop. The graphics 
task serves as an interpreter, converting the commands stored by the I/0 task into device-dependent instructions 
which are sent to the 4014 to generate the picture. By redefin- ing this task, different devices may 
be handled within the framework of a single system. Each call to this device driver interprets a single 
picture segment; repeated calls with the same segment allow the refresh capability. The graphics task 
returns to the main loop after once interpreting each segment that needs to be dis- played. Picture 
segmentation is handled at a level above the device driver. A number of graphics commands are used for 
manipulating segments. The I/0 task intercepts these and takes appropriate action, such as setting flags, 
allocating storage, etc. The actual picture commands (or "primitives") are stored in the microprocessor's 
free memory as one or more 64-byte blocks, linked together by a forward chain, one chain per segment. 
A set of memory management routines is available to manipu- late this data structure. Memory allocation 
is automatic and dynamic, implying that each segment receives only as much memory as it requires. The 
total amount of information that may be displayed simultaneously is thus limited by the amount of memory 
available to the microprocessor. Although the current implementation uses only real memory, this need 
not be the case; nonrefreshed segments could use an auxiliary disk, but system perform- ance would be 
somewhat degraded. Currently up to 16 segments may be defined. Commands for manipulating segments are 
listed below. OPEN (N, R) Opens segment N. All subsequent graphic primitives become part of the segment 
until a matching CLOSE is encountered. R = refresh status; 0 = no refresh; 1 = refresh. CLOSE(N) Closes 
segment N. No further informa-tion may be added to this segment. DISPLAY(N) Causes segment N to be displayed. 
ERASE(N) Removes segment N from the display, but the segment may be redisplayed later. DELETE (N) Deletes 
segment from microprocessor memory. Open segments may not be nested or overlap- ping; no more than one 
segment may be open at any time. No portion of a segment is visible until an explicit DISPLAY command 
is given, and a currently open segment cannot be displayed. This differs from the SIGGRAPH-ACM CORE system 
which specifies that portions of the open segment become immedi- ately visible as they are defined. Due 
to the existence of both stored and refreshed segments in our implementation, we departed from the SIGGRAPH 
CORE here in order to considerably simplify the microprocessor software. Erasing a segment merely removes 
it from the display; it remains available in the microprocessor memory for further use. A DELETE command 
destroys the segment entirely. Refreshing, as pointed out, is accomplished by the graphics task; successive 
iterations of the main program loop refresh the segment. Since the I/O task usually is not busy, the 
graphics task becomes the limiting factor in providing flicker- free refresh. Within that task two 
considerations limit the refresh capacity: I. the rate at which graphic commands can be interpreted 
into Tektronix code by the micro- processor, 2. the drawing speed of the Tektronix 4014 (about 190 
Ds/in. which is rather slow for refresh purposes). 314 I/0 time is negligible because of the parallel 
interface. Currently the flicker-free refresh capacity is approximately 75 characters or 65 inches of 
2-inch vectors (including both dark and written vectors). This is about half the capacity of the Tektronix 
4014 and is limited in our cur- rent implementation by the microprocessor software. Different software, 
discussed in the last section, should remedy this situation. Nonrefresh segments differ in that they 
are drawn only once, and not on each successive loop iteration. Normally such segments will be drawn 
in storage mode, but this does not have to be true. The primitive attribute REFRESH determines the mode 
the Tektronix 4014 uses when generating characters and vectors; therefore it is possible to draw nonrefreshed 
information that immediately disappears and to draw storage-mode information that is continually refreshed 
[not recommended). The general assumption, however, is that refreshed segments will contain refresh commands 
and non- refresh segments will contain storage commands. Selective erase is implemented somewhat dif- 
ferently for each type of segment. Refreshed segments merely have their display flag turned off. Nonrefresh 
(storage) segments that are erased cause the entire display to be erased, and the display flag for that 
segment is turned off; all other segments are flagged as not having been drawn. The result is that everything 
but the erased segment is redrawn on the next pass of the main loop. The redraw time is very short; the 
only objection being the screen erase flash that precedes it. A typical mesh plot containing about 1500 
i/4-inch vectors takes about 1 second to redraw. Host Software A package of Fortran interface subroutines 
on our PRIME-300 minicomputer allows a user's appli- cation program to generate commands for the GRAF80 
system. Access is allowed to each segment-level and primitive-level command. The subroutines gen- erate 
the proper transmission formats, perform data conversions where necessary, and send GRAF80 commands out 
the communications line to the micro- processor. All coordinates used at this level are integers, which 
run from 0-4095. This corresponds directly to Tektronix 4014 enhanced graphics screen coordinates, although 
any arbitrary units could have been chosen. Appendix C contains doc- umentation of these routines. CONCLUSIONS 
 From the host computer's viewpoint the system appears as a virtual device, with built-in func- tions 
for picture segmentation and refreshing. As such, it would be most useful when interfaced to a higher-level 
graphics system. This higher-level system could he an existing graphics package, modified to accept 
GRAF80 as another device type and to include segment manipulation features, or it could be a new system 
built on top of GRAF80. In the latter case, an implementation of the SIGGRAPH-ACM CORE system would 
be facilitated since GRAF80 has several of the CORE functions already available. Our 8080 microprocessor 
is only lightly loaded with the current GRAF80 software (except when refreshing). Thus we believe that 
much of the CORE system could be handled by the micro- processor with additional software. Currently 
we have designed, but not yet implemented on our microprocessor, the image transformation features of 
the CORE system and most of the input functions. We chose these functions for microprocessor im- plementation 
since they can provide fast inter- active feedback to the user when placed on a processor with a high-speed 
connection to the dis- play device. Also, they involve only fixed point coordinates. Today's microprocessors 
handle floating point computations only slowly in soft- ware. We have left the transformations from floating 
point (world coordinates) to fixed point (normalized device coordinates) to our minicomputer which has 
floating point instructions. As mentioned above, the limiting refreshing rate for GRAF80 could be improved 
through revision of the data structures. The graphics task could be modified to store Tektronix 4014 
code in a sep- arate buffer, rather than display it directly. A third refresh task would then display 
this buffer, with no interpretive overhead. A small test pro- gram on our microprocessor that used 
this tech- nique was able to refresh approximately 140 inches of vectors, about twice as much as GRAF80 
can currently refresh. However, our experience so far has been that the segmenting features (which 
pro- vide selective erase) are more valuable for most users than the refresh capability. The handful 
of users with engineering appli- cations who have been exposed to GRAF80 have generally been quite pleased 
with its capabilities. This is in part due to their previous use of an overloaded mainframe (a not uncommon 
occurrence) with a slow (300 to 2400 baud) data rate line to their terminal. These conditions favor our 
use of local intelligence and sending only changes in images instead of sending the entire image each 
time a small change is made. REFERENCES I. Computer Graphics (11,3) Fall 1977. 2. A Guide to PL/M Programming, 
Intel Corp., Santa Clara, CaTifornia, 1975. 315 APPENDIX A GRAF80 PRIMITIVE COb94ANDS All (X,Y) coordinates 
are assumed to be binary fractions in the range 0 to I, with 12 bits of precision. The coordinate format 
is  I x LO.~ I x HIGH4 I Y LO. 8 I Y HIGH4 I using 4 bytes total. The most significant 4 bits of the 
HIGH bytes should be zeros. The various primitives are listed below, with the following format: N~qEMONIC 
OPERAND(S) BINARY OPCODE REMARKS MOVE X,Y 00010001 Move beam to (X,Y). LINE X,Y 00010010 Draw line 
from current position to (X,Y), using current linestyle, refresh, and boldness. POLYLINE N,XI,YI,X2,Y2,...,XN,YN 
00010011 Draw N connected lines, starting at the current position and ending at XN,YN. Use current linestyle, 
boldness, and refresh.  MARKER N,X,Y 00010100 Place a marker at (X,Y). If N=0, the marker is a point; 
otherwise, N is taken to be an ASCII character, and is drawn using the small- est charsize and the current 
refresh status. TEXT N,STRING 00011000 Place text STRING of N characters at the current position. Use 
the current refresh status, boldness, and charsize. SET ATTRIBUTE TYPE 00100000 Types are: BOLDNESS 
0000000x x=l,bold ** x=O,normal LINESTYLE 000001xx xx=O0,solid xx=01,dotted xx=lO,dot-dashed xx=ll,dashed 
CHARSIZE 0001hhww hh=height ww=width ww is ignored. Character sizes are based on hh, with 00 the largest 
and Ii the smallest. REFRESH 1000011x x=0,no refresh ** x=l,refresh  **On the Tektronix, REFRESH and 
BOLDNESS are not mutually exclusive; REFRESH changes BOLDNESS, and BOLDNESS changes REFRESH. STOP 00001111 
 Signifies the end of a stream of graphic primitives, and causes a return from the graphics task. 
APPENDIX B TRANSMISSION FORMAT FOR GRAFS0 COMMANDS 1. All characters received are passed transpar-ently 
until the special control character ETB is encountered (ETB = decimal 25). 2. Segment-level con~nands 
have the following 3-byte format: I ETB f SEGNO (CODE ( SEGNO is the segment number, 0-1S. CODE is 
further broken down:  iJll l oP) OF= 0 - OPEN * i - CLOSE 2 - DISPLAY 3 -ERASE 4 -DELETE The high 
order four bits of code are appli- cable only with the OPEN command. A "i" in the R bit signifies a refresh 
segment. 3. After an OPEN, all commands have the format:  I CNTRL I LEN I I CLE. bytes~ CTRL~23 -primitive 
graphic commands follow. CTRL=23 -return to segment-levei processing, (2) above. 0 <= LEN <= 255 . 316 
 APPENDIX C PRIME SUBROUTINES The following routines generate segment-level commands as previously described. 
CALL OPEN(N,IR) CALL CLOSE(N) CALL DISP(N) CALL ERASE(N) CALL DELETE(N) Routines listed below generate 
primitive commands. CALL MOVE(IX, IY) Generates a MOVE command to coordinate posi- tion (IX, IY). CALL 
CALL DRAW(IX, IY) Generates a LINE from the ~arrent position to (IX,IY). CALL POLY(IXA, IYA,N) that Produces 
a POLYLINE primitive. IXA and IYA are arrays containing N coordinate values. N must be less than 64. 
CALL CALL MARKER(IX,IY,N) CALL Draws a marker at (IX,IY). N is either O, denoting a point, or an ASCII 
character code. CALL T~XT (ITXT,N) Generate a text string at the current posi- tion. ITXT is an arra 
Z containing N characters, packed two to a word. CALL CALL ATTRIB(IATTR, N ) Generates a SET ATTRIBUTE 
primitive. IATTR is the attribute to be set, and N is its value. IATTR=I -boldness N=0 - normal N=I 
- bold IATTR:2 -linestyle N=0 -solid N=I dotted N=2 - dot-dashed N=3 dashed IATTR:3 -charsize N=0 -largest 
N=3 -smallest IATTR:4 -refresh N=0 - refresh off N=I -refresh on QUIT Generates a STOP command. The 
CLOSE routine automatically generates a STOP code, so QUIT is not normally needed. In addition, several 
routines are available provide higher level features. LINE(IXI,IYI,IX2,1Y2) Draws a line from (IXI,IYI) 
to (IX2,1Y2). RECTAN(IX, IY,IXSIZE,IYSIZE) Draws a rectangle with its lower left corner at (IX,IY). 
IXSIZE and IYSIZE are the length and height, respectively, in GRAFS0 coordinate units. NUM(I,IA,N) 
Converts the integer value I to an ASCII character string which is returned in the array IA. N is the 
number of characters stored in IA. Characters are packed two to a word. IA may be used in a subsequent 
call to TEXT to display the string. 317  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807409</article_id>
		<sort_key>318</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>56</seq_no>
		<title><![CDATA[A flexible, high performance interactive graphics system]]></title>
		<page_from>318</page_from>
		<page_to>322</page_to>
		<doi_number>10.1145/800248.807409</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807409</url>
		<abstract>
			<par><![CDATA[<p>A computer graphics system with refresh and storage displays, flat-bed plotter, digitizer and film recorder is described. The software structure comprises a device-independent, front-end graphics package and a driver program for each device. Two and three-dimensional vectors, hardware and software characters, transformations and windowing, picture segmentation, element and segment attributes, and input from interactive tools, such as a light-pen, are supported. The extent to which the system is used by different research groups shows that this is a very cost-effective way to provide computer graphics facilities.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Device-independent graphics]]></kw>
			<kw><![CDATA[Graphics subroutine package]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39073503</person_id>
				<author_profile_id><![CDATA[81100561115]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Hubbold]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Unit, University of Manchester, England]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P332693</person_id>
				<author_profile_id><![CDATA[81541503056]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[P.]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Bramhall]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Unit, University of Manchester, England]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>563875</ref_obj_id>
				<ref_obj_pid>965141</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Greenberg, Donald P. An interdisciplinary laboratory for graphics research and applications. Computer Graphics, Volume II, No.2.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Status Report of the Graphics Standards Planning Committee of ACM/SIGGRAPH. Computer Graphics, Volume II, No.3, Fall 1977.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563878</ref_obj_id>
				<ref_obj_pid>965141</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Caruthers, L. C., van den Bos, J. and A. van Dam. GPGS a device-independent General Purpose Graphic System for stand-alone and satellite graphics. Computer Graphics, Volume II, No. 2, Summer 1977.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[GINO-F User Manual. Computer-Aided Design Centre, Cambridge, England, December 1976.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A FLEXIBLE, HIGH PERFORMANCE INTERACTIVE GRAPHICS SYSTEM R. J. Hubbold &#38; P. J. Bramhall Computer 
Graphics Unit University of Manchester, England ABSTRACT A computer graphics system with refresh and 
stor- age displays, flat-bed plotter, digitizer and film recorder is described. The software structure 
com- prises a device-independent, front-end graphics package and a driver program for each device. Two 
and three-dimensional vectors, hardware and soft- ware characters, transformations and windowing, picture 
segmentation, element and segment attrib- utes, and input from interactive tools, such as a light-pen, 
aresupported. The extent to which the system is used by different research groups shows that this is 
a very cost-effective way to provide computer graphics facilities. KEY WORDS AND PHRASES : computer 
graphics, graph- ics subroutine package, device-independent graph- ics. CR category : 8.2 I. INTRODUCTION 
 In 1974 the University of Manchester established a Computer Graphics Unit (CGU) to provide a cen- tralised 
interactive graphics facility for use by different departments. The decision to set up a centralised 
graphics system was taken principally on economic grounds. Many other universities and research establishments 
in the UK, and elsewhere, have expensive interactive graphics systems which are dedicated to specific 
research projects. Our feeling was that many of these systems were under- utilised and that a great deal 
of duplication of software was taking place. Centralised multi-disciplinary interactive graph- ics facilities 
have been and are being estab- lished elsewhere (e.g. Cornell University [i], University of Texas at 
Austin), but our system is unique in the UK. A major constraint on us was the amount of money available 
for equipment and staff (£i00,000 for equipment; 2 people for system development, maintenance, user 
documenta- tion and instruction, and everything else!). This paper describes the background to our 
work, our hardware and software. A general description of the graphics software which we have developed 
is given, covering user requirements and design goals, facilities implemented, software structure, and 
some performance details. We believe that this is an appropriate moment at which to do this, since our 
graphics software is similar in structure and capability to the SIGGRAPH core system [2]. 2. BACKGROUND 
2.1. Activities to be supported by the system  In defining and implementing our system we had to meet 
the requirements of a wide spectrum of users from different disciplines. Three specific activ- ities 
had been identified for which facilities were to be provided: Interactive graphics using a high-performance 
refresh display, with light-pen and other input tools, for computer-aided design and other high- ly interactive 
applications. Digitizing of information from maps, engineer- ing drawings and other diagrams. - Flat-bed 
plotting for large, high-quality graph- ical output. The diversity of projects meant that a flexible 
graphics system was needed, but one whose perform- ance would be good enough to enable its effective 
application in individual cases. Another require- ment was that the computer was to be operated in a 
"hands on" environment by the users. This made it essential to have a robust system, especially as we 
envisaged it being used by up to three people pur- suing unrelated activities concurrently.  2.2. Hardware 
configuration and operating system Figure 1 shows our present (April 1978) hardware configuration. 
 The Vector General is a Series 3 DD3 model with light-pen, alphanumeric keyboard, 16 function switches, 
i0 control knobs and direct-memory access interface to the PDP-II. At present, it does not have 3-D transformation 
hardware. The digitizer has a recording area 1.5m. by im. and is located physically next to the teletype, 
enabl- ing them to be used interactively together. The flat-bed plotter, also l.Sm. by im., features 
 analogue vector generation hardware for drawing  31a 224 KBYTES [ RKI  I OP I DQII E SYNCHRONOUS 
CORE [ DI: INTERFACE 1 PDP-II/45 l LAT- BED ] /VECTOR COPY ~GENERAL DIGITIZER PLOTTER 1 HARDI )] 
Figure 1 smooth lines and will draw at up to 10cm./sec. The DQll 9.6Kbaud synchronous link connects 
the PDP-11 to a large ICL 1906A/CDC 7600 configuration housed in the University's Regional Computer Centre 
and allows the PDP-11 to transfer files to and from the large machines and to submit jobs for running 
on the 7600. The configuration is run under the DEC RSX-IID op- erating system. RSX-IID is attractive 
for this kind of work because of its real-time features, its structure (which provides good protection 
and makes it easy to install and modify new device driver software), and its supporting software (e.g. 
com- pilers, editors, file system and utilities). 3. GRAPHICS SOFTWARE 3.1. Requirements and implementation 
considera- tions Many of our users had no previous experience with interactive computer graphics but 
needed to be able to make progress with their projects without fol- lowing a long and tedious learning 
process. For this reason, the graphics system had to he easy to understand by computer users without 
expert comput- er science knowledge. For similar reasons it had to be usable from programs written in 
FORTRAN IV, although we are well aware that there are other languages which are superior to it in may 
respects, and this constrained us to implementing a package of FORTRAN-callable sub-routines rather than 
a graphics language. The applications to be implemented on the equipment in the CGU required that the 
graphics package should have lines and characters as its basic elements rather than higher-level objects 
such as volumes and surfaces. Therefore, at least as a first step, we required the provision of comprehensive 
facilit- ies for the generation of these, together with a simple picture-structuring scheme, 3-dimensional 
transformations and windowing, and access to input tools. The package had to be small; it also had to 
be fast for both the generation of output and the handling of input because of the highly-interactive 
nature of many of the applications which would use it. In addition, it had to ensure that the integrity 
and operability of the environment and itself would not be jeopardised by faulty application programs 
or incorrect user actions, and to be capable of easy maintenance and extension. Because single programs 
would want to use differ- ent graphical output devices, it was important to have, as far as possible, 
a package with a device- independent user interface. This capability is most easily provided by implementing 
a package based on a device-independent front end together with a device-dependent back end for each 
graphical device. Such a structure and division of labour is similar to that described by the Core Definition 
Subgroup of SIGGRAPH's Graphics Standards Planning Committee. It also fits neatly into the RSX-IID operating 
system's concept of user-written, applica- tion tion-specific programs, incorporating sub- routines from 
a library to communicate with device drivers provided in the operating environment. 3.2. The Front End 
Packages available in Britain which support a meas- ure of device independence include GPGS [3] (and 
also GPGS-F), and GINO-F, [4] a commercially mark- ted package used widely in British universities. Because 
we wished to provide a service as soon as possible after the hardware arrived, we initially used one 
of these (GINO-F) as our front end. This provided many of the facilities our users required, but it is 
written in FORTRAN IV and we soon found it to be too large and slow for our PDP-II and Vector General. 
Additionally, we did not regard the facilities for handling input tools as satis- factory for our purposes. 
Consequently, we chose to write a new front end in PDP-II assembler to overcome these deficiencies whilst 
maintaining as far as possible the same interface to the user- written applications software. This is 
implemented as a library of FORTRAN-callable subroutines, the necessary modules of which are linked with 
user- written program modules by an operating system ut- ility during program development. The facilities 
 319 provided by the front end are as follows. 3.2.1. Device selection and release : Applications software 
may use one device at once, selected by calling a device-nomination routine. This initial- ises the relevant 
back end and arranges for subse- quent graphical input/output requests to be sent to it until the applications 
software calls another routine to release it. A device suspend/resume capability is also implemented. 
This permits an application program to switch between different de- vices, such as a display and plotter, 
and to re- sume operations on each one at the point where they were suspended. 3.2.2. Generation of 
graphical output : 2-dimen- sional and 3-dimensional vectors can be generated in a variety of line styles 
(solid, dashed, etc.), widths and colours. Applications software can choose between the generation of 
broken lines by the output device hardware or by software in the front end. Characters can be generated 
by hardware or software. Hardware characters are drawn at a size selectable from a range of sizes provided 
by the output de- vice. (In the case of the flat-bed plotter, they are actually implemented by its device 
driver, but this mechanism is transparent to the applications software and the front end). Software characters 
are continuously variable in size and aspect ratio and are optionally transformable. 3.2.3. Transformation 
and windowing : Transforma- tion (scale, shift, shear, rotate) in 2 or 3 dim- ensions of vectors, points 
and software characters are provided. Axonometric and perspective projec- tions of 3-dimensional objects 
are also supported. Transformations are implemented using homogeneous coordinate representation. After 
transformation, windowing can be performed in 2 or 3 dimensions to orthogonal planes paral- lel to the 
axes of the output device. The posi- tions of the window boundaries are variable. 3.2.4. Picture segmentation 
: A simple mechanism for the structuring of graphical output into a single level of picture segments 
is supported. Facilities for complex and hierarchical structures are not required by applications currently 
using this sytem, but provision has been made for a sec- ond level, comprising picture subroutines, to 
be implemented. At the moment, a segment is the only entity which may be created, extended (i.e. re- 
opened), deleted, replaced or identified by an in- put tool such as the light-pen. A segment also has 
a status (visible/invisible) and attributes (default brightness, etc.) which may be altered at any time. 
 3.2.5. Support for interactive input tools : Tools currently supported are the light-pen, control knobs 
(potentiometers), alphanumeric keyboard, func- tion buttons, sense switch mask, tracking symbol and refresh 
clock of the Vector General display. These are divided into categories, e.g. keys, positioner% valuators, 
identifiers, time clocks, and the front end contains one or more subroutines to handle each category. 
This provides a measure of independence from handling invidual tools directly and allows for extension 
to include new tools. Each category falls into one of two classes, namely, event-gener- ating tools, 
e.g. keys, and non-event tools, e.g. valuators. An event-generating tool is enabled when an input request 
is issued for it and disabled again as the request is satisfied. Normally, only one such tool is enabled 
at once, but a mechanism is also provid- ed which simultaneously enables more than one, e.g. function 
buttons and light-pen, and accepts data from whichever the operator chooses to use first. Non-event-generating 
tools may be read at any time without display operator action. Support for the different categories 
of tool will be implemented for the Tektronix in the near futur% but only upwards compatibility from 
the Tektronix to the Vector General will be feasible. 3.3. The Back Ends All the back ends, exept the 
one for the Tektronix 4010, are regarded by the RSX-IID operating system as device drivers. Each can 
be loaded into and re- moved from main memory to suit changing require- ments whilst the operating system 
is running. Back ends have been written for the following de- vices: 3.3.1. Tektronix 4010 storage 
tube : This uses the RSX-IID teletype handler as the device driver. A small routine linked into the applications 
software with the front end performs the necessary code gen- eration and transmission. 3.3.2. CETEC 
flat-bed plptter : This takes the form of a spo01ing system, as it is impractical to have such a slow 
device online to the application program. Commands received from the front end are processed and filed 
by a pseudo-driver; the file is read and used to control the device itself by a sep- arate device driver 
at a later time. 3.3.3. III FR80 film recorder : This device is lo- cated 150 miles away at the Science 
Research Council Rutherford Laboratory in Oxfordshire. Input to the FR80 is generated at the CGU on magnetic 
tapes which are mailed to the Rutherford Laboratory for proces- sing. The back end which writes these 
tapes is another pseudo-driver; it compiles optimised code to reduce the amount, of tape used and also 
looks after writing administrative and accounting data onto the tape. 3.3.4. Vector General refresh 
display : This is the most interesting, widely-used and complex back end. It contains code to receive 
commands from the front end, compile optimised display instructions, manage space in the display file 
(including garbage collection to concatenate free space), look after picture segmentation, enable input 
tools, service their interrupts and pass data from them to the front end. It also controls the display 
processor so that refreshing occurs at the required rate and organises interlocks so that no changes 
are made to items in the display file whilst the display pro- cessor may access them. In addition, it 
implements a facility for making a dump of the picture on the Vector General screen onto the T4010 (and 
thence to tSe T4610 hard copy unit if desired) or the flat- bed plotter, by interpreting the contents 
of the 320 display file. This facility is triggered from the Vector General alphanumeric keyboard and 
is totally independent of the front end and all applications software- it can thus be used to take a 
snapshot of the screen at any time regardless of the current state of the applications software. Many 
of the applications using the CGU have found this very use- ful.  The display file is contained in 
the Vector General device driver. There are two main reasons why it is not included in the application 
task's address space. First, the space available for application- specific code would be reduced. Since 
the limit imposed by the PDP-II hardware (64k bytes per task) is not generous for complex applications, 
any re- duction could cause serious problems. Second, there would be a much higher risk of it being cor- 
rupted by faulty applications software. Such an occurrence could easily cause the display processor to 
run wild and crash the operating system; this must be avoided in a multi-user environment.  3.4. Front 
end/Back end Communication The two parts of the graphics system communicate by means of the standard 
RSX-IID input/output mechan- ism. Output is assembled By the front end for transmission to the back end 
in batches in order to reduce the time lost by the communication overhead. Because these back ends are 
separate pieces of soft- ware with a well-defined interface to the front end, they can be used by other, 
user-written special- purpose "front ends" if required. An example of such a "front end" is a program 
written in Algol 68C for one particular application which required the Vector General display driver 
for picture segmenta- tion, display file compilation and management, input tool handling, arranging refreshing, 
etc., but which needed facilities different from those in the multi- purpose front end we had implemented. 
 3.5. Performance  3.5.1. Space : The space required by the front end linked into a user-written application 
program var- ies with the number of facilities called upon. Typ- ically it is 5 kbytes, including a ½ 
kbyte buffer for assembling instructions to pass to the 5ackend. The size of the Vector General display 
driver's code and data is 9 kbytes, plus 20 kbytes allocated for the display file. 3.5.2. Speed : One 
measurement which can be made to determine the speed of the software is the rate at which output vectors 
can be generated; for the system described here it is a maximum of 800 per second. The main overhead 
on input is caused by the operating system and is of the order of 2 millisec~ ends per request. 3.5.3. 
Capacity : The Vector General can display about 4000 vectors Before flicker and swim Become an annoyance, 
depending on vector lengths. A 20 kbyte display file can hold about 5000 2-dimensional vectors, depending 
on the degree of optimisation the display file compiler has Been able to achieve and the number of segments 
the picture is divided into. 3.5.4. Ease of maintenance : Device drivers can Be changed as easily as 
user-written programs. There is no need to perform a new system generation to extend or change supported 
features. Because most changes and all extensions to a device driver do not affect the definition of 
the front end/back end interface, modifications to the back end usually require no complementary action 
by users; where this is not so, all that a user needs to do is to link the corresponding new version 
of the front end into his program. Modifications to the front end are incorporated into a user's program 
by the same simple process. 4. DIGITIZER SOFTWARE Input from the digitizer is supported by a separate 
library of FORTRAN-callable subroutines. Together with a device driver, these provide facilities for 
single point digitizing, stream digitizing (either equal time or equal distance intervals between points), 
correction of coordinates to allow for paper skew, and menu handling. Alphanumeric input/ output can 
be performed on an adjacent teletype. In most cases, recording of information on the dig- itizer and 
its subsequent display and manipulation are separate steps performed with different pro- grams. This 
is not because of any constraint in the software but because it is not usually justifiable to tie up 
a display terminal for long periods of time when it can be used more profitably by someone else. In any 
case, we have found that it usually pays to make digitizing as simple as possible in order to minimise 
errors. Nevertheless, calls to the graphics routines can be incorporated in digitizer programs in order 
to pro- duce a display or plot of the recorded information. This is employed By several projects in order 
that an operator can take a "snapshot" of the informa- tion recorded so far, in order to check and correct 
errors. 5. APPLICATIONS Forty people from fifteen different university de- partments are using the 
computer graphics system which we have described. They include the follow- ing disciplines (the list 
is far from exhaustive): Anatomy (analysis of human abnormality); Astronomy (galactic evolution); Computer 
Science (printed circuit board layout, computer animation, software research); Dentistry (orthodontic 
treatment planning); Engineering (simulation of atomic power stations, display of wind tunnel test data); 
Geography (thematic cartography); Geology (geophysical modelling); High-energy physics (.analysis of 
particle tracks); Radio astronomy (spectrum analysis); Urban research (traffic simulation, network an- 
alysis); X~ray crystallography (molecular structure anal- ysis); Zoology (reconstruction and analysis 
of insect nervous systems).  The majority of these make extensive use of the in- teractive capability 
of the Vector General and its supporting software. Many exploit the ease and rap- idity with which displayed 
picture segments can be updated to implement dynamically changing displays. 321 Examples of this include 
3-D rotation, representa- tion of time-dependent situations, and dynamic mod- ification of computed 
graphs and surfaces by a dis- play operator. Another popular technique is the use of light-pen menus 
to make programs easy to op- erate by technicians and non-computer staff. 6. EXPERIENCE TO DATE AND 
FUTURE PLANS The system which we have described has been in nor- mal operation since the beginning of 
1975. On av- erage it is now being used by one or more people at once for 9 hours per day, 7 days a week. 
Cur- rently, twenty-two projects are being pursued. Dividing the cost of all our hardware by this fig~ 
ure yields a cost per project of less than £5000, or about half the cost in the UK of a Tektronix 4014. 
 The progress made by our users, many of whom had no previous experience of computer graphics, seems 
to us to be due to two main factors. The first is that they have been able to concentrate on their applications 
and leave systems programming aspects to the staff of the Unit. The second is that the "hands-on" environment 
has encouraged them to learn about the system's capabilities and to apply them effectively, as well 
as fostering cross-fertilisa- tion of ideas between disciplines. We believe that successful use of our 
system to date has clearly demonstrated that a single, flexible graph- ics system can satisfy the requirements 
of a broad range of users and application areas in a highly cost-effective manner.  We have recently 
concluded an agreement with the Science Research Council which will result in sev- eral major new projects 
being undertaken in the near future. In order to cope with the increased load we are about to expand 
our system by adding 80 Mbytes of disc storage and more core store to the PDP-II, and refresh memory 
and transformation hardware to the Vector General. 7. ACKNOWLEDGEMENT Some parts of our graphics software 
are based quite closely on the GINO-F package. We are grateful to the Computer-Aided Design Centre 
for supplying us with that package under a special agreement. REFERENCES I. Greenberg, Donald P. An 
interdisciplinary laboratory for graphics research and applica- tions. Computer Graphics, Volume II, 
No.2. 2. Status Report of the Graphics Standards Plan- ning Committee of ACM/SIGGRAPH. Computer Graphics, 
Volume II, No.3, Fall 1977.  3. Caruthers, L. C., van den Bos, J. and A. van Dam. GPGS a device-independent 
General Purpose Graph- ic System for stand-alone and satellite graph- ics. Computer Graphics, Volume 
II, No.2, Summer 1977.  4. GINO-F User Manual. Computer-Aided Design Cen- tre, Cambridge, England, December 
1976.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807410</article_id>
		<sort_key>323</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>57</seq_no>
		<title><![CDATA[A generalized graphic preprocessor for two-dimensional finite element analysis]]></title>
		<page_from>323</page_from>
		<page_to>329</page_to>
		<doi_number>10.1145/800248.807410</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807410</url>
		<abstract>
			<par><![CDATA[<p>Input preprocessors have come to be recognized as important components of modern finite element programs. A method is described which utilizes interactive computer graphics digitizing techniques to create a powerful input preprocessor for finite element analysis. A limited number of general mesh generators based on linear blending functions permit the program to handle virturally all two-dimensional topologies. The processes of geometric input and specification of problem-specific &#8220;attributes&#8221; have been kept separate so that the mesh generation routines may be used with a variety of analysis programs. Graphical editors have been implemented to specify attributes for structural mechanics problems. Although this type of graphical preprocessor shows considerable promise for applications in three dimensions, there are still unresolved problems in the areas of geometrical description, perception, and interactive hardware.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Finite element preprocessing]]></kw>
			<kw><![CDATA[Mesh generation]]></kw>
			<kw><![CDATA[Structural analysis]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Input devices</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.8</cat_node>
				<descriptor>Finite element methods</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Graphics editors</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003718</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computations in finite fields</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010391</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics input devices</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14194515</person_id>
				<author_profile_id><![CDATA[81100560180]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Haber]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics and Department of Structural Engineering, Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P332329</person_id>
				<author_profile_id><![CDATA[81339527958]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shephard]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics and Department of Structural Engineering, Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39037532</person_id>
				<author_profile_id><![CDATA[81100320367]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Abel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics and Department of Structural Engineering, Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14034160</person_id>
				<author_profile_id><![CDATA[81100068176]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gallagher]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics and Department of Structural Engineering, Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P68460</person_id>
				<author_profile_id><![CDATA[81100196982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Greenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics and Department of Structural Engineering, Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Singh, S., "A Computer-Aided Finite Element Idealization and Mesh Generation System," 2nd Int. Conf. on Computers in Eng. and Building Design, (CAD '76), Imperial College, London (March 1976).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Kamel, H.A. and McCabe, M.W., "Application of GIFTS III to Structural Engineering Problems," Computers and Structures, Vol. 7, No. 3 (June 1977), p. 399.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Leick, R.D. and Potvin, A.B., "Automated Mesh Generation for Tubular Joint Stress Analysis," Computers and Structures, Vol. 7, 1977, pp. 73-91.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Jones, R.E., "A Self-Organizing Mesh Generation Program," Journal of Pressure Vessel Technology, ASME, Vol. 96, No. 3, pp. 193-199 (Aug. 1974).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Leverenz, R.K., et al, "Using Interactive Graphics for the Preparation and Management of Finite Element Data," General Motors Research Publication, GMR-1486, 1974.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kamel, H.A. and Shanta, P.J., "A Solid Mesh Generation and Result Display Package," Journal of Pressure Vessel Technology, AMSE, Vol. 96, No.3 pp. 207-312 (August 1974).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>889976</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Coons, S.A., "Surfaces for Computer-Aided Design of Space Forms," Report MAC-TR-44, MIT, Cambridge, Mass. (1967).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Herrman, L.R., "Laplacian-Isoparametric Grid Generation Scheme," J. of the Eng. Mechs., Div. ASCE, 102, pp. 749-756 (1976).]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Zienkiewicz and Phillips, D.V., "An Automatic Mesh Generation Scheme for Plane and Curved Surfaces by Isoparametric Co-ordinates," Int. J. Num. Meth. Engrg., 3, 519-529 (1971).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>355712</ref_obj_id>
				<ref_obj_pid>355705</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Gibbs, N.E., Poole, W.G. and Stockmeyer, K., "Algorithm 508: Matrix Bandwidth and Profile Reduction," ACM Trans. on Mathematical Software, No. 4 (Dec. 1976), pp. 375-377.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359848</ref_obj_id>
				<ref_obj_pid>359842</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Wu, S.C., Abel, J.F., and Greenberg, D.P., "An Interactive Computer Graphics Approach to Surface Representation," Communications of the ACM, Vol. 20, No. 10 (Oct. 1977), pp. 703-712.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A GENERALIZED GRAPHIC PREPROCESSOR FOR TWO-DIMENSIONAL FINITE ELEMENT ANALYSIS by Robert Haber, Mark 
Shephard, John Abel, Richard Gallagher, and Donald Greenberg Program of Computer Graphics and Department 
of Structural Engineering Cornell University ABSTRACT Input preprocessors have come to be recognized 
as important components of modern finite element pro- grams. A method is described which utilizes interactive 
computer graphics digitizing techniques to create a powerful input preprocessor for finite element analysis. 
A limited number of general mesh generators based on linear blending functions permit the program to 
handle virturally all two-dimensional topologies. The processes of geometric input and specification 
of problem-specific "attributes" have been kept separate so that the mesh generation routines may be 
used with a variety of analysis programs. Graphical editors have been implemented to specify attributes 
for structural mechanics problems. Although this type of graph- ical preprocessor shows considerable 
promise for applications in three dimensions, there are still unresol- ved problems in the areas of geometrical 
description, perception, and interactive hardware. COMPUTING REVIEWS CLASSIFICATION: 3.20, 3.23, 8.2 
KEYWORDS: Finite Element Preprocessing, Computer Graphics, Mesh Generation, Structural Analysis I. INTRODUCTION 
2. Separation of Geometr[ Generation and Attribute Editing The increased use of general finite element 
pro- grams in recent years has underlined the need for Although different analysis routines generally 
efficient methods of preparing input data for an- utilize different input data, they all require a alysis. 
This has resulted in a proliferation of discretized geometric description. For this rea- preprocessor 
programs which vary widely in their son, the preprocessor system separates the pro- degree of generality, 
input method, and usage of cesses of geometric definition from the specifica- computer graphics. Several 
illustrative preproces-tion of problem-specific attributes such as element sor systems are described 
in references 1 -6. types, material properties, and boundary conditions. The geometry generator may 
therefore be used with a This paper describes the computer graphics prepro- problem-specific "attribute 
editor" to provide all cessor system developed for CIFEP (Corneli Inter-of the necessary input data required 
for a particu- active Finite Element Program). The preprocessor lar analysis program. has been designed 
to handle virtually all possible two-dimensional topologies. Meshes are generated 3. Use of Subregions 
to Define a Geometry automatically under the interactive control of the user. The analyst can easily 
control the refine- The problem geometry is defined by the analyst as ment of the mesh in order to produce 
an efficient a series of simple subregions. Each subregion is mesh for any desired loading. Extensive 
use of a defined by either two, three, or four edge curves. variety of graphical input methods and a 
unified This facilitates the description of complex forms overall design have resulted in a preprocessor 
that and also provides a natural method for blocking is both efficient and easy to use. large data sets 
in a minicomputer environment with limited high speed storage. The success of the preprocessor system 
is due to several key features of its basic design: 4. Use of General Automatic Mesh Generators I. Graphical 
Input The preprocessor utilizes a limited set of general mesh generators rather than relying on a large 
Wherever possible, computer graphics digitizing library of special purpose mesh generators. This techniques 
have been used to replace tedious key- improves the ease of operation of the system with- board input 
methods. These methods dramatically out sacrificing flexibility. reduce input time and errors. Numerical 
accuracy is maintained through the use of positioning grids and The operation of the geometry generator 
as well as automatic curve generators. The option for key- the algorithms for the mesh generators will 
be pre- board input is maintained for cases where it is more sented below. An attribute editor for two-dimen- 
convenient. Immediate visual feedback is provided sional structural mechanics problems will also be to 
the user throughout the input process. presented. Finally, extensions of the preprocessor to three-dimensional 
problems will be discussed. 323    III. ATTRIBUTE EDITORS FOR STRUCTURAL MECHANICS After completing 
the task of geometry generation, the analyst must specify problem-specific attri- butes in order to complete 
the process of data in- put. A series of attribute editors have been im- plemented+for two-dimensional 
structural mechanics problems. These editors were specifically designed to compliment the capabilities 
of CIFEP. Three general categories of attributes must be speci- fied: i) Boundary conditions 2) Loading 
3) Element properties Most of the data input for attribute editing is accomplished by graphical interaction. 
The editors have been implemented in a modular fashion so that new editors or modifications may be introduced 
as the capabilities of the analysis program are modi- fied or extended. The individual attribute editors 
are described below. Boundary conditions may be applied to the structure as nodal restraints or in the 
form of multi-point constraint equations. The nodal restraint editor allows the analyst to specify 
which degrees of freedom in the structure are free to translate and which are fixed against translation. 
The user may graphically create and edit a list of nodal re- straint types. All six three-dimensional 
rota- tional and translational degrees of freedom may be specified. The attributes of any nodal type 
may then be attached to any node simply by "pointing" at the node. A node type may also be attached 
to a series of nodes by "pointing" to a boundary curve. The nodal constraint editor permits the specifica- 
 tion of multi-point constraint equations for any degree of freedom in the structure. The type of constraint 
permitted defines any specified dis- placement component as a constant value plus a linear combination 
of several other displacement components. Constraint equations may be of use in a variety of situations 
such as problems involving support movement, the application of proper bound~ ary conditions along lines 
of symmetry, and in maintaining interelement compatability in transi- tion grids. The analyst may specify 
certain com- mon constraints graphically, such as linear edge constraints and skewed support conditions. 
More general constraints may be specified numerically. Two editors are available for specifying structural 
loadinss. The nodal load editor is used to specify concentrated nodal point loads. Its operation is 
similar to that of the nodal restraint editor. The analyst may create a list of nodal point load types 
consisting of forces and moments in the X,Y, and Z directions. These forces may then be applied to a 
single node or group of nodes by pointing. The edse load editor is used for specifying distributed element 
loads. These loads may be applied along a single element edge or along a portion of a bound- cry curve. 
The magnitude and direction of the load may vary along the edge. Element specific routines convert the 
specified distributed loads into con- sistent equivalent nodal forces. These forces are then summed 
with the loads specified with the nodal load editor to create a load vector for the analysis routines. 
CIFEP has multiple load case capabilities and can handle up to four simultaneous load cases. The element 
propert_~ editor is used to specify ele- ment types and element properties. The specifica- tion of element 
type resolves ambiguities such as whether a three-noded triangle represen~a membrane or plate bending 
element. The element properties that must be specified are dependent on the type of each element. Assignment 
of element properties may be done interactively on either an element-by- element or subregion basis. 
 IV. EXTENSION OF THE PREPROCESSOR TO THREE DIMEN- SIONS While most of the problems of two-dimensional 
 interactive graphical preprocessing have been solved, the important case of three-dimensional preprocessing 
still requires further research. In theory, the methods used in the two-dimensional preprocessor can 
be extended to handle problems in- volving three-dimensional solids. The object to be analyzed could 
be subdivided into a series of sub- regions composed of either brick-shaped or tetra- hedronal volumes 
defined by four-sided or three- sided boundary surfaces. The boundary surfaces would be defined by grids 
of key nodes in a manner analogous to the way boundary curves are defined by series of key nodes in the 
two-dimensional sys- tem. The spacing of key nodes on the boundary sur- faces would control the spacing 
of interior nodes generated according to three-dimensional analogs of the two-dimensional mappings. 
 In practice several problems arise in the develop- ment of a truly general three-dimensional prepro- 
 cessor which do not occur in the less demanding two-dimensional case. Most of the successful existent 
three-dimensional preprocessors have been written to handle only certain classes of structures~ in order 
to avoid the problems occurring in the general three-dimensional case. 3 A basic problem arises from 
the difficulties inherent in graph- ically communicating three-dimensional data through two-dimensional 
surfaces such as display screens and digitizing tablets. Although several attempts have been made to 
implement three-dimensional graphic input systems, none have succeeded in match- ing the efficiency, 
generality, and accuracy of two-dimensional systems. Three-dimensional finite element preprocessors 
have thus far been heavily dependent on keyboard input for coordinate data. It will probably continue 
to be necessary to accept some loss of generality in the graphical input pro- cedures and to depend 
more on keyboard input for the definition of the boundary surfaces. Interpre- tation of three-dimensional 
perspective displays is also problematic. It will be necessary to uti- lize techniques such as sectioning, 
dynamic rota- tion, simultaneous views, hidden line removal and shaded displays to overcome these difficulties. 
All these techniques are expensive, both in terms of computation and hardware. 32@ Difficulties also 
arise from the more complex forms of three-dimensional problems which do not occur in two dimensions. 
For example, cutouts and cavities complicate mesh topology. It would often be desir- able to create complex 
forms by merging simpler forms. This would require an effective means of manipulating these forms in 
space as well as a gen- eral method of computing the intersections of two volumes. The necessary data 
base and checking sys- tem required to maintain consistent node and ele- ment numberings would also be 
considerably more complicated. The maintenance of proper continuity of adjacent boundary surfaces represents 
yet an- other complication that arises in the three-dimen- sional case. This problem can be largely overcome 
using surface mappings based on spline representa- tions.ll V. CONCLUSION The preprocessor system for 
CIFEP represents a gen- eral, efficient, and easy to use system for the automatic generation of two-dimensional 
finite element grids. The use of interactive computer graphics input techniques greatly reduces the 
task of data input. Generality of the preprocessor has been maintained by separating the processes of 
geo- metry generation and attribute editing. This per- mits the use of the geometry generation routines 
with a variety of analysis routines. The value of graphical input techniques has also been demon- strated 
by the attribute editors developed for structural mechanics problems. Extensions of the techniques 
employed in the two- dimensional preprocessor show promise as the foun- dation of a three-dimensional 
system. However, many problems remain unsolved. The resolution of these problems will require a combination 
of effi- cient data management, innovations in graphical in- put and display techniques, and possibly 
develop- ment of new graphical hardware. ACKNOWLEDGEMENTS The research is part of a project sponsored 
by the National Science Foundation under grant number ENG75-17400 entitled "Interactive Computer Graphics 
in Structural Mechanics." All work was performed at the laboratory of Cornell University's Program of 
Computer Graphics which is partially funded by National Science Foundation grant number DCR74- 14694. 
The system is presently operated on a PDP 11/50 minicomputer using an Evans and Sutherland Picture System 
I. The authors are indebted to their colleague Sheng-Chuan Wu. REFERENCES i. Singh, S., "A Computer-Aided 
Finite Element Idealization and Mesh Generation System," 2nd Int. Conf. on Computers in Eng. and Building 
Design, (CAD '76), Imperial College, London (March 1976). 2. Kamel, H.A. and McCabe, M.W., "Application 
of GIFTS III to Structural Engineering Problems," Cgmputers and Structures, Vol. 7, No. 3 (June 1977), 
p. 399.  3. Leick, R.D. and Potvin, A.B., "Automated Mesh Generation for Tubular Joint Stress Analysis," 
Computers and Structures, Vol. 7, 1977, pp. 73-  91.  4. Jones, R.E., "A Self-Organizing Mesh Genera- 
tion Program," Journal of Pressure Vessel Tech- nqlo~y, ASME, Vol. 96, No. 3, pp. 193-199 (Aug.  1974). 
 5. Leverenz, R.K., eL al, "Using Interactive Graphics for the Preparation and Management of Finite 
Element Data," General Motors Research Publication, GMR-1486, 1974.  6. Kamel, H.A. and Shanta, P°J., 
"A Solid Mesh Gen- eration and Result Display Package," Journal of Pressure Vessel Technology, AMSE, 
Vol. 96, No.3 pp. 207-312 (August 1974).  7. Coons, S.A., "Surfaces for Computer-Aided Design of Space 
Forms," Report MAC-TR-44, MIT, Cambridge, Mass. (1967).  8. Herrman, L.R., "Laplacian-Isoparametric 
Grid Generation Scheme," J. of the Eng. Mechs.~ Div. ASCE, 102, pp. 749-756 (1976).  9. Zienkiewicz 
and Phillips, D.V., "An Automatic Mesh Generation Scheme for Plane and Curved Surfaces by Isoparametric 
Co-ordinates," Int.  J. Num. Meth. Engrg., 3, 519-529 (1971). i0. Gibbs, N.E., Poole, W.G. and Stockmeyer, 
K., "Algorithm 508: Matrix Bandwidth and Profile Reduction," ACM Trans. on Mathematical Soft- ware, No. 
4 (Dec. 1976), pp. 375-377. ii. Wu, S.C., Abel, J.F., and Greenberg, D.P., "An Interactive Computer 
Graphics Approach to Sur- face Representation," Communications of the ACM, Vol. 20, No. i0 (Oct. 1977), 
pp. 703-712. 329 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807411</article_id>
		<sort_key>330</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>58</seq_no>
		<title><![CDATA[An interactive graphics application to advanced aircraft design]]></title>
		<page_from>330</page_from>
		<page_to>335</page_to>
		<doi_number>10.1145/800248.807411</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807411</url>
		<abstract>
			<par><![CDATA[<p>Throughout the 50's, 60's and now the 70's, computer usage has continually been on the increase and, from all indications, this trend will continue in the future. Early computer application programs were run by &#8220;computer experts&#8221; with the engineers interfacing with the programmers to get their &#8220;batch&#8221; program run. With the advent of the remote access terminals a more efficient and direct interface to the computer was made available to the engineer-user. More recently the introduction of the storage tube and refreshed tube CRT's linked to computers has now provided the engineers with a graphic interface that is even more direct, and hopefully, more efficient. This introduction of computer-graphics resulted in a proliferation of graphics programs in the aerospace industry. Soon most of the analytically oriented specialities (e.g. Aero-dynamics, Structures, Loads, etc. ) were boasting of powerful graphics programs to assist them to more effectively perform their functions.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.2</cat_node>
				<descriptor>Aerospace</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Application packages</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010433</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Aerospace</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P329566</person_id>
				<author_profile_id><![CDATA[81100494491]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Bouquet]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lockheed-Georgia Company]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 AN INTERACTIVE GRAPHICS APPLICATION TO ADVANCED AIRCRAFT DESIGN D. L. Bouquet Lockheed-Georgia Company 
 INTRODUCTION Throughout the 50's, 60's and now the 70's, computer usage has continually been on the 
increase and, from all indications, this trend will continue in the future. Early computer application 
programs were run by "computer e~oerts" with the engineers interfacing with the programaers to get their 
"batch" program run. With the advent of the remote access terminals a more efficient and direct interface 
to the computer was made available to the engineer-user. More recently the introduction of the storage 
tube and refreshed tube CRT's linked to computers has now provided the engineers with a graphic interface 
that is even more direct, and hopefully, more efficient. This introduction of c(mputer-graphics resulted 
in a proliferation of graphics progra, s in the aerospace industry. Soon most of the analytically oriented 
specialities (e.g. Aero- dynamics, Structures, Loads, etc. ) were boasting of powerful graphics programs 
to assist them to more effectively perform their functions. Lockheed quickly recognized a potential 
in the computer-graphics area of providing the design integrator, or the "board designer," with a tool 
to assist him in the accomplishment of his job. Heretofore the assistance the board de- signer received 
from the computer was usually in the form of digital printouts to provide him geometric data or perhaps 
preliminary "first cut" performance calculations. In early 1964 a feasibility study was initiated to 
determine if computer-graphics could assist the advanced, or preliminary design engineer in developing 
an integrated aircraft three-view. By 1968 the feasibility had been demonstrated; however, the general 
aerospace industry slowdown was on the horizon and the associated financial pressures and priorities 
forced a halt to this activity. By late 1974 Lockheed had developed its well- known Computer-graphics 
Augmented Design and Manufacturing (CADAM) system as well as a host of interactive structures packages 
and other graphics programs. Additionally a modest effort was initiated and again directed specifically 
toward developing a graphics tool to assist the preliminary design engineer in developing an aircraft 
three-view. This paper will describe this effort and some potential applications of its product, GRADE, 
Graphics for Advanced Design Engineers. BASIC CONCEPT Programming jobs in graphics are, in general, 
time conseming and somewhat more difficult than the more familiar non-graphics programs. This usually 
results in conloromising the operations involved in the graphics man-machine interface in favor of procedures 
that make the progrannn- ing easier. Some of the compromises could, for instance, require the user to 
have considerable aptitude in recognizing mathematical curves, or functions, performing special operating 
sequences, and unfortunately, typing. One of the prime directives laid down for the GRADE program was 
that the software be designed for the user's ease of operation and to in- corporate ~liar procedures 
that the user normally followed in the routine acc~lishment of his job. This directive is considered 
very i/~portant from the standpoint of user accep- tance. Designers, especially the "old timers," have 
developed their own systems for accomplish- ing their jobs and tend to be reluctant to change. Therefore, 
the more nearly a new system approximates theirs, or uses portions of existing procedures from their 
systems, the more readily they will embrace the new brain- child. The system must be designed for user 
acceptance. A one-hundred percent technically perfect con%outer system that no one uses is one-hundred 
percent worthless. Obviously this directive cannot be "cast in concrete" and it was recognized that sometimes 
this directive too tin/st be compromised especially when in- ordinate amounts of progra~ning time, machine 
time, and/or machine response time would be involved in trying to meet the user's desires. The directive 
was followed whenever practicable and all procedures that tended to force the designer into using uncomfortable 
procedures, or into becoming a typist, math and/or computer "expert" were avoided. As a general rule 
the programs were designed with the thought in mind to replace the designer's paper with the scope, and 
his pencil with the light pen. GRADE was designed from conception for the user. Another directive required 
that the software be developed in modular form versus one long all- encompassing program. Very lengthly, 
"Solve all the world's problems," type programs are difficult to manage from a data management standpoint, 
and due to the domino effect in series programming these programs must frequent- ly have large portions 
rewritten when a "glitch" is found somewhere in the subroutines. It is also difficult for more than 
one programmer to work on at a time. The modular approach permits more programming flexibility, easier 
check-out and debugging and lends itself more readily to program modifi- cations. ~he modular approach 
also provides conspicuous milestones to attest to the pro- gress being made which may be essential in 
the real life atmosphere of in-house research where all programs are competing for a slice of the political 
or budgetary pie. AIRCRAFT COMPONENT DEVELOPMENT Cargo Compartment The cargo compartment, an obvious 
starting place for the layout of a new cargo transport aircraft, was the first module progranm~d. The 
 design option programmed first was a generalized rectangular box in side, plan, and front view with 
the capability to cut off the upper corners in the front view if desired. By using the light pen to 
identify the line to be moved, and then picking an option to use light pen or type-in, the designer 
can readily shape the cargo compartment into the desired en- closure configuration. A line changed 
in any one view is automatically changed, as appropriate, in the other views. There are other generalized 
cargo compartment shapes to be progranm~d, however, in this module, as in the others, only the most 
likely option was pro- grammed at this time due to budgetary and schedule constraints. Fuselage The 
fuselage proved to be quite a more formid- able undertaking. A completely generalized fuselage design 
routine was quickly ruled out as this would have required a prohibitive amount of programming time. A 
specific fuse- lage concept was chosen in order to demonstrate feasibility and user acceptance within 
a reason- able milestone time schedule. The fuselage was defined as having a constant center section 
with a faired forward and aft section. In this side view the curved lines making up the crown and keel 
lines are either third degree poly- nominals to provide inflection points if needed, or general conics 
as shown in Fig. i. The basic fuselage cross section (constant region) is constructed either by moving 
a light pen sensitive cursor in order to position the necessary control points, or by type-in n~neric 
locations. The choice of arc to connect the control points are either circular or ellipti- cal or any 
combination of the two. Connecting 3RD D. pOLYN. CONIC / ALL CONTROL POINTS MAY BE LIGHTPEN MOVED OR 
TYPED IN. 3RD D. FOLYN. Figure 1. Fuselage Control Points and Curies arcs may either be tangent at a 
common point or at some slope (input) to each other. Fig. 2 depicts a typical cross section, types of 
arcs, and control points. When control points are moved, arcs chosen, and slopes designated the software 
will test for the mathematical possi- bility of the geometric construction and will not accept a "bad" 
(geometrically impossible) input, and will wait for another choice. After a control point is located 
a menu pick named "coordinate" permits exact dimensional check. A "zoom" menu pick permits any enlargement/re- 
duction desired. /-CONTROL POINTS ~ ~ cSLOPE RANGE DESIRED ) ~r" TANGENCY/SLOPE "j k~ CONTROL POINTS 
MOVE IN ANY v DIRECTI ON / ALL CURVES /~.~ MAY BE / CIRCULAROR CROSS TO MOVE OR TYPE IN LOCATION Figure 
2. Cross Section Control Points and Curves 331 Fairing the Fuselage The fuselage is "faired" between 
the constant cross ection and the most forward part of the nose and between the constant cross section 
and the most aft part of the tail. This is unique- ly accomplished by moving the end points of the "crease 
lines" where it is desired to "fair-out" (eliminate) the crease. This crease line may be a "hard" (visible) 
crease or a "soft" mathematical crease (tangent control point) line. Fig. 3 shows an example of each. 
The program will currently generate an upper and a lower crease line. In the forward and aft fuselage 
fairing routine a mathematical expression ensures the proper cross-section interpolation and/or extrapolation 
to give a Em~oth transition (faired surface) from the constant fuselage section through the forward and 
aft sections. CONTROL I "HARD" CREASE MAXIMUM HALF BREADTH TANGENCY ~._ SHOULDER POINT / Figure 3. "Hard" 
and "Soft" Crease Lines Figure 4 shows the side view control points that are moved (4) to determine where 
the crease lines fair-out. The cross sections in the lower portion of the figure are then con- structed 
(a quarter section at a time) to be used as mathematical reference points for automatic interpolation/extrapolation 
of cross- sectional data as required to complete the fuselage fairing. Mathematical continuity between 
the fore and aft fuselage curves and the cross section arcs and control points per- mits a complete surface 
definition of the fuse- lage. Wing The geometric design of a subsonic transport wing is relatively 
straight-forward and is accomplished readily in the GRADE program. After menu picking "WING" an input-required 
list asks for: AREA miST ASPECT RATIO INCIDENCE SWEEP ROOT AIRFOIL TAPER RATIO TIP AIRFOIL DIHEDRAL 
 f I Y. ,,3 ~" CONTROL POINTS (4) TO LOCATE ENDS OF CREASE LINE -~ L~ HORIZONTAL MOVEMENT MATHEMAll 
CALLY 4-~ POSSIBLE i I IS DISPLAYED I Q I 3 /4 CROSS SECTION 1/4 CROSS SECTION DISPLAYBEFORE AFTER 
PICKI N G LOCATING POINT DESIRED SLOPE HORIZONTALLY (FWD UPPER S=.,c'noN) ~ i I I ~ LIMITS OF SLOPES 
THAT ARE MATHEMATICALLY POSSIBLE FOR TANGENCY CONDITION ARE DISPLAYED 2 1/4 CROSS SECTION AFTER LOCATING 
POINT HORIZONTALLY (FWD LOWER SECTION Figure 4. Fuselage Fairing Technique After typing in this input 
the dimensional data is calculated and a plan and side view of the wing is displayed on the scope. Four 
and five digit series airfoil data points can be automa- tically calculated from equations of the mean 
camber line and thickness distribution, while the super critical airfoil must be splined from input coordinates. 
Having a basic wing planform the designer has an option to keep this single panel wing or to change the 
leading and/or trailing edge geometry to design a 2 or 3 panel wing for fuel, landing gear, flow pattern 
improvements, etc., as necessary. Figure 5 shows typical planforms. An engineer who has laboriously "plowed 
through" the mean- aerodynamic-chord (M.A.C.) calculations for a 3-panel wing can readily appreciate 
the time savings by having this automatically done by the computer. The M.A.C. length and X, Y, location 
from the wing root leading edge is also scope-output. The wing is located on the fuselage by the  input 
of fuselage station and water line where it is desired to locate the quarter-chord of the wing M.A.C. 
Future incorporation of a balance routine will give a "first-cut" estimate of this location. 1~ PANEL 
  @ -- -Z Figure 5. Typical 1, 2 &#38; 3 Panel Wing Planforms Empennage The empennage program, like 
the wing program, was relatively simple to set up and many of the routines for geometry and M.A.C. calculations 
were derived from the wing program routines. However, as any broad designer could confirm, the integration 
of the empennage with the air- craft three-view, and the associated matching of tail arms, tail sizes 
and tail volume coefficients, is a manner of much iteration, trial and error, erasing, and drawing. 
An internal iteration sizing program uniquely determines the horizontal and vertical tail areas required 
to maintain the given tail volume coefficients consistent with the location of the quarter chord of the 
wing, vertical, and horizontal M.A.C., and the length of the fuselage. The engineer inputs empennage 
data similar to the wing input menu and locates the empennage by a fuselage and water line location-(user 
input) of the trailing edge point of the vertical root chord. This is accomplished in real time in just 
a few seconds after which the scope output depicts the correct empennage located on the fuselage as 
in Fig. 6. An option permits changing the basic geometry of the vertical and/or horizontal for structural 
and/or aerodynamic reasons whereby the program will again iterate to the proper sizes and locations. 
 Figure 6. Typical Empennage Located on Fuselage Nacelle/Pylon This program defines the nacelle/pylon 
geometry and locates the nacelle center-of-gravity at the wing station, fuselage station and water line 
specified by the designer and input by type-in. The designer sizes (wraps) a nacelle about an input engine 
diameter and length. Con- trol points and types of arcs available are shown in Fig. 7.  AIRFOILS (INPUT) 
E  LC, E E / E,/ SPECIFY CONTROL POINTS (LIGHTPEN OR TYPE-IN) SLOPE (ALL AFT PT) ---BASIC INPUT DIAMETER 
AND LENGTH C CIRCLE E ELLIPSE Figure 7. Nacel!e/P),lon Geometry The designer may design from 1 to i0 
engines per side of aircraft and may locate the engines above or below the wing, on the sides of the 
aft fuselage, on the aft fuselage centerline, and/or combinations of these locations. A duplicating routine 
permits the designer to quickly duplicate any nacelle/pylon desired thus saving design time on the scope 
when the engine configuration permits. Win~-Fuselage Intersection Fairing The wing-fuselage intersection 
fairing has always been an area of concern to the board- designer-integrator due to the significant impact 
on interference drag and the difficulty in determining the geometric shape and inter- sections from a 
drafting standpoint. Historically the original layout of a fairing, although there are some basic rules 
applied by good designers to the "angle-of-attack" of the fairing and its overall fineness ratio, is 
more an area of art than analysis and many designers take considerable artistic license when describ- 
ing this fairing. After the fairing is drawn on the preliminary design, a wind tunnel model is constructed 
and many different "clay models" of the fairing intersection are tested in order to find the one with 
the most favorable impact on the overall aircraft drag-weight problem. Unfortunately this iteration may 
need to continue over more time than is available and the fairing that must go on the production airplane 
may or may not be as near the optimum configuration as desired. It is felt that the GRADE fairing program 
has made a significant advancement in the state-of- the-art in the geometric and the analytical con- 
struction of the wing-fuselage fairing. Using the aforementioned basic rules for angle-of-attack, fineness 
ratio, and a mathematical surface definition technique, the GRADE program completely describes the wing-fuselage 
fairing and its intersections and internally maintains this surface definition for use later in calculating 
aircraft wetted area and cross-sectional area distribution. It is projected that this surface definition, 
in conjunction with an in-house wing-fuselage- intersection pressure distribution program and a drag 
estimation procedure based on wetted area and pressure distribution gradient, will permit the designer 
in real time on the scope MATHEMATICALLY DEFINED -COMPUTER DRAWN FAIRING  to estimate the drag of various 
fairing con- figurations and thus arrive at a near, or more optimum fairing thereby reducing the wind 
tunnel hardware iterations considerably. Figure 8 shows the mathematically derived, and computer drawn, 
fairing. WETTED AREA/AREA PROGRESSION  Total wetted area of an aircraft is very important early in 
the design of an aircraft for estimating skin friction drag which is a major portion of total drag. The 
most accurate way of calculating wetted area has been to make numerous cross-sectional cuts perpendicular 
to the fuselage centerline (for subsonic aircraft as opposed to cuts parallel to the mach cone angle 
for supersonic aircraft), then finding the periphery of these cuts, usually with a "map wheel," plotting 
these versus fuselage station and then manually integrating the area under the curve. This requires a 
considerable a~)unt of time for the designer to do this, particularly if many sections are required for 
accuracy and the cross sections are complex and not well defined as in the area of the fuselage -wing 
- intersection. Since the GRADE program has mathematical surface definition for the entire aircraft 
it becomes a sinple task for the computer to take say, 50 cross-sectional cuts and add up the peripheries 
then integrate vs length to get a nearly exact wetted area. A similar procedure is followed where areas 
are obtained and integrated to get the cross-sectional area dis- tribution which is then displayed on 
the scope with a Sears-Haack idealized (M = 1.0) distri- bution. Although not a transonic aircraft a 
high subsonic aircraft e~periences significant compressible drag rise in the cruise ranges above say, 
M = 0.7 and the area distribution comparison allows a good visual portrayal of areas that need redistribution. 
Figure 9 is a scope output exa, ple of such a comparison.  Figure 8. Mafhematlcally Defined -Computer 
Drawn Fairing 334  ACTUAL~~"--'--~ ~/.S~RS - ~ACK AIRCRAFTLENGTH  F|gure 9. Area Progression vs. 
Sears-Haack DistrTbufion WIND TUNNEL MODEL APPLICATION A near term goal of the GRADE project team is 
to determine the feasibility/desirability of NU machining a wind tunnel model directly from in- formation 
output (tape) from the mathexatically described configuration in the program. Presently in the aircraft 
industry there are various applications ranging from machining simple straight line element wings to 
nearly complete models with the notable exception of the wing-fuselage fairing. To the best of this authors 
knowledge there is no program in the aircraft industry today that can NC machine such a fillet fairing 
directly from scope out- put data. If it appears feasible to do this (mill the cor~plete model including 
the fairing) it will most likely require a very sophisti- cated 5-axis NC milling machine and numerous 
strea~ise cuts with a small radius tool. Cross-section (periphery) cuts may be more desirable from an 
NC machine standpoint and due to hand-finish requirements of models anyway to obtain very smooth surface 
finishes it may not be essential to require strea~wise cutting. Other applications such as making 2-D 
templates very quickly and accurately are already within the state-of-the-art of the computer -NC sytem. 
GRADE/CADAM INTERF ACE Lockheed's very popular and versatile CADAM system presents an opportunity for 
assisting the designer even further by interactively (graphically) enabling the engineer to finish the 
routine drafting jobs on the 3-view layout which is output from GRADE. After completing the external 
3-view and obtainin 9 a mathemat- ical description of the aircraft surface to- gether with the wetted 
area and area pro- gression, a software interface program would permit input of the basic 3-view drawing 
into CADAM. CADAM can then be used to good advan- rage to add the necessary control surface lines, windows, 
doors, dimensions, tabular data, notes, etc., and thus relieve the board designer of the more mundane 
aspects of his job. This combining of forces to accomplish a common goal is exemplary of the proper 
and efficient utilization of existing computer systems, each "doing its own thing" while still complementing 
each other rather than overlapping systems where both try to do the entire job. ~NC~SI~S The component 
parts of the aircraft, having been designed and located, are now integrated into the aircraft three-view. 
Any necessary changes are incorporated working in a partic- ular view or in three-views simultantaneously 
with a three-view zoom capability. The con- figuration may now be output to a plotter which generates 
an inked drawing accurate to + .005 of an inch, to any scale normally used, i.e. 1/50, I/i00, 1/200, 
etc. With basic input known, it now requires approximately 2 -4 hours to generate a three-view in the 
GRADE system complete with sections, fuel volu~s, wetted areas, area progression and output tape to provide 
an inked drawing. This is, con- servatively, an order of magnitude faster than it is possible to do it 
manually "on the board." It is felt that with the completion of the re- maining GRADE programming scheduled 
for the end of this year, the system will have demonstrated its usefulness and efficiency in laying out 
an aircraft three-view complete with wetted area, area progression, and a mathematically derived surface 
area. Software coupling of the GRADE/CADAM system will enable the designer to complete an aircraft layout 
and get a finished, dimensioned drawing in a matter of a day or two, rather than the weeks it now requires. 
Some "old time" designers may take issue with the ..."weeks it now requires" co,anent, but if they do 
they either haven't done a three-view in such a long time that they've forgotten how long it really takes 
or they are speaking of an approximate layout with fairly gross estima- tions of wetted area and area 
progression and "guesstimations" of e~pennage locations as opposed to exact iteration techniques. Far 
be it frcm the author to argue the pros and cons with these esteemed gentlemen, so set in their ways, 
but permit the author to suggest that they might throw away the sand paper pencil sharpener and T-square 
(along with the green eye shade) and willingly accept help from the number-crunching, dumb, (but fast) 
computer. Let it do the things it can do faster and thus release the designer from the more routine drafting 
and calculating chores, thus allowing more time to creatively consider a broader range of configurations 
and/or alternatives in order to arrive at a more otpimum configuration more efficiently.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807412</article_id>
		<sort_key>336</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>59</seq_no>
		<title><![CDATA[A system for interactive modeling of physical curved surface objects]]></title>
		<page_from>336</page_from>
		<page_to>340</page_to>
		<doi_number>10.1145/800248.807412</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807412</url>
		<abstract>
			<par><![CDATA[<p>It is often important to obtain descriptions of existing objects for computer graphics data bases. A system to aid interactive modeling (in three dimensions) of a physical object is described. The system allows a user to fit a bi-cubic parametric spline surface to an object by superimposing stereoscopic views of the computer surface with stereoscopic television views of the object. A 3-D joystick is used to manipulate surface control points while the user views the computed surface as isoparametric contours.</p> <p>A raster scan display polarization stereoscope is used.</p> <p>The left eye and right eye surface views are computed using a unique display processor designed and constructed for the evaluation of raster scan graphics techniques. The display processor consists of multiple non-pipelined concurrently operating microprogrammed modules. The computation of the two reasonably complex images (&gt;500 vectors each) takes less than 33 msec allowing real time display at standard television rates.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Computer graphics processor]]></kw>
			<kw><![CDATA[Display processor]]></kw>
			<kw><![CDATA[Raster scan graphics]]></kw>
			<kw><![CDATA[Stereoscopic display]]></kw>
			<kw><![CDATA[Three-dimensional surfaces]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Input devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010391</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P330965</person_id>
				<author_profile_id><![CDATA[81332497726]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[N.]]></middle_name>
				<last_name><![CDATA[England]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[North Carolina State University, Raleigh, North Carolina]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Agin, G. J., and Binford, T. O. Computer description of curved objects. Third International Joint Conf. on Artificial Intelligence (Aug. 1973), 629-640.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Baumgart, B. G. Geometric modeling for computer vision. AIM-249, Stanford Artiticial Intelligence Laboratory, (Oct. 1974).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Black, S. R. Digital processing of 3-D data to generate interactive real time dynamic pictures. Society of Photo-Optical Instrumentation Engineers 120 (Aug. 1977), 52-61.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bresenham, J. E. Algorithm for computer control of a digital plotter. IBM Systems Journal 4, (1965), 25-30.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Catmull, E. and Rom, R. A Class of local interpolating splines. Barnhill, R. E. and Riesenfeld, R. F. (Ed.) Computer Aided Geometric Design, Academic Press (1975), 317-326.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Clark, J. H. 3-D design of free-form B-spline surfaces. UTEC-CSC-74-120, Univ. of Utah (Sept. 1974).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360329</ref_obj_id>
				<ref_obj_pid>360303</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Clark, J. H. Designing Surfaces in 3-D. Comm. ACM 19,8 (Aug. 1976), 454-460.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Csuri, C. A. 3-D Computer animation Rubinoff, M. and Yovits, M.C. (Ed.) Advances in Computers, Academic Press (1977), 38-40.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359846</ref_obj_id>
				<ref_obj_pid>359842</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H., Kedum, A. M., and Uselton, S. P. Optimal surface reconstruction from planar contours. Comm. ACM 20, 10(Oct. 1977), 693-702.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Horn, B.K.P., Obtaining shape from shading information. Winston, P. H. (Ed.), The Psychology of Computer Vision McGraw-Hill (1975), 115-155.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>569955</ref_obj_id>
				<ref_obj_pid>800193</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Parke, F. I. Computer generated animation of faces. ACM Annual Conference (1972), 451-457.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>63448</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Rogers, D. F., and Adams, J. A. Mathematical Elements for Computer Graphics. McGraw Hill (1976), 84-87.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Stowell, G. W. and Garrett, R. E. Three dimensional display processor design. Conf. on Computer Graphics, Pattern Recognition &amp; Data Structure (May 1975), 157-162.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Sugihara, K., and Shirai, Y. Range data understanding guided by a junction dictionary. Fifth International Joint Conference on Artificial Intelligence (Aug. 1977), 706.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. E., Three dimensional data input by tablet. Proc. IEEE 62, 4 (Apr. 1974) 453-462.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Thornton, R. W. MODEL: Interactive modeling in three dimensions through two dimensional windows. M.S. Thesis, Cornell Univ. (1976).]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359848</ref_obj_id>
				<ref_obj_pid>359842</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Wu, S-C, Abel, J. F. and Greenberg, D.P. An interactive computer graphics approach to surface representation. Comm ACM 20, 10 (Oct. 1977), 703-712.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A SYSTEM FOR INTERACTIVE MODELING OF PHYSICAL CURVED SURFACE OBJECTS J. N. England North Carolina State 
University Raleigh~ North Carolina ABSTRACT It is often important to obtain descriptions of existing 
objects for computer graphics data bases. A system to aid interactive modeling (in three dimensions) 
of a physical object is" described. The system allows a user to fit a hi-cubic parametric spline surface 
to an object by superimposing stere- oscopic views of the computer surface with stereo- scopic television 
views of the object. A 3-D joystick is used to manipulate surface control points while the user views 
the computed surface as isoparametric contours. A raster scan display polarization stereoscope is used. 
 The left eye and right eye surface views are com- puted using a unique display processor designed and 
constructed for the evaluation of raster scan graphics techniques. The display processor con- sists of 
multiple non-pipelined concurrently oper- ating microprogrammed modules. The computation of the two reasonably 
complex images (>500 vectors each) takes less than 33 msec allowing real time display at standard television 
rates. KEY WORDS AND PHRASES: computer graphics, three- dimensional surfaces, computer graphics processo~ 
 stereoscopic display, raster scan graphics, dis- play processor CR CATEGORIES: 3.89, 6.22, 8.2 INTRODUCTION 
 In three-dimensional computer graphics systems there is always a need for some specification of object 
or surface input. This may be obtained from analytically generated functions (transfer functions in 
the complex plane for example), from experimentally generated functions (as in moni- toring a multiple 
sensor system), by interactive specification such as CAD techniques for surface design, or from models 
of existing physical objects. This paper describes a system which *Portions of this work were supported 
by U.S. Army Research Office Grant DAAG 29-76-G-0133, National Science Foundation Grant MCS-75-06599, 
and the National Aeronautics and Space Administration Grant NSG-1355. The author is with the Dept. 
of Electrical Engineering, N.C. State University, Raleigh~ NC 27650. involves a combination of the 
last two methods. The system is intended for object and surface description for a shaded curved-surface 
experi- mental graphics animation display system (EGADS) under development at the Electrical Engineering 
Department of North Carolina State University by J. Staudhammer, J. T. Whitted, J. N. England, J.W. 
Smith, M. C. Whitton and W.J. Seibert. Although there has been some work in automatic modeling of existing 
objects by researchers in scene analysis [1,2,10,14], the problems involved are complex enough so that 
human intervention in the process seems likely for quite some time. The future aim of this system will 
be to incorporate as much automatic modeling aid as possible in order to unburden the human operator. 
Hopefully the system will develop from large reliance on operator interaction to only that level of reliance 
absolutely necessary. Inputting of descriptions of physical objects has often been, of necessity, a 
somewhat labor inten- sive task. Most system have relied upon two or more views of the polygon edges 
and vertices nec- essary to define an object. This may be in the form of plans or blueprints as in [15] 
or the edges may be marked on the surface of the actual object before photographs are taken [ii], or 
manual digitization of corresponding points in photographs of unmarked objects may be used [16]. The 
common factor in these systems is that direct human specification of each polygon vertex and of each 
polygon is necessary. The second type of object specification depends upon the acquisition of contour 
lines and the subsequent lofting or fitting of a surface to these contour lines [9,17]. In this case 
it is the acquisition of the contour lines themselves that becomes the major problem. This may be done 
with some sort of range finder system as in scene analysis systems [1,14] or again by multiple manual 
measurements. There is at least one system~ however, which relies upon interactive fitting of measured 
contours with computer generated curves [17]. There has evidently been only one system developed which 
has had even the capability of ihteractively fitting a computer generated surface to a real object surface. 
This is Clark's head-mounted dis- play B-spline surface design system [6,7]. Although the system was 
designed for free form surface specification, the operator can see the real world as well as the computer 
generated images and the system could possibly be used for real object fitting. SYSTEM DESCRIPTION 
The system described in this paper allows the superpositlon of real world and computer generated views 
but with an intermediate level of processing between the operator and the real world. The operator sees 
not his own stereoscopic view of the world but the view from two television cameras with the computer 
generated images superimposed. See Figure i. The use of the television cameras means that appropriate 
stereoscopic views of objects much farther away than the useful range of human stereoscopic depth preception 
can be obtained. See Figure 2. Indeed, the input images could be photographs of objects, computer generated 
displays, or videotape of real world scenes. The stereoscopic image pairs from the television cameras 
have a geometry determined by the physical relationships of the cameras and the viewed object. This should 
be arranged so that the operator per- ceives image pairs readily conducive to stereo- scopic depth perception. 
Using the geometry shown in Figure 2 with a stereo angle ~,for the computer generated images the transformations: 
 cos(~/2) 0 sin(~/2) 0 1 T(RIGHT) = 1 0 0 Lsin(~/2)0c°s(~/2)0 -i/vl O and  cos(~/2) 0 -sin(a/2) 0 
I ~ T(LEFT) = 1 0 0 in(~/2) 0 cos(~/2) -I/v 0 0 1 are used. Note that this rotation and perspective 
transfor- mation differs from the more usual translation and perspective [i0] in order to model the camera 
placement. The polarization stereoscope is dia- grammed in Figure 3. The left eye TV monitor and left 
eye filter are polarized horizontally, the right eye monitor and filter polarized vertically. The images 
are superimposed at the same distance from the eyes. The computer generated surfaces which are fitted 
to the real world images are parametric bl-cubic curved patches of the form: f(s,t):[s 3 s 2 s i] [M] 
[P] [M] T It 9 t 2 t i] T (i) 4x4 4x4 4x4 The two types of patches implemented in this system are the 
interpolating Catmull-Rom spline patch [5.] and the approximating B-spline patch [6]. Both of these patches 
have local basis functions with easily understood relationships between control point manipulation and 
surface definition. The B- spline guarantees second derivative continuity; the Catmull-Rom spline yields 
first deriyative continuity. The surfaces are displayed as isoparametric con- tours or as a mesh of 
orthogonal isoparametric contours. A typical display is of 16 patches, each evaluated at four intervals 
in each para- metric direction, a total of 256 evaluated points. The operator also perceives the control 
points displayed in stereo and may "grab" and move any of these control points using a cursor box controlled 
by a 3-D joystick. The cursor box is, of course, also displayed in stereo. See Figure 4. As yet, this 
fitting of the surface via control point manipulation is the only mode of user interaction implemented. 
The addition of capabilities such as surface blending and intersection specification will be necessary 
for a complete modeling system. PROCESSOR STRUCTURE The key to any interactive display system usually 
lies in display update time. This is particularly true in this system with a high computational over 
~ head in curved surface evaluation and the addi- tional requirement of generating two raster scan vector 
images. The requirements have been met primarily through the use of a fast flexible dis- play processor 
designed and constructed for the evaluation of real-time raster scan graphics techniques. The processor 
is not pipelined as are most graphics processors [3,8,13] but takes advan- tage of concurrently operating 
independently mieroprogrammed modules. See Figure 5. Because of its architecture the processor is flexible 
yet fast enough for evaluation of alternative computing structures, a capability not available in dedi- 
cated pipeline structures. A key element of the processor is a 200 nsec bipolar 32 bit microprocessor 
 with 512x54 bit writable control store implemented using the AMD 2900 series of bit slices and microprogram 
sequence. A 2Kx32 bit scratchpad memory is included in the system for microprocessor use as well as serving 
as a host/processor buffer area. A special function module is used to speed up operations which might 
otherwise take a large number of microprocessor cycles. A reciprocal look-up table, sine-coslne look-up 
table, and multiple byte rotates are included. Four independent 16x16 bit multiplier-accumulator modules 
are included. See Figure 6. These are microprogram controlled and include two input cache memories 
(256x16 bits each) and one output cache (256x32 bits). The use of bipolar single- chip multipliers 
(TRW) along with a pipelined structure yield a 200 nsec cycle throughput for each card. The availability 
of these modules to perform vector and matrix operations concurrently with no off-card references (after 
initialization) lead to a performance evaluation situation in which a multiply-and-add is about one 
fourth as costly as any other CPU operation, clearly a reversal from the usual situation. A 16kx32 
bit frame buffer is included at present although expansion is planned. The frame buffer uses a 50 nsec 
microprogrammed sequencer to implement read, write, OR, and read-then-clear operations. The OR function 
in conjunction with 337 single bit addressability). Frame buffer display operation is controlled by 
the video sequencer mod- ule. The read-then-clear frame buffer function facilities vector operation by 
displaying from and then clearing one half (512xS12xl) of the frame buffer while the microprocessor is 
creating an image in the other half. This "ping-pong" dual buffer method of operation allows real time 
(30 frames/sec) image generation and display. For stereo image generation a 15 frame/sec display rate 
is maintained by alternate frame display to two monitors. The video sequencer can operate in alternative 
modes such as a 256x256x8 (to be expanded to 512x512x8) gray scale display format. The host processor 
interface allows host communi- cation to and from any other module using the bi- directional 32 bit data, 
24 bit address, 4 bit function busses common to all modules. Bus trans- fers take place in 100 nsec 
and all bus arbitration is handled by the video sequencer microcode. Bus transfer can be initiated only 
by the video sequencer (highest priority), host interface, and microprocessor (lowest priority) modules. 
 MODELING SYSTEM IMPLEMENTATION Although there exist difference equation methods of parametric surface 
determination as in [17] which are advantageous on a more conventional pro- cessor, the availability 
of fast concurrent, inde- pendent multiply-accumulate operations in this design leads to a rather direct 
matrix evaluation method of computation. We may reduce equation (i) to T F(s,t) = u m [P] u N where 
Um=[S ~ s~ s M I][M], uNT=[M]T[t~ t~ t N l] T For a given set of parametric values, say s=0, .2% .5, 
.75 and t=0, .25,.5, .75 we may precompute uM(i),UN(J)=UMN(i, j) for a total of 256 patch coefficients. 
The surface points may now be 4,4 evaluated as f(sM,tN)=.~ " UMN(i,j)P(i,j). The actual display operation 
consists of several parts, (i) determination of viewpoint transfor- mations, (2) transformation of control 
point arrays, (3) evaluation of surface points, and (4) transformation of surface points.  (I) The 
viewing transformations are obtained by multiplying general purpose user selected view- point transformations 
by the left eye and right eye transformations. The resulting viewpoint transformations are loaded into 
one input cache of each of three multipler-accumulator (M-A) modules.  (2) The control point arr~ys~,y,z) 
are loaded into the other input cache of the three M-A modules. The outputs (x,y,w) from these three 
M-A's are transferred to the fourth M-A with a look-up inver- sion of wen route. The fourth M-A performs 
the perspective calculation and passes results to the microprocessor for display.  (3) The viewpoint 
transformation coefficients are replaced by the patch evaluation coefficients (UMN)  in the first cache. 
Only a few such swaps occur, as the majority of the patch evaluation coeffi- cients remain resident in 
the cache. The surface evaluation now takes place, in three concurrent sections (x,y,z). (4) The evaluated 
surface points now replace the control point array in one input cache. The trans- formation coefficients 
are reloaded into the other input cache and the transformations take place exactly as they did for the 
control point arrays. The microprocessor uses the results from step (4) for final display of the surface 
in the two frame buffer halves (left and right) using Bresenhem's incremental vector generation method 
[4]. PERFORMANCE An M-A module can evaluate the inner product of two 4 element vectors in about one 
microsecond. The two transformations required for the control point display require a total of nearly 
four hundred such products or about 150 microseconds using concurrency. Evaluation of the surface points 
requires around 3000 inner products (about i000 microseconds) and transformation of the sur- face points 
requires slightly over 2000 inner pro- duts (about 750 microseconds). Thus the M-A usage is about 2 milliseconds 
total. Vector generation in the raster for~nat requires 1 microsecond per pixel point of vector (three 
orders of magnitude faster than Bresenhen's origi- nal implementation!). If the displayed meshes occupy 
the central quarter of the display, less than 20 milliseconds is requires. Fast pixel point generation 
is thus crucial to operation and precludes the use of iterative methods requiring more time per pixel 
point. For a 30 Hz dual frame computation rate, ii milli- seconds (over 50,000 microprocessor cycles) 
are available for host communication, viewing transform calculation, etc. A 15 Hz dual frame rate is 
adequate for stereo- scopic perception and is used with the current frame buffer size limitation. The 
limited spatial resolution (512x512 pixels) does not interfere with stereoscopic depth perception to 
any great extent because of the image correlation capabilities of the human viewer. The system has so 
far taken about $I0,000 in parts for the processor and about one and a half man- years for development, 
design, and construction. As of early May 1978 all components have been com- pleted and are working with 
the exception of the M-A units which have been breadboard tested but are awaiting delivery of printed 
circuit cards. The images in Figure 7 were displayed in real time by the processor from surface point 
lists computed in the host processor, an Adage AGT-30. SUMMARY A method for interactively fitting computer 
gener- ated curved surface descriptions to actual physi- cal objects has been described. The method deperfs 
upon simultaneous stereoscopic viewing of the com- puted surface and actual object. The key component 
 338 of the system is a unique display processor allowing real-time raster scan dual image generation. 
The system needs to be extended in two areas: the ability to handle multiple surfaces, and automation 
to reduce the design load on the user. REFERENCES i. Agin, G. J., and Binford, T. O. Computer description 
of curved objects. Third Inter- national Joint Conf. on Artificial Intelligence (Aug. 1973), 629-640. 
 2. Baumgart, B. G. Geometric modeling for computer vision. AIM-249, Stanford Artiticial Intelli- gence 
Laboratory, (Oct. 1974).  3. Black, S. R. Digital processing of 3-P data to generate interactive real 
time dynamic pictures. Society of Photo-Optical Instrumentation Engineers 120 (Aug. 1977), 52-61.  4. 
Bresenham, J. E. Algorithm for computer control of a digital plotter. IBM Systems Journal 4, (1965), 
25-30.  5. Cat-mull, E. and Rom, R. A Class of local interpolating splines. Barnhill, R. E. and Riesenfeld, 
R. F. (Ed.) Computer Aided Geo- metric Design, Academic Press (1975), 317-326.  6. Clark, J. H, 3-D 
design of free-form B-spline surfaces. UTEC-CSC-74-120, Univ. of Utah (Sept. 1974).  7. Clark, J. H. 
Designing Surfaces in 3-D. Comm. ACM 19,8 (Aug. 1976), 454~460.  8. Csuri, C. A. 3-D Computer animation 
Rubinoff, M. and Yovits, M.C. (Ed.) Advances in Computers, Academic Press (1977), 38-40.  9. Fuchs, 
H., Kedum, A. M., and Uselton, S. P. Optimal surface reconstruction from planar contours. Comm. ACM 20, 
10(0ct. 1977), 693-  702. i0. Horn, B.K.P., Obtaining shape from shading information. Winston, P. 
H. (Ed.), The Psychology of Computer Vision McGraw-Hill (1975), 115-155. Ii. Parke, F. I. Computer generated 
animation of faces. ACM Annual Conference (1972), 451- 457. 12. Rogers, D. F., and Adams, J. A. Mathematical 
Elements for Computer Graphics. McGraw Hill (i976), 84-87.  13. Stoweil, G. W. and Garrett, R. E. Three 
dimensional display processor design. Conf. on Computer Graphics, Pattern Recognition g Data Structure 
(May 1975), 157-162.  14. Sugihara, K., and Shirai, Y. Range data under- standing guided by a junction 
dictionary. Fifth International Joint Conference on Artificial Intelligence (Aug. 1977), 706.  15. 
Sutherland, I. E., Three dimensional data input by tablet. Proc. IEEE 62, 4 (Apr. 197~ 453-462.  16. 
Thornton, R. W. MODEL: Interactive modeling in three dimensions through two dimensional windows. M.S. 
Thesis, Cornell Univ. (1976).  17. Wu, S-C, Abel, J. F. and Greenberg, D.P. An interactive computer 
graphics approach to surface representation. Comm ACM 20, i0 (Oct. 1977), 703-712.  ,~EiR,ZAT'Or~ i 
STEREOSCOPE i | fVIEWER ._1 F AME I I FRAME I I~L'; ''~ I Figure i. SYSTEM DIAGRA~ ,......- STEREOSCOPE/' 
%.  I D ] SPLA~,/ L -- /"~EYE ~--~ _ ~.~ ',,, LEFT EYE .r'--.., v_ :q Figure 2. LONG RANGE STEREOSCOPY 
 f RIGHT FI,TER ~GHT EYE ~k~ LEFT F|LTER LEFT FI,T Figure 3. POLARIZATION STEREOSCOPE 339  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807413</article_id>
		<sort_key>341</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>60</seq_no>
		<title><![CDATA[The development of three-dimensional spatial modeling techniques for the construction planning of nuclear power plants]]></title>
		<page_from>341</page_from>
		<page_to>347</page_to>
		<doi_number>10.1145/800248.807413</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807413</url>
		<abstract>
			<par><![CDATA[<p>The results are presented of the first phase of a research project on the application of spatial modeling techniques to the process of planning and executing the construction of a nuclear power plant. A computer modeling technique, based on sets of polyhedra and spatial operations, was developed and applied to modeling the components of a nuclear power plant. The objectives of the modeling are: to store and retrieve information about the various systems in the facility; to produce drawings of those systems from any angle in differing amounts of detail; to aid in the search for interference among the parts of the plant by identifying those elements that occupy the same space or are too close to each other; to calculate information such as surface area, length, and volume of selected elements of the plant; and to aid in finding the optimum construction sequence by simulated construction of selected areas of the plant. Computer techniques are described for inputting information by digitizing directly from engineering drawings, for editing the spatial model, for management of the spatial and non-spatial data, and for graphic output from the model. The software is implemented on the University's central time-sharing computer system and on a mini-computer system in the Architectural Research Laboratory.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer modeling]]></kw>
			<kw><![CDATA[Digitizing]]></kw>
			<kw><![CDATA[Geometric modeling]]></kw>
			<kw><![CDATA[Polyhedra]]></kw>
			<kw><![CDATA[Relational database]]></kw>
			<kw><![CDATA[Spatial modeling]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Digitizing and scanning</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.7</cat_node>
				<descriptor>Real time</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Relational databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10002955</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Relational database model</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010570</concept_id>
				<concept_desc>CCS->Computer systems organization->Real-time systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003197.10010822</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Query languages->Relational database query languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010506</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Document scanning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Management</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P330702</person_id>
				<author_profile_id><![CDATA[81100182321]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Harold]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Borkin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Michigan, Ann Arbor, Michigan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P331616</person_id>
				<author_profile_id><![CDATA[81100422456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jonn]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[McIntosh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Michigan, Ann Arbor, Michigan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39080366</person_id>
				<author_profile_id><![CDATA[81339533508]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Turner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Michigan, Ann Arbor, Michigan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Hoskins, E.M., "OXSYS: An Integrated Computer-Aided Building System for the Oxford Method", Proceedings of the International Conference on Computers in Architecture, 1972.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Borkin, H.J., Turner. J. A., Architectural Computer Graphics System Users Manual, Architectural Research Laboratory, The University of Michigan, Ann Arbor, Michigan, 1975.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Childs, D.L., "Extended Set Theory", Third International Conference on Very Large Data Bases, Tokyo, Japan, 1977.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Braid, I., Design with Volumes, Computer-Aided Design Group, University of Cambridge Computer Laboratory, England, 1972.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>891970</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Baumgart, B.G., "Winged-Edge Polyhedron Representation", Standford Artificial Intelligence Project Report No. CS-320, 1972.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Fastman, C., "General Purpose Building Description System", Computer Aided Design, 8:1, pp. 17-16, January 1976.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Turner, J.A., An Efficient Algorithm for Doing Set-Operations on Two- and Three-Dimensional Spatial Objects, unpublished paper, Architectural Research Laboratory, The University of Michigan, Ann, Arbor, Michigan, 1978.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Turner, J.A., Three-Dimensional Polyhderon on Set Routines Programmers Manual, Architectural Research Laboratory, The University of Michgan, Ann Arbor, Michigan, 1977.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Turner, J.A., Two-Dimensional Polygon Routines Programmers Manual, Architectural Research Laboratory, The University of Michigan, Ann Arbor, Michigan, 1976.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[McIntosh, J.F., doctoral dissertation work in progress, The University of Michigan, Ann Arbor, Michigan.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4198</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Date, C.J., An Introduction to Database Systems, Addison-Wesley, Reading, Mass., 1975.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 TUg D~,V?.LOP:~ENT OF n_'IIL~E-DI,,ldNSIO~:AL SPATIAL MODELING TECHNIQUES FO,~ TliF CO'!ST£UCT£O[~ PLANN]N'; 
OF NUCLEAR POWER PLANTS Harold J. Bornin, Jonn F. Mclntosh, ,James A. Turner The University of Michiqan 
Ann Atbet, ~ichigan The results are present~a of the first phase of a research ~,ro]ect on the application 
of spatial noue-.iinq techniques to *he pt'oc~ss of plann,ng and ezecutinj the construction of a ~'aclear 
power plan ~. &#38; computer ~odelin.j teciniquc, based on sets of polyhe~]ra and ._;patiai operations, 
was develot~ed an.] appl£ed to mo{!eling the components of a nucl~:ar ~<,we,c plant. The objectives et 
the ihOd<~l£,~J a~e: eo s~ore and retrieve information about the various systems in the facilit]; to 
produce dFawin~s of those sfst~,%:; from .Iny angle ill differinq amounts of ~ietail; to aid in the search 
for ir~ter ference among the parts ,of the plant by Idet, tifying those elements that occupy th.-c sa:.~e 
s[~ace or are too close to earl or J~er ; to calculate infoL'mltJon such a ~, suuf,,ce a~ea, length, 
and volume of selected elements of the plant: a~d to di~ in finding the optimum construction :~equence 
ny simulated constructio;, of selectea area~ of the plant. Computer tecnIllques ace d~:scribed 5or inputtinq 
inf (~rma tion ~)y diqitizing direct iv from e:Igineerinj d/-awings, for editinq the spatial model, tot 
managemel:t of the spatial and non-spatiai lata, ani for qraphic output frog the mo~lei. The soft w,l_~e 
is imp±ugca tei on the 'Jniv~r.~ity's central tiuH~-~dL'll*g computer system and on a Lililli-cGai~.: 
2;y~tem in the Architectural ~(:scaL'Cl~ babo/atory. K~YWOROS AND PliEASF. 5: com~ute~ modeling, digitizina, 
geometric modeling, polyhedra, relational database, spatial mudeling CR CATEGOhIES: 9.27, .~. 1, 8.2 
 INTRO DUCTIO~; The application of computer spatial modeling techniques to ~:-cartect,~ral and enqineerinq 
construction projects has been very limited. The most notaule examples of implementations have been in 
~':n~land, in conjunction with indusrr iailzed building system-:~[ 1 ]. ! know of no examples of implementations 
that hana£e uniquely desiqned buildinqs. This is because, either con ventional design and cons~ruc tiol; 
drawings are sufficient to solve most of ~he problems in construction, or adeq~;atc comp1/ter aides have 
not Eeen avai fable to offer much assistance to this p/oceans. ~luch of the effort to aid the design 
and con:~truction of buildings with co'gunnel g~aphics has centered on improvement To th~ production 
of drawings and specificatiol~s. Although such effort~ have been successful in the automobile, aircraft, 
i..=achi~e parts, and electronics ind ustL- i[~3, they have had limited success in the building industry. 
In 1969 we began to develop a three-dimensional computer modeling system fo~ buil~ings and. other t~ree-d 
ime nsiona! objects. ~e believed that a three-dimensional comuuter model of a building would be mole 
useful to the designer than I cardooard and plastic ~i~odel, and could some .,lay permit the autouatic 
production of construction drawings. The system that we developed, called A~CH: G~A PHIC~ 2 ], allows 
a us~:r a ~ an interactive graphics terminal to compose a set of primitive ,deemer tic objects {solids, 
planes, or lines) into meanin~ful assemoiies (chair, room, or building), anl to vlew the model in a variety 
of ways. The developlaent of this modeling s yste~u continued over several years, until very large complex 
o~jectg could bc modelcl au.d displayed in perspectiw:, ~olai', _,ter(;o, parallel, or movie-sequence 
projections on a variety of computer ,jraphic dev ices. ~e made the softwasc available to a number of 
archit oct uKe school.~ wi~c i_'e it :Ised by students in des[qn courses. It has se~n little use in the 
b,lil~lmj industry. During 1914 we bejan to evaluate the deficiency of the appL-oach used in ARCH:GRAPHIC, 
with rile intention of producing a more powerful modeling system. The major deficiency, that we had built 
into this system, was a lack of consistenc[ in +he geometric model. There were no constraints on producing 
models where two objects occd~y the dame space. 341 In addition, simple of e Cations , such as calculation 
of ~he surIace area and volume of parts, were difficult to imi.lement. We concluded that, if we restricted 
the shapes to sets of poi~hedra and developed a group of set-qeomet~'ic oeerations , we would have the 
basis for an improved modeling system. The work oi CbildsLS], Braid['4], Eaumgart[5], and Eastman[6] 
was strong reinforcement ~hat this approach was a sound one. At th(} heazt of our efforts has Leon +l.e 
work O~ Turner[7], who deveiope3 ef ~ iciet~, t algorithms for doing set operations on two-and three-dimensional 
objects. In 19/0 ~e had begun to implement a new modeling ~;ystem based on these notions, whe~ the opportunit 
F presented itself to a~)?ly ou~ ideas in a practical way to averf large con.~truction project -a nuclear 
po~ec plant. NESEANCH OBJECTIVES Nuclear power ulants are amon.$ the most comple~ of buildings7. They 
may ta~.o over ten years to plan and co,,strucr, but the detailed design is not cotlh~iete~ before construction 
starts. The number of drawings required is v~sn. To aid in the design and construction plannin] of those 
plants, physical models are built. They are a tool for exi+osing errors or omissions during the d~esign 
[~roc~,ss. These models are quite iat-~e (ovel-tw,~n+y feet square), col, taJn considerable det~i!, may 
take years to put ~o~etaer, and now cost well over a milligu 4olla~. A major objective of our reseauch 
i.~ to d,~+ermiue if physical models can be sure, fomented, or even supplanted, by couq, uter models. 
~lhe advantages o~ a succes~/u[ computer model are more than merely co~t savings. The data in a computer 
model is transportable; it can be made available iaickly on the construction site. It can be ~inked to 
a parts inventory or a coiupletion schedule, thereby adding exact ~;Fat±al locations to a variety of 
en,t ~Jr[es. Our current researci, as limited to developing a computec iaodeiiag system that will aid 
in plannil~g and executing the construction of a spectific nuclear power plant, whose field constl'uctiol; 
will begin in 1980. Although we are dealing only with the contruction [>roc,~;s, this modeling system 
will be applicable to design and engineering, of or.nu~ i~iants or any complex building. Fe intend the 
computer modeling systeat to have %he ~ollowing capabilities: I. It m~lst store and r~,trieve information 
abou~ the various sy':~ten,:~ in the plant; the structural system, the electrical system, the piping 
system, and the mechanical equipment. Each major ~vstem will require so~'~ew hat different data input 
and storage tecani lues. 2. Drawii~qs of the various syst,~ms, in specific areas of tac plant, must 
be pro~ 11ced , fro~ ,.lily ali g±e .llid is different amount_~ o~ ~letail. These drawing~ will not tel, 
lace construction drawings, but will n~l F visualize con:~+ruc~ion proble,u~ by oveEl~zing the many systems 
tha ~ may exis ~ at a speci tic location. 3. It must ai:l in t~u search for intc~fe[ence a~oz ~ [he 
various parts of the plaht, by ;_uuntif y il,g those elements that occu[,y the same space or ar~ too 
close to eac.L Ot~er.  ~. Information such a5 ~ar fa.ce area, lenJth, an,] volum~ of s~::£ected elements 
of the ~nlant :~houiu be easily calculable. 5. It ~houid aid in fielding the optimum constr act ion 
s~queuccs ;~y simulating the construction ot :;eiect~d a[eas of the plant. ~,. It ,~ust be able to Kee£, 
tune< of the as-built conditiou of tu~ plant as the con~t r uct ion progresses, this mi~lht involve ~uilding 
a nt~w com£~uter model of the ~)lallt, while the: actual plant is being constructed. To cr'e ire an 
operatiuÀ,a i mo(,el of the power plant, we ale cond~ctiu.] a staged ceseacch prosE-am. Phase i, the 
modeling Gyste~a desigr~ an,i feaslbillty te~=ting, has been comL~icted. Cu[rently we are working on 
Ph,!~e II, the naL uwa[e spcctficdtion a:zd implementa+ion el tn~ modeling system. Phase III will be 
t~e hardware implemeiltation and complete input of the power plant descti~:+lou. ~inaliy, Phase IV is 
to be the field u~e of the model. DFV~[,O~MENT ~ORK To establish th~ feasibility of const r,act ins 
a modcllrl j system foe the IILiclea r poweu Dl.~ht, we built an operat ional moduling ~ystem !roving 
the essential capabilities of the proposed ~ystem. ~h~ ex petit,ned, ted w&#38;th this :~chematic syst{~m 
on a subset el the pla[ito To keep the cost few and to speed development, we chose to u~o. the [Iniversity's 
Aadahl 47J~/6 computer under the 2ichigaa Terminal System, the Arch itect u[al Research Labora for y's 
graphic hardware, and the modelinq and graphics software Fneviously developed. The intent was to ~imu£ 
at~d the final modeling system. ~e coul~ establish what features would be necessary and we could stimulated 
the potential user to identify the uses they miqht ma~e of it. Three components of the [~lode ling system 
were developed and iatplemented ; the spatial mo~leling operations, the data input and display ODerations, 
and tae data base management routines. Tue following is an overview of the tt;chn[i'leS employed. 342 
 Spatial ~'.odel in g The baltic spatial modeling toox consists of a darn structure foc ~e.sc£'ibin9 
objects in ehree-d i~ensi o~a i s~ace, and a collection of procedule,.~ for ~,0anipnlating them. The 
obj~ct.~ are defined as a set of polyhe~ra[b]. ~ polyhedron-set is used because a single ~,oIyhed~o~i 
is often not -~ufffcient to descL'ibe an obsect. Also, the results of operations oa a polyhedron can 
~roduce a grou~ oi pol ~he:lra. A polyhedron-set i.z defined as a set of disjoint and/or subsoint positive 
and neqative pol ~{.cdra. A aata ~tructure contains the spatial c~ord~nates, the line meg mentg lin~inq 
them, the poi ygon-sets that link the 1 ine sej~ents, and the polyhelra tLat link the l,o±ygon-sets. 
The procedure £o[ manipulating the polyi:e]ron-set-~ are currei~tly impl¢.mented as FO i~ T [,' ,%N callable 
subprograms that e.~pect one or sore pol~nedt'on-set data structures as their a~<~uaents. The more important 
of the.~e p£ocedures a~e: PH~UD genera*es a i;oly,~edron-set which is the uhion, intersection, oE di 
florence of two polyhedron-sets. PilTOL return:&#38; th~ ~. volume o£ the ?olyhedron-st~i passed to it. 
P[IARZA returns t~e surface area of the polyhedron-set passed to it. PIIC~'dT colr.pu¶o~ t:,c KYZ coordinates 
of the center of mass of a pol,lhedron-sct. PHBOX fi:~ds the 3,nall~t e[iclosing rectangulal-cuboid 
of a po!yhe/~on-set. PH~TST determines whether two rectan~ula~ c']boiu~ overlap. PHT~; translates a 
polyhedron-o, et to a new position. P[,~OmA rotate~ a poiyhedron-set about, or defines aa LYZ location 
by, a rotation matrix. PHSCI.~ scales a ~,olyhedi'on-set about a defined ;(¥Z location by X, Y, and 
Z scale factor. DHDRA~ draws a polyndron-~et on si~ecific qra,)hic uevice usinq a drawing pro jection 
|us trix and view port. P.'IBL D creates a rigat-prismatic polyhe Iron-set f~om a two- dimensional polygon-set 
together with a top to bottom dimension. Using these [,rocedurus we constructed a Shape Editor. It is 
used to produce the spatial description of the ele~ents of the nuclear power plant, flits the Shape ~ditor, 
holes can b~ "punched" through walls, objects can be "glued" together to form more complex ob]ects, and 
rough shapes can le "tooled" to exact size. The Shape Editor has also been used to extract elements from 
the model, and to search for interferences between elements. It has a direct command structure. Fo~ 
example, the 6ollowing command builds a new object from existing objects using calls to PHIUD by extracting 
a part from the originial. ? read atom ENTZR FILENAME(STOP) : atom ATOH ? build test ENTE~ D~%SE OBJECT(SfO~): 
atom I. "cube a -5],-33,670, I00,o0,50, 2. last TEST ? draw test The Shape Editor has b£ea used extensively 
to edit model shapes ~hich were digitized directly from engineerin9 drawings. Figure i Reactor Shield 
Before Editing / Figure 2 Reactor Shield With Portion Removed 343 Data Tnput and Display We developed 
a + echn i~lue for inputting three- limensional shades direct ly from engineering drawings. It was ~mportant 
to show that accurate, rapid it~put of complex shapes was pos~;ible b~ tecnnical staff. The input techniq~le 
adopted is pcesently limited to structural concl-ete shapes. Other input programs aue under d~velopment 
for piping, mechanical e~iuipme nt , and electrical distributiol~. The technique is b aseu on some two-dimensional 
pol y';on algorithms :le velop.~=d by Turner[ 9 ]. It is implemented on a hardware configuration consisting 
of a 36 by ~48 inch Summa ~raphlcs digitizer attached to the Unibas of a PD? 11/05 minicomputer with 
2%1 words of memory. Also on the Unib,]s is a d'aal-d~ive floppy disk, a printer/plotter, and a high 
speed communications port to the University's computer. The software i~ w~itten in FORTRAN under the 
ET-11 operati~,g system. A plan drawing is placed on th~ surface of the digitizer, the scale factor 
of the drawing is entered f~,)m a keyboard, and the origin and base-line o£ the drawing are digitized. 
The corners of polygons, representing the bases o~ s~apes, are then digitized. Coordinates are digitized 
clockwise for solid shapes and counter-clockwise fo~ holes. As shades are built up, a contin-aous rea~1out 
is supplied of the X and Y coordinates, relative both to the origin of the drawxag and to ~he last point. 
This data i~ displayed iu feet and inches, rounded off to the nearest inch. If the drawing is accurate, 
the <~perato~ can digitize directly. If the drawing is doubtful, he observes the readout and does not 
digitize a point uhtil the readout matches the written dimension on the drawing. In practice this quite 
a rapid activity. Lines that are nearly parallel to either axis are mad~ exactly parallel; consequently, 
small ~r~ors ale eliminated. %s they are collected, the polygons are displayed for ~er ification. ~dhen 
a polygon-set for one ouject is complete, the ba~e elevation and the top elevation are entered from the 
~eyboard. The program processes the polygu~,-sets to produce a polyhedron-set definitlon for the object. 
It then displays an isometric drawing on the screen. If necessary, ad-li tional shapes, possibly at differing 
base and heights, are digitized and expanded. This process is limited to right-prisms; that is, those 
shapes with the same base and top. Complex shapes are digitized piecemeal in the form of these "extruded" 
shapes. Later they ca[, be welded, subtracted, or cut with the Shape Editor. The collected data is sto~ed 
on floppy disk until it passed to the University's computer, where the Shape Esitor runs. The following 
are examples of shapes input using this technique. // // // / Figure 3 Concrete Walls Input With Digitizer 
Data ~ase ?~anagement Of the base several possible management, ~e ap£~=oache:.~ to believ~ that data 
the relational apDro ~ch offers the greatest potential for develop,~!~t o£ the modeling software. A 
primary rejuilemen% for this data base is that it handle spatial inquires, as well as conventional aphanu 
meric inquiries. [or e~ample, a request to display all 4" CARBON STEEL PIPING in TURBINE iO0~l ~2 re:]uiEes 
searching spatial al~d 1.on-spatial data. Using a relational approach, we can make the operations ou 
botit types of data appear uniform. Entities ann the relationships betweeu entities are +rented as sets. 
The operations oi~ sets are well define']; union, intersection, difference, and so on. In the above exa~:le, 
a non-spatial intersection Is ~ade bet'~een the get ~" CAPbON STEEL ?iFlN3, and the set oK all pipes. 
A spatial intersection is th~n made between tile resultant s~t o£ pipes and the spatial set TUhBINE ROO~ 
#2, yielding a final resultant spatial set for ,~isplay. The set apez.itions on the data will appear 
uniform, bur iu fact different kinds of calculations a~e requiied. ~ set operation on spatial data ~s 
a geometric calculation on pol yhe~Iron-set descriptions, while a set o[~eration on non-spatial data 
is a compariso~ of lists. A prototype relatienai data base system has been developed ~}' ~|cln tosh[ 
10 ]. Manipulation of ~e latioas between entities, and betwee~ entities ~ud their attributes can be catrlel 
out. A simple command processor allows the basic opera+ions of projection, join, union, difference, and 
selection as specified by Dater11 ]. The ~omains 'of a relation are essentially non-spati~ti in this 
system. They may be a real numuel, an lute jet, an 3-character stri~q, or a Julian date. spatial data 
has been integrated into this system by designating a special "shape" domain. The pool o~ values which 
may 344 appear as shade attributes ill relations, SET C = A P~OJECT (DOMAINI, + are the names of tke 
tiles containing DOMAIN2, ..., DOMAIN 21) poiyhe,]ron-set (iefinit ~o,~g. Relations of entities that 
have saa2e att/lbutes may be Resultant [elation C is a subset of rlraphical ly dispi ,yed, as well as 
column~ fro,: ihput relatlOU ~. The t a bu la rized. argumeuts el the opeL atlof~ are the domain names 
d~sired, in the order t hey a[~ des ired. The f)llowing i'~ a t,'['ze.f aescription of the more importaut 
co~a,uaads Lmpiemented t9 :late. A, b, ar:d C ;ZL:~; i e 3~;Ilt relatioa SET C = A JOIN 3 names. If the 
felt-most domain o~ A and B have SF.T C = A :qF, LIiC? (;)Oi~AIN; VALUE1, + the same name, data values 
are compared. :~hen a match i.~ foaha, tuples from each VALUE2, . . . , V:~l,[J2a) are combined to 
form a ~ew wider relation. SET C = A BE~'.'/CI':N (JO:~AIN; MIN, MAX) Resultarit gelati,)6 C i:~ a subset 
of rows SFT C = A UNIO" B from relatioa A. The S/LECT o[~eration SET C = A DIFF P ~etects +uoles with 
d onaiu vaiues <-qual to S~'T C = A INTER B one of the value,~ given in the argument List. The B Eq~UZICN 
Jpe£at ion restrict3 The tup/es of £clatioh g ale added to resultant relation tupie~; to uaose valu(,s 
those of relation A by the UNION between the minim,~m a~d maximum values operation. Usually re~attOh 
~ will consist specified. of a few update entries, manaully entered from a terminal, old eatcies may 
be deleted with the DIFFerence operation, The SET C = A POX,4 (XGI3, XgaX, YMIN, + tuples common to 
two ['elations are found Y'~.A~, Z?ilN, Z!AY) by the INTE~sectil;g theill. A special retrieval operation 
does an incl,sive ~:etw~,en ze~;t/ictioa across six COPY C = A domains ua,ncd X~IN, ;(Ci,t,(, ..., ZMA;(. 
These reserved duma1 i~ ,: a ~:,u.u describe a A duplicate of relauion can be produced rectanq,llar voiu.ne 
which cent 9ins the under a ne~ name. shape of an object. Possible candidates thus ~electe~q, have their 
actual detailed ~eomet r[ retrieved from the file name rental/ted if: the SHAPE doaaia. "" ~re[a~ions 
%ha% ~a~e ~ 'shape" d~maln can ~ ou%pu% in %nhu[ar £orm or @r~pnlcat ~orm > List hd-wa[[s 9ELATION: 
HD-WALLS CARDINALITY-15 DEGREE-IE 18:14:5~ JAN 30, 1978 ur{ZT POUR LEUEL SHOPE ~T~RT FINLqH XMINIMUM 
YMINIMU~ ZMINIMUM ×MAXIMUM YMAXIMUM ZMAX!MUM 1 W639-C29 639 A39!-6 02/Og~ge 03/14/~0 0,2~ ~.~ 0.~ 44.~0 
S3.eO !~,09 1 IJ639-D~4 639 ~391-~ @2/15/~8 03/21190 B.O 5,00 0.0 I WG39-D2S 639 A39~-7 e2/g~/2O @3/26"£0 
!8.33 S,~O e.~ ~0.40 47.~0 !C.00 I IJ639-F25 639 a391-8 e3/11,'80 04/11/£0 17,87 ~O.B3 0.¢ 5~.~0 99,0'#. 
~8.00 1 W,S39-F26 632 A3gt-IS 03"04/80 04/0S/90 32.78 53.00 e.O i WG3'°-C24 63£ R391-4 0~,'E7/80 03/26"£~ 
-0,24 53.0@ e.o 3,2G I~8.0@ IS,9@ I U639-H~ 639 A391-~ e3/17/80 04.~1/80 17.5S £I.00 O.O 5~.00 134.03 
16,0@ 1 U~39-JR4 639 A3g{-3 03,'~.I/S0 84/01/S@ -8.47 I@~.00 e.O 1 1/639-J@G 639 A39J-!4 93/1~,8~ 09.16,'~8 
49.~ 9~.O~ 8.0 57.B4 !'?g.O0 16.~0 i t/~39-Kg9 639 A291-~@ 02/27/S0 04/~2/B0 17.27 1:34.80 0.0 40.00 
17g.£'#J 16.0~ I t~G39-t~4 633 ~321-~ 0~,1S,'£@ 03/19,'80 ~8.72 161.0@ O.~ 2,0@ E16.03 1G, ~,) I U~99~29 
632 ~391-11 02/28/8@ 03/21,80 15.00 129,8@ ~.9 1 &#38;IG3:~-M~G E;3S A391-13 03,li'Se 04/i~'dO B2.O@ 
ZO~o~ 0.0 5~.0.9 2~3.~3 !6.00 I ;~639-N2G 629 A39~-18 83/04/£~ g4/~3.,S0 g~.O0 i?9.e~ e.O ST,2'a ~la,e:~ 
16.oo 1 ~J633-P85 639 A391-1 82/03/@0 03/14,30 --8.7~ 217.0@ 9.~0 12.24 223,E8 16.ee > draw hd-,~lIs 
AREA 37824.97 50.FT. VOLUME -38~53.77 CU.FT. '! "<L'-'-~j lii~---,~ ;" ~,! . Figure 4 Relation Showing 
Concrete Pour Joints "%. <&#38;.,..  }Ji J 345  INP;#T C = FDNAME  LIST C mo PH I~!T C OUtpUT FDNAdE 
= C  DRA!,; C Relations are formed, eithe ~" with data read from a file generated by another data 
A relation may h+~' ta,,ularized by LISTing base, or with data read zrom a tezminal. it at the user'~ 
t,}r~ainai, or PhIATinq it Relations may b( otlt~,ut to a forma~te/ on a high-speed printeL, i~ ,'.lle 
relation file for possible u~ie by auxiliary has a 5t!API: attribute with the al,[,[opriate analysis 
programs. geometric descrlptzon, it may be DRAV~'n at a qraphics terminal.  INFO SECUHE C INFO C UNSECUhE 
C INFO C (DOMAIN) DESTROY C Information can obtained about the .~ relatioi~ can bc SECUREd agains* universe 
of relations accessible to the inadvertent or u rla dtko~izc,| chan4es by ~ser, about specific ~:lations, 
and about locking it ill a real-only state. An old specific domains of st~eciLic relations. relat:ion 
ca~i be DI S'£ at] Yed, ~f it is UNSECUR[:d.  % re%~leve an4 ~raw all ~atls that a~e %0 s%a~% concre%e 
;ovrln~ dv~Ing march 198@ "" ~t -marchR@ " hd-~at~ between (star%; @31@%1~@ ~3131/~@) REgULTi-~PCHB 
CARDINALITV'~ DEGREE=I~ tJst -march~@ RELATION: -M~RCHS CARDIH~LITY-6 DE~REE-I~ 18:~i:~5 J~N 3@, IgY~ 
 UNIT POUR LEUEL SHAPE START FINISH XMINIMUM YMIHIMU~ ZMI~4!~UM XM~RIMUM YMRXiMUM ZMRXIMUM gGNg-F~5 
839 ~39t-~ e3!l~/~O 84/i~/~0 17.~7 78.90 e.@ S~.@@ 99.~@ IG.@~ I W639-F~G 839 A3~I-15 ~3/04/~0 C416SI~@ 
]R.78 53.## 0.9 ~7.~4 90.@0 tG.~8 I WG39-H25 639 A391-9 83,'t7i80 @4/£Iz8@ 17.5~ 9£.~@ @.8 S@,O0 l~.~B 
16.C@ 1 5i~39-J24 639 ~391~3 03/0,!I~@ ~4~I/8@ -8.4? !')~,9~ @,8 ~,~9 I$I.~ iG.~@ 1 WG39-~H8 $39 A39[-13 
03111i80 84/14,'80 H2.0@ ~.H4 e.@ 5~,00 alN.$U 10.09 % W639-~SG 639 A391-I£ @NiO41R@ 04~88/80 2£.#0 179.t0 
~.0 57.Ee ~16.00 J6.@9 > draw -mai-ch~# ~REA -t43q,~.?? SQ.FT. UOLU~E ~ 145~4.37 CU.FT. Figure 5 Walls 
Poured During A Specific Period  FUTURE EFFOh~S The Phase I modeling system was successful to the extent 
that we are supporting the input of some parts of ehe plant. These include: 1. structural concrete and 
steel work for the reactor, ~ux~ liary, Turbine, and Administration Buildings,  2. all construction 
joints Xor the reactor and Auxiliary Buildings, complete with pour identification and time sciledules, 
 3. construction sequencing on the above dat a,  @, some of the major piping assemblies, with checks 
for conflicts with the structural system. To improve support of the above uses of the model, we are 
currently modifyinq and ext end ing t he [ttod I i n g s yst e m. Specifically, we plan to acco~pii~h 
the following: I. Input ~outines will be developed for pip in<] systems, a,~d £0[ a spatial volume gelierator 
to find the volume that a shape qweeps otit as it ig moved along a path. 2: The Shape Edi+o~ wall De 
modified so that very large sha~es cam be ~rocessed efficiently and standard shapes, such as ~]oors, 
can be g~apbicaily input. 3. The Data Bas'.~ Manager, Lent L~outine will be enbanced so as to accept 
spatial inquires posed g,_'aph ica lit, and to produce a richeu assortment of drawings.  346 It ap~ea~s 
that it wzii be po:~sible to support the moJeling ~/stum, to,oether with a complex [~ode[ of the £)uwer 
plant, on a large mini-computer. We are implemenfing the spatial modelin(~ i outlnes on a PDP- 11/60 
com?uter that has a fast floating no[nt [)rocessor. I~'.itialiy this will be use,] as an i~put dad grapazc 
[,~ocessor. The Shah(: Editor, eahancud with hidden-~.Irface removal, Wiii run on it. A large disk storhqe 
,]nit will be ad(~ed, if it proves fcusiSle to ran tae i elational data base opera,ions ,)n ~i~e tills 
'.~ize ~achine. We are o[;timistic t!,~t thc nea~ future will s~e a use~ui co~,~,uter-aided design system 
based on ~patial modeling tech~i ?aes. The b lrrler-: to cL'catln~ such systems are fa.~ ~- li:;app~arin 
9. Powerful low-cost comput~rs are capable of suppor+ing comp~]t~,/ ~ode fin ~ operations, soph istica 
ted ir t(~Eact ire computer graphics, and ~]ata base u~a na gement o[,erations. And i~ has Ueco~,e econo;nical 
to dedicate hardwar.; to the bur1 ling design pr oc~ s:~. ACK NO~LI:D,;;:~: ENTS ~esearch into the a[~[>l[catloh 
j,r com~ute£s to buildinq dc,.;iqn ai,.n construction has been ~upported b~' ~:ne College of Architecture 
and U~ha:. Pi,~n|lil,:] for ~any years. Tac worh ae:~ct'£bel t,ere is a collabora tiw" effort involvi;,g 
Harold J. .9orki[', ['atricia ~;. ~clntosn, John F. :~clntosh, and James a. Tu&#38;ner. Fundillg for" 
the nuclear power i~laltt :.,ode ling effort was proviled by Towusend 6 POttUIll, Inc. and the Ohio }~,ii~3on 
Coruoration. EEFEPENCES [I] I[oskins, E.~., "OXSYS: An Integrated Computer-Aided Lnuiiding System for 
tile Oxford ~et hod", Proceedinq! _of the International _el Conference l Co mputeis in Architecture, 
1972.  [2] Horkin, ll.d. , lurner. J.A., Architectural ~i~puter c.raphics Sz~te~ Users iaau!! , Architectural 
Research Laboratory, The University of Michigan, aa,~ Arbor, Michigan, 1975. [~] Childs, D.L. , "Exteuded 
Set Yheory", Third Internatl~nal Couference on V~_rv La_K_q ~ Data ~d~/,_~_s, Tokyo, Japan, 1977. [4] 
Braid, I. , Desi~In ~i_th _V o__!_u~es, Compu ter-Aided 0esig n Group, ~Iniversitv of CamLridge Computer 
Labora*ory, Enqlaad, 1972. i~aumga[ t, J.G., "Winged-Edge Palyhedror ~epres~ntation", Ztandford Artlficial 
In tel iige~,ce Project R~,port No. CS-220, 197=. ,'6] Fas~man, C., "General _Purpose Building Descript 
ion Computer Aided Desiqn_, ~:I, pp. 17- 16, Ja~uary 1976. [7] Turner, J.A., An E£ficient Alqorithm 
foe Ooin~ S_et_-Ope_~atio~s on Two-and Three-Dimensional Spatial O b je_ct.s.s, unpublished paper, Architectural 
~esearch Laboratory, The University of ~ichi,:lan, ~n,~ Arbor, ~ichigan, 1978. [8] Turner, J.A., Three-Dimensional 
Po!~L3er on .qef Routines Proqrammers ~anua!, Architectural ~esearch Laboratory, The University of /lichgan, 
Ann Arbor-, ~ichigan, ]977. [9] TurPer, J.A., Two-Dimensional P__qolV~on !~our ines Pro H ram mers Manual, 
Architect ural Research Labora tory, The University of ~lichigan, Ann Arbor, Michigan, 1976. L13] :IcIntosh, 
J.F., doctoral dissertation work in progress, The rlnzve£sity of Michigan, Ann Arbor, ~licl~igan. [11 
] [)ate, C.J., ~L~ Introsuction to Database ~X'~tem~, Addison-Wesley, B~eading, :~ass., 1!973.  347 
 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807414</article_id>
		<sort_key>348</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>61</seq_no>
		<title><![CDATA[The problems of computer-assisted animation]]></title>
		<page_from>348</page_from>
		<page_to>353</page_to>
		<doi_number>10.1145/800248.807414</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807414</url>
		<abstract>
			<par><![CDATA[<p>In the last few years several systems have been written for aiding in the conventional two-dimensional animation process. The main purpose of these systems has been to let the computer produce missing drawings based on extreme drawings produced by animators. While there has been some success and a great deal of optimism, the promise of higher output and quality using a computer has not been realized. The transition from simple drawings optimized for use on the computer to the complicated and detailed drawings of quality conventional animation has been much harder than expected. The principle difficulty is that the animators drawings are really two dimensional projections of three dimensional characters as visualized in the animators head, hence information is lost, ie. one leg obscures another. The problem of making a program infer the original object from its projections is akin to extremely difficult artificial intelligence problems. Efforts to overcome this by drawing skeletons or increasing the number of overlays require more manual intervention thereby offsetting the gains of using the computer. One way to analyze an approach is to determine the average time required of an artist or operator at all stages of animation for every frame. A second problem not generally recognized is that a production animation system requires the management of hundreds of thousands of drawings, hence data base management techniques not normally found in experimental animation systems.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer animation]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Keyframe animation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Human Factors</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P75663</person_id>
				<author_profile_id><![CDATA[81100160637]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Edwin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Catmull]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Lab, New York Institute of Technology, Old Westhury, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baecker, Ronald M., Picture-driven animation, SJCC 1969, p273.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Burtnyk, N., and Wein, M., Computer Animation, Encyclopedia of Computer Science and Technology, Vol. 5, 1977. Pub. Marcel Dekker, N.Y. pp. 397-436.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Burtnyk. N, and Wein, M., Computer generated key frame animation, Journal of the SMPTE, Vol. 80, Mar 1971, pp. 149-153]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360357</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Burtnyk. N, and Wein, M., Interactive skeleton techniques for enhancing motion dynamics in key frame animation, CACM Oct. 1976]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>569952</ref_obj_id>
				<ref_obj_pid>800193</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Catmull, E., A system for computer generated movies, Proceedings ACM Annual Conference, August 1972, pp.422-431.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Csuri, Charles, Realtime film animation Annual, report to NSF, 1972-73, Computer Graphics Research Group, Ohio State University.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563870</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Hackathorn, Ronald J., Anima II: a 3-d color animation system, Siggraph proceedings number 2, 1977, pp. 54-64.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kitching, A., Computer animation - some new ANTICS, Br. Kinematography Sound Television J., 55(12), pp 372-386 December 1973.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563871</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Levoy, Marc, A color animation system based on the multiplane technique, Siggraph proceedings number 2, 1977, pp. 54-64.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>569955</ref_obj_id>
				<ref_obj_pid>800193</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Park, F.I., Animation of faces, Proceedings of ACM Annual Conference, Vol. 1, 1972.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>908714</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Stern, Garland, "GAS - A system for computer aided keyframe animation", PhD dissertation, Univ. of Utah, 1978.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Tuori, Martin I., Tools and Techniques for computer-aided animation, Masters thesis 1977, Dept. of Comp. Sci., U. of Toronto.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 THE PROBLEMS OF C(IMPUTER-ASSISTED ANIMATION Edwin Catmull Computer Graphics Lab New York Institute 
of Technology Old Westhury, New York 11568 ABSTRACT In the last few years several systems have been 
written for aiding in the conventional two- dimensional animation process. The main purpose of these 
systems has been to let the computer produce missing drawings based on extreme drawings produced by animators. 
While there has been some success and a great deal of optimism, the promise of higher output and quality 
using a computer has not been realized. The transition from simple drawings op- timized for use on the 
computer to the complicated and detailed drawings ofqualityconventional ani- mation has been much harder 
than expected. The principle difficulty is that the animators drawings are really two dimensional projections 
of three di- mensional characters as visualized in the animators head, hence information is lost, ie. 
one leg ob- scures another. The problem of making a program infer the original object from its projections 
is akin to extremely difficult artificial intelligence problems. Efforts to overcome this by drawing 
skeletons or increasing the number of overlays re- quire more manual intervention thereby offsetting 
the gains of using the computer. One way to analyze an approach is to determine the average time required 
of an artist or operator at all stages of animation for every frame. A second problem not generally recognized 
is that a produc- tion animation system requires the management of hundreds of thousands of drawings, 
hence data base management techniques not normally found in experi- mental animation systems. Key words: 
computer animation, computer graphics, keyfrane animation. CRclassification: 8.2 ~DLL-'TION There 
have been several systems written to aid in the process of animation [see references]. A s~n- mary of 
these has been presented in [2]. Some of these systems have been quite successful and have been used 
to produce short interesting films, most notably Hunger by Peter Foldes. However, there are some significant 
problems that remain. One of the inescapable conclusions one draws after exanining the process of conventional 
anima- tion is that there is a good deal of tedium in- volved. This observation has led to the idea 
that the computer can be used to greatly speed up the process and make it cheaper. It is time to examine 
this idea. There are several kinds of conventional anima- tion and computer animation. Broadly speaking, 
in conventional animation there is a continuum from the limited animation of the Saturday morning car- 
toons to the full animation of the Disney Studios. This continuum is referred to as "character anima- 
tion." Outside of this continuum are the animation "art" films with a great variety of style, quality, 
and methods. With computer animation there are roughly three categories: Art and graphic animation, 
three- dimensional animation, and computer-assisted char- acter animation, sometimes called "key-frane 
anima- tion". Art and graphic films are highly varied and will not be part of this analysis. 3-d is one 
area where the computer offers some exciting possibili- ties [5,6,10] but also is not part of this paper. 
 The area to be explored here is the application of computers to character animation. Of course one might 
legitimately wonder why we are trying to mold the computer into an existing process. While that is not 
the topic of this paper it should be noted that character animation is a very powerful medium for story 
telling. Since character animation is a continuum we should say something about the extromes of that 
continuum. At the low end, the action is very sim- ple. Movement is more indicated than actually per- 
formed. There is a lot of repeat animation, cy- cles, sound effects to indicate action, etc. Actu- ally, 
it is hard to imagine how it could be made much cheaper even with a computer. In any case most programaers 
interested in the problem aren't personally interested in producing low quality ani- mation. At the 
other end, the Disney animation is fluid and subtle. It is now so expensive that even the Disney Studios 
cannot afford to reproduce the quality of Pinocchio or Fantasia. Of course it is not necessary to live 
up to some past standard, but animators and interested computer professionals share a common goal of 
producing high quality films. The style may be different but it must be good. It is useful to characterize 
animation by the kinds of transformations that can be performed on figures. An important concept is that 
of "in- betweening" where a person (called an "in- betweener") or a progran draws a figure based on two 
extreme poses of a character. Most computer animation uses linear transformations and simple linear interpolation. 
The success of these systems has been extrapolated to use for full character animation. The extrapolation 
is not warranted. It is the thesis of this paper that there is a funda- mental limitation in autematic 
inbetweening and that there is a method for analyzing proposed solu- tions to the problem. The limitation 
and the method of analysis are discussed in the latter sec- tions of this paper. THE CO~IONAL ANIMATION 
PROCESS Conventional animation techniques have been developed to handle the organization of tens of 
thousand of drawings. The process is roughly a sequential pipeline with painting of the background going 
on in parallel. The steps are: i. story written 2. storybeard laid out  3. sound track recorded  
4. detailed layout  5. sound track reading  6. animate extremes  7. assistant animator draws some 
inbetweens  8. inbetweener draws remaining figures  9. camera department films drawings from paper 
  for pencil test i0. Xerox copy or ink trace onto acetate ii. paint figures on acetate 12. check 
for errors  13. camera department for final photography  14. edit together  A movie is made up of 
sequences and a sequence is made up of scenes. A scene corresponds roughly to 5-30 seconds of uninterrupted 
action. All of the scenes that belong to the same part of the sto- ry make up a sequence. There are 
two kinds of paper forms used to con- trol the flow of drawings through the pipeline: i) The route sheet 
 Every scene is listed with its length, vital statistics, and the name of the person in charge of the 
various stages. This allows the director to quickly determine the status and location of a scene. 2) 
The exposure sheet The exposure sheet has a line on it for every frame in the film. Each line indicates 
the dialogue for that frame, the order of all fig- ures, the background, and camera position. The exposure 
sheets are grouped according to scenes. Same of the procedures used in the process are arbitrary but 
most are grounded in necessity. For example, an arbitrary procedure is that film is measured in feet 
rather than seconds or frames. On the other hand, the exposure sheets and routing sheets are needed to 
control the large amounts of information that must be passed around. The value of this sheet is almost 
totally ignored in most computer animation research. THE COMPUTER IN THE ANIMATION PROCESS There are 
several steps in the conventional an- imation process for which we would like to use the computer: i. 
Inbetweening 2. input of drawings  3. coloring  4. composition and photographing or videotaping  
5. background painting  6. sound track reading  7. pencil test  8. exposure sheets  Each of these 
steps merits comment: i) Inbetweening This is a complex topic and will be dis- cussed in the next section. 
 2) Input of drawings Figures can either be drawn directly on the tablet, traced in, or scanned in. 
Tracing and scanning correspond to inking and Xerox copying in the conventional procedure except that 
we may not have to trace as many figures if automatic inbetweening can be performod. The quality of tracing 
is dependent on the ac- curacy and ease of use of the pen/tablet sys- tem. Scanning is dependent on the 
resolution of the scanner and the algorithm, s used to ex- tract information. In either case, overhead 
 has been added to the conventional ink or copy. 3) Coloring An operator indicates what color each area 
is to receive. The figures are colored by some area filling progran. Of course at this stage we must 
take steps to ensure that we do not see "jaggies" in the final image. Coloring is a process in which 
the computer offers a distinct advantage over the hand operation. It is not without problems howev- er. 
The coloring of a scannod-in image re- quires clean images and some hand touch up. 4) Composition This 
is normally done either at an anima- tion caaera stand or in an optical house. With the computer we can 
do this in a frame buffer (a large random-access memory that can store a picture) before sending the 
picture to the film or video recorder. Full generality almost requires that a rod-green-blue frame buffer 
be used with 8 bits for each color com- ponent. This is not obvious to most people, but it is an important 
capability to have for good picture quality. The prograns must include capabilities for zoom and pan 
of the components of the picture. This implies resolutions that are greater than that of the display. 
 349 5) Background painting INBETWEENING The software system for painting back- grounds using tablet, 
color monitor, and fr~ebuffer is one of the most successful software packages at NYIT. It was written 
by Alvy Ray Smith and is in full time use by the professional background artist Paul Xander (See figure 
2). The chief difficulties are that pictures consume large amotmts of disk space and one has to wait 
longer than is desirable to get the pictures from the disk. 6) Sound track reading The sound track 
is recorded on magnetic film with sprocket holes. Someone must deter- mine the frame numbers of every 
single signi- ficant sound event in the movie which must be matched to action, ie. the location of every 
consonant in the dialogue. This is time con- suming and error prone. Since the dialogue is known and 
the track is usually clean, it is not unreasonable to think that an interactive system could be written 
to speed up the track reading. This is clearly a research topic at this point. Digital sound equipment 
could also be used to synthesize sound or to fix errors by expanding or contracting sound on a tape. 
 7. Pencil test Animators need to check the action in their scenes. They do this by "flipping" their 
drawings for immediate viewing and by photographing the pencil drawings to get an accurate check of the 
timing. The latter takes a long time because the drawings must be photographed and the film developed. 
 With the computer, the artist can get real-time play back of a scene as soon as the figures are entered 
or synthesized. A fre- quently overlooked facet of this process is that the animators still need corresponding 
sound track in pictures. to sync hear the with the 8. Exposure sheets One can easily think of the exposure 
 sheet as a data base management system. It is a natural for implementation on a computer and has been 
virtually ignored. There have been several attempts at languages to control animation which are very 
useful for graphic animation but which are not applicable to conventional animation. A good analogy would 
be music: the conventional method for writing music is to write all the notes down. This method has very 
little in the way of iteration control. It is basically straight-ahead sequential with everything specified. 
Similarly, animators want total de- tailed control. Of course there are cycles and repeats but they can 
be handled quite nicely with the exposure sheets. The task of producing inbetweens has been the fecal 
point of most computer-assisted character an- imation systems. The problem is much harder than previously 
thought. The problem seems simple enough: given figures A and C, find the correspondence between the 
fig- ures such that we can produce an interpolated fig- ure B dependent on the correspondence. This prob- 
lem might be likened to another well know problem: given Russian and English, find the correspondence 
between them such that we can transform a sentence from one language to the other. On the face of it 
the problem seems quite simple but we now know that it isn't. Similarly there are subtle problems with 
inbetweening which require intelligence to resolve. To illustrate, an animator drew figures la and ic 
as extremes. The two drawings were given to an assistant animator who produced figure lb. The drawings 
would next be given to an inbetweener who would produce three drawings between la and ib and three between 
ib and ic. This example was taken from a real animation situation and is not tmusual. A close examination 
of the drawings will show that automatic inbetweening of full animation is a for- midable task. The 
principal difficulty is that the animators' drawings are really two-dimensional projections of the three-dimensional 
characters as visualized by the animator, hence information is lost. For exam- ple, one leg obscures 
another. It is the loss of information which severely limits automatic in- betweening. A person can infer 
the original object from the drawing because he knows what the original model is, i.e. he understands 
what a leg is. In order for a program to "t~derstand" a drawing it must contain a model of a character 
that corres[x)nds to the model in the animator's head. While such a program is not inconceivable, it 
is akin to difficult artificial intelligence problems. There are several possible approaches: i) Try 
to infer the missing information from the line drawings. 2) Require the animators or program operators 
to specify the missing information by editing. 3) Break the characters into overlays. 4) Use skeletal 
drawings. 5) Use 3-d outlines and centerlines. 6) Restrict the class of animation that may be drawn. 
 Each approach needs comment: i) Infer information This has already received comment. It should be 
further noted that human in- betweeners also make mistakes. 2) Editing The operator must specify the 
correspon- dence of the lines and the hidden lines. One must also ensure that during the process of interpolation, 
the hidden lines become visible in a correct manner. The process if further 350 complicated by extr6mes 
where there is no correspondence at all! (See figure i.) In this case more extremes are required. Anima- 
tors trained in the use of the sytems will know where to put extremes but the overall gain is reduced 
both because more extremes are required and because an editor must spend time on each drawing. 3. Break 
characters into overlays This means that the arms, legs, and body may be on separate levels. Someone 
(probably not the animator) must do the separation. Although this approach takes care of several kinds 
of problems (ie. the arms and legs in a walk cycle) it doesn't take care of the ro- tating head. 4) 
Skeletons Several people have suggested skeletons as an approach for easing both input and in- betweening 
[4,8]. The key idea is that a correspondence is established between a fully drawn character and a skeletal 
outline. It is then only necessary to animate the skele- ton. This method handles limited body move- 
ment but is not really adequate for changes in feature, expression, the manipulation of non- rigid figures 
or cloth, or motion involving hidden surfaces and three-dimensional rota- tion. These capabilities are 
important for good character animation. 5) 3-d outlines and centerlines It may be possible to extend 
the skeleton idea. For a large ntm~oer of views of a figure a corresponding outline with centerline could 
be drawn. This would then define a pseudo- three-dimensional character. The animator would draw the outline 
and centerline follow- ing certain rules. The program would deter- mine the appropriate outline from 
the charac- ter definition and hence the character. This is strictly a research topic at this time. 
6) Restrict the animation Just avoid troublesome figures or poses. Of course simple figures are also 
easier to produce conventionally so we may lose a sub- stantial portion of the gain. In practice, most 
systems (with one exception) require that the operator specify the correspon- dence between the lines 
of two extremes. If there is not a one-to-one correspondence then a new ex- treme is required. The one 
exception is that of Stern [ii] whose system automatically determines correspondence from scanned-in 
images. In all cases, the problems of incorrect matchup and manual intervention remain. ANALYZING PROPOSED 
SOLUTIONS There are many variations on the above methods. What may seem like a good approach fre- quently 
requires some preparation or fixup. In order to evaluate any approach we must introduce the concept of 
"touch-time." Touch-time is the amount of time that some operator or artist must spend working on a 
figure in some process. The total touch-time would then be the total of the times spent on all steps 
of the pipeline. An analysis then requires that we find the average total touch-time per frame. If the 
computer can perform inbetweening then the average total touch-time goes down. If any method requires 
some touchup, we must include the touch-up time. The processes included are tracing or figure entry, 
scanning, coloring or painting, error correction, etc. Solutions to the various problems of computer- 
assisted character animation should include ana- lyses of the remifications of that solution. The full 
extent of any ramifications cannot be fully understood until the method is tried in the en- viror~nent 
for which it is intended. Extrapolation of results will yield incorrect conclusions. The throughput 
of the animation pipeline is dependent on touch-time per frame, machine time per frame, the number of 
stations for artists and operators, and the amount of equipment for process- ing the images. It is not 
a simple matter to just state that the computer makes animation cheaper and faster. Cost-effective computer-assisted 
character animation has yet to be demonstrated. Another part of any analysis should be a state- ment 
regarding the class of characters to be han- dled. The ease with which any algorit~n can be used is dependent 
on the complexity of characters and the quality of movement. It is necessary to understand any restrictions 
on characters before one can evaluate the approach used to animate them. SUMMARY The production of 
a good animated film is a major heman effort. More advances must be made before the computer will be 
highly useful in such an ef- fort. Automatic inbetweening has not been a pana- cea. While the tone of 
this paper has been to stress the negative side of computer animation, it is felt that significant progress 
can be made only after coming to a better understanding of the prob- lem. The Computer Graphics Lab 
at the New York In- stitute of Technology was set up to develop comput- er animation. The lab has developed 
an animation system (TWEEN), a painting system, and a scan-and- paint system. Figures 3,4 illustrate 
some kinds of images produced for animation. Current work in- cludes 3-d animation and design. One intention 
of this paper is to put computer-assisted character animation is proper perspective based on analysis 
and experience. While on the face of it the results appear somewhat gloomy, it is only so if one relies 
just on this kind of animation. Other kinds of computer- assisted animation were not considered for this 
pa- per, however in practice we are marrying character animation with other computer graphics techniques. 
The computer is a "natural" for creating images of three-dimensional objects and for manipulating graphic 
images. Merging this capability with char- acter animation can enhance its story telling capa- bility. 
 AC KNOWLEDG~MENT The Cemputer Graphics Lab was conceived and spon- sored by Dr. Alexander Schure, president 
of New York Institute of Technology. Lance Williams, Alvy Ray ~nith, Garland Stern, David DiFrancesco, 
and Ephraim Cohen provided critical reading of the first draft. John Gentilella drew the extremes for 
figure two. The analogy to music was suggested by Alan Kay. REFERENCES i. Baecker, Ronald M., Picture-driven 
animation, SJCC 1969, p273. 2. Burtnyk, N., and Wein, M., Computer Animation, Encyclopedia __°f Computer 
Science and Technology, Vol. 5, 1977. Pub. Marcel Dekker, N.Y. pp. 397-436. 3. Burtnyk. N, and Wein, 
M., Computer generated key frame animation, Journal of the SMPTE, Vol. 80, Mar 1971, pp. 149-153  4. 
Burtnyk. N, and Wein, M., Interactive skeleton techniques for enhancing motion dynamics in key frame 
animation, CACM Oct. 1976  5. Catmull, E., A system for computer generated movies, Proceedings ACM Annual 
Conference, Au- gust 1972, pp.422-431.  6. Csuri, Charles, Realtime film animation Annual, report to 
NSF, 1972-73, Computer Graphics Research Group, Ohio State University.  7. Hackathorn, Ronald J., Anima 
II: a 3-d color an- imation system, Siggraph proceedings n~nber 2, 1977, pp. 54-64.  8. Kitching, A., 
Computer animation -some new AN- TICS, Br. Kinematography Sound Television J., 55(12), pp 372-386 December 
1973.  9. Levoy, Marc, A color animation system 'based on the multiplane technique, Siggraph proceedings 
n~nber 2, 1977, pp. 54-64.  i0. Park, F.I., Animation of faces, Proceedings of ACMAnnual Conference, 
Vol. i, 1972. ii. Stern, Garland, "GAS- A system for computer aided keyfrane animation", PhD dissertation, 
of Utah, 1978. 12. Tuori, Martin I., Tools and Techniques for computer-aided animation, Masters thesis 
1977, Dept. of Cemp. Sci., U. of Toronto. \ figure la figure ib figure ic 352 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807415</article_id>
		<sort_key>354</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>62</seq_no>
		<title><![CDATA[NUDES 2]]></title>
		<subtitle><![CDATA[A numeric utility displaying ellipsoid solids, version 2]]></subtitle>
		<page_from>354</page_from>
		<page_to>356</page_to>
		<doi_number>10.1145/800248.807415</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807415</url>
		<abstract>
			<par><![CDATA[<p>A system is described for producing 16 mm animated films of moving humanoid figurines and other figures composed of concatenated articulated interpenetrating ellipsoids. For such figures, the hidden line algorithm used consists in solving the quartic equations which result from simultaneous pairs of ellipses viz. (a) the projection of the outline of one being drawn, and (b) that of one potentially obscuring it. This is done in terms of Cohen's parameter, resulting in an ordered list of compacted hidden arcs of each outline. The visible outlines are then generated to the required fidelity separately.</p> <p>Where two ellipsoids interpenetrate, the outline of each is drawn up to the points where it disappears into the other. These points can be found by the simultaneous solution of the ellipse equations of (a) the projection of the outline being drawn, and (b) the projection of the ellipse of intersection of the obscuring ellipsoid with the plane of the outline of the drawn ellipsoid.</p> <p>The viewing window is assumed to be an ellipse also. Parts of objects projecting outside this ellipse are not drawn.</p> <p>The number of quartics to be solved is reduced significantly by testing each pair of ellipsoids for non-intersection of projected outlines by comparing the projected separation of centres with the sum of their maximum semiaxis lengths, and taking advantage of the total obscuration of one ellipsoid by another when discovered.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer animation]]></kw>
			<kw><![CDATA[Hidden lines]]></kw>
			<kw><![CDATA[Human movement]]></kw>
			<kw><![CDATA[Quadric surfaces]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Hidden line/surface removal</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P311480</person_id>
				<author_profile_id><![CDATA[81100148351]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Don]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Herbison-Evans]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sydney University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Barnard, S. and Child, S. Higher Algebra Macmillan &amp; Co., London (1936) p. 187.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cohen, D. On linear difference curves. Proceedings of International Symposium 'Computer Graphics 70' (1970) Brunel University.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Fleck, J.T., Butler, F.E., and Vogel, S.L. An improved three dimensional computer simulation of vehicle crash victims. Calspan Corporation (1975).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Goldstein, G.D. A system for computer animation of 3-D objects. Proc. 10th Annual Meeting of Users of Automatic Information Display Equipment (UAIDE) (1971) pp. 3-128 to 3-139.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Herbison-Evans, D. Animated cartoons by computers using ellipsoids. Proc. 6th Australian Computer Conference, pp. 811-823.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Herbison-Evans, D. NUDES 2: A Numeric Utility Displaying Ellipsoid Solids, Version 2. Technical Report 125, Sydney University (1977) Basser Department of Computer Science.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Herbison-Evans, D. How to merge lists of hidden arcs and then not draw them. Technical Report 128, Sydney University, (1978) Basser Department of Computer Science.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360355</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Levin, J. A parametric algorithm for drawing pictures of solid objects composed of quadric surfaces. Comm. Assoc. Comp. Mach. Vol. 19, No. 10 (1976) pp. 555-563.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>321330</ref_obj_id>
				<ref_obj_pid>321328</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Weiss, R.A. BEVISION, A package of IBM 7090 FORTRAN programs to draw orthographic views of combinations of plane and quadric surfaces. J. Assoc. Comp. Mach. Vol. 13, No. 2 (1966) pp. 194-204.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 NUDES 2: A Numeric Utility Displaying Ellipsoid Solids, Version 2 Don Herbison-Evans Sydney University 
 Abstract A system is described for producing 16 mm animated films of moving humanoid figurines and other 
figures composed of concatenated articulated interpene-trating ellipsoids. For such figures, the hidden 
line algorithm used consists in solving the quartic equations which result from simultaneous pairs of 
ellipses viz. (a) the projection of the outline of one being drawn, and (b) that of one potentially obscuring 
it. This is done in terms of Cohen's parameter, resulting in an ordered list of compacted hidden arcs 
of each outline. The visible outlines are then generated to the required fidelity separately. Where two 
ellipsoids interpenetrate, the outline of each is drawn up to the points where it disappears into the 
other. These points can be found by the simultaneous solution of the ellipse equations of (a) the projection 
of the outline being drawn, and (b) the projection of the ellipse of intersection of the obscuring ellipsoid 
with the plane of the outline of the drawn ellipsoid.  The viewing window is assumed to be an ellipse 
also. Parts of objects projecting outside this ellipse are not drawn. The number of quartics to be solved 
is reduced significantly by testing each pair of ellipsoids for non-intersection of projected outlines 
by comparing the projected separation of centres with the sum of their maximum semiaxis lengths, and 
taking advantage of the total obscuration of one ellipsoid by another when discovered. Keywords: Computer 
Animation, hidden lines, quadric surfaces, human movement. Categories: 3.41, 5.15, 8.2. Introduction 
This work was motivated by a request from a choreographer, the late Phillipa Cullen, to produce a system 
to show figures performing dances that had been previously coded in choreo- graphic notation. The suite 
to be described is intended as the bottom half of such a system. It produces frames of animated motion 
from a coded description of movements of figures composed of concatenated articulated ellipsoids. Examples 
of its output are shown in Figs. 1 and 2. A number of earlier computer animation systems have included 
three dimensional ellipsoids as one of a number of basic shapes available (3, 4, 5). These systems have 
either avoided the hidden line problem or else solved the full hidden surface problem. The complexity 
of this is somewhat forbidding (e.g., 9). In the present work, these calculations have been minimised 
by restricting the final visual repre- sentation to outline drawings rather than to shaded areas, and 
by not drawing the lines of intersection of ellipsoids (8), and by only allowing figures to be composed 
of ellipsoids (rather than in combination with polyhedra, cylinders, etc.). The last restriction limits 
the application of the NUDES 2 system to figures which have a natural convex 3D curvature. Thus it is 
very efficient for representing a stylized human form using say 20 ellipsoids, each being drawn using 
100 chords, needing the solution of at most 2 x 20 L (=800) quartic equations. A polyhedral representation 
giving this fidelity would need approximately 20 x ½ x I00 z (=105) faces, and an unsophisticated hidden 
line calculation on this polyhedral form would then need % x I010 interface comparisons (checking every 
visible face against every other for possible obscuration). Conversely, the ellipsoidal model is inefficient 
for representing objects with flat faces. Thus it would take a row of I00 ellipsoids to represent one 
edge of a cube to the fidelity described above, and hence 60,000 ellipsoids would be needed to represent 
a single cube. Thus it behoves the user to use a model to suit the figures that he wishes to represent. 
Drawing the ellipsoids Each ellipsoid is stored as a rotation matrix R, a diagonal matrix, D, of its 
inverse squared semi- axes, and a vector to its centre, C: (X -c)t.E.(X -C) = 1 where E = R.D.R t and 
X t = (x,y,z) 354 The projection onto the (x, y) plane of this outline where is then the ellipse fcos~ 
sin~ =ISl O\ = (cosO sinO Q = [-sin@ cos~| S T %-sine cosel (x, y, I) A (x, y, I) t : 0 s2) where A can 
be derived from E and C (6). x 0 = s I cos~ YO = Sl sin~ Before drawing this projected outline, the program 
and @ is the orientation of semiminor axis of the calculates its intersection points with the ellipses 
drawn ellipse, and Sl,S 2 are its semiminor and corresponding to: semimajor axis lengths. (a) the viewing 
window ellipse;  This gives an equation in terms of sin@ and cosO. (b) the projected outlines of all 
other ellipsoids These may be substituted by 2t/(l+t 2) and in the picture that are within range; (l-t2)/(l+t 
2) respectively which gives a quartic in tan (@/2). This may be solved by the usual methods (c) the projections 
of the ellipses of intersection (e.g., I). The roots for e are translatcd to lieof these other ellipsoids 
with the plane of the in the range 0 to 2~, and put into a list inoutline of the drawn ellipsoid. ascending 
order. Viewing window Interpenetrating ellipsoid% Windowing is done in order to eliminate unnecessary 
The elliptical outline of the ellipsoid to be drawn calculation of profiles, and to eliminate problems 
lies in a plane, whose coefficients may be derived of wrap-around and screen over-or under-flow. The 
from the equation of the ellipsoid (6). This plane NUDES 2 system, in keeping with its elliptical will 
intersect some other ellipsoid in anotherworld view, has an elliptical viewing window in the planar ellipse. 
The intersection points of this z = 0 plane. ellipse with the drawn outline are possible points of entry 
of that outline into the interior of theOn most display devices, the visible area is rectan-other ellipsoid 
(see Fig. 3). Such points are alsogular. If this is strictly limited, then the calculated, in terms of 
Cohen's parameter for theelliptical window must be defined to lie within it, drawn ellipse as before. 
just touching it at the midpoint of each side. The loss is a small part of each corner, which is Hidden 
arcsseldom important. Having calculated the Cohen parameters of possibleIf the display device has an 
invisible display area points where an arc of an outline being drawn may around the rectangular visible 
area, then the be obscured by some other ellipsoid, the points 0viewing ellipse can be defined just to 
touch the and 2~ are added and then these are all sorted intovisible rectangle at its corners. There 
is then no ascending order. Each arc between successive pairs loss of picture, but some unnecessary calculation 
of these points is considered in turn, and a of outlines. This is offset by the simplification comparison 
is made at its midpoint of the z depthsof having a system that uses ellipses throughout. of the drawn 
outline and of the nearer point on the potentially obscuring ellipsoid. If the midpoint isIntersections 
of ellipses obscured, then the whole arc is obscured, and it is merged into a list of hidden arcs of 
that outline. Given the equations of two ellipses, then their points of intersection are the solutions 
to both of The list of hidden arcs is kept as a list of pairsthese equations simultaneously. If one of 
the of Cohen parameter values, each pair consisting ofequations is that of the projected outline of an 
the start and end values of a hidden arc. The arcs ellipsoid which is to be drawn, then the intersection 
are kept in ascending order. Overlapping hidden points are required in terms of Cohen's parameter, O, 
arcs are appropriately merged into this list tofor this outline (2). To obtain these points, the minimise 
its length. equation of the intersecting ellipse is best expressed in a coordinate system centred on 
the drawn ellipse When the outline is drawn, its list is appropriatelyand aligned parallel to its major 
and minor axes. scanned, and only those chords or parts of chordsUsing suffices d for the outline to 
be drawn, and i that are visible are drawn (7). for the one intersecting it, this can be done by translating 
and rotating the intersecting ellipsoid: Intersection calculation avoidance t t t Rd.( X _ Cd ) = 1 (X 
- Cd).Rd. Ri.Di.R i. The solution of the quartic equation of the inter-section of two ellipses is expensive, 
and avoided and deriving the matrix A i from this as before. wherever possible. Then x and y may be substituted 
from Cohen's formulation of a point on the drawn outline: Before seeking the intersections of a possible 
obscuring ellipsoid with the outline of a drawn (x,y) t = Q.S.T.S-!Qt.(Xo,Yo) t ellipsoid, a coarse check 
is done to see if inter-section is impossible. The sum of squared projected separations in x and y of 
their centres is compared with the square of the sum of the maximum semiaxis 355 of the obscuring ellipsoid 
and the larger semiaxis of the drawn ellipsoid outline. If the latter is the smaller, then they cannot 
overlap. Squared values are used to avoid unnecessary Euclidean square roots. Similarly, in checking 
for windowing, a preliminary test is made of the square of the separation of centres against the square 
of the difference in semi-axes to see if an elliptical outline is totally within or without the window. 
The effect of these checks is to reduce the number of quartic equations to be solved e.g., for a central 
upright humanoid figure composed of 18 ellipsoids, the number is cut from 630 to about 70. References 
(I) Barnard, S. and Child, S. Higher Algebra Macmillan &#38; Co., London (1936) p. 187. (2) Cohen, D. 
On linear difference curves. Proceedings of International Symposium 'Computer Graphics 70' (1970) Brunel 
University. (3) Fleck, J.T., Butler, F.E., and Vogel, S.L. An improved three dimensional computer simulation 
of vehicle crash victims. Calspan Corporation (1975). (4) Goldstein, G.D. A system for computer animation 
of 3-D objects. Proc. lOth Annual Meeting of Users of Automatic Information Display Equipment (UAIDE) 
(1971) pp. 3-128 to 3-139. (5) Herbison-Evans, D. Animated cartoons by computers using ellipsoids. Proc. 
6th Australian Computer Conference, pp. 811- 823. (6) Herbison-Evans, D. NUDES 2: A Numeric Utility 
Displaying Ellipsoid Solids, Version 2. Technical Report 125, Sydney University (1977) Basser Department 
of Computer Science. (7) Herbison-Evans, D. Howto merge lists of hidden arcs and then not draw them. 
Technical Report 128, Sydney University, (1978) Basser Department of Computer Science. (8) Levin, J. 
A parametric algorithm for drawing pictures of solid objects composed of quadric surfaces. Comm. Assoc. 
Comp. Mach. Vol. 19, No. lO (1976) pp. 555-563.  (.9) Weiss, R.A. BEVISION, A package of IBM 7090 FORTRAN 
programs to draw orthographic views of combinations of plane and quadric surfaces. J. Assoc. Comp. Mach. 
Vol. 13, No. 2 (1966) pp. 194-204. Figure 1 Sample figure composed of ellipsoids: Ist arabesque sur la 
pointe. ~,~~ ,3u > OnlCil F.3 -," -o3C -{ 'i, ~_~il, i'c tLIClO t'" qOCt'~OC<I Cut! F'C ~" ~, ":0 i~ 
] -. ~ ~ ~ -ICiI~I?~H~II~H~II~I I~H~i I~ I~[1~1 I~11~H'_~ i.!l ~C!T~I P'HI~ I~'I~ >-, ,, , C <O,t, < 
' ~'I 'h3 i ~ - C '[ L,Oi300 -~ ,~ . 4YiC ~,~, LI " _ "u LC i C ~313 ~'<' C'C! ~C'n~tl?, FC, Figure 2 
Another figure composed of ellipsoids. ! t , ! 5 I l ! ! Fi gure 3 Two intersecting ellipsoids: A and 
B, showing as a dotted line ellipse of intersection of ellipsoid A with the plane of the outline of ellipsoid 
B. 356 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807416</article_id>
		<sort_key>357</sort_key>
		<display_label></display_label>
		<article_publication_date>08-23-1978</article_publication_date>
		<seq_no>63</seq_no>
		<title><![CDATA[Dynamic graphics using quasi parallelism]]></title>
		<page_from>357</page_from>
		<page_to>361</page_to>
		<doi_number>10.1145/800248.807416</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807416</url>
		<abstract>
			<par><![CDATA[<p>Dynamic computer graphics is best represented as several processes operating in parallel. Full parallel processing, however, entails much complex mechanism making it difficult to write simple, intuitive programs for generating computer animation. What is presented in this paper is a simple means of attaining the appearance of parallelism and the ability to program the graphics in a conceptually parallel fashion without the complexity of a more general parallel mechanism. Each entity on the display screen can be independently programmed to move, turn, change size, color or shape and to interact with other entities.</p> <p>The scheme presented herein begins with the notion of a quantum of time, or <italic>tick</italic>, within which there are no ordering constraints on events. Each entity or actor decides what it must do upon the next tick. Ticks are a powerful means of controlling parallel processes but are usually at too low a conceptual level for user convenience. Higher-level operations built upon the tick mechanism are presented, most notably the ability to instruct any entity or group of entities to gradually change or move at a rate that is itself changeable by the same operation. To illustrate these ideas a simple celestial mechanics simulation is presented. Upon each tick the velocities and positions of the objects are updated by the gravitational and propulsive forces acting upon them.</p> <p>Ticks are only one product of an object-oriented programming style. For the best control and the most modularity, graphics programming should be object oriented. Each object displayed, and its parts, should be independently programable. Instead of being passive data, objects should be responsible for the changes in their position or appearance. Instead of a global controller, each object should interact with the others.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P160130</person_id>
				<author_profile_id><![CDATA[81100453004]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kenneth]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Kahn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Massachusetts Institute of Technology, Artificial Intelligence Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39073160</person_id>
				<author_profile_id><![CDATA[81332503927]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Carl]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hewitt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Massachusetts Institute of Technology, Artificial Intelligence Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Dynamic Graphics using Quasi Parallelism Keuneth M. Kalm and Carl ilewitt Massachusetts Institute of 
Technology Artificial IntelligenCe Laboratory 14 May 1978 Abstract Dynamic coml~uter ~raphics is best 
represented as several pro.cesses operating, m parallel. Full parallel processing, however, entails ntucl~ 
c-mplex mechanism making it difficult to write siml~le, intuitive programs for generating computer an.imatiOll. 
What is presented in this papf:r is a simple means of atlainin~ the appearance of. parallelism and the 
ability to ~ oo am the ?raphics in a conceptually parallel fashion withoul the complexity of a more general 
parallel mecba||Jsn~. F:ach emily on the displa'y sc,re.en can be independently pr0gramtned to move, 
turn, change size, color or shape and to ilileract with other entities. ~ . "l-he scheme presented hczcin 
begins with the.notion of.a quantum of time, o! tick, within which there are no ordering constraii-ffs 
on events. ]~ach entity or actor decides what it must do upon the next tick..Ticks area powerful means 
of controllin K parallel puoces;cs but are usually at too low a conceptual level for user convenience. 
Higher-level operations built ul~-on .the tick n~ecl|anism are presented, most notably the ability to 
instlttct any entity or group of entities to gradually chan~e ot mow at a |ate|hat is itsel.f cha.ngeable 
by the same operation. l'o illustrate these ideas a simple celestial mechanics sinnflatiou is presented. 
Upon each tick the velocities and positio|ns of the objects are updated by the gravitational and prolmlsive 
forces acling upon them. "ricks are only one ptod|ict of an object-oriented pr%ramming sty.le. For the 
best .control and the most modularity, graphics progran.mm~?,' sliould be object oriented. Each object 
displayed, and its parts, should be independently l_~no~ramable. Instead 9f being passive data, objects 
should be responsilHe for the changes in their position or appearance. Instead of a ~,.lobal controller, 
each obje.ct should interact with the others. Parallel Processing for Dynamic .Graphie.~ Dynamic graphics 
is concerned wilh the display of changing images. Typically there are many different entities or aspects 
of entities changinf, simtnltaoeously. To reduce t.he programming complexity we represent each entity 
and Its parts as a module capable of chan?.ing its state and appearance and of interacting with other 
modules. To simplify the control of these objects wr: make them indel~endent entities and.run'them in 
pa.rallel. Each entity on the display screen cat] be thoug.bt of as a little person who can be asked 
to move, change appearance, remember and fol~,,et inlormation.. These little people,'or a~;tors, interact 
with each other to form a community. This metal:d~or of cornl~otation as a societ,y of interacting entities 
is esl)eciMly appropriate for dynamic graphics where it usually easy to av~lhrol~omorphize the images 
on'a d'isplay, whether they he of DNA strands, engine parts, simple geometric shapes. St~l~er s~0~ic 
transports, or people.. The communities can r,,'<ist at different levels, for example, there may .be 
a commnnity (,f l~cople while simultaneoualy there is a Community of arms, leg's, and heads associated 
with each l:~erson. (-).,jet-oriented computer languages .such as Smalltalk, Act I, or Director I are 
Ideal for programming in this style. l-hotL~,h re[,,ardless of computer language on.e can concepttnalize 
one's dlsplay as a community of active entities. '2 Apparent Parallelism To animate the chan~,es of m~ny 
objects simt|ltaneously one needs parallelprocessin~ or at least the appearance of having it. In this 
paper we opt fo~ the latter in.the interests of simplicity. During a tick. i~rocesses can run in any 
order, even sequentially, so long as Ihc obiccts are in the desired consistent state when the flame ends. 
If the animation is being filmed, uecorded fran|e by. frame oul video, or in the computer's memory for 
later pl.~yback then all that matters is that the display is correct '~,hen the frame is necorded, between 
recordings anything rnay happen, if animation is being displayed in real time tlwn thn time to perform 
all the actions of a tick. should he less than a refresh cycle (typically a thirtieth of a second). To 
cootdin ate and ccJnt|ol those processes we intr0dqce the notion of a lick, or a quantum of time within 
which 1. Director i~ an ol~jc~q-orwnl(*d I;mVua/rc r~lwcially desig,ed for animation and arlificlal mtrlhl_'r'nre 
application~. It wa~ de.~igned aml imph,montcd by kahw. [kalm 1OTll] All Ihe example~ in Ibis paper ,'fre 
working pVol'Vam~ in Director. 2. Of course, the" (07zVcTzi('~7(( wilh "whi(-I.t one can.program this 
way varies ./Treallv fv-oht I;mlrua~e to lan~ua£e. The object-ov'irnted pav'atlel sch,'vne I~V'e~onfe,I, 
for example, would be very difficult to implement in a"/,vv*ov'al fashion in any lan~ua/ze wl, ich did 
no! perrail the cnn~.|leic|ioi, ;In,] ~:uh~oquenl evah]aliott of code. The ahililv to modify pl;i,,i,c,,I 
a~:lion~; i~; important, ae, i~ the. ability to do par! of a plawwef| ;1eliot a¢.l plan I.n lhere~t }atler. 
 357 one is unconcerned about the order of events. All the objects have associated with them a va~iabl 
e containing a list of actions to take on the next tick. When an object .receivesa tick it does all the 
actions it had planned'for that time. in the simplest case, an animation p o? a ~ proccecls by sending 
a tick'to each object on the screen, recording or displaying the current state and repeating. It is the 
responsibility of each obje'ct to 'respond to each tick. More complexity is introduced wherl there are 
several ticks to a frame or when only certain subsets of Objei:ts are to run at a certain time. A Simple 
Example Suppose we want to animate a shape to move gradually forward. We already ha~/e a primitive, called 
"Forward" that moves an object folward l:,y causing, it to hide and reappear at its new po~itiou. I We 
could write the following simple program: REPEAT FOREVER (ASK AN-ODJEC.I I-ORWARD SPEED) (ASK SCREEN 
RECORD) The objeci called "an-ol)ject" will tic forward "speed" then the screen is recor.ded and thi~ 
J~ repeated forever. If we wanted two objects to move forward simultaneously then we could write: REPEAT 
FOREVER (ASK OBJECI.I FORWARD 5PEEDI) (ASK OBJECI2 FORWARD SPEED2) (ASK SCREEN RECORD) The need for explicitly 
usin~ ticks have not yet risen. But suppose we want '~Objectl" to go forward 300 steps and the other 
"t00 steps. Or we want "Ol~ject~" to change its speed after foul frames. The ptoL~ram becomes more and 
more unwieldy. An alternative is to explicitly use ticks as follows (as opposed to. the implicit rise 
of ticks in the previous examples) 2 (ASK OBJECT-1 SET YOUR SPEED 10 50) ; tl~is need onl~ be mentibned 
initia.ll~ (ASK OBdECI.2 SET YOUR SPEED lO 40) ; or a default could have been used (ASK OBJECTI PLAN 
NEXI GRADUAI L.Y i:ORWARD 300) ; insert (gradzzall~ forward 300} into Ob.iectl's list of action.s for 
t.he next tick (ASK OBJECT2 PLAN .NEXT GRADUAILY FORWARD 400) (ASK OBJECT,?. PLAN.AFTER 4 lICKS CIIANGE 
YOUR SPEED TO 60); '~ ticks inter cl~an,~;c speed At this point nothing has hal)pened on the display 
screen, only the plans have been associated with the objects. To run the plans and record the state there 
is a special kind of en.tity, "movies", that cause ticks to be sent to each object and the screen to 
be recorded. The sending of the message "gradually forward 300" to Objectl causes the following events 
(ASK OBOECT1 FORWARD ,50) ; ~oes forward ~0 units (it~ speed) {ASK OBJECT1 PLAN NEXt. GRADUALLY FORWARD 
250) ; plans to do the re~T ne~:t An Example from Celestial Mechanics Suppose we want to simulate the 
orbits of planets and space ships. One way to do this is to associate with each physical object another 
object corre~pondin~ ~, to i.ts velocity. The.velocity "actors have thei.r .own state and their position 
in velocity space relative to(0,0) represents their direction and magnitude. At each tick each physicalobject's 
positicin is updated by addin~ it to the position of its velocity. The velocity, itself may. beuT~dated 
in a similar manner by the thrust of the ship or by the'~ravitational pull of other massive objects. 
The tick mechanism l~rovides a means by which the different physical object~ can I~ehave in apparent 
parallelis'm. Ticks also sJml)lify the pl~ysics by reducing the problem to the computation of the chan~e 
during a small constant unit of time. In this way the integration needed to compute the position and 
velocity is alq~r.c~ximated implicitly'by the plogram~ This use of lho position of an'obJect or turtle 
to represent the velocity vector i~ similar to the approach pr.esente, d in [Abelson 1975]. First we 
define the class of pl~ysical objects by describing how to make instandes of it. how to update the state 
of an instance and how to compute tl~e ?;lavilational pull caused by an ~0bject. A subclass of p.Iwsical 
objects, space ships, are defined to do all that physical ohjects do and, in addition, know. how to thrust 
forward. Suns and planets are subclasses of physical objects witt~ no special behavior. Finally we define 
the g.ravit;~tional field which is capable of !. This example and Ihe nexl r~'h" upon a ~ompulational 
di.~play enlity calle(I a "l.urlle". "l',Jrlh'~ have a ~tate eongi~tin/; of a, position anti direelion 
an,| ro~po,.I Io it.'~a~,,'~ a~kin~ teem to go forward or !o I.urn. Mnre ,h,tail~ f'an be found in [Papert 
|971a], [Paperl. 1971b] a.,l [Cohl~te,. 107S]. 9. Thi~ paper i,~ nol |lie apl~ropriale elar'e In f,,lly 
de~cribe lee synLax of "l)ireclor. "The last of the Inllnwing ~tatemenl~ mean~ that the mes.~age (i)lan 
afh'r 4 fi~'l~ chan/,e vour.~peed Io 60) i.~.~ent to object2. 'Four tick~ lalcr obe,'(12 will receive 
tee imbe,ldrd message, i.e. (ehan/~e your ~pvrd In ~0). Thf, mlbedded messa~e'may be any me~.~a~e, lha.t 
the recipiv.! f'an re~pond to. changing the velocity of any ol~jecl hy r'xertlng tile pulls of all the 
masses that it knows about (define physical-object ol~ject ;; ntak.¢ physical-object as a kind of o!,ject 
and send if the following messages (set your mass to 10) ;; the (l<f, Tult mass (receive (make ?instance) 
now (Io ;; this enables rne to extend the normal behavior (ask :self make ,instance) ;; create the object 
as normal (ask ,instance lllan next rel)eat forever upda.te your state) ; ; on every ticl~ send ~)mt~sc![ 
the message (update ~our state) (ask velocity make (velocity-of ,instance)) ;; make a velocity/or oh./cot 
instance ) ; ; ?¢.ttt~n ttw nen,/y orated instance (receive (update your state) ;; when I get a message 
asking me to update my state (ask :self change ymw position to ;; I update my positEon by ;; I,? adding 
to my current position to .the position of my velocity ,(position-sum (ask :self recall your positibn) 
(ask (veloclty-of ,:self) recall your position))) (ask gravitational-field apply gravitational forces' 
at ,(ask :self reca1'l..your po.sition) to (velocity-of ,:sell)J) ;; I ask the gravitational ficht at 
my locat.io.n to chang'e my velocity (receive (yield pull at ?place) ;; to determine tl~e gravitational 
pull at the place (G=I i.n our units) (quotient (ask :self recall, your mass) ;; t.c~ke my mass (square-root, 
(ask :self yield dis'tance to ,place)) ; ; (tividf I,'p the square, root of my distance to the place 
to get force per second : Frames-per-second ; ; divide by this.to get force per frame : ticks-p~r-frame) 
) ) ; ; divide to. get force.' per tick (define gravil~ational-field snmething ;; make t.he field dn# 
se.nd it the followinF, messages (receive (apply gravitational forces .at ?l)lace to ?v.elocity) ;; for 
,u' to a/,/,l"~ tl~c gravitational forces at a place to a velocit~ (ask :self exert pulls of ;; I exert 
the pulls of the masses not at the /,lace ,(remove-any-at-place (ask :self recall y.our masses) place) 
on ,velocity at ,place)) ;; on the velocity (t'ecoive (exert pulls of (?first-mass %rest-of-the-masses) 
on ?velocity at ?place) ;; to exert the .~avitational pull at a point of some masses on a twlocity (ask 
,velocity move ,(ask ,first-mass yield pull at ,place) in direction from ,place to ,.(ask ,first-mass 
recall your posltlo,)) ;; move towards the mass f, om the /,lace by"the pull "(acceleration) at that 
place (ask :self exert l)lllls of ,rest-of-the-ma.sses on ,velocity at ,place)) ;; and let the ~est el 
the masses exert t.hemselves on the vrlocit~ (receive (exert pulls of () on ? at ?);; when there are 
no more masses do nothing nil)) (define velocity object);; a velocity is an object so that is can more. 
in velocity space (define ship physical-object ;; now to defineships (receive (thrust forward ?amount) 
;.; IYhen I'm asked to thrust forward (ask (velocity-of ,:self) change your heading I~o ,(ask :self recall 
your. heading)) ; ; I set the hr,lding o/ m~) velocity to my own heading (ask (velocity-of ,:self) forward 
,(quotient amoun~ (ask :self recall your mass)))) ;; and clmng," mV vclo,ir~ I,~ fraying it go forward 
the quotient of the thrust and my mas$ (draw using draw-rocket .of size)) ;; and I am drawn by the Draw-rocket 
procedmc applied to my $lze (define sun phystcal-ohject ;; a snn is also a physical~.object (set your 
angle to lO) ;; n~:+7~enov.ch to a circle (really a 36.-agon) (set your mass to log) ;; the dc/ault nmss 
of a su~i.s 100 (draw using draw-poly of size angle)) ;; I am drawn using Draw-pol~ of ,ly size and angle 
The advantages of proKramndng in this fashion are many. Computation.alentities correspond very closely 
with physically intuitive entities. Corresl:,Onding to each object in space there is an object in tile 
i)rogram complete with state and a behavioral specification. Thr, ~,ravitational field is also a s.eparate 
entity which tq,on request applies the gravitational pull of each mass to any w-locity. The ticks reduce 
the computation to that of calculating the change during a small amotmt of time. Al~r~ tilt:' nlatlxema.tics 
i/1 the.example is kept simple enn~l!,h for a ten year old by keeping the trigonometry insicle of tho 
turtle primitives for moving forward and tnrnin~ ri~,.llt. It sbouJd be clear that the program is very 
general, that an~ ntmlher of objects can exist and new ones can even be adcied or old ones removed at 
any time. Also the accuracy with which the calculations take place are easily controlled by the variable 
for the number of ticks pet frame. Figure I---A Simple Test Rml .with Two Suns and a Ship ® @ &#38;#169; 
® @ 0 ® ® @ 0 @ Q Efficiency and the Distribution of Control and Data Control and data are distributed 
in the previous examples of the use of ticks and.clhiects. There is little doubt that this reduces the 
conceptual complexity of the programming but i¢ poses many questions l e~,arding the efficiency of programming 
graphics m this manner. For example, the .lack of any globa! agenda or .~chedule might lead one to suspect 
that the distribution of tile planned actions and their times ofoccurrence is lessefficWnt. The argument 
goes as follows. If an object plans to do some action many tiCkS from now and nothing until then, tllen 
if control was based upon a global agenda then nothing need happen until that time. With the information, 
in tl~e a[.enda spread out in the objects involved the object with somethinR to do much'later still must 
be sen.t ticks in order to decrement the time it plans to do the action. This seems physically intuitive, 
but needlessly inefficient.. The cost ot an.actor processing a tick, however, can be very small.. Moreover, 
the distribution of the plans makes the cha.nging ot iilans much simpiier. An object can take its plans 
and modify thr'm arid there is no global structure that also nec;ds tn br, updated. Planning with a tick 
mechanism i~ not restricted to plans with respect t.o a particul.lr time. To plan an action to happen 
when a particular event hal)pens or condition is met can be done two waTs. ]"ither the actor involved 
can ask other actors to inform it of some event or upon every.tick it determine if some conditi(~n i~ 
true. In this way an object can plan to explode when it co]lirlcs with another or tO go forward when 
.some other actor has finished going forward. Suppose we want the ships to melt upon collisionwith a 
~unand explode if colhdiH?, with anything else. Then using ticks and messages we can arranF:,e that each 
ship a~ks the other objects where they air" on every tick, determines whether they are collicling and 
bch~ves accordingly. An alternative con.vention is to an;m?,e that on every ticks an actor corresponding 
to space (or several actors representing regions in space) checks for coihsions of" objects within it. 
This scheme is less ~eneral, but usually more efficient, than the one where each object asks ~'ach other 
for its position. For example, to have shipl explode or melt upon collision ask it the following: 360 
 (ask shipl plan to (tend ((ask ,other are you a sun) ;; if the ot./~er is a sun "(melt)) ;; then'lhe 
action is to melt (t "(explode))) ;; otherwise it is to explode after receiving colliding with ?other);; 
onl~ if receiving, a message matching (colliding with.?) If one has a nmlti-processor syslem with many 
processors then a tick mechanism can easily be.programmed to take advantage of" them. All t.he events 
that occur within a tkk are unordered except for any requirements, to serialize the acts of individual 
actors. The events are grouped by the object'involved ~nd so in terms of locality of data, one can optimize 
by running those actions of the same object on the same processor. The advantages of having ticks are 
great If one is running on parallel hardware since there is no global data structure that must be kept 
consistent and easlly accessible. Comparisons with Other Pvtrallel Dyn.~mie Graphics Systems Several 
animation systems l,ermit parallelism that is d?s~ribed and Controlled via graphical input. The approach 
taken in this paper is not an alternative to these demonstra't.ive systems but rather is complementary. 
One alternative approach was tat:ell by Pfister in the system called Dali [Pfister Iff74]. Dali is programed 
by specifying demons which fire when their tIig~eling conditions become true. The use of tickscombined 
with serializers [Atklnson 1978] is both simplier and more general since it does not make any restrictions 
ripen how reformation can flow. Some other lanf~,oa~.es are too similar to what is presented here to 
form any iml~ortant comparisons. ]=or example, $malltalk [Kay 1977] can easily lm extended to have ticks. 
Simula [Birtwistle !973]. a language which strongly influenced both Smalltalk and l.)irector, cou.ld 
also be'changed slightly to support quasi-parallelisnl for graphics. As we have seen, ticks permit the 
Slwcification of any condition for an event, while a global agenda sorted by time as in $1mula restricts 
olle to a temporal specification. Conelunions and Directions for Futuve Research One wants one's pln~,qams 
to reflect the structure of the task. Dynamic g.raphks involves the display of changes of many different 
elements arld their features. It has been at:gued that an object oriented parallel approach reflects 
this. This approach is also physically intuitive in its stress on locality and its rejection of "action 
at a distance". Programming in this style, ofw can m:~ke use of powerful metaphors from physics and think 
.of each entity as a physical object that is affected only l,y its inmwdi~te surroundings and that behaves, 
oni.ts owl] with il~ own clock. Another very useful metaphor that a l.~ro[~~anmwr can make use of !s 
that of a'society. Ju.q as in.societies we are familiar with, there are various strtJctures of cc,nnland 
and info{mation flow that map over [o object-qrJentehl con~l~nt~,tion. One direction of fuHlre re~ealch 
is to find other powerful computational coucepls f~,r the conceptualization of the display of changing 
ima~,~es. "lmlles, ticks, and objects are both programming a ~[, L~'.e constructs and ways of thinking 
about one's problems. "l'here needs to bemore0fth'em. F0rexample,,perh.allS the norton of an activity 
that an object is engaged in should be ex[,licilly represented as an actor. [n that w.ay it could r.eceive 
messages and change its plans in accordance with new ,~ve1~l~ One might also consider extending the physics 
melal,bor. Perhaps all events should be viewable only from a "frame" of reference" in a way anAlogous, 
to" relativity. T.he.~,~neralization of this idea of .taking the observer into account should apply to 
all.events, including, of 'course, the viewing of a three-dimensional object from a viewpoint. This direcHon 
for research is a.lso pointed out'in [Kay 1977b]. [Moore 1973], and [Bobrow 1977]. A related and eqt~all,,, 
important direction graphics programming should move is tow~rcls the inclusion of much more knowledge 
into the software, qhe more the system knows aboot, what tlie entitiesbeing displayed are, how they behave 
and interact the easier it becomes Io vse it. The graphics programming has been at too low a level of 
detail, we should be movfng towards syslems that knowen.ough so ]'hat a vser's p]imary effort is communicating 
what he or she wants to l]al:Jpen and not how to do it. Much of the research i!i !lle artificial intelligence 
communlty on "knowledge-based pro~ramnm]8" is very welevant to the task of making images and manil~ol;~ting 
them fn a convenient manner. The application of arHfici~l mlellif~'ence techniques to computer graphics 
is called for. One of the authors of this paper is engaged in creatin~ a system capable of producing 
.simple non-representational narrative cartoons in response to a vague, incomplete, hi.[,31-1evel description.[Ka'hn 
1977b]. The system knows enough about how characters should move and look in order to establish a personality, 
convey an emotional state, or an interpersonal interaction. Animation is morethan the simulation of a 
world, its production entails inferences, het,ristics, and knowledge. 361  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1978</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
</content>
</proceeding>

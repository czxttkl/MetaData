<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>07-31-1989</start_date>
		<end_date>08-04-1989</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[Boston]]></city>
		<state>Massachusetts</state>
		<country>USA</country>
	</conference_loc>
	<conference_url></conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES382</series_id>
		<series_title><![CDATA[International Conference on Computer Graphics and Interactive Techniques]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>77276</proc_id>
	<acronym>SIGGRAPH '89</acronym>
	<proc_desc>ACM SIGGRAPH 89 Panel Proceedings</proc_desc>
	<conference_number>1989</conference_number>
	<proc_class>conference</proc_class>
	<proc_title></proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn>0-89791-353-1</isbn>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>1989</copyright_year>
	<publication_date>07-01-1989</publication_date>
	<pages>336</pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<publisher>
		<publisher_id>PUB27</publisher_id>
		<publisher_code>ACMNY</publisher_code>
		<publisher_name>ACM</publisher_name>
		<publisher_address>2 Penn Plaza, Suite 701</publisher_address>
		<publisher_city>New York</publisher_city>
		<publisher_state>NY</publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>10121-0701</publisher_zip_code>
		<publisher_contact>Bernard Rous</publisher_contact>
		<publisher_phone>212 869-7440</publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url>www.acm.org/publications</publisher_url>
	</publisher>
	<sponsor_rec>
		<sponsor>
			<sponsor_id>SP476</sponsor_id>
			<sponsor_name>Computer Society</sponsor_name>
			<sponsor_abbr>IEEE-CS</sponsor_abbr>
		</sponsor>
		<sponsor>
			<sponsor_id>SP932</sponsor_id>
			<sponsor_name>ACM Special Interest Group on Computer Graphics and Interactive Techniques</sponsor_name>
			<sponsor_abbr>SIGGRAPH</sponsor_abbr>
		</sponsor>
	</sponsor_rec>
	<categories>
		<primary_category>
			<cat_node>I.3.0</cat_node>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
	<ccs2012>
		<concept>
			<concept_id>0.10010147.10010371</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
			<concept_significance>500</concept_significance>
		</concept>
	</ccs2012>
	<general_terms>
		<gt>Design</gt>
	</general_terms>
	<chair_editor>
		<ch_ed>
			<person_id>P245344</person_id>
			<author_profile_id><![CDATA[81339508101]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>1</seq_no>
			<first_name><![CDATA[Robert]]></first_name>
			<middle_name><![CDATA[L.]]></middle_name>
			<last_name><![CDATA[Judd]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[]]></affiliation>
			<role><![CDATA[Chairman]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
	</chair_editor>
	<ccc>
		<copyright_holder>
			<copyright_holder_name>ACM</copyright_holder_name>
			<copyright_holder_year>1989</copyright_holder_year>
		</copyright_holder>
	</ccc>
</proceeding_rec>
<content>
	<article_rec>
		<article_id>77278</article_id>
		<sort_key>7</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Virtual environments and interactivity: windows to the future]]></title>
		<page_from>7</page_from>
		<page_to>18</page_to>
		<doi_number>10.1145/77276.77278</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=77278</url>
		<abstract>
			<par><![CDATA[I really apologize. I promised everyone I would come out wearing the data suit, but it just slipped my mind and I never got around to it. Actually Marvin Minsky was saying that the thing to do would be to come out with nothing on because that would be the perfect interface to the computer. So I kind of shunned the whole thing off at that point.We just heard Nicholas Negroponte ask us -- "how do we communicate with computers?" Well, that's why this panel is here today. We'll be discussing virtual environments and interactivity with some of the people who have been doing a lot of work in this field. I was interviewing a lot of people last night at the parties about virtual environments and I realized that everyone has their own idea of what their virtual environment will be. Some want to interact more, others less. Some want little people running around on the screen bringing them all sorts of messages or images. We'll be hearing about a lot of different types of interactivity on our panel today.I'd like to point out that Margaret's slide should also include the MIT Media Lab as well as UNC.I'm going to show some tapes and do some talking later on so I'd like start of by introducing Jaron Lanier. He's the guy with the dreadlocks you've seen at the Silicon Graphics booth. He has an amazing collection of musical instruments from all over the world and when he plays them, he transports you to other times and other places. He's a designer of programming languages and he started VPL, the company that brought you the glove, Jaron.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P35873</person_id>
				<author_profile_id><![CDATA[81332494021]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Conn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Homer and Associates]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P124668</person_id>
				<author_profile_id><![CDATA[81100623833]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lanier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[VPL Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39075959</person_id>
				<author_profile_id><![CDATA[81336491376]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Minsky]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina / MIT Media Lab]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14191067</person_id>
				<author_profile_id><![CDATA[81100550071]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[S.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fisher]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NASA Ames Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P3425</person_id>
				<author_profile_id><![CDATA[81332496962]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Druin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tell Tale Technologies]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SIGGRAPH '89 PANEL. PROCEEDINGS Panel Sessio n Virtual Environments and Interactivity : Windows to the 
Futur e Chair : Coco Conn, Homer and Associates Speakers: Jaron Lanier, VPL Research Margaret Minsky, 
University of North Carolina / MIT Media La b Scott Fisher, NASA Ames Research Cente r Allison Druin, 
Tell Tale Technologie s I really apologize . I promised everyone I would come ou t wearing the data 
suit, but it just slipped my mind and I neve r got around to it . Actually Marvin Minsky was saying that 
th e thing to do would be to come out with nothing on because tha t would be the perfect interface to 
the computer. So I kind of shunned the whole thing off at that point . We just heard Nicholas Negroponte 
ask us -- "how do w e communicate with computers?" Well, that's why this panel i s here today. We'll 
be discussing virtual environments an d interactivity with some of the people who have been doing a lot 
of work in this field . I was interviewing a lot of people las t night at the parties about virtual environments 
and I realize d that everyone has their own idea of what their virtua l environment will be. Some want 
to interact more, others less . Some want little people running around on the screen bringin g them all 
sorts of messages or images . Well be hearing about a lot of different types of interactivity on our 
panel today . I'd like to point out that Margaret's slide should als o include the MIT Media Lab as well 
as UNC . I'm going to show some tapes and do some talking later o n so I'd like start of by introducing 
Jaron Lanier. He's the gu y with the dreadlocks you've seen at the Silicon Graphics booth . He has an 
amazing collection of musical instruments from al l over the world and when he plays them, he transports 
you t o other times and other places . He's a designer of programmin g languages and he started VPL, 
the company that brought yo u the glove, Jaron . Jaron Lanier VPL Researc h Okay, here's our video surprise. 
Video. Sound . VIDEO TAPE PLAYING WITH SINGING (Computer animation of a teapot and cup ) I'm a little 
teapot short and stout.; here is my handle; here is my spout . When you tip me over, tea comes out . 
So tip me over and pour me out . (Video of young girl wearing Data Gloves and Eye Phones ) I'm a little 
teapot, short and stout . here is m y handle, here is my spout . When you tip me over, te a comes out 
. So tip me over and pour me out . So that was Ellie Harvill, the daughter of Young and Ann , who both 
work at VPL, being a teapot for you . I can't see all of you. This is a very strange experience, its 
just to sea of black with two white tights . I'm going to talk a little bit about th e past, present 
and future of virtual reality . First, I assume we'r e talking to an audience here that knows about virtual 
reality, bu t just a very brief introduction for those of you who don't kno w about it . It's a simulation 
of a reality that can surround a perso n that's created with computerized clothing . It's rather like 
th e physical world in that it's an externally perceived reality tha t you perceive through your sense 
organs and the physical world . You perceive sensation on the outside of your eyes and you r ears and 
your skin, and what you do in a virtual world is you pu t on clothing that generates stimulation right 
on top of those sense organs . There is a special pair of eyeglasses called a hea d mounted display that 
you wear over your eyes and through th e head mounted display you see pictures that are three dimensional 
stereo pictures . When you move your head in on e direction the pictures move in the other direction 
t o compensate for your motion and it creates the illusion tha t you're moving around inside a space 
that's just out there an d stationary . Then there is the glove. You put on a glove and th e computer 
can measure your hand . You hold up your hand i n front of your face and you sec a hand . It lets you 
pick thing s up . Several people can be in this space at once and see each other with faces and so forth 
. So what you have is a creation o f a new level of reality . If you want to see these things, there 
is actually two o f them on the floor . There's one at Silicon Graphics' booth tha t we at VPL did, and 
another one at the Matrox booth, tha t Autodesk did . And you can try the Autodesk one out . There' s 
also another one that is slightly different but also relevant a t the Hewlett-Packard booth, done by 
a company calle d Simgraphics . So I recommend very much that you go to all o f those. I'd also like 
to -- just before I go further -- say that thi s is really the first panel about this stuff that there's 
been at a SIGGRAPI-I and it's corning kind of late because people hav e been working on it for a long 
time. So I wanted to, before anything else, acknowledge some of the pioneers . The work was started by 
Ivan Sutherland in the '60s, who I believe is at the Conference, and was continued by a few othe r people. 
Myron Krueger in particular is here and 1 believe in th e audience, and should be recognized . And also 
Fred Brooks and Michael McGreevey, who aren't here, among others . So now what we've clone now is created 
a virtual realit y that has two people and a time in it . So this means that you can go into the reality 
and see other people . The experience -- i f you haven't been in it -- is kind of like being in Toontown 
, from the Roger Rabbit movie . You're surrounded in this spac e that feels utterly real . Its a colored 
Gouraud shaded space right now. It feels kind of like being in a plastiform world . But the interesting 
thing is that there's other people and you hav e interreactions with them, and it really becomes like 
anothe r reality. It's a very interesting kind of reality. It's absolutely a s shared as the physical 
world . Some people say that, well, th e physical world isn't all that real . It's a consensus world 
. But the thing is, however real the physical world is -- which w e never can really know -- the virtual 
world is exactly as real, an d achieves the same status . But at the same time it also has thi s infinity 
of possibility that you don't have in the physical world: in the physical world, you can't suddenly turn 
this building into a tulip ; it's just impossible . But in the virtua l world you can . Then the other 
thing that's interesting is the virtual worl d is composed by people; it's an active human expression 
. And that combination, the three things -- the infinity of dreams, th e sharedness of the physical world, 
and the composability of art ­ -is an intersection that has just never existed before . I find this to 
be just an incredible experience and I can' t spend enough time inside it . It's a very hard thing to 
describ e to people, if you haven't experienced it, but there's an experience when you're dreaming of 
all possibilities bein g there -- that anything can happen, and it's just an open worl d where you're 
mind is the only limitation . But the problem i s that it's just you . You're all alone. And then when 
you wak e up, you give up all of that freedom, but you can meet othe r people within this limited world, 
and I think all of us suffered a terrible trauma that we've forgotten as children, where we had t o accept 
the fact that we discover we're physical beings and yet i n the physical world where we have to do things, 
we're ver y limited . The thing that I think is so exciting about virtual reality is that it gives us 
this freedom again. It gives us this sense o f being able to be who we are without limitation ; for our 
imagination to become objective and shared with other people . This will bring me right to the topic 
of the future . The present you can see today . Some of you saw the present in Scott's class on virtual 
environments and you can see some o f what we're doing at the Silicon Graphics booth . The thing s that 
are good about what we have today is we do have tw o people in an environment at once, so it's become 
shared . We do have a quality of environment going that's reasonable. We have tools for making environments 
where you don't have t o program to make them. All of those things are good. Now there's a great deal 
that needs to be done. We're really just starting . The first one I want to talk about is an area of 
software . I think the goal in virtual reality should be to be able to make u p virtual reality from 
inside it fast enough that you can do i t conversationally . The idea right now is that you'd sit down 
at a computer terminal with a mouse and a screen and you make up a virtual reality and then you go into 
it. And what we really want in the future is to be inside and to be able to pick up imaginar y tools 
and use them to create the reality while you're there . And especially what we want is tools that get 
good enough that yo u can do that fast enough to sort of talk with it . Now I want to explain this idea. 
It's a thing that I cal l post-symbolic communication. The idea is that in a virtua l reality you're 
directly making up the outside world that you share with other people . And this is an incredible thing 
an d actually it's a very deep thing, and it takes a while to get used t o the idea . Normally when we 
share ideas with other people we ' r e using symbols to communicate . We use words and pictures and so 
forth . But with the virtual reality, you can actually make th e environment -- you can make the shared 
world with the othe r person objectively there. And that's an amazing thing. We've really had some incredible 
experiences of doing strang e evocative worlds that really are just a new kind o f communication. It's 
really putting people inside your dreams , and something that's very hard to describe, because it's a 
mod e of communication ; I think that's really different tha n description . But the key to this thing 
working in the future is peopl e have to be able to improvise realities just like they improvise d speech. 
So that's I think the primary direction that research has to go is in the area of software that's eloquent 
enough t o use. It's sort of a user interface problem . And so that's what we're working on primarily 
and I think it's a long adventure . I think the realistic timeframe for something like that is decade 
s of work before it would really start to get good . But I think it will . The experience of having a 
lot of people in the world at once has been just incredible . The first time we did it in publi c we 
had people using the system who weren't technical ; they were people who we hired basically to demonstrate 
the system , and this was in San Francisco two months ago . And they started doing incredible things 
with each other. They started playing tag at a furious pace all over the place, and all kinds o f games. 
The tag game was amazing because one person figured out a killer strategy, which is to hide inside the 
other person' s head, and then the counter strategy to that turns out to be t o move like in this spiral 
through always checking if there' s someone inside your head . And then of course you mov e slowly, so 
you're sort of crippled . So it's this interestin g world . Another one was an executive from Silicon 
Graphics cam e up with this idea of sneaking up behind somebody and placin g their hand through their 
head and suddenly covering their eye s from the inside . The most amazing one was to watch two people 
flirting i n virtual reality who hadn't met in the physical world . One of those people might be in the 
audience, but I won't identify him . But he knows who he is . And that was interesting because the y 
were sort of like he -- the bodies that we made for these people were androgenesis . They could have 
been either sex . But jus t behaviorally the people became man and woman when the y enter the environment 
together, and he pinched her and sh e slapped him and this whole kind of thing . What 's really wild 
is later on in a crowd they recognize d each other from body movements, which just illustrates tha t 
the world of the body is something we don't pay that muc h attention to and it's actually very important 
and somethin g we're very aware of all the time. Another area is in tactile sensation -- just getting 
into hardware, where things have t o improve in the future . We've done a glove that lets you fee l things 
crudely -- internally at VPL and we're going to keep o n working in that area. But that's a key thing 
right now . There is an amazing effect where sometimes you think yo u feel things in virtual reality 
even though there isn't tactil e simulation there. There is an amazing phenomenon in virtua l reality 
where it sort of works better than it should because you r brain wants your reality to look good . It's 
a really high priority for your brain to believe in your reality . So there are many sorts of illusions 
that come into play to cover up littl e gaps in our simulation . It's almost like we're getting a free 
rid e sometimes because we're asking the nervous system just to do SIGGRAPH '89 PANEL PROCEEDING S exactly 
what it was evolved to do, which is to make reality fo r you . But sometimes say if you slam you hand 
down on a n imaginary table and especially if you have a shado w converging with it and you have a little 
thunk at the time yo u hit the table, you really kind of feel it . But that's about th e level it is 
right now and eventually we need to solve thi s problem . It's a very difficult problem because all of 
the device s that have been done with forced feedback are sort of ver y special purpose . They provide 
a particular type of forced feedback . And Margaret will be showing quite a few of those . You really 
want is to have freedom of movement in rea l generality to be able to move around an environment and 
fee l whatever you want there . I can tell you some of the crazy ideas, but I hope somebod y in this 
audience will make a career of figuring out how to d o this right . One would be that you have these 
very fast robots that rush around and suddenly place, like a tabletop, under you r hand as it's coming 
down . And then remove it just as quickly . Or little thrusters mounted all over your body to put forces 
on you . There's all kinds of things, but nothing has worked yet . Another one that's very important 
is sensing the huma n body better. The head mounted display we make, which i s called the eye phone, 
is going to have facial expressio n sensors so that when you're in the virtual world you can smile at 
other people and make eye contact and all that, which is ver y important . But that needs to evolve a 
lot . For instance, you need to be able to measure the tongue because you watch the tongue a lot when 
other people ar e talking and there's no way to measure that noninvasively that I have found and so forth 
. That's another good problem . Then the other big one, which is probably going to b e solved anyway, 
but really needs work, is just rendering . There's still no graphics machine in the world that's goo 
d enough to make a reality in real time that is normal -- a norma l reality. So those are important areas 
. We're going to mention a few things about application s that -- this is a morning after a SIGGRAPH 
night. I'm sure yo u all know what I mean. Actually, I'll tell you what. I'm stalle d for a second and 
I'll just admit it and go on on some mor e videotapes, so you can see some of our worlds . And then I'l 
l come back as a brilliant speaker . Here's a little selection of some of our worlds, just so yo u can 
see what some of them look like. The first one is a ride that you get on . You sort of step o n a conveyor 
belt and it starts with this virtual reality archway . And you proceed through --- that's another person. 
--- This is more of it. ---This is Alice in Wonderland's Mad Hatter's Te a Party. Actually, -- if you 
come right at the end of the day, yo u can try this out perhaps if there's not too many people . You 
can go in and be either Alice or the Mad Hatter . ---That's a glove just sitting on a desk when we were 
filming this . Somebody wasn't wear it . So it's just kind of resting there.--­That's the Mad Hatter. 
There's the Door Mouse . This is an experiment in moving around a very large color ­coded grid to try 
to be able to find a large number of objects like in a data base, and you can sort of fly around it . 
It's quit e large. The experiment is to see how large a space you can get to know.--- This is sort of 
a strange ball game that we just did the othe r night. ---This is a thing called ritual world which is 
an exoti c world I just made up one night when there were some peopl e over. ---I don't know what to 
say about it. It has a lot of strange things in it, like places, like secret places you can put your 
head when you enter a different kind of world and all that kind of stuff. That's called the Oriental 
carpet because it keeps on reorienting . This is a day care center -- a model we did for architects , 
where the idea is that you'd have two architects who enter a world and design a day care center. The 
interesting thing about this world was that with a gesture you could change yoursel f from an adult to 
a child . Then you could experience the day car e center from a child's perspective. Here -- we're seeing 
if a chil d can reach the light switch or not. This is the switch that controls the fan. As you can see, 
there's another person down there looking up and watching . So it's just another being ther e in the 
world . So I'm going to stop now . I thought I'd say a little bit about some of the othe r feelings we've 
had working with virtual reality. One of the things that's really interesting about it is the sensation 
of wha t virtual objects start to feel like . I've spent many, many hours in it now, and there's some 
other people around the VPL wh o have spent more hours, and there's some of us who have reall y gotten 
to know it pretty well and there's an interesting thin g that happens . One thing is that it changes 
the way you perceive the physical world pretty profoundly I think . Part o f that is you come out of 
it with an increased sensitivity , especially to your own nervous system . You start to notice i t while 
it's running . Once you're inside virtual reality and yo u see your own visual system sort of create 
a reality for you that feels real out of what's basically a very crude technology, yo u really start 
to walk around and notice -- well, God, what's reall y going on here -- and you become aware how much 
you're reall y creating your everyday world out of fragmentary information . Another thing that's really 
interesting is when you leav e it, sometimes there's this real interesting after image thin g where both 
worlds are present at the same time -- a ver y amazing sensation . But after you've done it awhile you 
don' t notice it anymore and it sort of goes away . But for those of yo u who are trying it for the first 
time -- and pay attention to that -­that's a really interesting one . There's a very interesting thing 
psychologically abou t virtual objects . Since they're all easy to make and sort of al l just part of 
a simulation, you start to not treat them as preciou s as you would real objects, kind of, and there's 
a real interestin g thing happens where people are sort of forced to becom e creative. I've seen that 
again and again. Let me try to explain that idea . In the physical world a lot of what you notice is 
based o n sort of the novelty or quantity of some object. For instance, a very large building is very 
noticeable . But in the virtual worl d that's meaningless because all it means is you set a particular 
number to tall on a building grid. So the only things tha t really stand out are creative things -- creativities 
like mone y and virtual reality. It's the only thing in short supply. I think it just naturally sets 
up this economy that brings people out . That's I guess the thing that's most exciting to me about it 
. We're so used to media kind of making us duller in a way -­particularly television . And when people 
use virtual reality , they just come awake. It's like an incredibly stimulating and empowering thing 
. And I think ultimately that's its meaning . I think it's a tool for sharing and creativity and I hope 
you al can experience it soon . Why don't I take a few questions or should we save thos e for later ? 
CONN : We'll save them for the end . LANIER : I think what I'll do is I'll sign off for now and I lik 
e answering questions ; it always gets me going . So maybe if you have any good ones and you'll hear 
a lot of good stuff. We have some buttons too, if you want some, on virtual reality . So thank you so 
much for coming .  Moderato r Coco Con n Homer and Associate s This is a pretty sophisticated graphics 
audience, and whe n you see those graphics you're thinking yes, they're okay, but -­and I think what 
you have to realize -- wait, OK I'll do one o f these things. How many people have ever put on the helmet 
and the glove and been in a virtual environment? Anybody ? Some. What you really have to do is go on 
the floor and tel l Eric at Auto Desk we sent you and get on their system . Wha t you need to realize 
is that you're interacting with thi s environment and you'll forgive all these graphic/visual thing s 
that as an audience watching the screen you start thinking about the quality of the graphics, and that's 
not what you're thinking about when you're in the environment . You -- like Jaron was saying -- you get 
into a whole other head space . Ron Reisman said, "If you're doing this panel ; I want yo u to see what 
real men do on flight simulators." We went to NASA Ames and I got on a CAE Link flight simulator. It 
wa s like really intense . $I5 million of computer graphics and $1 0 million of hardware. You're sitting 
in $25 million of really elegant computer graphics flight simulation . You're thinkin g this is really 
going to be it and yes, it's kind of cool, but th e only thing you really feel like doing is bombing 
villages --I mean, you know -- I'm sorry . I just hope that this crowd ca n take it into a whole other 
space . We need feedback. We need to be able to feel those things that we're touching and interacting 
with . Margaret Minsky , who is a doctoral student at the MIT Media Lab, just spent th e last year as 
a research scientist at the University of Nort h Carolina in Chapel Hill -- in the Graphics Lab . She's 
got a lo t of wonderful and interesting things to show us about force ­feedback . She'll tell us about 
her work and that of others acros s the country . So here she is . Thank you .  Margaret Minsk y University 
of North Carolina at Chapel Hil l MIT Media La b Thanks. Virtual worlds harness sensory immersio n somehow 
. And the best ones give an illusion of very grea t freedom. Actually they don't really give you that 
kind o f freedom to explore, but it seems like they do. Sometimes the y strongly guide you to what to 
do . I'm going to show you some examples of fairly artfull y constrained worlds, which illustrate where 
virtual worlds have gotten in some of the research that I have participated in . These examples come 
from -- actually, can I have the first slide . The examples come from University of North Carolina a 
t Chapel Hill and from MIT and from Atari . Some of the things I'm going to show you come close t o creating 
a complete environment for doing a particular thing . Some of them are kind of tool kits, pieces of research 
into ho w to provide the environments that you can build . So some o f them will seem really directed 
and some of them will see m really like parts and pieces to be put together. In some sense they are kits 
for exploring the physical and computationa l technologies behind creating a virtual world , Every one 
of the things I'm going to show you choose a very, very constrained and abstracted world and try to make 
i t seem real . Next slide . I'm going to show you five -- as you can see -- pieces o f work and three 
of them are particularly exciting to me becaus e they do use our sense of touch to come alive . Force 
display , which means displaying mechanical forces to the parts of you r system that can understand them 
-- pushing on you and all th e things that are tactile and kinesthetic -- is new and people hav e made 
some elaborate and baroque devices to give you force display . I'm continuing in that tradition -- working 
wit h elaborate and baroque devices that do limited things in tha t domain . But they 're very, very 
exciting -- even the ones tha t exist now . It's very visceral, it's very convincing to touch things 
. And it's about the hardest thing you can imagine to show o n videotape. We'll try . This is from University 
of North Carolina and you may have - those of you that have seen the film show, it's a n architectural 
walk-through simulation . It was actually used i n the architectural simulation of the new computer science 
building at University of North Carolina Chapel Hill to fin d flaws in the architectural design and fix 
them, and the architec t was convinced to fix them only because of walking through th e simulation . 
VIDEO TAPE PLAYING (NOT TRANSCRIBED ) (SPEAKER TALKING OVER TAPE ) Needless to say, this is computed 
on the Pixel Planes IV a t the University of North Carolina and it's an animation and at the end of the 
tape you'll see the real time version . It's abou t the only thing we'll show that's slower than real 
time because i t really nicely represents what's going to be there in about a year, There is the wall 
I believe that got bowed out because th e architect was finally convinced by -- only by walking throug 
h this that it was too cramped if it was flat . And it's a very soun d real example of somebody convinced 
with graphics only, bu t with sort of a body interface -- walking through on tha t treadmill -- that 
they were in a real building and that we wer e going to have to live with it . You kind of take for granted 
though that you can modif y the worlds that you're in and when you can't, what does it fee l like, what 
you do with the rest of you that wants to do that? The next piece is from MIT Media Lab and it's a tool 
kit o f constrained objects which can be interacted with and modifie d physically -- sound up . VIDEO 
TAPE PLAYING AGAIN There are a few points to make, having seen that, and on e is that by virtue of the 
reality not being good enough or b y virtue of it being good enough -- I'm not sure which -- the user 
s were obligated to add sound. And sound is very, very important . You can see that it's so important 
that you just hav e to hum along if you don't get it from the world itself . In that world there's a 
suggestion of an ambient physica l activity -- things walking around . You're free to shift you r point 
of view, you're free to change what the objects are doing , where they are, how they're connected . But 
there's thi s cockroach crawling around, which has a life of its own . I thin k  SIGGRAPH '89 PANEL 
PROCEEDING S its a suggestion of the kind of live agents that you're going t o find in virtual worlds 
. Hopefully the agents in the future wil l interact with a more directed way so that they can try to 
get yo u to do what they want and you can try to get them to do what yo u want, but they may be no more 
lively than a cockroach . But they will be smarter. The next thing I'm going to show is a very specific 
kind o f scaling . We are going to feel the bond forces betwee n molecules and this is work at the University 
of North Carolin a enabling molecular biologists to create drugs by figuring ou t how to make the best 
drug for the situation, by how to bond i t to whatever active site it's going to work on, and the way 
the y do that -- and it seems like it's about the fastest way -- is to feel the obstructing bond forces 
and tweak the molecule until yo u don't feel the obstacles anymore. I'll show you that. Sound up , please 
-- higher than it was before . -- VIDEO TAPE BEING PLAYED These folks really make cancer drugs with this 
. You twis t them and measure if they fit, and it's just plain faster and nice r than any kind of nonhuman, 
nonexploratory world . I've been looking and I've been inspired by the work at Chapel Hill for a long 
time in using a force display to let you know what's going on and to explore the world, and I started 
looking at what's th e best thing that touch can do for you? And at the moment I think the best thing 
that touch can do for you is let you fee l textures and continuous media and jello and softness and fur 
an d things like that. Basic shapes and forms are pretty well taken care of by the rest of the things 
we can build . For instance , computer graphics . So I'll show you what I do to create textures . Sound 
. -- VIDEO TAPE BELNG PLAYED If you thought that was good, the next one kind of puts i t all together. 
The next thing is about the most successful al l around virtual world that I've seen in a long time . 
It engage s you, it teaches you, it directs what you're doing, it uses sound , it uses force feedback, 
and -- well, without further ado . VIDEO TAPE BEING PLAYED (Hard Drivin -video game from Atari) (NOT 
TRANSCRIBED ) That was made after many, many years of hard wor k convincing their company and the rest 
of the world by a five ­person advanced development team at Atari Games . You noticed the dreamlike point 
of view shift at the end, I take it. Point of view is important in the MIT work. You could shift your 
point of view at will . In this one the world tells yo u well, you're dead, you better see it from the 
third person . It's a little bit smart . I wanted to thank also Atari for letting inc show that and I 
want to thank Pacific Interface for the treadmill footage at the beginning . (Pacific Interface does 
the visualization state of th e art series for SIGGRAPH Video Review .) And my colleagues at North Carolina 
and MIT as well, for being able to show thei r work . What do you learn? Some things are pretty good 
. Som e things are great . What's missing? For me what's missing i s ambient behavior. What makes the 
world real? What's going on out there when you're not affecting it? And really smar t agencies in there 
that are a part of the world, just like we have very smart agents always communicating with us in the 
rea l world. And for lack of a better term I think what 's missing is a kind of aggression on the part 
of the system in the sense that i f you're trying to get something done, then you want it to hel p in 
a very serious directed way . It occasionally might kno w more about it than you, and it certainly might 
be able to pu t you, so to speak, on the right track . So the flip side of agent s that you can, as Negroponte 
said this morning, that you can us e as agents of delegation, are agents that really seamlessly guid 
e you, and our virtual worlds need all of those three things to b e helpful and to be real and to be 
expressive media . So, thanks for the opportunity to show work that I'm ver y proud that people are doing 
now . Moderato r Coco Con n Homer and Associate s At the Vivarium office in Los Angeles, I was playing 
wit h a bird wing that Paul McCreedy built . He built it for Alan Kay's Vivarium project at the Open 
Magnet School in Los Angeles . It's this big mechanical arm that you can grab onto it . It feels similar 
to when your arm is sticking out the window of your ca r while you're going sixty miles per hour . I 
thought what a great way to understand how birds fly . In the future you'll be able to build all these 
neat interactive learning tools for kids . So talking about education, I'd like to introduce Allison 
Druin who has been creating computer environments fo r children since her Master work at the Media Lab 
. She'll b e talking about education and interactivity . Here she is . Allison Drui n Tell Tale Technologie 
s Could I have the slides? I want the lights down so you ca n see this beautiful computer graphic image 
. Somewhere over the rainbow, in a never never land, bac k behind the house at pooh corner, where I know 
the wild thing s are, I found a place called childhood . Where you could eat gree n eggs and ham, a place 
where you could meet Big Bird, a plac e where apples are still fruit, and a place where a mouse is stil 
l called "Mickey ." This is not a world where adults roam freely , this is a world where fantasy can 
be a reality, and wher e learning can be playful . That 's why when I set out to bring computers to this 
worl d of childhood, I was not about to tell kids, "Hey, throw awa y those stuffed animals, who needs 
picture books, take off thos e play clothes, I got something better for you! A hard plasti c box, keyboard 
and mouse, you will love it . We will put nic e bright colors on it and apples and Zebras . And for a 
real treat we will let you answer yes and no questions or even fill in th e blanks . " I won't names 
but, this is not the stuff that virtua l environments are made of, especially for kids . And certainl 
y the approach I have chosen to take is quite different . Becaus e you see, I believe that children should 
meet computers on thei r own turf, in their own world and in their own way . I got my chance to do this 
beginning in 1986 while I was a graduate student of Marvin Minsky and Allen Kay's at a Lab . many of 
you may be familiar with, the MIT Media Lab . And a s you well know by now, it is not your typical researc 
h environment . It was there that blimps were made into fish, an d legos into robots . It was there that 
I was a part of the Vivariu m research group supported by Apple Computer . And back the n we were a 
collection of people, ideas, and projects which al l focused on creating a multi-media environment for 
kids to learn about animal behavior . For my particular project, I wanted to combine thos e things that 
made being a child special . So, together with a number of people that shared by same crazy vision, we 
used th e tools of puppetry, animation and computer electronics to buil d what we got was Nuby. Nuby 
was a five foot computer creatur e who's parts could be squeezed to build cartoon animals on th e screen 
and in his stomach . Since then a number of us from the project have gone to form a company called Tell 
Tale Technologies . We wanted to continue to create alternative ways of bringing computers int o a child's 
environment. Needless to say, our methods are a bit unorthodox . One project we are working on now is 
a lap-top Nuby that plugs into the computer to give small children access to a computer adventure by 
way of a stuffed friend . Recently, Tell Tale Technologies had the pleasure o f working with a number 
of student interns from Rhode Islan d School of Design . Yes, artists can develop computers . Together 
we took the technology we had been developing an d brought it to other parts of a child's world . Here 
you see Kristina Castello and Larry Trimm workin g on nothing less than a stuffed globe . Again we took 
away the keyboard and mouse in favor of something that a child alread y knows . It says it graphically 
and in two minutes a child ca n probably figure out what is can do . What do you do with a globe? Well 
of course you g o places. A child presses a place on it and he is brought there b y way of sounds, pictures 
and voices . And here of course he ha s gone off to L.A. He can press it again, and find his way t o 
London . Another element from a child's world that we thought mos t computers could not do without was 
a book . Again i t transforms the computer environment into a place the child already knows. Here, Mark 
Seal our chief book designer join s our little boy in turning pages, pointing out pictures an d picking 
out words . But with this computer book, by turnin g pages, pages on the screen turn and by pointing 
out pictures , words or graphics animate on the screen . But what we came to realize is that any computer 
company that is focused on the future, that is worth calling themselves visionaries is really incomplete 
until you make compute r clothing. And of course the people that wear our compute r clothing, they need 
a little help getting dressed . So here you see Dave Spargrove, our programmer for this project, helping 
our computer user into his input device. And wa la! Not only has he made this years best dressed list 
but, he can press any o f the patches on his clothing to change the clothing of th e computer character 
on the screen . Doesn't he look like him , huh? And so when he presses his pants, his shirt or his hat 
, things pop on the screen . Of course really the best way to see any interactive environment is interactively 
but, for now I've got a film tap e clip, . VIDEO TAPE BEING PLAYED Alright, so as you can see, we have 
tried to give the kid s the opportunity to still be kids and yet explore variou s environments in ways 
they have already discovered from th e physical world around them . But something we have begun to consider 
is that many children are confined to this physical environment . Their reality is defined by a wheel 
chair. Sometimes a body strap and even a head pointer for communication . And there are so many physically 
challenged children that not only want but nee d alternative environments to support their creativity 
so they can develop their self reliance and so they can enhance thei r learning environments . So Tell 
Tale Technologies has joined forces with th e Massachusetts Hospital school access world to adapt it 
s technology to their community of children . And the hospital school is a home, school and hospital 
to 150 students wit h physical disabilities ranging from cerebral Palsy to muscula r dystrophy to spinal 
cord injuries . And here is a place where computer users have lon g accepted that mice and keyboards 
are probably not the bes t solution for them . A lot of these kids do not have the luxury o f being able 
to move their heads freely, or being able to mov e their hands without help . So, unfortunately all the 
fanc y graphics in the world, at all the high speeds their are, are no t going to do these kids much 
good unless they can see a scree n or can access information . And so virtual environments are important 
. Some work has begun to be done adapting software an d some work has been done to improve hardware . 
But, fe w people have considered the whole . So it can be a full and ric h environment instead of piece-meal 
adaptations . Therefore, w e have begun on a project to build an adaptive multi-medi a environment that 
would give these physically handicappe d children the educational tools they need, in a way they can 
us e them creatively . We see this is a way of bringing back those stuffe d animals, picture hooks and 
play clothes to physicall y challenge children who for some haven't been able to turn a page in a book 
without help . And for others who haven't ever been able to reach out and grab a stuffed animal without 
help . As for now, obviously fund raising efforts are alway s ongoing, but, what we have begun to focus 
on is what are ou r goals in creating virtual environments . For children in and out of wheel chairs 
and basically, it is to create environments tha t don't just replace what's been there. The past is great, 
but let' s go beyond the past and let's let kids go to places they hav e never been before and let's 
let them do things they have neve r done before . As so maybe, they can go somewhere over th e rainbow 
to a never-never land and, perhaps they can find a ver y special place called childhood .  Moderato 
r Coco Con n  Homer and Associate s That was great . Um, I am going to quickly show som e more tapes 
. There will be three pieces on here . The first piece is a to visit with Brenda Laurel who was at the 
Atari Lab. She has been thinking a lot about inter-activity and she is coming out with her book this 
summer titled Future Interaction . Published b y Addison Wesley . I want to show the work that Dan Venolia 
is doin g currently at the Advanced Technology Group at Appl e Computers. He has been working with 3-D 
interactive technique and he'll show you something that he's bee n building .   A . The LCD is a passive 
element . I think the only issue would be the back light . It is the only thing that would mak e energy 
. A . Maybe if people would have Miso soup for breakfas t instead of coffee their health would be a 
little better.  A . The only health effect I guess we have noticed is eye strai n from trying to stay 
in there too long . Q. I got one that is a little bit related. Somebody told me the other day that some 
people experience nausea and, n o seriously, physical discomfort. It is interesting, like Steward Brand, 
whenever he talks about the stuff the first thing i s "Virtual reality sickness!" It is a mild kind of 
problem . I think we are getting close to where the technology will be goo d enough that that will be 
very rare . Once in a while you feel a little bit off. But, it is really not a practical problem. I mean 
i f you don't spend all day in these things really .  I have a couple responses to that . I mentioned 
yesterda y in the tutorial that one of the strange things we have noticed i s that when we first started 
this, like 4 or 5 years ago, we ha d some of the first data bases up. Granted very sparse fairl y simple 
stuff. Higher incidence of people reporting vertigo , some kind of dizziness . But, still a fairly small 
percentage . We found that as soon as we put the hand in there, that you ha d some sense of yourself 
in there rather than this disembodie d viewpoint . The complaints went down quite a bit . Another issue 
has to do with, actually we are kind o f interested in this because we do a lot of work on sym sicknes 
s and motion sickness . So, to have a facility that can induce tha t fairly easily is not bad actually 
! There are some strange things in terms of sym sicknes s that frame rates are quite critical in fact. 
It might be a fact that too high of frame rate will generate more vertigo . That is something, I didn't 
really go into detail on some other thing s we are trying to do . We have tried to make this a researc 
h facility so that we can sort of get the bugs out of the system . That is a very important one for us 
. The stuff you saw on th e tape range from like 6 hertz to 12 hertz . Even though ou r system is specked 
to do 30 hertz . There is some, well yo u know about hardware problems . Hopefully by the end of th e 
summer we will be up to 25-30 hertz for at least a couple of the demos we do . A lot of the research 
in simulator shows that to o high a resolution and too high a frame rate and too goo d response rate 
on the simulators may in fact be bad and ma y induce some of the sickness . Q. I have a question or comment, 
everybody is talking abou t force and tactile response and the two things I thought abou t were magnetism, 
which would create a pull if there were som e way to use magnetism for pulling. For pushing I was thinkin 
g of wind. Also of since I am scuba diver, I was thinking of another environment that would be a gelatin 
that would perhap s that when you impact it suddenly it would be crystalized . But, if you impacted it 
slowly it would be more flexible and if yo u impact it completely passively it is penetrable . Those 
are m y suggestions . A . Great Idea! We want more ideas . We get in enough troubl e though doing this 
stuff with US tax dollars . Actually the magnetism, talk to Marvin Minsky about that, he has bee n suggesting 
that for years . The trouble is that we use a magneti c tracker . So that does not quite go together 
. Q . Ted Nelson, Auto Desk Project Xanadu, it is very difficul t with the one second audio lag .  
About 30 years ago someone made a terrible misnomer . Deciding to refer to virtual immense memory as 
virtua l memory . I think we are on the verge of another misnomer here . . Cyber space is very good 
because we have feed back in cybe r space therefore the term cyber is uniquely appropriate . Virtua l 
reality is nice because you are simulating reality . But virtual environment makes no sense because, 
all compute r environments are virtual . So there ! A . That is the shortest I have ever heard Ted speak 
. A . Of all people he should know that words make no sense ! We need new vocabulary . We need a vocabulary 
committee a t this point because what words are we going to use for all ne w imagery and technology ? 
 Q. Are there virtuosos skills for virtual reality users that ar e different from virtuosos skills for 
people in real reality ? A . Not for public discussion ! Q . My question is dealing with your focus 
of all the let us sa y the peripherals? I don't know, what would call these? Th e gloves as far as going 
into this virtual reality? Do you se e possibly the body glove being part of such a virtual reality? 
Do you see possibly shoes or toes or another external part s becoming a part of this reality? Would they 
be of any use? A . We have a whole body and originally Coco was going t o wear it during the panel, 
but we lost our nerve . The thing i s that you have to have some kind of trade off betwee n convenience 
and what you want to do . It seems like kind o f putting on gloves and glasses is a pretty neat thing 
. It is ver y convenient and you get a lot from that because your hands ar e your main output device 
in your body . So, it gets you a lot . So putting a suit on is just a lot more work . A . But, still 
the ultimate interface is like maybe like n o interface. We are just trying to feel our senses and feel 
ou r sensors and somehow learn to communicate with that machine .  I think that is what all of these 
peripherals are all about . I don't think this happening because they want gloves and hats an d shoes. 
I think it is just because it is just the starting point o f how to start learning to communicate . It 
is hard to make any particular interface . Especially if it is mechanical. Which a lot of these things 
are now . When I was first experimenting with textures, I of course foolin g people into thinking that 
they working on a flat surface or a surface at all . Lot's of people had trouble with your hand as i 
t moves on a joy stick , the throw has a bit of a curve to it . Doing the naive thing. Lot's of people 
can detect that and i t ruins the illusion of the flat surface with lots of things on it . So I ask people 
to put the joy stick on the floor and put the sol e of their foot on it and feel things with their feet 
. I had no idea whether I could do science with that but, it flattened the surface out for everybody 
. Now, it is worth, things are different . Different parts of the body. It is worth experimenting. But 
every kind of tool that you use in the real world is different . It is specific for grip . It is specific 
for the part of the body and w e are going to learn how to build all of those things . Each on e takes 
work . Q . I have a second part to the question . It is more in reference to Pacific Data Images' Waldo 
project . They were focusin g more on kind of a puppet. Would one need so many digits as far as dealing 
with the glove? Couldn 't one just deal with more like just something more limiting as just a puppet 
as actually a pointer and it kind of grasps and touches . A . It really depends on what you want to 
do, and we're just a t the beginning of this . I think we'll see a lot of differen t configurations . 
The main reason to use a glove is if you want a lot of generality because you can always make sort of 
a virtua puppet thing inside the virtual reality if you want to have fewe r degrees of freedom . So the 
glove's a good general purpos e  device since it captures most of your hand. But it really depends 
on what you want to do . On the other hand, with like a Waldo type device, a mechanical device, you can 
put in force feedback much mor e easily than with a glove . A . It's also important though to notice 
-- I'm for exampl e experimenting with something that's a lot like a tool with a certain grip on it -- 
which may not be appropriate for the kind s of things I'm trying to create, and Susan Liederman at Queen 
s University has experimented with how people figure out wha t an object is, and they have motions that 
they make with thei r hands that let you figure out what's there, and if you don't hav e the freedom 
to explore with your hand, you really can't do it , and if you have freedom to explore with your hand, 
you really can do it -- by touch alone, and figure out what objects are . Therefore, you've got to allow 
the exploratory motions tha t you're hands and the rest of your body really want to make . There's also 
a whole set of -- I mean there's a whol e language to the arts of puppetry, of body language and so o 
n and so forth, and sometimes when you do mimic what's sort o f been there before, it does help people 
go beyond things , instead of having to make up a new language . So we're experimenting with -- we've 
been talking to Jaron about mining some of what we do with what they're doing . Q . Have any of you looked 
into the field of hypnosis as i t relates to all this? I'm thinking specifically of what happene d with 
Gordon Pask in his early work with music color, where h e recounts one night having a professional musician 
jammin g with the system for like eight, 10 hours, and afterwards h e thought he'd only been playing 
for an hour . The other was the hypnotherapist, Milton Erickson' s work, where he was actually able to 
induce nausea in a hypnoti c subject, just by moving his own body around so that where th e sound was 
coming from was changing . He actually got peopl e throwing up this way . Q . Why (INAUDIBLE) want to 
make people sick ? A . Kind of. I mean, certainly the kinds of capabilities yo u have to change the 
physics of the environments, the realitie s in the environments, is something that both VPL -- I guess, 
I think probably all of us are playing with . One of the mos t interesting calls we've gotten -- actually, 
well, we get a lot -­was from someone who was interested in using the system for  coma arousal . I guess 
that's somewhat related -- people wh o needed some kind of constant stimulation. So maybe that's a little 
bit of an inverse . But you certainly do get -- you get los t in there . So for us it tends to be a sign 
of success when peopl e don't pop out right away . I mean, it's hard to get any work done, but -- A . 
I think of the virtual reality as a very active thing wher e you're making up reality and stuff, not 
as something where yo u do things to people. But it is a very hypnotic experience and I think it illustrates 
how much everyday life is hypnosis too -­you know, how much our experience is made out of our sensor 
y system and stuff . Q. I would like to ask the panel whether they have experience with mixing real reality 
with the simulated reality? Fo r example, translucent (INAUDIBLE) cities . We saw something like in the 
last -- Scott Fisher's tape -- where we saw the --I think it was made with a camera or two cameras actually 
, interlacing the pictures or something like that. But you coul d put objects that are simulated on real 
things, on real tables, an d people could stand around. You could see each other. Have you any experience 
with that? SIGGRAPH '89 PANEL PROCEEDING S A. For now, we're only doing the enclosed version . Ivan 
Sutherland's work in the late '60s was a see-through display . It was a beam splitter and two CRTs mounted 
on the head an d really an incredible piece of work that he did at the time t o superimpose those graphics 
into the real world and the n interact with them . To my mind though it's a much, muc h harder problem 
than the kind -- well, it has different hardness t o it than the kinds of things we're doing, in the 
sense that ther e you're trying to map these things into the real world in dealin g with calibration 
. I mentioned yesterday some work we tried to do at Atari with building or proposing -- and we didn't 
get to th e point of building it . Let's say a video game based on that , where you'd have these creatures 
kind of popping out fro m behind your couch . Knowing where the couch is and doing th e clipping for 
this creature as he pops out is not a trivial thing . The Air Force -- Wright Patterson is doing a thing 
called Super Cockpit, which is a helmet for pilots flying in zer o visibility, where they're trying to 
overlay terrain maps ont o the real world . Now again, I don't know if I would fly that plan e right 
now. I mean, that's a very hard problem . Q . It seems to me that we're at a great place now to get into 
using like, for example, the glove in this virtual environmen t to create your own environment -- like 
each person can get i n and create their own environment with a glove, just by, fo r example, forming 
their own 3-D figures by some sort o f software technique developed to do that . So you could create 
-­each person could go in and create his own environment an d deal with that. But the other thing associated 
with that woul d be, for example, in that thing where there's an architecture o r the architect 's walking 
through his own building, right, and h e sees he has to move this wall out of the way a little bit, it 
woul d be nice, the application, to be able to be walking through tha t and actually take the glove and 
say well, I want to move thi s wall a little bit to the left here . It comes open and then he say s yes, 
well, now I've got to move it just a little bit back and i t moves right in to the place where he sees 
it in thi s environment and says yes, that's what I want . Then out com e the floor plans that get that 
corrected . A . That's already happening . That actually works now . Q . Oh, it does ? A . Yes . We 
have some worlds that are like that, and I thin k Autodesk -- I'm not sure if you can pick up a world 
inside, but i f you can't yet, I'm sure they'll do it soon . And I think Scott has some of those too 
. A . Yes, actually, when Warren Robinette worked with us a  couple of years ago, he had done some 
interesting work in a virtual environment object editor, so you kind of have thi s library of primitives 
and kind of build things . But he also di d an interesting thing with a kind of Metaworld -- Met objec 
t editor -- so that you could actually pop out a little bit and the n see this graphic, this hierarchy, 
the tree of the graphi c structure, and literally grab those objects and plug them int o different parts 
of the three, and then sort of pop back in and se e those changes, which is kind of a really nice idea 
. Q . Is anyone working on olfactory stimulation, because i t strikes me if you want to create in virtual 
realities for people t o wander around in, you've got to do more than just stimulat e them visually and 
orally . A . We've done a little bit of it. The hard part seems to be not getting smells out near somebody's 
nose, but more clearin g them away quickly . But I mean it's very early. There's so muc h  to do. I'd 
say that's like number 20 on the list of things from our point of view, but it's definitely something 
to do . A . There actually is a company in France, of course, doing a thing they called Odorama, and 
its a video-disk based system in a little glass booth that you interact with the disk and i t happens 
to be about perfumes and things and you punch u p different things and it blows this stuff in your face 
and the n sucks it out really quick . So I think doing it -- I guess we coul d do it in the astronaut 
helmet . I guess that would be a nic e environment . A . Because if you -- what happens a lot of times 
where we d o it is there's like two people sitting only a few feet from eac h other in the physical world, 
but in the virtual world they migh t or might not be in the same room, and since smells carry, yo u 
have this problem . A . There's a common sense thing too that I think its one o f the few sensory things 
you can feel comfortable havin g common sense about, that smell is very, very closely couple d to memories 
and very complicated things happen when yo u smell a smell . So you can't do as much predictable stuff 
with i t as you can with everything else, like touch and sound, and eve n music and visuals. But I was 
talking at one time to dentist s about using force feedback things that I'm doing to teach denta l students 
how to extract teeth, because they need to learn -- I'l l stop. It's clear what's going on. I was talking 
to a dentist and said well, how do you really do this stuff . He said you sort of feel the thing, but 
after all, you're using a funny shaped too l and it's pretty bad feedback, and mostly you smell it . 
You smell what you're drilling through . Sorry. So that wa s predictable and I said yes, when you're 
getting aerosols like you're getting all kinds of health problems too, I mean, he wa s quite taken aback, 
having not thought of that, and that's a plac e where you could do something practical, I guess . But 
you hav e to find really specific situations where the memories don't tak e over . A. I guess one other 
thing about smell is that there 's no spectrum for smell or some sort of abstraction that you coul d 
use for making up new smells or something like that. Yet, it' s not really that well understood. It's 
like a catalog of different molecules . So it would be more like just selecting from a smellavision set 
of things. So it has a long ways to go . We have time for two more quick questions . Q . Mr. Lanier, 
if I may just briefly -- the name of you r company is Virtual Programming Languages . Have you don e 
any work towards using these 3-D virtual environment tools o r actual software development ? A. Yes. 
Actually, that's something I really want to do. We've done just the little bit so far, but that's very 
much the directio n we're going. Yes. Q . Since this work actually started back in the '60s with Ivan 
Sutherland's work and with the grope system at North Carolina , I think it might reflect on what happened 
for the next 20 som e years, and why it happened . I can relate ; it's sort like a . . ., I think it 
might reflect on what happened for the next 20 som e years, and why it happened . I can relate ; it's 
sort of amusing t o think -- I took some ideas to -- similar related ideas anyway -­to all the research 
establishments in '74, and after doing fiv e years of stuff, and DARPA's reaction was man machin e interaction 
had been done . NSF says that sounds lik e engineering . And NASA was proposing a telecommunication project. 
I said that I could do it if I could get the satellit e launched. So I think it's sort of interesting 
just to think about why this was not pursued and I'd like anybody on the panel wh o has a thought about 
it, to consider what they're doing now, ho w much might have been done earlier, and whether it would 
have ­  -I'm sort of struck because the vector environments look like they would have been compelling 
and could have been pursue d much earlier . Some of the tactile feedback work -- while it' s leading 
edge now -- could you -- do you need today's technolog y to do it, or could it have been really pursued 
10 years ago? An d some of the even for Jaron and the data glove and the body suit, how much of those 
things -- in other words, how much is the ability to see and portray the graphics enabling not just th 
e technology, but the perception that it would be worth doing? I t seems like it would be nice to have 
all this other stuff done an d have it all sort of fit together at the right time, rather tha n waiting 
till it's economic to make the toys and then do the research. Maybe we should have the toy industry fund 
-- direct the research and -- A. The questioner is notable. This is Myron Krueger, one of the real pioneers 
in the field . I just wanted to let people know . A . God, the toy industry . I think a lot of it could 
have bee n done earlier . I don't know if there's any good answer to that . I wish I understood . A 
. I guess my response would be that probably -- I don't thin k a lot of it could be done earlier . I 
think we're really lucky to be working at a time when a lot of the technology is accessible, low cost 
. I mean, it's certainly been our trust in this thing, i s  to try to keep it at the low end . I mean, 
we've seen thes e simulators that cost 15, 20 million dollars for a long time, an d we were trying to 
keep it down at the other end of the spectru m so we could get it out into this kind of personal simulation 
. The 3-D sound stuff that Beth Wenzel and Scott Foster ar e doing really rely on some DSPs that really 
weren't around unti l about a year ago. The LCD displays, we took a gamble in the design of our headset 
that -- actually it wasn't a gamble . We pretty much knew that the LCD's display stuff was going t o 
improve so much over the last couple years and again in th e next few years -- that we could just design 
it to pop in a ne w module as they come out. And that in fact has been the case. Of course, it's not 
fast enough for us, but I guess -- well, we'r e getting there . CONN : When Myron mentioned tactile stuff, 
the computatio n -- you need computation for all of it and yes, sometimes yo u can compromise and sometimes 
you can't . With the tactil e stuff, the kinds of experiments we do with changing th e internal physics 
that lets the tactile space feel like things , we've really, really needed a lot of computation, and 
maybe it' s a few years where that computation is cheap enough to put in a few labs. But it's not a lot 
of years . But you've been able to get that amount of computation to stick right to the physica l object 
. The other thing is that -- especially working on trying to develop stuff for kids, it always seems 
like it's the trickle dow n theory in that it takes so many years before they let kids on i t and when 
they let kids on it, finally well, okay, then it's safe o r whatever. I mean, the only time that I've 
actually seen or hear d of a place that they've really let kids on big machines , important machines, 
was the Logo Lab back in the '60s, and since then it's been hard . It's been hard getting access to th 
e systems, the money, because it's not readily there unless yo u can, unfortunately, take off and go 
to the moon with it . I think we had a great turnout for our panel . Thanks fo r being here, and there's 
a breakout room I think in Liberty A . So if I'm wrong, they'll correct me .  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>77279</article_id>
		<sort_key>19</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Retrospectives I: the early years in computer graphics at MIT, Lincoln Lab, and Harvard]]></title>
		<page_from>19</page_from>
		<page_to>38</page_to>
		<doi_number>10.1145/77276.77279</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=77279</url>
		<abstract>
			<par><![CDATA[I am Jan Hurst; welcome to Retrospectives. In early 1988, SIGGRAPH funded a project which was called Milestones, the History of Computer Graphics. We believed it was important to capture the early history since the graphics of tomorrow continues to build upon its past. We established goals, and one result was to begin a series of retrospectives which focus on specific aspects of the industry. Boston seemed like the perfect opportunity to focus on MIT, Lincoln Lab, and Harvard.I hope that you will get a sense from the pioneers as to what graphics was like in its infancy in Boston. I hope that you will enjoy hearing about their experiences as I have. They have been absolutely charming and inspirational to work with, and I'd like to thank all of them at this time.The speakers have many things to share with you, so I will be brief. I want to thank SIGGRAPH for supporting and encouraging this project and I want to thank the Pioneers for their willingness to share their experiences and their knowledge with all of us.I want to introduce you to Michael S. Mahoney, who will act as the moderator for the retrospectives. Mike is a professor at Princeton, he is in the program in the History of Science, he is editor of the ACM History Series, and he is a distinguished member of the Milestone Advisory Committee. Mike.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>K.2</cat_node>
				<descriptor>Software</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>K.2</cat_node>
				<descriptor>Hardware</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.0</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003456.10003457.10003521.10003523</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->History of computing->History of hardware</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003521.10003524</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->History of computing->History of software</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31080450</person_id>
				<author_profile_id><![CDATA[81332505569]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hurst]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[EJH Associates]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P181717</person_id>
				<author_profile_id><![CDATA[81100230830]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Mhoney]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Princeton University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P206125</person_id>
				<author_profile_id><![CDATA[81543487256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[N.]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Taylor]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Androx, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40036845</person_id>
				<author_profile_id><![CDATA[81100265827]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[Ross]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[SofTech, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31075584</person_id>
				<author_profile_id><![CDATA[81100313954]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Fano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MIT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SIGGRAPH '89 PANEL PROCEEDING S Special Session Retrospectives : The Early Years in Computer Graphic 
s at MIT, Lincoln Lab and Harvard Chair : Jan Hurst, EJH Associates Speakers: Michael S . Mahoney, Princeton 
University Norman H . Taylor, Androx, Inc . Douglas T. Ross, SofTech, Inc. Robert M . Fano, MIT I am 
Jan Hurst ; welcome to Retrospectives . In early 1988 , SIGGRAPH funded a project which was called Milestones, 
th e History of Computer Graphics . We believed it was importan t to capture the early history since 
the graphics of tomorro w continues to build upon its past. We established goals, and one result was 
to begin a series of retrospectives which focus o n specific aspects of the industry . Boston seemed 
like the perfec t opportunity to focus on MIT, Lincoln Lab, and Harvard . I hope that you will get a 
sense from the pioneers as t o what graphics was like in its infancy in Boston. I hope that you will 
enjoy hearing about their experiences as I have . They have been absolutely charming and inspirational 
to work with , and I'd like to thank all of them at this time . The speakers have many things to share 
with you, so I wil l be brief . I want to thank SIGGRAPH for supporting an d encouraging this project 
and I want to thank the Pioneers fo r their willingness to share their experiences and thei r knowledge 
with all of us . I want to introduce you to Michael S . Mahoney, who wil l act as the moderator for the 
retrospectives . Mike is a professo r at Princeton, he is in the program in the History of Science, h 
e is editor of the ACM History Series, and he is a distinguishe d member of the Milestone Advisory Committee 
. Mike . Michael S . Mahone y Princeton University Thank you very much, Jan . As I said to the group 
when w e had lunch today, I feel a bit ill at ease when I'm with them because they started the party 
about 40 years ago and I jus t walked in . Now I'm supposed to act as moderator of thei r activities 
and I'm supposed to introduce them to an audience that I suspect already knows many of them . I'm going 
to keep my own remarks brief also because the story we are going to hear today is a story that really 
only the y can tell . However, I would like to say a little bit about the value of panels of this sort 
. Back in the mid '70s at a conference held, I believe it wa s at Los Alamos, on the history of computing, 
Dick Hamming of Bell Labs titled his keynote address, We Would Know Wha t They Thought When They Did 
It, meaning that he was hopin g that people doing the history of computing would get bac k beyond firsts 
to try to understand the mindset of the peopl e who were doing the work and making the achievements tha 
t were being documented. I didn't fully comprehend how deep a thought that was o n his part until a colleague 
of mine told me a story about Jea n Piaget, which may be apocryphal, but if it is, I'm going to tel l 
it anyway, because it's too good to let go . The story goes that Piaget was out one evening with a group 
of 11-year-olds and pointed out the moon to them an d said, isn't it interesting that when we come out 
here each evening the moon is just a little bit higher in the sky? What d o you suppose causes that? 
And the children said we don't know , professed their ignorance of it. And in the way that was hi s own, 
his highly manipulative, Socratic dialogue, he manage d to get them to work out that the moon revolves 
around the eart h about once a month and that this would account for the changing angle each evening 
. About a month later Piaget was out with the same group o f children, pointed out the same phenomenon 
and asked the sam e question and one 11-year-old popped up and said well, that' s very simple . You see, 
the moon revolves around the earth about once a month and that accounts for the angle . And Piage t looked 
at the child and said that's amazing, how did yo u know that? Oh, said the boy, we've always known that 
. What we're trying to do with perspectives here is to ge t back to a time when people didn't know what 
they know now , try to understand what they were thinking before the question s became as clear as they 
seem to us now, and certainly before th e answers did. And it's with that goal that we start today's 
proceedings . Our first speaker is Norm Taylor who received his degree s from Bates College and MIT, 
and went on after the war t o participate in the design and development of the very earl y Whirlwind 
Computer . He worked at Lincoln Lab where he wa s associate head of the computer division and then led 
the engineering effort for the four later versions, including th e original, coincident, current magnetic 
memory on the SAG E FSQ-7. At Lincoln Lab he was a senior member of the SAG E Air Defense effort and 
was technical assistant to Dr . Jerry Weisner on the White House Gaither Panel . Later on he joined ITEK 
as vice president of engineerin g and led the effort in the development of the Digigraphic s system, 
later acquired by Control Data, where he becam e technical assistant to the president . For the past 
20 years he's been a consultant both a t Arthur D. Little and at his own firm, Corporate Tech Planning 
. And he told me just before we started that he is now adjusting t o retirement, trying to stay active 
.  RETROSPECTIVES I ; THE EARLY YEARS IN COMPUTER GRAPHICS    SIGGRAPH '89 PANEL PROCEEDING S other 
drums caught the data as they came in from the radars . So we were interlacing everything with 15 second 
intervals . But details of the FSQ-7 will take longer than my allotted 2 0 minutes and we will end here 
with the first ten years o f computer displays . Thank you . Moderato r Michael S . Mahoney  Princeton 
University I forgot to explain the ground rules we had established . Each speaker is going to speak for 
about 20 minutes and then I thought what we would do is have two or three minutes for an y questions 
from the audience specific to that talk, and that wil l leave us some time at the end of the session 
for more genera l questions across the speakers or from commentary from th e floor, as difficult as it 
is to see . Are there any questions that anyone would like to addres s to Norm Taylor? Good. Thanks for 
the okay, here we go . Q . You mentioned that the Charactron tube then we saw th e display there where 
the characters and there were als o vectors showing the outline of the New England coast. How did you 
generate those ? TAYLOR: I don't remember exactly . I think there were som e vectors on that matrix and 
I think we added them together then . But we didn't have individual vector generators in this tim e period 
. So that was the reason we went to the Charactron . It was very hard with 82 different consoles to have 
individua l anything . So we did everything centrally and I think th e reason the coastline was so crude 
is that we used lines if yo u want to actually go back to that slide, I don't know which one it was 
. It gives us that . ROSS : The Whirlwind analog scopes and the Charactron both had analog vector generation, 
sweeping X &#38; Y deflections . TAYLOR : Okay, we did have an analog sweep, and I don' t know how we 
transmitted that to the consoles . When I though t about that I tried to remember and I couldn't remember 
. Remember the 82 consoles, Doug? That didn't make it easy . Q . Thank you . This work is so exciting. 
 Q . This Charactron tube -- is this the same one that went i n to the Stromberg Carlson the 4020 film 
recorder later ? TAYLOR: I believe so. I believe Stromberg Carlson was th e source of the Charactron. 
The inventor was a fellow named Jo e McNarny, I failed to mention that . It was I think Stromberg either 
sold it to Convair or was in a joint venture . As I remember, the Stromberg name was involved and I think 
it wa s the only one around at that time .  The Typotron tube which I mentioned was made by Hughe s 
Laboratory . We went there . They slid have a storage tube an d we asked them could they put a Charactron 
on a storage tub e mask and they were delighted to do that . We had a little trouble funding the Typotron 
becaus e Hughes always wanted a development contract, and you kno w about how hard that is . So we just 
plain ordered the 50 of the m at a fixed price before they were designed and somehow it al l worked out 
. Moderato r Michael S . Mahone y Princeton Universit y Thanks very much, Norm. Our next speaker is 
Doug Ross , Douglas T. Ross, who began his career as a graduate student i n math at MIT where he was 
quickly lured into computing, serving as head of the Computer Applications Group from 195 2 to 1969, 
when he left MIT to form SofTech, Inc ., which h e served as president until 1975 and since then as chairman 
. He's made seminal contributions to several areas o f computing, ranging from automatic programming 
o f numerically controlled tools, the computer language APT , through Computer Aided Design, his Automated 
Engineerin g Design System, down to software engineering, the method o f structured analysis design technique, 
which he puts generally under the heading of man machine collaboration . He's an old hand at historical 
gatherings, having reported on APT at the conference on the History of Programmin g Languages held in 
1978, and more recently on the earl y development in the History of Personal Workstations in 1986 . Today 
he is going to talk about working compute r graphics from Whirlwind through Sketchpad and beyond with 
a little bit about APT. Doug Ross . Douglas T . Ross SofTech, Inc . Thank you very much, Mike . Actually, 
I'm going to b e trying to cover a 17-year span from 1952 when I started on Whirlwind -- I'm just a youngster 
compared to Norm, you se e through the founding of SofTech in 1969 because we did n o further graphics 
work after, leaving MIT . So the interesting thing is that I sort of span all the tim e of all the panelists 
on this session and the next, which means I have too much to cover . It also means that another problem 
that I have is that this has sort of been a year of nostalgia for me, because in addition to this meeting, 
we had Project Mac's 25th Anniversary on time sharing this year. The Computer-Aided Design Journal asked 
me to do a 20th anniversary piece for them and I submitted the Statement of Objectives for the Computer-Aide 
d Design Project that I did in 1960 . All they asked for wa s something that the information was my words 
and still up to date, and they thought I would write a special thing . It's interesting that in that 
opening memo I introduce d what I called "outside-in problem solving," which nowadays i s called "top-clown 
." But I prefer outside-in because outside-i n allows you to have many different viewpoints instead of 
a single top that you stupidly try to get to the bottom of, and things of that sort . Object oriented 
programming came out o f that . Then in addition, Computers in Industry Journal, had a special issue 
in memory of Joe Hatvany, so I had to go bac k and do one on the first automatic factory design for them, 
an d then just a few months ago in the International Conference o n Software Engineering had a panel 
on the pioneers of the NAT O Software Engineering Conferences in 1969 . I went down and did one for that 
. And then just a few months ago in May, th e Smithsonian Air and Space Museum just opened a brand ne 
w huge beautiful gallery on Computers in Aerospace . So I'll sho w you a few things that I contributed 
to that. And so now we have this for me to do . So I'm sort of rattling around in the old clay s and 
having a great time with it . Mike has already mentioned the two formal history papers that I've published 
and I have some slides that I used in various spots there . Those are the clear ones . I tried to make 
mor e slides covering different territory, you see, for this talk, but I tried to solve a problem where 
sometimes my flash would mak e a bright spot . So this time I discovered that I had a little wir e to 
hold the flash off to the side and I thought that would solv e  RETROSPECTIVES I : THE EARLY YEARS IN 
COMPUTER GRAPHICS       SIGGRAPH '89 PANEL PROCEEDING S FANO: I really don't know the details . 
It's just he tried t o get them to produce the display but they were not interested . They produced 
the tube . Q . They did produce tubes quite successfully ; they made a lo t of business . That's why 
they're in graphics today . MAHONEY: Can we turn on the mikes on the panel ? ROSS : Anyhow, as 1 recall, 
one of the problems that Ro b Stotz had with his company was that Tektronix essentiall y went into competition 
with him, and yes indeed, they did fo r some time make and sell quite a number of systems based on th 
e same tube. I think also that the Computek that was started b y Don Haring and Mike Dertouzous also 
used storage tubes i n their early displays didn't they? Remember that company ? FANO: Yes . ROSS : 
It's a little hazy in my mind, but yes, Tektronix was a leader for quite a while . FANO: That's right 
; I had forgotten that . Tektronix, after saying no, we are not interested, went in business doing tha 
t same thing. That's right. You are correct . Q . Where did the name Project MAC come from? I've hear 
d there's some stories . FANO: The name Project MAC . MAC stands for Machine Aided Cognition and Multiple 
Access Computers one bein g the goal and the other being the means to the goal . Lots o f names were 
coined afterwards . The one that I remember ver y well obviously coined on the West Coast was More Assets 
t o Cambridge. I also have to tell you that by April, 1963 the name of the project had not been coined 
yet and I was forced t o coin it in a hurry because the first employee, my assistan t director, an ived 
on the scene at MIT and needed a parking sticker. And the office that distributed parking stickers aske 
d him where do you work at MIT . And there was no name . So they couldn't, they wouldn't, give him the 
parking sticker . So he came back to me and that evening I coined Project MAC . So the next day he could 
get his parking sticker . MAHONEY: It all really did begin with Henry Ford . We have some time left if 
anyone has a general question or observation , comment. Let me throw the floor open and we'll keep ou 
r panelists' microphones open . ROSS : As a matter of fact, I have I was just thumbin g through these 
resumes, extracts, and with respect to what Bo b found, I was just checking your memory . It was excellent, 
Bob . It's on March 13, 1963 . In those resumes, I referred to th e project as just the "ARPA Project" 
at that point : "At the ARPA meeting, the 7094 is due to be shipped September 1 . Hopefull y we will 
be on the air October 1 . (They made it .) They also decided to have some combination of letters to make 
a name fo r the project . The current ones being IPS for Informatio n Processing System. But hopefully 
we can get some better letters, and Bob Fano will decide what it's going to be ." Ther e you are ! FANO: 
There was only one name that had been used up to that time. When I decided to start Project MAC for a 
variety of reasons that I won't go into, I wrote a little memorandum that was sent to every significant 
member of the MI T  administration, including the dean of engineering, who wa s Gordon Brown at that 
time. Later on he told me how he instructed his secretary to file the memo . It was under FF meaning 
Fano's Folly . So that was the only name . So I had t o hurry to concoct some names so that it wouldn't 
be know n forever as Fano's Folly . ROSS : Let me read just the next sentence or two here . It's really 
fascinating to go over this stuff that was actually writte n at the time . Right after saying this about 
how Fano was going to decide what it 's going to be, then 1 described our console , using the memo that 
Rob Stotz put together listing th e specifications . "'Then Fano introduced my suggestion -- I had talked 
to him just a couple days before that if ARPA could buy some of Corby's computer time, then we could 
put ou r console on the 7090 and make it generally available . Everybody was very enthusiastic about 
the console especially since it would be in effect a $100,000 gift . And so it looks like we will put 
it on the 7090." So it actually had a short time when it was hooked up to the 7090 down at Projec t MAC, 
which is why it was able to be brought up -- at th e computation center which was why it was able to 
be brough t up so fast when Project MAC got on the air . It's very interesting . Good times . Q. I was 
just interested to know in that picture of the Kludg e because I was involved got into graphics way 
about th e early '60s myself. Was that in fact a Dec 338 display ? ROSS : Yes, it was a Dec something 
30, right . FANO: Yes, I can tell you what that something was . I think I've got it here. I've got copies 
 type 30. Digital Equipment Corporation 530 . Then the second one was a better model . Incidentally, 
one of the significant developments that too k place shortly thereafter was the design and implementation 
of a different kind of light pen . You see, the original light pen wa s sensitive to light . And that 
through the phosphors you had a time delay involved . So the hardware developers I don' t remember whose 
idea it was developed a light pen that wa s sensitive to the electron beam striking the screen. Therefore 
you avoided a delay introduced by the phosphor . That was a significant development . ROSS: Yes, I found 
a reference to that in my resume someplace too . That was very interesting . HURST : If we have some 
time, I would like the panel t o discuss some of the feelings and the atmosphere of the areas a t the 
time that you were working . That's been one of the mos t interesting and fascinating things for me to 
hear about . What the atmosphere was, what the students were like . Did you understand how important 
all of these milestones were ? FANO: I can talk about the feeling in Project MAC and in the MIT community, 
but that's mostly about time sharing, rather than graphics. It was a period of really great excitement. 
Time sharing started out as a way of sharing a computer . What it turned out was something much, much 
more important tha n that . It became the repository of the knowledge of a community . What made the 
system real effective was the fac t that it had the first disk file the IBM what is it 1301 came 
in in 1963 . And that made a tremendous difference . Everybody's files were stored on the disk file . 
So it really was the storage of the knowledge of the community . As a matter of fact, it was not long 
after th e beginning that we had to institute an editorial board. There were three ways in which information, 
programs and data, coul d be stored in the system . One was in the personal file of th e individual. 
Another one was in a public file accessible t o everybody . The third one was a system commands . No 
w somebody had to decide where to put it, and this is ver y analogous to an editorial board of a journal, 
when you're tryin g to publish. And it was very interesting, the effect on programmers of that. Before 
then programmers never thought of their work being used by anybody else really . So they didn' t document 
it, they didn't it just was a personal thing . Suddenly a program became in effect a publication, a 
compute r publication, and people poured a lot more energy in writin g good program and documenting, 
and of course they wanted i t  RETROSPECTIVES I : THE EARLY YEARS IN COMPUTER GRAPHICS SIGGRAPH '89, 
Roston, July 39 Auest 4, 198 9 really published . Now there was also a subtle thing there . Everybody 
was allocated a certain amount of storage space o n the disk disk file . But the public files were not 
allocated . S o people had an interest in being able to put their work in the public file and even more 
in the command file . There was a rea l prestige attached to become a system man . That was a very interesting 
thing . The other very interesting thing is the community effect . People knew eac h other through the 
computer system, and that happened on many occasions of people meeting physically at some time an d saying, 
"Oh, that's you!" They had communicated through th e computer before and they knew about each other . 
The one thing that I regret very much is that I didn't get a very good sociologist, social psychologist, 
to look at wha t was happening early enough, because of course, it is a phenomenon that you cannot recreate. 
If you miss that chance , you'll miss it forever . But from a sociological standpoint i t was an extremely 
interesting phenomenon . TAYLOR : I might speak to that idea of what was th e atmosphere. Whirlwind was 
probably the first computer tha t ran well, that was fast enough to be a real time computer, and therefore 
when it started to run in about 1951, it was a feelin g of excitement probably more than I've ever had 
since . In the year following that, when we get the core memory on the thing as I pointed out, the storage 
tube was kind o f cantankerous, but after we got it to the the core memory o n it, which is about that 
time, the first year after that we were able to do much more interesting things . We still had som e 
displays on it, some of which Doug used . We had 25,00 0 visitors . We had to set up a department to 
handle the visitor s because they were there all the time . And of course, it wa s tough for us to continue 
development on the SAGE system , which this was the prototype, with all these people walkin g through 
there all the time. We had people from Europe , Switzerland, Germany, Japan, China all of that . And 
it went on and on for such a so that all the students that came out o f MIT wanted to do their thesis 
on this thing . So we had mor e students trying to do theses than we had people working on th e system 
. So as far as everybody seemed to sense they were on the threshold of something very important . And 
it was largely I think this was a display being able to communicat e with what was going on that we 
were able to get tha t excitement satisfied. It was a little dull when you just put in numbers and got 
out numbers. But when we got the display started, it changed the whole thing, and I think that meant 
no t only the bandwidth you can get out of a display system, but th e man machine interaction of the 
light pen just seemed to excite people beyond comprehension . Moderato r Michael S, Mahone y Princeton 
Universit y Thanks very much . We've reached the end of the first hal f the first panel taking us from 
the early days of Whirlwin d up to the early '60s when, as Doug and Bob suggested, some o f the hardware 
became available to realize in actuality the idea s that people had about putting pictures on the screen 
. We'll pick that up in the second session which will begin aroun d 3:30. I do want to thank our first 
set of panelists, Norm Taylor, Doug Ross, and Bob Fano, for very interestin g insights and for some 
sense of what they were thinkin g when they did what they did . RETROSPECTIVES I : THE EARLY YEARS IN 
COMPUTER GRAPHICS  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>77280</article_id>
		<sort_key>39</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Retrospectives II: the early years in computer graphics at MIT, Lincoln Lab, andd Harvard]]></title>
		<page_from>39</page_from>
		<page_to>73</page_to>
		<doi_number>10.1145/77276.77280</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=77280</url>
		<categories>
			<primary_category>
				<cat_node>K.2</cat_node>
				<descriptor>Software</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.0</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003521.10003524</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->History of computing->History of software</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31082351</person_id>
				<author_profile_id><![CDATA[81332505569]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hurst]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[EJH Associates]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P181334</person_id>
				<author_profile_id><![CDATA[81100230830]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Mahoney]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Princeton University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P122927</person_id>
				<author_profile_id><![CDATA[81407591803]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[Gilmore]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Digital Equipment Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14202198</person_id>
				<author_profile_id><![CDATA[81100585520]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[L.]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Roberts]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NetExpress, Inc]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P232133</person_id>
				<author_profile_id><![CDATA[81332498990]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Forrest]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of East Anglia, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
        SIGGRAPH '89, Boston, July 31 -Au~tust 4, 1989 I am proud to have been part of the team 
that developed the TX-2 and its systems software. But more importantly, it was a pleasure to have worked 
with such an auspicious group of people. These are some of the key reports by that team regarding the 
TX-2: --GILMORE SLIDE 38 -- --GILMORE SLIDE 39 -- --GILMORE SLIDE 40 -- --GILMORE SLIDE 41 -- --GILMORE 
SLIDE 42 -- --GILMORE SLIDE 43 -- Larry Roberts will tell you more about the graphic work done on the 
TX-2, particularly about Ivan Sutherland's Sketchpad and his own key contribution regarding three dimensional 
objects and the determination of hidden lines Bob Everett reminded me that Ron Mayer had done some interesting 
experimental display work on the TX-2 in 1960. I called Ron Mayer and he described the work as an exercise 
to simulate planet and gravitational activity where one could observe the motion of the planets rotating 
about the sun and also their moons rotating about themselves. He used the light pen to control the gravitational 
velocity and acceleration vectors of an object. --GILMORE SLIDE 44 -- Once the TX-2 came on the air (late 
1958) it commandeered the TX-0 65K word memory and the TX-0 got an 8K bank as a replacement and was shipped 
to the MIT campus in Cambridge (1959) where a new breed of computer hackers were to hatch. --GILMORE 
SLIDE 45 -- The concepts of On-Line in Real-Time and serious console work using the Display and the Light 
Pen went with TX-0 and the MIT students embraced it with a vengeance. --GILMORE SLIDE 46 -- Some time 
in 1962 The TX-0 was supplemented in the same lab at the Institute by its child the DEC PDP-I. --GILMORE 
SLIDE 47 -- With the additional horsepower and storage of the PDP-1 there evolved a significant program 
called SPACEWAR developed by Steve Russel and Alan Kotek. SPACEWAR on the PDP-1 and Ron Mayer's Planet 
Gravitational Display on the TX-2 were the early origins to the modern computer games and an inspiration 
for graphic display speeds, orders of magnitude faster than one thought possible at that time. I think 
there should be a future SIGGRAPH session on the early computer Game Display Programs to fully appreciate 
the giant step they provided to the graphics world. --G/LMORE SLIDE 48 -- And finally we move to the 
last leg of our chart .... --GILMORE SLIDE 49 -- In October 1959 I also moved on from Lincoln Laboratory 
to co-found a software firm with my former boss at Whirlwind, Charlie Adams. We too, continued to work 
in the On-Line in Real Time scheme of computing and in 1960 we sought out Norm Taylor, who by then was 
a Vice president of ITEK corporation, to continue the graphics effort started on the TX-0 and produce 
an Electronic Drafting Machine for ITEK. Norm was still vitally interested in computer graphics and by 
the fall of that year had gotten ITEK's senior management to approve the EDM project and start work. 
--GILMORE SLIDE 50 -- The DEC PDP-1 was chosen and ITEK's engineering staff took on the task of building 
a hard disk which could not only be used for the storage of programs and drawings but also used as the 
display buffer to provide a 30 cycles per sec flicker free display monitor. Norm Taylor directed the 
design of the display hardware and was assisted by Charlie Adams from our shop, Earle W. Pughe Jr. from 
ITEK and Ben Gurley, who had gone with Digital by then, coordinated the PDP-1 interface. Our firm had 
the system design and software responsibility and I was the project leader. Key players included Charlie 
Adams, Frank Greatorex, Dave Isenberg, Patricia Gordon, Nick Chase, Dave Weisberg, Allen Rousseau and 
Charlie Burgess of ITEK provided systems support. --GILMORE SLIDE 51 -- This March 2, 1962 issue of Time 
reported on two major breakthroughs; Obviously the first was the cover story of John Glen's successful 
orbiting of the Earth. The one on page 74 listed under was titled, Breaking the Language Barrier The 
article referred to the language barrier between man and the computer and the need .to develop a machine 
that can communicate in a speedier and simpler language namely pictures. --GILMORE SLIDE 52 --  54 RETROSPECTIVES" 
Ih THE EAR'L'Y YEARS IN (~'0'MPUTER GR'APHICS "To beat the language barrier between man and machine, 
ITEK has, in effect, hitched the digital computer to the draftsman' stylus. With a photoelectric light 
pen, the operator of an EDM can formulate engineering problems graphically (instead of reducing them 
to equations on a console that looks like a flat, unflickering television screen.". DRAFTING on the The 
ITEK EDM provided the user with the basic ability to draw charts, diagrams, curves, etc. on the face 
of the display scope. The drawings could contain graphical and alphanumeric information, which was reduced 
to a condensed digital format called an entity table. The table could be operated on by special purpose 
software operators either during the drawing action or after the drawing is completed. --GILMORE SLIDE 
53 -- Certain Man-machine programming techniques were designed to accelerate the manual task of drawing 
or drafting. The console user could draw points, lines, circles, arcs, and freehand or third degree curves. 
Distances and angles could be specified but need not be. Sub drawings or macros as they are called now, 
could be moved about, rotated or reflected about vertical, horizontal or any slanted line; angles and 
distances could be queried, and drawn dimensions could be generated on the drawing itself. The maximum 
size drawing could be an E size sheet printed on a CalComp plotter. --GILMORE SLIDE 54 -- THE Draftsman 
operated in two modes: SKETCH MODE The light pen was used like a pencil. Its position was monitored by 
a Roland Silver tracking cross immediately below the pen. There was also a displayed point, offset from 
the pen by a quarter of an inch to the upper left, which represented the drawing point. Using a button 
on the pen itself, a set of control buttons at one's left hand on the CRT drawing board, the operator 
could constrain the motion of the drawing point horizontally, vertically or to some selected angle or 
arc; thereby creating the illusion of drawing on the CRT with various straight and curved edged tools. 
--GILMORE SLIDE 55 -- CONSTRUCT MODE: The light pen, used like a pointer, activated controls (called 
light buttons) which defined quantitatively end points of lines, centers of circles and other boundary 
conditions of interest at any scale desired up to a maximum 64:1. The drawing's elements could be modified 
or manipulated by changing appropriate control buttons or numbers. The operator could work in any scale 
of reference -inches, feet, yard, centimeter etc. by a simple scale designation. --GILMORE SLIDE 56 -- 
RETI~'0sPECTIvES Ih THE EARLY YEARS IN SIGGRAPH '89 PANEL PROCEEDINGS The control panel of light buttons 
also included a full alphanumeric keyboard, a numeric keypad and a set of numeric display registers. 
Notice the similarity ol this photo with the early TX-0 Scopewriter photos shown earlier. --GILMORE SLIDE 
57 -- This is a photo of an early drawing we made on the EDM. Its a simple block diagram of itself, which 
we found amusing to do as a milestone. The first drawing, however, was of the American flag but I either 
lost the copy of it or it's with some of the other photos at the Computer Museum. --GILMORE SLIDE 58 
Here is a shot of Frank Greatorex at the console with David Isenberg working on rotations and reflections. 
Norm Taylor was convinced that our ability to reflect about any line angle, not just horizontal or vertical 
was a key feature. This also shows how we imbedded the display scope right into a drafting table as part 
of the console. --GILMORE SLIDE 59 -- The EDM system was sold to Control Data in 1964 and our firm helped 
convert the software to the CDC 3200 machine. It was sold as the Control Data Digigraphics System and 
was purchased by such firms as Lockheed Aircraft and Martin Marietta Corporation for Aeronautical design. 
Norm Taylor can elaborate on this part of the story much better. --GILMORE SLIDE 60 -- A version of the 
EDM was also done for the U.S.Air Force on a DEC PDP-1 and called the DX-1 Computer System. I reported 
on that system in a DECUS Meeting at Lawrence Radiation Laboratory in November of 1963. --END OF PREPARED 
REMARKS Moderator Michael S. Mahoney Princeton University We have time for maybe one quick question before 
we move on to the next speaker. We'll follow the same procedure we did, which is to have each person 
speak for about 20 minutes, and then questions specific to that paper right after it, and then at the 
end we should have a little bit of time left over --we did in the first session -- for questions addressed 
to anyone and for general discussion. So, are there any questions? Okay, not seeing any, our next speaker 
-- Larry Roberts --is best known today for his work in the realm of data communications. He is considered 
the principal architect of packet switching technology and oversaw the planning and implementation of 
ARPAnet while he was acting as director of information processing techniques at ARPA in the 1960s. In 
1973 he founded Telenet Communications Corporation and served as president and CEO of the world's first 
packet  COMPUTER GRAPHICS          SIGGRAPH '89, Boston, July 31 -Au~lust 4, 1989 FORREST: 
I actually read those papers very carefully because I couldn't believe that it really was due to the 
buildup of error and I couldn't find anything in the papers which suggested that the problem was incremental 
vectors and I asked Charles Lang and he assured me that that was exactly the case and I certainly believed 
that at the time. I'm glad that we were wrong. ROSS: It may be the buildup of error, I'm not sure about 
that, but the cause was not roundoff but the other sort of noise factor. I'm not clear on that, I just 
remember seeing it in my notes and I thought I would mention it to you. MAHONEY: Yes, right here. Q. 
Yes, I'm wondering, if we have enough time, could we hear about the planet display programming on the 
TX-2. ?????: Ron Meyer, who was also a Whirlwind alumnus, apparently did some work on the TX-2 after 
I had left. When I touched based with Bob Everett a few weeks ago to check on some things, he reminded 
me that Ron had done some work on that and essentially what it was, he was displaying the planets and 
the sun and they were rotating about one another based on whatever gravitational accelerating forces 
were inputted and he was using the light pen to actually grab onto the planet and then modify either 
the velocity or the gravitation. So that was probably one of the first displays along those lines and 
then, of course, Space War in '62 picked up on that and from there I believe the great game display programming 
continued on. People like Alan Koteck and Steve Russell, I think it is, and Ron Meyer really fall into 
that category of pioneer. MAHONEY: I have a question sparked by a remark Larry Roberts made. Larry you 
talked about going back in the mathematical literature and finding that the mathematics of perspective 
lay in one body of literature and mathematics of matrices lay in others and you had to put it together. 
In general, where did one get the mathematics for computer graphics? Was it a question of going out and 
picking up mathematics that was there and putting it together in new ways or to what extent did you have 
to create the mathematics you were using? ROBERTS: Well, the mathematics for the three-dimensional display 
was done pretty much as ! said, going back to the eighteen hundreds in terms of when they did a lot of 
perspective geometry. After that point in time, it turns out, as far as 1 can tell, people got into crazy 
abnormal surfaces and things which were almost useless to us in terms of displaying things. But perspective 
geometry back in the 1800s was in terms of real issues, of how to do the perspective transform, but it 
was all done without matrices. And so I had to translate that into matrix technology and then the four-dimensional 
transform resulted from that because matrix technology was, of course, well known to us by that point 
in time and it was a lot easier to implement smoothly on the computer. But we needed to do something 
that could handle the perspective cleanly. So I did that; as Robin, you said, Ivan did it slightly differently, 
he picked up what I was doing. FORREST: Perhaps I can just add to that. I was given a row by my supervisor 
in Cambridge for not consulting people enough on my thesis. So [ went up and consulted mathematicians 
in the University. One of them who was a died in the wool numerical analyst, referred me to the Brunsviga 
Desk Calculator of 1935, said it would solve all my problems. And the other looked at me with absolute 
horror and said all that work was fashionable in the eighteen hundreds, this is surfaces, but nobody 
is interested in that nowadays. Then he said, 'I guess you've got real problems.' And this sudden realization 
and what Larry had done with marrying classic n i nmn i nnnmnlnlunql RETROSPECTIVES projected geometry 
and matrix techniques because he had to do that for the computer and I was doing similar things so for 
that reason, I started talking about doing 'computational geometry' in 1970. That was rather before the 
theory of algorithms people started talking about, computational geometry in the context of algorithmic 
complexity. MAHONEY: Yes, go ahead. Q. I have a question for Larry. Was the homogeneous coordinates your 
invention or did you pick that up someplace else? ROBERTS: The homogeneous coordinates in matrix form 
was my invention. The concept, the word homogeneous came from the 1800s, in terms of their handling of 
perspective geometry, but again it was all in terms of individual equations and not in matrix. So throughout 
this whole period we were picking up old things that people had done, as Robin said before they thought 
it was boring, and applying it, because we were trying to work with real problems, and applying it to 
the real world. And the same happened with conic generation and conic display, cubic generation, and 
cubic surfaces. We were picking up math and applying it, and it was certainly new in the computer field 
but it wasn't new in perspective geometry. Q. These comments about mathematicians not being aware of 
what the mathematics were for doing this reminds me of the comment that I heard in one of the papers 
at SIGGRAPH '88. This was someone doing physically based modeling and they had gone to the Physics Department 
and asked them for advice and everyone sort of scratched their heads and didn't know anything about it 
because it had nothing to do with superstrings or anything else that you could get grant money for and 
he had to go back to a 1930s mechanics textbook to find his answers. FORREST: In fact, the textbooks 
I went back to were the only times I have ever used technical German. Q. Question for Larry Roberts. 
I'm Dave Rogers by the way. Roberts' algorithm is considered to be applicable to convex volumes. MAHONEY: 
What algorithm? ROGERS: Roberts' hidden line algorithm is considered to be applicable to convex volumes. 
Some of the slides you show are obviously concave. Are they real or are they a fiddle? I hate to use 
that word. How are they done? ROBERTS: The objects were all constructed from convex pieces. In other 
words they were -- you obviously can build a concave object by way of piece part. And that's how all 
of the objects you saw were created. And so though the algorithm only worked for convex components, those 
components could be arbitrarily very small and you could have any number of them and therefore you can 
build anything you want from those things. And therefore you saw what we finally built up out of that. 
I can't actually place which of those was the first hidden line display in the world, but one of them 
was. Q. I'm George Michael. I'd like to make a small comment that some of the things that happened at 
MIT which were much more important than what we heard about today haven't gotten mentioned and I wondered 
why. And rll give you some clues, the whole field of nuclear physics with PEPR and things of this sort 
had a lot to do with the development of computer graphics and we didn't hear anything about them. Is 
there a reason? ROBERTS: Which things did you mention? MICHAEL: PEPR --Pattern Extraction and Pattern 
Recognition. ROBERTS: Well, the work of Minsky and Pappert which was obviously very major at MIT was 
typically using the graphics I1: THE EARLY YEARS IN COMPUTER GRAPHICS SIGGRAPH '89 PANEL PROCEEDINGS 
that were around in terms of artificial intelligence and pattern recognition. And it was somewhat later 
in time, in the large part that they were using that, in my memory, but it was clearly fairly major in 
terms of the development of artificial intelligence. I'm not sure which early things you were thinking 
of. MICHAEL: PEPR was a thing that was evolving in the early 60s, okay. All right, it mostly is a judgmental 
call. I think it was important because it showed that you needed computers and image detectors to see 
how things were put together. There is another comment I wanted to make, as sort of a compliment. Someone, 
I think Doug Ross, said that the reason that everybody in the 60s and so forth was doing so well and 
what we are being so self-congratulatory about now, is because we have real problems to work on and they 
inspire people and you were saying, if I quote you correctly 'you don't see any real problems being worked 
on now, or to a lesser extent.' I think that is a very important point and you might want to have more 
comment made on it by you. ROBERTS: Clearly, the excitement during that period was that it was -- we 
were doing it for the first time too and one person could do a tremendous amount, And that was very exciting. 
As the computer field developed, it became teams and huge groups that could do significant changes in 
the technology. That's one of the reasons I switched to data communications is because I could start 
where one person could do a lot again. But we certainly were working on things where we were actually 
anticipating real problems. The reality is that we weren't ourselves designing cars like GM or somebody. 
We were developing the technology which we knew could be used for that. But compared to this perspective 
geometrist, we were doing very real things. MAHONEY: Any further comments or questions? If not, I want 
to thank our speakers this afternoon -- Jack Gilmore, Larry Roberts, Robin Forrest --and thank you all 
for joining us at this look into the early history of computer graphics in the Cambridge area. Thanks 
very much for coming. RETROSPECTIVES II: THE EARLY YEARS IN COMPUTER GRAPHICS  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>77281</article_id>
		<sort_key>75</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Digital canvas: artists and designers in the 2D/3D marketplace]]></title>
		<page_from>75</page_from>
		<page_to>92</page_to>
		<doi_number>10.1145/77276.77281</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=77281</url>
		<abstract>
			<par><![CDATA[<p>I'm Rachel Carpenter, and this mike seems to be really alive.Thefilms that you've been watching on the screen are from theAnimation Screening Room, which is really hot this year. We've gota lot of wonderful pieces. It's in the Sheraton, just as you walkin from the Hines, and you'll see signs there. There are threeviewing environments. Right at the beginning, there is a cafeenvironment where you can sit down with food and just watch things.There's a room next to it with monitors and then there's a largeroom with rear projection, large screen, lots of seats. There areschedules available. At any time you can watch two differentthings.</p><p>I decided to put this panel together when I was working at acomputer graphics school for artists and designers. People werealways asking, "Well, where are the jobs? What kind of work isthere, and why should I bother with computers?" So I got thesepeople together who have been in the business, in various aspects,for many years, and have found their own way. They will tell youtheir stories and give you an idea of how to look for things.</p><p>There are some very specific ideas. Other people seem to havebeen having the same thoughts because the education committee puttogether this wonderful Volume 23, Careers Handbook, and I suggestthat you get it. It's in the education booth as you come into theHines, there are all those booths --- well, the one on the end,toward the entrance, is called Space, they have up the studentartwork. Volume 23 has categories of different kinds of jobs,career profiles, colleges and universities which are organized bytopic first, if it's art and design or engineering or other typesof signs or medical or whatever, and then by state.</p><p>Then they have about the job search process. There's also aquestionnaire at the end, which the people who put this togetherreally urge everyone to fill out the questionnaire and send it in.It's a tremendous amount of information. They are available at thebooth or you can call up ACM and order one. It's Volume 23.</p><p>I also want to tell you about another really good opportunityfor artists. I happen to be the United States Representative forPrix Ars Electronica; it's a competition in Austria for computerart, animation &amp;amp; music. They have significant cash prizes.So if you're interested in entering that after this is over, giveme your address and I'll see that you get entry forms for that. Youcan also call me in California at 415-892-8254.</p><p>Also, you've seen a lot of things while you've been here atSIGGRAPH and I want to let you know that everybody can participate.I started going to SIGGRAPH in 1980 when it was in Seattle.</p><p>I'm not sure quite how many people were there then, but it wasprobably something like 17,000, and when I was SIGGRAPH '85 ArtShow administrator in San Francisco, there were 27,000 peopleattending the conference. It keeps on growing because people areinterested and because the industry is growing. You can contributetoo. If you have an idea, write it up, present it as a course,panel or submit to someone on the committee.</p><p>The Animation Screening Room shows works representative of whatis going on in computer graphics, over 50% of the work in there isscience related. Some of that's medical, some engineering, geology,molecular modeling --- various things. The are lists there; you canlook and see types of job categories.</p><p>A large group is composed of works that could be consideredcommercial production. Architecture, art and character animationform a smaller amount of what is being produced in computergraphics. So search out those other areas. There are many fieldsout there. This handbook will help you and we hope you get someideas from our panelists.</p><p>The amount of material in the Screening Room is about 8-1/2hours. It's taken a lot of work to put that together. There were 21hours of work submitted to the film show jury and all of that hadto be gone through many times.</p><p>I want to let you know also that afterwards we have a breakoutroom for people who want to get together. I know we have a lot ofartists and designers here, besides the panelists, and there may besome of you who are looking for --- maybe you have jobs for peopleor maybe you're just interested in listening. So we will find outwhere that breakout room is going to be and I'll tell you at theend.</p><p>&lt;b&gt;A:&lt;/b&gt; J as in Jones.</p><p>&lt;b&gt;CARPENTER:&lt;/b&gt; Okay, the breakout room is goingto be in J Room --- as in H, I, J, K. J. Tonight there is going tobe a reception at the Computer Museum and buses are leaving fromthe Hines at 5:00, 5:30 and 6:00, and there's no video or audiotaping of this, and there we've got that. Okay.</p><p>The way we're going to do this is John Derry will speak next andthen all our other panelists will speak and then we'll havequestions. So you need to sort of keep track of your questions.</p><p>John has a BFA in Painting and Drawing from the University ofNebraska at Omaha and a MFA in Painting from Cranbrook Academy ofArt in Michigan. He has been involved in computer graphics since1982. John has found exciting ways to combine traditional methodswith computer graphics to create pieces unique to both worlds. Hefeels that the public has become so visually aware that the staticimage has to have more excitement in it to compete with the manymoving images that people see each day. Derry enjoys each newproject and approaches it as a creative challenge. He works in theareas of fine art and pre-press.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor>Arts, fine and performing**</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14025998</person_id>
				<author_profile_id><![CDATA[81332492211]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Carpenter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cinematrix]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P121860</person_id>
				<author_profile_id><![CDATA[81100354654]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Derry]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chromaset]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14154180</person_id>
				<author_profile_id><![CDATA[81332489070]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Barry]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[SuperMac Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P214458</person_id>
				<author_profile_id><![CDATA[81100011929]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[P.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Conn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Homer and Associates]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P289335</person_id>
				<author_profile_id><![CDATA[81332529248]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[V.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sorensen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of the Arts]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SIGGRAPH '89 PANEL PROCEEDING S Panel Sessio n Digital Canvas:  Artists and Designers in the 2D/3D 
Marketplace Chair: Rachel Carpenter, Cinematrix Speakers : John Deny, Chromaset Claire Barry, SuperMac 
Technology Peter Conn, Homer and Associates Vibeke Sorensen, California Institute of the Arts I'm Rachel 
Carpenter, and this mike seems to be really alive . The films that you've been watching on the screen 
are fro m the Animation Screening Room, which is really hot this year . We've got a lot of wonderful 
pieces . It's in the Sheraton, just as you walk in from the Hines, and you'll see signs there . Ther 
e are three viewing environments . Right at the beginning, ther e is a cafe environment where you can 
sit down with food and jus t watch things . There's a room next to it with monitors and the n there's 
a large room with rear projection, large screen, lots o f seats. There are schedules available. At any 
time you can watch two different things . I decided to put this panel together when I was working at 
a computer graphics school for artists and designers . People were always asking, "Well, where are the 
jobs? What kind o f work is there, and why should I bother with computers?" So I got these people together 
who have been in the business, i n various aspects, for many years, and have found their own way . They 
will tell you their stories and give you an idea of how t o look for things . There are some very specific 
ideas . Other people seem t o have been having the same thoughts because the educatio n committee put 
together this wonderful Volume 23, Career s Handbook, and I suggest that you get it . It's in the educatio 
n booth as you come into the Hines, there are all those booths well, the one on the end, toward the 
entrance, is called Space , they have up the student artwork, Volume 23 has categories o f different 
kinds of jobs, career profiles, colleges an d universities which are organized by topic first, if it's 
art an d design or engineering or other types of signs or medical or whatever, and then by state. Then 
they have about the job search process . There's als o a questionnaire at the end, which the people who 
put thi s together really urge everyone to fill out the questionnaire an d send it in. It's a tremendous 
amount of information. They are available at the booth or you can call up ACM and order one . It's Volume 
23 . I also want to tell you about another really goo d opportunity for artists . I happen to be the 
United State s Representative for Prix Ars Electronica ; it's a competition i n Austria for computer 
art, animation &#38; music . They hav e significant cash prizes. So if you're interested in entering 
tha t after this is over, give me your address and I'll see that you ge t entry forms for that . You 
can also call me in California at 415 ­892-8254 . Also, you've seen a lot of things while you've been 
here a t SIGGRAPH and I want to let you know that everybody can participate . I started going to SIGGRAPH 
in 1980 when it wa s in Seattle . I'm not sure quite how many people were there then, but i t was probably 
something like 17,000, and when I wa s SIGGRAPH '85 Art Show administrator in San Francisco, ther e were 
27,000 people attending the conference . It keeps on growing because people are interested and because 
the industr y is growing . You can contribute too . If you have an idea, writ e it up, present it as 
a course, panel or submit to someone on th e committee . The Animation Screening Room shows work s representative 
of what is going on in computer graphics, ove r 50% of the work in there is science related . Some of 
that' s medical, some engineering, geology, molecular modeling various things . The are lists there; 
you can look and see type s of job categories . A large group is composed of works that could b e considered 
commercial production. Architecture, art and character animation form a smaller amount of what is bein 
g produced in computer graphics. So search out those other areas. There are many fields out there. This 
handbook will help you and we hope you get some ideas from our panelists . The amount of material in 
the Screening Room is about 8 ­1/2 hours . It's taken a lot of work to put that together . There were 
2.1 hours of work submitted to the film show jury and all o f that had to be gone through many times 
. I want to let you know also that afterwards we have a breakout room for people who want to get together 
. I know w e have a lot of artists and designers here, besides the panelists , and there may be some 
of you who are looking for maybe you have jobs for people or maybe you're just interested i n listening 
. So we will find out where that breakout room i s going to be and I'll tell you at the end . A: J as 
in Jones . CARPENTER : Okay, the breakout room is going to be in J Room as in H, I, J, K. J. Tonight 
there is going to be a reception at the Computer Museum and buses are leaving fro m the Hines at 5:00, 
5:30 and 6:00, and there's no video or audi o taping of this, and there we've got that . Okay . The way 
we're going to do this is John Derry will spea k next and then all our other panelists will speak and 
then we'l l have questions . So you need to sort of keep track of you r questions . John has a BFA in 
Painting and Drawing from th e University of Nebraska at Omaha and a MFA in Painting from Cranbrook Academy 
of Art in Michigan . He has been involved in computer graphics since 1982 . John has found excitin g 
ways to combine traditional methods with computer graphic s DIGITAL CANVAS : ARTISTS AND DESIGNERS IN 
THE 2D/3D MARKETPLACE     SIGGRAPH '89 PANEL PROCEEDING S The second I felt was that it didn't really 
show ho w transparency affected multiple colors, and I thought that tha t was really important . In a 
True Color program you can use u p to 16 million colors and this limited the potential . The third problem 
was that it isn't really accessibl e quickly to the user . This would need to be accessed through a pull-down 
window or double clicking somewhere on screen, an d even though that's a pretty effective approach, it 
is man y seconds delay and I definitely didn't want the artist t o compromise the degree of transparency 
because of any tim e limits . So what I did was went on to my second idea which i t was very important 
to me to address how transparency looked over multiple colors . So I took an image ; I quickly used th 
e Apple logo because it had multiple colors . I also tried balloon s and rainbows, just something with 
multiple colors, and agai n putting in the same type of format of the dialogue box with th e scroll bar. 
The way this would work would be the user adjuste d the scroll bar, the degree of transparency would 
change . Now this introduced a whole new set of problems. It's basically pretty confusing . It definitely 
isn't an interfac e objective . It wasn't really clear and we did try this out with bet a sites whether 
the foreground was becoming opaque or th e background was becoming a transparent . So it wasn't clea 
r what those numbers were relating to . The next concept I tried was where the numbers woul d change 
as the degree of transparency within the number s changed all interactively in real time. Needless to 
say, th e programmers found that quite amusing . We got a laugh out o f that . So I was given two books 
. I was new to the Macintosh at the time. I had worked on the platform that didn't have trash cans in 
the corner, and it was my misconception I think , coming into Macintosh platform, that the Macintosh 
interfac e °', was cute and if you couldn't remember "erase * . you were a wimp. So I was doing things 
that I thought were cute . What I began to learn from these two books besides from Inside Macintosh, 
the reality of computing speed I began t o understand the Macintosh philosophy from the interfac e guideline 
book . So just to outline some of the basic interface objective s which relate to at least my challenge 
in designing th e transparency interface, the interactive objectives accessibility. Accessibility is 
"See and Use" as opposed t o "Remember and Find" . As I mentioned, the trash can in th e corner. "See 
and Use" is "I see the trash can, I drag the folder t o the trash can" . It's easy. "Remember and Find", 
I have to remember, erase, remove , delete whatever it is and then find out how to do it . WYSIWYG 
(pronounced Whizzy Whig) . What you see is what you get. If the interface doesn't give you a preview 
o f what you're going to get, then what's the point of having th e interface . If it's not a realistic 
interpretation of what your nex t actions are going to be, then its pretty useless . Feedback. Data coming 
towards the user . Numbers, as i n the transparency. You want numerical data, you want visua l feedback. 
So that was something to keep in mind. Also delight. I just basically like to enjoy everything I do and 
I thought that the user should enjoy using and adjustin g transparency. So that's something I always 
kept in mind a s well . The visual objectives and these are basic graphic desig n objectives . Communicate 
. Graphic design is to communicate information and if the interface is cute for cute sake, then it's 
not very effective if it's not giving back the information that the user needs . Simplicity . Basic fact 
that less is usually more. Except our sales team doesn't think so . But more is more . Clarity. Is it 
obvious that this is a transparency interface'? If it's not, then it's not going to be used . So what 
I did at this point after beginning to understand these objectives, was to figure out which were the 
minimu m visual elements that I needed to communicate transparency . I was really adamant about wanting 
to use a spectrum of color . I thought that the transparency needed to be shown over a spectrum of color 
. The second element would be some kind of transparenc y indicator and then of course some kind of percentage 
control s to adjust the transparency . So with those elements in mind, I am going to show yo u the building 
of what becomes a lot closer to the en d transparency interface . The scroll bar on the Macintosh is 
to adjust information . So I thought that that would be a good place to incorporate th e spectrum of 
color right into the scroll bar and then I overlai d what was the transparency indicator. As you can 
see while I flip through these slides, that as the user scrolls th e transparency indicator left and 
right, the level of transparenc y inside of the scroll bar becomes less or more transparent giving the 
user the information about the degree o f transparency . This is becoming almost completely transparent 
. Then I added percentages. Again, just the numerical feedback. Then we put it back in the window, and 
it's interesting . I came fro m consumer package design, and the way that we would treat a packaging 
problem was to first work on the package and the n put it back into its environment, which would be usually 
a supermarket shelf and then analyze it amongst the environmen t to see if it worked . What happened 
in this case even thoug h I liked the concept and I knew I was really close i t overwhelmed the interface 
. The bright colors on the pallet were just overwhelming to the user . The second problem which when 
we actually applied th e interface was that the arrow, the pointer used to adjust the scroll bar was 
covering up the information that I wanted to give back to the user. So that wasn't very effective . What 
I did then wa s brought it back to a more typical looking scroll bar and no w when the user clicked on 
the scroll bar the spectrum would po p up, and in this way it was nice because I was actually able t 
o make the spectrum taller and similar to what I just showed you . As you move the transparency indicator 
left and right, the colo r becomes more transparent . Then we put that back in th e window . Again, even 
though we're getting even closer, ther e was one last problem and that was that it was confusing becaus 
e you had then double windows and also the windowing or th e scroll bar metaphor was typically to indicate 
enlargement of a document . So that was pretty easy to solve . We just changed the look of the scrolling 
device . And it actually worked ou t better because we were able to eliminate the arrows which w e felt 
that the user was probably going to actually be clicking o n the scroll bar and adjusting from there 
as opposed to using th e arrows at the end . So we eliminated those and added this scrol l bar, and then 
when they clicked on it, it would pop up again . One last nice thing that was added was that whatever 
you r cu n .ent color for instance, if I'm using red, there's a goo d chance I'm going to make t ransparent 
red text afterwards or a red shape that would be indicated in the transparenc y indicator, whatever 
the color green, blue, yellow  DIGITAL CANVAS : ARTISTS AND DESIGNERS IN THE 2D/3D MARKETPLACE 8 5 
SIGGRAPH '89, Boston, July 31 . August 4, 198 9 whatever it is. So it gave back even more information 
to the user about what they were going to do next . That's it in use i n our window . The product, which 
is actually shipping nex t week, is Pixel Paint Professional from SuperMac Technology , and that's about 
it . That's one example of the interfac e evolution. There are many like that in a lot of our functions 
. Thank you . Moderato r Rachel Carpente r Cinematri x Thank you, Claire . Peter Conn is up next, and 
he and his wife, Coco, began the company Homer and Associates 12 year s ago, and in doing the business 
they've had to build hardware , get and cost jobs, hire production staff, get the jobs out o n time, 
and all of those things, Peter is going to tell us all abou t it . Also Peter did the great SIGGRAPH 
'88 hit, Flying Logos , and I think we get to see it. Do we get to see it, Peter? Yes . Peter Con n Homer 
and Associate s Actually, I'm going to start by rolling the video . A couple rules. No smoking and no 
flash photography, please. (joke to go with the slides) This is a little countdown we just finished for 
the Mexican Lottery . VIDEO TAPE BEING PLAYED- I just put these few animations on here just to show the 
us e of a data base . Everyone after Flying Logos wanted globes, an d we tried to talk them out of it, 
but they just -- it didn't matte r how many globes they saw, they wanted a globe . So we gav e them globes 
. This is a new one we just finished . This is an ink company; they make colored inks. International. 
You can turn the music up for this . - VIDEO TAPE BEING PLAYED­ I'll tell you about that one later . 
This is animation that was done for a Diet Cok e commercial and I put it on here because it's a real 
interestin g simple concept that gets really great response and as a matte r of fact, everyone right 
now wants the same thing . They se e this and they want the Diet Coke look. I mean, this was done -- 
I mean, we didn't even go to 1 inch . This was like 3/4 layoff. This was monitor screens for a commercial 
and it's kin d of interesting because especially dealing with commercial people, they really like to 
see what they get before they get it , and I think the commercial is on after this . So you can see ho 
w these screens were used . -VIDEO TAPE BEING PLAYED You can stop the tape there . Basically I thought 
 no t really knowing what to talk about I would kind of tell yo u my story and you can deduce anything 
you want from it, bu t this is kind of what happened to me and it's just one little story . Twelve years 
ago we started this company Homer an d Associates and for many years we did music videos, some industrials 
. We had a slide animation system we were workin g on and did a lot of live action, but we were really 
known for integrating special effects with live action ; that was the bi g thing. And we started building 
our own computers during tha t time, and we built a customized 24-channel visual mixin g console which 
allowed you to do animation effects using slide s and a real time joystick, and kind of got us into computers 
. This was definitely in the early days and the big change tha t happened was that at one point we wanted 
to put in a one-bi t frame buffer and we saw an ad in the Recycler which is like the place you buy your 
couches and refrigerators and stuff for a n eight-bit frame buffer. So we bought that and a paint system 
. This was like in 1980 . Actually, Paul Rather wrote it . He's i n the audience here . And we had ourselves 
an in- house pain t system . This was just when Quantel Paint Box was coming out . And we developed a 
system where you could take slides an d using a motion control camera, you can move across them , digitize 
them, and do a lot of effects using color levels an d color map cycling and it was all custom software, 
and it worked great. It had a real funky look to it, and 3D was just like a dream at that point . We 
weren't even thinking about it . I guess it was in 1983 I did a music video for Steve Mille r called 
Bongo Bongo and there was a machine that had just com e out then, the FGS 4000, which was the first accessible 
3 D machine. They have them in video facilities. And basically I took a few shapes that people were doing 
logos with, some tetrahydra and stuck them together and made a character and di d some primitive character 
animation, integrating with liv e action . But it was great . I thought this is really neat stuff an 
d I've got to do this. So I went to Bosch School and learned how to operate th e machine and the next 
few years I would operate around town . There were a couple of them . And I learned 3D by doing this 
. The Bosch is a really awkward machine, but it really made a good learning tool because everything after 
that was so much easier to use . Then actually getting into 3-D in-house was really almos t another accident. 
It was 1986 in SIGGRAPH and I kind of cam e around the corner of this aisle and I saw this couple of 
guy s with this system there, and they had this chrome donut wit h this chrome ball going through it, 
doing an environment ma p of this fractal landscape, I went, "Woa that does that on a PC?" That's when 
we bought the first digital art system, an d they were just starting it then. But I wasn't really looking 
to buy hardware because this was around the time where all the bi g computer graphics companies were 
going under and I wasn' t planning to get into it . But at that level, if that system did tha t kind 
of animation, I thought I could do something an d especially since the Bosch was always a big problem 
because i t couldn't do metallics and that's what everyone wanted reflections and everything . So we 
got the first system and basically it just kind o f built up from there . I had an advantage because 
in 12 years o f doing work I had a lot of contact, so it was a lot easier to buil d up a reel from almost 
nothing . Most of the Flying Logo s animations were done during the first year, year and a half. And 
we built up after about a year, added a full-time technica l director, Michael Cory, and just started 
getting more jobs an d developing our techniques . Since then we've added several other systems . We 
adde d two Digital Arts. Then just recently we added an IRIS with Wavefront to do animation, and now 
we have a transputer base d renderer running the Digital Arts RenderMan code, and that' s actually a 
brand new thing for us . But it's a system that we'v e  DIGITAL CANVAS: ARTISTS AND DESIGNERS IN THE 
2D/3D MARKETPLACE SIGGRAPH '89 PANEL PROCEEDING S developed that works for us, and hopefully it does 
. Were all putting it together right now . And everything is ethernette d together and were able to turn 
out quite a bit of animation o n what a lot of people would call kind of small machines . A couple of 
notes here . Certainly one problem I alway s had selling animation was the idea that we were working 
o n PCs and competing against companies that had much fancie r hardware and the way I came up with the 
basic ways to get around that . When they asked what kind of hardware you had , you always kind of said 
something like 32-bit workstation . You just basically it really worked quite well . I totall y avoided 
the issue of hardware . A lot of people, I would never even show them th e hardware, and I learned actually 
from years before when we ha d built this line animation system . We had put it in this giant oak console 
and it had like 3,000 LEDs on it and I thought thi s is really going to impress them, and it didn't matter, 
becaus e you find out that clients really don't know anything abou t hardware and really aren't impressed 
by it. If you don't show i t to them, it's just as well. And if you clJ, they don't know wha t they're 
looking at anyway . So you can tell them anything . Clients. Usually the problem is they don't really 
kno w anything about 3D animation . So you have to kind of hold their hand . We use -- I don't have an 
example of it -- but w e have a 3D flow chart that I developed that kind of shows all th e steps of doing 
animation the storyboard, the ink coding, th e Wireframe, the test lay-offs, the rendering. And it's 
actually a sign-off sheet. Now I sit down with them and I go, "These ar e all the steps ." It actually 
makes them more comfortabl e because they think they understand . Let's see . Costing jobs . We're supposed 
to talk about that . I don't know . It's a black science, as far as I can tell . I mean, certainly when 
you're making animation, there is labor , but it's not I mean, you're making pixels. So it's a little 
different. You have creative fees, you have amortization of the equipment you've got to figure, and also 
you've got to figur e what if you take one job, what are you going to pass up because you only have 
so much capability . Basically the way I have approached it ; it's worked for inc . You can do what you 
want. But we started small and we built and then as we had some minor successes we added mor e equipment 
and more staff and we're still just taking it easy . I mean, people have done other approaches where 
they go ou t and buy the fanciest most equipment you can, and certainl y there is a trade-off there . 
You have to always figure o n efficiency because in some ways hardware is cheap. If you r hardware is 
going to hold you back, it can cost you a lot mor e in the long run . Jobs and opportunities . I always 
see people basically we're looking for people who have significant 3D capability . Both of the full-time 
people that work for me now worked o n large systems and they brought that experience to our place . 
3D is something certain people are better at than others an d even when you're good, you need a lot of 
experience, a lot o f time, a lot of production problems because you just in ever y system you learn, 
it's very easy to learn another system after that . So it doesn't matter if you know Digital Arts or 
you kno w Wavefront you can learn it if you've known other systems . But it's hard getting started because 
you don't get access to th e equipment and so on. But we're always looking for new peopl e to use . I 
don't know . That was basically all the notes I had . It's a real exciting business . You don't get a 
lot of sleep . I usuall y play cleanup man, which means I don't do the animations, but when it gets down 
to the end and the deadline, you know, I' m dealing with the client. I go in and jump on there and help 
ge t things composited and laid off to video, which is always th e last step . And it's pretty exciting 
and we expect to do -- righ t now we're doing mainly commercials . We kind of went throug h our flying 
logo stage and now we're doing commercials . We'd actually like to do music videos again kind of come 
ful circle around there because I think as we get rendering up to a place where we can put through a 
decent amount of animatio n and we start developing character animation a little bit more, I think there's 
a lot of things you can do in longer form pieces . That's it. Okay. Moderato r Rachel Carpente r Cinematrix 
Last but not least Vibeke Sorensen . Her background i s primarily in architecture and art . Her range 
of experienc e includes producing computer animation and synthetic music , performance art, 3D stereoscopic 
imagery, teaching compute r animation, and working with scientists . She has shown he r work widely and 
has frequently collaborated with other artists . She's currently teaching at Cal Arts and consulting 
with San Diego Supercomputer Center . She's also got a piece in the art show, which I hope she'll tell 
us about . Vibeke Sorense n California Institute of the Art s Could I start with slides, please? I've 
done some desig n work in computer graphics, and among other things, variou s Christmas cards, including 
these two pictures for Rolland Synthesizers two years in a row . And also I've worked on a couple of 
Omnimax films . This one is the Magic Egg, which I believe has been or is being shown in context with 
thi s Conference. And a film called The Seasons, in which I modele d two models of the solar system 
the Copernican and then th e Ptolemaic, and by the way, in doing that I rediscovered th e solar system 
myself. There are a lot of issues relating to that , but I don't really think I have time in the 10 minutes 
to talk about that . Recently I worked at the Jet Propulsion Lab in Pasadena on a Mars Rover animation 
project in which I created a model of a robot arm prospecting on Mars, and I'd just like to show you 
a little of that. It's about 20 seconds. Can we go to the tape , please? VIDEO TAPE BEING PLAYED Okay, 
that's it; please stop the tape . Please stop the tape . Primarily though I teach for a living, and this 
is b y choice. This is the Dean of the School of Film and Video, E d Emshwiller, working in what was 
one of our first set-ups in th e lab. DIGITAL CANVAS : ARTISTS AND DESIGNERS IN THE 2D/3D MARKETPLACE 
  SIGGRAPH '89, Boston, J 31 -August 4, 198 9 technology, and in many ways though secondary to the goal 
o f art making for art sake, Art is greater than or equal t o applications . I am defining art making 
as a desire to transform or reflect the world as a visionary sees it . Artists should thin k of themselves 
not only as designers, but as researchers an d pioneers in technology . They should apply for and receiv 
e positions in industry and academia side by side with compute r scientists, and work in tandem with 
these people doing thei r own work as well as the work of others . Artists are expert a t visual language 
and visual communication, and in essence ar e doing research in visual language and image creation frequently 
the same work as the scientists, but for different reasons . Artists have an important contribution to 
make to the new field of scientific visualization . Artists are highly educated an d innovative intellectuals, 
in addition to being organizers o f visual information. And scientific visualization artists function 
beyond illustrators, applying their creativity to ne w information . The National Science Foundation 
report last yea r describes this . Donna Cox of NCSA National Center fo r Supercomputing Applications 
 is setting an excellent example . She and her colleagues have pioneered th e renaissance teams, which 
bring together artists and scientist s in joint efforts in scientific research, specifically the visua 
l representation of multi- dimensional data . The "Art to the Nt h Group" in Illinois is also active 
in the synthesis of art an d science. At the San Diego Supercomputer Center, there is a n effort to bring 
together artists and scientists, includin g Holiday Horton, who is working with scientists on variou 
s visualization projects, and myself as well . I am currently collaborating with Dr. Lynn Teneyck, a 
crystallographer, on a research project in interactive stereoscopic animation, funded by the National 
Scienc e Foundation . I just talked a bit and showed you about my work this summer at the Jet Propulsion 
Lab . This experience was a delight for me on many levels, since I felt I was helpin g science while 
at the same time educating myself . Contrary to popular opinion, research fine artists and research fine 
scientists share a great many concerns an d sensibilities, and are able to truly enhance each other's 
work i n profound ways . There is a natural link between the two, a natural desire to share ideas, vision 
and expertise . And scientific visualization is an area where I feel the artist a s intellectual, the 
artist as interpreter of complex data and concepts is well suited and integrates smoothly. Fine artists 
are also good and necessary role models for th e next generation of computer graphics professionals . 
Let us no t forget that education is an important and respectabl e profession . Not only is this a way 
to give back to a society i n a world which has provided for us, but it is also a way for us t o pursue 
unbeholden except to our highest ideals the pu rest goal s of our creative minds. For many artists intellectual 
freedom i s worth more than the difference in pay scales between variou s jobs. Further, to ensure the 
longevity of the field, whic h ultimately will sustain each and everyone of us, it is vital tha t the 
field continue to transform itself in tandem with society . Since artists are also the mirror of our 
time and the conscience of our culture, artists are in a way a shortcut to the sometime s elusive knowledge 
about society . But be aware that the truth is sometimes painful and tha t the predictions of visionaries 
are confirmed only in the future . That at the time of invention a new work or idea may not b e immediately 
valued . It may seem worthless, but actually be worth a million . Have the courage of your convictions 
and yo u will probably not be disappointed . Even if you do want to do commercial work because i t seems 
guaranteed, keep in mind that popular culture is based on change always a new look. The best way to 
be remembered is to innovate, not imitate . By refining your personal look , you become more unique and 
therefore more marketable . The very best designers are also fine artists . Keep up your dreams and your 
integrity . If you are a goo d artist, you will have many opportunities . You can choos e according to 
your value system, and you may even be able to create a more compatible job for yourself than you eve 
n imagine possible . For example, study a company o r environment . Figure out how your expertise can 
enhance an d benefit it, and make a proposal . You may be surprised with th e results. Realize that our 
time on the planet is limited, that time is our only hard currency, that no matter how much money we 
have we cannot buy back the time that is gone . Weigh your choices carefully and choose the path that 
passes what I call the "80-year-old test" . Will you be proud of what you did with you r life when you're 
80 and looking back over it? Anyway, that' s what I have to say . Moderato r Rachel Carpente r Cinematri 
x Now I know we've taken a little bit of time here, and so I want to remind you about the breakout room, 
which is going t o be in J. We do have time for some questions, We don't have to be out of here until 
3 :15 . There are mikes around the room and I will try to see you if you have a question for any of us 
 fo r Claire, John, Peter or Vibeke, or myself, Rachel go to th e microphones and I will try to be systematic 
about it . Are ther e any questions? Over there? Yes ? Q. I've got one here. (INAUDIBLE NO MICROPHONE) 
CARPENTER: I would like to ask you to first to clarify for what. Q. For (INAUDIBLE NO MICROPHONE ) DERRY 
: I think the main objective is to come into contac t with the people who you can communicate with . 
There are probably . I don't know what your environment is like . But there are researchers at various 
industries not jus t universities . But a university is a great place to find thes e people. And that's 
certainly been the resource that I've sought . Q . How about for the rest of you? You talked about you're 
a little more commercial . California are we talking abou t California as the hub of the planet here 
? BARRY : I was raised in Sunnyvale, California, right in th e heart of Silicon Valley, and I think that 
it certainly did impac t how I developed as an artist, how I was able to be logical an d creative at 
the same time . It was okay because everyone on m y block was an engineer growing up . I didn't know 
until I wa s about 12 that everyone's father wasn't an engineer . So being in a hub of technology like 
that, certainly as a n artist growing up, definitely made me not afraid of math and science . DERRY : 
I think for myself too I'm from Nebraska . Mos t people know Nebraska to be that wide spot in the middle 
tha t you drive through on your way to either side, The firs t intrusion for me into computer graphics 
was I think NCGA o r SIGGRAPH five or six years ago. Once I saw that I realized I knew I wanted to get 
involved with it, and I had to figure out a way how and it became apparent to me anyway that the Ba y 
Area or Northern California is one of the hot beds of compute r DIGITAL CANVAS : ARTISTS AND DESIGNERS 
IN THE 2D/3D MARKETPLACE  SIGGRAPH '89 PANEL PROCEEDING S graphics. There are several of those hot beds 
around th e country, but for me, moving to the Bay Area was one way to ge t close to all of the resources 
and other people that were involve d in it. So for me it required a physical relocation . DERRY: A lot 
of it will have to do with applications. Well , obviously, video, Southern California is probably mor 
e appropriate . Were graphic design, San Francisco and Ne w York. Advertising, New York . So application 
would have a lo t to do with it as well . But it certainly isn't the way it was fiv e years ago . There's 
a lot of access to education now . Seven years ago it was MIT, NYIT and a couple of other technologica 
l schools . Q. How does one find out about the different schools to go to ? CARPENTER: You can refer 
to that Volume 23, that I wa s telling you about before, of the ACM, go to the educatio n booth, and 
the list of schools there . You can even write letter s to people of what you're interested in . Is there 
another questio n in the center? Front center ? Q. My question is for Peter. He's talked about having 
difficul t clients and a sign-off sheet . Is there a possibility of getting that sign-off sheet or copy 
that sign- off sheet ? CONN: Yes, if you see me afterward, I'll get you a copy . CARPENTER: Is there 
a question in the back center ? Q. Yes, there is. I tend to be I'm working with Macromind animation 
product, and I've come out from a perspective of a frustrated artist-programmer, and so I tend to from 
m y experience of being within this animation company, is reall y my first real interaction with an artist 
being at my side an d actually using the product simultaneously as I'm programming it. So I would like 
some feedback as how soon should I reall y start bringing in an artist onto product design and what woul 
d and if I was going to hire an artist, what would I what kin d of background should I be looking at 
and what as I as a computer scientist should have in order to elevate myself as a better artist or a 
better builder of tools for artist ? DERRY: I'd say right away, bring the artist in on clay one . I work 
at Time Arts . We develop software tools and part of m y role there is kind of be an in-house artist 
. It's been amazing t o work with programmers . They'll come up with genius leve l tools or ideas about 
how to manipulate an image, but generall y where they sometimes will go a little off from an artis t 
perspective is in the interface of it . Claire's example that she showed earlier was one of those . When 
there's an artist in ­house that can be first of all just right there as a direct feedbac k to test out 
the tool, that's very valuable to the programmer . Several things that I've worked on I mean they were 
just on e degree off of being a really great tool, and it just took an artis t to sit and talk with the 
programmer about their ideas and realiz e that a little bit of slight changes could make that tool exactl 
y what an artist would want . Later on it got to the point where I could actually come u p with tools, 
and having kind of a clear understanding of wha t goes on underneath the hood, you can start to work 
more directly with the programmers to shape tools together . So to me, the artist is a very important 
 if you're going to desig n tools for artists, you better have artists designing them . CARPENTER: Okay, 
I think there's another question on the side here . Q. I have a question for Ms. Sorensen. This is a 
question I' d like to ask one of the visualization, scientific visualizatio n panels of tomorrow . I've 
heard what comes down to tw o different points of view I think, on the role of the visual artis t in 
scientific visualization . So I'd like to pose this to you a s somebody who has worked in that field 
in an academic context . What I've heard is both a "renaissance team" concept and something that's counter 
to that, as far as eliminating the need for a renaissance team by putting all of the software tool s 
directly into the hands of the artist I mean, into the scientist and that would seem to me to somewhat 
the diminish the rol e of the artist in working directly in the creation and exploration of images for 
scientific visualization, and I'd like to, I guess , ask you how you see the role how you see the role 
of th e artist within a scientific visualization context increasing o r diminishing given those two 
points of view . SORENSEN: Well, considering how much there is to grow, it can't help but increase and 
grow . And I think that considering the level of education of many of the artists their role is no t 
entirely defined and limited at this time . I think it's good that scientists, for instance, have a good 
art background, and try t o learn more about visual language and communication an d aesthetics so that 
they're able to take on some of the work tha t artists do. I don't think that's a threat to artists. 
I think in fac t that what the next generation of people will become is kind o f artist-scientist, where 
some artist may learn enough science a s well. That's a bit idealistic, I know. But it's certainly not 
impossible . Educational curricula have to develop to allow fo r this . I also think that there are plenty 
of people who are s o focused in whatever discipline they're in that they just find it a better use of 
their time to collaborate with somebody who ha s the expertise in the needed field . I think that's going 
to create a continuing need for artists . I don't think that's going t o change all that much, considering 
the size of the field . CARPENTER: We have another question front, center . Q. It's a fairly philosophical 
question, so I expect a philosophical answer. In part you've already answered it . CARPENTER: Could you 
speak a bit more loudly, please? Q. It's a philosophical question in a way, and it's partiall y been 
answered just now. To what extent do you think in th e future the role of an artist and a scientist aren't 
going to b e completely separated, but they might come one discipline i n itself that integrates the 
two areas . When is that going t o happen? And it's going to happen through education I suppose and what 
can we do about it ? BARRY: I think all of us being here are doing a lot about it . I do believe it 's 
happening now . CARPENTER: That's SIGGRAPH . Q. Everybody still talks about an artist here and a scientis 
t here as two separate entities, as opposed to one . SORENSEN: I would just say that I think the best 
thing is fo r the two groups to establish constructive dialogue whether it's through formal education 
or informal contacts . I think there is so much common so many common interests tha t it's such a natural 
interaction and I like that it's not there' s no one solution . There are many solutions . And I think 
it' s that kind of grass roots widespread movement that's going to accelerate it, So I think it's an 
inevitable . But it can be accelerated even more by educational programs . CARPENTER: Is there a question 
on the side over here ? Q. Yes . This is for the whole panel . I'm an engineer and I' m exploring uses 
for a recently developed technology and the question is there a need for more realistic input tools in 
th e graphic arts world? For example, the ability to hold a stylus i n your hand and that stylus would 
feel like, act like and emulat e an airbrush, so that you could but instead of depositing pain t on 
paper, you would deposit pixels onto the screen . But as yo u move the airbrush closer and further away, 
the pattern change s  DIGITAL CANVAS : ARTISTS AND DESIGNERS IN THE 2D/3D MARKETPLACE SIGGF;APH '89, 
L3oston, July 31 -August 4, 1989 --just like a real airbrush . Is there an interest from the artist i 
n those types of tools ? DERRY: There definitely is . I think if you walk around the show floor this 
year, you'll see this is the year of the pressure sensitive tablet . There's some breakthroughs in th 
e technology of using a pressure sensitive tablet, and it's early i n its implementation. But our company, 
among others, have integrated this pressure sensitivity with the paint tools so tha t they do start to 
provide a very natural feeling toot to the artist . And it's just at the beginning . I know there are 
tools on the drawing boards that will allow you to sense rotation and angl e and like I say, this is 
the year of the pressure sensitive tablet , and probably within a couple, three years I would imagine 
any really high level paint system will have a full pressure sensitive set of tools in it . So I think 
you're going to start seeing that happen quite a bit . BARRY: The main advantage of having something 
like that is to be able to take advantage of the familiarity that yo u already have with tools, so that 
the traditional art tools tha t you already know how to use, you'll be able to transfer thos e skills 
to your computer experience . I think it will be actually interesting once everything is done on the 
computer. Where do we go from there when we have special computer tools? That's something that I' m looking 
at . CARPENTER: I think we have time for one more questio n and then we will migrate over to Salon J, 
which I guess is dow n that way . Yes? Scott? Does anybody know which way is it ? Yes that way. Okay, 
I think there is another question over here. Yes? No? Q . Yes . For anyone who would care to answer, 
I am part of a company; I'm a programmer for a company who's making it aspires to make a tool for people 
making animations vide o animations and it's my understanding that most of these, the soundtrack comes 
first and then the video is created to matc h the soundtrack. I wanted to know, am I mistaken in tha 
t impression? Or if not, what are the problems associated wit h reversing that procedure? Does anyone 
know ? CONN: Yes . It works both ways . I mean sometimes th e soundtrack is first and you work it, and 
sometimes yo u postscore something . Actually, the best method is to go back and forth where you do like 
a rough soundtrack, and then you d o your visuals or rough visuals, and then you go and you do more refined 
soundtrack, and you keep a feedback loop goin g between the two so they can feed off each other and you 
get th e nicest integration of sound and picture . CARPENTER: Okay, thank you very much. We need to clea 
r out now. There is another panel following us . DIGITAL CANVAS ; ARTISTS AND DESIGNERS IN THE 2D/3D 
MARKETPLACE 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>77282</article_id>
		<sort_key>93</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[The multi-Media workstation]]></title>
		<page_from>93</page_from>
		<page_to>109</page_to>
		<doi_number>10.1145/77276.77282</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=77282</url>
		<abstract>
			<par><![CDATA[<p>Good afternoon, ladies and gentlemen. Thank you very much fortaking time out from the parties to join us for one of theperipheral activities of SIGGRAPH. As you know, the panel thatwe're going to be holding this afternoon is entitled theMulti-Media Workstation. Before I make some introductory remarks, Iam required to make some administrative remarks.</p><p>The first thing is to remind you that the proceedings of all ofthe panels are being audio taped this year for subsequenttranscription and publication. What that means, is that when wehave the audience interaction, please come to the microphones thatare scattered around the floor to make your remarks. Otherwise, Iwon't be able to recognize you.</p><p>The second thing I want to mention to you is that when we'redone at 5:15 we are going to vacate the stage. We're going tovacate the room so the AV people can lock up. If you want tocontinue discussion with us, there's a breakout room that's beenset aside, Salon J, which is down around the corner. So join usthere please, because we'll be scooting out of here right away.</p><p>Finally, I need to tell you that the --- for those of you whoare involved --- the Pioneers Reception will be held between 6:00and 9:00 at the Computer Museum this evening, and buses will leavefrom the Boylston Street exit of the Convention Center at 5:00,5:30 and 6:00. Absolutely no video or audio taping allowed at thePioneers. You don't want to hear any of those old reminiscencesrepeated.</p><p>Let's get on with the business of the afternoon. Multi-MediaWorkstations. A couple of preliminary remarks that I think all ofmy colleagues up here will agree with. The things that we're goingto be discussing this afternoon do not represent fundamentally newtechnologies. You've been able to buy add-in video cards and audiodevices for personal computers and workstations for some years now.What we are going to be addressing is a confluence of manytechnologies --- hardware and software --- that has finally made itpossible to envision a fully integrated system that willincorporate all of these multi-media capabilities. So we're givingyou a vision of maybe not what you're seeing at this year'sSIGGRAPH, but certainly a SIGGRAPH or two from now, I canconfidently predict that you're going to be seeing workstationsthat incorporate the kinds of capabilities that you'll heardiscussed this afternoon.</p><p>I should also emphasize that we are not here to give the kind ofa presentation that you might expect from a group of folks --- fromthe Media Lab or from Xerox PARC who are going to tell you aboutsome of the far-out kinds of things that they're working on. Iemphasize again the technologies that are being described thisafternoon are almost here and now, and will soon be available toyou.</p><p>Now let me make some comments about how in my particularenvironment I came to be interested in the concept of a multi-mediaworkstation. I think each of us will probably have differentstories to tell about why multi-media is important to the kinds ofapplications that we're involved with or envision.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>B.4.2</cat_node>
				<descriptor>Data terminals and printers</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010594</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Printers</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31092379</person_id>
				<author_profile_id><![CDATA[81100520747]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Phillips]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Los Alamos National Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P218262</person_id>
				<author_profile_id><![CDATA[81100419778]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[P.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vais]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NeXT Computer, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P256076</person_id>
				<author_profile_id><![CDATA[81100008231]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[S.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Perlman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Apple Computer]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P154071</person_id>
				<author_profile_id><![CDATA[81100425739]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lantz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Olivetti Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P182687</person_id>
				<author_profile_id><![CDATA[81332521114]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Picco]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Parallax Graphics]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
  SIGGFAPH '89, Boston, July 31 -August 4, 1989 an external microphone plug, so its an analog channel 
into th e computer that can be utilized . We use an 8-bit mu law encoded quantization on the soun d input. 
The sampling rate is 8,012.8 hertz, which is generall y accurate enough for voice and for speech type 
of applications . Obviously, it's not adequate for something like concert hal l music, but it works pretty 
well for voice . It's also relativel y compact compared to some higher resolution sound formats . The 
output side of it, on the other hand, is a higher qualit y sound capability and we have a D to A converter 
 digital t o analog converter in the monitor as well, which is just lik e the one you would have in 
your home CD player . And it's ful l stereo ; it's a 16-bit quantization, and the sampling rate is 44 
. 1 kilohertz . So it's a lot more accurate, and that is in fact th e format of data on compact disc 
players today . To put that in perspective, sound data in that format i s generated at a rate of about 
176,000 bytes per second . So it's a pretty big amount of data to work with . In the monitor is a monaural 
speaker as well . There is a volume and muting control on the keyboard, and there is gol d plated RCA 
line-out jacks on the back, just like the ones on the back of your stereo, so you can plug it into your 
Klipsch corne r horns at home or whatever you might have . In the interest of supporting industry standards, 
there's a Walkman compatible headphone jack on the back too . So, that's basically it for the hardware, 
and I'll b e demonstrating that in a second. The software -- there is you may or may not know, bu t 
the NeXT system is based on object-oriented programming too l kits, and two of those are specifically 
used with sound th e sound kit and the music kit . The sound kit allows programmer s to incorporate 
sound effects into their applications relativel y easily. It allows easy access to the microphone and 
allow s programmers to examine and manipulate sound to the en d purpose of their application . It's primarily 
used with sampled data but it is compatibl e with DSP synthesized data as well . The NeXT system has 
a digital signal processor on board, which can be used t o synthesize sound real time again generated 
in the CD format . The sound kit allows programmers again to manipulate sound files which are stored 
images of some sound . Now the music kit, on the other hand, is used to compose , store and perform music, 
which is of course, a collection o f sounds . But the music kit communicates with external synthesizers 
through a MIDI interface . It's similar to a soun d manipulation, and bottom line the music kit helps 
musicians organize sounds for performance and composition . What I'm going to concentrate on in the demonstratio 
n part of it is really the sound kit today and I'll play some examples of the music, but the software 
that I'm going to be demonstrating is a mail program that we deliver with th e system, and it's kind 
of indicative of what we expect to happe n in the future in integrated media applications . So I'm going 
t o take a step back here to the system and put on the othe r microphone. APPARENTLY MICROPHONE IS NOT 
WORKING -­ . . . special window, and it immediately images that bi t map into the mail message . I can 
also put in documents that perhaps are from differen t applications in this case a WriteNow file . If 
I drop that i n there, if I double click on that, my mail message, it wil l message right now, and the 
word processing program will pop up in a different window in a different process always on the same 
computer, of course, but this is another program whic h has been tied into that mail message . In general, 
any kind of data file can be integrated into thi s message, which is quite a powerful feature for communicatin 
g with co-workers, for example, or colleagues . To put a voice attachment into it, you bring up the Lip 
Service menu here . I've got a little microphone plugged in the back. We can just do a small test: Welcome 
to SIGGRAPH . "Welcome to SIGGRAPH . " Now, if you don't like the way that came out, you can g o ahead 
and edit it. This is part of the sound kit, the ability t o edit those things . "SIGGRAPH ." I'm just 
going to cop y something and paste that in there a couple of times . You can kind of make yourself sound 
like Max Headroom. "Welcome to SIGIGIGGRAPH ." And when I attach that in, it actually drop s that little 
Lip Service icon in there and you could say listen t o this, something, whatever. That's basically how 
that works . If you want to take a high resolution sampled score file , this is a excuse me ; a sampled 
music file this is a Vivald i selection. Essentially data stored on the system in CD format just to 
give you a taste for what that sounds like . It fires u p the sound player, another application . MUSIC 
PLAYING You can make some pretty compelling mail messages wit h this . Let me quit that, and let's see. 
That's basically what I wanted to show in terms of the mail . I'm running out of time here, so I'm going 
to show you just a couple more things . I'm going to quit the mail program, give you an example of wha 
t the synthesized DSP music can sound like, and this is some stuff that you could presumably integrate 
into applications a s well. This is real time synthesis on the DSP . MUSIC PLAYING That 's the score 
file . That's the program that's generating this music . MORE MUSIC Sorry I had to cut that off; it's 
a nice piece . The last thing that I wanted to talk about, and show you, i s a project that came out 
of Carnegie Mellon University and thi s is the Sphinx speech recognition project, and this is reall y 
going to be a landmark project we think . It's continuou s speaker-independent speech recognition, and 
what it allow s programs to do is basically given a vocabulary, take spoke n speech input and come up 
with words out of a particula r vocabulary. There's speech recognition systems out there tha t are faster 
and more accurate, but they're not speake r independent . Pretty much you can walk up to this one cold 
and star t talking into it, and it gets about 95% of what you're going t o say. This is a very preliminary 
version of it and all I'm goin g to do is speak a few words into it and see how well it does . Thi s 
particular data base is designed for spreadsheets. So there are going to be numbers. It takes about 45 
seconds to load here , which is probably about as much time as I have left . But onc e it's up, it will 
be pretty interesting . And we think that ove r time this type of capability will be very pedestrian, 
if you will , on the system . Okay, let's try it . (Speaks 1,196) . What it' s doing is it's going out 
and doing an analog conversion of tha t THE MULTI-MEDIA WORKSTATION SIGGRAPH '89 PANEL PROCEEDING S voice 
that came in, and comparing it to its data base . And here comes the result, 1,196. (Computer speaks 
"1,196") . So pretty much anybody in this room can walk up to thi s thing and get these kind of results 
. So this type of capabilit y is really going to have an impact on a wide variety o f applications. That's 
basically all I have. So I'll turn it over t o you, Dick . Moderato r Dick Phillip s Los Alamos National 
Laboratory Thanks very much, Paul . Our next speaker is Stev e Perlman from Apple Computer who will be 
talking about som e of the multi-media activities that Apple has been involve d with. Steve? Steve Perlma 
n Apple Compute r Hello . Was there anybody out there who had any doub t who was the one from Apple? 
Oh, come on, be nice . I'nm here to talk about the evolution from the current worl d of desktop publishing 
where we are today, to a future world of desktop media or multi-media whatever you want to call it 
of the future . Right now desktop publishing is a reasonabl y mature technology. I mean, on the Macintosh 
and other machines you can do a pretty good job without knowing to o much about what's going on . You 
can integrate all differen t kinds of static documents and things like that, and put togethe r some really 
great slides or really great printouts . And when it comes to multi-media, as Dick was saying, yeah, 
okay, you ca n do animation, you can get video overlay, you can do sound things like that although we 
saw some very nice soun d integration, trying to get the video and the sound and all thes e things working 
together is still not as smooth a job as we ca n do today with desktop publishing . So, to talk a little 
bit about the process, if we look where we've just come from, with desktop publishing we start ou t with 
static documents, and you can just scan something in o r bring in some clip art from a disk or perhaps 
capture it with a camera, you integrate it into the computer and then you produc e some sort of printed 
output . The computer is essentially th e integration place where things meet. You can think of it as 
an application integrator in a sense, and it does a pretty good job . If you look at the scanner, for 
example, that only handles stati c documents. But something like the video camera could actually bring 
in dynamic information . But in fact, all we do is usuall y grab one frame, dither that frame, whatever 
we want to do or grab the thing whole in color, integrate it with our document , and then the only thing 
we can print out is a static document. The page doesn't move, the slide doesn't move . So where we'd 
like to get to is where we can now deal wit h dynamic documents, things that change in time produc e 
sound, produce video, have all the things worked together. So if you look at what the world will look 
like then, now wel l have input from disk of dynamic information . Also, video input for video disks 
, LIVE VIDEO DEMO VCRs and cameras, and you'll see live information on the screen, just as you saw there 
. Essentially what you'll be compositing together i s moving stuff stuff that's really happening while 
you'r e manipulating it . And your output document instead of bein g  THE MULTI-MEDIA WORKSTATION a 
static page or a slide will be say, video to a video monitor , or something that you record on a VCR 
and give to your friend s essentially a desktop video that we were talking about . Or use something you 
use with a video projector like you're seeing here . Now to move to the next section . I'm going to need 
a biological video switch called Dean. We sort of brought a second Macintosh here without giving them 
much warning . S o could you come and switch to the other machine? Okay, great . What I have here is 
a prototype that we developed tha t we're using in our research at Apple, and it's essentially thi s 
big box that's sitting on top of a Mac II . It's a couple of board s plugged in there. I was going to 
call it a black box, bu t considering what else is up here on the stage, I think I'l l choose a different 
color . But no, seriously hey, come on . Be nice; be nice . Essentially what this technology allows 
us to do is dea l with things that are moving objects that are moving on th e display pretty much as 
easily as we deal with static objects , and that's a big thing especially when you're dealing wit h 
large things that normally involve large movements o f memory . Sometimes when we were moving the windows 
around th e screen with the NeXT machine; things would kind of shake a little bit or break a little bit. 
And we have the exact same problem with Macintosh . So what we developed is this technology here and 
you ca n see you move this around ; it's no big deal . It's just a one bit pe r pixel window . Again, 
we can do th e LIVE VIDEO DEMO -­ scrolling in real time. But we can actually scroll thing s that are 
moving . And it all runs dynamically and in fact of course, you can have sound clicking on it . And 
nothing slow s down because the whole thing is working . Now what's interesting about this demo is everything 
I' m showing you here we could do on a Mac Plus, not just on a Ma c II. We're not really using any of 
the processing power of the 68020 . In fact, if you have say captured video, this is an 8-bi t per pixel 
window . So now you have an 8-bit per pixel objec t together with a couple of one-bit per pixel objects 
. LIVE VIDEO DEMO Nothing slows down because the load, the number o f objects on the display, no longer 
defines the amount of time i t takes to draw it. It's real time by definition. In fact, we can even do 
Eric Headroom if you'd like. That's Eric Hoffert;, he jus t gave a paper in the hardware section . In 
fact, you can do all different color depths . The syste m we have actually will support one, two, four, 
eight and 32-bit s per pixel . And of course, all the user interface stuff happens i n real time, and 
all the different things will work at the sam e speed . You can see it doesn't slow down just because 
you hav e more stuff going on on the screen . It all runs in real time . The next demo I'm going to show 
you I'll show a littl e animation. This is showing some digitized stuff, some captured stuff, that's 
a little bit compressed, so we can store a lot of frames, and play them back from the film show, He 
r Majesty's Secret Serpent, done by Gavin Miller and Michae l Kass at Apple. What's neat about this is 
I'm going to show yo u how once we have these images digitally stored in the system , because of the 
way the hardware can deal with the stuff pretty     SIGGRAPH '89, Boston, Jul 31 -August 4, 198 
9 integrated environment is everything in one location . I don't want to have to deal with a variety 
of different ways o f representing the same signal . Q . Sorry to interrupt, but the question that the 
gentlema n from Apple wasn't sure if he could reveal I happen to kno w that's public information. My 
name is Greg Wallace from Digital Equipment Corporation and I'm involved in imag e compression standards 
. There are two standards of interes t along the lines . There is a still frame photographic compression 
standard which is a joint group of ISO and CCIT T known as JPEG, and that's for high resolution still 
fram e images. There is a sister sub working group within ISO called MPEG, for the Motion Picture Experts 
Group, and that's the on e that you were probably thinking of as a potential DVI competitor some day 
that's likely to be symmetrical . PHILLIPS : Thank you. Gentleman in the center aisle here . Q . Thanks 
. My name is Dave Backer ; I'm writing for Ne w Media News. This is for Steve: Great demo . Can you say 
a little bit about what's going on in the hardware or can yo u characterize it generally, and can you 
say something about th e software that you used to create the demo ? PERLMAN: All the software is proprietary, 
including th e stuff the well, it's proprietary, but it's compatible wit h existing Mac stuff, so that 
you'll be able to upgrade it . Those are just PICT files, things like that, that we were showin g there 
.  Then the other thing is the hardware is something w e designed and it's also real compatible with 
all different kinds o f stuff and it works at all different video rates coming in an d going out, etc 
. It's kind of a new thing we developed that' s actually quite different from other things that we've 
seen . So it's kind of hard to compare it really without going into a lot o f detail about it . PHILLIPS 
: Question from the gentleman over here on th e right . Q. Thanks. I'm Mark Lapp from IBM. My question 
comes from the need for synchronization between video and audio an d all of these various things going 
on, and that leads you to th e need for an open standard for defining for variou s manufacturers . The 
question is if one wants to push for such a standard, is there a point to push on? Is there a center 
o r organization for that kind of thing? This is for anyone on th e board . PHILLIPS : Marty, you talked 
about that . PICCO : Not to my knowledge . PHILLIPS : Any other response to that ? LANTZ : The only 
other thing I can add is the Vox stuff that I mentioned . We are promoting that as there is no centra 
l organization, but on the other hand, in terms of audio, one of the purposes of the Vox work is in fact 
to make it a publi c domain standard . All the specs are already public domain an d we're very close 
to making the reference implementation publi c domain as well . We're trying to put together a Vox consortiu 
m patterned after the X Consortium . So anybody interested i n talking about that should find me or Barry 
Arons or Chri s Schmandt any time in the next couple of days . Q . If I can just make a follow-up observation 
. You mentione d X and that's worked very well in that case and worked very wel l in the RenderMan case 
. Let me just put for something like tha t in this case as well . PERLMAN : I think on the standards 
front, though, we ar e real interested in supporting standards for like communicatio n of data especially 
-- like that video compressions that yo u were talking about . Hey, it doesn't do much good to have something 
that's easily transportable that you can't use in an y other machine, etc. And things like Postscript, 
etc. We love to support that kind of thing . Or X windows under UNIX. It's just sometimes we'll be doing 
some things I thin k different vendors, in addition to Apple, we're doing some things in a proprietary 
way because you can't always rely o n other people's hardware doing things exactly the same way tha t 
your stuff does, and then if we could just have good communication links between the different platforms, 
I thin k that would be terrific . PHILLIPS : There is some work going on I'm sure there' s somebody 
in the audience that can tell us more about it t o incorporate video in the X server. But why don 't 
you take a turn at the microphone? Are you there? Great. I was going to call on you next anyway . Q. 
My name is Paul Tellett from Digital Equipment . Again , there's another subcommittee that also runs 
in parallel with th e MPEG and the JPEG, called MHAG, which is attempting t o standardize synchronization 
and multi-media . So that's like in parallel to the image compression and the motio n compression . PHILLIPS 
: Thank you for the comment . And I'll take the gentleman in the front here on the left . Q. My name 
is Hal Bullock. I'm with the U.S. Government , which I guess could be a euphemism for a lot of places 
. At an y rate, my question has kind of been touched on and if it's bee n already answered to the extent 
that you can, then I apologize . But I'll direct it particularly toward the gentlemen from NeXT , but 
if anybody else wants to answer, that's okay too . I just sai d that because we are using NeXT computers 
for this . We're heavily involved in a project right now which uses both speech synthesis and speech 
understanding . And one o f the problems that you mentioned when you gave you r demonstration was that 
speech requires a great deal of memory if it's stored in high bandwidth . Outputting speech that's bee 
n pre-recorded at high bandwidth is not a big problem if you come off a CD or something like that . But 
if you're trying t o store it at high bandwidth, it is a problem, unless you have lot s and lots of disc 
. You already touched on compression real tim e compression and decompression of video but what about 
rea l time compression and decompression of audio to handle that problem ? VAIS : Well, specifically, 
the case of speech recognition, i t turns out from the experience that we've seen, is that you don' t 
really need all that high resolution sound for speech input. In fact, in a demonstration that I had here, 
it actually works better with a Radio Shack microphone than a $50 Sony microphone . The amount of data 
that we're storing is about 8,000 byte s per second . We do mu law coding of the 12-bit quantizatio n 
down to 8 bits . We do realize some compression there . The frequency response in that type of configuration 
is about zer o to 4,000 hertz, which is generally acceptable for speec h communication . So we don't 
typically use the CD format 44 .1 kilohert z sampling rate for speech . We seem to be doing all right 
. Obviously, if you really want to store a lot of that type of data , you're going to need some disks 
or removable media tapes o r optical disks . Optical disks we think is a good option obviously. But it's 
probably pretty low resolution sound . That's what we're working on . LANTZ: Note again that it isn't 
sufficient just to have arbitrary amounts of disk space because just like the NeX T machine and the SPARCStation 
will begin to lose audio when  THE MULTI-MEDIA WORKSTATION SIGGRAPH '89 PANEL PROCEEDING S they generate 
it if they're doing lots of other things at the sam e time because of inadequate buffering, the same 
thing is tru e when they attempt to record and handle all of these things a t the same time, and that's 
because UNIX is not real time when i t comes out of the vanilla box. So you need either a real time operating 
system with real time scheduling or you need lots o f buffering in the right places in either your audio 
server or i n your file server . So you really have to tune the operatin g system appropriately to handle 
the real time constraints o f both either audio or video to the extent that the video ma y be going 
through the operating system too . VAIS : I might comment on that just a little bit . We've had some 
experience with that, and we've actually been able to tun e our operating system which is based on Mach 
 to prett y much acquire the 8 kilohertz sample data rate, non interrupted , under a wide variety of 
conditions . Of course, the CD format i s a little bit tougher, but in a relatively quiescent system 
you ca n record uninterrupted to the limit of you r disk. But again, a s Keith points out, it's a matter 
of tuning your operating syste m to really free up the buffer space and make sure that the thing i s 
captured . I think it's probably closer within reach of lo w resolution . PHILLIPS : I'll take a question 
from in the back over there on the left. Q. My name is Mill Davis . The question I have for the panel 
I guess it's for Steve. We're now talking mostly about media , and whether or not we can put that all 
together and someho w show it on a screen and any kind of time . But it seems also th e meaning of this 
information is an aspect of the multimedi a workstation that needs to be addressed . Suppose we actually 
had multi-media workstations with al l the video and audio. How do we organize, classify index, find 
our way around these archives? Nobody's addressed this yet . Could you and others of the panel sort of 
talk about some o f those aspects of the semantic and the need to organize an d access that information 
? PERLMAN : I think we've touched on some important points . It's the more or less hyper-media side of 
multi-media, and you need a good way of organizing knowledge, I guess, and just a s you need it for desktop 
publishing kinds of things stati c media you need for multi-media as well . That's one of th e things 
we've been doing with HyperCard and I've seen grea t stuff on the NeXT machine and other computers that 
do all sor t of neat stuff along those lines . But I think it's essential that we continue to evolve 
ou r knowledge organization and representation tools along wit h our kind of raw data movement technology 
. PHILLIPS : My interpretation of your question is if I no w have multi-media components in a document, 
just as I ca n search for text strings and combinations of them, I'd like to b e able to search for a 
piece of video that has some semanti c content that I can represent . A . That would be one implication 
. Or graphic bases that I' m dealing with certain attributes of the visual information . PHILLIPS : Or 
sound that has some particular A . Yes, sound . Perhaps it has content or it has certai n qualities that 
I'm but these are problems in language an d notation that become very important because it's invisibl 
e once it's electronic . PHILLIPS: That's something that's gotten me kind of excite d recently, because 
I've been involved in a project where yo u would like to do exactly that same kind of thing, and I run 
u p against a brick wall because I don't know anything about an y efforts in those fields, and if anyone 
here can enlighten me and us on things that are going on there, I'd like to hear about it . think that's 
a very exciting area, particularly if were going t o have the fully integrated multi-media workstation. 
I think we have to address that problem . A . We have some thoughts to share, but I think it would b 
e more appropriate in the breakout . PHILLIPS : That's fine; thank you. Yes, sir. In the middle right 
here .  Q. I'm Steve Bulick from U.S. West. One of the things I'm kind of interested in is a multi-media 
document architecture . That is, if you're going to send messages and you're not goin g to be always 
on the same machine on the same kind of network, there's going to have to be some kind of standard for 
unwrapping that package and playing the video, playing th e audio or showing the graphics, the text and 
so on . The onl y demo that we saw that used it explicitly was Paul's . Clearl y there are some kind 
of document architecture implied unde r ability to send multi-media mail . I wonder if you would sa y 
something about that . VAIS : It's currently a NeXT specific interface, I guess . The mail program itself 
is UNIX Mail, and if all I did was type tex t in there, it would just send a standard text message to 
someone . When you start putting the attachments in the NeXT system, i n the mail program, it starts 
building a small directory hierarchy of included objects that are constructed by the mail program . When 
it gets sent, what happens is that that data is essentiall y tar'ed up, using the tape archive type of 
command in UNIX, an d encoded into ASCII and then sent across the standard UNI X mailers .  Q. Do you 
even encode the video and the audio in ASCII ? VAIS : Yes. The audio portion gets in there and the bit 
map s and any generic object in the file system in NextStep, anywhere on the box will go into this format 
essentially . It's really independent of that .  Of course, if you don't have a NeXT system that's 
going to read that mail message, you're going to get a lot a reall y long, ugly mail message that goes 
on and on and on and on because you're going to get uuencoded tar files . So clearl y there's got to 
be some type of effort to standardize that . Q. That was actually what I was interested in . Is there 
standards work in this ? VAIS: No, there is not a standard for that right now and we ar e very interested 
in promoting a standard or discoverin g someone we can collaborate with to establish that . LANTZ: Playing 
devil's advocate, only momentarily, IS O would refute that statement and say of course, there's X400 
an d there's ODA . A . ODA doesn't do multi-media though, does it? It's mostl y text and graphics . LANTZ 
: No, but if you read the standards documents and loo k at all of the empty sections, they have lots 
of empty section s for FAX and audio and video . And there is work underway i n those organizations to 
fill those in, but I wouldn't dare mak e any predictions as to when that will happen . So in fact many 
people in the Internet community a s opposed to the ISO Community have begun to think that th e transport 
of multi-media documents is probably importan t enough to address in one of its task forces . I happen 
to serv e on the htternet Research Steering Group, so if I had a list o f lots of companies that thought 
that was real important, tha t would help make that happen . So if you're real interested i n making 
that happen in doing something in addition to or a s an extension to ODA let me know .  THE MULTI-MEDIA 
WORKSTATION SIGGRAPH ®89, Heston, July 31 -August 4, 198 9 PHILLIPS: In the front, over here on the 
left thi s gentleman . Q . Bob Jurgens with Mitre . Dick, you had said that the multi ­media tools would 
be available in the next couple of years and our vendors look like they're going to be providing the 
too l sets on their platforms . This is a question for the panel as a whole. What can we expect from 
third party vendors? Are the y lining up with you to provide integrated applications, and i f so, what 
kind of applications using multi-media can we expec t within two or three years ? VAIS : I think a natural 
spot would be courseware authorin g systems and in my personal experience, dealing a lot wit h higher 
education, there is a real clamoring for powerful tools t o design and deliver that at a low cost a 
price point . So I thin k that's going to be a market that really drives it, and there are some companies 
out there investigating that. A friend of mine just got funded to do a pretty high leve l design for 
of courseware authoring systems . That's certainly one area that's going to be integrated media . PERLMAN 
: We're already beginning to see a couple of interesting a few interesting multi-media applications 
. That thing I used to put up the slides in the beginning is somethin g called Macromind Director. That's 
one of the pretty good ones for the Mac . And there's this new thing from AutoCAD for th e PC that we've 
seen, and what's neat is there's a real lot o f interest in the Developer community . I think they kind 
o f latch onto new things and they kind of like oh, wow, I want to work on that, and we'll find a market 
later . So I'm pretty excited, and there is also a very stron g interest among developers to make sure 
their stuff works with everyone else's, and we're real happy to try to be kind of th e application integration 
platform for that sort of thing, and I' m sure the same is true with other vendors as well . PHILLIPS 
: Keith, do you want to respond ? LANTZ : Let me add that another principal use, the target tha t of 
course my talk was about, is teleconferencing itself . That's a world where we use all of the media just 
to do the teleconference, and then any of the other applications that yo u may have run in the context 
of that teleconference . One of the things that's going to stop that fro m happening is if the video 
peripherals -- things like the Parallax board and the RGB Technology board don't get a lo t cheaper 
 at least if you want video. So that's another case where I wish 100,000 people would stand up and make 
orders for Parallax boards or whatever else, so they could produce these things in quantity and get the 
price down . PHILLIPS : Marty'? PICCO : Yes, it will definitely get cheaper . The technolog y to implement 
the functions has definitely declined . The memory costs are going down and some of the displa y architecture 
where you merge with the analog video, it can sav e you a lot in terms of what it takes to implement 
tha t technology. The analog is actually fairly inexpensive onc e you figure out how to do it right, 
which is not trivial . PHILLIPS : My response would be from the standpoint o f doing scientific visualization 
and I think were going to se e that scientific visualization tools are going to have t o incorporate 
multi-media applications . A couple of things ar e happening here at SIGGRAPH . Tomorrow night there 
will be a demonstration jointly by Sun and AT&#38;T and NCSA, where the y will be showing a video hook-up 
from the Cray at NCSA via a live video link, to here at SIGGRAPH, where on a Su n workstation you're 
going to be seeing live video . That's reall y quite similar to what I showed you in the beginning, and 
let me also give a plug for another panel that I'm involved with on Friday, where we will be talking 
about several differen t approaches to scientific visualization, and all of those issue s will come up 
there . So there are some manufacturers right no w I think someone told me today that Wavefront has provide 
d a visualization package that's being distributed with th e Silicon Graphics machines. There's some 
work that's been going on at Stellar to provide a generic visualization tool . That to my knowledge 
does not yet involve the incorporatio n of anything other than images and certainly not video and certainly 
not sound . PHILLIPS : Let me see ; gentleman over here, go ahead . Q . My name is Brian Machon with 
MIT Project Athena . I guess this question is best directed at Keith Lantz . We've bee n working with 
multi-media applications in X the X windo w system for a number of years now . One of the most difficul 
t things we have to do is the coordination of events or keepin g track of where a video disk is, and 
then the screen refreshes an d we lose track; we have to resync. Given this architecture, d o you think 
that a true multi-media computer must be a paralle l processor or at least multi- printed server ? LANTZ 
: Yes, and all input events have to be time coded . PERLMAN : One comment on that . We have a very tough 
time with UNIX in trying to wrestle it to being real time . I mean, look, we're always going to support 
UNIX ; I think that' s real important. But the fact of the matter is it's like you're trying to retrofit 
this old operating system again and again . It was really made for I mean, lots of users kind of logged 
into a time sharing system . And this concept of real time, yo u know, is completely alien to its original 
conception . There ar e ways to make real time operating systems . And it's amazing what you can do when 
you suddenly say well, suppose I don' t have to be UNIX compatible . What can I do now? It just open 
s up all these doors . Suddenly you begin to see kind of the ligh t of well, sorry suddenly you begin 
to see a glimpse o f what our integrated real time world I mean, lots of differen t third party things 
that don't know anything about each other work in real time . You don't have to worry about the soun 
d conking out from the disk because it knows the bandwidth i s known what is needed to be able to maintain 
this thing . It's kind of like memory management. How about time management? You know, things like that 
. It's real importan t to not give up hope there and just assume it's got to be a rea l expensive system 
just because it's real time . It may require a little rethinking though. PHILLIPS : Back here on the 
left, please . Q. I'm Barry Arons from the Olivetti Research Center . I have a question of appropriateness 
for Dick and indirectly for Marty . Since it seems that most of your images are coming digitall y from 
a Cray, why do you bother digitizing them? I mean, wh y do you bother turning them into NTSC, transmitting 
them a s NTSC and then having the Parallax board, which basicall y redigitized them to display in your 
display? Why don't you jus t distribute your images from the Cray digitally? I think NTSC i s great for 
archiving and things like that ; I just don't see it' s appropriate in your application . PHILLIPS : 
You're absolutely correct, and I'm working wit h what I have available now . In the near term there will 
be fibe r available to me for doing exactly what you suggest. NTSC certainly is a compromise at this 
point and it's really tradin g off bandwidth for image quality and I'd prefer not to do that . Indirectly 
for Mary, did you say ? PICCO: I would think in that application what we would be moving towards is frame 
buffer access for things like FDDI an d  THE MULTI-MEDIA WORKSTATION SIGGRAPH '89 PANEL PROCEEDING 
S network interfaces that would allow you to transmit digita l information into the system . I guess 
that's kind of what I was hinting at when I wa s saying that there needs to be more media types besides 
vide o and audio . I mean, there are a lot of other ways to ge t information around and they need to 
be looked at as well . PHILLIPS : In fact, I hate to put in another pitch again for th e Friday panel, 
but I will be talking about some 800 megabi t networks that are being installed that are certainly going 
t o make life a lot easier for the kinds of things that I'm intereste d in doing . Q . My name is Patrick 
Boyd . I'm with Boeing Compute r Services, and my question is not really focused on the tools a s much 
as teaching people to use these tools, and my question i s is it inevitable, or are we going to be able 
to avoid th e ransom note phase that we went through with deskto p publishing . In other words, what 
about the issues of video production and audio engineering? Just because you have a too l doesn't mean 
you can build a house . PHILLIPS : Anyone like to respond? That's the hard part, I guess . PICCO : I 
guess I would say that video production will remai n for some time to be one of the stumbling blocks 
because i t tends to be very expensive and it takes a lot of money and a lo t of time to produce good 
video, and people are used to watchin g video at very, very high production quality . I don't see that 
substantially changing in the short term unless people ar e willing to take a much lower production quality 
in the video that they're going to be doing . LANTZ : All I can add is to paraphrase a comment fro m 
someone who may be in the audience and can attribute himsel f if he wishes . There was a meeting last 
year on this topic the whole topic of video in workstations and most of the major player s were there, 
including Dick. There was a good deal of consensus that nobody expected to see significant amounts of 
"casua l video". Nobody saw in the near future, anyway, the tool s available so that the typical user 
would feel comfortabl e creating a piece of video that he would want to send to anybod y else, in the 
sense that they could really imaging anybody els e wanting to watch it . So that was a comparison between 
the idea of productio n quality video, which is what you typically see, Camcorde r video, which is what 
most video mail, one would think, woul d be like. And that could in fact be a real problem with any products 
that come out and claim to be video mail . PHILLIPS : There's probably an analogy to the infancy of desktop 
publishing where people went crazy with the fonts tha t were available to them and passed out what is 
called chart jun k by some people . LANTZ : But again, actually Dick and Wendy McKay an d associates 
at Project Athena have done some interesting vide o editing tools associated with their respective window 
systems . Dick's, in the case of NeWS and, Wendy's in the case of X . So there are some examples out 
there that you can actually rea d about in the most recent issue of CACM . PHILLIPS : CACM, right, and 
it's being distributed on the floor here or at least advertised on the floor . I'll take at most two 
more questions and this gentlema n was first, I believe . Go ahead . A. A comment on this last subject. 
I'm William Roberts; I'm in the interactive technology concentration at Harvard Graduat e School of Education, 
and I'm working on a cu rriculum of video literacy and then further beyond that, a curriculum of interactiv 
e multi-media . PHILLIPS : Thank you. One more question; this gentlema n over here on the right . Q. 
My name is Scott Mise ; I'm a multi-media evangelist at Apple Steve, awesome presentation . My question 
has to d o with content, and it's a two-part question . One is I'd like t o have people's perspectives 
on what are going to be th e effective strategies for getting the major information owner s on the planet 
involved in doing multi-media products, an d secondly, what do you see as the ratio between multi- medi 
a that people are working with that they have to purchase, versu s what they create on their own, which 
kind of ties back to thi s what's the quality of the video that you're working wit h question. Any insights 
on those two? PERLMAN : I think I was I worked at Atari quite some tim e on interactive video disk several 
years ago, and it was kind o f interesting trying to get Warner to move on makin g interesting video 
games that were based on the large amount o f video that they had at their disposal, and what kept coming 
u p again around and around was where are the delivery units? And I think that that's going to be it's 
a chicken and the eg g problem . Before you get the major publishers to get ver y excited about it, there's 
got to be a lot of delivery units that ar e cheap and available out there or they're just not going to 
 they're just not going to get interested in it . VMS : One other thing that might be driving that equation 
a little bit is perhaps the mass storage issue because if there's a lot of data to be stored and there's 
no real way to store it commercially and inexpensively, then some people may no t see the benefit in 
doing that . Our experience with some of the publishers that we try an d work with to get digital editions 
of books out is similar to tha t with mass storage devices getting to be very high density an d relatively 
low cost for movable storage . That's going to ope n up the availability of markets to publishers and 
they'll b e presumably inclined to get involved in that . But right now it' s a tough battle right now 
. PHILLIPS : Anyone else like to comment on that? I'm goin g to close off questioning now and I want 
to thank both you folk s for joining us this afternoon and my great panel for bein g available for this 
. Thank you . THE MULTI-MEDIA WORKSTATION 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>77283</article_id>
		<sort_key>111</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Effective software systems for scientific data visualization]]></title>
		<page_from>111</page_from>
		<page_to>136</page_to>
		<doi_number>10.1145/77276.77283</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=77283</url>
		<categories>
			<primary_category>
				<cat_node>J.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39084625</person_id>
				<author_profile_id><![CDATA[81100562050]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[L.]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Treinish]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NASA/Goddard Space Flight Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39076354</person_id>
				<author_profile_id><![CDATA[81100302796]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Foley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[George Washington University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14082477</person_id>
				<author_profile_id><![CDATA[81100210389]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[W.]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Campbell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NASA/Goddard Space Flight Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P232661</person_id>
				<author_profile_id><![CDATA[81408593381]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[B.]]></middle_name>
				<last_name><![CDATA[Habor]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NCSA/University of Illinois at Champaign-Urbana]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P232629</person_id>
				<author_profile_id><![CDATA[81100503448]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Gurwitz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stellar Computer, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
            SIGGRAPH '89 PANEL PROCEEDING S to have some input and some comments from the 
pane l members that would perhaps provide some direction in where we ought to look as to enhancing either 
current graphic standards or what new kinds of graphic standards might b e appropriate, coming out of 
the graphic standards community . HABER : This is a nice question because it gives me a chanc e to make 
a point I didn't have time to make. I think part of the question is what level the standards exist at 
. I mean, there are certainly many details we could debate back and forth o n existing graphics languages 
like PHIGS+ versus GL, that level . But I think the real issue is that there's a need for a higher-leve 
l standard . Just as device drivers are too low a level for previou s work, the level of a graphics language 
is too low a level interface for most scientists to deal with. So what we'd like i s something on the 
level of a viewing system ; the scientist jus t provides geometry and you have a viewing package that 
allow s you to animate it in real time and look at it from differen t perspectives . So an interface 
that deals at that level would b e very desirable . Another point is that beyond points and polygons 
an d lines, volume visualization is now getting to be reasonabl y routine and if a standard could be 
developed for input, it woul d be very useful. I think that's really the only new rendering technique 
or class of rendering techniques that was introduce d during this scientific visualization period that's 
only three o r four years old now . The other point is not so much at the graphics end ; it' s between 
the visualization mappings and the applicatio n upstream. So that's really an applications issue. People 
doing solid mechanics, finite element work, ought to have a standard output form so that their data could 
be fed to visualizatio n mappings . That's more the application discipline's problem, I think, than the 
graphics field's . GURWITZ : I think addressing this from my point of view as a system vendor, we are 
trying to base on existing lower leve l standards for graphics interfaces and user interface an d networking 
and operating systems . I would agree with Bo b that a higher level of standard is needed for applicatio 
n interface . I think one of the things that's become apparen t working with the folks that we work with 
at Stellar in the research community and in the industrial community is that it' s a very early time 
for scientific visualization systems . Key research is being done in software systems such as the work 
a t NCSA, the work at Stellar, a number of other places, Ohi o State, and I would caution against premature 
standardization . I think there's a rush that people have to go and standardize things . Unfortunately, 
it takes a long time for standards to evolve . We are struggling with the issues in producing products 
in thi s area of not casting things in stone and yet supporting user s who want to do research with effective 
tools and not having t o live with l0-year-old technology at some point in the future . So I think that's 
another thing that needs to be kept in mind . HABER : We definitely need higher-level standards, but 
we're not ready to write them yet . TREINISH : Also in the area of standards, of course, the data standard 
level we're also really at a pretty low level . There are many different data standards that do exist, 
but most of them ar e oriented towards magnetic tape formats, and there's a plethor a of them . In terms 
of formats at a higher level, there is a handful o f products that have been developed, but they're all 
fairly ne w and we're still learning how to do that effectively . A question on my left . Q. My name 
is Michael Good from Digital Equipment Corporation. I had a question on the user interface aspect o f 
visualization . I was wondering if the panelists could describ e what potential they see for the type 
of virtual environmen t technology that's been described in one of the panel s yesterday, for instance, 
exemplified in the VPL research Ey e Phone and Data Glove systems not necessarily as they are right 
now, with limited resolution and speed, but as they ma y be in a few years . FOLEY : Certainly the potential 
for doing the sorts of thing s that Jaron has demonstrated, of walking around in a virtua l environment 
which actually represents the isosurfaces, feelin g force fields that are created by some of the computationa 
l processes or the physical processes, rather, that are bein g modeled, will provide another more visceral 
level of experienc e and understanding . TREINISH : Next question in the center . Q . My name is Don 
Bard and I'm from the David Sarnof f Research Center in Princeton . All of the examples I've seen o f 
visualization have been with deterministic data, and while I understand that simulations can be constrained 
to b e deterministic, the world usually isn't that way . I haven't see n anybody trying to cope with 
variability in data . Do any of the panelists have comments on that ? CAMPBELL: I can take a crack at 
that. Traditionally, when we had any kind of interaction with a data system, you had to live with the 
underlying data structures and primitives , regardless of what tools you had to generalize or visualize 
o r determine some scientific variability or information from i t and that was it . You lived with it 
because the data structur e itself wasn't necessarily representative of what you would lik e to glean 
from it . So what we've done in our laboratory i s simply layer technologies on top of it that may help 
the use r get through the process in a seamless transparent fashion, but when they finally get down to 
the underlying data structure , they still have to live with something that is truly no t representative 
of what they would like to have . When we try and model that data structure, it turns out tha t there 
is multiple models . I mean, there are many models ou t there and just trying to force everything to 
one model didn' t work, and we already tried that paradigm from the user interfac e perspective . What 
we are proposing in the future is that we recognize there are multiple models of visualization and what 
the use r perhaps would really like to see, and that is to creat e specialized products on the fty, and 
that's one attempt we're going to try to do in the Earth Observing System . That is, t o have primitive 
boolean operations sitting there, sleeping, i n terms of creating browse products on the fly, so that 
you ca n actually visualize, take a look at what's out there . You don' t like it, you ask a different 
type of question and the product i s regenerated into a different kind of paradigm . You look at i t 
again . and if that makes sense to you, then you say yes, that' s the way I'd like to have my data set 
created, and then it goe s into more of a production mode and it comes out the pipeline . That may be 
a high level answer to your question, but that' s what we envision . HABER : I think one example that 
you might be familiar wit h where people have done visualization of nondeterministic dat a is in molecular 
modeling, where they do isosurfaces or som e kind of volume representation of electron density clouds 
. That's basically a nondeterministic phenomena . Becaus e visualization is essentially a process of 
abstraction an d drawing pictures of an abst raction, I think it's possible to go EFFECTIVE SOFTWARE 
SYSTEMS FOR SCIENTIFIC DATA VISUALIZATION '133 SIGGRAPH '89, Boston, July 31 August 4, 198 9 further 
and develop new visualization idioms that will represen t other aspects of nondeterministic information 
. But I think it s an interesting area for development . GURWITZ : I also think that the exploratorium 
modes o f operation of systems that I mentioned are a way of trying to ge t at the problems specific 
to nondeterministic systems . TREINISH : I think there's a question on my right . Q . I'm Chris Landreth 
from the University of Illinois . The concept of a renaissance team has been used a lot in the las t 
couple of years to describe an interactive group of people fro m very many different disciplines -- including 
scientists an d artists -- to work together to explore scientific insights usin g visual data . I'd like 
to ask the panel in general where they se e the concept of renaissance teams going, what future it has 
. GURWITZ : As a tool builder, what we try and do is build tools that are sufficiently flexible so that 
nonprogrammers ca n use systems, can experiment with different visualizatio n models and can work together, 
and I think the model of havin g artists, for example, having scientists and having system s programmers 
work together to collaborate will become easier in the future as these tool frameworks become more ubiquitous 
. I kind of refer to the system that we built at Stellar as th e beginnings of a visualization operating 
system, and I'd like t o see that kind of raising of the level of abstraction be mor e widely adopted 
so that nonprogramming type people can ge t involved more not just as places where they're specificall 
y brought together . FOLEY: I think this is exactly analogous to the situation w e have in user interface 
design in which its been alway s important to have psychologists, human factors expert s involved in 
the process, and the user interface developmen t tools have gone through a succession of levels of increasin 
g abstraction to make them more accessible to th e nonprogrammers . That's exactly what we see in AVS 
and othe r systems and it's a very important trend to continue to empowe r the nonprogrammers, including 
the art members of the renaissance team, to do these things . CAMPBELL : At NASA traditionally the way 
that idea didn' t work was a principal investigator wrote a proposal, it was pee r reviewed, it was funded, 
the principal investigator had firs t rights on whatever data was generated according to tha t proposal, 
he or she kept that data for two to three years, got as many papers out of it and grad students out of 
it as possible , and then the data was made public managed or not and some people knew it or not . 
That's the way it always was . A big step forward is what is proposed again for the Eart h Observing 
System you have to play with other tea m members and currently there are 551 investigators and co ­ 
investigators who have been submitted and who have bee n approved to be investigators . You have to get 
your data bac k into the system as fast as possible . We're calling that multi ­disciplinary analysis 
and multi-retrospective analysis, and tha t is forcing the scientific community historically th e scientific 
community and the builders and the developers of th e system to work together to come up with the best 
possibl e combination . HABER : I think one way to say it is that what you really nee d for a good visualization 
project is a renaissance skill set . Whether that comes from an individual or from a group o f people 
depends a lot on their personalities, the organizationa l structure around them and things like that 
. So I think there are advantages to both modes, single warrior and collaborativ e efforts . They both 
have their plusses and minuses . They probably will both continue . TREINISH : I think there's a question 
in the back center . Q. My name is Drew Henry. I'm from TRW. I manage th e engineering visualization 
center at TRW, which is a top leve l organization to provide engineering visualization expertise t o 
TRW, and I think this is rather unique for an aerospace company like TRW to commit to something like 
this, and I think that we'll be seeing more of these types of thing s happening at other aerospace companies 
and other larg e companies in the country . We of course are very interested in the data visualization 
. We have a large research staff, a large engineering staff . Wha t I'm interested in knowing is if there 
are organizations, perhap s represented by yourselves, who are coming together to try t o decide upon 
what directions to take visualization in th e standards you've been talking about, trying to direct 
the hardware vendors, the software vendors, and the areas tha t they're writing. To address the needs 
that companies lik e ourselves have, like researchers like yourselves have . That' s really what my question 
is . Is there some kind of a n organization coming together to address these needs ? HABER : Well, I 
think the answer is probably at this point no. The main platform for discussing issues and visualization 
, I think, ACM SIGGRAPH, this conference, its probably th e leading one . Some of the other computing 
organizations, like IEEE, are also getting going with publications and discussio n in their meetings 
. So, so far, it's come under the umbrella of existing organizations . It's kind of interesting it's 
a discipline that sits betwee n disciplinary boundaries, because there are many issues i n visualization 
that really have nothing to do with compute r graphics or even computing . They're really science issue 
s and abstraction issues . So, whether at some point it makes sense to split this of f into its own organization 
or to use all the wonderful A V equipment that we've got here, I don't know . TREINISH : Certainly in 
the NASA space scienc e environment there is really very little standardization or ver y little efforts 
in this direction . There is some chaotic activities a number of small groups but nothing formal reall 
y towards the space science community . GURWITZ : I think one thing to keep in mind is tha t scientific 
visualization as sort of an organized discipline that' s not just a buzz word or not just interactive 
graphics is a relatively new area . I think last year was the year of scientific visualization a s a 
buzz word for a lot of people . I guess the NSF report wa s 1987 . I think what were seeing is a lot 
of users, a lot o f scientists in the community that share, have a lot of concerns that are coming together 
and certainly there are a lot o f commonality to the system approaches that you've see n represented 
here today . It's clear that these will continue to come together informally through research and development 
activities and I wouldn't be surprised if those activities became more forma l over time. But again, 
the answer to this standards question, I think it's still early in the life of this particular topic 
as an organized topic . CAMPBELL : In terms of NASA's historical and traditiona l scientific community 
that the word visualization, as Lloy d pointed out, is almost brand new . But the word browse isn't . 
And they use that term without much distinction or any kind o f standardization and in fact a vendor 
came to me recently an d said they are prototyping a browse for a particular system that I was working 
on, and I said you can't even define browse, le t EFFECTIVE SOFTWARE SYSTEMS FOR SCIENTIFIC DATA VISUALIZATION 
 SIGGRAPH '89 PANEL PROCEEDING S alone prototype one . So its all in terms of interpretation o f what 
is really required or what is meant by the term . TREINISH : Next question on my right . Q . My name 
is Rich Dempsey . I work with the Eastma n Kodak Company in Rochester, New York . Actually I have a couple 
of responses here . First off is in terms of this issu e about working through what are the issues around 
-- what are the standards and what are the needs that people have aroun d here. This sounds like a great 
idea for a workshop next year i n Dallas . The other thing is I'd like to suggest that perhaps th e renaissance 
team is created as a result of our not completel y understanding what we can do with all of these different 
tools , so that I mean, the renaissance team as we've seen them showing up at places like Illinois 
are composed of typicall y a systems programmer, a graphics artist and the scientist . S o what is the 
scientist bringing to the table? He's bringing t o the table this gob of data, and the problem he's trying 
to ge t some understanding of what's going on here . The graphics artist is bringing to the table a n 
understanding of a number of different tools, a number o f different ways of looking at this data and 
some understandin g of what the human system human, shall we say, imag e processing system, is capable 
of apprehending . And wha t sorts of things you can put together that look good and conve y information 
and what sorts of things that you put together loo k like mud . And what does the system programmer bring 
to the table i s how to make the box hop so that the tools, the elements that the graphic artist says 
would probably give us a good idea as t o what's going on in this area . Okay, the system programme r 
brings that together . The fact that we have to bring together this particular skil l set is that we 
haven't taken this -- we haven't codified thi s knowledge and I think that when we put together the 
 no . To me, object oriented programming, object oriente d paradigms look very attractive for bringing 
together th e system programmer and codifying the system programmer' s knowledge, so that we create the 
objects . The objects hav e encoded with them the things that can happen, be performed o n them . The 
expert system ideas that Jim Foley mentioned i s essentially will become the codification of the knowledge 
o f the graphics artist, and that assuming that such an exper t system can be built, assuming that the 
knowledge domai n that's involved here is not an infinite domain, but one that i s small enough that 
we can get our hands around, then when w e create the expert system, we have this renaissance tea m embodied 
in the visualization system . Then we will have los t this wonderful personal interaction and what will 
we do? W e will stick our heads up and say -- then I think the teams wh o will be starting to pull together 
will be teams around differen t areas of the science involved people who TREINISH : Could you try to 
focus the question a little bit? DEMPSEY : Okay, I'm making a comment . The statement i s that I think 
the renaissance team will become obsolete fairl y soon . GURWITZ : I guess I have two comments on that 
. One is I think the role of the systems programmer is not to mak e systems hot per se -- although that's 
part of it but is to make systems useable . And I think that's an important poin t that many people 
lose . The other thing is that I think that I disagree with th e comment of the speaker that we're going 
to lose the renaissance team approach when we have better tools . I think better tools are just going 
to enhance it. I don't think having a good tool set is the end of the story . I mean, having a goo d 
tool set is sort of the beginning of the story . Once you hav e the tools, then you can get away from 
some of the low leve details, and I hear object-oriented programming a lot . I hear systems programming 
a lot . And as a systems programmer i n background, I don't really want to get away from that . I want 
to get to a point where we're dealing with science, where we'r e dealing with the problems and their 
solutions, and that we hav e the tool set that can be used as a mechanism, as a lever to get a t those 
, So I disagree with that. I think getting better tools won' t destroy the renaissance team concept . 
I think it will enhance it . FOLEY : The notion of embodying some design intelligenc e into the binding, 
to the visualization binding, I think will tak e us a small distance toward routinizing, creating at 
leas t satisfactory visual representations . Certainly the renaissanc e team concept is much too labor-intensive 
for applications t o every visualization task at hand . But there is no way that the role of creativity 
in developing fundamentally new approache s is going to happen without people in the loop . TREINISH 
: Question in the back, center aisle . Q . I'm Reed Predmore from the Department of Physics an d Astronomy 
at the University of Massachusetts, and just to sor t of extrapolate your browse comments, I wondered 
if there wa s any thought towards how you're going to publish this stuff, i f you're going to have a 
CD of the month with your data and you r visualization algorithm sort of encoded on that, and encourag 
e that there be some thought towards standardizing that in th e future . TRE1NISH : There already are 
some trends at least in th e NASA earth science community to being able to publish dat a in - let's 
say in CD-ROM format, for example . There is a lot o f inertia to overcome with regard to what traditional 
publication s require . It wasn't all that long ago that publishing in color wa s nearly impossible . 
Many journals still have difficulty wit h that . But the idea that we need to evolve more into dealing 
wit h interactive visualizations as a method of publishing, and fo r that matter, publishing well organized 
structured data . There i s still a lot of work to be clone in that area . Then that could fit i n underlying 
into visualization software . Bill? CAMPBELL : In terms of multiple models of browse, as soon as one 
person came up and said well, I think I've solved the browse problem, I say, let's see it and he says 
well, what I' m going to give you is in terms of imagery every fourth pixel . And I says I want every 
pixel. So your browse doesn't work for me, but it may work for someone else . Then he says all right 
. Well, I figured out a way to do a recursive subdivision and I' m going to go down to the bottom level 
with a quad tree or som e other structure and I'll finally give you the object or feature o f interest. 
I says well, I don't have image data, so now yo u haven't helped me at all . I may just have a sine wave 
or som e XY plotting or something else . So what we truly need in terms of visualization and thi s gets 
back to Jim Foley's comment is one of those 55 1 scientists said you know, if you have your knowledge 
bas e or your metadata base rich enough with information, I ca n probably stay out of trying to visualize 
my data 95% of th e time simply by asking the appropriate question and getting the appropriate answer 
back . So one way one way of doing it i s just having a rich knowledge base that the user interacts 
wit h  EFFECTIVE SOFTWARE SYSTEMS FOR SCIENTIFIC DATA VISUALIZATION 1 39 SIGGRAPH '89, Boston, July 
31 -Aumist41989 and when they're finally satisfied that they're real close to th e data that they would 
like to see in a fashion they'd want to see it, then we have to go into those multiple models and create 
the product . HABER : In terms of the publications that you're askin g about, where things stand now 
is that there are beginning to b e publications that include videotapes . ACM SIGGRAPH has been publishing 
the SIGGRAPH Video Review with severa l special issues on visualization. This month IEEE Computer i s 
going to have a special issue on visualization which will b e accompanied by a videotape and if Greg 
Nielsen's out there, I'l l send you my segment soon . So you're just seeing the dawn of that kind of 
idea . Whether videotape is the ultimate medium, that remains to be seen . I doubt that it is . But it's 
starting to happen and it is a n interesting problem from a technical point of view . TREINISH : Question 
in the front center. You have to get close to the mike . Q. I'm Kathleen Dyer from Lawrence Livermore 
Nationa l Laboratory and I'd like to make a comment to Bob Haber. First of all that I'm a big fan of 
the NCSA Mac tools . I've been usin g them for quite some time . HABER : Thank you ; I didn't write them, 
but thank you o n behalf of the rest of the folks that did . DYER : AVS also looks very interesting to 
me . I've notice d though when I talk to the vendors down on the floor and say scientific visualization, 
they get kind of a glazed look on thei r face . They can handle CAD/CAM and engineering type things . 
GURWITZ : Not this vendor. DYER : Yes, with your exception . Are any of you aware o f any other existing 
software systems either commercial o r public domain that exist now or something that's coming tt p 
in the near future, that we may be able to use in the same sens e as we're using the NCSA and the AVS 
tools . TREINISH : Bob, did you want to comment ? HABER : I've been hearing rumors that Chuck Csuri i 
s working on a product at Ohio State probably not at Ohi o State because I think it will be a commercial 
product. I don't know too much about it, but there's something going on there . GURWITZ : I know of a 
number of efforts that are going o n and I think it's going to become a more common theme . I am a little 
bit surprised at the questioner saying that the vendor s glaze over when they hear scientific visualization 
. From ou r point of view, it's kind of a hot topic for people at least dealin g with making products 
that scientists use . I think you'll see more and more of those . I think it wa s surprising to me in 
coming into this particular area when I did , at the lack of high level tools that existed . And I think 
you're going to see that change . I think that the RIVERS project, I think that AVS, are certainly examples 
 early examples . I think there will be other systems that come out . Before, prior to this, as you know, 
people were usin g things like Wavefront which was designed for the vide o production industry for making 
commercials because tha t was the only software that was available . So we're really at th e very beginning 
stages of getting commonly available packages . But I can tell you from where I sit I see a lot o f 
activity on the part of both commercial houses, researc h institutions, and the national laboratories, 
at providin g software and making it available for this area . So I think th e news is good . TREINISH 
: In the commercial realm there are a couple o f other possibilities . One, of course is the software 
bein g developed at Cognivision that Jim Foley mentioned . In addition, there's also a package called 
IDL Interactive Dat a Language which runs on VAX/VMS and Sun 3 and Sun 4 systems. And its orientation 
is at a programming level , although a very high one . It has a structure not unlike APL i n terms of 
being dynamic and interactive and naturally handlin g multidimensional arrays . But it uses a FORTRAN 
style syntax , rather than APL Greek, and it has primitives for doing dat a analysis, so it has built 
in fast Fourier transforms and statistical operations, and some graphics primitives from X Y plots to 
basic image processing . And it promotes an exploratory data analysis process . That package has considerable 
potential . GURWITZ : It just reminded me there . I can cite a couple of other packages. There's PV Wave 
from Precision Visuals . TREINISH : That's IDL. GURWITZ : Okay, so that's mostly in the 2D area . TREINISH 
: Yea, primarily . GURWITZ : And the VisEdge system that runs on the Allian t systems is another one 
that comes to mind . HABER : I think that before you see a real flood of this an d before all the salesmen 
on the exhibit floor know exactly wha t you mean, it's going to take a little bit of time . Right no 
w there's not a big volume because only high-end systems hav e the performance levels that will support 
this kind of system . But I'm sure that over the next few years you'll see that level o f performance 
migrating down to your personal desktop unit . When that happens, just like with the Mac and PC revolution 
, then I think you'll see this flood of software packages availabl e commercially. Then those salesmen 
will all know what it is . TREINISH : One last quick question in the back to my right , and other questions 
we'd like to postpone to the breakout roo m after the session, because we do have to leave here promptly 
. I thought there was a question in the back on the right . Q . There is . TREINISH : Okay, please go 
ahead ; quickly .  Q . My name is Steven Zick . I'm from AT&#38;T Pixel Machines .  Before that I 
was working on medical visualization th e reconstruction of CT scans . I've seen many packages to do 
thi s sort of stuff, using very at times contradictor y techniques . Is any work going on evaluating 
the effectivenes s of different visualization methods, or trying to enumerat e where certain techniques 
work better than other ones ? TREINISH : The work is still at a very primitive stage . A lot of it is 
exploratory . We're still looking at the relevance o f different techniques for different classes of 
data and learning a t the same time, trying to even build a knowledge base . FOLEY: The one specific 
set of experiments with which I' m familiar, having done it at the University of Lowell with som e of 
the glyph type representations I showed you, I think this i s a very important area . It's one that's 
been neglected much to o long and I'm very encouraged by the starting efforts and hop e that we'll see 
a whole lot more of it. It's what we've got to hav e in order to begin to further automate the process 
and build the knowledge bases that will generate at least initial stabs at a good visualization without 
having to go through many, man y iterations of experimentation each time we need a new one . TREINISH 
: At this point we'd like to conclude the panel . Thank you very much for your attention and interaction 
. If you have further questions, we'll be available in Salon D, I believe , which is off to the left. 
Thank you again . EFFECTIVE SOFTWARE SYSTEMS FOR SCIENTIFIC DATA VISUALIZATION 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>77284</article_id>
		<sort_key>137</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Hardware/software solutions for scientfic visualization at large reserach laboratories]]></title>
		<page_from>137</page_from>
		<page_to>157</page_to>
		<doi_number>10.1145/77276.77284</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=77284</url>
		<abstract>
			<par><![CDATA[Good morning. My name is Linnea Cook from Lawrence Livermore Laboratory. This session is a panel session on hardware and software solutions for scientific visualization that are being pursued at some of the large research laboratories in the United States. This panel originated because I saw and other people at Los Alamos saw that we were pursuing different avenues of -- and quite vehemently -- pursuing different avenues of meeting our graphics needs. In Livermore in particular there was real strife for several years over graphics terminals versus graphics workstations. I thought that other people may benefit from seeing why people are pursuing some of the solutions that they are.Today there are five of us who are going to discuss a little bit about what the environment is that we work in and what we're each doing to solve the graphic needs in our environments, and also why we think our solution is the best.Each panelist is going to and make an eight to 10 minute statement to that effect. I will give each panelist a complete introduction when they get up to speak.I suppose I should tell you a little bit about who I am before we get started. My background is in math and computer science. I have a BS/MS in that, and I am currently a group leader for one of the computer science groups that supports one of our large physics divisions at Lawrence Livermore Laboratory. Part of the work we do is to support our physicists with good computer graphics and I have been leading the graphics workstation effort for my group.Our first panelist to speak is Gordon Bancroft. He is from NASA Ames and he has a BS in aeronautics. He's been at NASA for six years, and is currently task manager of workstation applications, as part of the fluid dynamics division. He's involved in the creation of applications for visualization of fluid dynamic simulation. He has been involved in some of the procurement that NASA has been doing. Gordon.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Software support</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>J.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10011007.10011074</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P165345</person_id>
				<author_profile_id><![CDATA[81100111406]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[L.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cook]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lawrence Livermore National Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31069874</person_id>
				<author_profile_id><![CDATA[81332489209]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[G.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bancroft]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NASA AMES Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP17013315</person_id>
				<author_profile_id><![CDATA[81332505670]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hussey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Jet Propulsion Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P122019</person_id>
				<author_profile_id><![CDATA[81332496463]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dragon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Los Alamos National Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14197806</person_id>
				<author_profile_id><![CDATA[81100571045]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[W.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Johnston]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lawrence Berkeley Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
         SIGGRAPH '89 PANEL PROCEEDINGS have done their science a certain way for a long time 
into th e era of visualization . The first step of that was to add bi g computing power like a Cray . 
But that doesn't change the wa y that these people do work -- particularly that just port thei r applications 
to a larger computer . But when you're addin g working visualization to a scientist or engineer's environment 
, then how do you get them or what is your solution to adap t their work environment to include what 
has to be a new way t o do work with the graphics? How do you get them to change -­either change the 
way they do work or what do you do t o implement all this stuff on their level, because they have to 
b e intimate with the process . COOK : Go ahead, Gordon . BANCROFT: I think if I get the gist of the 
question, it's ho w do you take any of these plans and then go to scientists and ge t them to use them? 
I think that was the point -- like we'r e making up these things but are we paying attention to th e 
scientists? Is that sort of the gist of the question ? Q. No. I'll try and clarify it a little bit. John 
Dragon, for instance, you provide people with terminals and it sounded t o me, well, maybe the reason 
for that rather than workstations o r something that would give people more power to d o visualization 
where they were was because they like doing wor k the way they've been accustomed to doing work and ar 
e resistant to changing their habits to learn -- do a learning curv e to add graphics to their capabilities 
. I'm just wondering i f that's a problem that any of you have come up with and ho w you've addressed 
that . DRAGON: I guess I'd say it's a problem if you cart this new piece of hardware or this new complicated 
software packag e into their office and say this is it ; use it . If you can find -- and it usually happens 
-- you can find a small subset (one or two people out of a group of 30 people) that are interested in 
tryin g something new because they have a problem that they just can' t figure out how to address it 
with the tools that they have . You get that kernel, that core of people to use it and if it works an 
d they can do neat things with it, they show it to their colleague s and it builds upon itself . So that's 
my answer is that ne w techniques will flourish if they work and they're judged to wor k or not work 
by the most conservative people watching thei r more progressive colleagues and see what those colleagues 
d o or do not do with that . HUSSEY : We got into this ; we got into the whole area of visualization 
several years ago through scientists coming to u s with their data, not having any tools, not really 
having an y image processing or graphics hardware at all, coming to u s saying hey, you guys look at 
pictures . I want to see this stuff . And what's occurred is over the years we've gotten a bigger , bigger, 
a longer and longer list of scientists coming to us wit h data. We're overwhelmed at this point and our 
emphasis now i s shifting from us being practitioners of visualization doing th e work for scientists, 
to providing tools for the scientists to us e -- whether it be on a workstation, whether it be on a supercomputer 
. The next frontier is getting the scientists o n the machines and with the software themselves . We 
work very closely with the scientists to do this . COOK : I really like that question because it's something 
that we have addressed at the Lawrence Livermore Laboratory . We found two guinea pig physicists who 
were willing to use the first prototype software . It is essential to have someone who is willing to 
put up with the pains of coming up on a syste m being newly developed . And like John said, as these 
people d o things that other physicists value, then our intent is -- and thi s is happening -- it is 
fostering the desire for this equipment in the other physicists . I guess in the last year there is one 
physicist who has switched from doing plots by hand an d pencil and paper to actually using a computer 
to do some of thi s plots . So that is a hard problem . People get used to the way the y do things and 
it's hard to get them to use something new . I think the nice user interfaces that the graphics workstatio 
n people are coming out with -- Silicon Graphics and Sun wit h Open Look -- I think that those things 
are a step in the right direction to make it very easy so the user doesn't have to learn a whole lot 
of new things . BANCROFT: I just had one other comment . That is if yo u develop tools that are flexible 
enough, the concept that w e took -- our sort of goal when we started our FAST project -- was to build 
a modular environment that allowed the scientists t o build their own workbench with a set of tools . 
And I thin k that's another thing that having the flexibility built into th e software at different levels 
so with the worst case being that they have to write a module to make the software do something ; the 
best case it does it out of the box . And if it's built that way , then perhaps it can solve different 
problems for different scientists . I think we've done a really lousy job in th e computer graphics area 
of using computer graphics workstations or in general for solving scientific problems . So I think we 
have a long way to go. JOHNSTON : I would like to amplify on one point . Clearly the first thing you 
have to do is to demonstrate what's useful . Then you have to make it easy, because if it's not easy 
to use , unless there's a whole collection of graduate students to do al l the work, then the scientific 
community in general won't pic k it up. You also have to, of course, integrate with thei r environment 
. But sometimes that means changing it and fo r the most part, it's pretty easy to make people change 
to a window environment because of the obvious advantages . The point that hasn't been addressed is that 
-- and I thin k it's a really critical point -- is that once we have analysis an d visualization tools, 
the next problem is we really have to b e able to build enough intelligence into the data set that they 
ca n be used without having to write a front end program tha t incorporates the semantics of the data 
set . So I'm reall y arguing that we need self describing data files, we need data objects that will 
tell you enough about themselves so that yo u can do a reasonable job of analysis or visualization . 
And people are thinking about that . Lloyd Treinish's CDF and th e HDF from NCSA are both steps in that 
direction . But just as the people in the window environment are getting to the point no w where you 
can snip out a piece of one application and paste i t into another -- that only happens because there's 
enoug h semantic information about the data that you know how to dea l with it. We really need the same 
thing in the whole pipeline . COOK : Question center in the back . Q . The point is well taken regarding 
one scientist having a n opportunity to work with the tool and then everyone has a chance to see how 
it works and everyone starts doing it . An d that's certainly true also with workstations or simpl e 
computers . A number of years ago one person brought in th e Macintosh and now we have well over 300 
and not very muc h time has gone by . But in one of the slides that John showed it said something like 
a five-year life cycle for computers an d something like that is needed for a size of a machine like 
a Cray, but with computer vendors coming out with five, 10, 1 5 models a year, and the advances in computations 
and graphics , it seems on some level things are changing faster than we ca n  SIGGRAPH '89,Boston,J-s89 
 accommodate . And in working in a computer center as I do an d most of you do, it's hard to keep pace 
with the change . Yet, a t the same time, people, our users are demanding to have thes e newer techniques, 
these newer faster computers . So I guess th e general question at large is how do we deal with trying 
to stay with the advancing technologies and make these tool s available versus the cost of changing computers 
every year ? COOK: I will take a crack at that. My opinion is that if th e people on the panel and out 
there are not planning to mak e their software portable to take advantage of the workstatio n developments, 
that they're making a big mistake . If you'r e keeping your stuff on graphics terminals and videotape 
and not planning to be portable, you're going to get left behin d because its that software that is so 
hard to move . One of the things that were doing is that initially we'r e only giving workstations -- 
the high end workstations - - t o maybe a third of our users. And were continuing this year a third of 
the users, next year a third of the users, the following year a third . Then as we have more money, starting 
again t o upgrade as a gradual process and give the people who have th e heaviest requirements for computing 
and graphics the latest an d greatest and fastest equipment that we can get our hands on, an d we're 
keeping our software portable . I mean, we are writing t o PHIGS, but Jeff Long has put a thin interface 
between ou r applications and PHIGS, for example, so that if he goes to a new workstation and it has 
PHIGS+ or it has somethin g different, that he only needs to change that interface an d doesn't have 
to change every single place in the code where h e is using a specific call . So we 're making an attempt 
to be able to easily span the changes in hardware and software so that the important thin g that moves 
-- our application -- is very portable and very eas y to take advantage of a new workstation . JOHNSTON: 
Let me play devil's advocate on that . Obviously, from a computer science point of view, I agree tha 
t portability is very important, that as you saw, the little thin g that I showed runs on a whole lot 
of different systems . On the other hand, portability is not necessarily essentia l and the reason it's 
not essential -- in fact, sometimes not eve n possible -- there may be resources that you cannot move 
and i n particular there may be data that you cannot move . There are lots of people who have data sets 
that are sufficiently large tha t they essentially have to reside in one place and one place only . So 
the fact that you have the front end to that data portable o r not is really not significant . What you 
have to have i s transparent distributed access to these unique resources and wel l defined interfaces 
and it's the interfaces that you want --I hesitate to say portable -- but static enough so that you ca 
n write portable applications to address these interfaces . S o complete portability of everything is 
not always an issue . COOK: Now I will take issue with that just a little. We are trying to get most 
of our work off of the Crays, but we do hav e a distributed access to the data . We are able to open 
a file on the Cray from a program that's running on the Sun . And so I agree that there are some things 
that are so large that yes, you can't afford to move that data anywhere else . But all of th e software 
that's handling that -- or at least the most of it -- is of f of the Crays and on to something else . 
Admittedly right no w we couldn 't handle a three million zone problem, but in the future workstations, 
are just getting better and faster . I know that there's some limit, but right now they're continuing 
t o progress at an amazing rate, and I think having the software a s much as possible portable is going 
to be essential in the future. JOHNSTON: My claim is that the data will increase just a s fast as the 
computing capabilities -- if not faster -- and in fact, a whole lot faster if what we see currently . 
I mean, the peopl e who build sensors are a lot farther ahead of the people wh o build computers . COOK: 
You're nodding your head . BANCROFT: Yes, that's true . The scientists just -- when yo u roll in a new 
computer they just multiply by 10 and the nex t minute they've got a bigger problem. We're always going 
t o have supercomputers and we're going to always hav e workstations, and the problems will just be as 
big -- they'll us e every bit of the machine that they have . COOK: I agree with that. I mean, I agree 
we are going to hav e bigger problems with the bigger machines . But much of - - a t least of our work 
-- is small enough already that it will do quit e nicely on graphics workstations . And that software 
needs to b e portable and it's the same software that works and the sam e calculations and graphing that 
is done for the large quantitie s of data that will be forced to remain on the big machines, and that 
has to be portable . Someone from the left side . Q. Yes. Continuing on the realm of software solutions 
an d PHIGS, my question is -- is PHIGS really a proper pradigm fo r the problems involved in visualization 
or is a different kind o f graphic standard really an approach which should be taken fo r visualization 
. Is PHIGS appropriate ? JOHNSTON: I think that for those of you who attended th e advanced visualization 
course on Tuesday, that question was answered very well . And the answer is no. It is nowhere nea r adequate. 
And the reason it's not adequate is not because you can't set up the appropriate viewing parameters for 
a 3D view o r something ; the reason it's not adequate is because there are no t enough ways to get in 
and out of the viewing pipeline and s o you're limited in the kinds of visualization techniques that 
yo u can implement when you use a standard like that, just becaus e you're constrained to the single 
3D interface that it provides . Anyone else ? BANCROFT: There are some things that are actuall y missing, 
and I wasn't at the session on Tuesday, but there's als o some things that are missing that are central 
to doin g visualization at least at NASA, and unless those are added, an d then the complexity again 
-- the hierarchy that's implicit in the PHIGS structures is just not appropriate for the kinds of thing 
s that we're doing . JOHNSTON: A lot of the reasons that you need to get in an d out of the viewing pipeline 
is to add the things that ar e missing . COOK : Question from the center. Q . It seems to me that perhaps 
you're talking about tw o different categories of software environment . On the one hand you have applications 
that can use a tool box or some sort o f production program where you format a data set and you feed 
i t in and you expect results that are reliable . In those cases it' s kind of analogous to hooking up 
a couple of laboratory benc h instruments to monitor an experiment . On the other hand, you have another 
category for problem ­solving where the software is in fact part of the experiment . The code that you 
write as a scientist perhaps is something tha t is analogous to building your own piece of test equipment 
. Now it seems to me that to some extent, some of you a t least are breeding a conflict. Scientists who 
want to work in an environment where they can write their own software may b e prevented from doing that 
easily, for instance, at JPL . Wher e on the other hand perhaps at NASA Ames or at Livermore it's a 
SIGGRAPH '89 PANEL PROCEEDING S little easier because you have a workstation and you can sa y well, okay, 
I don't want to play your games of formatting m y data sets a certain way or using PHIGS or not using 
PRIGS ; I will go to my own workstation and hack my own code and ge t my results. Now, in a situation 
where the results are what ar e important -- and you can prove by various tests that they'r e valid -- 
that's an acceptable thing to do . But on the other hand if you have to work in a large community of 
users, you have t o have interchange. Now how do each of you resolve thos e obvious conflicts ? HUSSEY 
: That's exactly what we have built that capability into our flow analysis software tool set -- to solve 
exactly tha t problem, that a scientist doesn't have to rewrite Dave's pane l library . The interface 
is there ; the data structures are in share d memory ; and a guy can write a module if he has to do . 
The jo b of this scientific visualization stuff is not going to be solve d by computer graphics people. 
So the tools have to be flexible to that extreme, what you're talking about . JOHNSTON : That's not a 
resolvable conflict . The situation you described is just a fact of life. Some people are in the more 
production environment where the canned tools are perfectl y adequate, but certainly an awful lot of 
the scientific community , as you pointed out, the code is an integral -- the development o f the mathematical 
models and then the numerical computin g techniques that are used to implement them on the computer ar 
e just an integral part of what they do. You have to allow fo r both of those . COOK : I think at Livermore 
maybe our environment is a littl e different than elsewhere . We have physicists who work wit h computer 
scientists and work very, very closely, and the y specify -- well, gee, this is how I might like to see 
the data and you give them that solution. They say no, that's not right, let's try something different, 
and we iterate around to ge t something that is satisfactory to them . As far as th e production environment 
goes, our environment is just not on e where you can put a job in at night and say well, now I wante 
d to have these views of the data and then get them out in the morning and be happy with them . Always 
you get them out i n the morning and you didn't specify what you really wanted t o see or you see that 
you would really prefer to have had a pictu r e at a time step in between or some other way of representing 
th e data. So our solution addresses that need and does not match the environment where you're putting 
together a videotape an d you've specified this is what you want in the morning and the n you come back 
with it . And again, like I said, we have th e situation where we work very closely -- computer scientists 
an d physicists -- to produce the right tools that they need . HUSSEY : Let me ask you a question . Do 
the compute r scientists and physicists -- do they understand each other ? COOK: Yes. HUSSEY : They do? 
That's rare . COOK : At least some of the times . DRAGON: At Los Alamos it's almost always the physicist 
s that come up with the idea of what the new variables, what th e new physics is that they want to look 
at, and they will write th e little code on the Cray -- very inefficient, no vectorization, n o multi-tasking 
-- which probably for their problem set and thei r problem set alone will go through the data and put 
it in a for m where they can see something. Then they show that to thei r peers and to our code developer 
groups and if there i s acceptance in the peer review process, the code developers wil l sit down and 
generalize it and incorporate it into a bigge r package that is efficiently useful to everybody . COOK: 
Question from the center . Q. I have a specific question for Bill Johnston . He pointe d out the need 
for data compression for networking graphics lik e this, and yet the sustained rates he had on his local 
are a network seemed very low . They were much lower than advertised rates on ethernets available today, 
and presumably a lot like yours, is using FDDI and things like that. Is there a good reason for the sustained 
rates being so low ? JOHNSTON : Yes, there are a lot of good reasons . The sustained rates, transfer 
rates on a network, are governed b y how many people are using the network and how many gateways are 
between the source and the sink of data . The reason for compression is purely and simply to increase 
th e available bandwidth -- whatever it is that you can get hold o f currently -- in some way which is 
useful. I think that we're going to see a lot more of that in the future . I think that fiv e years from 
now that what Senator Gore has called the NREN -­the National Research and Education Network -- will 
provid e effectively gigabit links between all of the major scientific an d educational institutions 
in this country . Now you won't, of course, be able to get a whole lot o f that, but you'll be able to 
get a lot more than you can today, an d in conjunction with the fact that in the same five-year perio 
d your Macintosh will probably run at 80 or 100 mips, you ca n do an awful lot of compression, and my 
claim is that if you ca n get hold of even 10 or 15 megabits sustained bandwidth, whic h I feel is probably 
practical in that environment, you can do effectively real time HDTV quality animations or any sort o 
f visualization that involves that kind of thing . But you're right . A year ago our national backbon 
e supported typically a kilobyte per second . Today with the NS F backbone we're up to about 10 kilobytes 
per second, and I think in five years we'll be up to pretty close to FDDI speeds o n the national backbone 
. Q . I'm Dave Oliver with the University of Massachusetts . First of all, as a fellow rejectee of the 
SIGGRAPH video show , I'd like to congratulate Kevin on an excellent production . For those of you who 
have chosen the distributed approach to graphics and are interested in providing users with eas y programmability 
and all of the advantages we've been hearin g about at the show of having a workstation which would includ 
e editing and manipulating one's data, have you thought abou t the issues of managing data that resides 
both locally an d remotely on main host or several main hosts and all of th e many workstations ? COOK 
: I think that one's for you, Gordon . BANCROFT : Yes, we have . OLIVER : Thank you very much . HUSSEY 
: In doing that clip, in doing Mars, the Movie, clip we (because of deadlines) needed to do, quote, distribute 
d processing, so we used an Alliant, a Sun and a VAX, and sorr y to say, we had to have the entire data 
set replicated at all thre e locations to do that because eight kilobits a second does no t cut it when 
you're trying to do ray casting . It is a big problem. Distributed data like that is going to cause -- 
until this hig h speed network's available and usable -- it is going to be a majo r problem . BANCROFT: 
I guess I could say that an example I can give you to some of the sort of problems that we're dealing 
wit h with data is we have local users, we have remote users, we hav e a whole lot of different types 
of users and we had to deal wit h shared memory and shared data and what data was going to reside where 
. The people at Langley who used Diana's real tim e interactive particle tracer can't move their files 
; it's impractical for them to move their raw data from NASA Ames across th e SIGGRAPH '89, Boston, 
July 31 -August 4, 1989 country to Langley . So in that situation we saw that ou r software had to be 
able to support the remote users and be agai n flexible . And so its a big problem and its something 
we'v e really had to look at long and hard when we did the design o f our new software. COOK : We have 
a question in the center . Q. Ralph McNall from Digital . I think it can be reasonabl y said that most 
visualization environments today are not wha t Alan Kay would refer to as end user tailorable . You basicall 
y need to have a fairly significant level of computer expertise i n order to be able to tailor them to 
be effective to most individua l needs. The question I have is given that we eventually hav e what Alan 
refers to as end user tailorable environments fo r scientific visualization, how much larger an audience 
is goin g to be able to effectively use them than the current audienc e that's taking advantage of them 
. I guess I'm basically askin g what percentage of the potential users out there are we currentl y reaching 
-- number one. Number two is how much more effective will the current users and those users become tha 
n what they currently are in their day-to-day work . HUSSEY : The reason were moving toward providing 
tool s instead of capability per se is so that the visualizatio n techniques that we have developed (and 
we will continue to develop) will be transportable, for example, to anybody with a VAX running VMS for 
one, and when we go to other platform s the desire is to make sure that these tools will run on the othe 
r platforms . So we're trying to make visualization tool s available for everybody who wishes to do it 
that has a minimum set of hardware. Did I catch the drift of your question ? McNALL: Not really . What 
I was trying to get at is tha t basically right now the scientists who have effectively used most visualization 
software have had to be programmers to a certain extent or have a support staff . That basically limits 
hi s ability to flexibly adapt those capabilities to meet his specifi c needs and I wasn't asking so 
much the issue of portability ; I was asking the issue of the ability to tailor or adapt a specifi c 
analysis environment to his specific needs in a way that peopl e can do with spreadsheets today with 
like macro capabilities an d Lotus and that. A lot of people have been able to tak e advantage of those 
capabilities to make a Lotus spreadshee t environment much more effective to meet their specific needs 
, than it would be if they had to do everything manually or had t o rely on someone else to provide the 
capability . HUSSEY : We define tools as having that adaptability as well . In order to be useful, it's 
going to have to be able to do wha t you just said in most cases . So those have to be built into th 
e tools . The tools have to be extensible . McNALL: Okay, but those tools as they exist today don' t 
really address my understanding, the bulk of the people tha t could take advantage of visualization . 
HUSSEY : That's called job security . It gives us something to do. It's once we solve that problem, then 
there'll be anothe r group complaining about something else -- which is great . BANCROFT: Most of the 
tools -- I don't know about Kevin , but a lot of the software that we have, it grew like crystals, an 
d we've had to step back now and take a new approach . So mayb e it's that some of the things that you 
are familiar with are no t extensible and you see them as sort of black boxes and the y are. I guess 
the point that we're making is that those things are changing and the things will be extensible . It's 
probabl y going to be another year or so before they'll be out where people can see how they work, but 
I guess that's my sense of i t -- if I understand the question . COOK : I would like to address your 
question also . One of the features that we're trying to build into the utility that we'r e making for 
our graphics workstations is the ability to use the interface that we have and plug in your own graphics. 
So if you have a mesh type that is alien to the rest of the mesh types tha t we are plotting and your 
data is self descriptive, which is th e type of data base that we're using to get data into the tool, 
the n you can use the framework of our tool and plug in the graphic s that you need in order to do the 
plotting that you need . In our case the graphics routines would be produced by a compute r scientist 
and not by the physicist . Our physicists do not -- a t least the design physicists do not enjoy programming 
tha t much and want to use the computer as a tool and not to progra m on it. So we're trying to design 
extensibility and flexibility int o the tool that we're creating right now . JOHNSTON: Let me address 
one question that I heard yo u asking - sort of what's the untapped market ; what portion of th e community 
that could use visualization analysis techniques ar e [using them], and the answer is that in an awful 
large fraction o f the cases, it's a function of how well integrated computing i s into the other aspects 
of the scientist's environment . In the case of an experimental physicist the computer is one of th e 
primary tools. So the only issue is the availability of th e particular software and how easily can you 
get at it and so on . hr the case of the life sciences, computers are not very wel l integrated into 
that environment . There are an awful lot of wet biologists out there who routinely use a notebook and 
nothin g else. I'll have to say that I think that our savior there is th e Macintosh because what the 
Macintosh has done is to replac e the notebook and thereby introduce this whole -- I mean, th e life 
sciences are an awfully large community if you look at th e science community generally and the more 
you can introduc e computing into that community . Now certainly there are th e small specific areas 
of the life sciences community, the tomography people, for instance, that are already well integrated. 
But there's an awful lot of them that are not. As they become more integrated and I really think that 
th e Macintosh is the vehicle by which that is being done, the n we'll be able to introduce a whole lot 
of new computing tool s into that environment . Q . My question is what would it take --COOK : Do you 
want to state your name and where you're from ? Q . Bob Walsh, Digital Equipment . What would it take 
t o completely replace the wind tunnel? I remember seeing a slid e of a rocket or something put up by 
Gordon Bancroft where i t seemed that some of the surfaces weren't symmetrical wit h respect to the plane 
that split the computed from the win d tunnel computed data, and I'm not thinking of infinite bandwidth 
and infinite compute cycles, but what would it tak e to be able to completely replace the wind tunnel 
results give n the time it takes to do a wind tunnel experiment and th e sampling error that you would 
get from that experiment an d from the visualization of the resulting data ? BANCROFT: We have a lot 
better resolution. The resolution of the data in a wind tunnel is a lot lower than it is in our CFD world, 
so in terms of sampling and sampling points, we hav e trouble comparing -- I don't know what slide you 
were referrin g to, but when we compare -- if you looked at the shuttl e comparison, that's the best 
we've done at getting enoug h points to be able to do the comparison . So we actually have more resolution 
obviously computationally than we ca n measure-- no matter how you take data in a wind tunnel .   SIGGRAPH 
'89 PANEL PROCEEDING S So its not difficult to -- quote -- simulate a wind tunnel . The difficult parts 
are getting the wind tunnel -- getting enoug h points to be able to compare it to the computational problem 
and -- so that's a big problem, is getting enough points and I guess that's -- does that answer the question 
? WALSH : Sure, it does. There are distinctions. There's a slide of either a rocket or a space shuttle, 
and there are distinction s on some of the control surfaces. It's fairly good clown th e middle, except 
for some aliasing . BANCROFT : It works -- for politicians it works great and i t justifies the money 
that we're spending on the supercomputers . I mean, its a difficult thing to do . We'd really like to 
be able t o do it better. It's an important thing for political reasons and others to be able to do those 
kinds of comparisons. We actually did a highlights video where we did actual footage of airplanes flying 
and matched those as best we could with the computational visualization . So it's something that we really 
need to be able to do better . Q. Jeff Hanson from NASA Lewis . We all work at Nationa l Laboratories 
and so we have the best stuff, we could spend hug e sums of money for it. How are we going to get the 
software? I mean, I know if I call Gordon he'll send the software to me . We do CFD; so its great. But 
how are we going to get the softwar e down into the industry? How are we going to get it down t o small 
consulting houses? All our software is public domain . We have to be able to find some channel to get 
it clown to othe r people because that's another test on how we can distribut e visualization. Great 
if it's in central systems, but let's get i t down to people. How are we going to do that ? HUSSEY : 
NASA currently has a clearinghouse for its softwar e -- public domain software. At the University of 
Georgia a t Athens there's a facility called COSMIC . I don't know what th e acronym stands for. But 
again, they're in Georgia at the University of Athens called COSMIC, and if you would like a catalog, 
they'll send you one. We make periodic deliveries of VICR to COSMIC . You can get it there for a nominal 
price . BANCROFT : The problem with COSMIC is you don't have -- I know they have no Silicon Graphics 
equipment or they're thinking about buying some. It's still a problem. The Workstations Applications 
Office -- under Val Watson w e distribute the software ourselves . It goes through Val and u p through 
NASA and then comes back to us and we actuall y distribute it as well -- even though those codes also 
have bee n released to COSMIC . Val just told me that they are going to release - - we released it to 
them at least six months ago and they're going to release it this next week -- the 3000 serie s versions 
of our software -- and those things are already ancien t history and I don't even know if they're going 
to release the m on Silicon Graphics tapes . So it is a problem and I think NAS A is looking at the problem 
of how these codes are distributed an d they realize that they need to change their policy . I don't 
kno w much about that . Val is here and you could ask him . JOHNSTON: To answer the question or to address 
th e question a little more generally, that is, not even within a specific applications community, to 
a certain extent you'r e sitting at this very minute right in the middle of the bes t possible advertising 
and distribution mechanism - - that is, th e SIGGRAPH publications and the annual conferences coul d 
provide a substantial opportunity to acquaint people with the available software, and certainly an awful 
lot of people come t o these conferences to go to the exhibition to do just exactl y that. So one might, 
for instance, lobby for a mor e applications oriented section of the conference where it woul d show 
up in the proceedings or perhaps somebody should start an article in a catalog in the quarterly or something 
like that . I mean, there's an awfully large audience to the variou s SIGGRAPH functions and I don't 
think that we've made ver y good use of that in terms of the kind of thing you're talkin g about . COOK 
: I really like that question because that's somethin g that we've been looking at also at Lawrence Livermore 
. How d o we find out and how do we distribute? And I think it' s something that SIGGRAPH ought to address 
to have a centra l forum for that . We would like to be able to give away the too l that Jeff Long and 
a couple of other people are developing i n my group, but we don't want to see him getting thousands 
of people calling up asking about problems or new additions t o the software . I think that it's a problem 
that should b e addressed probably by SIGGRAPH, and I've been informed tha t we're running out of time 
here. If anyone has anymore comments on this, I'll take one more comment, but otherwise, I was told that 
Salon J is where we should retire if we have an y more questions or discussions . Okay, thanks very much 
.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>77285</article_id>
		<sort_key>159</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Speech and audio in window systems: when will they happen?]]></title>
		<page_from>159</page_from>
		<page_to>176</page_to>
		<doi_number>10.1145/77276.77285</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=77285</url>
		<abstract>
			<par><![CDATA[<p>Good afternoon. Boy, I can't see anything out there. I assumeyou all can see me -- thats why these lights are here. My name isChris Schmandt from the Media Lab at MIT. I'm co-chairing thispanel with Barry Arons, who is sitting over here. It's actuallyquite a pleasure to co-chair this panel with Barry. We've beenworking together off and on for more years than I care toremember.</p><p>This panel has a long ridiculous name. Basically it's aboutaudio and window systems and workstations. I'm wearing two hatshere. I'm going to spend a minute or two introducing the panel andthen I'm going to spend some time talking about my own segment ofthe panel.</p><p>We're going to try to be a panel as opposed to a series of fivemini-papers that never get published. In other words, we're goingto try to keep our presentations relatively short, then segue intoa series of prepared questions that the panelists are going toanswer amongst themselves. Then we'll open the floor up forquestions.</p><p>In some ways this is a very incestuous crew. We've all knowneach other for quite a while. We have different slants and we'reactually going to try to focus on those slants a little bit. So ifwe disagree with each other, that doesn't necessarily mean wereally hate each other. We're all friends.</p><p>Where this panel is coming from is a surge of interest in audio,and multimedia, in general, in computer workstations. The Macintoshhas had audio for quite a while -- you may or may not choose tocall that a workstation. The NeXT computer sort of surprised peopleby having fairly powerful DSP and audio in and out. You'll get ademo of that later if you haven't seen it. The Sun SPARCStation hascome out with some primitive digital record and playbackcapabilities.</p><p>On the other hand, there's been interest in voice in computerworkstations for years and years, and what we've seen so far isthat voice really hasn't had very much success. There have been anumber of products that have come and gone. What has become popularhas been centralized service -- specifically voice mail. Voice mailis tied in more to a PBX -- and the interface is more like atelephone than it is a mouse and window system, in the computerworkstation interface.</p><p>Obviously, window systems are here to stay. We're not suggestingthat audio is going to replace the graphical paradigm, but ratherhave to interact with it.</p><p>On the other hand, everybody has a telephone. People hadtelephones on their desks before they had workstations, and we talkall the time at work. Voice really is a fundamental component ofthe way we talk, the way we interact with each other.</p><p>What we're seeing in terms of the technologies showing up inthese workstations is higher bit rate coding. Gone are the days ofunintelligible low bit rate linear predictive coding or somethinglike that -- except for specialized applications.</p><p>Speech recognition is here, but it's in its infancy.Text-to-speech -- it's around, it's difficult to understand. Youcan learn to understand it.</p><p>Telephony is obviously part of this set-up if we're dealing withaudio. We don't know whether it's going to be analogue or digital.Is it going to be plain old telephone or is it going to beISDN?</p><p>Those are some of the issues that we're going to be talkingabout in this session. As I say, we're going to try to keep each ofthe speakers to a relatively short period -- and now I can put onmy other hat. (puts toy plastic headset on -- laughter)</p><p>Some people ask me whether speech recognition is a toy or not.Yes, it is. It's sort of a fun toy. Speech technologies are ingeneral fun. I was originally hoping to be able to play this out tothe audience. But I don't think it's going to work well enough.This is actually a kid's toy -- $50 at Toys R Us. SpeakerIndependent Isolated Word Speech Recognizer -- "yes", "no", "true",and "false". It will take you on tours about dinosaurs and thingslike that.</p><p>From my point of view, the key for what we can do with voice hasto do with understanding its advantages and disadvantages and thecomcomitant user interface requirements leading us to designreasonable applications for it.</p><p>Voice has some advantages. It's very useful when your hands andeyes are busy; you're looking at a screen, you have your fingers onthe mouse. Sometimes it's intuitive; we learn to talk at a veryearly age. People talk to their computers even if the computersdon't have speech recognition. (laughter) Usually it's expletives-- especially with UNIX. (laughter) Voice really dominateshuman-to-human communication. No matter what we're doing withE-Mail and FAX, the bottom line is we just still have to spend acertain amount of time physically speaking to each other.</p><p>Telephones are everywhere. If I can turn an ordinary pay phoneinto a computer terminal, suddenly I have access from all over theplace.</p><p>From my own work, this suggests a heavy focus ontelecommunications. The kinds of systems that I'm building arereally designed to use voice in a communications kind ofenvironment. On the other hand, there's many, many disadvantages ofvoice. It's very slow. 200 words per minute, 150-250 words perminute. That's less than a 300 baud modem and who uses those anymore.</p><p>Speech is serial. You have to listen to things in sequence. It'sa time varying signal by definition. And it requires attention. Youhave to listen to what's going on, as opposed to simply scrollingit by and stopping it occasionally.</p><p>My way of characterizing this is to say that speech is "bulky".Yes, it takes up space on the file system, but most importantly youcan't "grep" it, you can't do keyword searches on it. It's hard tofile, it's just hard to get any kind of handle on it. It takestime.</p><p>Finally, speech broadcasts. If my workstation is talking to meand you're sitting in my office, you're going to hear what it says,which is very different from if it appears as text. In fact, if itappears as text, and I'm sitting in front of the screen with thesekinds of tiny bit map fonts that we tend to use, I'm probably noteven going to be able to read it -- much less you.</p><p>This has some user interface implications. One is that itsuggests that we would like, where possible, to have graphicalaccess to sounds. I'm going to show a video in just a second,showing you an interface to audio built under the X Window System,designed to give you some kind of a graphical context, so you canmouse around and perhaps use some visual cues to keep track ofwhere you are in the sound. If you could roll the first piece ofone-inch, please.</p><p>This is a sound widget.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>B.4.2</cat_node>
				<descriptor>Voice</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>B.4.2</cat_node>
				<descriptor>Data terminals and printers</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010594</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Printers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010597</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Sound-based input / output</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14130541</person_id>
				<author_profile_id><![CDATA[81100365992]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[B.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Arons]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Olivetti Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39082887</person_id>
				<author_profile_id><![CDATA[81100444749]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schmandt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MIT Media Lab]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14076588</person_id>
				<author_profile_id><![CDATA[81344491653]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hawley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NeXT Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP45030307</person_id>
				<author_profile_id><![CDATA[81344494245]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[H.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ludwig]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bellcore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P218646</person_id>
				<author_profile_id><![CDATA[81100351035]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[P.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zellweger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Xerox PARC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SIGGRAPH '89 PANEL PROCEEDING S Panel Sessio n Speech and Audio in Window Systems : When Will They 
Happen ? Co-Chairs : Barry Arons, Olivetti Research Center Chris Schmandt, MIT Media Lab Speakers : 
Michael Hawley, NeXT Inc. Lester Ludwig, Bellcore Polle Zellweger, Xerox PAR C Good afternoon . Boy, 
I can't see anything out there . I assume you all can see me -- thats why these lights are here . My 
name is Chris Schmandt from the Media Lab at MIT . I'm co-chairing this panel with Barry Arons, who is 
sitting over here. It's actually quite a pleasure to co-chair this panel wit h Barry. We've been working 
together off and on for more year s than I care to remember . This panel has a long ridiculous name. 
Basically it's abou t audio and window systems and workstations . I'm wearing tw o hats here. I'm going 
to spend a minute or two introducing the panel and then I'm going to spend some time talking about m 
y own segment of the panel . Were going to try to be a panel as opposed to a series o f five mini-papers 
that never get published . In other words , we're going to try to keep our presentations relatively short 
, then segue into a series of prepared questions that the panelist s are going to answer amongst themselves 
. Then we'll open th e floor up for questions . In some ways this is a very incestuous crew . We've al 
l known each other for quite a while. We have different slants and we're actually going to try to focus 
on those slants a littl e bit. So if we disagree with each other, that doesn't necessaril y mean we really 
hate each other. We're all friends . Where this panel is coming from is a surge of interest i n audio, 
and multimedia, in general, in computer workstations . The Macintosh has had audio for quite a while 
-- you may o r may not choose to call that a workstation . The NeXT compute r sort of surprised people 
by having fairly powerful DSP an d audio in and out . You'll get a demo of that later if you haven' t 
seen it. The Sun SPARCStation has come out with some primitive digital record and playback capabilities 
. On the other hand, there's been interest in voice i n computer workstations for years and years, and 
what we've see n so far is that voice really hasn't had very much success . There have been a number 
of products that have come and gone . What has become popular has been centralized service -- specificall 
y voice mail. Voice mail is tied in more to a PBX -- and the interface is more like a telephone than 
it is a mouse and windo w system, in the computer workstation interface . Obviously, window systems are 
here to stay . We're no t suggesting that audio is going to replace the graphica l paradigm, but rather 
have to interact with it . On the other hand, everybody has a telephone . People ha d telephones on their 
desks before they had workstations, and w e talk all the time at work . Voice really is a fundamenta 
l component of the way we talk, the way we interact with eac h other . What were seeing in terms of the 
technologies showin g up in these workstations is higher bit rate coding . Gone are th e days of unintelligible 
low bit rate linear predictive coding or something like that -- except for specialized applications . 
Speech recognition is here, but it's in its infancy . Text­to-speech -- it's around, it's difficult to 
understand . You ca n learn to understand it . Telephony is obviously part of this set-up if we're dealin 
g with audio . We don't know whether it's going to be analogue o r digital . Is it going to be plain 
old telephone or is it going t o be ISDN? Those are some of the issues that we're going to be talkin 
g about in this session. As I say, we're going to try to keep eac h of the speakers to a relatively short 
period -- and now I can put on my other hat . (puts toy plastic headset on -- laughter ) Some people 
ask me whether speech recognition is a to y or not. Yes, it is. Its sort of a fun toy. Speech technologies 
are in general fun . I was originally hoping to be able to pla y this out to the audience . But I don't 
think it's going to wor k well enough . This is actually a kid's toy -- $50 at Toys R Us . Speaker Independent 
Isolated Word Speech Recognizer -- "yes" , "no", "true", and "false". It will take you on tours about 
dinosaurs and things like that . From my point of view, the key for what we can do wit h voice has to 
do with understanding its advantages an d disadvantages and the comcomitant user interface requirement 
s leading us to design reasonable applications for it . Voice has some advantages . It's very useful 
when you r hands and eyes are busy ; you're looking at a screen, you hav e your fingers on the mouse 
. Sometimes it 's intuitive ; we learn to talk at a very early age . People talk to their computers eve 
n if the computers don't have speech recognition . (laughter) Usually it's expletives -- especially with 
UNIX . (laughter) Voice really dominates human-to-human communication . No matter what we 're doing with 
E-Mail and FAX, the bottom lin e is we just still have to spend a certain amount of tim e physically 
speaking to each other . Telephones are everywhere . If I can turn an ordinary pa y phone into a computer 
terminal, suddenly I have access from al l over the place . From my own work, this suggests a heavy focus 
o n telecommunications . The kinds of systems that I'm buildin g are really designed to use voice in 
a communications kind of environment . On the other hand, there's many, many disadvantages of voice. 
It's very slow . 200 words per minute , 150-250 words per minute . That's less than a 300 baud modem 
and who uses those any more . SPEECH AND AUDIO IN WINDOW SYSTEMS : WHEN WILL THEY HAPPEN? BIGGRAPH '89, 
Boston, July 31 - Au tst 4, 198 9 Speech is serial . You have to listen to things in sequence. It's a 
time varying signal by definition . And it require s attention . You have to listen to what's going on, 
as oppose d to simply scrolling it by and stopping it occasionally . My way of characterizing this is 
to say that speech i s "bulky". Yes, it takes up space on the file system, but mos t importantly you 
can't "grep" it, you can't do keyword searche s on it. It's hard to file, it's just hard to get any kind 
of handle o n it. It takes time . Finally, speech broadcasts . If my workstation is talkin g to me and 
you're sitting in my office, you're going to hear wha t it says, which is very different from if it appears 
as text. In fact, if it appears as text, and I'm sitting in front of the scree n with these kinds of 
tiny bit map fonts that we tend to use, I' m probably not even going to be able to read it -- much less 
you . This has some user interface implications . One is that i t suggests that we would like, where 
possible, to have graphica l access to sounds . I'm going to show a video in just a second , showing 
you an interface to audio built under the X Windo w System, designed to give you some kind of a graphical 
context , so you can mouse around and perhaps use some visual cues to keep track of where you are in 
the sound. If you could roll the first piece of one-inch, please . This is a sound widget . VIDEO TAPE 
BEING PLAYED Thanks to Mark Ackerman for doing the coding . As yo u can see, this is integrated in the 
rest of the window system an d this is a recurring theme, and what I'm talking about is the nee d for 
integration --and we'll get back to that in just a second . Another issue here with voice is because 
it's so slow, yo u have to support interruption . In the case that I just showe d you, while playing 
a sound, you could mouse around and stop i t and play any other sound . You could drag the little curso 
r around and let go and hear a piece over . If you're calling u p from a telephone, you always have to 
be listening for the use r to respond to a touch tone while you're playing something . You don't want 
to leave somebody where they have to listen t o a three-minute message in order to do the next thing 
. Predictably what they'll do is hang up and walk away . That' s not a useful user interface . Finally, 
because of the difficulties of speech, this suggest s it might be useful as an auxiliary channel. We're 
not trying t o replace the keyboard . We're not trying to replace the mouse -­or maybe we are trying 
to replace the mouse . But what I'rn suggesting is that for some of the kinds of operations that I' d 
like to do on a computer, voice is a side channel which ma y convey another channel -- another domain 
of information . An d obviously, in terms of auxiliary channels, if I'm not in a situation in which I 
have a terminal, I have a keyboard, and a CRT, and a mouse, then the world is wide open for voice , calling 
in from a telephone . You can only do so much with a 12-button touch tone keypad. From my point of view, 
and the work that we're doin g currently at the Media Lab, the key really is integration . Soun d is 
not a medium that exists without respect to the other kinds o f things that are going on in the workstation. 
As I already said , there's a need for graphical representation . So here right awa y we're tying in 
graphical user interface and the audio as data . What we would like is for voice to become an integrate 
d part of whatever window system we're using -- becaus e obviously, window systems are simply part and 
parcel of ou r computing environments these days . We'd also like speech to become a ubiquitous data 
type -- something that we can use in a variety of applications -- in just the same way that we use text 
. We don't really think of text as a data type . Text is just th e medium that we use to interact with 
things. Sometimes it's a command channel when I'm typing into the shell . Sometime s it's data when I'm 
editing a document, and we'd like voice to be able to do the same thing . This really suggests that we're 
looking at multiple applications . In the rest of my talk I'll describe some of these ­ -a number of 
different voice applications . And thos e applications are going to cover a range of functions -- thing 
s like editing and document creation and messaging . And they're going to coexist with the kinds of things 
we al ready do on our workstation . We're not going to stop using our workstation s for editing programs 
because all of a sudden we're going to star t recording voice on them . This is going to suggest that 
thos e applications are going to have to have access to resources . Audio resources are going to be shared 
just like bits on a scree n or shared by a window system . Barry is going to talk abou t this in some 
detail in his talk . Finally, in terms of a window system, I believe that we'r e going to need a technique 
for doing multimedia selections . One of the things that window systems get us is the ability, under 
user control, to select a piece of data and stick it in another application -- call it selection, clipboard, 
cut and paste or whatever. Things start to get interesting when the object of the selection -- it may 
be text, or it may be audio, or it may be a sound file ; it may be a sound file segment . In fact, from 
the point of view of my interest i n communication, the selection might be a telephone numbe r which 
is temporarily represented as text, or it might be a n address, or it might be a reply to a telephone 
message . We nee d to be able to support the ability to shift these different kinds o f data and different 
messages associated with that data back and forth between applications . So basically, the long and the 
short of it is that I'm sayin g that speech really needs to become integrated into the windo w system 
in many, many different ways, in order for it to achiev e the kind of functionality that we currently 
have with text . It' s never really going to get there, but it may be able to approac h it asymptotically 
. In terms of applications, answering machines and voic e mail, they're almost the same . Voice mail 
gives you the abilit y to forward messages . Here is an old slide from an old syste m called Phone Slave, 
that Barry and I built a tong time ago at th e Media Lab with graphical representations of sounds . 
SPEECH AND AUDIO IN WINDOW SYSTEMS: WHEN WILL THEY HAPPEN?      SIGGRAPH '89 PANEL PROCEEDING S 
Edison invented Kinetaphone in 1895 and it was a flop, A very much McLuhanesque kind of progression . 
Not unlik e combining a computer with a telephone, Edison took a gian t photograph player and hooked 
it up to a projector . The phonograph was down by the screen and there were a system of belts of pulleys 
to try and keep it in sync . This is not unlike some approaches that are being taken right now by people 
i n the computer industry to integrate audio into their workspaces . There were a host of almost Balkan 
approaches to th e problem. If you look back over the inventions, you find Cameraphone, Kinetaphone, 
Chronaphone, Vivaphone , Synchroscope, Cinetalk -- dozens and dozens of littl e companies started up 
to all try and push their way into th e market. And they all tried the same thing and failed . They too 
k a very orthodox approach . They tried to mate the phonograp h with the silent movie to come up with 
something new, and i t sort of worked, but not quite . In 1925 a fellow named Lee DeForest had the bright 
idea t o try and actually impress the audio on the same strip of media a s the image. An optical soundtrack 
-- the very first one. He did quite well, except he was sort of a bumbling and lackluste r entrepreneur, 
so he was unable to cut the key deals and get the kind of press that he needed in order to make a dent 
in th e industry . Eventually, of course, they figured out sound . . . -- but does anybody, by the way, 
know who actually solved the proble m once and for all? Shout it out if you know . . .? It was AT&#38;T 
-­the phone company . In 1925 they teamed up with Warne r Brothers and decided to really lick the film 
sound problem, an d in 1927 Al Jolson was singing away in the Jazz Singer, th e very first talking film 
. There was a 50-year evolutionar y period after that that got us through to THX . Right now where I 
think we are is at the beginning of the "talkies curve" wit h computers . The computer that some friends 
and I built -- the NeX T machine -- is really like the Al Jolson of computing . And th e question we 
should be asking is if Al Jolson is to NeXT, the n THX and Lucasfilm quality Sound Design are to ., . 
what? Wher e are we going and what kinds of technologies do we need ? The more that people hammer away 
on rinky rink custo m speech cards that all cost two or three thousand dollars, th e more twisted and 
warped the approaches are going to get, and I think only by stepping back and tackling a hard problem 
ar e we going to be able to get the kind of integrated audio that wel l need to produce the most wonderful 
SIGGRAPH film, or th e most wonderful user interface in the future . So with that in mind, let me press 
a few buttons on th e NeXT and just try and show you quickly the basic capabilities here. It's got high 
quality audio output, compact disc audio quality, and voice-quality input -- although you can also fee 
d data directly into the DSP port and crunch on it . I think i t provides some of the foundation tools 
that people will need i f they want to invent say, the postscript for audio, or other suc h languages 
. First of all, let's play two sounds real quickly . Here i s some livestock I happen to have lying around 
; this is a cow . This is what a cow looks like . It's a frequency domai n transform . Now I don't know 
of any computer yet that can tel l the difference between a cow and a sheep, but if I bring up -­whoops, 
that's our cow again. Here's a goat. Goats are kind of like sheep . They bleat, in evenly-spaced pulses 
over time, and if I play the sound you'll hear that . This is the cow . (Moo!! ) Whoa. And this is a 
goat. (Baca!) Now it's real easy to tell at a glance which one is which . The cow has kind of a widespread 
spectrum with an amplitude and frequency curve that sweeps up ; the goat does not . We can play the cow 
backwards . It stil l sounds like a cow -- kind of a distressed cow . On the othe r hand, as you might 
guess, a goat sounds the same forwards o r backwards . It's a pretty symmetric sound in time . Whoops 
, that's a goat . Somewhere I have a human impersonating a goat . And this looks unfortunately different. 
There are still pulses , but they're not so well autocorrelatecl . It would be desirable t o be able 
to come up with a language for representing a soun d adequately so that you could tell the difference 
between sheep s and cows and goats and chickens, and people impersonatin g the same things, as well as 
different types of speakers . Thes e sort of elements are not yet nuts and bolts that can be screwe d 
into current user interfaces -- but they'll have to be . NeXT, of course, has integrated audio into the 
mai l system. I'll show that to you very quickly. You can send out a letter to someone . Let's send a 
note to Steve Jobs . I don' t know if it will get there or not, but to send a little voic e annotated 
message, we can record a little bit . . . "Hi, Steve, thi s is Mike . This is a test ." And then play 
the sound back . ("Hi , Steve. . .") It's possible to go in and edit it. We see a little wiggly waveform 
and scroll around . Notice smooth scrollin g everywhere. Select little bits of sound, play them out. 
I think there are lots of approaches that can be taken for this problem . Since we all are on such tight 
time budgets, let me come up t o the microphone and sum up in about 30 seconds . NeXT really is the first 
machine that you can purchas e which has an "ear" (a microphone) and which has high qualit y sound output, 
and really the capability that one needs t o approach the sound problem in a general way . I don't think 
it' s been licked yet . Were just at the beginning of a very fun and very exciting curve, and I really 
believe that audio is going to impart more personality and spunk and feeling to use r interfaces than 
we know what to do with right now . We need to think deep thoughts about more than just speech, and I 
hop e that next year when SIGGRAPH rolls around there will be NeX T machines providing soundtracks for 
the movies -- not jus t squeaking Foleyed Luxos . Thanks very much . Moderato r Chris Schmandt MIT Media 
La b Thanks for bringing your toys, Mike . I wish we had mor e time to play with them . The final speaker 
is Barry Arons fro m Olivetti Research Center . Barry Aron s Olivetti Research Cente r Hi . I'm going 
to talk a little bit about a project tha t integrated voice and audio into the workstation, some hardwar 
e and software approaches of how we did that, and then som e current research -- what we're doing now 
to improve upon tha t architecture . The project I'm going to talk about is called th e Conversational 
Desktop . It's built in a large extent upon th e ideas in Phone Slave, that piece of tape that Chris 
showe d earlier -- it was a conversational answering machine . Howeve r in the Conversational Desktop, 
there was a much deeper leve l of integration into a network of workstations . One interesting thing 
that we did was to do audio-base d direction sensing . The user would wear a headset mounte d microphon 
e  SPEECH AND AUDIO IN WINDOW SYSTEMS : WHEN WILL THEY HAPPEN?   SIGGRAPH '89, Boston, JyIY 31 -A 
cu uSt 4, 1909 you hear different kinds of sounds and attributes of the sound s tell you a attributes 
about the data set . People are investigatin g this sort of thing . There's also other applications too 
where you could us e environmental audio, for example in training an engin e mechanic to listen for audio 
cues as running engines ar e adjusted and that sort of stuff . But for synthesized audio, a lo t of times 
just having sort of backdrops of different kinds o f sounds could be useful . Somewhere in this year's 
conferenc e videos -- I forget which video -- someone showing somethin g about some workstation or some 
data set, and just the moo d that some of the background music created I think could be use d as an audio 
symbol to denote the input focus in a multi ­application display. Also, in Scott Fisher's stuff with 
the artificial realities, as you move from on artificial reality worl d to another, you could have different 
audio background theme s cluing you in as to what world you currently were in . Such cue s from backdrops 
can be very important I think . ARONS: This is the last question -- if you want to get up -­we're going 
to take questions after this . What are th e advantages and disadvantages of using analogue versus digita 
l technologies ? SCHMANDT : Let me just say one word on that . Everythin g is digital down the road . 
Telephones are going to be digital . You think it's going to be a wonderful digital world . We hav e 
digital telephones at MIT and it ends up being a real pain in th e something-or-other to try to get your 
computer to talk to thi s digital telephone -- even though it's all digital . There' s protocol conversions, 
and you end up with a co-processor i n your machine and suddenly to talk to your telephone line cost 
s you an extra 1500 bucks . ARONS: In terms of our set-up, were really trying to set up a rapid prototyping 
environment so we can build application s like you saw here today really quickly and there just isn't 
th e software running on a DSP that will let us simultaneously do recording and playback and synthesis 
and recognition all at th e same time . So it's easier for us right now to use a bunch o f analogue components 
and plug them together . It's really chea p and it's efficient . The other problem with digital right 
now in terms of using external components is that there is lots of standards . There is all kinds of 
different encoding rates in bit rates for audio and different ways to compress it . So it's easier for 
us just to us e analogue . HAWLEY : I've always thought the question of analog versu s digital is sort 
of a no-brainer -- the great property of all digita l things is you can edit them, and once that door 
is open, you ca n do miraculous things with digital audio . But on the flip side there is a transition 
period that one has to get passed in order t o ensure that the data is reliable . You see, the not so 
great property of digital things is that if a bit goes bad, the syste m tends to either work or not work 
. Namely, if a bit goes bad, i t doesn't work . Analog media tend to degrade more gracefully . You accumulate 
noise, but at least you can hear some signal , whereas digital stuff is sometimes subject to drop-outs 
. So until the technology stabilizes, which also has something t o do with standards and the amount of 
attention industry pays t o it, I think digital is going to feel a little creaky to us, but it' s clearly 
the right thing to do . ARONS : We're going to open it up to questions -- go ahead i n center . Q. I 
have a really obvious question . Do we really want to b e talking to our computers and do we really want 
to have thi s extra noise in our office space, because I get annoyed when I hear someone's Mac go "biqueeee" 
and all this irrelevant nois e going on in my environment . I don't have the luxury of havin g my own 
office enclosed space isolating me and I don't necessarily want to wear a headset, so where do you see 
th e happy medium there ? SCHMANDT : Good question, a very good question . The question is -- it has 
to do with appropriateness . If you'r e working in an environment in which you can hear othe r people, 
clearly you can hear them on the telephone. It's not an office if they're not on the telephone . I think 
hearing peopl e having a conversation -- one side of a conversation on a telephone is a whole lot more 
distracting than hearin g somebody occasionally speak the name of their window, whic h is what I'm seeing 
with some of my students right now . On th e other hand, it's a real problem that voice does broadcast 
. ARONS : In the center in the back . Q. Hi . I'm interested in how you're solving problems wit h the 
general real-time operating system stuff, particularl y relevant to I believe the NeXT and also Etherphone. 
Yesterday we talked in the multimedia session a lot about the problems o f you've got no real-time operating 
system . How are you going to be scheduling between tasks, and not breaking up the signal that you 're 
receiving from the user, or transmitting back . So I'm interested to hear how you're overcoming these 
problems , or whether you just ignore them and hope they go away . HAWLEY : I think the operating systems 
question is reall y central to how adequately a computer can handle hig h bandwidth media . And current 
operating systems, as you poin t out, really cannot schedule audio efficiently enough in order to make 
the best use of it . Now in the case of NeXT, we took a pretty straight-forwar d approach . We had to 
make the system be 4 .3 BSD compatible , but we knew we were going to use MACH . MACH provide s lightweight 
processing at the "thread" level, which is muc h more amenable to control of tasks like audio streaming 
throug h the machine . There are also some hardware innovations that facilitate this kind of thing, like 
the way the DMA works in the operating system -- it puts much less strain on the main CP U when some 
piece of sound goes squirting through . I'm not trying to brush off the problem because it stil l exists 
and I guess in real practical terms the way the current NeXT machine scales up -- and remember the NeXT 
is only th e next; it's not the last -- is that running off an optical disk on e can generally play CD 
quality sound through the CPU and take down about 20% of the CPU. It's too difficult to record compac 
t disk quality sound directly onto a magneto- optical dis k because the writing bandwidth is not high 
enough on optica l disk technology yet . However, you can record stereo CD rate sound onto a magnetic 
disk -- but not much more than that . That's about a s fast as the drives will go . One last little seat 
of the pants number to keep in mind i s that running at about 25 megahertz in an 68030, if you want t 
o play telephone quality sound, which is commonly eigh t kilohertz and Mu-law-encoded -- that's 8,000 
bytes per secon d with a special logarithmic type of encoding . The converters run at 44 kilohertz . 
And that means that you have to interpolate the sound -- which is an arithmetic-intensive computation 
-- in order to feed the DACs at the right rate . That's tricky . It can either be done through a DSP, 
which w e have one of, or it can be done through the main CPU, whic h takes 20% or 40% . Either way, 
there is a lot of crunching tha t has to go on and it's very clear -- to me anyway -- that curren t 
 174 SPEECH AND AUDIO IN WINDOW SYSTEMS : WHEN WILL THEY HAPPEN? operating systems are sort of a shoehorn 
solution, but no t really taking the bull by the horns. ARONS: Over there; please state your name and 
affiliation so people know who you are . Q . Nobody else had to . Bart Locanthi at Bell Labs . I have 
a flip side to the other question, which is are we sure we want ou r computers listening to us? I mean, 
when we think they'r e listening. Maybe they're listening when were swearing at them or when were -- 
 HAWLEY : I'd kind of like to put an end to this line o f questioning. Do we really want to read books 
off of computers ? People ask me all the time . Why would I want to rea d Shakespeare off of a computer 
screen? And the point is tha t you guys are going to fix graphic display technology for us i n the next 
10 years and make it as compelling as paper . The same is true of color. Why would I want to look at 
anything on one of these obnoxious Mexican-color-TV displays that peopl e are showing all over the place? 
People by and large do no t make appropriate use of color technology . And I think audio -­both in and 
out -- is the same kind of thing. There's always th e Big Brother potential looming in the background, 
but clearl y there are very useful things one can do with sound . It' s a virtually untapped resource 
and I think we have an obligatio n to figure out what the right things are to do with it before someone 
gums up the works by doing the wrong thing an d selling too many computers . SCHMANDT : In the back, 
please . Q . Ken Pier, Xerox PARC . A question for Mike . What yo u  demonstrated was a multimedia 
mail application and som e isolated sort of manually clone playback of pre-recorded voic e or pre-recorded 
sounds. What kind of tools are available on the NeXT machine, or planned, to be able to build the kind 
o f multimedia documents that we've been seeing ? HAWLEY : That's sort of a large question . Let me try 
and answer it real briefly. There is a fair amount of software fo r dealing with the digital signal processor 
at a nuts and bolts level . If you want to write auto correlators or do low level DS P stuff, you can 
do that . There is object-oriented stuff in a thin g called the "sound kit", which controls management 
of audio i n and out -- recording and playing of various formats . You ca n get down to samples and display 
them on the , screen. That begins to tap into a software library called the Application Kit , which provides 
"view"-like objects and window objects to support display and editing of sound . As far as integrating 
audio into documents is concerned , that's more of a can of worms that we've tried not to open u p yet. 
A lot of people have done hyper-text very, very badly, an d we've been quite conservative. You won't 
see "link" buttons i n our documents yet . However, it is possible to nail in bits o f sound and I think 
maybe Dick Phillips has done a little bit o f that with his "living" SIGGRAPH proceedings demonstration 
. I haven't seen it yet, but -- high level integration we leave tha t to other people to figure out for 
the moment, because any othe r solution would be more of a liability in five years than a cure . Q . 
My name is Mark Linnish, and someone talked a little bi t about needing a language like Postscript for 
audio, and one o f the things that really concerns me about this whole multimedia area is common file 
formats . How do you share those thing s and how do you share them over networks, and how can I receive 
a -- let's say a compound document with audio and som e of these kind of things from my machine when 
you send it -­and we've got different machines and all that kind of stuff . So I was just going to ask 
the panel again about this idea o f common formats or --  SIGGRAPH '89 PANEL PROCEEDING S SCHMANDT : 
There's actually a lot of work being done o n that. From my own personal point of view, the reason I'v 
e been using X windows is not because I love the X windo w system, but because of portability . As soon 
as I get a version of X running on the NeXT', then I can start playing with th e NeXT. In terms of interchange 
protocols -- you're talkin g standards, you're talking CCITT, you're talking about 10 years to get anything 
done . There is a lot actually happening in th e X.400 series of protocols to sort of standardize some 
of those message handling, to at least allow us to have different body parts that have different media 
in it . It's still probably goin g to be a case that the speech format that I'm using on m y machine 
may be different from the speech format that you'r e using on your machine, which may involve conversion 
and reconversion . On the other hand, a lot of the speech coding came out o f the need to get rid of 
a lot of bits and since my belief is that memory is cheap enough and disk space is plentiful enough that 
we may end up going with relatively unencoded speech jus t for the ease of moving it back and forth -- 
you know, 64 kilobi t voice. You can edit it, you can do anything you want to it an d it's relatively 
cheap to move around . LUDWIG : I'd like to respond to that a little bit too , obviously because it's 
involved with communications . We're at a period now I think when there 's a lot of change going o n 
and usually when there's a period of change going on, there' s some people who wish the change already 
happened and wonde r why it hasn't happened yet and there's those who figure wh y even bother with the 
change. So all of us are sort of torn between what's comfortable and what's doable and what w e know 
is feasible, and what we'd like to see and what we kno w we can do to get in between . And I think probably 
right no w what's going on is there's some hesitation on the part o f decision makers spending resources 
to develop these things i n earnest, and the need to actually do that, the need to sit dow n with the 
problem and figure out what the appropriat e machinery, what the appropriate technology is . It won't 
b e until after some of that foundational work is done and you ge t the demonstrated possibility for 
market share that people wil l sit down and make the compromises that they need to get th e different 
kinds of standards. Sure, there's the standards form s and so forth, but a lot of times they -- with 
all due respect -­work in isolation from the technology and the best technica l solution . So I think 
until there gets to be some unification as to what we want to do with this stuff, what's the right kind 
of thing to do and what sort of the common denominator is acros s a lot of the applications, the so-called 
primitives -- mayb e that's what the Postscript thing is . It's going to be a bit of a problem to expect 
the standards to come prematurely, and I think we're seeing that in all kinds of things -- not only digita 
l audio or the audio functionality, but also in the HDTV busines s that's going on in this country, if 
you're familiar with that . Everybody's trying to figure out whether it should be like a T V set or more 
like a workstation . Same kind of phenomena . HAWLEY : Just to sum up with a real quick analogy, it strike 
s me that your question is a great one, but it's asked really early . It's a little bit like asking "What 
about Postscript?" before the y made a laser printer . Right now there's only one computer tha t does 
general audio in and out, and it's the NeXT . Maybe there will be more; I hope there would be lots more 
to help create tha t industry .  SPEECH AND AUDIO IN WINDOW SYSTEMS : WHEN WILL THEY HAPPEN? SIGGRAPH 
'89, Boston, July 31 -Auac ust 4, 198 9 LINNISH : If the standards were there though, I could envisio 
n buying one of these things for fairly cheap and I can't do that right now . HAWLEY : Well, I think 
its the cart before the horse though . Standards come after you push enough devices and technologie s 
around . LUDVVIG : We also know about standards that are mad e prematurely . I won't mention any of them 
. SCHMANDT : Over here on this side . Q. Cliff Bashears, Columbia University. My concern is on voice 
as an input device . I haven't heard any mention of usin g the pitch to control say a valuator, and in 
general a more ric h taxonomy of devices as you find in the graphics literature . Have you people thought 
about how to categorize differen t parts of the voice and simulate other devices that are commonl y used, 
and do you think that's a hokey idea or do you think yo u should incorporate it in VOX? I just want to 
hear your thought s about it . SCHMANDT : I've clone a lot of work of trying to understan d human intonation, 
just of speech, not of non-speech sounds. It's very exciting, its very important . It ends up being extremely 
difficult to do . HAWLEY : Go talk to Bill Buxton about that one . He know s lots of people who've already 
controlled sliders by singin g various pitches into a microphone . And in my own lab when I do music 
research I often sing notes into a pitch tracker, t o provide pitch input, or to push other things around 
. It's moderate hokum, I would say. But there might be something there, particularly for handicapped 
users . ARONS: At H.P. Labs we started doing a little bit of work to try to use pitch to help speech 
recognition . If you can tell b y the pitch if something is a question or a statement, you can d o better 
in the recognition phase . HAWLEY : But I could put on my Media Lab hat there for a second too, which 
is to say one of the things that people d o when they listen is detect anxiety or pleasure and other 
feature s like that in the voice of the person they're talking to, and i t might be useful at some point 
in time if the computer can tel l when you're screaming at it -- notice whether or not you'r e distressed 
and maybe offer some assistance . (laughter) So i n the very long terra, there are a number of let's 
say mor e emotional features that could be measured, and which would b e useful . ARONS : Again, over 
here on the right ; I'm afraid we'r e running out of time -- so this is going to be the last question 
. Q . I'm Leo Hourvitz from NeXT also, and I want to grous e about telephony and see if we've got any 
way out of this . I sat about 10 feet away from the geek when he and Barry did the Phone Slave, and I 
thought this was really great . Gee, I wan t one of these bad . Now we can see machines coming out tha 
t like have the ability to throw that audio around . I mean, eigh t kilobytes per second isn't that bad 
on these generation o f workstations . But the phone interface has gone backwards . I mean, it used to 
be you knew what a phone was . You know , Bell came, they wired it in, it was analogue . You could get 
b y with two wires if you had to . But now, those things -- I haven' t had a desk with a normal phone 
in like four years, right . It's al l been some kind of PBX which has changed about every eigh t months. 
And the interface to every PBX is different. I don't have an analogue phone line any more . How can I 
possibl y connect my computer to it? Okay, panel, get us out of this . SCHMANDT : That's what ISDN is 
supposed to be all about. HOURVITZ : Right. But is ISDN going to make it to my des k or is it going 
to stop at the PBX which would still be one of 1 0 different brands . LUDWIG: It's going to your desk 
. SCHMANDT : It will go to your desk, but not to your home . HOURVITZ : Gee, great . LUDWIG: I don't 
know if I would agree with that one, but I guess I'm . . . HAWLEY: I don't use phones. I use E-Mail 
now . Moderato r Barry Aron s Olivetti Research Cente r We're running out of time. There's another 
session which is coming in here very shortly, so we're not going to have time to answer any personal 
questions here -- if people would go t o the breakout room next door . . . We'd like to thank the Panels 
Committee and SIGGRAP H for allowing us to do this . I'd like to thank the rest of th e panel, particularly 
the co-chairman Chris -- and we'd like t o thank everybody for showing up. We hope that it sparked your 
interest in audio, and perhaps this session will help in integrating audio into the workstation. Maybe 
a few years down the road we'll all see you at the ACM SIGAUDIO conference or something like that . 
SPEECH AND AUDIO IN WINDOW SYSTEMS : WHEN WILL THEY HAPPEN? 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>77286</article_id>
		<sort_key>177</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[HDTV (Hi-Vision) computer graphics]]></title>
		<page_from>177</page_from>
		<page_to>189</page_to>
		<doi_number>10.1145/77276.77286</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=77286</url>
		<abstract>
			<par><![CDATA[Good afternoon, ladies and gentlemen. We'll begin the panel session -- HDTV Computer Graphics. I am Koichi Omura at Osaka Municipal University. I am the chair of this panel. At first I'd like to thank SIGGRAPH, giving us the opportunity speaking today.The first presentation is by Mr. Ryou Mochizuki. He is the controller of NHK Engineering Service Corporation. He will discuss the compact disc application of HDTV, and after that he will present the brief introduction of HDTV.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Digitizing and scanning</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.4.0</cat_node>
				<descriptor>Image displays</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010506</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Document scanning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P154680</person_id>
				<author_profile_id><![CDATA[81332519679]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Omura]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Osaka Municipal University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P234382</person_id>
				<author_profile_id><![CDATA[81100026736]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mochizuki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[New Video Systems Research Association]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P105138</person_id>
				<author_profile_id><![CDATA[81100201550]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[H.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tamegaya]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Japan Broadcasting Corporation (NHK)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P303288</person_id>
				<author_profile_id><![CDATA[81100452554]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Y.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kawajuchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Nippon Electronics Colleg e]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P55170</person_id>
				<author_profile_id><![CDATA[81100589026]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Miskowich]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Symbolics]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
   SIGGRAPH '89, Roston, July 31 -A List 4, 1989 Hideichi Tamegay a Japan Broadcasting Corporatio 
n (NHK) Thank you, Chairman. Thank you, everybody. I will tal k about the program production using the 
high definitio n television system for the television program . So I am used t o work for the creating 
television program, using the compute r graphics image and special effects systems . For making the animations, 
until recently there were only two ways to record computer animations . One way was t o shoot it frame 
by frame by 16 millimeter film or 35 millimete r film . The other way was to record it on the NTSC VTR 
frame b y frame or videodisc . However, both ways are -- not satisfy a s quality for the computer graphics 
images . Recording on NTS C system can degrade picture qualities -- if the resolution of th e original 
system is higher . So most of the computer graphi c systems, it has the high resolution display at the 
present . So I am here today to tell you about our new way to recor d computer animation, using HDTV 
for production -- television production. The new approach combined the high picture quality of film with 
the convenience of video . HDTV is a first complete system available which enables us to produce hig 
h quality computer graphics entirely electronically . So HDTV produces computer graphics animation wit 
h higher resolution and a wider range of color reproductio n capability . HDTV graphics also gives more 
of a feeling o f depth, have better texture and look more transparent than graphics produced in conventional 
television system . There are several things which we need to keep in min d when we produce HDTV computer 
graphics . First, already othe r panelists mentioned before HDTV has a resolution of 1920 b y 1035 pixels. 
So it needs about six times as much memory fo r its frame buffer as an NTSC production does . It also 
requires si x times as much calculation time, if pixel by pixel renderin g techniques, such as ray tracing, 
are used . While these increas e time and memory requirements, presently a drawback . Hardware is continuously 
evolving . So these inconveniences are becoming more and more trivial. So secondary, HDTV has a wide 
aspect ratio of 9 by 16 . This is wider than NTSC and nearly the same as the aspect rati o of movie screen 
-- like Vista Vision . Because of this differenc e conversions between NTSC and High Definition Television 
ar e not just a matter of converting picture resolutions . The framing of the picture or composing of 
the picture must also b e decided on. It's a frame composing technique and it is very artistic work . 
So I'd also like to mention the very good results HDT V gets in making composite pictures . These good 
results ar e possible because HDTV is a component signal system and th e computer can generate a totally 
flat color background with n o reflection of the background onto the foreground wit h chromakey . So 
this is a quite conventional television technique . But high definition television system has goo d advantages 
using this method . These advantages can also b e used for conventional television . We can now shoot 
the background and foreground o n HDTV, composite them, and then down convert it to NTSC . This works 
well in situation where high quality pictures ar e required. So I'd like to mention last a very important 
thing abou t HDTV computer graphics . Since the pictures are generated digitally and with high definition 
digital recording an d processing system, animation of such high quality can b e printed or transferred 
to the other media with their origina l quality . This means that HDTV can be the common visio n medium 
-- not only broadcasting use, but also for variou s applications . So thank you very much . I will show 
you th e sample of the broadcasting production by HDTV images. We used these images for the television, 
high definition television broadcasting in Japan . Thank you . We produced this high definition compute 
r graphics image by an Iris graphic workstation and the 32 bi t minicomputer systems for the rendering 
machines . So we usually use these images for the television programs . As yo u know, the television 
program is very tight time schedules , producing schedules. So we have to create these images in a short 
time. So we need a more high power, more cheaper systems for the HDTV system . Thank you very much. Moderator 
Koichi Omur a Osaka Municipal Universit y Thank you. The final panelist is Mr. Yoichiro Kawaguchi . 
He's famous to all of you very well and know him . He is no w the associate professor of Nippon Electronics 
College and he is also the computer graphics artist in Japan . Yoichiro Kawaguch i Nippon Electronics 
Colleg e Hello, everybody. They are talking very short. So I have so much time . But I guess they are 
all engineers . I am an artist . Today I want to present my art works for HDTV . I guess you saw the 
film and video show presentation, HDTV works fo r SIGGRAPH. Unfortunately they have no HDTV system. So 
I did down conversion from HDTV to normal NTSC . So I guess in the Film and Video Show, my work is very 
low resolution . But anyway, I guess next year at the SIGGRAPH in Dallas , maybe HDTV computer graphics 
works will be more popular --I hope . Anyway, today I want to show my work of Flora with I-IDTV tape. 
But before showing Flora I'm going to sho w normal NTSC works . I want to show printing material . . 
So before showing my works, I want to introduce my art work history . My first showing at SIGGRAPH is 
maybe 8 0 seconds -- in Boston too . Maybe seven years ago . I showed them my work with normal NTSC . 
So I want to show a slide . This picture is a 512 by 512. Maybe you can see jaggie s and the scan line 
for each works . These works are in not so high resolution -- 512 by 512. But when I started compute 
r works research -- 1979 in Japan. No color -- just only lin e drawing. So middle of 70s for artists 
computer works is not s o interesting -- just only looks for painter, looks only just o n sketching . 
This picture for normal TV resolution . But mayb e still not so good -- this lines not good too . HDTV 
(HI-VISION) COMPUTER GRAPHICS   SIGGRAPH '89, Boston, Ju31 -August 4, 1989 Moderato r Koichi Omur 
a Osaka Municipal Universit y Thank you. I think this panel is until 5 :10. So we have over 15 minutes. 
So if you have some question or some point of discussion, well start the 15 minutes discussion about 
HDT V computer graphics . Q . I'm Steve Jepson with Boeing Computer Services . I notice on the 1920 in 
the horizontal direction for the digitized HDT V images that the pixels aren't square . Why was that 
numbe r chosen ? OMURA: Who are you addressing your question to ? Q . Anyone who knows. I guess the gentleman 
fro m Symbolics . A related question is, I notice that he is mentioning that the output is to analogue 
. Is there a digita l output anticipated ? MISKOWICH: Yes, I can answer the latter question first . A 
digital output is anticipated. We had a technology demonstration at the show here where we were showing 
a processor that would be able to frame grab digital high de f images and output digital high def images 
. As to why the 1920 pixels were chosen for the number of pixels on a line, I can' t give you a clear 
answer about that . It has a lot to do with i t being a good - - quote/unquote -- number for translating 
back and forth between various media . I'd like to also comment on the point you brought up abou t non-square 
pixels . Symbolics considers square pixels a non ­issue. We feel that modern technology and even the 
curren t state of the art really allows you to pick whatever aspect rati o you want for your pixels and 
your pictures, and all the processing that we anticipate having to do on images can be handled quite 
easily -- whether it's square or non-square . So really, as far as we at Symbolics are concerned, you 
can tak e your pick -- square pixels or non-pixels or anything you want . MISKOWICH : The gentleman in 
the back on the right, g o ahead. The other right . Q . Do you have any idea how long it will take for 
the cabl e companies to lay in enough fiber optics for a distributio n center or just widespread distribution 
. Does anybody have an y idea how long or whether anybody's got any plans for that ? For general distribution, 
rather than industrial use . MISKOWICH: Repeat the last part -- for commercial use ?  Q . Yes, for distribution 
of commercial television -- HDTV to . .. MISKOWICH : To the homes you mean .  Q. Yes, to homes and things 
like that . MISKOWICH : Well, I really don't have any good idea . I can't really give you a good answer 
. It's moving pretty fast . I would venture to say that for the next four years we'll see thi s kind 
of technology being implemented in industria l applications . I know they're busy laying fiber optic 
cables i n places . But I really don't have - I'm not in a position to reall y definitively comment 
on that. I would look for it in about 1 0 years myself. But it's a very unexpert opinion there . OMURA 
: In the back on the left, go ahead.  Q. There's a follow-up to that question about the non-squar e 
pixels . I'm going to disagree really strongly that there are non-issues. Symbolics may have a lot of 
extra compute powe r lying around to turn simple two dimensional bit problems int o geometry problems, 
but I don't think that's everywhere . If you want to do something as simple as turn the HDTV on its side 
and use a portrait display to typeset a newspaper page, you'r e going to be dealing with a 44% aspect 
ratio problem . It's 130  to 125 I think is the pixel aspect ratio . As far as I can see, there's a 
couple of solutions to that problem, which involv e extra compute power here and there or hardware to 
correct it , and if you're going to do interactive graphics that's going t o cost. What I want to know 
is if there's going to be a standard solution to that problem and what it's going to cost . MISKOWICH 
: Thank you for your opinion . I couldn' t comment further on it. I have stated our position on it . 
Q. I'm Glen Rightmeyer from the David Sarnoff Research Center, and I thought I could answer the question 
of why 192 0 pixels . 1920 was selected to be the wide aspect rati o corresponding number to that of 
CCIR-601 . CCIR-601 was th e first digital video standard that was set in the world and it wa s selected 
to have a common sampling frequency of 13 . 5 megahertz, which yielded a common sampling frequency and 
a common number of active samples per line for both 525 and 625 line systems . I might also add that 
in terms of HDTV standards, both square pixels and progressive scan are clearly issues that wil l have 
to be addressed in future HDTV standards and that these are issues of great concern in the video industry 
which I thin k would benefit from some of your inputs . Thank you . OMURA : In the center in the front, 
please . Q. I think this is a question for the gentleman from NHK . What new types of programs or different 
kinds of programming does HDTV make possible and how much HDTV broadcasting i s going on anywhere in 
the world today ? TAMEGAYA : How do you answer? Practically so in Japan a s NHK already broadcast one 
hour test transmission each day . So in the United States there are some production, high definitio n 
television production, and also in Europe and in Japan . So also NHK produced some high definition television 
programs fo r this experiment in transmissions . So especially in th e computer graphics images for the 
television programs, mostl y used for the title logo you've seen before in the title NHK hig h vision 
as the title. It's mostly used through application of the high definition television . But we are very 
interested in hig h definition visual simulations for the television program, suc h as the Typhoon number 
19. This data derived from the Meteorology Agency of Japan, and then they calculate it b y super computers 
. So then we received from these datas -- imag e data derives from the super computer output, and then 
w e transferred to the HDTV signals . So this reason is easil y understand -- everybody -- to clear pictures 
. It's easily understand for the viewers -- more than NTSC signals . That' s the reason why we are creating 
the simulated images by th e HDTV system . Also this image can be converted to the NTSC or converte d 
to the films -- 35 millimeter films . We can print out and als o we can project it by the 35 millimeter 
film projectors . So thi s media's qualities is useful for the various kind of media -- suc h as films 
and NTSC signals or video discs . Especially digitall y transferred from the computer to digital disc 
or VTR It's so amazing qualities we can see on the displays, no signal degradations . This quality almost 
satisfied so huma n acceptance of the picture qualities I think . This is my persona l opinion. OMURA 
: Thank you. On the left in the back, please go ahead . Q. My question is addressed to the artist, as 
well as th e gentleman from NHK. Has any thought been given to the production of stereoscopic HDTV productions 
? TAMEGAYA: Yes. That's a very interesting question. At the present I am mostly interested in stereoscopic 
images by th e HDTV (HI-VISION) COMPUTER GRAPHICS  SIGGRAPH '89 PANEL PROCEEDING S HDTV systems . As 
you know, as the HDTV system has th e very high resolutions, So it increases the stereo quality fro m 
the high resolution pictures . So high definition system is the most useful or effective to this stereo 
images . So we alread y shoot by the television camera -- a high definition television camera -- we can 
shoot the stereo images . And I am very encouraged . This SIGGRAPH shows many stereo animation -­computer 
graphics animations in this film show . So if we ca n use the computer graphics techniques for this stereo 
visions , its very easy -- I think its very easy to calculate, than shooting by the television cameras 
. So computer can calculate the stereo images in the computer softwares . So I am very, very interested 
in stereoscopic images i n future applications . But I'm not sure -- it's the broadcasting is a different 
way . So mostly used for the production o r presentation purpose of this system -- I think . OMURA : 
Thank you . Next. This is the last question, please . Q. I have a question for Mr. Miskowich . Can you 
first tell me what is the frame rate of high definition television ? OMURA : Frame rate? Q. The number 
of frames per minute or per second that you ge t on HDTV. Is it 50 or 60 or some other figure ? MISKOWICH 
: It's 60 in the version that we're supporting , although I believe there's still some discussion about 
wha t frame rates should be worldwide . So as far as I know, it's stil l an open question and we can 
go at much higher frame rates tha n that with what we're dealing with . Q . That leads me to the second 
question . If you've got a frame rate of 60 frames per second, you will need something like a 6 0 megahertz 
bandwidth to be able to display upwards of 2,00 0 pixels per line . You said before that the standard 
only support s 22 .5 megahertz of analogue bandwidth . How do you explai n that discrepancy ? MISKOWICH 
: Yes, it's a lower bandwidth than what the digital specification would require. It's above what th e 
analogue specification requires . We're sort of right in the middle right now and our newer technology 
takes us up abov e the digital specification . Thank you . OMURA : Thank you very much . This is the 
end of th e session. Thank you very much to all the panelists and to yo u all .  Finally, we will show 
you the rest of the compact disc digital HDTV images on the screen so you can see that it's a very near 
position. Please see that . HDTV (HI-VISION) COMPUTER GRAPHICS 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>77287</article_id>
		<sort_key>191</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Physically-based modeling: past, present, and future]]></title>
		<page_from>191</page_from>
		<page_to>209</page_to>
		<doi_number>10.1145/77276.77287</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=77287</url>
		<abstract>
			<par><![CDATA[<p>My name is Demetri Terzopoulos and my co-chair, John Platt, andI would like to welcome you to the panel on Physically-BasedModeling -- Past, Present and Future. I'll start by introducing thepanelists; the affiliations you see listed on the screen aresomewhat out of date.</p><p>I'm Program Leader of modeling and simulation at theSchlumberger Laboratory for Computer Science in Austin, Texas, andI was formerly at Schlumberger Palo Alto Research. I'll speak onthe subject of deformable models.</p><p>John Platt, formerly of Cal Tech, is now Principal Scientist atSynaptics in San Jose, California. He will be concentrating onconstraints and control.</p><p>Alan Barr is Assistant Professor of computer science at CalTech. Last year he received the computer graphics achievementaward. He'll speak about teleological modeling.</p><p>David Zeltzer is Associate Professor of computer graphics at theMIT Media Laboratory. He will be speaking on interactive microworlds.</p><p>Andrew Witkin, formerly of Schlumberger Palo Alto Research, isnow Associate Professor of computer science at Carnegie MellonUniversity. He will speak about interactive dynamics.</p><p>Last but not least, we have with us James Blinn, who of courseneeds no introduction. Formerly of JPL, he is now AssociateDirector of the Mathematics Project at Cal Tech. He says he'll haveseveral random comments to make against physically-basedmodeling.</p><p>I was also asked by the SIGGRAPH organizers to remind theaudience that audio and video tape recording of this panel is notpermitted.</p><p>Many of you are already familiar with physically-based modeling,so I will attempt only a very simple introduction to this, in myopinion, very exciting paradigm. Physically-based techniquesfacilitate the creation of models capable of automaticallysynthesizing complex shapes and realistic motions that were, untilrecently, attainable only by skilled animators, if at all.Physically-based modeling adds new levels of representation tographics objects. In addition to geometry -- forces, torques,velocities, accelerations, kinetic and potential energies, heat,and other physical quantities are used to control the creation andevolution of models. Simulated physical laws govern model behavior,and animators can guide their models using physically-based controlsystems. Physically-based models are responsive to one another andto the simulated physical worlds that they inhabit.</p><p>We will review some past accomplishments in physically-basedmodeling, look at what we are doing at present, and speculate aboutwhat may happen in the near future. The best way to get a feel forphysically-based modeling is through animation, so we will beshowing you lots of animation as we go along.</p><p>I would like to talk about deformable models, which arephysically-based models of nonrigid objects. I have worked ondeformable models for graphics applications primarily with KurtFleischer and also with John Platt and Andy Witkin. Deformablemodels are based on the continuum mechanics of flexible materials.Using deformable models, we can model the shapes of flexibleobjects like cloth, plasticine, and skin, as well as their motionsthrough space under the action of forces and subject toconstraints.</p><p>Please roll my Betacam tape. Here is an early example ofdeformable surfaces which are being dragged by invisible forcesthrough an invisible viscous fluid. Next we see a carpet falling ingravity. It collides with two impenetrable geometric obstacles, asphere and a cylinder, and must deform around them. The next clipshows another clastic model. It behaves like a cloth curtain thatis suspended at the upper corners, then released.</p><p>Here is a simulated physical world -- a very simple worldconsisting of a room with walls and a floor. A spherical obstaclerests in the middle of the floor. You're seeing the collision of anelastically deformable solid with the sphere. Of course, we're alsosimulating gravity.</p><p>We've developed inelastic models, such as the one you see herewhich behaves like plasticine. When the model collides with thesphere, there's a permanent deformation. By changing a physicalparameter, we obtain a fragile deformable model such as the onehere. This deformable solid breaks into pieces when it hits theobstacle.</p><p>Deformable models can be computed efficiently in parallel. Thismassively parallel simulation of a solid shattering over a spherewas computed on a connection machine at Thinking Machines, with thehelp of Carl Feynman.</p><p>Here is a cloth-like mesh capable of tearing. We're applyingshear forces to tear the mesh. The sound you're hearing has beengenerated by an audio synthesizer which was programmed by TonyCrossley so that it may be driven by the physical simulation of thedeformable model. Whenever a fiber breaks, the synthesizer makes apop. Keep watching the cloth; we get pretty vicious with it.</p><p>Deformable models are obviously useful in computer graphics, butthey are also useful for doing inverse graphics; that is to say,computer vision.</p><p>For example, here we see an image of a garden variety squash.Using a deformable tube model, we can reconstruct a threedimensional model of the squash from its image, as shown. Once wehave reconstructed the model from the image, we can rotate themodel to view it from all sides. You can see, we have captured afully three dimensional model from that single, monocular image.That's a basic goal of computer vision.</p><p>Kurt Fleischer, Andy Witkin, Michael Kass, and I used thisdeformable model based vision technique to create an animationcalled &lt;i&gt;Cooking with Kurt.&lt;/i&gt; We wanted to mix livevideo and physically-based animation in this production. You seeKurt entering a kitchen carrying three vegetables. We captureddeformable squash models from a single video frame of the realsquashes sitting on the table -- this particular scene right here.Now the reconstructed models are being animated usingphysically-based techniques. The models behave like very primitiveactors; they have simple control mechanisms in them that make themhop, maintain their balance, and follow choreographed paths. Thecollisions and other interactions that you see are computedautomatically through the physical laws, and they look quiterealistic. It's difficult to do this sort of thing by hand, even ifyou're a skilled animator.</p><p>This second tape will show you some of the physically-basedmodeling we're up to now at the Schlumberger Laboratory forComputer Science. Keith Waters and I are working on interactivedeformable models. We're now able to compute and render deformablemodels in real time on our Silicon Graphics Iris 240 GTX computer.For example, here is a simulation of a nonlinear membraneconstrained at the four corners and released in a gravitationalfield. Watch it bounce and wiggle around.</p><p>Here you're seeing a physically-based model of flesh. It's athree dimensional lattice of masses and springs with musclesrunning through it. Again, this is computed and displayed in realtime. You can see the muscles underneath displayed as red lines.They're fixed in space at one end and attached to certain nodes ofthe lattice model at the other end. By contracting the muscles wecan produce deformations in this slab of -- whale blubber, if youwill. We did this simulation as an initial step towards animatingfaces using deformable models as models of facial tissue. And ofcourse, the muscle models make good facial muscles.</p><p>The next clip will demonstrate real time, physically-basedfacial animation on our SGI computer. Here we see the latticestructure of the face. Let's not display all of the internal nodesso that we can see the epidermis of the lattice more clearly.There. Now we're contracting the zygomatic muscle attached to oneedge of the mouth -- now both zygomatics are contracting to createa smile. The muscles inside the face model are producing forceswhich deform the flesh to create facial expressions.</p><p>Now the epidermis polygons are displayed with flat shading. Nextwe contract the brow muscles. Here the epidermis is being shadedsmoothly. Finally, we relax the muscles and the face returns tonormal.</p><p>An important reason for applying the physically-based modelingapproach to facial animation is realism. For instance, the facialtissue model automatically produces physically realistic phenomenasuch as the laugh lines around the mouth and the cheek bulges thatyou see here.</p><p>Keith videotaped this animation off of our machine only lastweek. Our next step will be to develop control processes tocoordinate the muscles so that the face model can create a widerange of expressions in response to simple commands. Keith's priorwork on facial animation, published in SIGGRAPH 87, showed how onecan go about doing this using muscle model processes. Beyond musclecontrol processes, we're also interested in incorporating vocodermodels -- that is, physically-based speech coding and generationmodels, so that this face can talk to you.</p><p>The tape will end soon, so I'll release the podium to Dr. JohnPlatt, who will talk about constraint methods and control. Thankyou.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.6.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP40036751</person_id>
				<author_profile_id><![CDATA[81100294834]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Terzopoulos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Schlumberger Laboratory for Computer Science]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P126642</person_id>
				<author_profile_id><![CDATA[81332521527]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pltt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Synaptics]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14034823</person_id>
				<author_profile_id><![CDATA[81100070192]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Barr]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39086111</person_id>
				<author_profile_id><![CDATA[81100216523]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zeltzer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MIT Media Lab]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39081231</person_id>
				<author_profile_id><![CDATA[81100295587]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Witkin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31072761</person_id>
				<author_profile_id><![CDATA[81100294395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Blinn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SIGGRAPH '89 PANEL PROCEEDING S Panel Session Physically-Based Modeling : Past, Present, and Future 
Co-Chairs: Demetri Terzopoulos, Schlumberger Laboratory for Computer Scienc e John Platt, Synaptics Speakers 
: Alan Barr, California Institute of Technology David Zeltzer, MIT Media Lab Andrew Witkin, Carnegie 
Mellon University Jim Blinn, California Institute of Technology My name is Demetri Terzopoulos and my 
co-chair, Joh n Platt, and I would like to welcome you to the panel on Physically -Based Modeling -- 
Past, Present and Future . I'll start b y introducing the panelists ; the affiliations you see listed 
on th e screen are somewhat out of date. I'm Program Leader of modeling and simulation at th e Schlumberger 
Laboratory for Computer Science in Austin, Texas , and I was formerly at Schlumberger Palo Alto Research 
. I'll speak on the subject of deformable models . John Platt, formerly of Cal Tech, is now Principal 
Scientist a t Synaptics in San Jose, California . He will be concentrating o n constraints and control 
. Alan Barr is Assistant Professor of computer science at Ca l Tech . Last year he received the computer 
graphics achievemen t award. He'll speak about teleological modeling . David Zeltzer is Associate Professor 
of computer graphics a t the MIT Media Laboratory . He will be speaking on interactiv e micro worlds 
. Andrew Witkin, formerly of Schlumberger Palo Alt o Research, is now Associate Professor of computer 
science at Carnegie Mellon University . He will speak about interactive dynamics . Last but not least, 
we have with us James Blinn, who of course needs no introduction. Formerly of JPL, he is no w Associate 
Director of the Mathematics Project at Cal Tech . He says he'll have several random comments to make 
agains t physically-based modeling . I was also asked by the SIGGRAPH organizers to remind th e audience 
that audio and video tape recording of this panel is no t permitted . Many of you are already familiar 
with physically-base d modeling, so I will attempt only a very simple introduction to this , in my opinion, 
very exciting paradigm . Physically-base d techniques facilitate the creation of models capable of automatically 
synthesizing complex shapes and realistic motion s that were, until recently, attainable only by skilled 
animators, if a t all. Physically-based modeling adds new levels of representatio n to graphics objects 
. In addition to geometry -- forces, torques , velocities, accelerations, kinetic and potential energies, 
heat, an d other physical quantities are used to control the creation an d evolution of models . Simulated 
physical laws govern mode l behavior, and animators can guide their models using physically ­based control 
systems . Physically-based models are responsive to one another and to the simulated physical worlds 
that they inhabit . We will review some past accomplishments in physically ­based modeling, look at what 
we are doing at present, an d speculate about what may happen in the near future . The best way to get 
a feel for physically-based modeling is through animation , so we will be showing you lots of animation 
as we go along . I would like to talk about defonnable models, which ar e physically-based models of 
nonrigid objects. I have worked on deformable models for graphics applications primarily with Kur t Fleischer 
and also with John Platt and Andy Witkin . Deformable models are basecl on the continuum mechanics of 
flexibl e materials . Using deformable models, we can model the shapes o f flexible objects like cloth, 
plasticine, and skin, as well as thei r motions through space under the action of forces and subject 
to constraints . Please roll my Betacam tape . Here is an early example o f deformable surfaces which 
are being dragged by invisible force s through an invisible viscous fluid . Next we see a carpet falling 
i n gravity . It collides with two impenetrable geometric obstacles, a sphere and a cylinder, and must 
deform around them . The next clip shows another clastic model . It behaves like a cloth curtai n that 
is suspended at the upper corners, then released . Here is a simulated physical world -- a very simple 
worl d consisting of a room with walls and a floor . A spherical obstacl e rests in the middle of the 
floor . You're seeing the collision of a n elastically deformable solid with the sphere . Of course, 
we're als o simulating gravity . We've developed inelastic models, such as the one you se e here which 
behaves like plasticine . When the model collides with the sphere, there's a permanent deformation . 
By changing a physical parameter, we obtain a fragile deformable model such a s the one here. This deformable 
solid breaks into pieces when i t hits the obstacle . Deformable models can be computed efficiently in 
parallel . This massively parallel simulation of a solid shattering over a sphere was computed on a connection 
machine at Thinkin g Machines, with the help of Carl Feynman . Here is a cloth-like mesh capable of tearing 
. We're applying shear forces to tear the mesh . The sound you're hearing has bee n generated by an audio 
synthesizer which was programmed b y Tony Crossley so that it may be driven by the physical simulatio 
n of the defomlable model . Whenever a fiber breaks, the synthesizer makes a pop . Keep watching the 
cloth ; we get pretty vicious with it . Deformable models are obviously useful in computer graphics, 
but they are also useful for doing inverse graphics ; tha t is to say, computer vision . For example, 
here we see an image of a garden variety squash . Using a defonnable tube model, we can reconst ruct 
a three dimensional model of the squash from its image, as shown . Once we have reconstructed the model 
from the image, we ca n PHYSICALLY-BASEDMODELING : PAST, PRESENT, AND FUTURE SIGGRAPH '89, Boston, July 
31 -August 4, 198 9 rotate the model to view it from all sides . You can see, we hav e captured a fully 
three dimensional model from that single , monocular image . That's a basic goal of computer vision . 
Kurt Fleischer, Andy Witkin, Michael Kass, and I used thi s deformable model based vision technique to 
create an animatio n called Cooking with Kurt . We wanted to mix live video an d physically-based animation 
in this production . You see Kur t entering a kitchen carrying three vegetables . We capture d defonmable 
squash models from a single video frame of the rea l squashes sitting on the table -- this particular 
scene right here . Now the reconstructed models are being animated usin g physically-based techniques 
. The models behave like very primitive actors ; they have simple control mechanisms in the m that make 
them hop, maintain their balance, and follo w choreographed paths . The collisions and other interactions 
tha t you see are computed automatically through the physical laws , and they look quite realistic . 
It's difficult to do this sort of thin g by hand, even if you're a skilled animator . This second tape 
will show you some of the physically-base d modeling we're up to now at the Schlumberger Laboratory fo 
r Computer Science. Keith Waters and I are working on interactive deformable models. We're now able to 
compute and render deformable models in real time on our Silicon Graphics Iris 24 0 GTX computer . For 
example, here is a simulation of a nonlinea r membrane constrained at the four corners and released in 
a gravitational field . Watch it bounce and wiggle around . Here you're seeing a physically-based model 
of flesh . It's a three dimensional lattice of masses and springs with muscle s running through it . 
Again, this is computed and displayed in rea l time. You can see the muscles underneath displayed as 
red lines . They're fixed in space at one end and attached to certain nodes o f the lattice model at 
the other end . By contracting the muscles w e can produce deformations in this slab of -- whale blubber, 
if yo u will . We did this simulation as an initial step towards animatin g faces using deformable models 
as models of facial tissue . And o f course, the muscle models make good facial muscles . The next clip 
will demonstrate real time, physically-base d facial animation on our SGI computer. Here we see the lattice 
structure of the face. Let's not display all of the internal nodes so that we can see the epidermis of 
the lattice more clearly . There . Now we're contracting the zygomatic muscle attached to one edg e of 
the mouth -- now both zygomatics are contracting to create a smile . The muscles inside the face model 
are producing force s which deform the flesh to create facial expressions . Now the epidermis polygons 
are displayed with flat shading . Next we contract the brow muscles . Here the epidermis is bein g shaded 
smoothly. Finally, we relax the muscles and the face returns to normal . An important reason for applying 
the physically-base d modeling approach to facial animation is realism . For instance , the facial tissue 
model automatically produces physically realisti c phenomena such as the laugh lines around the mouth 
and th e cheek bulges that you see here . Keith videotaped this animation off of our machine only las 
t week. Our next step will be to develop control processes t o coordinate the muscles so that the face 
model can create a wid e range of expressions in response to simple commands . Keith' s prior work on 
facial animation, published in SIGGRAPH 87 , showed how one can go about doing this using muscle model 
processes . Beyond muscle control processes, we're also intereste d in incorporating vocoder models -- 
that is, physically-base d speech coding and generation models, so that this face can talk to you . The 
tape will end soon, so I'll release the podium to Dr . Joh n Platt, who will talk about constraint methods 
and control . Than k you . John Platt Synaptics Hello . I'm John Plan and I'm going to tell you one 
majo r idea that I have found to be very useful in working with physically-based models . Animation is 
simulation plus control . worked on this idea with Al Barr while I was a graduate student a t Cal Tech. 
I claim there are two necessary ingredients to mak e interesting animation . One of them is the physical 
simulation o f elasticity . Demetri talked about this a little bit . You need to have models that obey 
the theory of elasticity . In other words, you us e Newton's laws to make the models act naturally . 
The animatio n looks natural, because the theory of elasticity describes the wa y flexible models actually 
behave . Physical simulation is also nice because it's automatic. If you have a simulator that simulates 
an elastic object, it can hav e hundreds of variables . Trying to do key framing would be ver y difficult: 
you would have to specify hundreds of splines in orde r to make the animation . In addition to the physical 
simulation, elastic models need to be controlled . Models should follow basic rules which creat e good 
animation . For example, you usually don't want models t o fly through each other -- unless you want 
that particular effect i n your animation . Objects should bounce off each other . The y should be able 
to be incompressible or moldable . More generally, you want to guide models. You don't want just a pure 
simulation. You want to be able to specify some amount of control and then let the rest be automated 
. So you ca n specify a few degrees of freedom and leave the other few hundre d to the computer . So 
I claim this means you want to have bot h simulation plus control to make animation . Let me show you 
some examples of animation made usin g constrained flexible models that will illustrate this principle 
. What you're first going to see is an elastic trampoline with a sphere above it . With constraints, 
I specify that this sphere shoul d not penetrate the trampoline . And you see, it doesn't . It bounces 
; it stays above the trampoline . In the next example, I use constraints to try to assembl e complex 
objects out of simple objects, and I also use constraints t o position the objects where I wanted . Here, 
I specify a fe w constraints and the system automatically positions the models t o create a double trampoline 
. You don't have to confine yourself to surfaces . Very interesting animations result when you simulate 
elastic solids . S o here I'm going to make a jello cube . Now, I pick up the jello cube with constraints 
. Gravity is applied to the jello cube so that i t falls. The grey table is made by constraints: I'm 
constraining the jello cube to stay above the table. Finally, you can make reasonably complex animation 
s involving hundreds of variables. This is an example of such an animation using both flexible models 
and constraints . This animation was made with the help of a lot of my friends from Cal Tech while I 
was there, and in fact, we did it up at Appl e on their Cray . So I'd like to thank all those people 
. In conclusion, I want to reiterate : if you want to make very complex and interesting animation, then 
I think you need both simulation and control . The simulation can be any sort of physics . It doesn't 
have to be elasticity ; it could be fluid mechanics or neutrino physics or whatever. But you need both 
simulation an d control to create animation that does what you want .      SIGGRAPH '89 PANEL PROCEEDINGS 
It took us a little while to realize how to really use th e physics layer. I remember talking to Lance 
Williams a few years ago. We were making an Omnimax film and I told Lance that th e right way to do everything 
in animation is to use physics . An d Lance said, "I don't know, Al . I don't think so ." I certainly 
wa s convinced that there was no other way . That Omnimax movie is being presented tonight at the Science 
Museum, and the interesting thing about it is that I wa s simulating the swimming motions of creatures 
and I thought that I had done my job by doing the physics of the swimming. I did i t correctly. I had 
the camera swooping through this flock o f swimming things and by the time the camera got to where it 
wa s going to be, they had all swam away . Well, that doesn't seem right. So, I aimed them at the trajectory 
of the camera . The camera swooped through them and they swam behind the camera . So after fiddling with 
this for a while, I realized yes, Lance i s right. There's something more than physics. There is the 
specification of what you want . That's what teleological modeling is . It lets you control th e physics 
and get what you want in a mathematically guarantee d way . Whatever you don't say that you want, you're 
not guarantee d to get. There might be a happy accident in which the physics might accidentally give 
you what you want, but it won't b e guaranteed, unless you use a mathematically guaranteed method . We're 
going to show a little bit of animation here . Wha t we're first going to see is an attempt at connecting 
objects togethe r using rubber band forces . The yellow arrow is a force and it drag s the rod over to 
the nail, but the rod doesn't really get there . No w we're going to acid a second rod and connect it 
to the first rod . Whoops, the first rod pulled off the nail! So you can see tha t making something out 
of rubber band forces looks like it's mad e out of real rubber bands when you turn on gravity . If you 
want to guarantee that the objects will be held together, you need a smarter force than this sort of 
rubber band force that is small whe n you're close to fulfilling a constraint and large when you're fa 
r from fulfilling the constraint . So here's basically the inverse dynamics approach : th e teleological 
approach . We say : Hook this point on the rod to tha t point in the middle . Tile green lines displayed 
are the velocities o f the points. Notice that a radial force connects the rod to the nail . Of course, 
when you remove the constraint force the rod wil l fly off into space. When you add a second rod and 
ask it to hook to the first, they now stay hooked together, unlike the previou s case. There's no friction 
unless you ask for friction. When yo u suddenly ask for gravity then the object will fall and stay hooke 
d together . The forces adapt to whatever they need to be in order t o hold the objects together . You 
can assemble objects . Here's a tower that's putting itsel f together . We're just saying hook this object 
to that object . Hoo k this strut to that strut, hook that strut to that rod . In this next example we're 
going to see two towers, and we'r e going to connect the set of chain links between them . We ask the 
constraints to hook up the chain links, nose to tail . So the physic s and the shape and the pixels on 
the screen are all byproducts . W e didn't calculate those by hand. They're all byproducts of the teleological 
commands, which is just hook the links together, nos e to tail, and hook the end points to the tips of 
the towers . Here you see a more lively, more snakey chain . Althoug h the commands to create these animations 
are easy to use, it took a great deal of work for our group to create the substrate . Ronen Barzel of 
our group and John Platt and many other people in ou r group worked very hard to make the underlying 
substrate . S o even though it took three lines of code to specify this whol e movie, there are thousands 
of lines of code at the substrate level . In principle you can use these methods to control rea l physical 
objects . You can have spacecraft that can cloc k automatically, as is illustrated here . But this is 
just the beginning . I think that we're seeing the very beginning of making complex systems of objects 
that do what we want . We've just scratched the surface . When we have hardware that can do this in real 
time and when we call render i t and see it in real time, we will take all of these capabilities fo r 
granted and wonder how could anyone every have lived back i n the old primitive clays when you couldn't 
even have an object bounce on the screen right in front or you or drop a piece of jell o on the table. 
So I'm going to end my talk here with the wiggling jello . Thanks very much. Our next speaker is Professor 
David Zeltzer of the MIT Media Lab .  David Zeltze r MIT Media Laborator y Good morning . I think physically-based 
modeling is a crucial element of putting together convincing micro worlds . Ca n I have the first slide, 
please ? What I'm going to talk about is in some sense a continuatio n of the notion of abstractions 
for physically-based modeling an d micro worlds that Al Barr was just talking about . We're working on 
something we're calling an integrate d graphical simulation platform . That is to say, a workstation 
tha t knows a lot about the physical world, that provides a medium fo r users in a variety of applications 
to experiment and explore a variety of computational models . We're interested more i n allowing people 
to observe the behaviors of autonomous agent s and objects rather than convincing them in some sort of 
syntheti c reality . Here are a couple of applications . Fred Brooks has bee n doing some wonderful work 
in his lab at UNC involving virtual experiments in molecular docking . Were also interested in providing 
people with a medium for learning and exploring -- fo r looking at computational models and peeling back 
the levels o f detail as they gain confidence in their understanding at each leve l of representation 
. It's important to its to allow people the means not only t o control computational models, but also 
to define them an d represent them and modify them . If a scientist is studying a computational model 
of some process -- motor control, fo r example -- we'd like to allow him to program that model an d insert 
it into the micro world to control some agent and observe it s effect . So, we're interested in exploring 
the kinds of window s people can have on these computational models . PHYSICALLY-BASED MODELING : PAST, 
PRESENT, AND FUTURE  SIGGRAPH '89, Boston, July 31 ° August41989 The basic idea is to be able to start 
with a purely geometri c object -- we'll start with curves in the plane which have n o physical properties. 
There's no sense in which a circle has physical behavior -- it's undefined . However, we want to give 
i t physical behavior in an automatic, consistent way which we ca n derive just from the geometric equation 
that you need to draw th e thing. What that lets us do is turn a purely geometric object int o something 
we can manipulate in a direct physical way . So thi s circle has degrees of freedom for position and 
radius and we ca n pull on it and get any size circle we want and place it wherever w e wish. Here, we 
get any ellipse we want. Rather than worrying about the parameters, we can just frob the thing directly 
. This i s my personal favorite -- a spiral . So we are able to obtain this physical behavior automaticall 
y from the geometric equation that defines the curve . A basic wa y we do that is by giving it a physical 
interpretation that says there' s uniform damping and negligible mass along the length of th e curve 
. Now there's a kind of constraint that you can put on thes e objects that's trivial . It involves freezing 
one or more of th e parameters. So here we freeze the radius of this circle. Now it's a rigid circle. 
And we can make a sort of inverse punching bag by attaching a spring. Now when we unfreeze the radius, 
we get very different behavior . These are all real time things, by the way . To impose constraints on 
objects, we use a classical metho d of Lagrange multipliers . Here, we're illustrating that for a particl 
e constrained to travel on a circle . The yellow an ow is the force w e apply and the green arrow is 
a constraint force . You can see ho w the net force vanishes when we're trying to pull the circle directl 
y off the circle. The resultant force -- the blue one -- is simply being projected on to the tangent 
to the circle . So what we're doing is calculating the force we need to add in to counterbalanc e the 
component that's trying to pull us off the circle . It's tha t simple. That extends to much more complicated 
systems and it involves solving a system of linear equations to do that projection . Now, there's a little 
bit more to it, because if that's all you di d you would drift off because of accumulating numerical 
error . So , we add feedback. Here the particle has drifted off the circle and the feedback pulls it 
back . So feedback gives you something that's very stable and robust and fast . Using that constraint 
method coupled with the dynamics o f the object, you can start to build little things . Here is the same 
old circle we saw before . Now, rather than attaching it by a string, we nail it in place . So there 
is an ether nail there, and you see th e circle can go anywhere you want it to as long as that particula 
r point stays exactly where it is . Now we can attach things togethe r to obtain something that has some 
constrained degrees of freedom . You don't have to worry explicitly about what those degrees o f freedom 
are . You just pull on it and it goes to where you want it to go. This is a nice way to build and manipulate 
things . You can start to do more complicated things using the sam e mathematical machinery and make 
contraptions . Here is a circl e again. We're doing the same things we did before, but we ar e doing 
it from scratch. So now we have attached things together . Now we can start to reshape things and acid 
some more object s and make linkages and watch them go. This all running in real time on a Silicon Graphics 
Personal Iris, by the way . So you can draw things with this, design things with it, d o constructive 
geometric proofs and such. So there it goes. It behaves the way it is supposed to . As you can see, it 
is al l damped behavior because we have assumed that these object s don't weigh much and that the drag 
forces dominate . So you can add more and more stuff. Here we get to use one of the spirals . It has 
all sorts of nasty parameters that you don't even want to think about . It would be very unpleasant to 
try to control an object lik e that directly by turning the control knobs . These methods are a way of 
just worrying about how th e object looks and where you want things to be, rather than trying t o figure 
out what you have to do to the random scaling parameter s to join angles and things like that to make 
things go where yo u want them to. So now we have built this thing and it move s around . It does whatever 
you tell it to, subject to the constraints . One of the things you can do with this method is control 
fo r key frame animation . It is a very different thing than doin g animation using physics to determine 
the motion . This is usin g physics to determine where things are going to by pulling the m there and 
hooking them there . You can do some more abstract things with interactiv e dynamics . One of those is 
to do optimization . If you have some function you want to minimize, then you can turn that into a forc 
e that is minus the gradient of the function you want to minimize . That gives you something that always 
pulls towards the nearest local minimum. Here we have made a little scattergram and we are minimizing 
a locally weighted distance from the model to eac h dot. So each dot is exerting an attractive force 
. You can pull the model off and then when you let go, it gets sucked in . Here you can see that. It 
is a strictly interactive thing because what the use r is doing is picking the model up and putting it 
near the desired solution and then you let go and it rolls into the energy wells . Here is the same thing 
with an ellipse that is going to automatically fit itself to that sort of "0" there when you turn o n 
the force . So this is the optimal ellipse fit . Since it is hard to optimize non-linear functions globally, 
if things fall into the wrong local minimum, you just pick up the model and help it ou t by putting it 
near the minimum you are looking for . You see, these things are stable attractors, if you let go, th 
e model snaps back as long as it is not to far away . One of th e applications of that idea is to interactively 
fit models accurately t o the shape and motion of things in real live images . Here is a nic e image 
. We have a little line that is being attracted to edges . It i s the same idea except that it is attracted 
to points of high contras t in the image . You can see that if you let go of the line and if it i s reasonably 
close to start with, the line will get sucked into the edge and stay there . If you perturb it a little 
bit, it will come back . You can track motion that way . This illustrates snakes, an earlier work that 
Michael Kass , Demetri Terzopoulos, and I did at Schlumberger Palo Alt o Research. Snakes are springy 
pieces of wire . They are a type o f defonnable model . Here, we are attracting them to edges, an d since 
they have lots of degrees of freedom they can conform pretty much to any shape . Here you see snakes 
conforming to th e shape of an edge . So you can blast the snake off the edge, and i t will come back 
. It is basically the same behavior that you sa w before . Next we will see motion tracking . If you 
have some video , you can fit snake models interactively on the first frame, and the n as you advance 
from frame to frame, all the energy well attractor s move around and drag the snakes with them. Here 
is a movie of a person speaking, then we will see two snakes superimposed on the moving lips and tracking 
them . So you see that the snakes reall y lock onto the lips and follow them very well. This was the 
only thing that is not real time on this tape . We did this on a Symbolic s lisp machine and, though 
it didn't take too long, it couldn't quit e keep up. So there are all sorts of interesting things you 
can do with snake models . Now all of this extends to 3-D and we have an initial syste m that Michael 
Gleischer, my student at CMU, has implemented .  SIGGRAPH '89 PANEL PROCEEDING S My 3-D input device, 
by the way, is a mouse, which works very well. Here we have particles and we can connect them by distance 
constraints . These constraints aren't springs ; they are hard constraints that are being enforced by 
solving a linea r system. So here is a little jointed thing, that is now rigid. It is a little triangle 
and you can pull on it . This is again real time . S o here we have made a tetrahedron and again it is 
rigid . Next, here is a little contraption. Those blue things are 3-D ether nails, o r anchors in space 
. So we have attached things to them and now w e have this odd little linkage that has it's degrees of 
freedom and w e can pull it around . Various people participated in this work, and here are thei r names. 
Now a word from our sponsor . Thank you . Our final speaker will be Dr. Jim Blinn . James Blin n California 
Institute of Technolog y Well I think physically-based modeling is a terrible idea . Is that ok? They 
put me on this panel to cause trouble, I guess . I am not sure why they picked me to do that, but the 
idea is that we ar e supposed to have some lively discussion and dissention here . So , I am going to 
tell you the bad parts of physically-based modeling . Before we do that, let me show my gratuitous video 
tape . Before I saw the light and realized how evil physically-base d modeling is, I used to do it myself 
. These are some rando m scenes out of the Mechanical Universe . Modeling physica l phenomena, especially 
simple ones, is fairly straightforward wit h the computer. A lot of the things you have seen today have 
bee n physically-based modeling of more complex phenomena . One of the objections I have to the printed 
description of thi s panel is with the statement that physically-based modeling ha s been done only in 
the last five years . Well no, actually physically ­based modeling has been done from the beginning of 
computer graphics. One of the first computer animations I saw was calle d The Tumbling Box Movie . It 
was a simulation of a box tumbling while it is in orbit around the earth . So physically-based modelin 
g has been done more often than non-physically-based modeling , even in the early 60s . Many things can 
create problems, as you can see in thi s simulation of an ideal gas exerting pressure on a piston . If 
yo u simulate some phenomena exactly, they just don't do what yo u expect. For example, we had problems 
with this piston in that it started oscillating up and clown; because, if you only use a few atoms, you 
wind up with statistical irregularities interacting wit h the natural mode of vibration of the piston, 
given the sprin g constant of the air and the mass of the piston . And so, we jus t prevented the animation 
from going on long enough for that kin d of oscillation to start building up and being obvious . A better 
simulation of how atoms work is this somewha t different force field between individual atoms . Once 
you sort o f see how that works with any two atoms, you can do it with a larger number. Here is our version 
of atomic jello . A singl e frame of this animation looks really boring, so it is kind o f pointless 
to publish an article in a magazine about it . Basically, with physically-based modeling, for the most 
part , you give the simulation some initial conditions and stand back an d let it fly and see what happens 
. The big trick is controlling it to d o what you want . There are a lot of demonstrations in the mechanical 
universe project of this sort of thing, for example , where we wanted to show the effect of 10 to the 
23rd atoms usin g only 100 . We had to be very careful about setting up the initia l conditions so that 
the atoms evolved in the way that we wante d them to . Well anyway, what sort of business does this lead 
to? It sor t of turns animators into video game pilots . Generally, animators are used to dealing with 
the positions of objects. They specify the position of various key frames either by drawing explicitly 
or something . Physically-based modeling means that they are goin g to be specifying the accelerations 
of objects . And they hav e somehow to figure out what accelerations to use in order to get th e position 
they want after the acceleration has been integrated twice . An analogy may be made between painting 
and photography . Painting is the old technology of doing things manually . Yo u have to have a lot of 
skill to be an artist and represent somethin g realistically. With photography, you just aim this little 
box at the thing and click and a realistic picture cones out right away . Yo u can make a similar analogy 
between what you call animation, o r key frame animation, and simulation. Key frame animation i s how 
it used to be done . It took a lot of skill and the animators ha d to know physics as well as painters 
had to know light an d reflection and so forth, and the animators had to know physics i n order to simulate 
it manually . Once you use computer simulation , all that is taken care of automatically for you . You 
no longer have to have experts to do this ; now amateurs can do it too . Physically ­based modeling means 
that now everybody can get into the act . So there is a progression of what goes on in modeling . We've 
seen the progression from key frame animation, specifyin g positions, to physically-based modeling, which 
is specifyin g accelerations and forces and what not . The next level beyond that , as we are getting 
into the future, is what you would basically cal l psychology. You kind of give your characters motivation 
and tell them that they like this thing and they don't like that thing . A common phrase is "Gee we can 
land men on the moon but w e can't learn to live together in peace and harmony ." Well there is a reason 
for this . Landing men on the moon is really easy . That i s just physics, we know how the moon operates 
and it is just a matter of some acceleration vectors and so forth . Living together in peace and harmony 
is not easy at all . We don't understand psychology well enough to be able to predict how people ar e 
going to act, and even if it is desirable, to control how they act . So as a next stage after physically-based 
modeling, you migh t consider what could be called emotionally based modeling . Thi s is something that, 
for example, classical animators, like those at the Disney Studio, were real good at . They were able 
to pu t emotions into their characters . But, if you have a computer doing this in some automati c way, 
it removes the animator one step further from exerting tota l control over the environment ; animators 
now become like movi e directors . They are dealing with something that has personality . You have to 
exhort your character and get your character excite d about the part. You have to convince your characters 
to do it you r way instead their own way. The characters might have temper tantrums and go off into their 
dressing rooms and blow lines an d make mistakes and so forth . So where do we go beyond that? Beyond 
that we get into meta physically-based modeling . You put your hands on th e television screen and you 
channel the spirits of all of the past grea t animators and rub your crystals over the screen . When 
that sort o f thing happens, then maybe we will all be out of business . I don' t know . . . Thank you 
. Moderato r Demetri Terzopoulo s Schlurnberger Laboratory for Computer Scienc e I'll take this opportunity 
to point out that we could not possibly show all of the exciting work that's going on i n physically-based 
modeling at this panel . I regret that the pane l  PHYSICALLY-BASED MODELING : PAST, PRESENT, AND FUTURE 
 SIGGRAPH '89, Boston, Jul 31 uUust 4, 1989 could not have included several other talented researchers 
wh o have made important contributions to physically-based modeling . Having said that, I would like 
to open the floor microphones fo r audience participation . We welcome your questions, comments , flames, 
whatever you like . Please state your names an d affiliations before asking your questions . Q. My name 
is Arthur Who and I am with Mosaic Software . We make lotus compatible spreadsheets. On the metaphysical 
thing, there is a medium called Radio which I imagine uses th e metaphysical type metaphor . TERZOPOULOS 
: Is your comment directed to anyone i n particular? WHO : Well, I guess Jim Blinn talked about just 
imagining thing s and that is sort of what Raclio uses . TERZOPOULOS : Do you care to respond to that 
Jim ? BLINN: Sounds good to me ! TERZOPOULOS : Is there another question out there? I' m having difficulty 
seeing . Q. My name is John Dunic . I am with IBM . I am directing thi s to either Alan Barr or Andrew 
Witkin . Most of the things yo u were showing looked like they are real time . In fact, And y indicated 
that they were. But, there were small numbers of elements in your system . How many elements can you 
simulate before performance degrades such that you can't have real time ? BARR: In my case, it was already 
degraded so that it was not real time. It took about fifteen seconds a frame on a Symbolics machine, 
sent over the net to a Hewlett-Packard workstation an d rendered frame by frame . What is interesting 
though is that par t of the research that we have been doing over the past year or so i s on this scaling 
problem . How do you simulate the universe i n such a way that you get reasonable accuracy, yet you are 
no t simulating the behavior of every molecule . Let's say that you want to simulate a field of grass 
for instance . Would you want t o do elastic bodies on each blade of grass? No, you need a differen 
t abstraction to do that . My expectation is that we are going to need different kinds of physics that 
are just as accurate as curren t physics but can automatically go between the different kinds o f representations 
. WITKIN : For my stuff there is a more concrete answer : the things that I was doing were dominated 
by solving the linea r system for constraints . I was using an iterative method which i s essentially 
n-squared complexity in practice, where n is th e number of elements . However, if every element in the 
world i s connected to every other other element in the world the metho d turns into n-cubed . For ordinary 
things it is more like n-squared . But you'd like to continue adding new objects and connectin g them 
to a few existing things . How fast is your computer ? Eventually, even n-squared will be too slow, but 
N-squared is no t really very scary. It is something you can fix by having faster computers and also 
with some linear systems you can probabl y use LU decomposition methods that are order-n, so that it 
woul d all be linear time . DUNIC : Could you imagine connecting this up to a CAD system , for instance, 
and expect it to work ? WITKIN : Sure, absolutely! To do large scale things, we'll nee d to wait a little 
while . At least, I will need to wait a little while for faster machines than I currently have . The 
things that I am no w doing in real time took a few seconds a frame for me a coupl e years ago with the 
machines I had then . So you know, thing s improve . It is real time technology . TERZOPOULOS: Perhaps 
I can add something: With regard s to CAD/CAM, deformable models appear promising as a type o f computational 
modeling clay . We will soon be able to simulate 3 -D modeling clay in real time on our graphics supercomputer 
clas s o~®®moo.. ~~~~® machines. In the past, the speed limitations of our machine s restricted our 
interactive simulation to 2-D where it was onl y mildly interesting . Who's next ? Q. I am Dave Breem 
from RPI. I was wondering how physically-based modeling, as you describe it, is different fro m what 
the physicist and mathematicians and the mechanica l engineers have been doing for the past 100 years, 
besides the fac t that you are just making pictures from your models ? BLINN: The difference is that 
we are doing it now instead of them . BARR : That's actually not completely correct, they are still doin 
g it. In addition, it turns out, let us consider the physics of a particular body . How should we represent 
the body? Fo r physicists it would be quite satisfactory to say, in principle, tha t we have elastic 
van der Waals forces between the differen t molecules . We have the covalent bonds between the molecules 
. You can do it all at the molecular level . Or, you can be a mechanical engineer and you could talk 
about the fluctuation an d bending strengths and what not . See, a scientist typically care s about their 
discipline only and not the modeling techniques tha t another discipline might use . And so there is 
in the future something that I will call generi c scientific modeling in which you are quite happy to 
model th e molecular behavior . Or if you need to you will model this othe r behavior. The difference 
is that were interested in the generic modeling . In tenns of all of these constraints, the physicist 
s typically are happy with the description --- let us call it the U=0 equation -- the unworldliness = 
zero equation . It is not necessaril y a description that can be easily implemented . This example that 
I gave requesting a sort of flexible bod y with non- interpenetration constraints, it takes the physicist 
a good long time to write down the equations of motion of that . If I wer e to change the abstraction 
it would take them a long time to react to that . I have been talking with Ronen Barzel -- we have been 
thinking about this . How come it is so easy to state a little piec e of the model, yet it is so hard 
to do the actual simulations, t o actually write the code . When you think about it, as Ronen and I decided, 
two hundred years ago, three hundred years ago, even taking a square root was difficult . So that the 
physics that ha s been done over the past three hundred years is physics as designed for use without 
computers . So the physics that we are designing i s one that is good to use with computers . I would 
say that that is th e difference in the physics . There is actually a different physics behind it -- 
a different collection of equations . So although, the actual Newtonian appearance of it is of course 
the same because i t has to be if you are going to be presenting the real thing, th e underlying equations 
are completely different, at least some o f them . WITKIN: There are important differences in what we 
are usin g this stuff for. I agree with Al that to be able to add in some new kind of object into your 
simulation and connect it to other object s without having to go back and rewrite all your code is, maybe 
, good system design, but it is a comparatively new development . Also, there are things we want to do. 
Making movies for movie s sake, for example, is not something that a physicist or mechanical engineer 
is going to do. The stuff I was talking about using physical methods to develop modeling media or, as 
Dave Zeltze r was talking about, to develop interactive micro worlds where yo u can play ping-pong or 
something . These are just different thing s and very often it is the same physics underneath and ultimately 
at least similar in the numerical methods. But what you use it for colors a lot of what you do and a 
lot of the technical problems that you have to solve to make things really work. ZELTZER: I think another 
important difference is our emphasi s on interaction in real time . As our computing tools are gettin 
g powerful enough to let physicists and mathematicians deal wit h the formerly intractable models, its 
turning out that the ability of a scientist to apply his specialized knowledge about where th e solution 
might lie is critical in finding solutions . Fred Brooks ha s a wonderful example in which he shows that 
using an interactiv e force display as well as visual cues allows scientists to fin d solutions in molecular 
clocking problems interactively, while a SUN-4 for example cranked overnight was not even close to the 
solution. So, interaction is something that we are bringing into th e problem as well . BARR: My prediction 
is that there is going to be a great body o f knowledge that is going to go from people on this panel 
and othe r researchers in graphics back into the physics community . I thin k there is a lot of good 
information that we will be giving them . That is my predication . PLATT: Also, just in terms of the 
math, it hasn't actually bee n hundreds of years . Again, because of the emphasis on th e computer, some 
of the constraint math has been around i n mechanical engineering only from 1972 or so, and we have been 
developing it further . BARR: Let us just consider something called solvin g simultaneous equations . 
You would think solving simultaneou s equations is easy . But, when you actually try to do it on a computer 
it turns out that your systems become unstable . You r solutions get sent out to infinity . So, you need 
to use a completel y different kind of solver that was only invented a few years ago , called singular 
value decomposition. When you don't use it, what happens is that all of your answers get turned into 
mush. There is a great deal of difference . You learn a lot more when you "reall y do it," rather just 
saying "U=0 "-- I wrote the equation ­ something like that ought to work . TERZOPOULOS: Go ahead, Sir 
. Q . I am Salim Abi-Ezzi from RPI . I direct my question to the whole panel ; who ever cares can answer 
me . In the past we wer e successful in expressing the problem of displaying shape very concisely, and 
we came up with what we call the graphics pipelin e -- Transformation, clipping, rendering. Having worked 
on these problems in physically-based modeling, do you think that we wil l be able to express the physics 
and constraints that are needed in a concise and generic fashion, so as be able to have hardwar e accelerators, 
for example ? BARR: You should read the PhD thesis of Devenclra Kalra , hopefully coming out in the next 
year . Our expectation is tha t there will be a significant amount of progress on the problem yo u 
are addressing . ABI-EZZI: The answer is yes ? BARR: Well, in one year, it is not finished yet . Devenclra 
wil l also be talking later on this ; I guess on Friday . So, if you wante d to, you might be able to 
speak with him personally after the talk . TERZOPOULOS: Perhaps Andy would explain how he goe s from 
analytic expressions, as a concise way of expressing th e physics and constraints, to executable code 
automatically . WITKIN: Yes, sure, that is concise for the things that I am doing. There is the geometric 
part of objects that we know an d love -- exactly the stuff you need to draw objects . So, if it is a 
curve, the geometric part might be the parametric equation for th e curve. The same thing for a surface 
. Using symbolic math, yo u can add a physical interpretation which says how objects are going to move. 
It is sort of a template that you fill out mathematicall y which will let you take some symbolic derivatives, 
make som e symbolic simplifications, and then turn it into C code that goes t o the compiler . These 
templates involve mathematically extremely  SIGGRAPH '89 PANEL PROCEEDING S concise descriptions that 
can be converted automatically into stuf f that you can execute . Also, as far as accelerating the things 
we do, a lot of the low ­level operations that go on are main stream . When you are solving linear systems 
there area lot of dot products, matrix multiplies -- exactly the things that people who are programming 
supercomputers are usually worrying about, so in some cases ther e may be neat ways to set things up 
and make them go fast . The y may be quite generic and not special to what we are doing . TERZOPOULOS: 
Ok, go ahead please . Q. My name is Terry Boult . I am from Columbia University . My question is directed 
at the entire panel, but particularly t o those who are interested in trying to actually model the physics 
, especially for animation of the body, like in the facial animatio n that Demetri showed . Is your goal 
to actually have animators star t specifying force profiles for all the muscles that control a person' 
s face or a person's arm? If not, why are you going through physical modeling as a means of giving someone 
just another typ e of clay to work with . Why not start simplifying long before yo u have to start solving 
finite element equations or partial differentia l equations ? TERZOPOULOS: Well, our goal in facial and 
body animatio n is to develop process models that control individual muscles. The animator will interact 
with the model at the high level o f abstraction. He will give a high level command, let's say, "smile 
, broadly." The muscle process will coordinate individual muscl e cont ractions to initiate the expression, 
the physical layer will propagate forces through facial tissue, the tissue deformation wil l modify geometry, 
the geometry will be rendered, and the animato r will see a happy face . Why are we going through physical 
modeling? In large par t because you automatically get more realism that way, and ofte n its critical 
. Keith Waters developed a face model two or thre e years ago which was a purely geometric surface warped 
by muscles under kinematic control . It is fast and looks fairly good , and for certain applications 
it may be sufficient. For example, if you are trying do band limited teleconferencing, so at one end 
yo u take pictures, a movie, of the face of a speaker, you analyze th e pictures in real time to extract 
a few parameters for a face model , you transmit the parameters over a low bandwidth channel, an d then, 
using the extracted parameters, you reconstruct and animat e the face at each receiver so that others 
may "see" the speaker, i t may be sufficient to do that using a purely geometric face model . However, 
if you are making a feature involving animated characters, such as Marilyn Monroe and Humphrey Bogart 
in th e Universite de Montreal production Rendezvous a Montreal, an d you want a close up of faces, geometric 
face models suffer fro m too many artifacts . People can be very critical of human faces . I think that 
to make a really good human face you have to mode l some of the anatomy and some of the underlying physics 
. WITKIN: I have a one word answer to that question. It is : control . If you look at what really happens 
when people and animals move around, do tasks, and so on, you will see a n interaction between their 
own physical selves and the physical environment, and what happens in their brains to control thi s interaction. 
Of course, if you were going to make a physica l model of someone walking or talking or anything like 
that, to tr y and do that at the level of actually specifying the forces that th e muscles are applying 
would be a disaster . It would be hopeless . The point is that you can solve for the forces that need 
to b e applied to accomplish a task . That is an interaction between th e job that is being done and 
the mechanical situation in which it i s being done . PHYSICALLY-BASED MODELING : PAST, PRESENT, AND 
FUTURE SIGGRAPH '89, Boston, Ju131 --August 4, 989 Can I show the video tape? I just happen to have one 
t o illustrate what I mean . It was a take off on Luxo Junior, tha t maybe some of you have seen . We 
define a jumping critter an d give it muscles that it can control . We tell it to go from here to there. 
Then we indicate the optimal way to do that, how it can use its mechanical resources, its muscles, to 
do the job. From this specification, you get really nice structured motion that has bot h physical realism 
and goal-orientedness, by specifying something that in the end winds up looking a lot like key-framing 
. You are saying, be here now and be here then . ZELTZER : Let me give another answer while Andy is setting 
u p the video tape . That is, that animation in the conventional sense is only one thing you might want 
to do with these systems . In the piece I showed of the facial tissue simulation, the purpose is t o 
provide surgeons a means for planning surgical techniques . So, o f course, faithful physical modeling 
is critical, otherwise th e application is entirely worthless . It is not just the case that thes e techniques 
are only devoted to generating animations that tel l stories . BARR : I think that what Jim Blinn was 
saying is actually quit e exciting. This emotionally based modeling is really quite real . There is a 
brain biologist, John Allman, at Cal Tech who is quit e interested in how emotions can control the movements 
of th e faces . Certainly, if you want to express some sort of emotion wit h your medium, it would be 
hopeless to specify it with forces . ZELTZER : In fact, physiologists have developed a system calle d 
the facial action control system in which they have categorized th e muscles of the face. It is pretty 
well known which muscles are involved in creating which expressions . BARR : They can even tell which 
is a real smile and which is no t ZELTZER : That's right . So this is a tool providing economical control 
of facial expressions . TERZOPOULOS : Andy has a video tape to show . WITKIN: Ok, let's take a video 
break! This is work that Mik e Kass and I did at Schlumberger Palo Alto Research . If you look a t the 
way Luxo Junior jumped, this is a obvious take off on that . There is a lot of structure in there . All 
we are saying here is that Luxo should start at the beginning and stop at the end . We have a full 
mechanical model of Luxo, and we say : do it with minima l muscle power . Then we have an iterative 
solution that goes from a stupid initial version of the motion that does not look real, t o something 
that cloes look real . We are showing the solutio n process with a sequence of strobed images . So we 
are going from the initial version to the final solution . Here we are going to play the solution back, 
and we get a jump. Look at all the stuff that goes on in there. There is squash and stretch, and all 
of that, which comes out as part of the physica l solution. We give it basically two key frames to do 
all that . There it is in slow motion. Then since it is a physical thing, you can change the motion in 
sensible, intelligible ways by changing th e physical situation a little bit. We changed the mass of 
the bas e and it is all exaggerated . And look at that in slow motion . You can take that as far as you 
want to . Here's a hurdle jump with on e more constraint that says clear the hurdle . In the slow motion 
, notice how Luxo gets the extra height -- by scrunching, rather tha n by jumping higher, which is the 
sensible and energy efficient way to do it . Mike Kass programmed a ski jump . So this was pretty hard 
to do ; the mathematics is a little bi t rough, We're solving a variational optimization . But eventually 
I think we'll be able to package this into something that, when we'r e done, starts to look kind of like 
a key frame system again -- eve n though what goes on inside is a lot of mathematics . TERZOPOULOS : 
We have time for one or two more questions . Q. I have a question for Jim Blinn. I'm Ronen Barzel from 
Cal Tech, and you sort of said physically-based modeling is a crumm y idea . I figured I'd pick up that 
gauntlet . You made a really nice analogy between painting and photography . I really do like the analogy 
; I think it's really valid . But would you extend th e analogy and say that cameras are a really crummy 
idea ? BLINN: When they're aimed at me they are, yes! There is a n effect of this that you see, in that 
before cameras were invented , painters primarily painted realistic scenes and they were hired t o paint 
portraits of people and so forth . When cameras came about , cameras took over that process . Instead 
of having a painter, yo u had a photographer. And so it was no longer commercially viabl e for painters 
to do realistic paintings, and it was no longe r necessary. It sort of freed the painters to go off and 
paint weird abstract things and they no longer had to focus on reality -­ "photographic reality ." They 
were able to start exploring things , because anybody with some training can copy reality, whil e somebody 
with maybe more imagination was needed to d o something interesting abstractly . So maybe the fact that 
physically-based modeling comes along and takes over some o f the mechanical operations that animators 
have been doin g manually might free the animators to do more interesting abstrac t things . TERZOPOULOS 
: One more quick question, please . Q. John Williams, MIT. I think physically-based modeling seems like 
a really great area, but I feel there's a kind of conspiracy of silence about the actual physics and 
modeling, th e mechanics. As you're probably well aware, there 've bee n techniques around from the early 
'70s, like the finite element method, the boundary integral method, finite differences . I don' t really 
see anything different being proposed now -- if the aim is t o do physical simulation. If you want to 
really predict how the physics is going to move through time . It seems to me that the real benefit here 
is on throwing away the physics and saying we'r e willing to do inaccurate physics . We're willing to 
make som e approximations which the mechanical engineers and civi l engineers wouldn't make. And it seems 
to me, then, we can ge t this interactive behavior, which in fact makes the models reall y useful . 
Perhaps the panel can comment on this silence about finit e elements . BARR : I gave a physically-based 
tutorial last year that include d John Abell who spoke about finite elements . Finite elements are integrally 
involved in what we're doing. It's one of the mathematical methods that we have at our disposal, even 
fo r solving certain integral equations for synthesizing the swimmin g motions of objects. I would say 
it's not fair to characterize the bulk of what we're doing as "inaccurate modeling" -- that woul d not 
allow us to make predictions . We're building on that previou s work. So, if there's a conspiracy of 
silence, it's because we're making reference to this work in our publications and perhap s people are 
not picking up on it . But singular value decompositio n is a technique, Gear's method for stiff equations 
. These are som e of the tools that we're using . WILLIAMS : But if you look at all the examples that 
are given , they're all very deformable-type models and there's a good reaso n for that, because if you 
have very stiff materials, they're muc h more difficult to analyze. I do it myself. I mean, I like flopp 
y models because I can get the answer out in no time at all . Whereas a piece of metal, it's tough, and 
the animation in thi s year's Computer Graphics Theater of the falling teapot whic h breaks (Tipsy Turvy) 
. That's very deformable and there's a goo d reason. If you try to do it with a very stiff, brittle material, 
it will take you hours on a Cray .  SIGGRAPH '09 PANEL PROCEEDINGS BARR: There's a talk this year at 
SIGGRAPH called Moda l Analysis by Sandy Pentland . Q. I'm the co-author on that . BARR : Now that's 
good stuff. TLRZOPOULOS : Cm afraid our time is up, so I'm forced t o terminate the discussion . My apologies 
to those of you who didn' t get a chance to ask your questions . I would like to thank th e panelists 
and to thank you for coming to the panel . .  PHYSICALLY-BASED MODELING : PAST, PRESENT, AND FUTURE 
 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>77288</article_id>
		<sort_key>211</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Computer art - an oxymoron? Views from the mainstream]]></title>
		<page_from>211</page_from>
		<page_to>221</page_to>
		<doi_number>10.1145/77276.77288</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=77288</url>
		<abstract>
			<par><![CDATA[Hello. My name is Dorothy Spencer, and this is a special session entitled <i>Computer Art - An Oxymoron? Views from the Mainstream.</i>Before I introduce the panel members I want to tell you two things briefly about the session. First I'm going to tell you what the session does not focus on, and to do that I'm going to read from the SIGGRAPH 89 Show daily that came out this morning. So, for any of you that read it and came here expecting to hear museum curators, gallery owners and artists discuss the evolution of computer art as a means for artistic expression, you can go away now; we're not going to do it.What we are going to do is talk about the fact that computer generated imagery --- although it's been around for several decades, the mainstream art world has been slow to acknowledge it as a viable medium for the creation of fine art. There have been few computer art exhibitions and even fewer reviews. Like photography, is computer art going to take three-quarters of a century before it's accepted into the mainstream?Is it partially the fault of the artist? Are artists too wrapped up in the technological processes to be concerned with the aesthetic results?Does the majority of the artists using the computer not participate in regular juried shows because they feel their work is not understood?Does the technology need to be understood before the work can be judge aesthetically?These are just a few of the questions that we hope to discuss this morning and hopefully we'll have answers for. After each panelist has made his or her presentation, we'll let the panelists respond to each other's remarks before we let you people loose with questions and answers.My first panelist is Harry Rand. He's curator of painting and sculpture at the Museum of American Art in Washington, D.C. He'll be followed by Kathy Huffman, She's the director of the Institute of Contemporary Art, Boston. Followed by Philip Pearlstein, internationally-known artist and former professor of painting at Brooklyn College; Bob Riley, curator of media art, San Francisco Museum of Modern Art; Will Stapp, curator of photography of the National Portrait Gallery; and Vivian Rainer, art critic for the New York Times. We hope you enjoy the session. Thank you.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor>Arts, fine and performing**</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14069053</person_id>
				<author_profile_id><![CDATA[81332529250]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Spencer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Read/Write Press]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P104537</person_id>
				<author_profile_id><![CDATA[81332522584]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[H.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rand]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Museum of American Art]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P153598</person_id>
				<author_profile_id><![CDATA[81332505553]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huffman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Institute of Contemporary Art]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P217115</person_id>
				<author_profile_id><![CDATA[81100466494]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[P.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pearlstein]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Internationally known painter]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P26356</person_id>
				<author_profile_id><![CDATA[81332523304]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[B.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Riley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[San Francisco Museum of Modern Art]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P298392</person_id>
				<author_profile_id><![CDATA[81100188419]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Will]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stapp]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Portrait Gallery]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P291892</person_id>
				<author_profile_id><![CDATA[81100583216]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Vivian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rainer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[New York Times]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Special Sessio n Computer Art - An Oxymoron ? Views from the Mainstream Chair: Dorothy Spencer, Read/Write 
Pres s Speakers : Harry Rand, National Museum of American Art Kathy Huffman, Institute of Contemporary 
Ar t Philip Pearlstein, Internationally known painte r Bob Riley, San Francisco Museum of Modern Ar t 
Will Stapp, National Portrait Galler y Vivian Rainer, New York Times Hello. My name is Dorothy Spencer, 
and this is a specia l session entitled Computer Art - An Oxymoron? Viers from th e Mainstream . Before 
I introduce the panel members I want to tell you tw o things briefly about the session. First I'm going 
to tell yo u what the session does not focus on, and to do that I'm going t o read from the SIGGRAPH 
89 Show daily that came out thi s morning. So, for any of you that read it and came here expecting to 
hear museum curators, gallery owners and artist s discuss the evolution of computer art as a means for 
artisti c expression, you can go away now ; we're not going to do it . What we are going to do is talk 
about the fact tha t computer generated imagery although it's been around fo r several decades, the 
mainstream art world has been slow t o acknowledge it as a viable medium for the creation of fine art 
. There have been few computer art exhibitions and even fewe r reviews . Like photography, is computer 
art going to take three-quarters of a century before it's accepted into th e mainstream ? Is it partially 
the fault of the artist? Are artists to o wrapped up in the technological processes to be concerned wit 
h the aesthetic results ? Does the majority of the artists using the computer no t participate in regular 
juried shows because they feel their wor k is not understood ? Does the technology need to be understood 
before th e work can be judge aesthetically'? These are just a few of the questions that we hope to discuss 
this morning and hopefully we'll have answers for . After each panelist has made his or her presentation, 
we'll le t the panelists respond to each other's remarks before we let yo u people loose with questions 
and answers . My first panelist is Harry Rand . He's curator of paintin g and sculpture at the Museum 
of American Art in Washington , D .C . He'll be followed by Kathy Huffman . She's the director of the 
Institute of Contemporary Art, Boston . Followed b y Philip Pearlstein, internationally-known artist 
and forme r professor of painting at Brooklyn College; Bob Riley. curato r of media art, San Francisco 
Museum of Modern Art ; Will Stapp , curator of photography of the National Portrait Gallery ; and Vivian 
Rainer, art critic for the New York Times . We hope yo u enjoy the session . Thank you . Harry Ran d 
National Museum of American Ar t I'd like to begin with something of a disclaimer to pu t everything 
in context, because, after all, this panel is suppose d to be about the mainstream . My electronic skills 
are limited to plugging in a toaste r and my computational skills are limited to running Wor d Perfect 
4 .0 on a DEC Rainbow, a machine that, as some of yo u know, was hijacked by managerial talent after 
engineers ha d done a nice job on it . I'd like to set the tone of this panel by talking abou t something 
that may not be very much on the minds o f computer artists as they begin ; art and computers in the 
contex t of the past integration of new technologies and art, becaus e after all, I am here as an artist 
historia n It may not be immediately apparent that there's alway s been a time lag in the integration 
of new technologies into th e world of art . A lot of the masterpieces by which we reckon th e high points 
of art history are indeed monuments to that tim e lag . For example, the Parthenon, a building we all 
know wa s executed in stone, is actually a wooden building built of stone . It's an old wooden model 
of a form that had existed for centurie s perhaps thousands of years -- before it was executed on to 
p of a hill in Athens . That mimicry of earlier forms is typical o f the new ways of making art that 
are brought into th e community of artisans as they are developed (perhaps for some other need and sometimes 
because art itself represents th e cutting edge of technology) . In the world of graphics, when engravers 
first had etchin g put at their disposal, they didn't understand that when cross ­hatching is done in 
etching the plate deteriorates . You lose th e surface. It took a long time for people to develop a vocabular 
y of line that could be executed in etching . I'm tempted here t o talk about the time lag involved in 
photography, but Wil l Stapp will talk about that far more eloquently than I can . To bring things up 
to date, I'd like to mention on e example that's flagrant on television . One doesn't think of television 
as exhibiting this kind of time lag . There's a ver y popular show on television aimed at mass audience 
. It's calle d Masterpiece Theater . When you think about that title, yo u realize it's a total misnomer 
because the works that you see ar e not masterpieces ; they're the plots of novels written by usuall 
y anonymous teleplaywrights, and of course it isn't "theater" , a COMPUTER ART AN OXYMORON? VIEWS FROM 
THE MAINSTREAM it's television. But in order to make it palatable to th e audience, they create this 
name, which hark back to two earlie r forms . That's just one instance of the integration of technolog 
y using earlier forms as the basis for presentation to th e audience. However, there are other examples. 
Like, for example, Bach, who wrote a series of works called the Wel l Tempered Clavier to demonstrate 
the tempering of the geomet rically perfect scale to a somewhat warped scale tha t made advanced harmony 
possible . Perhaps the most misunderstood but important time lag i n the integration of technology is 
in the world of books --Specifically in printing where, (aside from the Bible) earlie r verbal forms 
were copied by printing and the most prominent of those forms was the novel in most languages called 
th e romance or the Roman because what it presented was a verbal form, the epic story . Until the late 
19th century th e work of Stephane Mallarme and certain other writers in Englan d and in America, the 
printing industry and the technology o f printing for art was using the stored up backlog of thousands 
o f years of verbal epics . If we talk about a time lag of a couple o f years in the computer world, 
we're talking about a very smal l time scale . Once the technology integrate a new art form, there's 
n o guarantee that it will result into major works or even works a t all. For example, there are technologies 
that have resulted i n no appreciable art technologies that have massively affecte d our lives . For 
example, the telephone and the airplane . Thes e are technological tools that have no art forms associated 
with them . How will computer art reach its mass audience'? The answe r is not through any technological 
innovation per se nor eve n through a critical mass of technological innovations, but b y the towering 
figure of an artist who can make palatable and ca n move the spirit of the audience . That is to say, 
a Beethoven o f the computer . Well, that concludes my opening remarks about th e expectations that we 
have for computer art based on historica l predications . But I'd like to raise one more point about 
th e imbedded associations that we carry with us about how we vie w and judge art, and this is based 
on a very recent event . Last night I viewed the SIGGRAPH Graphics Theater an d toward the end of the 
program there were two large pieces tha t were really torus de force of computer generated imagery . 
One of them from the United States was called knickknack and th e other one from Japan was called Imagination 
. I was surprised that the audience for those films o f which you are a subset included, I am told, 
between eight an d nine thousand people ; their reaction to the Japanese product , which was tinged with 
all sorts of sci-fi images, was far more enthusiastic. They were reacting to the plot, the imagery in 
the movie . Whereas in fact the American film was technologicall y more complex, it didn't try to impress 
you with the technolog y that was behind the imagery . They were both using essentiall y the same technology, 
and the Americans may have used eve n more advanced technology that seemed to involve mor e algorithms 
for light sources, reflectivity, friction, muscle generation, etc . But what we saw were two products 
that were very typica l of those national cultures, just as one could look at a Japanes e painting and 
an American painting or a French painting and a German painting, and make statements about the characteristics 
of the society that produced them . The Japanes e work seemed very typical of a spiritual authoritarianism 
that we associate with Japan, whereas the American film had a lightheartedness . It's through the integration 
and the comfor t that one would take in those technologies, that over time we'l be able to make stylistic 
statements that will eventuall y produce major aesthetic statements in computer art . Kathy Huffma n 
Institute of Contemporary Ar t First of all, I will be very direct and tell you that I als o don't feel 
I represent the mainstream of art . I am working a t Institute of Contemporary Art, which is directly 
across the street from the Hines Auditorium and it's my base as a curato r and a producer and we support 
contemporary living artists such as Chris Burden, which is an exhibition that many of yo u attended the 
opening of last night . If you haven't, I invite you to come and check it out . It' s just a few minutes 
across the street and it exemplifies som e very unique uses of power and violence as central themes o 
f conceptual art . In fact, every time a visitor comes into th e galleries he must pass through a turnstile 
which applies som e kind of pressure to this jack that is pushing massive bar s against the ICA's bearing 
walls . So the advertisement is the more successful this exhibition is, the more dangerous it is t o 
you as a visitor of the institution and to the institution itself. So you can see this is hardly what 
we can call mainstream art i n the broadest sense of the word . But it's also probably the place where 
you might find something called computer art, if you will, as a first line t o enter into an art exhibiting 
possibility . Because of that, w e also do performance, we do video, we do film programs and ne w music 
programs. And they quite often combine computer technology . All of this is basically an investigation, 
I believe, o f time, of space, and to some extent the technology and tha t together with sculpture, print 
making and photography an d painting, comprise the contemporary art scene today . It is a special I'm 
a specialized curator for video and I came to explore computer works through video . Today many o f the 
video processes are indeed digitally based and are becomin g more and more accessible to many more people 
because of th e low format technology that's more and more available now . But I've been keeping abreast 
of the developments sort o f separately in computer art since the early '70s . One of the firs t shows 
was this artist and the computer which was 1976, an exhibition organized by Ruth Leavitt, and I was just 
checkin g this out last night to see how the field has changed no t having looked at this in a long 
time, and it really is quit e different today than it was in the mid '70s and early '80s . Here most 
of the exploration I believe was in the kind of permutations, the representation of reality in a very, 
very lo w end way as compared to what's happening today with th e sophisticated rendering techniques 
. But because the computer art look has expanded dramatically, as has video look, I'd like to compare 
a little bit this sort of word oxymoron as compute r art, with the similar oxymoron of video art . First 
of all, it's art or it's not art, and actually bein g computer or video has very little to do with the 
fact that it's art. And the fact that they both have to exist with these combine d titles I think is 
more to its detriment than anything . But as I was also reading in the computer graphics issue here o 
f Leonardo, several of the writers for the SIGGRAPH Art Sho w have really addressed these issues quite 
well, and I'd like t o single out a couple of the essays that I'd suggest that you read . One is by 
Donna Cox and she discusses this paradox o f postmodernism and the relationship to the computer, and 
sh e really offers some invaluable glossary terms for those of us who aren't quite familiar with a lot 
of the newer techniques o f the computer world . Brian Rethen-Smith, who is also an artist himself, als 
o writes about beyond computer art, and he outlines a lot of th e criticisms that have been lodged against 
art made with th e computer. I also enjoyed Richard Wright's essay, The Image In Art and Computer Art, 
and especially a section called The Creativ e Process in Symbolic Space, which tries to describe the 
nature of the computer as a medium and its non-physicality, which I think is probably one of the more 
interesting aspects o f computers and art today . First these terms of art and computers and all of this 
 it' s really the ideas that I find that are more important and the idea s that artists are expressing 
and really not the technicians or th e design aspects or the technical concerns . Their contribution 
i s completely viable within a design context or within a technica l context. But many of the so-called 
computer artists, they've spent many, many hours carefully rendering or rathe r rerendering the great 
works of 19th and 20th century artists , including Picasso, Miro and Cezanne. hi fact, many of the works 
we tend to think of when we think of computer art i s those homage to Cezanne or this homage to Picasso, 
and I think that without any kind of political subtext or subversion of the form, it can really get stuck 
in a very flat place . Art, on the other hand at least today in the 20th centur y is rarely a pretty 
picture . The artist today is receivin g attention in the mainstream with works that might includ e themes 
that are about representation, marginalization , sexuality, social space, and the definition of the art 
object . These things themes along with others, can be and ar e explored in a variety of media, and 
media in combination which of course includes the computer as a source for ideas an d images . If we 
were among the art workers from the nonprofi t sector, like I am, and especially within the alternative 
gallery , and artist run centers, we would be discussing the computer an d artists who use a computer, 
in a much different way than it' s being discussed here in a technological framework . It would be the 
intent of the work, however, or the output, that ou r colleagues in this alternative world would be concerned 
about . So here in this context I do feel rather uncomfortable i n the midst of all of these advanced 
technological innovations , many which I find to be amazing futurist concepts . But the vocabulary, the 
marketing technology and the destination fo r the output is somewhat foreign to me . I'm much more accustomed 
to viewing works by artist s which have been made on the Amiga or the Apple Computer , rather than on 
a Waveform or a Cray 10, or whatever is th e latest edition of this. Not unlikely, since a few artists 
have had the opportunity to use any of these machines . And if the y have, they rarely send them to alternative 
art museum . But as this pyramid is going to flatten and as it is an d computer graphics technology itself 
flattens and as has vide o electronics, we're going to see more and more access and mor e and more interesting 
works . There will no longer just b e illustrations that are the sci-fi look, or T .V, logos or other 
bi g ticket advertisements . So I guess I've answered one of the questions of the pane l already that 
 yes, computer art is accepted in some alternativ e mainstream with some qualifications, and I'll just 
review quickly . It's mostly low tech . It rarely reveals a fantasti c landscape. Its vistas are rather 
a landscape of the intellect . It encompasses a multiplicity of concerns and other time-base d media, 
including performance, video, film, music, etc . And it relies much more significantly upon words, and 
it is often a n investigation of the computer itself. So just as the best work of contemporary artists 
question s the system that supports it and the hardware and software that make it a reality, I see the 
future for computer art, that is mus t sort of follow in that line if it enters into the same genre o 
f contemporary art . I hope to see much more art made with th e assistance of a computer that does not 
reduce the images to some kind of a common denominator, but rather creates an individual expression that 
is made personal by virtue of its availability. Thank you .  Philip Pearlstei n Internationally-known 
Painte r I'm an artist, but I was glad to hear Mr . Rand mention tim e lag because I'm a late blooming 
artist . Everything in my career has come late, I decided to become a realist painter when I wa s approximately 
40 years old after having worked in a number o f other ways and periodically I've gotten involved in 
other kind s of techniques lithographs aquatint etching, and mos t recently I completed a 10-foot wide 
landscape in woodblock , made up of nine blocks . When I was approached to do a video disk it's als 
o available on tape -- of let's say a kind of monograph o n myself, I decided it should also include 
my teaching. I got involved in teaching rather late in life too, after having had a career as a graphic 
designer. Then I studied art history for a while, and I painted, exhibited . Anyway, finally stumbled 
int o teaching. I've been teaching for the past 30 years. I make myself sound older. I've lost track 
of time. At any rate, the person who put all this together came to Brooklyn College t o take the course 
that I thought would work as part of thi s monograph, and essentially it's an art history course, but 
i n which I have the students more or less take one image throug h the history of art . By the way, when 
I first set up this course, I found tha t representational art you could call it illusionistic art 
presented the most interesting challenging problems, and th e ones that I knew least about. I spent the 
rest of my days trying to figure them out. At any rate, this person came, took the course, and decide 
d that a lot of the stuff I was scribbling on the blackboard woul d really be best on video, in a computer-generated 
form . I spen t roughly 200 hours at a computer over a period of a year , working out all kinds of ideas, 
most of which were eliminated . They're not usecl and the ones that were used are just used ver y fast. 
So I had a tape made up of some of the images developing . They're not in real time . I mean, I constructed 
them over a lon g period of time. But they're in playback time, which is roughly five times the actual 
time in which it takes to draw something . I'd like to start with that tape. That's the name of the project. 
This was a demonstration of pointillism vaguely taking Seurat as my point o f departure. But I did work 
 by the way, all my work i n painting, printmaking and so forth, has almost entirely bee n done directly 
from life . The one exception has always bee n landscape prints . I've done water colors and then worked 
up the prints from the water color . That's more or less the approach I took here . But some of the images 
were done, constructe d directly from the model . The model came and sat in the studio . The machine 
I used was called a full paint machine . It wa s custom built. I don't remember if it had a commercial 
name o r not. It had a huge refrigerator unit attached to it and it was very cold -- which was one reason 
why I gave up the idea of havin g models sit there nude all the time . This was a cubist exercise starting 
with three views of on e model . Again, it's an approximation of the idea of cubism . Here you see all 
three drawings being superimposed . They were open form drawings, rather than continuous outline drawings 
. Then I began superimposing on this image certain ideas out of action painting. I actually found myself 
emulating th e work of one of my friends . One of the thoughts that occurred to me as I was workin g 
on this was that you have to accept the limitations of any media and the limitations of this media has 
to do with those light pixels, the fact that the light is part of it, and that it's o n that screen . 
I think printouts that I've seen that most artist s seem to work towards are ugly . They're just bad 
photograph s of the final image. I would much rather do a real print. But I thought that working within 
the limitations of this media i f they could be made up as tapes, as this one we're watching there was 
a kind of validity to it . This could be conceivably a work of art if the artist who worked at it deliberately 
went abou t choreographing his moves . The fascination is in this built-i n animation, and I would assume 
that somebody along the lin e will come to grips with it . One of the fascinating things about the machine 
I worke d on was that you could program any color you wanted and als o make that color any degree of 
opacity from full transparenc y to the point where it was like actually working with the past e of pigment 
 or reaching in and putting a pastel mark down . I was really fighting the machine which wants to d o 
geometric work very easily most easily . It also wants t o scribble. It would be great for a graffiti-type 
artist. Perfect for someone like Keith Herring. Also the way that you can superimpose photographic imagery 
and manipulate them , change them around and scale, superimpose them and so fort h change the color 
seemed to me the perfect kind of mediu m for a young Robert Rauschenberg . What I was trying to do was 
to make my own kind of image on it the kind of thing i n this case the kind of thing I would do with 
water color. As I say, my approach to realism though did come out of an intellectual structure, a structuring 
of the problems . In fact, I gave a panel at the College Art Association abou t 10 or 12 years ago, 
which I called the Conceptualization o f Realism, and had a number of artists on it who I felt worked 
in the media or with a media to an extent that that work . The process itself, became the subject matter 
. Artists like Georg e Segal, Chuck Close, Sylvia Plimack Mangold . There were a couple others . But 
everybody worked within the limits of th e media, and what you're seeing is exactly my approach t o realism 
. I spent many years as a graphic designer . My hero at th e time was Mondrian. When I came to teach 
graphic design, it was in terms of Synthetic Cubism . But I always think in term s of a grid overall 
grid structure and the arrangement o f shapes on that grid . I think in terms of proportions , measurements 
 which has nothing at all to do with academi c drawing, of course . I kept layering the colors and what 
you're seeing now are the various scrims I don't know what you call them -- wher e the page comes down 
slowly when you call it up . Because yo u have to reassemble your image . Every set of marks that you 
make you give a title, it gets recorded, and then you have t o reassemble it at the end . That can be 
a lot of fun . It can also b e a big headache. But I think there is a lot of room for futur e experimentation 
within that the assembly of the image . Bob Rile y San Francisco Museum of Modern Ar t A little over 
a year ago, the Museum of Modern Art in Sa n Francisco, in rearranging the curatorial enterprise of th 
e museum, formally established a Department of Media Arts, an d I am its first curator. The founding 
of the department is based on it's in recognition, pretty much, of the variety o f activities and media 
art forms around the Bay Area and internationally the number of artists from California working in synthetic 
images and video and film and in sound, that hav e had very little recognition at the museum regionally 
in Sa n Francisco, but have international influence . It's also in recognition of the fact of the presence 
and influence of these forms and media art forms on the high minded ideals of modern art . So by that 
I suppose I' m representing the mainstream . I don't at all come from a mainstream position or practice 
in the art world. But this position was so interesting that I accepted it . It's been quite a year so 
far . So the question is raised today and I'll addres s you, assuming that you're all computer artists 
in the audience , that the question is raised whether you are making art with computers. And from what 
I know and from what I've seen an d from what I've gathered at the Conference, is that the answer i s 
unfortunately yes . You are making art with computers an d that's exactly where the problems begin . 
Now the articles in Leonardo that I stayed up to read las t night were particularly interesting to me 
because they were s o dissatisfied about where this art work is going to go, where thi s interest in 
computers is going to go . In fact, some of the articles are cranky they're downright cranky. They're 
all very, very quick to use some art historical terms . The one that I find most annoying, of course, 
is post-modernism, because I don't believe that thank you that modernism, of course , is not over. 
All kinds of forms in the past 20 years have com e back from the dead to make killings in the marketplace, 
but I still believe in the ideals of modernism and I think that thi s computer art movement and the media 
art movement has muc h to do with modern art. As computer artists, that I am first agree that you do 
set ou t on very ambitious of computing as Kathy pointed out o f simulation . You develop very compelling 
techniques visua l techniques that are interesting . But the final outcome seem s to be based on all 
the wrong models of visual art . It's not boring for the practitioner, but it's extremely boring for 
th e viewer. As far as I can see especially manifested in thi s particular Conference and over the past 
10 years or so for th e most part, the computer art looks to me that it embraces '60 s technological 
utopianism and a fascination with phenomena , randomness and indeterminacy that you find in certain ar 
t movements of the time like Happenings and Fluxis and different experiments with early media and expansion 
arts . An d all that has seemed to meet the '80s work ethic . Everyone' s busy . Everyone's in suits 
. Everyone's doing things . So walking around the Conference I noticed a few things and I ha d some thoughts 
. And I discovered that it was the presentation i n the floors, in the marketplace, in the shows, in 
the booths not the art show that seemed to raise my spirits and m y expectations . I find that all 
these are magnificent tools that are invented to solve problems, invented to assist people in rendering 
and display techniques and all that. But the drawback about all this equipment and all this technology 
and all th e programs, as I understand them, which is not of course a s informed as you, but as an outsider 
who is working from an art museum situation, looking outward at this kind of activity, i s that here 
you have all these men in suits telling you exactl y what to do with their program - exactly what problems 
you have that need to be solved . So I'm walking around "says who?" So I'm listening to all these barkers 
and all these guys in the carnival and displa y booths down there which are remarkably designed an d 
beautifully built . But still, all the booths created some skepticism in me. They generated some skepticism 
and some doubt about computer art . I stopped by one place . I won't mention any products, o f course. 
Somebody was claiming that their product was th e fastest route from imagination to reality. Ooo. I hung 
around . There are other places where there were salesmen an d barkers telling me that I was looking 
at 3-D . I wasn't lookin g at 3-D . I was looking at the illusion of 3-D in all these ver y colorful 
graphics inside this screen. I wasn't looking at stiff 3 - D . Someone else comes along and says and 
then we add a littl e texture. I see no texture. I have no empathy for this object . It's just an illusion 
. It's just light in the screen . So I spent m y entire day walking in different floors looking for these 
kind o f experiences . Say no more . But I want to reassure you, of course, tha t the art world is conscious 
of the activity in this isolated field o f program designed graphic display and manufacture. We know 
it. We know it's profoundly influencing the art world. But we really don't know how. The best thing to 
do is to come to as many of these programs as we possibly can, meet you, see wha t you're doing and understand 
the technology from this kind of a perspective . The art world, of course, is aware that what we see 
in you r final products isn't really the creative ingredient either. This is a bit of a problem in the 
tradition of the visual arts in th e tradition of scholarship, in the tradition of connoisseurship . 
That this is a unique object and that everything you see in it the artist's touch it's all a recording 
of different kind o f decisions which we understand . Computer art is a recording , it's a storage of 
decisions that we don't quite understand yet , because we haven't had your background. Hopefully, there'll 
be people coming into the field, of course, who are born with computers, who know exactly what is going 
on . But I'm from the generation, of course, that comes sort of midway yo u know, the sink or swim generation 
. But the art world is also waiting to see forms develop that are unique to the command and the control 
medium, of which you're all familiar. It's something interesting I find an d other curators working 
with me, like colleagues find tha t there's something extremely interesting about the act o f assembly, 
the lack of fixed parameters, that seem to be involved with projection and with different compute r technologies 
that are possible for you to work with as material and as form . And also the possibilities of this endles 
s expansion and retraction, the infinitesimal kinds of images o r logic or conceptions that you can't 
see, and also expansion o f scales to such an extent that you also can't see it . So there' s this whole 
dynamic that's going on with the movement, with your computer art movement . There are also artists, 
of course, as you know, who us e computers, but it isn't called computer art . There are performers and 
sculptors who have always needed to contro l time and event in their performances, and of course video 
i s pretty much a catalog of special effects. Whether or not it's suitable for the service of some expression, 
of course, i s questionable, but still you can see plenty of it in television an d in video art . I don't 
know if you know an artist that I'm particularly interested in right now Alan McCollum, who makes uniqu 
e objects . I don't know if you've seen them . He was in the Forest of Sign Show in Los Angeles, but 
he designs all thes e surrogates, all these objects that are not art, but still they're objects, and 
all these other objects that he calls unique objects , from information that he supplies and that he 
enters into a computer, and then he draws the pattern for the fabrication o f these little units from 
the body of possible solutions in hi s computers and no two are ever alike, and he manufacture s them 
by the thousands . And this is also how he displays them . No two are ever the same . So I'm interested 
 I'm not resistant at all to computer ar t and computer technologies. I've come to no conclusions. I've 
yet to develop any kind of theories about it . But I do certainl y have the interest. Just in closing, 
I'd like to say that there are since I don't have any answers, any solutions, I will quickly tal k through 
this so that we can move along and then get to som e interaction and some audience questions and responses 
fro m everybody up here . But there are some very importan t questions that we're all beginning to start 
a process o f exploration. Among these kind of questions are what happen s to the structure of the art 
museum when the unique object i s obsolete, when everything is a print or an luminous screen . There's 
no recording or touch . And if you come to the museum , what happens when your museum visit is one of 
interactivity , that you walk in and you call up whatever image that you wan t or whatever kind of relationship 
you want to have with th e technology at the museum . What happens when the work of art exceeds the structura 
l or compositional frames and is perceived in a time frame? I as k this because one of the most annoying 
things about crossin g the field and going through the art show is that everything is i n a frame except 
for one piece the bicycle piece, with th e text that is projected . Everything is in this annoying frame 
. You know, the barker did have an argument when he talke d about the fact that it was 3-D . Well, the 
3-D illusion was onl y possible because of the fixed frame of the television image . Everything had glass 
over it . Couldn't touch anything . Nothing came out. But the dynamic of the image was there working 
because of its relationship with the frame. Once I saw that frame, all I could see was frames everywhere 
. But I think that there is a way out of this slavery to the frame . I look t o you for computer artists 
to find a way . What happens with ones empathy for objects, as I hav e mentioned before? What happens 
when your body consumes space and one of the most compelling things about sculpture i s your trajectory 
around the object, your empathy, your physica l being, in response, in relationship, in communication 
wit h this other physical thing without language? It is the languag e of the physical nature. Ultimately, 
I really have to ask the question, What is society rejects these forms of production al l together? The 
museums are full of antiquated things . Yesterday I walked through the computer museum it had one antiquate 
d piece, beautifully designed, but one antiquated piece o f equipment after the other . So what happens 
is, as Kath y mentioned, there are some very important issues happening i n the art world today. Issues 
of survival, issues of the third world entry into the more dominate culture and what forms o f expression 
are they going to invent. What kinds of forms of expression in culture is going to be suppressed as the 
population shifts in that kind of lull from one culture to th e other. So what happens when society rejects 
these forms of production? Will they or won't they ? I close, thank you! Will Stap p National Portrait 
Galler y My name is William Stapp, it is not up on the screen . This is just to identify me to you . 
I am the curator o f photographs at the National Portrait Gallery in Washington . I am here, I think 
as the most history oriented member of th e panel. My real interest in 19th century photography which, 
of course, is really the progenitor of what your dealing wit h today . Photography was really the first 
technological medium . It went through many of the same kind of crisis . Crisis of identity that contemporary 
arts and particularly th e contemporary technological arts are going through. Less from my point of view 
than perhaps from yours . I don't know . I think it is important to consider the situation of th e history 
of photography when you think about yourselves . Because, photography as a technological medium when 
it wa s introduced was completely unprecedented . Computer imaging is not. You use other vocabulary that 
had become familiar to us in the past 40 years or so . But, the photograph itself i s unprecedented . 
Its technology was not understood at all . It functioned as magic and yet there was this impedist wh 
o adopted and to transform it from a technology into a visua l medium very quickly . That happened very 
quickly . The technology was introduced 150 years ago . Almost today, 150 years ago in France . Within 
6 months, images tha t could be considered and looked at, and viewed today as ar t objects have been 
made . Both technically perfect i n something that had the image content that transcended th e description 
. The power of description that was so fascinatin g about photography and its inception . At the same 
time there were very few people , photographers, who considered themselves as artists . They were delineators 
. They called themselves operators to express or describe the mechanical nature of this process they 
were using . Yet, in retrospect we see them working and using thi s instrument, this technology with 
the eyes of an artist with a n artistic vision . It is just that they did not conceive it as such , or 
did not address it as such . It was probably 25 years before a photographer identifie d herself as an 
artist and described her works as artworks an d presented her works as artworks in a gallery . In an 
art gallery . Not in the context of an industrial exhibit or a mechanical fair , which is the way photographs 
were traditionally shown or had been t raditionally shown since about 1840 . That person wa s Judy Margaret 
Cameron . What interests me in the history of photography is thi s transformation of it from a technology 
into a medium . It is a little bit hard to study because people were not particularly aware of what was 
going on. Yet, it very certainly occurred . It just did not become recognized probably until the later 
part o f the 19th Century and beginning of the 20th Century by a few people. People like Alfred Stiglets 
in this country . Museums didn't really begin to collect photographs unti l the very end of the 19th 
Century the beginning of the 20th Century . And then, only very sporadically and very, ver y intermittently 
. There were perhaps only three museu m collections in the world that collected photographs as object 
s as distinct from records or artifacts of technology at the turn o f the Century . It was not really 
until the late 1930s on the anniversary , the centenary of the introduction of photography that peopl 
e began to consider it in a larger sense . In a larger context as an artistic medium . Even then it has 
taken another 20-30 years fo r that broadening appreciation to develop into a market . Photography is 
an art medium. It is a significant art medium. It is really something that has been accepted onl y within 
our fairly recent life times . Within half of my life time . Beginning in say the late 1960s . It has 
been very closely tie d to the art market . What is interesting about this is, that as this market ha 
s developed we have learned a lot more about the history of photography itself and about the development 
of photograph y as an artistic medium . In 1900, 1905, 1910, when Stiglets, Alfred Stiglets wa s talking 
about the history of photography and the great artist s of the medium, he identified I think really only 
two people . People whom he considered to be his antecedents . One wa s Judy Margaret Caraman, who was 
photographed in the earl y 1860s. The other was actually a team of photographers, David Octavius Hill 
and Robert Adamson in Scotland who actuall y began working in the early I840s . Nowadays, we have not 
just scores, but probably hundred s of names from those very years who are recognized a s significant 
figures in the history of the medium. Significan t artists in the broader world of world art. What I 
would suggest that is in many ways we are probabl y too close to the introduction of computer art to 
really evaluat e it. Although, in the post-war period, the post-world war II period, history is accelerating 
. We become interested in things and more informed about things and perhaps more judgmental about things 
much more quickly than we did in the pre-wa r period . I think even so, we still need perspective . I 
don't know an awful lot about computer art, in truth . I have no questions at all, no doubt at all, that 
it is evolving into a significant medium if it has not already done that . It may tha t we just haven't 
identified those artists who are significan t figures yet . We may not be able to for another 20-30 year 
s providing of course that those objects, used in the ver y broadest sense of the term object, survive 
, One of my concerns about the medium is its inheren t fugitiveness . Most of your creations are done 
on tape now . Tape doesn't last . You are dealing with a medium that will no t endure. It is a problem 
that really needs to addressed and to be considered. Thirty years from now the works that you have created 
after hours, perhaps hundreds hours of effort may b e memories only. It is a significant problem. It 
is a significant problem for museums that will collect them . However, those collections are built in 
however they may be displayed . Questions of obsolescent of technology which occurs no w at an increasingly 
rapid rate, I think is a significant one t o address too . The objects may exist, but it may be impossibl 
e to show them. Those are problems that need to be considered and need to be looked at . At this point, 
I don't think that I have anything else to say except that we are still too close, you yourselves are 
t o close to your own time perhaps to understand what you ar e doing in the broader context . The other 
thing I think, don' t believe that the medium has limitations . The most interestin g photographs were 
made by those people who were eithe r ignorant that there were things that they were not supposed t o 
be able to do, so they did them . Or, people who ignored the rules, who knew the rules . but ignored 
them. Stretch you r imaginations and push the medium beyond what you are tol d that it cannot do, always 
explore . Beyond that, I haven' t anything else to say at this point .  Vivian Rainer New York Time 
s There is one of the works in the exhibition is a dead computer terminal with a fish tank in it. There 
is this tiny little fish in it and I feel very close . I identify . I have reviewed one large show of 
computer art and it too k two hours to get around and I felt physically ill at the end of it . Not because, 
and I have seen a lot of large art shows, no t because there was anything wrong with you or anythin g 
repulsive about the images but because I had spent two hour s giving, you know, flying faculties formed 
by hand made art t o machine made art . The absence of the artists touch . It is absence made me feel 
very uncomfortable . Working around this show here, I feel as though I a m looking at after images . 
The things that look like things tha t have happened in art 10 or 15 years ago . They are not the rea 
l thing . On the plus side, I feel that computer art solves the objec t problem we are rapidly becoming 
inundated with art objects . Computer art is ephemeral, that is good too . My feeling abou t it . That 
is all I have to say . Moderato r Dorothy Spence r Read/Write Press Because we are running really short 
of time, I think we ar e going to, unless there is any burning questions between th e panelists, why 
don't we open it up to people on the floor now ? Ok? Are there any questions ? Q. I think this panel 
has a really good place in thi s SIGGRAPH convention and I hope that in the future we ca n really use 
this arena to open these issues up . I think the cinema is a medium that computer graphics needs to acknowledge 
th e cinema a little more . That is why we are still locked into th e frame. I think that the technology 
is going to really expan d that for us in the future . But, where we really need to focus is i n the 
art schools because we can bring all of the media together that contribute in this area. I wonder if 
any of the panelists ca n speak on that ? A . Sure, I will go for that one . Yes, I completely agree 
wit h you. I think that is something that most art schools follo w through . I know that Mass Art here 
has a program in computer s and I teach at the San Francisco Art Institute, a littl e moonlighting, in 
the performance video and compute r department . The students have wonderful ideas and they don't kno 
w how to do it . That is one of the best things about teaching I think, in art schools is you watch all 
these students chip awa y at their inspiration and at their desire . They want to make thes e things 
but, they don't know how to do it . But, now that there is computer programming possibilities as the 
art school i t attracts students to look for an alternative material in a n alternative way to perform 
to their ideas and their expression . I think every art school should of course generate a department 
of computer art . I have heard repeated often, people that are teaching and graduating people that don't 
hav e computer literacy . They feel that they really have to examine , you know the focus of the academy 
and the academic situatio n that this student has gone through over the years. Because, al l of the sudden 
they are releasing a student into a world in whic h they have no training. They have no background. They 
have no knowledge of it . So, as I said in my talk a little bit, I think once you see people more familiar 
with computers and more familiar wit h what they can do and how they can help them solve a problem , 
and help them put a final form to what they are doing . I thin k we'll see a lot more computer art . 
Am I the only one who teaches on the panel ? A . I would like to say, one thing that was ignored by thi 
s panel that you did mention , a great deal of computer, the use o f computer art and investigation of 
possibilities is done in th e commercial areas . You see it on TV . I think most art school s have set 
up a kind if hierarchy between fine art and the so called commercial art . Which is totally artificial 
. There is a great deal of confusion now in the fine art world in that many people who should be in the 
commercial world ar e showing works and having them accepted as fine art and the y are really just variation 
on graphics design or advertising art . I think a lot is going on already in those other departments 
. Not the fine art department but where they teach graphic design o r commercial art or whatever you 
want to call it, communicatio n media. There was a program here the previous panel, where a lot of work 
is being done with computers and scienc e programs. I think the art departments should take a walk sometime. 
See what is going on . SPENCER : Next ? Q. You don't find it sinister that the corporate world is s 
o interested in this medium . Seems to me that since they hav e been buying all the art and controlling 
so many of th e exhibitions, now they want to get in and make it themselv es . They want it all ! RAND 
: Well, that was true of the Medicis as well . A . Medicis didn't do any art work that I know of . 
 A . Well, the corporation don't do the art work . It is individuals that they . . .  A . I don't buy 
mogulism of the Medicis editing myself . RAND : They are functioning on very much the same level . Unfortunately, 
they don't have a Michelangelo to work with .  A . They might . SPENCER : I just want to go, well first 
of all I want to than k you all for addressing these issues . It is wonderful to here it an d begin a 
dialog. But, I would just like to go a little bit further o n the question that I guess was being addressed 
by Mr . Pearlstein .  It is about intent . Those of you who are dealing with th e issue of exhibiting 
computer art, is intent a part of tha t meaning for instance, if you have seen the film and video show, 
the intent there was a storm video . That was ver y beautiful . I could see someone having done that 
for a reaso n that had to do with the analysis of weather and somebod y taking that afterwards sort of 
taking away some of the stuff an d putting in other stuff and saying this is a beautiful image, thi s 
is art . So is intent part of your evaluation and the other question I had is very different, it that 
issue of because this medium yo u can borrow anything from many places. Those of you who are dealing 
with exhibiting and presenting computer art, what about the issues of stealing and copyright issues . 
Are thos e part of what you have to, for instance in this Smithsonian, d o you have to deal with those 
issues of "that image was take n from that person . Do artists have to sign a release that the y haven't 
done this that of the other thing ? RAND : The issue about copyright is really an interesting one . We 
had a Rauschenberg piece a few years ago that incorporated another image and there was a real question 
about the patent an d copyright rules regarding this image . Because, suppose then someone decided to 
buy their reproduction right fro m Rauschenberg and put it on a T-shirt or a coffee mug . It reall y 
got very complicated . Where would we stand as the exhibitors of the work. I am please to say that there 
are lawyers for that problem . Money solves your problem . The question has meaning only within the legal 
context of a particular society. It is not a question of expropriation of image, which is an artistic 
problem . The initial question you asked really goes much more t o the point, about intentionality, because 
it has to do with the business of art history . One can't know with any kind o f certitude the original 
work of art from the past . For example , some of the works in this show that we see around us today 
demonstrate certain technologies . Or, if the artist was more adroit, use those technologies in the service 
of some idea o r some esthetic . But, all art from the past until a certain moment quite clos e to us 
in history was in the service of some other idea o r esthetic . It was religious or for the purpose of 
selling image o f the state. High-tech always cost a lot of money . So patronage is the Philip Pearlstein 
referred to was usually in the hands o f the richest people . If you don't believe that, you can go ou 
t and try to build a pyramid yourself . You would be amazed a t how much it costs. You really have to 
marshal the intent of the state. That is pretty low-tech . A . Photography is a perfect example of the 
whole issue o f intent. The collecting of photography. Most photographs, at least in the 19th Century 
and probably into the early part of th e 20th Century, were not taken and conceived deliberately as ar 
t objects. They had other functions. It might have been pure record . In many cases it was commercial 
. Particularly in th e works from the 20th Century, early 20th Century 20s and 30s . These pieces now 
are seen and collected as individual artwork s and exhibited as artworks. On the market they can fetch 
price s that would have staggered, probably killed, the person wh o created them because they were done 
for a few dollars. Earned a few dollars and can now fetch now tens of thousands of dollars and even more. 
One of the things that has happened in the 20th Century i s this whole concept of the found object as 
a significant work o f art. It has often been an artists decision in this era, But, at least as photography 
goes it is also a curators decision . It is not one that concerns me a great deal . For someone wh o 
collects photographs for an institution, most of the works tha t I have were commercially produced and 
commercially intended . Q. I will move on . I don't think that the copyright issue is a s simple as you 
say as getting lawyers . I really don't. Q. Hi, during the late 70s I was doing video work . At thi s 
point I am doing work with computers . During the 70s I ha d works at the New York Modern Art Museum 
over at the Lon g Beach Museum . The types that we were trying to out was in Lo s Angeles at the time 
and we were breaking down the barriers o f the museum, being able to have, the works are not really there 
able to be displayed, available to everyone and not th e necessity of having a museum . On that point 
they were talking about before. I was wondering, the work that I have seen here are more desig n oriented 
and not exploring the medium of the late 20th Century and I was wondering are there people, have you 
seen peopl e addressing this new medium in a new way? Not traditionall y like one of the panelist has 
you know the serrate or that type o f modeling . What directions do you see? Why should thi s medium 
model the past of almost the stone age? Why do w e have to start at a place of traditional art and go 
from there ? Why can't we take it and move on beyond and start from Z and go beyond that instead starting 
all the way back from ancient history . SPENCER : Bob, do you want to start on that? RILEY : Oh , ya 
. I know Kathy has quite a bit of theory abou t this Don't expect anything profound here . I know a number 
of artists who have just started to pick u p computer technologies in pursuit of solving problems . I 
know a sculpture who wants to enlarge one his pieces into suc h extreme proportions that you can no longer 
see it . This is Howard Freed. I know many artists that of course go into the video editing studio with 
notebooks and notebooks full o f notes and edit descriptions that they are after. I think that in your 
interest not to have, as you say, thes e works of art, revert all the way back to the stone age, I think 
i s a beginning for people to start in the modernist pursuit o f critique and looking at the art making 
practice . I think that is a very smart place to start to think about computer languages an d ultimately 
computer images and what you can do with th e computer . Kathy , HUFFMAN : Well, I think one of the problems 
today is tha t people are coming to computer graphics by prepared program s and they are bound by limitations 
of a prepackaged kind of paint by numbers kit . One of the reasons we installed an Appl e computer at 
the Long Beach Museum in 1980 when I was the curator there, was to allow artists to try to find some 
new ways . There were no other video studios in the country that had a graphics tablet and a computer 
and that was the only one w e could afford. With our Rockefeller grant . I think that coming from another 
medium such as vide o and then trying to incorporate computer graphics into tha t process, is a bit problematic 
because you are trying to make it satisfy the ends of another medium also that the actua l programming 
probabilities are limited with a lot of artists that they come without having the preparation . They 
are jus t taking prepared programs home . That is a problem why i t looks like something that is already 
in existence . A . I think that there is more to it than that . I think that mos t people that go into 
art ,when they are young anyway, go into i t with the love of the art that they see . Everybody essentially 
starts by reinventing the wheel. I think that is basic to the art process . Some of us never out grow 
it . I think you could say the same thing with the language . Language is structured . It is something 
we inherit . You don' t ask every writer to restructure the English language . Why as k that of vision 
. Visual art. During the era when everybody when everybody wa s beginning to take drugs, you always had 
students come around . They always had clone sat up all night eye, and had produce d this great work 
. It all ended up looking very much alike . When you asked for a kind of art that hasn't been seen before, 
I assume, I would guess that it will all look very much alike . There limitations that are built in, 
psychologically , mechanically, whatever else goes in making our hands work . There are only certain 
ways in which we work. Period . Q, I was wondering, because the technology that we are usin g today is 
so much different , A . It isn't Q. It is just the foresight that it is applied to, the creativit y 
that is being applied in the direction and focus . The direction I have seen at, the works in the gallery 
are of traditional values . I was just wondering the different directions . They had som e excitement 
going on in the early 60s . They had an art i n technologies at the L .A . County Museum . They had variou 
s other technology . . . . A . Just to take the matter of the edge, the frame that was brought up before 
. Until you design a different kind of TV se t or monitor screen you are not, you are going to be stuck 
wit h that edge and everybody who deals with that problem is goin g to have to work with that edge. That 
frame. How many different shapes can you come up with for a monitor screen? I mean just to talk about 
one aspect of the technology . SPENCER : Let's go one to another question . . . A . They go sideways, 
upside down, but you are still stuc k with some outside edge .  There has been some interesting projection 
. Use of projected video and projected images on . . . TO LOW TO TRANSCRIBE THE END OF COMMENT-- Q. Okay, 
two real quick questions. One to Mr. is Stot or Stapp? Mr. Stapp and one to Mr. Riley and the other curators 
. The first is from a historical point of view, thoug h photography might not, photography as a form 
may have been unprecedented . Some of the language cane from camera obscura . Today we have some artists 
cloing a kind of compute r obscura . Where they design on the system and then project o n to the canvas 
to paint. What do you see in that as a trencl both for curators who are worried about the artificiality 
or the non­originalness as it will of an object ? Second to Mr . Riley, in regarcls the concerns of th 
e museum breaking clown due to different systems of distribution . How have you looked at both telecommunication 
art as a for m within itself and the ability of the computer to send image s back and forth between other 
computers to be kind of a gallery out in n-space where you can down load whatever you want to see ? STAPP 
: Let me, a lot of the early language of photograph y actually was taken over from print making . That 
was simply a device to afford some means to comprehend and to describ e these objects that they were 
dealing with . They were ofte n produced on plates or on paper so there was a kind o f commonality between 
an earlier acceptable comprehensible system of image making. That was just a device of language. The 
second question is perhaps, it is not as terrifying a s you seem to think it might be . The end product 
that you r describing as a painting . The computer is one of the technique s that is used to create this 
painting . There is not a question o f originality at all involved. It is as an original, an object, 
the painting is an original an object as a photographic print is . They are both achieved through an 
instrument that i s essentially a machine . So what's the big deal? You have go t an original object 
. Does that answer your question ? A . So you ask me how I deal with telecommuications an d satellite 
links and this kind of global communication ? SPENCER : Go back to the microphone, please . Q . One, 
the when you said that you, one of the questions yo u posed was about people stopping to go, stopping 
going to th e museums and the museum no longer have original objects pe r say or they become a place 
where things are interactive . Where there is nothing designed or people go in . As it corollary o f 
that in terms of telecommunication art as an art form, one an d in terms in the breakdown of the museum 
of the theorize d breakdown of the museum . Being able to send images from home to home via phone lines 
through computers . How do yo u view that ? A . 1-low do I do it, right? There is a fax machine at th 
e office.How do I deal with it? Well, I have worked with a fe w artists that are involved with these 
esthesitzed structures o f telecommunications and sending images from point and point . My question with 
them ultimately is, what are you going t o  say. They say, Well we will do this, we'll do that, we'll 
do this. They design a really astounding system for the exchang e of information . But, I always ask 
"what is the information? " Many of these people ask don't have the area of thei r imerest go into that 
kind of a vision. Their interest isn't al l the telecommunications properties of that thing. I don't 
know what I am going to do about it . You know, this one of the reasons that the museum has entered, 
has chosen to enter itsel f in whole set of problems . I am looking for things . I am looking for proposals 
. I would love to see a telecommunications link that was say a t least as interesting as ???'?? and Good 
morning Mr . Orwell of a couple years ago and more . I am mumbling. I am getting reall y insecure and 
panic stricken . I don't know . Actually you can have that reaction to many things at thi s conference. 
You will just approach the situation, you wil l approach the dynamic, you will approach the phenomenon 
an d say "I don't know! " Q . The difference see between being able to send thing s through the fax is 
that the fax is definitely not an original . At this point the technology does not allow you to have 
th e resolution and frequently not even the color of the original image. The difference sending something 
from computer to computer is I am sending it if I sending from the kind o f computer that I have to the 
kind of computer that the othe r person has, then essentially it is the same image on th e medium . Well 
it is not even a photograph of the image that I mailed. How do you sec that as being different ? A . 
The phenomenon is exciting . What are you sending ? What is the image? What are you telling the receiver? 
How d o you feel as the sender? What do you, see the question I a m asking ? Q . What is the message 
in the museum? What is the messag e hung on the wall ? SPENCER : This could go on for about Q. A sympathetic 
comment for Mr. Stapp. Computer art is not photography . The difference lies in nature of how w e understand 
medium . The photographic medium began with amateur chemists. Smelly chemicals, breakable glass, and 
al l kinds of fun stuff for a few people .  As of this moment, I am pretty sure that to become a curator 
of photography it is not required to take courses i n chemistry. Computer art the medium is called software 
. The medium is called computer science which is a very comple x workable medium . Complex, by the way, 
computer scientist s feel they know exactly what the definition of complex is . They define the word 
. Workable means that those of that write software feel tha t we can get our hands on this thing . Like 
the smelly chemical s and the breakable glass in the early days of photography . But, of course, the 
complexity is what is the difference. The complexity of course is what offers the very wide open future 
for computer art . Photography, computer art is no t photography . STAPP : I am not suggesting that at 
all . In fact there is a break down in your analogy or your differentiation between th e two. In the 
beginnings, if anything photography was muc h more problematic and much more accidental than computer 
ar t is today. The early photographers were using processes that were completely unreliable and even 
if they made tw o photographs, let me finish, even if they made two images fro m the same batch of chemicals, 
one would come out and on e wouldn't. It was not understood . It was not a s programmatically systematized 
. But to me that is not really a relevant issue. A relevant issue is how you use the medium an d what 
you do with it and how well you understand it, or how wel l you use what you understand . Even if it 
is by the seat of th e pants . Photography until 1888 was done, everybody did it, b y the seat of their 
pants . It was all instinctually crafted . Each negative . Q . There is probable quite a few a folks 
in the audience tha t would like to speak with you sympathetically about th e concept of bugs and writing 
software and things not working , there is going to be a session later today . A . I don't doubt it. 
Things get screwed up even today whe n photography is so systematized that anybody with n o knowledge 
at all can walk into a camera store, pick up a book , and make photographs. Everything can go wrong . 
 That is exactly right . It was as vast as the medium of the common man. It very quickly became apparent 
that that wa s not in fact the case. It was much to difficult to work . SPENCER : If you want to debate 
this later Q . I can't let Miss Rainer get away with her remarks without a  response . SPENCER : Anything 
in particular?  Q . Yes, Ms . Rainer, I think that the art critics in this societ y are walls between 
the people and the media. I think that when art critics stand in the way that the artist should probably 
go straight to the people. My question to you is have you ever read The Fountain Head? SPENCER : Vivian, 
we have less then 10 minutes, give her a short answer, I know they want to hear this . RAINER : You are 
running short of time, do you want to ski p the whole thing ? SPENCER : No, not at all . We want you 
to go .  Q . I asked you if you ever read The Fountain Head and I made a commentary on the fact that 
art critics can stand in the way o f an art form becoming acceptable before these alleged lag times 
 which are probably created by the press . RAINER : If there wasn't somebody to stand in the way ou 
t there we would be mown clown in minutes, wouldn't we ? I would like to remind you that there have 
been art i n technology movements, two or three of them in this century and they never seem to last very 
long . I think the last one was Robert Rauschenberg in the 1960s and there was another one i n the 30s 
. I don't really worry about, I don't think the art critic has anything to do with it. I don't think 
it has any influence really. This is a force that is coming at us now which is probably irresistible. 
If we have any more publicity like we are having with this, who can stop computer art? I just hope that 
I don't have to review it, that's all . Q . I am going to send you a piece . SPENCER : Next question 
Q . I would just like to point out that a critical aspect o f computer and video media enables the perpetual 
archiving an d infinite and perfect reproduction of any kind of trash and that i s digital recording 
and reproduction . SPENCER : Thank you for pointing that out! Next question  A . Thank you for pointing 
that out . Next question ,  Q . My name is Herb Bazell, and I'm a professor o f compudesigns, and it's 
all our fault, you see, and it remains ou r fault. The fundamental problem is that the people who have 
th e most effective imaginations find it difficult if no t impossible at present to use the computer 
as an effectiv e media. I think Mr. Riley's reaction to the exhibits wa s perfectly appropriate . But 
I want to caution you . There are people in computer science who are attempting to overcom e  this 
difficulty . It may no longer be necessary in a while perhaps 25 years unfortunately for artists to 
learn how to program computers at all . RILEY : Because they're born programmed ? Q. No. RILEY : Why 
put so much between yourself and the en d product . Q . All they will have to do would be to interact 
in a ver y natural way perhaps even with speech in asking for wha t they would like to try and to interact 
with the result that come s out them and it will come out them in many forms no t necessarily on a T 
.V . screen . Perhaps on a sheet of paper which will look like an oil painting . Perhaps even with a 
rea l object. But that may be 50 years away that will be produced as a result of their interaction with 
a computer. You see, what is happening is that the gap between imagination and reality is going to be 
narrowed ver y sharply narrowed by the use of a computer . That is difficult to see today because we 
in computer science have been slow t o react to the needs of our artists and very quick to react to th 
e needs of business managers . RILEY : And how . Q. And how because that's where the money is . And 
I think your reaction to who funds what may slow rather tha n speed the ability of artists to use the 
computer as a much mor e effective tool . RILEY : You must be joking . A . No, I'm not at all . RILEY 
: That gap, by the way, strikes me as having bee n narrowed in television commercials notably in the 
California Raisins whom I'm a major fan and in a commercial that's been withdrawn now, that was absolutel 
y brilliant, and you couldn't have done it without a computer. It involved mustard I think, and a croissant 
was crossing its legs , so to speak, to avoid being penetrated by the wrong mustard . This was a work 
of genius . I'd like to know that artist . A. I want to avoid a debate. Just one comment. You see, it's 
the people with the imagination who should be driving th e investment of the money not the other way 
around . Q . There was a remark earlier about how old photographs tha t maybe were originally produced 
for a dollar or two are no w becoming priceless . I think that may in part be because of th e age. You 
take a look at a coffee cup that's got a few splashes o f paint in the shape of a dog, but it's been 
buried in the groun d for 2,000 years . Of course, it's valuable . So what happens 20 0 years clown the 
line when stuff that we consider horrendousl y primitive today suddenly becomes valuable simply because 
o f its antiquity, and how does that figure into it? A . I'm not sure it figures into it at all . The 
real question is i s it going to survive . That really isn't a question about compute r art; that's about 
market forces . Q . I'd like to thank Dorothy Spencer for organizing such a panel . I found it fascinating 
. I just have two brief comments . As an artist working with computers, I just think of th e computer 
as another tool amongst many other tools that I us e  which are paints, pastels, charcoals and I treat 
it as such . It is not a means in itself . It is a vehicle for me to express myself. And one of the greatest 
limitations that I find workin g on the computer right now are the quality of the output device s that 
are available to me. And I really would like to see outpu t devices which have a few people brought 
that up th e power to convey the sensuality and the touch that I have in m y own work on the final product 
. That's where I think one of the greatest areas of research will still remain to make that fina l product 
something closer to the artist, actual thought proces s and ideas and where that currently is . RAND 
: Dorothy, may I make a quick comment on that? Wha t you just described is exactly the problem that faced 
th e development of the piano, starting with a clavichord up to th e grand piano, how to communicate 
the touch . The history o f technology has many precedents dealing with that problem . It isn't new, 
but the solution isn't here yet . The previou s questioner asked about or mentioned the gap betwee n 
technology and something called reality . The latter I'm no t really familiar with . But I do know that 
technology will no t solve that problem . There will always be a gap -- thank Go d between imagination 
and reality . There'll just be differen t technological problems to overcome . SPENCER : We can only 
take these last three questions an d then I'm sorry . You can come up afterwards . But we have to shut 
the doors clown . Q . I'm Ken Musgrave from Yale University . I'm a compute r artist who sort of snuck 
up on art from behind throug h technology. I do have some training in the fine arts, but I'v e been 
out for a while . So I have a fairly simple question . What I do is I create fractal landscapes . So 
I sort of view my job as bringing back images, like a photographer and explorer fro m other worlds to 
show them to other people . And I try t o inject as much visual aesthetic value as I can into it . My 
question is just being far, far out of the mainst ream of art, how well accepted is photorealism today 
and how much of a n upstream battle is it going to be for me just to have my ar t viewed as art, rather 
than just as computer graphics ? A . How well accepted? What was the end of the sentence ? Q . How 
difficult is it going to be to have my images viewed as fine art, as opposed to just computer graphics, 
given tha t they're basically photo realistic art . A . Are you showing them in New Haven ? Q . 1'11 
be showing them in New York in the fall . You'll get a chance to review them . A . Well, I'll tell you, 
there is a practical problem and not s o much with computer art, but with video. I dread a group show 
that incorporates video movies because I can get around a grou p in an hour or so. Now I have to spend 
like two hours viewin g  time for video . This can be a problem . I don't know, but th e Museum of Modern 
Art is certainly doing something . I don' t see why it wouldn't be easier with video . Q. This is still 
photographs. I don't do animation. It's just like photographs that an explorer would bring back. A . 
Have you shown in New York? Q. Not yet. A . Who have you tried to show with?  Q . I'm taking a unique 
route since I'm assistant to Benoi t Mandelbrot . He controls my access to the media and is makin g sure 
that we'll have a grand entrance and all this stuff . So I don't have the typical route, but I'm interested 
 I just don' t know what is the place of photo realism . A . I would say that as long as the economy 
is continuing i n the present way, you should have no trouble at all . Of course ,  we get a crash and 
we're all out on the street selling apples . Then you may have a problem there . It depends on wealth 
 this medium, this new medium . Capital investment and th e computers . Q . I'm a computer animator 
and one of the problems that I face is that the media goes by so quickly . My question is is i t possible 
to do a five-second masterpiece ?  A. Yes, it is. This is our last question and we just have a minute; 
I'm sorry .  Q . I just wanted to thank the panel for their serious treatmen t of an issue that they 
know a lot about or they don't know a lo t about, and I was actually prompted to get up because I wa 
s embarrassed by some of the questions that I felt particularl y pertaining to the technique and that 
I felt lacked an insight fo r content which you were trying to get across, and 1 thought yo u did it 
very well and so thank you .  A . Thank you .  Thank all of you for coining . Thank you for participating 
. Thank everyone for coming. Thank the panel fo r participating, and we hope we've sort of answered som 
e questions . Thank you .  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>77289</article_id>
		<sort_key>223</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Bloopers, outtakes, and horror stories of SIGGRAPH films]]></title>
		<page_from>223</page_from>
		<page_to>239</page_to>
		<doi_number>10.1145/77276.77289</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=77289</url>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor>Arts, fine and performing**</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14093807</person_id>
				<author_profile_id><![CDATA[81100243559]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lasseter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pixar]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P26315</person_id>
				<author_profile_id><![CDATA[81100228727]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[B.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Reeves]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pixar]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31071674</person_id>
				<author_profile_id><![CDATA[81100040066]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[L.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Carpenter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pixar]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P73220</person_id>
				<author_profile_id><![CDATA[81332519767]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[E.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ostby]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pixar]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P184946</person_id>
				<author_profile_id><![CDATA[81365595781]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wahrman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[deGraf/Wahrman]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31072764</person_id>
				<author_profile_id><![CDATA[81100294395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Blinn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39082343</person_id>
				<author_profile_id><![CDATA[81100469355]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Reynolds]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Symbolics]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31099009</person_id>
				<author_profile_id><![CDATA[81332534588]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wedge]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Blue Sky Productions]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P92856</person_id>
				<author_profile_id><![CDATA[81100039181]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>9</seq_no>
				<first_name><![CDATA[G.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Walters]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pacific Data Images]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P25500</person_id>
				<author_profile_id><![CDATA[81100231657]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>10</seq_no>
				<first_name><![CDATA[B.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kroyer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Kroyer Films]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SIGGRAPH '89 PANEL PROCEEDING S Special Session Bloopers, Outtakes, and Horror Stories of SIGGRAPH 
Film s Co-Chairs : John Lasseter, Pixar Bill Reeves, Pixar Speakers: Loren Carpenter, Pixar Eben Ostby, 
Pixar Michael Wahrman, deGraf/Wahrman Jim Blinn, California Institute of Technology Craig Reynolds, Symbolics 
Chris Wedge, Blue Sky Production s Graham Walters, Pacific Data Images Bill Kroyer, Kroyer Film s John 
Lasseter &#38; Bill Reeve s Pixa r LASSETER : Were going to start about 24 seconds early . We've got 
really a full program here . We'd like to make one announcement first -- that there's absolutely no videotaping 
allowed in this session . If anybody sees someone videotaping next to him, they have the co-chair's permission 
to beat th e living daylights out of them . By the way, it won't matter . We have two gian t electromagnets 
just inside the door . When you leave we're going to turn them on . REEVES : John and I got this idea 
at last year's SIGGRAPH . You come to SIGGRAPH every year and go to the film show , and everything is 
so slick. It's just great most of the time. But behind the scenes there's a lot of effort, a lot of horror 
storie s and a lot of bloopers. We thought we'd have a session about that . LASSETER : Over the past 
few years at Pixar, Bill, Eben and I have started saving some of our more ridiculous mistakes, such as 
when the rendering just doesn't go quite right and the head i s about the size of a pin . We started 
saving those thinking tha t some clay we'd like to show them and so we're able to sho w them here . We 
told AV this is about bloopers, so if they screw up , then it's all part of the show . We left the form 
of this sessio n open so that if Bill and I heard of some more silly thing s occurring in films that 
were made this year, we would add them . Since the panel was formed we've added two more speakers and 
I think you'll really enjoy their stories . . We'd like to start with our first speaker . Put your hands 
together for a big SIGGRAPH welcome for Mr . Loren Carpenter of Pixar . Loren Carpente r Pixa r  I've 
been given the dubious honor of speaking first . I don't know what that means in this situation, but 
the first thin g we're going to do is show you a film, Vol Libre, I did about nine years ago . There 
is sound on this, but I don't want it very lou d because I'm going to talk over it . There are a couple 
of stories with this film . It was done o n evenings and weekends at Boeing on CAD equipment that we 
had, and it had absolutely nothing to do with my job . That' s why my boss has a credit on the film . 
The other thing abou t this film was that since it was done on evenings and weekends , I turned the machine 
loose and it would make a tape overnight . I would come in in the morning and I'd look at the frames 
in a frame buffer, and if they all looked okay -- and in fact, the y always did . There were never any 
bad frames in this thing --I don 't know why. Then the tape would get air freighted off to Minneapolis 
where they would put it on 16 millimeter film fo r me. At the end of the project, which took about a 
month or so , I got all these little pieces of film back that had been developed -- each on a different 
day, probably by a different lab, an d certainly with different chemicals . And so with the marvelou 
s help of Alpha Cine in Seattle, we spliced all these thing s together and their color timer did the 
job of his lifetime . All the pieces -- the work print that I saw, which was what we showed at SIGGRAPH 
as its premier, was the first time I had ever seen it run . This is a little cleaner print we shot at 
Pixa r sometime later . But it was just incredible, there were black ones, there were white ones, they 
were incredibly disjoin t pieces . Also, the other thing I wanted to say about this film is tha t the 
motion in this is all script driven. I had absolutely no motion preview hardware at all . This was just 
done fro m plotting on a piece of paper . Now the next thing on this tape is the Genesis sequence . Bill 
and I worked on the Genesis sequence for Lucasfilm, fo r Star Trek II, III and IV and probably V . They 
keep using it ove r and over again. I even saw it on the TV show . Anyway, I did the mountains and the 
atmosphere and par t of the stars and so on, and I'm going to buzz over some of thi s preliminary stuff 
here. But basically the project, as you can see here in wire-frame, was to show a dead planet coming 
to life . And we wanted to be as dramatic as we could, and I imagine we succeeded . But this was all 
done on a VAX 11/780 . But there were a few problems. Right here is where my geometry takes over, and 
we're bringing the mountains up . We didn't really know how long it was going to take to comput e this 
scene -- because these pictures have a variable amount o f detail in them. Sometimes when we're just 
back looking at th e mountain, it's like two minutes and down in the canyons her e it's like an hour. 
So what we did is we went through and, since it was supposed to be a simulation, we computed every 16t 
h SIGGRAPH '89, Boston, July 31 -August 4, 198 9 frame and that way if it took a year, well, we'd show 
every 32n d frame, and we'd call it a simulation . But it worked and it wa s fine . So we went back and 
did every eighth frame, and the n every fourth frame. After we finished that, they all looked fine , 
looked great . So we went back and did every frame, and that' s when we hit the mountain . Because at 
this point the camera i s descending as well as slowing down . So there was this big gray, solid frame 
. Now where did that come from? So what we had to do was put a clipping plane in the model and attach 
it to the camera, so it clipped the geometry as the camera flew . There was another little thing that 
was in here . The subdivision process to create the mountains took triangles an d if they were too big, 
it would break them up . Unfortunately, the process caused triangles to snap at a certain size, and thi 
s twinkling effect, which is hard to see in the video, but you ca n easily see it on the film -- caused 
this incredible crawl an d twinkling all over the frame . Everything else had been carefully anti-aliased 
and this was so aggravating . So we went back and discovered the proper solution, bu t we didn't have 
time to recompute it all . So we recomputed th e center 25% of the image, right where the eye is looking, 
an d substituted those pixels . And no one has ever complaine d about it. There is an island coming up 
here on the left. There it is in the lower left corner . And the video cuts it off . On the fil m frame 
it comes up and then it goes away. The reason that's happening is because all of the fractal geometry 
is defined on a sphere, at the North Pole of the planet, so that the subdivisio n goes in the Z direction 
; it's real easy . But the water is a bicubi c sphere, which is different from a true sphere . And the 
water i s attached to the camera. This difference of less than 1% between the real sphere and a bicubic 
sphere causes the water level to b e not quite a sphere and island to appear . You can see it in th e 
film some day . I'll just let this finish running so you can se e the rest of it . One more little thing 
we'd like to throw in . Coming into the lower left corner is the big dipper and there's an extra star 
i n it and that's the sun as seen from Epsilon htdi ; there it is in th e lower right, about 15 light 
years away . That's a t rue star field . Our next speaker is Jim Blinn, and I'm sure you ca n remember 
who he is . Jim Blin n California Institute of Technolog y I'm not entirely sure why I'm here, since 
I've really neve r made any major mistakes in any of the movies that I've done . At least not recently 
. The thing about the business that I'm primarily going t o show now is that the mistakes mostly happen 
when you're doing things with film . When you do things with video, an d there is a bad frame in the 
video, you just go through an d rerecord the bad frame . So it's kind of like a minor backspace character 
on your keyboard, and you don't think of it so muc h as a major mistake . But when you film something, 
and there's the bad frame, you've got to start over again and film the thin g from the beginning, which 
is a real pain . So for those of you who have never used film, I want t o give you an outline of what 
the filming process is -- at leas t what it was when I was doing it . It involves setting tip a camera 
on a tripod aimed at the screen of the tube, and you have to tur n off all the lights in the room to 
make sure you don't ge t reflections off the screen and so forth . The very first film I made and the 
very first film a lot o f people have made in the computer graphics business -- and this shows you how 
dedicated you have to be in order to make film s -- is to trip the shutter on the film camera manually, 
every time there's a frame on the screen . So you set up your program, yo u hit return to get the next 
frame, and then you click the shutte r with the other hand and you just go back and forth like this fo 
r about two hours, and hope you don't get out of phase . After a while we got the major advance of having 
a devic e that could trip the shutter via computer control . So I used tha t on the first Voyager fly-by 
animation back in 1979 . This was the first time we had used the camera, the first time we'd set th e 
thing up, and I had the thing set up in the dark room . I had t o load the film in the camera for the 
first time with all the light s off so that the film didn't get fogged, set up the camera on th e tripod, 
and it was about an eight-hour filming job because we had 12 tapes full of frames calculated . l would 
set the thing u p for one tape's worth which would take 45 minutes, and set u p three chairs and kind 
of take a nap while that's going on or jus t kind of lay down . It's a little bit difficult because all 
three o f those chairs were arm chairs . So I was kind of bent in an L shape with my rear end on one 
and the feet on one -- and sittin g there listening to this camera that I didn't know exactly how i t 
worked . So it would click the shutter and click the shutter an d then the sound would be a little different 
on this click, and I thought you know, is the film jamming or not . And you're biting your fingernails 
for eight hours while this happens . We went out and got the film developed and the exposur e was real 
crummy. It takes two days to get developed ; you don't know if it's good or not. So we went through, 
filmed the whole thing again, another eight-hour filming job, and it came ou t looking great. So NASA 
wanted to distribute this to the news media so they demanded that we send them the negative t o Washington 
so they could duplicate it, and they lost the negative. So I had to spend another eight hours filming 
i t again. That one we didn't send them . We sent them a copy o f the negative . The next main horror 
story has to do with the DN A sequence off of the cosmos project, which many of you migh t have seen. 
This was about 7,000 frames long and it was a n early example of multi-processing and doing animation 
. Basically we got six or eight PDP-1 Is scattered around in th e lab to calculate the frames . Each 
one would do frame number 200 to 220 and frame number 1500 to 1700 and so forth, an d we had to merge 
those all at the end onto a set of tapes sequentially ordered . And again, set up the film camera to 
ai m at the screen, filming the thing . This is another -- like a 12­ hour filming job . Sitting there 
kind of watching the screen with the lights off in the room. You have to be very paranoi d when you do 
this . Because if there's any mistake on the film , it's start all over again . Frames are coining up, 
frames are corning up . Somethin g in the next frame came up over here, and I was able to hit the control 
C interrupt just in time before it had clicked the shutter . I realized that I had 200 frames that had 
gotten the wrong data base . So while the film was in the camera I had to have th e thing recalculate 
those 200 frames, insert those onto the tape and resume. Fortunately I got it to happen right. So I didn' 
t have to do that completely over again . Now the sorts of mistakes that you make a lot with this ar 
e ones that are not obvious from looking at the individua l frames, as Loren sort of mentioned . You 
look at the individua l frames, you kind of preview them on the screen and they loo k okay, but then 
you discover there's some strange animatio n gliche where it jitters from frame to frame .  SIGGRAPH 
'89 PANEL PROCEEDING S I learned an important lesson from this film -- which is , when you have an animation 
rendering production system, d o not make it with interactive controls on it . One commo n thing, as 
Loren said, is you calculate the even numbered frame s first to see if they look okay, then you calculate 
the od d numbered frames in between -- right? This works great as lon g as you do nothing to the program 
in between doing those tw o sequences of frames . The nothing includes changing the input data . Well, 
I had this simple little molecule simulation to try out the blobb y molecule things, and set the thing 
up to do the even numbere d frames, and it worked neat. So I went through and clid the odd numbered frames 
. The thing is this particular molecul e simulation had interactive controls on it. The little knob box 
, for example, changed the rotation angle of the viewin g direction . So I nudged the rotation knob when 
I did the secon d number of frames, and so the thing starts out okay and then th e film starts jittering 
back and forth . This doesn't see m astoundingly amusing, but its a lesson to be learned . Another similar 
sort of thing is an interaction betwee n film and video that occurred in the Uranus fly-by movie a couple 
of years ago. At that point we had a video system an d we did everything on video. But for European television, 
its a different standard and so forth, and for a lot of news media, the y like it on film. There are 
mechanisms to transfer video to fil m and vice versa, but we weren't sure how well they'd work, so w 
e tried out a test. Basically all the animation I had clone up t o that point had been on film . This 
new animation is done i n video. So each of the two fields are identical -- 1/30th of a second, two fields, 
and then another frame of two fields and s o forth . When you do pans on video, fields seem to separate 
apart. It's a fairly commonly known phenomenon, so I did the pan part of it on fields, so that it would 
look like a smooth pan . But I wasn't sure how this would work on the film transfer, so I did a test 
of doing the pans with field animation and doing i t with frame animation and I didn't think the field 
animatio n would look right because when you transfer film to video you'r e going to wind up with two 
fields exposed on the same fil m frame. So you're going to see the interlacing on one frame of the film 
separated out . Sure enough, I got the test back, and one of the test s looked crummy and the other test 
looked good . So we went ou t and had 300 copies of this film made with the frame animation , and it 
turned out that was the one that was bad . So we had to junk all of those and come back and remake all 
300 copies . But the main interesting story which I have told to severa l people and actually dug up 
the film for was the famous Korea n janitor scene . We did a lot of animation off the picture syste m 
for Carl Sagan's Cosmos project, which was a black and white monitor and ran in more or less real time 
. But when we wer e filming it we had to do single framing . So again, we set up th e camera on the tripod 
in the dark room . By this time I coul d control the thing from across the hall, so I didn't have to 
be i n the dark room getting paranoid about the noise the camera wa s making . So I was controlling it 
from the other side. So I locked the door and put a little sign on the door saying, "D o Not Enter, Filming 
In Progress ." Fine. So we're filming alon g for about an hour and unfortunately I didn't realize that 
th e janitor we had in the building was Korean . He did not rea d English . So he came along and used 
his pass key to open u p the door, turn on the lights and started sweeping out the room . So what we've 
got is this really nifty stop frame animation o f the lights coming on, and the Korean janitor sweeping 
out th e room real fast . So let's roll the film . This is the jittery molecule thing , and in fact I 
think I snipped off the tail end of it when I firs t edited this together . But back in the days of film 
when yo u were projecting these things, you could blame some of thi s stuff on saying oh, the film was 
probably torn and it's jitterin g in the film gate . So that wasn't my fault after all . This is th e 
pan test . Let me focus that a little bit better . Basically wha t you're seeing here is one thing -- 
one version of it has field s which turns out to look better even though you have tw o different images 
on each film frame, because it gives yo u almost a sense of motion blur. This second version, however, 
alternates two images in one field frame and then one image o n each field frame . And this sequence 
out of the movie that w e copied kind of accentuates that even worse . Here we are. The janitor sequence. 
I'll warn you when it' s happening because it's very quick. It's just as the galaxy starts pulling back, 
look to the center and slightly to the right of th e frame, and you'll see the door open . Ready? Now 
. Our next speaker is Craig Reynolds . Craig Reynold s Symbolic s I've been interested for a long time 
in behaviora l animation -- animation involving characters that have som e amount of cont rol over their 
own actions . The only thing that I've clone along those lines so far is a model of flocks, where the 
individual birds are in charge of steering themselves around and acting like a member of the flock . 
It's a very nice property that an object will navigate around and have a little bit of common sense knowledge 
about the world so that it doesn' t pass through objects and things like that . But it raises th e distinct 
possibility of misbehavior. So I guess this talk i s about misbehavioral animation . In '86 I did some 
early tests on that and we 'll see some o f those and then in '87 we produced a film called Breaking 
the Ice and we'll show some bits from that . My credit on Breaking the Ice was for behavioral animation, 
but I preferred the Hollywoo d term which is wrangler . So I was the Boid Wrangler for thi s film . We're 
going to show some videotape here . This was one of the early tests -- actually a reshot of one of them 
from my paper in '87 about this stuff. I just wanted to show a vanilla flocking with the group just moving 
clown along a country road. Here we go. Well, this is not good. This was what it was supposed to look 
like. They're just flying around, a little bit of bouncing . This is actually a secon d version of it 
that I shot . I was running in the background . This is a nice multi-processing environment that I run 
it in, so I wa s editing my paper in the foreground and this was running in the background. Here, Larry 
Malone, our geometry guy, said that he had some new patches, So I loaded them and it turned out there 
wa s a bit of a problem in them .There was a small error in the patc h and it induced this sort of complicated 
behavior . This was a test -- early test -- of obstacle avoidance . The thing to watch is the last one 
in the group who gets a littl e confused by that last column . This was a test leading to Breaking the 
Ice, and there are sort of two things going wrong here . The clipping was suc h that when they got near 
the edge of the sphere, they wer e magically tcleported back to the center. It caused the rest of th 
e group to say -- "whoa!" Really, the behavioral character s deserve the credit .  SIGGRAPH '89, Boston, 
Jul 31 -August4,® This is a test of them wandering inside a spherica l constraint, sort of an early version 
of the concept for Breakin g the Ice, and this is the way it was sort of supposed to look. We were thinking 
about the possibility of putting the camera attached to one of the birds and from the outside it looked 
like a good idea, but the flight characteristics of these things are about like that of a jet fighter. 
They turn very fast. It's like every once in a while, you can see something that looks cool , but -- 
so we thought we'd use splines for the camera . There was an early version of the film prepared for the 
fil m show jury, which traditionally has nothing to do with the fina l film. Here's the look of some 
scenes from the opening of it . This is more or less what's supposed to be happening, but we'l l watch 
this scene as it progresses . Look at this pretty bizarre behavior here of these fish . There were start-up 
transients i n this model so what I ended up doing was sort of aging the flock so that they were straightened 
out. This character animation is by Philippe Bergeron . These are early tests of the final version . 
Towards the en d of this scene I'd like you to look at some birds that get stuc k next to columns up 
there ; they get wedged in between the columns . The fish that are closest to the viewpoint were splatting 
against the obstacles, and you see them ending u p vertical and horizontal . The problem was I wasn't 
using a physically-based model . So I had to add on more layers of cheating . At the top of this -- I 
don't know if it's obvious -- but som e of the birds are flying right through the columns, and you'l 
l also note this lightning effect . The problem with the column s was that there were two data bases 
-- a low detail data base to us e for the avoidance calculation, and another one used for the rendering, 
and it turned out that one was rotated and the other one wasn't. The lightning effect was an artifact 
of the fact tha t we were rendering this on many machines and so a little initialization bug becomes 
multiplied by as many machines a s you have . We've got sound here. This is an almost finished version 
. This is the Doc Bailey soundtrack . We were pretty tense at thi s point. The deadline was coming up 
and this soundtrack, thoug h it wasn't used in the final version, was a big help, because everybody cooled 
down a lot with this soundtrack . You know , we'd watch it and breathe deeply and everything was going 
t o be all right . So this is basically just a little more of the sam e scene that we saw before . These 
camera moves are by Larr y Malone, who did the additional animation . Philippe did the character stuff. 
Some outtakes from that period. Notice the fish in the background . Larry did this scene actually and 
apparently forgo t to put in the thing in the script that says make the flock move . So there's dead 
birds, dead fish . As Stan breaks through the ice, the thing to watch is the fish down below . It's a 
little hard to see when they're all there , but watch the couple in the background after the ice clears 
. You'll see that they're sort of randomly moving back and forth along their path. We'll look at that 
again. This only happened for Larry . It didn't happen for me . So I figured it was "operato r error" 
. This is the final scene in the film. This was kind of an after-the-fact motion test using high detail 
models . The ice i s broken, so the birds and fish, though they're out of the scene , they're supposed 
to come in and I wanted them to join togethe r and look friendly. So there's a parameter in the flocking 
model that's sort of how much separation they want to have, and I wanted to turn that down a little bit 
. Start it high and make it look like they were being buddies. It was basically that I was animating 
the thing which was supposed to be used t o interpolate the parameter. I used the interpolation contro 
l instead of the output of the interpolator . Anyway, this is Stell a and Stanley in stand-in form . 
So here come the fish up from th e bottom, birds down from the top. They get friendlier an d friendlier 
and real friendly . Then we'll just play through the way it finally came out. If you look closely, you'll 
see that some of the bloopers are stil l there. These guys are still clipping in the foreground . The 
birds are still stuck behind the columns . We did reshoot thos e flashing scenes, the flashing frames 
. I was assured that no on e would see those. So it worked until this panel . Just like Philippe was 
sure that no one would see the wing intersecting the ice there. So I'll point that out for him . Also, 
note the little rectangle on the side of Stanley' s head. That was some sort of attribute error. Actually, 
the staging of this scene was kind of a conceptual blooper . There was no good reason for him to still 
have his wings out, but th e way he was built he couldn't really fold them up . Whenever I see this, 
all I can imagine is Philipp e performing these facial expressions in front of a mirror an d then trying 
to transfer them onto the model . So if you thin k Stanley looks goofy doing that . And so they lived 
happily ever after . While we're playing the endless credits, I'll introduce our esteemed producer -- 
now of deGraf-Wahrman Productions --Mike Wahrman .  Mike Wahrma n deGraf-Wahrman Production s Thank 
you, Craig . It's a great honor to be here . I'm certainly very experienced at horror stories . My first 
horror story is today I previewed my tape in the speaker preview room and it looked fine and I came up 
here, an d we can't get vertical sync on it . So I am going to be playin g the tape from audio visual 
. I'm going to talk about the SIGGRAPH film, Stanley and Stella, and then a little bit about some live 
performance horro r stories that we've had . Stanley and Stella was a horror stor y from beginning to 
end. I'd like to talk a little bit about sin . In compute r animation the worst sin is the sin of indecision 
. If you don' t know what you're going to do, it's very, very hard to do it . The basic problem was that 
we were doing a marketin g film for Symbolics . We were going to show Craig's behaviora l animation, 
we were going to finally get into the film show a t SIGGRAPH, and we were going to help Symbolics sel 
l computers . Nothing the matter with any of that . However, on e of the original concepts for the ending 
of film involved grou p sex. The basic idea was that Stanley loved Stella, which is a pretty weird concept, 
if you think about it . This is a bird and a fish . What do a bird and fish have in common ? There's 
a lot of overlap between Craig's tape and my tape . These are original storyboards . The ice is broken 
and the fis h go behind panels to mess around. Stanley is heartbroken. Here they go behind the panels 
and all the little panels are going t o start twitching . Stanley is heart broken . Where is Stella? 
Ah , there she is . She's making little smooching noises . I didn't write this -- okay ? They join each 
other, they go off behind a panel . The panel starts twitching. Little spheres come up. Each of the little 
spheres become the one world -- the world we saw at th e beginning. This is the recursion ending, so 
popular i n  SIGGRAPH '89 PANEL PROCEEDING S computer animation -- popular only to people in compute 
r animation . The other possible ending was the toilet bowl ending . The basic idea is -- and we got 
into theater workshop here . What is their motivation? What does Stanley feel about Stella? On e possibility 
is he breaks the ice ; he dies . The other is he break s the ice, he keeps going, Stella looks at him 
going, he goes t o the bottom, he makes a little hole, the water starts swirling, it clumps into the 
void. Film's over . I don't have that on tap e today. The food chain ending I do have on tape . What 
do a bird and fish have in common? Well, birds ea t fish . But were very sensitive to issues of sexism 
. So perhap s the fish ought to eat the bird . We'll get into that . Then there' s the romantic ending 
; they fly off into the sunset -- you know , less interesting . Finally they love each other and the 
tw o worlds unite through the love of the main characters . I'll show the film . I've got some outtakes 
. Some of thes e you've seen before . Here's an outtake of Stanley expressing hi s lust. This is like 
a really good use of visual imagery. This got cut . You've seen this. Craig showed this to you. You can 
see the wild fish and this and that . Stella -- best animation in the film, unfortunately . Got cut when 
we rewrote it . He's broke n through the ice . He looks at her. No, she slaps the ice, okay . This is 
the other ending . It's not on the list, but we'll g o through this here . It's a tender moment in the 
film that didn' t get shown . He goes up, he breaks the ice, and then what's h e going to say to her? 
He's never talked to her before? What's o n Stanley's mind? Well, this is what Philippe Bergeron though 
t was on Stanley's mind . He gets close, there she is, he whisper s in her car -- she goes -- what! Take 
this ! This is the food chain ending. I think we can have th e sound up here ; there's good sound . She 
kisses . Suddenly he looks at her joyfully, jus t wonderfully. She smiles -- suddenly -- okay, we 've 
got instan t replay. Now this is really a problem . There's a lot of troubl e with these characters . 
There's a lot of trouble . Stella doesn' t have a mouth. Stella only has lips. So what she does is -­watch 
this; watch closely. It's very fast -- is her lips extend to grab him . This is animation by Philippe 
. It's nmy, idea . We have one more little shot of this . I just thought tha t the lips were so wonderful 
here that you should experience i t one more time. Here we go . At this point the ending becomes more 
developed . Basically we determine we are doing a nice love story and w e figure out how to make that 
happen and stage it . I think that the other horror story, I want to mention is th e last chance motion 
test. I don't know if you've noticed -- that was July I Oth . This is the state of the film 18 clays 
befor e opening . Of the six films in theatrical in 1987 five of the m were not delivered to Joan Collins 
in final form until two week s before the film show . All of them got delivered but ours . Five clays 
befo re the film show we delivered our final fihn . What Joan doesn't know to this day -- unless you 
tell her -- is tha t that wasn't the final film . We snuck in the final edit two days before the film 
show under the master one-inch . Someone in our crew -- who I will not embarrass -- though t voice effects 
would really help the understandability of th e film. So he directed the voice effects. Let's have the 
sound a little bit higher. Close your eyes and imagine what they'r e doing . It's wonderful, isn't it 
. So that's enough for Stanley and Stella . I think that th e point in all of this is here? A marketing 
film is not an art film . You have to decide what you're doing? Are you doing a marketing film? Are you 
doing an an film? Are you doing a cartoon? If it's a cartoon, it should be funny . Just think abou t 
it. It's a little deep, but there's some issues . Filmmaking is no t a theater workshop . If you're doing 
a film about th e Flintstones, we're not here to get in touch with our feeling s about Fred and Wilma 
. At some point you have to choose wha t shots are in the movie . I have to go now, I'd like to introduce 
John Lasseter, wh o will show a little film . Thank you . John Lassete r Pixa r This is one of the little 
special things that we have t o show . Everybody's familiar with the wonderful compute r graphics company 
called Pacific Data Images . They started i n 1982. Glen Entis, who unfortunately is not here (1 was 
goin g to surprise him with this), gave me this tape and he forgot h e gave it to me . It's six months 
after the company was forme d when the three partners were the only people there . One night every single 
computer they had was broken . The air conditioning in the computer room was about 8 9 degrees, and they 
had been up three days straight trying to ge t something done, and they were very frustrated . So what 
di d they do? They shot a tittle tour of PDI . --VIDEO TAPE TRANSCRIPTION (Voice of Glen Entis) You 
have all seen Tron. Some of the newer TV commercials . Seen some of the new pictures tha t are coming 
out on the covers of science magazines . You must think "Ha, this computer graphics is prett y easy stuff. 
Pretty easy to put out computer animation." Well, my name is Glen Entis at pretty dumb images and I am 
here to show you that it is no t as easy as it looks . This is where the decisions that have mad e computer 
graphics are made . The president's des k at the Pacific Data Images . Making computer graphics is not 
simple . It takes a lot of tools and a lot of ideas and a lot o f work . Some of the tools that it takes 
to make high ­quality computer graphics can be found right here o n this desk. For example, batteries. 
The high technology industry . Pencil and pen so that n o matter what form an idea takes the tools that 
write that idea down are available. We have got lots of paper and things for all kinds of ideas . Color 
folder s so that you don't loose track of things . The latest research is right there . System integration 
device : we don't like to have ideas in isolation . When the y need to be connected together we have 
got th e device to do it . Keys for all kinds of irnportant things . An adding machine for the highly 
mathematica l decisions . I thought that was smoke, sorry! As yo u can see it is all right here at my 
finger tips . Far from what the science magazines will hav e you believe, making computer graphics is 
more tha n a [natter of having high-quality pencils and staplers. There are other tool involved . As 
we take you on thi s walking tour through Pacific Data Images, I wil l introduce you to some of the other 
tools that we have . I would not pay any attention to the plants .      SIGGRAPH '89 PANEL PROCEEDING 
S So what are you doing this evening John ? This evening I am animating a scene from th e dream sequence 
. Which one is this one ? It is called DS-5 . Is it readily identifiable by those who have see n it . 
Yeah, there is a shot where Lumpy is jugglin g and looses the ball over his head and looks up . Then 
you come to a shot where Red slips out fro m underneath him and hits the ball back up in the air . Then 
you cut to this shot, which is DS-5, and he i s looking up, the ball comes in and he goes kind of like 
"what, what is going on . " So this is a rough level of detail of what th e figure looks like in wire 
frame ? Yeah, this is a rough level of detail . This is how I tested out the animation of the tag . That's 
great . So you can see how I got the movement of th e tag . Would you make movies of this, or would yo 
u just watch it ? No, I just would watch it . We had visitors walk i n once and I was staring at this 
thing like this . They said "John, are you busy?" Acting like I was crazy. So that's how you -- move 
it around and you sort o f study how it settles . That's how I got this rocking back and forth. I didn't 
think of that until I studied this action . How long did it take you to animate the 30 0 frame sequence 
we just saw ? That was about five days ; that was a little long . Five days? How many hours a day were 
yo u working ? Just a couple . How come your car has the best parking spot ? Because it hasn't moved 
in about three days ; I've been sleeping here . In the car? No, in my office . This is cool . This is 
3-D . This is a design for our poster . It's about to premiere i n Anaheim . What's Canada ? Canada is 
just an animation festival . France , forget it. 21st century, maybe. And then To B e Announced . Wasn't 
there a big controversy on the name o f the film? Desperately Seeking SIGGRAPH ? A Boy and his Unicycle 
. And Unicycle Jones and the Circus of Doom . You can see it rendering right now in here . This is actual 
speed ; this isn't touched up . Hey, cool . You can see him blinking . He doesn't have an y pupils . 
When he blinks his whole pupils go away . They just scale down . See, there's actually two channel processor 
s working at once here, and the bottom one's alread y finished and the top one's still working . So each 
of these frames take about five minutes to render or so . So, are you doing any tricks in this shot here 
? Is this just straight rendering or are you takin g advantage of something in order to redo this ? 
We may have to do a little bit of tricks her e because in some scenes the balls may intersect hi s nose 
or his head or his hands or come down in front of the hands . But that wouldn't be real life -- would 
it? I mean , if it hit his nose in real life, wouldn't it bounce off ? It would bounce off, but this 
is a drea m sequence, you see . That's the beauty of this story . It's a dream sequence, so we can get 
away with a lot . Everything intersects in people's dreams, don' t they? I just wanted to show you the 
machiner y because this building is not designed for machines -­for those people who think Pixar is this 
amazin g computer graphics company . You see, actually thi s was somebody's office and they kicked him 
out an d they put in all the machines. This was a picture system right here and this was a Pixar, this 
is Jab a and Robby . This is a CCI ; see all this gray stuff here? Well, they since have come up with 
this thing , which is exactly the same computer -- only it's tha t much smaller. Here's the air conditioner 
. See, the cold ai r comes out of there and the hot air goes up into th e attic. They wouldn't let us 
cut a hole in the roof, so we just shoot it up in the attic . We forget about it . Our upstairs neighbors 
are really -- it's a tannin g booth. So it works out great. They really like it. I could have had a career 
in orthodontistry, but I just had to get into animation production -- what a mistake . END OF VIDEO TRANSCRIPTION 
Thank you . Our last speaker is Bill Reeves . Bill Reeve s Pixa r My first blooper was in the first 
film I ever worked on : Th e Genesis Effect that Loren talked about . I did the fire sequence i n Genesis 
and that was done with particle systems, all sorts o f hackery going on. So I had some fun with that, 
and there wer e lots of random numbers in this thing . Anyway, there were essentially two sequences in 
the film . There is the early fire and the late fire, if you will . Like everybody, you want this thing 
to compute as fast as possible . So I made a last minute change which was to fix the rando m number generators, 
to go from -- I can't remember what it was . Probably go from a function to a table or something like 
that . It probably gained me 2%, but what it lost was all sense o f frame-to-frame coherence, if you 
will, for the particles . So let' s just -- hopefully I've got it queued up here on the video . An d 
you can see that the first part of the fire is nice ; trajectorie s follow, and the particles actually 
move through space and d o what I wanted and give you a nice feeling for what was supposed to be fire 
. It doesn't look like fire any more to me, but yo u know, it was a good effect in any case . So when 
it comes over the limb here, if you look closely , it's just mush. It uses different random numbers every 
frame. It just doesn't work . It just didn't quite get it . Actually, we   SIGGRAPH '89 PANEL PROCEEDING 
S frames per second mode and John animated the thing an d previewed it all at 30 frames per second . 
And we rendered the whole thing. Both eyes -- you know, it's a stereo film. I'm working on knickknack, 
doing some pencil tests, and I look over at the monitor and I say oh, wow, it's not doing 3/ 2 pulldowns, 
going from 24 to 30, and I sort of go "whammo!" I t was three or four weeks where this system, if you 
will, wa s stuck at 30 frames per second. We re-rendered the whole thing . It's one of those times when 
you wish you had got it right th e first time . A little bit about what it's like doing a film production 
. First of all, there's long hours, which I think John and Eben di d a good job covering . You learn 
what caffeine's all about if you're into that, or at least you find something that can make you last 
the long hours . Your home life becomes non-existen t almost, and you get into all sorts of problems 
about that. Is it raining outside? Is it sunny outside? You don't even know . One good thing about it 
though is you get to see Davi d Letterman every night . Then there's the issue of what the production 
room look s like. Here are some examples. This is only the tip of the iceberg, as they say . I mean, 
odors of all kinds, thing s growing here and there . Our janitors got so scared of the room they wouldn't 
clea n it. For six months, this room just never got cleaned -- and o f course, we're so busy we would 
never clean it up . Your des k begins to look like this and then the worst thing is people come around 
for tours and you just want to kill them . An d dietary habits . I mean, it's just beyond belief what 
you ' l l actually eat during production . Here's another caffeine slide, o f course . You've also got 
these production meetings where -- John' s tape sort of showed it well -- but another great line was 
: "You typed rm * in what directory?" I'll never forget that one . Needless to say, some heated discussions 
. In any case, you go through hell . I mean, it really is . Yo u do it for SIGGRAPH films and you do 
it for commercial thing s as well, but why do you -- I mean, we don't make money on th e SIGGRAPH films. 
It's good for PR and stuff like that, but wh y do you do it? Well, sometimes good things happen like 
an Academ y Award . But beyond that -- and that only happens every once i n a while, of course -- once 
in a lifetime type thing . But there is a real thrill. And I think the panel will attest to this. There 
is an enormous thrill of seeing your work up on the screen, bein g part of the film show, then the films 
get out to other places , and it 's just a real thrill for everybody to see them . It's a lov e that 
we all have and it's so hard to explain to your wife, to you r mother, to -- I probably don't have to 
explain it to many of yo u in the audience, so maybe that goes without saying . The other thing that 
I really love about this is the tea m work that is involved . You work with people and you begin t o 
love them as family almost, and it really is a great comin g together of minds . You really feel good 
about it when you'r e done, and it's just great. So, there you go. That's all I wanted to say . Thanks 
for coming. We hope you had a good time . Thanks to all the panel members . May you never bloop again 
.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>77290</article_id>
		<sort_key>241</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[Future directions in desktop video]]></title>
		<page_from>241</page_from>
		<page_to>255</page_to>
		<doi_number>10.1145/77276.77290</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=77290</url>
		<abstract>
			<par><![CDATA[<p>Good morning. My name is Tim Heidmann and I'd like to welcomeyou all to this panel, which is entitled Future Directions inDesktop Video, and I'd especially like to thank all you people whostayed up a little late on Thursday night to come to this panel.It's really good to see you all out there.</p><p>I've gotten word that this panel is being transcribed. They'reputting together a booklet, so they're taking the slides and thestills from the videos and all the things that we're saying. So I'djust like to take this opportunity to say hi to the person who'stranscribing this and sorry you couldn't be here today, and Iwanted to let you know that the word of the day is Neopraseodymium,and I hope you've got your scientific dictionary close by.</p><p>When we first started putting this panel together, I talked tomy friends who were involved in a number of different areas invideo, and the question that came to the forefront very quickly iswhat exactly desktop video is. There's been a lot of talk about it,a lot of magazine articles. It's a good buzz word. But we all feltit incorporated a whole bunch of different areas that weren'teasily put into one category.</p><p>We did agree that the name of desktop video came from the fieldof desktop publishing. In desktop publishing, which has been arapidly growing field in the past few years, the whole point isthat we've got a computer bringing together elements from theoutside world, creating elements inside the computer, putting themall together and coming up with a final product. The point is it'sall done inside the computer. Again, it does the things thatcomputers do really well -- like text editing and graphics designand layout. And it was made possible by the fact that these highquality printers -- laser printers -- had come out that you couldproduce a very high quality output from it.</p><p>Well, on the video side, there is a similar development. Thatis, it's possible now to make video animation completely within thecomputer. There are software packages for modeling objects, forcreating animation, for rendering very high quality images andoutputting them directly to tape. And I guess you could call thatdesktop video. You're doing the same thing as you're doing indesktop publishing, but now you're producing videotape andanimation.</p><p>But really what's happening in video is a lot bigger than that.I've kind of come up with this map. If you look at the entire videoprocess, you can split it into four parts. The first being creatingthe elements, which I've called Source here. Now that would includesuch applications as computer graphics, generated completely insidethe computer, but also things like pointing a camera at someone orsomething, things like medical imaging. Basically the creation ofthe images.</p><p>The second step would be assembling those images and probablysome audio into a master video production. Just about everythingyou do in video involves some sort editing to it, even if it's justputting a title on the beginning.</p><p>The third area is the distribution. How do these images get outto the outside world? A lot of times it's just making lots of VHScopies and mailing them to your friends.</p><p>And the final part is how do you look at this videotape? How doyou use video in your application?</p><p>What we're going to talk about today, when we talk about desktopvideo, is actually all these areas. The speakers today have anumber of different backgrounds. We'll be addressing this in anumber of different ways.</p><p>Basically the reason we're doing this panel today and why it'simportant now is because there are a lot of developments that arebringing video into the reach of more application areas. People areinterested in what can be done with video, want to know what'shappening and what the developments are. Specifically the thingsthat we're seeing are the appearance of higher quality consumerformats. That is, videotape recorders, players, that are availableat consumer affordable prices, but give you enough quality to letyou duplicate and edit a little better than VHS or just plain 8millimeter.</p><p>Computer graphics hardware and software is becoming lessexpensive and more accessible. The fact that you can buy editingequipment for these new consumer formats and do a really good jobof putting together a final videotape without going to apostproduction house. New distribution methods and integrated videoapplications like DVI, which allow much broader use of video. Sothere's more incentive to produce these things.</p><p>These are the areas we're going to be talking about today, andjust keep in mind this map, and I think if we can reference thedifferent things we'll be talking about to this map, maybe it willall make sense.</p><p>I'd like to introduce the first speaker today who is MichaelMacKay, currently of the Sony Advanced Video Technology Center,formerly of Diaquest; before that with Atari Research. Michaelbrings a strong background in computer graphics, in videoproduction, interactive video applications, and without furtheradieu, Michael.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Vector display devices**</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Application packages</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P274663</person_id>
				<author_profile_id><![CDATA[81100350987]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Heidmnn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P181285</person_id>
				<author_profile_id><![CDATA[81100236414]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[MacKay]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sony]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P90930</person_id>
				<author_profile_id><![CDATA[81332513933]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[G.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[MacNicol]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics World]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P83075</person_id>
				<author_profile_id><![CDATA[81332536272]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[F.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wray]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[BYTE-by-BYTE]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
       Corporation, which manufactures the Sculpt 4D package for th e Amiga and now the Macintosh 
. Floyd . Floyd Wra y BYTE-by-BYTE Corporation Good morning . Since Tim, Michael and Greg and I firs 
t got together to plan our attack, two things have become clear. First, that this panel was going to 
take place entirely too earl y on a Friday morning, and second, in spite of that fact, I have looked 
forward to what they had to say on the subject . I knew i t would be enjoyable and informative -- at 
least right up to thi s point, right here, where it became my turn to talk . This has to be the worst 
part of my clay . In some ways m y angle on the subject almost comes in as a summary for what ha s been 
said, and it's not an obvious summary at all because i t deals with how to go about buying desktop gear 
. Most of us will probably make a desktop purchase in the not-too-distant future if we haven't already 
. What do you bu y first and why? How do you model the future of desktop video as it relates to purchasing 
? Now if those questions aren't tough enough, how do yo u further explain obsolescence upon purchase 
to a banker? For a s you know, the minute you invest in desktop technology, yo u just bought an antique 
. As has been said, one of the first thing s that comes to mind when you mention desktop anything i s 
desktop publishing . Unfortunately, a pretty good argumen t could be made that desktop publishing was 
an accident -- like Columbus, who accidentally discovered the Americas . Computer manufacturers charted 
a course toward case of use an d power and ended up discovering desktop publishing enroute . And here 
is the distinction . With desktop publishing we discovered the capabilit y first. Then we named it. With 
desktop video, in the gran d tradition of American marketeering, we discovered the name first. As a result, 
desktop video tends to be in the words of St . Paul -- all things to all men . A first order of business 
involves defining the subject . Notice how that theme keeps coming up . What is deskto p video? Now your 
definition might be based on cost, hardwar e configuration, software . The point is, without some dee 
p introspection at the definition end of this subject, it i s impossible to make an intelligent purchase 
. I have a weir d metaphor in this regard . Imagine two kingdoms residing ato p two made-in-one-hour 
toxic green 3-D mountains . In th e resulting valley these two kingdoms share a vast technologica l border. 
On one side is the Kingdom of Video, populated by a sturdy race. Perhaps we should point out that the 
inhabitant s here are largely analog in nature . On the other is the Kingdom of the Computer, populate 
d by an equally competent race, full of answers, restless , innovative, and by contrast, incredibly digital. 
Now depending upon your degree of cynicism, desktop video i s either the land bridge between these two 
kingdoms or th e landfill . And that gives us a pretty good perspective . The technology being tossed 
into this gap by companies on bot h sides of the boundary -- with this simple metaphor of tw o kingdoms 
we have the basis for a purchasing strategy . The next question is equally basic . What is the chie f 
enterprise in desktop video? Desktop video deals ultimately i n what might be called audiovisual sentencing 
. On th e videographer side of the gene pool, we use cameras to tra p bulky visual sentences . Once we've 
stored them on tape, we SIGGRAPH '89 PANEL PROCEEDING S send these sentences to a fat farm, also known 
as the edit suite , where we trim them and edit them together . On the other side of the gene pool the 
computerists tend to author visual sentences . Where the camera traps images , computers are used to 
construct them . The video desktop i s thus involved in two things -- the enterprise of audiovisua l 
trapping, and the enterprise of audiovisual authoring. All desktop gear can be lumped into one category 
or the other. After the problem of basic definition, one of the toughes t issues regards where to go 
for purchasing counsel. Now videographers can give you pointers on formats and syn c configurations . 
Computerists of course can explain the CP U and frame buffers and criteria for good software . Chances 
are though most desktop video buyers are looking for technolog y that exists along the outside edge of 
either specialty, and if yo u probe either side in an effort to stimulate a little wisdom on th e subject, 
you'll also most likely hear faint traces of good ol d fashioned technological racism . For example, 
I'm going to do a little characterization. If you crept over the border and listened to videographers 
around the campfire at night you might hear something like this : Computer weenies honestly think they're 
going to change th e world with two super VHS machines -- not even three-quarter -­and $50,000 editing 
software . Someone ought to take a missionary journey over there and help them drag thei r production 
values out of the mud . Computerists of course can also demonstrate their own version of bigotry . Around 
thei r campfires you hear: All a video weenie thinks about are character generators and flying logos 
. Ha, ha, ha. When th e day of digital fully dawns, we will blow them to the other sid e of the universe 
. Hold onto your Old World shabby NTSC pants, folks; help is on the way . (Applause) I've heard this 
pretty much. This duality is critical to you r purchase because both sides have information you need. 
They also may have some misinformation . You are the one wh o makes the call based upon exactly what 
you expect from you r desktop . So solid definition of desktop video according t o your own expectation 
is a first order of business . Second, it' s important to generate an equipment list based on as muc 
h information as you can dig up . And third, we must deal with those dark and wonderful prophecies of 
the future -- thos e technologies that bear upon our decision-making becaus e they're just around the 
corner. And that takes us back to that earlier issue of obsolescence . All too often some of us get so 
hamstrung in informatio n gathering and what's just around the corner, that we end up a t the polar extreme 
-- not doing anything in the present . I guess this points up one of the few known quantities o n the 
subject. Desktop videographers are spending their ow n money and maybe this is a powerful clue for our 
ongoin g definition. Maybe we should try to ignore describing deskto p video in terms of price and power 
. Maybe desktop video reall y should be -- as has been said -- mostly defined as an enterpris e of the 
individual. We may also discover that desktop video is not as much technology as it is human passion 
-- driving u s forward to a new form of literacy . Now in my own notion of the future, I see emerging 
3-D technologies as vital to any purchase . With this in mind, I want to show three animations. Unlike 
demos produced in a huge production setting, each animation here was animated b y small team -- one or 
two people at the most -- on PCs . VIDEOTAPE PLAYING FUTURE DIRECTIONS IN DESKTOP VIDEO SIGGRAPH '89, 
Roston, July 31 -August 4, 1989 But at SIGGRAPH we expect high resolutions. High resolutions. That's 
how it should be. But there's anothe r resolution we should be concerned with -- individual resolution 
. I don't believe that desktop video is the frail brother of deskto p publishing . Every desktop computer 
consumed with wor d processing today is a potential site for tomorrow's audiovisua l authoring. With 
so much happening, with so much change , how do you plot a course? How do you resolve your fina l purchase 
dilemma in the face of obsolescence ? Well, if desktop video truly is an enterprise of the individual, 
then obsolescence may be an appropriate description for those of us who never get involved for the fea 
r of investing in the wrong thing . As it turns out, deskto p videographers are not investing in technology 
. Desktop videographers are investing in themselves . They buy, they close their eyes to new stuff that 
comes out the next day, and they content themselves to produce with the hardware that the y have . Now, 
they may eventually suffer an attack of pride as they work with their antiques, their old cows, but they 
learn . The y learn to milk those old cows until they're dry. Crackfish was assembled on a Sony 5850, 
which I bought in 1985 . It wasn' t Betacam SP or D I or D2 or even three-quarter SP . I love my ol d 
cow . Let us rewrite our understanding of what's actuall y happening here . Desktop video could probably 
be achieve d with a $200 Gold Tongue VHS machine from Taiwan and a UH F transmission . The point is after 
you have achieved a bit o f clarity and spent an appropriate time researching equipment -­jump in . When 
it comes to your future desktop purchase, do no t fear most the buying . Fear most the not doing . Thank 
you .  Moderato r Tim Heidman n Silicon Graphic s We're going to try and go to these microphones . 
Am I audible? We've got a few minutes to do some questions an d answers. We've got microphones set up 
around the hall. If you'd like to bring up a point, contradict anybody, please jus t step to a microphone 
and make yourself known. Q . You were talking about the different types of equipmen t that might be needed 
to take a computer signal and put it on videotape . Do all of the PCs that we were looking at -- we wer 
e looking at Silicon Graphics equipment, we were looking at th e Amiga, I think we were looking at like 
IBMs or something lik e that. Do they all have that same type of problem? Are there any computers that 
it's less of hurdle by the nature of the desig n of the computer, or is it just the same standard problem 
wit h each of those computers ? HEIDMANN : Everybody stinks. Do you have anything to say, Michael on 
that ? MacKAY: Yes, I've actually had quite a bit of experience being the one that has to come in the 
room and make this thin g go on the tape . So basically the main problem is that vide o has a very defined 
specification -- defined by the EIA --Electronic Industries Association . We've entered into a worl d 
where everybody wants to do single frame editing and this put s even tighter constraints on there . Companies 
like Silico n Graphics have done a good job of allowing you to go int o NTSC mode. The only problem is 
you can't see your other monitor. So it makes it hard to get back to UNIX . Computer s like the Amiga, 
they have RS 170A style -- actually RS 170 -­style video outputs, and they actually work quite well, 
and if you find in the PCs and Macintosh style platforms that actually have display adapters that can 
be added in after the fact, if yo u do some homework and actually find some stuff, there's a lot o f 
products that are very high quality, that by choosing th e correct display adapter can produce very high 
quality video . Then it's just more of decisions about dealing wit h synchronization, like Greg pointed 
out, and being able t o genlock that . So depending on your application, I'd say g o with the computing 
platform that has the most flexibility in choosing display adapters . You cannot record VGA cards an 
d you cannot record 1125 60 displays, like the 1280 by 1024 -­60 hertz stuff that's the typical console 
on a high en d workstation. But there are a lot of cards and I'm not going to try and name people right 
now . But if you do some research , and I'd be glad to give you a list of some of these things after 
. HEIDMANN : So, no easy answers . One good idea is always i f you're thinking about some hardware, find 
somebody who' s using it, somebody hopefully who's doing the same sort o f thing you hope to do, and 
talk with them . Because you'r e going to find troubles doing something with everything . So just pick 
the piece of equipment that is at least you know i s good for doing what you want to do . Yes . Q . I 
had a question for Michael . You mentioned the high ban d 8 millimeter . I'm not familiar with that term 
. I have a Son y CCD V9 8 millimeter camera ; it's a great camera . I love it . Is the high band tapes 
-- can they be used in that camera? An d how is the high band different from a regular 8 millimete r 
format? MacKAY : What goes on is that there are incrementa l improvements in technologies that have come 
about -- mostl y actually from tape formulations is what we're seeing right now ­ -where now they're 
actually using some of the techniques use d to manufacture semi conductors in the manufacturing o f videotapes 
. So what we're getting is tapes with higher coercivities, and without going into all the terms about 
th e manufacturing of tape, it allows you to do higher bandwidt h recording. So what we're doing is we're 
pushing up the carrie r frequencies in these decks . U-matics have taken a step forward , and there is 
now what's called U-matic SP, which is calle d Sony's Superior Performance SP U-matic, and basically 
tha t same technology has been applied to the Betacam line and i s being applied to now the 8 millimeter 
line. I own a V9 myself . They're all upward compatible . In other words, if you buy an S P three-quarter 
inch or a high band 8 millimeter or even the stil l image stuff, the older medium will stay play in it 
. You won't take advantage of the format . But basically high band 8 millimeter is over 400 lines . Sony 
is also very conservative on their specifications, and it has a great improvement i n chrominance signal 
to noise ratio, with the difference being i n S-VHS they have not macle any of these improvements in 
th e chrominance area . They have all been in the luminance area , and we like color pictures . So you 
need both . MacNICOL: I'd like just to add that while a lot of these formats are really good, the key 
element in creating a system i s integration . For instance, while high-band 8 is very hig h quality, 
you have to look at what interface controllers wil l work with it, and also which ones will work with 
frame accuracy . For instance, VHS, which is good -- S-VHS, which i s better -- in spite of its qualities, 
sometimes has difficult y getting still frame accuracy. So if you create an animation with that, occasionally 
you'll have a frame that's missing or a fram e that's extra . This is the reason why if you are creating 
a lo w  FUTURE DIRECTIONS IN DESKTOP VIDEO cost animation, you really have to look at the issue o f 
compatibility . HEIDM ANN : We have a question over on my left . Q . I wanted to thank the speakers 
for a great set of talks . Then I wanted to point out an area that they hadn't discussed . One of the 
phenomenon in computer use today is the use o f computers for interpersonal communication online, and 
n o one's mentioned the possibilities for video enhancing tha t interpersonal communication . HEIDMANN 
: Certainly a big application area which w e haven't talked about much, which I guess falls into th e 
distribution and viewing area. Again, the hardware manufacturers, what hooks are we making to make that 
easy t o get video on a computer screen -- if that's the way you want t o do it. And how do you make 
effective use of that in software, s o that you're not just setting up a camera and running a cord ove 
r to a monitor and then setting up a camera and running a cord over to the monitor . So the writing, 
coding and compressio n make use of that . There is a lot of stuff we didn't cover today -­in case anyone 
was wondering. Yes. Q . As we have learned with film, tape doesn't last very long . Is there a way to 
preserve a final product so that we can see i t 10, 20, 30 years from now ? HEIDMANN : Anyone volunteer 
to answer that ? MacKAY : Basically what you do is you rerecord tape s periodically -- anybody that's 
dealing with the large archivin g things. And if you have the need to archive something over that period 
of time, then you really need to preserve a digita l archive of the original byte maps of the renderers 
in som e format. There has been a lot of third party development using 8 millimeter as a terabyte storage 
medium, and being able to us e mass quantities of staff. Don't tell anybody, but were t rying to develop 
-- I have a proposal on the table right now to do a hybrid 8 millimeter deck that's also a st reaming 
tape drive and a single frame editable animation controller -- all in the sam e thing . HEIDMANN : There's 
a question in that corner , Q . I'd just like to describe a situation that we're working i n and see 
if you know people that are working on it or if you are . We built a digital video studio in CBC in Toronto 
and fro m what I've seen here, in a sense you are talking about simulatin g what already people do in 
Videoland -- basically Analoglan d that's becoming more digital . But from a production point o f view, 
I'm wondering if people are working on how you prepar e for complex productions because what we see on 
the floor wit h desktop video is basically simulating what an operato r doe s when they're editing. But 
when you're dealing with complex ideas -- for example, in a documentary . You want to go into a postproduction 
suite where you have mega layers of materials -­all with different virtual points of view, all with different 
kind s of timing on them . There is no way that you can pre-view tha t now. You're working with paper 
scripts and awkward stor y boards. And I haven't seen anything in effect. Computer supports the intellectual 
production part of the production , rather than just the technical part of how you plug in machines , 
as digital and video get together . I think that's really where w e talk about what we're actually saying 
with the images -­whether they're generated or whether they're captured . There's a language that's been 
developed in the images . And if we don' t look at that issue as we move into the computer world, we 
won' t have those tools either . HEIDMANN : Greg, slid you want to say something? MacNICOL : That's a 
really good point. That really i s excellent. Recently I wrote an article just focusing on that SIGGRAPH 
'89 PANEL PROCEEDINGS issue . When I wrote the article it was -- typically there's abou t a two to three 
month lead time, and by the time I had the articl e out, everything was completely different. I focused 
on about two companies focusing on that issue -- editing, video editing . And at the moment there are 
about at least five companies -- an d I know about five other companies -- that are developing ver y 
powerful and complex video editors . The wonderful feature about these is that instead o f requiring 
about a week of training on a very advanced vide o editing system, it's much easier to use, and it's 
based not o n rows and rows of numbers and time code, but pictures -- the cut in and the cut out point 
. So this is a very serious issue and thi s is also how all low cost systems -- in fact, we're seeing 
now o n low cost Amigas and of course on Macs -- we're seeing these systems being used to replace $100,000 
editors . Now these systems aren't complete yet. Some of these systems are not frame accurate ; some 
of them are close to three or four frames , which for a professional studio is not goocl enough -- an 
d especially for computer animation -- is not good enough . But I think in the next year we're going 
to see some very impressiv e developments . HEIDMANN : Thank you . Unfortunately, I've been told we'v 
e run over time and we won't be able to take any more question s in this forum . We have to end the panel 
. But the panelists wil l be staying around. If you do have some more questions you' d like to follow 
up on, please come on up . We can continue thi s out in the hall perhaps . Thank you very much for your 
attendance . FUTURE DIRECTIONS IN DESKTOP VIDEO 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>77291</article_id>
		<sort_key>257</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Distributed graphics: where to draw the lines?]]></title>
		<page_from>257</page_from>
		<page_to>280</page_to>
		<doi_number>10.1145/77276.77291</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=77291</url>
		<abstract>
			<par><![CDATA[<p>Good morning, ladies and gentlemen. Welcome to the panelentitled Distributed Graphics: Where to Draw the Lines?</p><p>My name is Dick Phillips. I'm from Los Alamos NationalLaboratory and I'll be your chair this session. I'll be joined by agreat group of panelists --- friends and colleagues all.</p><p>Our second speaker following me will be Michael Pique fromScripps Clinic. Following him will be Cleve Moler from ArdentComputer. After Cleve we'll hear from Jay Torborg who is associatedwith Alliant Computer. And batting in the clean-up position isgoing to be Don Greenberg from Cornell University.</p><p>I have to give you one administrative announcement. You probablyknow this by now if you've been attending panel sessions all week.But once again, these proceedings are being audio taped forsubsequent transcription and publication. That means that when weopen up the session for question and answer, which will be inanother 30 or 40 minutes, if you would like to ask a question, youmust come to one of the microphones that's situated in the aisles.They are just about in every aisle, part way back and close to thefront. And to be recognized, please state your name andaffiliation, and I'll remind you of that when we get into thequestion and answer session.</p><p>The title of our panel begs a question --- where to draw thelines. Well, the trivial answer to that question is obviously onthe display that you have available. The real implication of thattitle was where to draw the lines of demarcation for graphicsprocessing. You're going to hear from me and from my otherpanelists several different points of view. Just when you thoughteverything was settling down and it was clear that all graphicsprocessing was moving out to workstations or graphicsupercomputers, you're going to hear at least two different pointsof view that may sound a bit nostalgic.</p><p>Let me take you back in time just a bit, and this is a greatlyoversimplified graphics time line --- where we have been and wherewe are and where we're going in the evolution of visualizationcapability.</p><p>I'm not going to dwell too much on the part of this time line tothe left. We're really interested in what's up at the right handside. But I can't resist pointing out that back in the days which Ihave labeled pre-history here, a lot of us can remember gettingexcited about seeing output in the form of a printer plot, thinkingthat we were doing visualization and that that was really computergraphics. And I for one can remember the first time I had 300 bandavailable to me on a storage tube terminal and I thought this isblazing speed. I cannot believe what kind of graphics capability Ihave got now.</p><p>Where things really get interesting though, if you move alongthat time line to the right, up into the mid 1980s, I have put someI think seminal events on there --- Silicon Graphics introducingthe geometry engine in the workstation. Well, workstations ingeneral. That was a real watershed event that has changed the waythat we do graphics and where we do graphics considerably.</p><p>Then as we move into the later part of the 1980s, I have notedthe appearance of graphics accelerators for workstations. These arespecialized plug-in boards that have all of the graphics featureslike Phong shading and high speed transformations built into them.Graphic supercomputers like Ardent and Stellar and HP/Apollo haveappeared in that time frame. Then we look a little bit further intothe '90s and I have indicated the occurrence of very high speednetworks is going to have a profound effect on the way we dographics display and how we distribute the activities that areassociated with it.</p><p>Let me give a very oversimplified couple of statements on whatgave rise to the need for specialized graphics hardware --- theaccelerators that I talked about and indeed the graphicsupercomputers. As I've said, to terribly oversimplify, it wascertainly the need for real time transformations and rendering. Allof the advances in computer graphics over the last 10 or 15 years,many of them we can now find built into the hardware of theworkstations and graphic supercomputers that we have available tous.</p><p>One of the other reasons for wanting to bring all of that highspeed computational capability right to the desktop, as it is, wasto compensate for the lamentably low communication bandwidths whichwe had then --- which we have now, as a matter of fact. And I'meven including Ethernet and I'll be bold enough to say that theFDDI, which is not really upon us, is also in that lamentably slowcategory for many of the kinds of things we'd like to do.</p><p>It turns out --- in my view, at least --- that that specializedhardware, wonderful as it is for many, many applications, and makeno mistake, it has revolutionized the way that we can dointeractive graphics --- it's not useful for all applications.</p><p>One application that I've listed as a first bullet is one wherewe're doing specialized rendering --- research rendering let's callit. Not everything we wanted --- not all the research in renderinghas been done --- right? So Gouraud shading and Phong shading andso on is not the be-all end-all necessarily. There's a lot ofinteresting work being done. It has been reported at thisconference, as a matter of fact.</p><p>That is really a small reason for wanting to do the graphicscomputing on yet another system. But the next one that I've listedis a very compelling reason in many installations, particularlywhere large scale heavy-duty simulations are being done. I'vementioned that I'm from Los Alamos and that's certainly one centerwhere there are computations that are done on supercomputers andthat need to be visualized, and because of the nature of thecomputations all of the specialized hardware in accelerator boardsand in graphic supercomputers is not necessarily useful. Indeed,I'll argue that in many cases it's of no value whatsoever.</p><p>The last point I want to make here --- before I show you acouple of specific slides of these simulations that I'm referringto --- is that what will happen is that the emergence of very highspeed networks --- both local networks and international andnational networks --- is going to provide a way for these largescale simulations to take advantage of graphics hardware that doesnot necessarily have the specialized capabilities we just talkedabout.</p><p>At Los Alamos a group of folks in our network engineeringdepartment have taken the lead in defining what is called the HighSpeed Channel specification. Before I get to that, let me just giveyou an idea of the kinds of computations that are being done at LosAlamos --- and I know at many other places --- that simply can'ttake advantage of the specialized hardware that I've just beenreferring to. This happens to be the mesh that's associated with afinite difference computation for some simulation. It doesn'treally matter what it is, but I just wanted to show you that we'retalking typically tens of thousands of individual mesh points, andI can guarantee you this is a fairly sparse mesh compared to thekinds of things that most of our users encounter.</p><p>The point in showing you this is that as the simulation evolvesin time, there is a different version of this mesh for every singletime step. The scientists who are doing the simulation would liketo be able --- either after the fact or perhaps if the timing isappropriate --- to steer the computations that are going on bybeing able to visualize the evolution in time of meshes like this.And they need to be sent to some display device. And ideally you'dlike to do that at the rate of 24 frames per second, but we can gothrough some computations and find that's simply not feasible withthe kind of network bandwidths that are available today.</p><p>The specialized hardware that I've just been talking about givesus no help at all here, because what I need to be able to do is tosend one instance of this mesh to the display device for every timestep, as I mentioned a moment ago.</p><p>In addition, the scientists at Los Alamos and other places wouldlike to be able to have the counterpart of a numerical laboratory.This is completely synthesized, but you can --- and many of you mayhave had experience in the past with visualization techniques andfluid flow, where you can actually see shock waves by variouslighting techniques. The intent here is to be able to simulate thatsituation and be able to show the flow evolving --- not necessarilyas it's being computed, but perhaps after the fact --- but be ableto pick out important points by seeing a temporal evolution of thatparticular simulation.</p><p>So those are just a couple of examples that have given rise tothe development of a high speed channel specification and anaccompanying network at Los Alamos, and I wanted to say right now--- just so you don't think oh, great, a special purpose solutionfor a national laboratory that no one else will ever be able to use--- not so.</p><p>Many of you out there I am sure know --- and I know several ofour panelists are either aware of or working on high speed channelhardware for their particular products. There are about 30 vendorsthat have signed on to the high speed channel specification.</p><p>In addition, Digital Equipment Corporation is building thecorresponding network, which is called CP*. I'm not going to gointo network details here because that's not my point. I reallywanted to describe what is now a new highway for data transmissionthat facilitates my job, which is to help the scientists do thevisualization that they need to do.</p><p>So what we're seeing here is a very simplified view of how thishigh speed network, which is spec'ed at 800 megabits and acorresponding cross bar switch-style network that is going to alloweffective point-to-point connections between the various componentsof the computing environment --- the supercomputers, the datastorage devices, and the display devices. And each --- unlike witha bus structure --- each user will effectively have that completebandwidth available to him or her.</p><p>A larger view of that network is shown here and it gives us anidea of how we might interconnect the various devices and again. Idon't want to go through the details here, but you notice thatwe're accommodating FDDI gateways, so that the FDDI LANs can beused easily in this environment, and various workstations. I'veshown a Sun workstation there. I described vendors who are signingon to this concept, and Sun is providing a high speed interface totheir TAAC board, which can then be put into a Sun workstation, andconnected at 800 megabits directly over the network.</p><p>I mentioned earlier that this is not necessarily limited to justour local area networks. Many of you are probably aware of the workthat's going on now to establish these so-called national datahighways. The Corporation for National Research Initiatives iscoordinating an activity to establish centers throughout the UnitedStates that will participate in a test bed of what is to become inthe 1990s a four gigabit data highway spanning the UnitedStates.</p><p>So I'd like to leave you with the thought that while we havemigrated a lot of the graphics computing capabilities --- graphicsrelated computing requirements to workstations and specializedgraphic supercomputers --- the emergence of extremely high speeddata communications makes one rethink these situations ---particularly when you are faced with the kinds of computing tasksthat I just mentioned that we have for large scale simulations atnational laboratories.</p><p>I'm going to stop my heretical remarks here and I'm going toturn it over to the panel to describe several different points ofview.</p><p>As I mentioned earlier, the next speaker will be Michael Piquefrom Scripps Clinic and Research Foundation. Michael? Thankyou.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>B.4.2</cat_node>
				<descriptor>Voice</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010597</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Sound-based input / output</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31090342</person_id>
				<author_profile_id><![CDATA[81100520747]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Phillips]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Los Alamos National Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P182714</person_id>
				<author_profile_id><![CDATA[81100365016]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pique]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Scripps Clinic and Research Foundation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP37038436</person_id>
				<author_profile_id><![CDATA[81332516763]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Moler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ardent Computer]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P128528</person_id>
				<author_profile_id><![CDATA[81100089135]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Torborg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Alliant Computer]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14078352</person_id>
				<author_profile_id><![CDATA[81100196982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Greenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
           SIGGRAPH '89 PANEL PROCEEDING S the molecules by the positions and moving positions 
an d static colors of the atoms . Then Jay showed us what happens i f we both of them showed us if we 
render one of these thing s and then Jay would take that thing and compress it again . So the question 
for both of you is : Which is the fewer bytes th e original representation of the molecule in terms 
of it s coordinates, or the compressed picture after you've rendered i t and then compressed it back 
? TORBORG : I guess I can start by saying that the compression algorithms we're developing are not necessarily 
to come up with the fewest bytes to send to the particular representation . The idea is that not everybody 
can afford an Ardent on thei r desk, and we believe that to provide access to the visualization capabilities 
that scientists and engineers could really tak e advantage of, its better to provide that capability 
as a share d resource because there the service can be used much mor e efficiently than it can if its 
on somebody's desk down the hall . MOLER : I'm asking a mathematical question . TORBORG:Thc representation 
of a molecular image like tha t would probably be in the 30 to 50K byte range . So I'm not sur e exactly 
how long it would -- how much it would take t o represent this . PIQUE: Well, 50K that sounds like that's 
optimistic, bu t it's quite believable though is about 500 atoms if we sen d just the positions . MOLER 
: So that the position data and the compressed imag e data are sort of about the same maybe within a 
factor of tw o amount of data . PIQUE : It's going to depend on the rendering style . TORBORG : Yes, 
if you were doing wire frame, it would take hardly any data at all. If you're doing all ray-traced images 
wit h a fancy background and showing reflectivity and everythin g else, it would obviously take a lot 
more data to represent th e image . MOLER: No, you can represent the image by the origina l coordinates 
. TORBORG : No, the image, not the object . MOLER: Okay, fine . PHILLIPS : Thank you, gentlemen. Now, 
as I told you earlier on, if you would like to ask a question, please assume th e position behind a microphone, 
state your name and affiliation , and please, if you want to direct the question to a specifi c person 
or specific persons, indicate that. If its just a free fo r all, let me know and then I'll ask the panel 
to respond . Now le t me see. Let's just start over on the left this gentleman here . Q. I'm Bob Haber 
from NCSA. I have a comment and then a question . In the class of problems we're dealing with o n supercomputers 
in many applications, particularly as we go t o 3-D, we are past the crossover point where the model 
data i s much larger than the graphics data. If you think about needin g to have the same kind of resolution 
in the simulation that we want in the graphics, you don't want to boost one resolutio n without the other 
. It's clear that compressing from 3-D down t o a 2-D image mathematically is a compression, and if we're 
eve n handed on both sides we'll end up with pixel images which wil l have a finite limit in terms of 
size, based on visual acuity, a s Don pointed out. That will end up being a compressed forma t of the 
model data . The thunderstorm simulation we saw in the compute r graphics theater is already a case in 
point . There's much mor e information in the model than in any particular frame at an y particular time 
. Now the question I'd like anyone on the panel to comment whether they think that mass storage devices 
and large memories that are necessary to feed these high spee d processors that we're now seeing in work 
stations, are going to be affordable in the near future or whether we'll still nee d larger machines 
to handle that . PHILLIPS : Cleve, why don't you start ? MOLER : Dick Hamming has already mentioned Bell 
Lab s told a story where about the difference between information retrieval and information regeneration 
. He sai d you this is an old story you wire your 407 printer, prin t out all possible 8-digit numbers 
and you get a stack of pape r about this high and you keep it in your desk . A guy walks into your office 
and says got a problem, and he tells you th e problem . And you'd say oh, I got the answer right here 
. I just have to find it. Don't store the stuff. Compute it over again . That may be better . PHILLIPS 
: Mike ? PIQUE: The question asked about mass storage . I'll have to take that to mean disks for now 
. What was the other part ? HABER : Basically I'm pointing out that processor speed i s not the only 
question in a balanced system . You can have a very fast processor, and no matter what you 're doing, 
whether you're putting out output or whether you're getting the input fo r the calculations, you need 
to get that data from somewhere . Right now, people that are working with the high en d workstations 
often get limited by they can't get the data in t o get crunched fast enough . So the processor speed 
is not th e bottleneck . PIQUE : That's true, but I don't at least in our environmen t see any economies 
of scale in putting our storage devices , our disks, on our larger computers . We find we get as good 
a speed and certainly a lot cheaper by putting them on the loca l workstations . So at the moment, the 
technology doesn't see m to go towards the centralized even disk storage . TORBORG: I'd like to present 
a different viewpoint . I contend that the performance of high performance machines i s really going 
to be limited by memory bandwidth and dis k bandwidth, and although I don't believe you can get economie 
s of scale necessarily in a higher performance machine, you ca n make better use of that facility if 
you're using it in a time sharing environment, where when one person's job is done , another one can 
take over . Whereas in a workstatio n environment, often those resources are underutilized and you'r 
e not effectively utilizing the resources that are available . PHILLIPS : Don, do you have any comments 
on that ? GREENBERG : Yes, I think Bob's trying to get even with u s for the tough questions we asked 
him on his Ph .D. exam . Bob, I think you're absolutely right . I think you're hittin g the nail on the 
head . I think the goal, first of all, is how do yo u get into the model data? And you want to get into 
the mode l data from the terminal which you're working on . Under the present circumstances, it's pretty 
tough to store all the mode l data in the workstation . But I think that the size of the mode l data 
is going to grow either linearly with the number o f elements, or as a cubic function of the scale of 
the problem . But the computational size of the problem is going to grow as a factor to an exponent of 
some place between six and nine. So you're still going to have to do the computations on th e supercomputers 
. We're just going to have to increase th e memory the physical memory in the workstations . I don' 
t talk about disks because I think the goal really is th e interactive steering of the computations . 
I still believe it's going to be cheaper to transmit the model data than to sen d image data, and you 
can't really interact with the model if you'r e only dealing with the image data . DISTRIBUTED GRAPHICS 
: WHERE TO DRAW THE LINES? SIGGRAPH '89, Bostoh, July 31 August 4, 198 9 PHILLIPS : Cleve, do you want 
to respond ? MOLER: Yes, I wanted to deal with this one more time. The thunderstorm is an interesting 
example . There's a huge amount of data there . But that's only part of it . That's one-tim e snapshot 
in a time-dependent thing . I think its misleading to take that static description of the field and eject 
particles in i t and twist ribbons through it. The motion you want is the motion of the thunderstorm 
 not the motion of the ribbons i n a snapshot of the thunderstorm . And you want to animate th e time 
dependent calculation. Now that's really hard. We're not doing that yet; we can't do it. But the amount 
of data involved in the time dependent thing; it's out of the question for storing on the disk, You're 
going to have to compute it over again. PHILLIPS : Let me respond to that . There are some situation 
s where it 's just not cost effective to compute it over, and we'r e talking about simulations that 
may run 30 hours or more on a top of the line Cray, and you don't just cavalierly say well , we'll toss 
that away and then we'll run that over again. That just is not feasible to do . PHILLIPS : Question over 
here . Q. Craig Hubley, ACM SIGCHI, Hubley &#38; Associates . It sounds to me like you've got both a 
problem and a potentia l solution sitting in the same word interactivity. I've got a pretty good idea 
now how you intend to distribute calculation . What I have less an idea of is what's the vision of scientifi 
c computing that's driving this? There is a lot of problem whe n you talk about standards, architectures, 
national networks , when you haven't properly defined what kind of interaction i s going to take place 
over those networks . At present we've got wonderful devices for getting outpu t to the human being, 
and our devices for getting input from the human being into the model and into the system are just plai 
n lousy, and our networks and our interactive systems don't reall y support that . If someone 's thinking 
about it and they have an interactive hook into the model, I can maybe get one finger i n there called 
a mouse or two . If they're really thinking about it, then they get a whole hand in there with a data 
glove on it . But at some point we may want to just walk in and walk around, an d if that's not being 
thought of now at this stage where peopl e are setting up these networks -- I don't know when it's goin 
g to be thought of, and you have to communicate these things t o people with less vision who actually 
do the implementatio n work . When I say this is a solution, what I mean is that the mer e information 
of where someone is in the model, what they'r e looking at, what's concerning them at the moment, the 
othe r half of the human equation could save you an awful lot o f rendering time . I suggest that the 
additional bandwidth to b e concerned specifically with these kind of interaction issues i s well worth 
it in what it can save you in doing your outpu t alone . So I'd like to hear from the panel what they 
think abou t the actual model of interaction that's going on, what thei r vision is for scientific computing 
. PHILLIPS : That's an excellent comment, and that clearly is a dimension of computing that needs a lot 
of work . My ow n view is that the kinds of capabilities that the High Spee d Channel and the CP 5 network 
is going to provide is going t o facilitate those very high bandwidth input capabilities, bu t developing 
them and coming up with the right schemes for doing it, I think is we're still on the verge of that 
. But I' d like to hear from the panel on that . I know Don's got som e strong feelings about those things 
. GREENBERG: He does? What are they? PHILLIPS : Do you remember when we were drinking th e other night 
? GREENBERG: I do have some strong feelings on it. But first of all, I think the modeling certainly wants 
to be don e locally . You want to do the modeling where you are and I think it's in your own laboratory 
. So I'm back to my workstatio n bigotry. I'm always amazed when I come to a place lik e SIGGRAPH where 
I put up a fancy image and the first questio n is how long did it take to render? Very few people asked 
th e question how long did it take to model . They laugh when you tell them the rendering time, but they 
would probably break u p into hysterics if they really knew what the modeling time was . We don't have 
the tools yet . That's the biggest unsolve d problem in computer graphics right now you're absolutel 
y right it's something that we should be working on, and ver y few people, to my knowledge, are working 
on it. It's a tough problem. I can't make any more comments . PHILLIPS : Mike? Comment ? PIQUE: We 
touched on this a little before. Cleve calls it a matrix movie where you take your data may not be the 
right word. It's good for everything else though. You take the results of the computation, the results 
of the simulation, an d save it so you can look at it with different visua l representations . I call 
that a data flip book in contrast to a picture flip book. But that gives you the ability to make multiple 
use of the same simulation run either now or to g o back and look at it later and this is where I 
believe that it' s crucial to have the viewing at as close to real time rates as yo u can, so that 
it matches the human perception, and b y decoupling the calculations from the display that you can d 
o with a data flip book or a matrix movie, this leads to th e proposals you have of being able to then 
look at that quickl y with the advanced graphics that are separate from th e computation . PHILLIPS 
: Cleve, are twisting knobs and things like that really enough to respond to the question that he's 
asking ? MOLER : I don't know; I'm not anywheres close to being abl e to walk around in my models. I 
haven't really thought much about it . We certainly twist knobs . One of the most important knobs is 
the Oh Shit knob, and you know something's going wrong and you just want to start it over again . I 
don't know how many of those 30-hour computations at Los Alamos should have had an Oh Shit knob after 
the first 10 minutes. To Don, the modeling time is people time, and it's very hard t o measure. The 
rendering time is computer time and you ca n measure that to the microsecond . Maybe we don't hear muc 
h about the important time in the model . HURLEY: But it is the human time that stays and gets mor 
e valuable and it's the computer time that gets cheaper . MOLER : Absolutely. HURLEY : So if we're 
talking about architectures for the nex t 20 years . That's going to be important . MOLER: Of course, 
the computer time will help the people time; if you can speed up the computer it may make the human 
job easier and get it done faster . PHILLIPS: Let me move to the next questioner in the middle here, 
please . Q. Martin Minnow, Digital Equipment. We're starting to see some new technologies for parallelism 
with the transputers an d the connection machines at one end of the scale and Linda as a software strategy 
at the other, and several of the panelists hav e nudged the question of parallelism, but I'm wondering 
if the y could discuss it directly . PHILLIPS : For anyone? Cleve, go ahead .  2 7 8 DISTRIBUTED GRAPHICS 
: WHERE TO DRAW THE LINES?  SIGGRAPH '89 PANEL PROCEEDING S MOLER : I spent a couple years of my life 
programming a massively parallel computer. My favorite expression is ISMOP its a small matter of programming 
. If you have th e time and the wherewithal and the inclination to develop ne w algorithms like Greenberg 
is talking about doing distribute d algorithms, particularly with distributed memory machines then 
the large scale distributed memory parallel machines like the hyper cubes and the connection machines 
and th e transputer boxes can be very effective, very cost effective. But it takes a lot of time to get 
the stuff. They're easy to program , but they're hard to develop the algorithms for. The kind of automatic 
 everybody's going parallel but automatic fe w processor parallelism with shared memory is probably 
the thing that most scientists and engineers want to use if the y want to spend their time doing physics 
and chemistry and no t algorithm development . TORBORG : I basically concur with Cleve, but I'd like 
to ad d one thing, and that is that in many applications th e performance that we get out of parallel 
processing is limited b y the memory bandwidth the speed at which the processors ca n access the memory 
and can share data among themselves . That's one reason why it's not going to be a simple matter o f 
throwing in a few N10 processors and a workstation and be abl e to get substantial increases in processing 
power, because the performance is really going to be limited by how fast you ca n get the data out of 
the memory and that's going to dramaticall y affect the cost, and the memory costs are unfortunately 
no t going down as dramatically as we'd like to see. The cost per bit might be going down, but the cost 
per megabyte per second i s not going clown appreciably at all . And therefore, that's reall y going 
to limit how far we can go with deskto p implementations of parallel processing . PHILLIPS : Anyone else 
want to comment on that ? PIQUE: Just that it's sometimes difficult to draw the line between the computation 
and the imaging, the pixel plane s machine, for example, with the parallel processors doing the simulated 
 running the volume rendering . I'm not sure it' s not what I would have thought of as computer graphics 
unti l maybe two years ago . I would have thought of that as straigh t computation . PHILLIPS : There 
was someone over here. They disappeared . Q . The question was already answered . PHILLIPS : Okay, great 
. Over here, please . Q . Wesley Wright, University of Vermont Academi c Computing Center . I've got 
a quick comment and a quic k question. I worked this out on a piece of paper with a penci l over there 
 not a super computer. So I might be wrong. But for a 300 x 300 mesh of points, that's about 90,000 points 
, three degrees of freedom for each point that's 270,00 0 degrees of freedom . Let's see . If you do 
that at four bytes pe r each degree of freedom, that's about a million bytes worth o f data right there 
. So that sounds like about a screen full o f pixels. So in the data transmission for pixel transmissio 
n problem, that's a point you should keep in mind .  The question is, however, I'm sort of unclear from 
all o f this exactly who falls into whose camp and exactly what th e differences are. There seems to 
be a lot of commonality as wel l as differences. So if maybe by a show of hands or a division line, could 
you say who believes in whose ideas and wh o doesn't. PHILLIPS : What would you like us to do ? Line 
up in order . WRIGHT: Yes, move chairs or something ; I don't know. I'm not quite sure who's in whose 
camp . PHILLIPS : I think what you're seeing is ideas that are stil l evolving, and if you don't see 
us up here engaged in fisticuffs , it's because there is I think some truth to the position tha t everyone 
of us takes, and it's very much application dependent . Trying to come up with a black and white answer 
out of this panel I don't think was a reasonable expectation, and certainl y I didn't expect anything 
like that . But I think we've given yo u a diversity of points of view, and some of them are emergin 
g and maybe in another SIGGRAPH or two we'll have a better we'll have a vantage point to look back and 
see exactly wha t might be a clearer approach to take . PIQUE : I think if you go look at Alvy Ray Smith's 
dividing line on geometry and sample data, that our problem is clearl y in the geometry domain, so we 
stay with geometry as far as w e possibly can, and people who are sampling in a continuou s base might 
be reasonably expected to go to image compressio n techniques earlier . PHILLIPS : Question here in the 
middle . Q . Yes, I have a question regarding interactivity . Centralize d graphics versus distributed 
graphics . It occurs to me that i f you're implementing a centralized graphics and you imagine t o rotate 
or to manipulate your model interactively, and i f someone else is sharing your centralized graphic server, 
the n you might incur in jerky movements or a loss of quality o f interactivity . Would anybody comment 
on that ? PHILLIPS : Don ? GREENBERG : I agree with your comment. That's why I take the position that 
everybody has to have their powerfu l workstation and not worry about the centralized server or the supercomputer 
to do any of the graphics operations . You should have control over it entirely yourself and that the 
nex t generation of workstations will be able to handle to a larg e degree the increased complex models 
that we're talking about . PHILLIPS : What's the role of window servers then in ou r future of distributed 
graphics ? MOLER : I was going to make a comment about the nex t generation of workstations . I think 
I can promise to bring a machine to SIGGRAPH a year from now that I could carry in th e room myself, 
hook up to the AV equipment back here, an d show the computation I just showed you by being compute d 
live in the room with no satellite dish out in the parking lot . PHILLIPS : No taking orders now . Okay? 
Any other comments on that ? TORBORG : One thing I was going to say about th e centralized graphic server 
versus the distributed graphic server , we found in talking to many of our customers that the user actually 
doesn't use the graphics as significant a percentage o f the time as you might expect . If you stand 
behind somebod y that's actually running a graphics intensive interactiv e program, it tunes out that 
the frame is not being updated all tha t often. It might be only 5% of the time. A user tends t o dynamically 
rotate an object and then stare at it for a fe w seconds before he decides what to do next . So we're 
only usin g a very small percentage of about half of the hardware in ou r typical graphics workstations 
. So if that hardware could b e centralized in a facility where it could be shared by multipl e users 
and let's just consider, to begin with, that you wer e willing to invest exactly the same amount of money 
in tha t hardware and a central resource . Then basically you would hav e 20 times roughly the graphics 
computational power in that central resource than you had distributed across you r workstations . Now 
in reality, you're probably not going to be willing t o spend quite as much on that hardware as you would 
have if yo u DISTRIBUTED GRAPHICS : WHERE TO DRAW THE LINES? SIGGRAPH '89,Roston, Jul +311 AAuuc ust 
4, _198 9 put it in the workstation, but even so, you will end up wit h substantially more compute power 
that's available to the users than you would have otherwise been able to have if you pu t them in each 
workstation . So although there is som e timesharing interactivity issues that have to be considered, 
a lot of that can be overcome by the appropriate application o f hardware and software in using multi-threading 
techniques an d the operating system and the other things that companies tha t have been in the timesharing 
business for a while understand at this point and have applied to really addressing the interactivity 
issues in timesharing computers . PHILLIPS : Go ahead, Don . GREENBERG : Jay, I'd like to just take a 
little look into th e future . Were all old enough to have seen the migration from two dimensions into 
three dimensions . Many scientific problems I would imagine a dominant portion of them, i n fact are 
time dependent . And with the combination of the fact that they are time dependent and therefore will 
have to hav e motion in them to understand these time dependent phenomena as well as the fact that they 
'll be more complex, we will nee d motion just to be able to perceive the depth perception . I suspect 
that the percentage of time for graphics operations i s going to increase substantially instead of staying 
at the lo w levels which you describe . TORBORG : That could be and I'm sure that's probably true , but 
even so, you were not always going to unless you'r e running a flight simulator or something, you're 
not going t o sit there in front of a dynamic display continuously or you 'l l lose total track of what's 
going on . So we believe that even a s the interactivity in dynamics increase as an ability t o understand 
the model, you're still not going to be doin g continuous motion on the screen . I think although tha 
t percentage might increase from 5% to 10% or even to 20%, it s still a long way from taking full advantage 
of the hardware i n most workstations . GREENBERG : I'm sorry for making this just a dialogue, but I 
really disagree . Take even a profession like architecture wit h buildings which don't move, theoretically 
. You take a look a t trying to model the building, My students are using th e interactivity and motion 
for every single step of that model creation for hours on time, and not only that, when they try an d 
evaluate the space, the only way to evaluate the space is t o walk through it. You don't evaluate it 
by a picture. You evaluate architecture by the space which it creates and mov e through it. That's the 
least problematic example . When we are involved with simulating tornadoes and finite element analysi 
s and crack propagation and beating hearts and the medica l profession, your whole data base is changing 
. We're going t o have dominant portions of graphics operations locally . MOLER : Mike points out that 
both he and I are fro m California where the buildings do move . PHILLIPS : We have time let me take 
one last question . This gentleman over here has been very patient . Q . Ralph McNall, Digital . I have 
an observation and then a question. The observation is in the interaction human factor s area, and that 
is there are needs for some improvements . In th e hardware the biggest problem is really the software, 
but the rea l question is why are we still using QWERTY keyboards, whic h we know are not optimal design 
.? The question is towards Do n and possibly towards Michael . It has to do with PI-IIGS and if my understanding 
serves me correct, PHIGS is extensible i n that you can have user defined elements . Why isn't PHIGS 
being used for model representation, because I think that wa s Don's complaint about it . PHILLIPS : 
Don, why don't you start? GREENBERG : It's terrible . That's not fair . I'll be serious . The real problem 
is that at least for myself when I' m working in computer-aided design or some scientifi c visualization, 
I want to get at the model, and PHIGS is a construct which basically extracts information from a model 
and puts it into a form which can make a hardwar e implementation fast and get the graphics pipeline 
accelerated . But that's not just the problem. We're no longer just trying to accelerate the graphics 
pipeline . We want to get back into th e model and PHIGS was developed as a one-way street . PHILLIPS 
: Mike, do you want to comment ? PIQUE : I don't disagree, and we are looking for bette r approaches 
to that . The one I'm most fond of myself is the Dore approach from Ardent that keeps up . Well, it has 
it s limitations, but it keeps up higher level geometric yes, it' s still geometry, but it keeps a higher 
level geometri c description of the object, not only for rendering, but for doin g other analyses . PHILLIPS 
: Okay, I think with that, we're going to conclude this session on Distributed Graphics : Where to Draw 
the Lines . The panel will be leaving the stage . If you have questions , please don't come up to the 
stage. The AV people have to clear the room and they want to go to lunch . Thank you very much, folks, 
for coming . DISTRIBUTED GRAPHICS : WHERE TO DRAW THE LINES? 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>77292</article_id>
		<sort_key>281</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Operating systems and graphic user interfaces]]></title>
		<page_from>281</page_from>
		<page_to>293</page_to>
		<doi_number>10.1145/77276.77292</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=77292</url>
		<abstract>
			<par><![CDATA[<p>Good afternoon, ladies and gentlemen. On behalf of myself andthe panelists and SIGGRAPH, I'd like to welcome each of you to oursession this afternoon.</p><p>This afternoon we're going to be talking about operating systemsand graphics user interfaces. Of course, I'm the panel chairperson.My name -- J. Paul Grayson, the chairman and CEO of Micrografx, andI feel very fortunate this afternoon to have a number ofdistinguished speakers here with me. I'd like to briefly introduceeach one of those.</p><p>As you're probably aware from looking at the program, there havebeen some last minute changes in the speakers. But I think we'revery fortunate to have a number of unique and talented individualswith us this afternoon. So I feel very good about the speakers thatwe have.</p><p>The first speaker this afternoon is Chris Espinosa, who is atechnical consultant at Apple, but I think that description reallydoesn't do Chris justice at all. Many of you are aware that Chrishas been in the personal computer business about as long as it hasexisted. He was one of the original members of the Home BrewComputer Club, was actually employee number eight at AppleComputer, and is now the most senior employee at AppleComputer.</p><p>While at Apple he's had a number of significant accomplishments.He was originally responsible for the Apple II, was on the originalMacintosh development team, was the author of the Macintosh userinterface specifications, and has also been the product manager forHypercard.</p><p>The second speaker today will be Martin Dunsmuir, who is thedirector of Presentation Manager development for Microsoft. Martinhas been with Microsoft for approximately four years. He is fromthe U.K., from Britain. So you may notice a slight accent. He waspreviously the director of Zenix Development for Microsoft. He wasresponsible for Zenix 386. He is also responsible for PMX, was partof the technical team that sold the PM behavior, the PM userinterface to the OSF Motif Group, and has been the OS/2Presentation Manager director since about March.</p><p>The third speaker changed so recently I didn't have a chance toupdate his slide. So rather than Tommy Steele today, from IBM wehave Dr. Mike Edwards. Mike is a software engineer in the PMtechnical office. He's been on assignment in Boca Raton forapproximately 18 months, having originally been in Hursley as aHursley PM developer, and I think he was planning on going back toHursley in the next few days and got called in to do this. So Ithink his wife had to take care of some of the business, likeselling the car and the house, while he came to Boston.</p><p>Mike also has a very interesting background. He got intographics while he was a student at Birmingham University inEngland, and he was part of a team of people that won a Nobel Prizein 1983 for particle physics. And I hope you'll hold your questionsabout particle physics until after the presentation is over.</p><p>The last speaker today is also a very distinguished gentleman.Guy or "Bud" Tribble is a founder of NeXT, where he now overseesall of the systems software development. Previous to that he was asoftware manager for Apple where he oversaw the system andapplication software development for the Macintosh and for theApple II.</p><p>The panel format this afternoon -- we'll hear each of thespeakers in the order that I've mentioned. Between each speaker Iwill probably ask one or two questions to try to draw outparticular topics from the speakers. Then after the final speaker,we'll open it up for questions from the audience.</p><p>Please join me now in welcoming our first speaker, ChrisEspinosa.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>D.4.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.2.2</cat_node>
				<descriptor>User interfaces</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011066.10011069</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Development frameworks and environments->Integrated and visual development environments</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010949</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Operating systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P123103</person_id>
				<author_profile_id><![CDATA[81100494947]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Grayson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Micrografx]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P36217</person_id>
				<author_profile_id><![CDATA[81100328625]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Espinosa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Apple Computer]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P178365</person_id>
				<author_profile_id><![CDATA[81415591654]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dunsmuir]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14205581</person_id>
				<author_profile_id><![CDATA[81100595644]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Edwards]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P26869</person_id>
				<author_profile_id><![CDATA[81100381477]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[B.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tribble]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NeXT Computer]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Panel Sessio n Operating Systems and Graphic User Interface s Chair: J. Paul Grayson, Micrografx Speakers 
: Chris Espinosa, Apple Compute r Martin Dunsmuir, Microsoft Mike Edwards, IBM Bud Tribble, NeXT Compute 
r Good afternoon, ladies and gentlemen . On behalf o f myself and the panelists and SIGGRAPH, I'd like 
to welcom e each of you to our session this afternoon . This afternoon were going to be talking about 
operatin g systems and graphics user interfaces . Of course, I'm the pane l chairperson . My name -- 
J . Paul Grayson, the chairman an d CEO of Micrografx, and I feel very fortunate this afternoon t o have 
a number of distinguished speakers here with me . I'd like to briefly introduce each one of those . As 
you're probably aware from looking at the program , there have been some last minute changes in the speakers 
. But I think were very fortunate to have a number of unique an d talented individuals with us this afternoon 
. So I feel very goo d about the speakers that we have . The first speaker this afternoon is Chris Espinosa, 
who i s a technical consultant at Apple, but I think that descriptio n really doesn't do Chris justice 
at all . Many of you are aware that Chris has been in the personal computer business about a s long as 
it has existed . He was one of the original members o f the Home Brew Computer Club, was actually employee 
number eight at Apple Computer, and is now the most senior employee at Apple Computer . While at Apple 
he's had a number of significan t accomplishments. He was originally responsible for the Apple II, was 
on the original Macintosh development team, was th e author of the Macintosh user interface specifications, 
and ha s also been the product manager for Hypercard . The second speaker today will be Martin Dunsmuir, 
who is the director of Presentation Manager development fo r Microsoft . Martin has been with Microsoft 
for approximatel y four years. He is from the U.K., from Britain. So you may notice a slight accent. 
He was previously the director of Zeni x Development for Microsoft . He was responsible for Zeni x 386 
. He is also responsible for PMX, was part of the technica l team that sold the PM behavior, the PM user 
interface to th e OSF Motif Group, and has been the OS/2 Presentation Manage r director since about March 
. The third speaker changed so recently I didn't have a chance to update his slide. So rather than Tommy 
Steele today , from IBM we have Dr. Mike Edwards . Mike is a software engineer in the PM technical office 
. He's been on assignmen t in Boca Raton for approximately 18 months, havin g originally been in Hursley 
as a Hursley PM developer, and I think he was planning on going back to Hursley in the nex t few days 
and got called in to do this . So I think his wife had t o take care of some of the business, like selling 
the car and th e house, while he came to Boston . Mike also has a very interesting background . He got 
int o graphics while he was a student at Binningham University in England, and he was part of a team 
of people that won a Nobel Prize in 1983 for particle physics . And I hope you'll hold you r questions 
about particle physics until after the presentation i s over . The last speaker today is also a very 
distinguishe d gentleman . Guy or "Bud" Tribble is a founder of NeXT, wher e he now oversees all of the 
systems software development . Previous to that he was a software manager for Apple where he oversaw 
the system and application software development fo r the Macintosh and for the Apple II . The panel format 
this afternoon -- we'll hear each of th e speakers in the order that I've mentioned . Between eac h speaker 
I will probably ask one or two questions to try to dra w out particular topics from the speakers . Then 
after the fina l speaker, we'll open it up for questions from the audience . Please join me now in welcoming 
our first speaker, Chri s Espinosa. Chris Espinos a Apple Compute r  Thank you, Paul . What I want to 
do this afternoon is t o give you an overview of some of our systems softwar e directions at Apple . 
But first I want you to understand a little o f the why and the how of what we're doing -- not just the 
what -­and to do that requires going through a bit of history . When we designed the Macintosh we were 
basing it on th e proposition that if you built a computer that was fundamentall y easy to use, that 
more people could use it. And we achieved that to some degree . A lot of people are using Macintosh who 
jus t wouldn't have touched or felt a computer before, and they'r e getting some productivity benefits 
out of it. They're doing things better and faster than they could have . But what's more interesting, 
when we listen to what users say about what they'r e doing with their Macintosh, is that they don't tell 
us abou t what they're doing with it, so much as they tell us how they fee l about it -- how they feel 
about themselves when they use it . And we get these letters and sometimes we solicit an d sometimes 
they just come in over the transom . One user writes : I was concerned because I had to work on a computer 
and to me, Macintosh was a computer . I don't think of it as a computer anymore . I mean, it's a computer, 
but i t doesn't have the negative connotation of something that ca n control you . You can control and 
use it . It's a valuable one . Paul Somerson, who used to edit PC Magazine and no w edits MacUser Magazine, 
writes : The Mac had so many built-i n user smarts that it ended up dispatching many of th e housekeeping 
chores that would have distracted my though t processes on the PC. And what we've discovered over time 
i s that while we've succeeded on getting more people int o computing with the Macintosh because its 
easier to use, th e fundamentally interesting thing about it is that it's great to use , SIGGRAPH '89, 
Boston, July 31 -August 4, 1989 and that people who love using their tools, are doing bette r things 
with them than people who merely get by using thei r tools . Now what is it about the Macintosh that 
makes peopl e love it and love to use it? We've been looking for one particular element that really stands 
apart and makes Macintos h separate from other computers, and it's not just one element , It's a lot 
of little things . It's not mice and windows, fo r example . Some of the stuff that sets Macintosh apart 
is obvious -­and some of it is a little more subtle . Graphic user interface s are obvious . They really 
help you get into the computer a littl e faster, and make people feel more comfortable with it . What' 
s not so obvious is to be so into the user that you actually hav e the computer smile at you when you 
turn it on . Consistency is a good thing ; it's obvious . If people learn things in one application they 
should be able to leverage tha t learning into other applications . That's fairly obvious . What's not 
so obvious is that in order to do that right, you'v e got to build the tools to do that into every machine 
-- to th e degree of soldering them to the board so that applicatio n developers and users don't have 
to wonder about what th e environment is or what the tools are to be consistent with . And it's kind 
of obvious that you have a direct manipulation human interface where people can go grab and touch things 
an d that's a lot faster than an indirect command line user interface . What's not so obvious is that 
in order to make al l developers use that and use that well, you've got to make sur e that there isn 
' t a command line user interface anywhere in th e system -- in order to make direct manipulation really 
work the way it's supposed to for users . So it's qualities like this -- approachability, the sensibility, 
the intuitiveness of the human interface, the forgiveness, the ability to go and undo things or pull 
thing s out of the trash can -- that really make the experience of usin g the personal computer very 
high quality, and it's not just mer e efficiency again. It's really the whole enchilada. And they require 
this whole system to be designed for the user's benefit , and when you're designing the computer you 
really have to think about the user first and then work down to th e technologies, rather than starting 
at the technologies and the mips and the chips and working on up, and that's what we do at Apple . So 
now I'm going to talk about what we're doing with our system software in the future, and I want you to 
see that desig n philosophy come through in the things we're doing . Last May we disclosed to our software 
developers some o f the core technologies behind our upcoming system software, so they can start planning 
and working on using its feature t o minimize the disruption when it actually comes out, an d maximize 
the leverage developers have when we actuall y deliver the software to users. We haven't announced a 
shipping schedule for it yet, but we're going to sometime this fall . The seven core elements of this 
system software are first, a 32-bit operating system with virtual memory . Second, a n inter-application 
communication architecture that allows bot h live copy and paste between documents of differen t applications, 
as well as lets applications drive each other . Third is a new object-oriented version of the finder 
tha t simplifies and consolidates the fundamental user interface. In our graphics technology -- we're 
introducing an outline fon t technology for fast, sharp type at any size, from an y application, on any 
device, and improved text line layout . A couple more things. There's a data base access manage r which 
makes consistent the interface to remote data bases o r even local data bases, and a communications toolbox 
whic h we've already introduced and is available now through APDA , that simplifies and consolidates 
interface to seria l communications and network communications. And a new printing architecture that 
radically simplifies the task o f implementing great high quality consistent print drivers acros s Macintosh 
. This is going to be the standard Macintosh operatin g system. We're going to transition everybody we 
can to this , It's going to run on all machines from a Macintosh Plus, all th e way up to our higher 
end machines and we're going to b e introducing more and faster machines in the future -- as well a s 
more nicely packaged lower end machines . It's going to take two megabytes of RAM . Luckily, the Macintosh 
Plus can take two megabytes of RAM . It doesn 't require any additional hardware . In order to get the 
virtual memory part of it, you will need the PMMU that's in the Macintosh II as an option -- or the 68030 
which is in now a good half of our CPUs . But you can run system 7 .0 without virtual memory on any of 
the machines, regardless of whethe r it has a PMMU or not . I want to go into these cor e technologies 
one by one and give you a feel for why we'r e doing them and how they'll fit in . The 32-bit OS and virtual 
memory allows users to ru n multiple applications, large applications that use a lot of data . All the 
Macintoshes from the beginning have had that 32-bi t processor in them, the 68000 processor. But because 
of some design limitations in both hardware and software, we haven' t been able to use the full 32 bits 
-- the 32-bit range, addressin g range of the processor . Consequently, Mac applications toda y are limited 
to about eight megabytes of space -- and that's no t enough. 32-bit addressing will allow applications 
to directl y access up to 128 megabytes of physical RAM in the machine , and that should effectively 
remove a lot of the limitations o n program and data size . But even 128 megabytes is a bit of a limitation 
to us. So we're implementing virtual memory that will allow the full four gigabyte 32-bit addressing 
range i n virtual, shared between physical RAM and disk RAM . Now, of course, there are speed trade-offs 
when you us e virtual memory instead of physical memory . But we want to allow that possibility. The 
come down for the users of this i s that they really won't have to worry as much about how muc h physical 
RAM they have . It will give you the ability to launc h just one more application under the Multitask 
and Multifinder environment, where before you would have to quit one in orde r to make that . The beautiful 
thing about it is that it's jus t transparent. The user interface to launching applications doe s not 
change ; the application interface to dealing with memor y does not change . It's just that you get this 
little slider up i n your control panel and you control how much virtual memory you want, and it's a 
speed/space trade-off. Raise it higher -- it takes up more space on your disk . System may operate a 
little more slowly if you fill it up . Drag it lower -- you're going to use more physical RAM; the physical 
RAM will go a little faster . And that's the entirety of the user interface for it . So we're trying 
to make this technology very useful, very clea n conceptually to the users, and to the developers . Now 
when you start doing that, when you start havin g more applications running at once, regardless of the 
amount o f physical RAM you've got, it becomes much more interesting t o have those applications talking 
to each other, and that's wh y we have the inter-applications communications architecture , which has 
three or four separate pieces . I'm just going to hi t the high points of it now . The first interesting 
piece is live copy and paste. Since the beginning of Macintosh we have had a mechanism fo r applications 
to exchange information, for one application to paste something -- to copy something to a clipboard and 
another application to paste it in. We have defined a couple o f simple information kinds for applications 
to exchange, and that's been very successful . Now you've got thousands o f Macintosh applications that 
exchange information . Were going to extend that mechanism with a publish and subscrib e parallel to 
copy and paste, so that you as a user can find something . Instead of copying it, you publish it and 
you stor e it in a file -- either a local file or a file out on a hardware -- fil e server out on the 
network . Then other documents can subscrib e to that published piece of information . When you update 
th e original, the published version gets notified and all subscribers to the publication get notified, 
so they update automatically . If the application is still alive, they update immediately . If the document 
is closed, it updates the next time it's opened. So you can take things and publish them and have the 
m propagate in a hot fashion throughout your system o r throughout the network, and were building this 
into ever y Macintosh with the next version of the operating system, and we want to get a lot of developers 
working on it so they no t only implement live copy and paste, but we also want t o develop a lot more 
standards of what you can live copy an d paste. This gives us an opportunity to define more interestin 
g fundamental information types for applications to share . Another interesting inter-application communicatio 
n mechanism is called Event PPC, and its a way for application s to like spawn new events and send commands 
to them --a standard program communication -- but also for differen t applications, to send commands 
and instructions to each other . And we're not only defining a language called Apple Events t o handle 
the standard things like open yourself, open a document, print a document, select some information, cop 
y some information -- things that happen in every Macintos h application -- but also for all spreadsheets 
were going to define the standard subset of what spreadsheets do, and encourage al l spreadsheet developers 
to listen to those messages . The sam e for word processors, the same for graphics programs . So wha 
t that will do is let applications that want to chart graphs or d o calculations, but don't want to include 
all of the code to do that , it will let them send those commands to whatever spreadshee t or graphics 
application happens to be around and get the resul t back. That's going to give users an incredible ability 
to use applications that have a lot of features without having a lot o f code in that one application, 
and once again, because they're using the same applications to do those calculations or those graphs 
to increase the consistency among the system, and th e fluidity of using the multiple applications . 
And were working with developers to define that language of even t communication . In the user interface 
side were completely rewriting th e Finder from ground up . Now the Finder is the fundamental interface 
to the Macintosh. It's the first thing you see when you start up, and over time we've added functionality 
to it . We've added also a lot of utilities to do standard syste m functions to just do housekeeping 
and stuff. And the Finder ha s gotten a little crafty around the edges . So were starting fro m scratch 
and were writing it in object oriented C++ and what w e want to do is really consolidate and simplify 
the fundamenta l user interface . All icons will respond to the same set of commands . You'll be able 
to open them up . Open up th e printer icon, you'll look at the printer queue, drag a document t o the 
printer icon. That will print the document -- things like that . Trying to make it much more cohesive, 
much mor e coherent, and take us into a new world where the Finder can do a lot more interesting things 
-- make it modular and extensibl e so people can add electronic mail packages, add archive an d back-up 
functions, for example, and make them integrated int o the Finder rather than stand-alone applications 
. On the graphic front, we're doing a lot to extend th e graphic model . For this round of system software, 
were goin g to concentrate on typography . We just recently introduced 32 ­bit Quick Draw to enhance 
the color model of the Macintosh . This round is going to be typography and in the future what w e want 
to do is architect the system so that we can extend it int o things like acceleration -- both hardware 
and softwar e acceleration : floating point capability, so that you're not stuc k with the integer Quick 
Draw drawing capabilities ; the variabl e resolution Sc) you can talk to screens, the different resolutions 
; 3-D animation . We're already introducing some animatio n tools in the system software in synchronizing 
sound and graphics going on on the screen . What we're doing now is outline fonts, which take the bit 
map font model and augment i t -- that we've got now in Macintosh -- augment it with an outline font 
model that combines mathematical outlines fo r fonts with an instruction set for how to transform fonts 
fo r various sizes, and that gives its both great looking type at larg e sizes, great looking type at 
small sizes where the problem is a s hard or harder, and also very, very fast performance across th e 
board -- whether you're talking to a screen or talking to a printer. Once again, that happens without 
changes to th e human interface, without changes to the programmati c interface ; it's transparent . 
So those were just a few of the technologies . I don't hav e time to go into all of them . We had a three-day 
develope r conference where we went through all of the technologies, an d those materials are available 
from Apple if you want to rea d about what we're putting in to the system . But I hope I gav e you a 
little taste of what we're doing . We're not just throwin g new technologies into the box because we 
like them or becaus e users need them or because developers are yelling for them . We're patiently crafting 
the things we want to do to reall y improve and enhance the thing that's great about th e Macintosh -- 
and that's the joy of using it and the quality o f the results you get from it . Thanks very much . Moderato 
r J. Paul Grayso n Micrografx  Thank you very much, Chris . I just wanted to ask you a quick question 
or two . One of the items that hasn't been clea r in my mind in the last few months since the System 
7 announcement concerns multitasking and to what degree the multitasking will be improved in System 7 
. Could you addres s that for us, please ? ESPANOZA : As some people know, we have ha d multitasking, 
as we define it, for quite a while in th e Macintosh. What we've clone is we've given users what they 
want. We've given users multiple applications on the screen at the same time, ability to quickly switch 
from one applicatio n to another, and background printing . When we talk to users , that's what they 
want . Now those things have to be done better. We're improving the print manager to allow SIGGRAPH '89, 
Boston, Jul 31 -Au ust 4, 1989 background printing from all print drivers . With faste r processors its 
going to be much faster to go from on e application to another and from one task to another . With event 
PPC were going to provide facilities for applications to talk to other applications and to subtasks . 
Now the obviou s omissions are memory protection and preemption . Were not going to do those yet ; we 
are going to do those eventually . It's not going to be in the next round of system software, but w e 
know we need it and were working on it . GRAYSON : Thank you. The next speaker this afternoon is Martin 
Dunsmuir . Martin Dunsmui r Microsoft I'm waiting for my slides to come up . My name is Marti n Dunsmuir. 
I'm director of Presentation Manager development at Microsoft, and what I want to talk to you today about 
is ou r view of graphical user interfaces on the PC, on the desktop . If you look at the market today, 
there are really a choice o f platforms that the end user can buy . There is PCs running OS/2, MS-DOS 
or UNIX, and there is the Macintosh . What we see as the key thing that helps the market to grow is that 
yo u can provide the same software on each of these platforms . This will allow ISVs and end users to 
capitalize on thei r development on one platform on those others, and it will allo w the end user -- 
once he's become familiar with, for example , using Windows on the PC -- to be able to move to othe r 
platforms and have the same user interface and where there ar e the same applications, the use of the 
applications will be th e same as well . So what the OEMs are looking for is a standard offering to put 
on all of these platforms . Now the other important factor is that whereas up until th e last two or 
three years, the graphical applications have rather been the exception, except perhaps on the Macintosh. 
On the PC now all -- more or less, all of the new applications ar e graphical . Microsoft has three graphical 
user interfaces, which ar e designed to address these needs . In the first place, we have Microsoft Windows 
which runs on top of MS-DOS on the PC . We have OS/2 Presentation Manager, which brings the same graphical 
user interface to the higher end PCs and brings multitasking and many other features as well . And it 
also has a programming model which is very similar to Windows . And we have another product which is 
currently under development, which we call Portable Presentation Manager, which i s designed to allow 
us to put Presentation Manager functionalit y onto a variety of other platforms . The primary platform 
we see is UNIX as the first of those platforms. Now what these three offerings give you is a common use 
r interface and a common mode of writing applications across al l of these platforms . If we look at 
Microsoft Windows for a moment, it's bee n hugely successful . The installed base and the ship rate o 
f Windows today rivals the Macintosh . After rather a slow start , it's surprising everybody -- including 
us -- how successfu l Windows has been . If you look at the marketplace today, most of the peopl e who 
are buying DOS are buying Windows too . So they can ru n one of the -- or some of the -- about 200 to 
250 applications ar e available. In fact, if you look at the ISVs, virtually all the ne w applications 
for the DOS environment are being written t o Windows . The key things that were focusing on in the 
Window s development area is making sure that the system can run o n machines with a small memory configuration 
offering hig h performance, and it can offer the appeal and the features th e people want on the low 
end desktop. So if you like, it's a Macintosh style religion put onto the PC. Now if you look at Presentation 
Manager, we release d OS/2 version 1 .1 at the end of last year, and that has a graphical user interface 
and a graphical programmin g environment, which we co-developed with IBM, calle d Presentation Manager 
. Basically what it aims to do is t o extend the success of Windows onto the high end . The feature s 
of Presentation Manager are a user interface which looks an d feels very much exactly the same as Windows 
. It provides some extra functionality, largely because OS/2 is a protecte d operating system -- an operating 
system that has ful l multitasking features . And it also provides a much more powerful graphical programming 
environment for buildin g applications . So we believe that OS/2 represents for ISVs a very compelling 
platform for building their new high en d applications, and whereas, for example, Windows has been a 
hard sell to the higher end graphical applications developers -­for example, people who have been traditionally 
on the hig h end UNIX workstations -- OS/2 we think provides the features , the performance, the functionality 
that will allow them t o really bring their applications into a new environment . If you look at the 
major components of Presentatio n Manager, there are four components that you can identify . In the first 
case there's a windowing API . API is Application s Program Interface . This is the set of functionality 
that allow s programs to create windows, to manipulate them and to do al l the other things that you 
want to do with your user interface -­scroll bars, dialogues, menus and so forth . Then there's a graphical 
subsystem, which basicall y allows you to control what you can draw on the windows you'v e created. The 
third feature, which is very important in the P C environment where there are many manufacturers and 
many add ­on peripherals, is that you can add third party features to th e operating system . The main 
features one's looking at is device drivers and also libraries of functionality which can be called by 
othe r applications . Then we also have a graphical shell which has bee n designed to provide the end 
user with an easy-to-use interface for getting at the file system, starting programs and so forth . If 
we look a little more closely at the windowing API, th e first thing that's important to notice is that 
it's conforman t with Windows, in terms of its user interface, and its als o conformant with IBM systems 
applications architecture , common user access specification . IBM has standardized the user interface 
across all of thei r systems, and OS/2 Presentation Manager is in fact the firs t embodiment of that 
interface . Another feature is that the programming model is objec t oriented. So when you're writing 
your applications, yo u basically have to break them down into a class hierarchy wher e each class is 
represented by a Window type within the system . Now this can lead to some difficulties in getting started 
. There's a steep learning curve you have to go up to write you r first Presentation Manager application 
. It's true to say that i t is difficult to write applications for Presentation Manager th e first time. 
However, we've got two things working for us . One is that there are good market reasons for wanting 
to write P M applications and all of the big ISVs are really very ke y independent of how difficult it 
is to do it . Secondly, there are a lot of Windows ISVs out there wh o know how to write for Windows, 
and really moving from Windows to PM is really quite a simple matter . We are planning -- I'll talk about 
it in a moment -- to ad d some features to the system in the future, which will make it a lot easier 
to write programs . There is a library of Window classes predefined in th e system and they're really 
the features of the system that define the user interface -- the classes for scroll bars, for windows, 
fo r sizing borders, for menus and so forth -- they're all ther e already . So you don't have to do any 
of that hard work . You can obviously create an application just using thos e standard libraries, but 
you can also extend the existing classe s by subclassing or you can create your own cont rols . The next 
important area is graphic support. Really there are two things I'd like to say about graphics . The first 
is that we do provide a very rich set of functionality -- much riche r than Windows did, for example 
. The second thing is that the way you talk to the graphic s functionality through the API is device 
independent . So fro m an applications writer's point of view, whether he's talking to the display or 
the printer or a plotter, he really only has to do one -- write the code once . This is very important 
from th e point of view of making it easier to build applications . Some of the functions that we have 
in the Graphics Engin e -- we support coordinate transformations, we support a variet y of lines, beziers, 
cubics, and so forth . We have extensive colo r support . We support a model of your drawings which use 
s paths, areas and clipping regions to make it easier to do certai n things . We support a combination 
of bit map and vector fonts . What's currently the font technology is not scalable -­automatically scalable 
technology ; that's something that we're working on. It will be coming out in a future release . The 
last graphics functionality that we support is we hav e a display list package, which is really very 
similar to some o f the functionality you can get on the big IBM mainframes, and we support Metafiling 
. The way you write a Device Driver for the Presentatio n Manager is basically you take the functionality 
of the Graphic s Engine, which is the GPI portion, and you replace functionalit y in there to drive your 
device . What this means is that you ca n basically decide how much you want to do in terms of you r 
device driver . If you want to have a very high performanc e device driver or evolve -- have a very mature 
device driver -- i t can be doing almost all the things that the Engine does . But to get started and 
particularly for printing device drivers where performance is less critical, you can really start off 
quit e simply . Device drivers are installable on the fly, so you ca n actually install printer drivers 
and so forth as you go along . And you can replace the display driver. So third party peripheral manufacturers 
can provide display drivers fo r Presentation Manager with their monitors or what have you , and the 
end user can install those and bring up Presentatio n Manager . I'm getting short of time here, so I'm 
going to talk a littl e bit about our future directions . Functionality that we're considering for our 
future releases . Presentation Manager -- we're just coming up to the secon d release, OS/2 1 .2, and 
it has some greatly improved features , performance, better printing, device drivers and so forth . There 
are many features though that we'd like to add to the system --3-D support, support for imaging so that 
you can do halftonin g and so forth, improved color support so that you can hav e applications that have 
a very wide range of colors . The contro l over the color palette is somewhat limited at the moment . 
 We're looking to support some future PC models which have multimedia type peripherals . We're looking 
to suppor t scalable fonts . As far as the programming interface i s concerned, we're looking very seriously 
at building an object­oriented API_ which goes on top of the existing API, so that yo u can build a -- 
basically write in C++ and write object oriente d applications . It also allows us to build some very 
high leve l applications which will make it easier for corporat e programmers and so forth to build fairly 
simple business typ e applications without having to get to the grips with the har d slog of writing 
a Presentation Manager programs . We're looking to improve our shell . As you'll see in a moment, the 
OS/2 1 .2 shell has a lot of object oriente d features, the further we can go, though, in terms of drag 
an d drop type manipulations and so forth . And integratin g applications into the system in such a way 
that you ca n actually invoke applications from the shell directly by jus t clicking on files that are 
associated with them . Another feature that we're planning to bring out toward s the end of next year 
is support for X Windows insid e Presentation Manager. This will allow somebody who wants to run an X 
application on a remote host to basically run it in a window on Presentation Manager . We feel this is 
ver y important from the market point of view . I haven't really got time to talk about Portabl e Presentation 
Manager, other than to say that what we're doin g is making Presentation Manager, the Presentation Manage 
r code, structuring it in such a way that it can be ported into a variety of OS platforms . Our primary 
targets there are UNIX , where we plan towards the end of next year to bring out a Presentation Manager 
system that sits on UNIX and provide s the Presentation Manager API. And secondly, it will allow it s 
to put pieces of Presentation Manager in peripherals such a s laser printers and so forth, which we believe 
is a large marke t we can address . So in summary, I think -- a wild prediction . I think th e industry 
press tends to bear this out though . It's ou r expectation that Presentation Manager will become the 
leadin g graphical user interface of the 1990s . One can questio n whether or not the penetration will 
be as great as DOS has bee n on the PC ; there are other contenders . But certainly it's goin g to be 
a very significant player . We believe that we do provid e with Presentation Manager the features you 
need to really buil d great applications. And great applications and not syste m software are what actually 
sell machines . We also believe that the market penetration o f Presentation Manager makes it a very 
compelling platform for all the OEMs and ISVs who commit to it . Finally, we think that we will be able 
to make Presentation Manager technology available across a wide rang e of platforms, and therefore we 
will be able to bring it to a variety of users -- high end or low end -- with the sam e features, the 
same user interface . Thank you very much .  In terms of the user interface constructs rather than 
th e graphics now, then really its object-oriented with everything . The user interface is already to 
a large extent object-oriented , and I think well see, as indeed in Office Vision, an application that 
IBM is producing for the office, everything becomes mor e object-oriented, that everything is represented 
in a desktop environment, as an object which you manipulate in order to get things done . But allied 
to that, there need to be in the future sets o f programming tools that make it easy to produce suc h 
applications . So there's a great push at the moment to develop tools that enable programmers to build 
applications easily i n an object-oriented environment . So we're developing object ­ oriented programming 
tools and associated object libraries tha t go along with that . We're also looking, of course, at future 
systems in terms o f hardware . Martin already talked about the portable version o f OS/2, which we will 
see on new types of hardware which brea k away from the traditional PC mold of the hntel 286, 386 and 
s o on . For example, we can think of the RISC technologies tha t are now emerging -- the Intel 860 chip, 
for example . We wil l look to have OS/2 running on platforms like that in the not to o distant future 
. Those systems are also exciting in many other respects , such as the ability to have multiple processors 
built in the system -- to increase the performance of the system . An OS/2 in its portable form is really 
ready to exploit those types of hardware environment with its multithreads and multitaskin g already 
built in. I think its going to be an exciting future for us over the next five and 10 years, and OS/2 
and Presentation Manager is going to be right there in the middle of it all . It's the platform for applications 
development for the '90s . Thank you . Moderato r J. Paul Grayson Micrograf x Thank you, Mike . I also 
have a couple of quick question s for you if you don't mind. If we had more time, I'm sure I coul d extend 
it. You demonstrated a nice piece of font technology . I couldn't help but noticing the word Speedo on 
the screen . I think Bitstream technologies or Bitstream software has some Speedo technology for drawing 
outline fonts . Is that a Bitstream font ? EDWARDS : That indeed is Bitstream indeed . We are workin 
g with a number of font vendors . It just happens that Bitstrea m happened to provide us with a rather 
nice demo . So I'm ver y happy to use it and I don't mind mentioning that it is indee d Bitstream . GRAYSON 
: Part of the reason I ask is I think a recent issue o f PC Week had a little news item that Microsoft 
had selecte d Compugraphic fonts for OS/2 . So I'm sure that we're going t o have some speculation that 
Microsoft and IBM is divergin g again. How would you respond to that? EDWARDS : I would like to say that 
both IBM and Microsof t have been investigating font technology very carefully ove r the last six months 
or so, and that no final decision has bee n made yet and were still evaluating technologies for performance, 
for quality and for code size -- all the kind of things that matter . When the decision is made, I'm 
sure we'l l let everyone know about it . GRAYSON : So you would say that the news report in P C Week 
was inaccurate then? EDWARDS: I would say that it was premature . Moderato r J. Paul Grayso n Micrograf 
x  All right, thank you . Please join me in welcoming ou r next NeXT speaker, Mr. Bud Tribble . Bud 
Tribbl e NeXT Computer, Inc .  First I want to mention that NeXT's goal is really simpl e to state, 
and that is we would like to bring desktop ease of us e to workstation class computing, and we include 
ease of use fo r both users -- end users -- and programmers in ease of use . We see this as part of a 
larger picture in that the kinds o f computing that you can do on your desktop has been steadil y increasing 
over the years and we think will steadily increase i n the future. In the early 1960s Ivan Sutherland 
in his semina l thesis on Sketchpad showed us what we could do at that tim e with an entire roomful of 
equipment -- had 72 K words o f memory, took up an entire room, and you could do Sketchpa d on it. As 
we all know, eventually that technology ended up o n the desktop in a commercial form . I would say that 
the Sketchpad implementation of today i s essentially something like a Cray 2 where you generally devot 
e an entire room to a Cray 2 or at least a large part of a room to a Cray 2, and I believe that again, 
within the next 10 -- certainl y 20 years -- that performance and maybe even a bit more tha n that performance 
will appear on people's desktops . When tha t kind of performance gets to people's desktops, that's whe 
n NeXT becomes very interested in it . Our roots are in persona l computing and I believe that's where 
our roots will stay . Now I just want to mention one thing about deskto p computing and ease of use, 
and say that I agree very strongl y with Chris from Apple -- that ease of use is not just mice an d windows, 
that there are some very important aspects that appl y here. And some of the ones that Chris mentioned 
I agree with . Since this is SIGGRAPH, the first -- and I think one of the mos t important -- is that 
user interfaces need to be graphical use r interfaces. This may seem obvious on the face of it, but one 
thing that I like to say is that one very important thing abou t graphical user interfaces is that I 
call them over-the-shoulde r user interfaces, and the reason is that you can stand behin d someone who 
is using a graphical user interface, look ove r their shoulder, watch what they're doing, and learn -- 
prett y much learn how to do what they're doing just by looking ove r their shoulder . They may comment 
a little bit . Now the same thing is not true of command line base d interfaces or any kind of interface 
that relies heavily o n typing. You just can't see what a person's typing in EMACS al l the time . It's 
not a good way to learn how to use EMACS . think this kind of learning of how to use aps and user interface 
s goes on to a tremendous extent, very informally, people showing other people how to use programs . 
It's all predicate d on having a graphical user interface . Second is consistency across applications. 
This is a very important issue right now . A big question is whether yo u optimize for the user who uses 
multiple applications fro m different vendors on the same machine most often, or yo u optimize for the 
user who tends to use the same application, bu t SIGGRAPH '89, Boston, Jul 31 Au ust 4, 1989 kind of 
switches around from seat to seat and uses differen t machines . Obviously, for the latter user, you 
would like th e application in question to have the exact same user interface , no matter which platform 
its running on . However, one thin g that we believe at NeXT, and I think is true, is the the forme r 
case is a lot more common. That is, when someone is sitting down and using the machine, that is generally 
the hardwar e platform that they tend to use almost all the time in a lot o f cases . They don't tend 
to switch around and use five or si x different platforms. What they do do is they switch around and 
use five or different applications, often from different vendors , on that same hardware platform . That's 
the person we would like to optimize for . Now I believe you can optimize with both those cases i f the 
entire world settles on a single standard for user interface . Not only do I think this is not going 
to happen very soon, I also think it may be a little bit premature to standardize on a single user interface 
. There's still a lot of experimentation being done and ideas being tried out. To freeze that in concrete 
at this point would probably be premature . Then the last thing is that there's always an operatin g 
system buried somewhere under the user interface, and it' s important to -- independent of what that 
operating system is -­whether it's Mac OS or OS/2 or UNIX -- it 's important to present something to 
the user that accomplishes the task o f making the simple things simple . Now there are lots of complex 
things that you have t o make sure that there's some way to accomplish them, but the simple things, the 
things he does every day should be simple . In the case of NeXT, sometimes its very trivial things like 
-­ for example, UNIX tends to have this idea of a swap partitio n and you're always having to decide 
how big should your swa p partition be . We didn't think users wanted to worry about that , so we did 
away with the swap partition . There's a swap file tha t grows to be whatever size it needs . You don't 
need to create a special partition . That's something, a change that can be mad e in the operating system 
in order to remove something from the user's worry list . And these kinds of things are very important 
. A lot of operating systems that were designed with that ide a from the ground up -- like the Mac OS 
-- already incorporate a lot of things like that . Other operating systems have had t o maybe change 
a little bit to make things easier on the user . Let me switch to the computers . I actually did my slides 
o n the NeXT computer, and this is compliments of -- this is jus t running Frame here -- and we're actually 
shipping a dem o version of Frame with our 1 .0 software, which will be comin g out in September . I 
use that to make my slides . This is the firs t time I've ever done this . Usually I make real slides 
and us e those. So I figured since this is SIGGRAPH, I ought to at leas t be able to do this . This is 
a snapshot of the NextStep, as we call it --Architecture. And what I want to do is go over each of th 
e components very briefly and explain some of the ideas in the m that are keyed to the topic under discussion 
. That is, th e relationship between the operating system and the use r interface . I'll just mention 
the items and then go into detail . Our UNIX is -- the interface to this UNIX is essentiall y BSD 4.3 
but the underlying architecture uses the Mach. I call it a sub kernel ; it's a small, fast kernel on 
top of which operatin g services are built. The Mach IPC or interprocess communication and threads and 
other Mach features are mad e visible to the programming interface so that you can use those features, 
but other than that, the programming interface pretty much is BSD 4.3 . The DPS or Display Postscript 
Window Server is on top o f that. It's a client server-based Window Server, and I'll b e mentioning a 
little bit more about that . On top of that is th e application kit . That is a library of objects which 
correspond pretty much to the objects you see on the screen -- Windows , menus, buttons, etc . And these 
objects are the raw material fo r creating the user interface of an application. We implement these in 
a shared library so that each Ap doesn't have to pay the penalty of having it in its physical memory 
. There are other kits. For example, we have a sound kit and a music kit currently. We anticipate other 
kits which are kits full of objects that will be used in the future . Interface Builder on top of this 
is actually an application and it is nothing more than an editor -- a graphical editor -- fo r the objects 
in the application kit and other kits as well . Then finally the Workspace Manager is -- I sometimes 
cal l it the Finder Equivalent . It is your interface to the operatin g system and the file system . 
Important features of our operating system -- well, some o f them are like Mom and apple pie . There's 
multitasking, virtua l memory. These actually impact the user interface in that the user no longer has 
to worry about running out of memory fo r the most part . He doesn't have to kind of partition his aps 
an d make sure they all fit into physical RAM . Fast interprocess communication is extremely importan 
t for two reasons . One is you would like to have fast IPC whe n your application talks to the Window 
Server . A client server ­based Window Server -- especially for WYSIWYG like applications -- really requires 
this, because the loop time fo r getting an event, doing some drawing in response to tha t event, and 
waiting for the next event -- that loop time i s critically important in how the user perceives the throughput 
of the application and whether it's a responsive user interface . There are some features -- which I 
won't go into here . Another important feature is the Display Postscrip t Window Server . First of all, 
we concluded very early on that a uniform imaging model for both the screen and printer wa s extremely 
important . Not only does it simplify the programmer's task -- he only has to worry about a singl e imaging 
model -- but there are implications for anything yo u do that's WYSIWYG. You really do want what you 
see on the screen to correspond very closely to what the user ultimatel y prints out. And in the desktop 
market, I would say that the final product ends up being something printed on a piece o f paper or on 
a slide virtually 90% of the time. This is extremel y important on the desktop for the general commercial 
market -­and for the academic market for that matter. We chose a standard imaging model and we chos e 
Postscript. We like the functionality of Postscript . We had a joint development project with Adobe to 
implement Display Postscript and make it faster and interactive, and we're ver y pleased with the results 
there . We support network transparency for our Server. We support multiple Postscript context, the compositing 
mode l with Alpha Channel for bit map operations. It's kind of the logical follow-on for the standard 
and/or not operations whe n you have multiple bits per pixel . So you can have Alph a Channel to specify 
transparency for any bit map . Finally, I already mentioned the fast IPC . We use th e Mach IPC when 
we're talking to our Window server . This is just a graphical depiction of what I just mentioned . You 
have multiple clients all talking to the Window Server , which handles not only drawing, but Window management 
an d event Handling, and runs as a process . Those IPC connection s can either be on the same machine 
or across the network -- tha t is, transparent to the application . The NextStep Application Kit -- its 
an object-oriented ki t for developing NextStep applications . It's the path of leas t resistance for 
the developer . It's the reason why most NeX T applications will have a similar look and feel . The alternativ 
e would be for the developer to kind of roll his own . It turns ou t to me in almost all cases a lot 
easier to just use NeXT menus , NeXT Windows, etc .. etc. All that code is there, and more important, 
the tools to manipulate those objects and put the m into your application interface builder is also there 
. We use the Objective C language for several reasons . I'll just mention a couple important ones . One 
is run time binding . In order to have an Interface Builder application where there's a run/test button, 
you can hit the test button and test out the use r interface portion of your application without an y 
recompilation . We needed to have run time binding . The second issue is minimal damage to ANSI C . There 
are about three syntactic constructs added on to the language . This is nice not only that it's quick 
to learn, but also nice from the standpoint of adding those same constructs to -- so far we'v e added 
them to LISP, we've added them to FORTRAN . There' s now an objective FORTRAN available. Not that we're 
pushing that -- but we think it's extremely important that the object ­oriented part of the system be 
available from any language tha t we support -- not just from C . The NextStep Application Kit -- I already 
mentioned -­contains all of the objects for the user interface. Another ver y important one is the speaker 
listener objects, and we use these for inter-application communication, which is based on Mac h IPC. 
This is the way that we do cut and paste. It's the way that each application can respond to a standard 
set of commands . For example, open, print, save . Also we use this for requests made on other applications 
. For example, we have a Webster application that looks u p words in Webster's dictionary . The Write 
Now word processor , you can click on a word and say request dictionary, and tha t selection is sent 
over Mach IPC to the dictionary application , and it looks up that word. This kind of blurring of the 
distinction between different applications and kind of expanding what you can do in any one application 
is wha t Chris was talking about. I think this is a very important thin g for any architecture of the 
'90s . Then finally, NextStep Interface Builder, which allow s rapid design and implementation of effective 
graphical use r interface . The fact that we use an object-oriented design make s this very easy, and 
since user interface design is alway s iterative -- you always have to build it, try it and build it 
again . It's optimized for reducing this turnaround time -- to chang e menus, to change buttons, to change 
Windows, you clo no t have to recompile your program . You simply drag them aroun d on the screen and 
change the message connections on th e screen and hit the test button and within a second or so, you 
ar e testing out the new user interface . Just a couple issues that I think have already bee n addressed. 
Multitasking causes increased functionality . It is a somewhat more complex model for the user, but I 
think it' s worth it. Inter-application communication -- very important t o blur the boundaries between 
applications . And then just faste r hardware . The majority of cycles, I would say, still on deskto 
p machines with graphical user interface, will continue to go to user interface support, for the most 
part . For the guys doin g spread sheets and word processing, the cycles are not going t o lay-out or 
to the spreadsheet recalcs . Most of the cycles mos t of the time are going to support any user interface. 
And I don't think that's such a bad thing. I think it's a valuable thing we'r e doing in increasing the 
functionality here . Then just to end, the last thing I already mentioned -- these issues about optimizing 
for developers versus optimizing fo r users . I think it's just very important that a user have a consistent 
user interface across all applications on the same platform . Take-home messages: Good, fast IPC is critical 
whe n you're in a client server architecture . A single imaging model -­we think Postscript for both 
screen and printer is essential . This is for 2-D ; I'm kind of leaving out 3-D in color here -- 3-D 
in interactive . Object-oriented design permits rapid interaction in use r interface development, and 
that again is critical so that you r user interface is fun to use, it's pleasant to use, looks nice o 
n the screen, is consistent and also sounds nice . Thank you . Moderato r J . Paul Grayso n Micrograf 
x  Thank you, Bud . A couple of quick questions and the n we'll open the panel for questions from the 
floor . GRAYSON : I'm kind of curious about color and the NeX T machine. It seems to me, as a graphics 
application developer , that we'd need color on your computer before we'd be ver y seriously interested 
in it . Could you address that please ? 'I'RIBBLE: Sure. We are very actively addressing the color issue 
at this time . We have an advisory board which we had for general development of the computer. We have 
a specia l advisory board which is advising its on color . Although I don ' t have any announcement dates 
to give you, there is one thin g that I think is very important to mention, and that is we'v e decided 
to kind of bypass issues of dealing with eight bits pe r pixel in Color Map. We've decided to implement 
color usin g 32 bits per pixel in our base implementation . This i s obviously predicated on memory prices 
continuing to drop . However, I don't see any problem with that in the future . Moderato r J . Paul Grayson 
Micrograf x  Thank you, Bud . Now I'd like to spend the last few minute s taking questions from the 
audience . Anybody who has a question, would you please step to the microphone. Yes, sir. Q. Hello. My 
name is Jarecl Spool. I have a company calle d User Interface Engineering, and my question is to the 
panelis t whose user interface will be for the '90s . GRAYSON: I think I'm confused. Which one are you 
talkin g about ? SPOOL : I would like to tell you about my mother . My mothe r uses -- she's in her forties 
and she uses computers every day . She cooks with a microwave, she steps on the brake in he r Oldsmobile 
and she uses her Money Machine all the time . None of these have consistent user interfaces, yet she 
seems t o be very happy with them . Nor when she bought them did th e salesman talk about when she could 
get a faster processor an d cheaper memory . - SIGGRAPH '89, Roston, July 81 August 4, 1989 When she 
uses them she's mostly concerned about th e tasks that she wants to perform with them, and not the user 
interface of the machine . She tends to think about stoppin g before hitting the car in front of her 
and getting those $30 ou t of the bank . I think many people here are like my mother -- well , somewhat 
-- in that --GRAYSON: Do you have a question ? SPOOL: Yes, I do . I'm getting there. But it has a little 
set-u p -- in that many people here are interested in the tasks they hav e to perform . They want to 
see their cloud structures in 3-D s o they can figure out how to stop airplanes from crashing i n microburst 
storms . They want to see brain tumors visualized . When you have a complicated user interface that require 
s the user and the developer -- who are users in a sense -- to think about the constructs in the user 
interface, they lose a transparency and they have to -- because they're distracted b y the user interface 
. If I have to think about Windows, if I hav e to think about file names, if I have to think about these 
things while I'm trying to solve this task of figuring out where th e micro bursts are, then I'm distracted 
. I am wondering what th e panelists are planning to do in the future to remove thes e distractions so 
that my clients and myself as a user interfac e implementer, I can go and get my users' tasks completed 
. Mike, could you address that question, please ? EDWARDS : If you want a funny story, you think consisten 
t user interface is important do you ever rent cars from ca r agencies ? SPOOL : All the time . EDWARDS 
: Have you ever had the experience, you get in the car, and you can start it up. There's usually a place 
to put the key that's fairly obvious. And you drive off down the freeway and then it starts to come to 
rain . And it's a serious poin t because this happened to a friend of mine coming up from Miami in the 
summertime when it tends to rain in Florida in the summer. There he was in the outside lane on the freeway 
and i t comes to rain and he can't find the wiper switch . So he pull s across six lanes of traffic -- 
just straight across -- and has t o scream to a stop on the side of the road. Otherwise, he'd hav e crashed 
. It's deadly serious . Because every car is different . They don't have consistency, and where consistency 
become s important is where you have to make transitions from on e thing to the next. When you're renting 
cars, you typically en d up in a car you've never been in before . Unfortunately, the ca r manufacturers 
have never come to an agreement on how to la y things out. So you don't know where they are. If you're 
sensible like me, you sit down and work it out in the car lo t beforehand, but not everyone does that 
. The same thing I would like to point out about computer s is that you're using multiple things on one 
computer . You are making transitions from one application to the next . It's not a good idea to have 
to relearn every time you come to a ne w application. That's where the consistency is necessary. I agree 
that it's a good idea if you can make the user interface a s transparent as possible, that it shouldn 
't get in the way of what you're trying to do . I mean, it wouldn't be a good idea in a car to put the 
gea r changer in the back. That would be silly. But to have a degree of consistency when you're making 
these transitions from on e application to the next is vital . Otherwise, people ge t confused, lost 
and get annoyed . And to some extent that's th e kind of environment we've had in the past . GRAYSON 
: The next question, the gentleman to my left . Q . Hello. My name is Lens Akeman from the University 
o f Guelph. My question is to all of the panelists, and that is no t word one has been said about what 
our university thinks is going to be the predominant one which is the OSF Moti f interface, and where 
that comes in for us is that we have a real problem that we have PCs on researchers' desks -- big UNIX 
boxes without any interface, and UNIX graphics workstation s and all of our researchers are very bright 
people who still get confused with all of these different things . Contrary to th e belief that not one 
interface will work across all of thes e things. I think it's absolutely necessary -- at least for our 
kin d of environment -- that there is one interface that does work across all these platforms, as well 
as the applications . GRAYSON : Martin, would you mind addressing that ? DUNSMUIR : Yes. I'm not quite 
sure exactly what the question is . I think he was just reiterating what we've all bee n saying. As far 
as OSF Motif is concerned, I mean that' s definitely a step in the right direction . I was involved in 
tryin g to convince OSF successfully that they should adopt P M behavior . One thing that I can say is 
that it's only half th e story. I mean, the OSF Motif product provides the same behavior as Presentation 
Manager, in the sense that when yo u sit down at the machine you know what to do . For the applications 
developer, there is still a difference . mean, the applications for the API is very different from Presentation 
Manager, and that's something that I think need s to be rectified . So yes, it would be great if everyone 
coul d standardize around things, and in time they maybe will. I agree 100% with what's being said . 
I think that we've said enoug h about this subject . GRAYSON : We only have time for one more question, 
so I' d like to give the gentleman on the right an opportunity . Q. My name is Jean Byrd . I'm from 
RPI Systems . What' s your market segment? Are you going to compete against sa y Sun, SGI, HP, and the 
new IBM graphics series that's comin g up soon ? GRAYSON: I'm not sure who you're addressing the questio 
n to . BYRD : Actually, all four of you . GRAYSON: Can you make a quick response ? EDWARDS : I didn't 
understand all the question . Could you -- BYRD : Basically, are you going to stay with the PC standalone 
market, or are you going to compete against highe r end graphics workstations as we see them today ? 
EDWARDS : If you want my view, then OS/2 and Presentatio n Manager will compete everywhere . BYRD : Including 
IBM's upcoming graphics series? IBM i s going to have low ends, mid ends and high ends graphic s workstations 
coming up . EDWARDS : Right. We will look to have OS/2 Presentatio n Manager running on the range of 
IBM systems, and that wil l include, of course, providing graphic front ends for things like the high 
end and the midrange series as well, so tha t applications will be able to talk PM wherever they run 
on IB M systems. That is the aim . GRAYSON : Any of the other panelists like to make a comment ? ESPANOZA 
: Apple was one of the first companies to make personal computers -- or to participate in the definition 
of what a personal computer is. We've always made personal computers and I don't see us changing from 
making personal computers . Now what we want to change is what the average person can d o on a personal 
computer without becoming a workstation jockey, and that's our objective . GRAYSON: Thank you very much 
for joining us. The speakers are going to be moving to Salon J, if you'd like t o continue to ask. a 
few questions . We have to vacate the roo m for the next conference . Thank you very much .  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>77293</article_id>
		<sort_key>295</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[Preparing for the future]]></title>
		<page_from>295</page_from>
		<page_to>332</page_to>
		<doi_number>10.1145/77276.77293</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=77293</url>
		<abstract>
			<par><![CDATA[Welcome to Preparing for the Future, a panel on educational issues in computer graphics. The field of computer graphics education, as no other, combines the disciplines of science and art, and in this sense presents computer graphics instructors in both art and science with some unique problems not faced by their counterparts in other fields.As computer graphics courses become a standard addition in art and science curricula, the way in which we prepare students for this evolutionary field is changing.This panel explores the methods of establishing computer graphics curriculum and maintaining these programs. Panel members will share curricula developments and goals, its integration with existing courses, plan growth, raising monetary resources, hardware and software selection, and various educational issues.This session's panelists come from varied backgrounds -- private and public institutions with limited and unlimited resources to share their experiences with you.The first panelist will be Wayne Carlson, an assistant professor in the department of computer and information science at the Ohio State University.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>K.3.2</cat_node>
				<descriptor>Computer science education</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>K.3.2</cat_node>
				<descriptor>Curriculum</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.0</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003456.10003457.10003527.10003530</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing education->Model curricula</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003527.10003531.10003533</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing education->Computing education programs->Computer science education</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P182731</person_id>
				<author_profile_id><![CDATA[81332521419]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Plazzi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rutgers University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31071694</person_id>
				<author_profile_id><![CDATA[81100379189]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[W.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Carlson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14206111</person_id>
				<author_profile_id><![CDATA[81100597261]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lucas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bowling Green State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P183652</person_id>
				<author_profile_id><![CDATA[81100387185]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schweppe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[School of the Art Institute of Chicago]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P185267</person_id>
				<author_profile_id><![CDATA[81100630491]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yanilmaz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Northwestern University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
      SIGGRAPH '89 PANEL PROCEEDING S fide program . It gives you a little bit more weight, and 
legitimizes your efforts quite a bit more . So practically from clay one, that was what we started t 
o do. There are honor stories about where we were going to ge t money and what we were going to spend 
it on. I think most of our disagreements had to do with what we were going to spen d money on if we got 
it . We never disagreed that we needed money. We were in total agreement there. What kind of hardware 
we needed and what software would be used, and it was always something we bantered about, and I think 
that's good . I think it's probably good . We didn't have a singular mindset s o it allowed us the ability 
to bounce ideas off each other an d really find out what we needed . The program since then has developed 
into a major, as I say; it's an undergraduate degree. We have five courses o n record ranging from the 
introduction classes where we cover th e basics, the fundamentals . Many of our students are bein g introduced 
to a computer for the first time, let alone compute r graphics as a medium/art fonn, and working all 
the way up t o three dimensional computer data building and animation . The lab -- or labs, because we're 
now in two separate labs -- has been built, if you will, near to the division of design . It's not a 
part of division of design . But it was one of ou r earlier realizations that we needed to be -- at least 
at that time -­under the wing of a friendly department . And at that time, th e majority of students 
at Bowling Green School of Art who wer e taking the existing computer graphics classes were design majors, 
as opposed to the fine arts areas . That is evening ou t now. But I think understandably so, the students 
who wer e going out into a commercial environment felt that the need t o experience electronic imaging 
was more important perhaps than the fine artists did at that time . So we worked with our own design 
division . We wanted an ally. This came in handy in a number of ways. Politically, i t was nice to have 
somebody in your corner when you had to si t clown in the trenches and talk about how the budget was 
goin g to be divided up for that year -- who was going to get what , where the monies would be spent, 
how much should th e photography department get, what about computer graphics ? Oh, yeah, well they're 
not really a degree program, so it doesn' t matter. Our first realization of the beneficial aspects of 
being a part of an established department, like the design division , came when we first attempted to 
write a grant for what for u s was a large amount of money . The Ohio Board of Regents gran t requests 
had come out and again I'm going back two and a hal f to three years . Our grant was drafted and was 
endorsed by th e design department, which again gave it legitimacy, and also i n truth, since our facility 
-- our physical space was in essence a part of the design department, the hardware that we woul d purchase 
with the money was going to be under the umbrella -­the responsibility umbrella of the design department 
. It worked out well . We were looked upon favorably tha t year. The money -- the pittance of $55,000, 
which is what we were asking for and we thought that was a lot -- was granted t o us . We bought a number 
of Amigas, we invested in Atari STs , we have -- by the way, we have five Amigas, 20 Atari STs wit h 
40 meg hard drives, a couple of melts of ram on thos e machines. We also have six IBM PC ATs that we're 
running , Time Arts Lumina 2-D software on, and the 3-D program usin g is West End Films 3-D sculpting 
and animation program . The software we use on the Ataris and on the Amiga's ar e off the shelf software 
-- Sculpt 3-D, Sculpt Animate . And Cyberpaint and CyberCAD on the STs . These may be familia r to some 
of you out there . In any case, we have developed two separate labs - - one fo r the first and second 
year students, one for the second and third year students. With that we were able to I think visually 
creat e an image that we meant business . And working in tandem, Ro n Coleman and myself, I think we 
did -- we broke clown a lot o f the barriers. We were able to get people's attention for the firs t time 
. Ultimately we began to develop a curriculum that w e knew would be necessary to request an undergraduate 
degree . It was a year and a half requesting it. lt took about thre e months to draft the curriculum, 
and we made a few modification s and we went before the Curriculum Committee a number o f times. I was 
the head of that committee at the time, so we had an in there . But we had to pass -- we had to jump 
through man y hoops, and that request went all the way to the Ohio Board o f Regents, and that took over 
a year -- a year and a hal f approximately before it was finally approved and we were thrilled , Not 
surprisingly, we are now considering the possibilit y of a graduate program -- why not? The problems 
we had with money for a state university ou r size aren't surprising . There's never enough there . State 
universities have just so much . We've stopped whining abou t where the money is coming from . We know 
the school has jus t so much and we now look to outside sources . We are in contac t all the time in 
net-working with retail outlets. They occasionally donate software and hardware to us . We're i n touch 
and woo quite closely, computer graphics servic e companies in and around our university . That helps 
us in term s of getting software donations, as well as having them give ou r students valuable internships 
and in many cases full-time jobs . So that works out pretty well . I'm running out of time here . I never 
seem to be able to get enough into what time is allotted me . What I want to talk about, as I get down 
to the last fe w minutes here, is an ironic goal that both Ron Coleman and I have for the development 
of our computer graphics resource o r degree program, as it now stands . What we envision in the next 
-- this is a guess -- the nex t 10 years -- and what we hope will happen is that there will b e no computer 
graphics department . We know that it's necessary now. We are the vanguard at our university and I think 
the computer graphics departments or labs at any university are no t just resources for electronic imaging, 
but they stand for tha t first line of defense in support of what ultimately could b e considered a new 
art form. It's certainly a separate media fro m the traditional techniques used in schools of art and 
design . But ultimately we don't want it to become a white tower . To call it computer graphics, to give 
its own separate lab, t o keep it separate from everything else, I think in the long run i s not good 
. What we hope will happen and what we will strive t o accomplish over the many years that we may work 
together, i s that the computer facility will break down and be absorbed b y the design department, the 
painting department, the departmen t of sculpture, printmaking -- so that we will find the resource s 
presently locked and under guard in these two labs that we hav e ,in every department . It will become 
second nature . Our students will simply initiate much of their work in their give n field, using electronic 
imaging . Whether or not it' s photography . they could be doing digital imaging . Whethe r it's printmaking 
. That's ultimately our goal . But unfortunately, to get tha t far we have to build a strong department 
to justify that. So PREPARING FOR THE FUTURE               SIGGRAPH '89 PANEL PROCEEDING 
S the end of the hallway down here . I can't really even see anything . Q . I don't have a question . 
I just want to I guess give the people who will teach at colleges a message, and that is tha t I'm a 
high school art teacher and I think it's real important fo r the colleges and the high school to communicate 
because w e started a program in computer graphics three years ago, and w e use the Amiga 1000, and we 
offer a year of computer graphic s and paint systems and image processing, and then the secon d year 
in computer animation -- hopefully, 3-D design . But I just wanted to let you know that the high schools 
are starting to d o this and the elementary schools are starting to do this, and that there should just 
be an open communication so that the colleges know what's happening out there in the high school s because 
you're going to be getting some kids that are really , really ready for this stuff and really high powered 
compute r graphics. PALAllI : I think that's great to hear, and I guess probabl y most of us know that's 
coming up . Some of us up here even have children who probably are starting to type on the keyboards 
now . I can say for us at Rutgers Camden, thi s summer we already had two high schools come down and 
we'r e starting a network with some area high schools around us s o that we can share information because 
a lot of the high school s are using Amigas around us, and we're really excited about tha t possibility 
. Q . My name is Vera Kaminsky . I'm at the University o f Delaware Art Department. I'd like to thank 
the panel for sharing their insights and pioneering experiences in academi a in setting up these kinds 
of programs . It brought home th e quote from Cray in the Computer Graphics Museum for m e today where 
he said he never wanted to be a pioneer ; it's alway s better to come in second because then you got 
to tak e advantage of the work of those who had been ahead of you . My question is directed to people 
who had develope d introductory courses in computer graphics or computer literac y and visual literacy 
-- in efforts to try and sift out and search i f you've done any studies of what I'll call the carryover 
o r synthesis effect, and to know if your labs permit students or i f you have the opportunity and space 
to permit students wh o have taken an introductory course, to come back and solv e problems that they 
may be trying to come up with solutions , but in traditional courses where the professors who teach thos 
e courses may not -- they may be very famous in what they do i n the studio, but they may not be computer 
fascile themselves . Do students who have had an introduction -- are they able to come back? Are they 
able to carry over the information tha t you've introduced? I'm not just targeting it towards art students 
because there was the mention of business students coming an d taking introductory graphics courses . 
Can your studio in it s 24-hour operation permit a student who isn't currentl y registered to come in 
and solve a problem, and do they do that , and at what point, if any, does that happen ? LUCAS : I'll 
start . I'll respond to that first at least . Speaking from my program, yes ; we do our best . The program 
is -- as I think everybody's is eventually interdisciplinary, and what w e try and do at Bowling Green 
when we develop a curriculum fo r any individual course -- and there's a trick to this -- is to keel) 
the structure of that curriculum just soft enough . It's detailed enough to satisfy the needs of a curriculum 
committee who needs a structure -- before they approve, of course -- but just soft enough to allow elbow 
room and flexibility, so that in ou r case students come to us from the various departments . Thes e 
are students who are not majoring in computer graphics necessarily, but are still taking our courses, 
and can take ou r problems and solve them in their own field of endeavor, thei r own unique way. Yes, 
for example, there are people in ou r program who will come to us with paintings half clone , continue 
working on them through an electronic medium, usin g digitizers, using paint programs, bringing 3-D application 
s into it, and then outputting it out at the video end or a fil m recorder, and then continue the work 
in another medium -- back into canvas, for example . We do that, and it's a good question . CARLSON : 
We have a lot of students who are in paralle l areas, as well, in numerical analysis, for example . Som 
e students have taken the graphics renderers that they hav e written and done analysis of algorithms, 
display of th e performance of algorithms as well. We're limited by the fact that our interactive computing 
facility is only open to thos e people who are actively involved in courses for reasons o f security 
of the system, etc ., etc . So someone couldn't, as a n example, take the graphics course and then use 
th e environment (INAUDIBLE) school without someho w registering for a course in computer science. SCHWEPPE 
: We have a similar situation . We would love to keep our facilities open for anyone in the school to 
use them , but we don't have the kind of maintenance money an d equipment money that would support that 
. I think possibly at some point we will have. It's been proposed. I don't know how soon that might happen 
. We encourage people to do projects which are integrate d with other classes that they're taking at 
the time or with thei r major, and adapt the projects to their own needs instead o f necessarily sticking 
strictly with the projects that are assigned . They have to let you know in advance what they'd like 
t o do instead of the assignment that you gave, so that you have a n opportunity to make sure that it 
covers the material that's there to be covered and the reason that you picked the assignment to begin 
with . But we try to keep it as flexible as possible and ge t a lot more interesting results that way 
. Then it's real open i n terms of somebody has an idea of a project they want to do . They can propose 
it and almost always get some kind of facult y support for carrying the project out . PALAllI: We're 
also starting to get the faculty involved i n coordinating some of the assignments too . So between -- 
for instance, graphic design . Maybe some of the students that have already had the experience on the 
computers are almos t forced in a way to come in and use the computer as a way t o communicate whatever 
that assignment might be . So again, we too try to keep it as flexible as possible, and we see students 
that already have experience in the lab being willing to share their knowledge with students that come 
in that really aren' t too familiar with the computers, but students that want to solv e a problem and 
think the computer might be a good way to do it . Q . I have a question . I'm Charlotte Wells with the 
U .S . Geological Survey in Reston, Virginia. Two parts. Most of you are either with a computer science 
background, art o r engineering . Have you had any interest in your respectiv e schools from the communication 
departments or your busines s departments as a tool in those areas. And number two , regarding internships, 
several of you have mentioned th e importance of those . Do you as a school actively go out an d seek 
those or do you wait for the business community to approach you to establish an internship? Are they 
salaried or unsalaried ? SCHWEPPE : At the Art Institute we have a real active co-o p program where there's 
a department of people who activel y PREPARING FOR THE FUTURE SIGGRAPH '89, Boston, Jul 3A4,1989 seek 
potential co-op jobs for students, and in the past year the big push has been in the area of art and 
technology or compute r graphics type jobs . And they are paid ; almost all of them ar e paid. Occasionally 
one won't be paid if it's at a place wher e someone would be willing to work if they were not paid . 
We also have all our full-time students, but we have a fai r number of people who come as students at 
large who ar e involved in business or some other kind of business, and d o take our classes in order 
to become proficient on the computer . LUCAS : I'll add to that that on the reverse side of that same 
coin, our program requires that our majors take thos e communication classes in another part of the university 
-- VC T -- visual communications technology is an area separate fro m the School of Art, where communications 
is taught fro m broadcast radio, television and film . Because we're a youn g program, I can't say that 
we get many of their students . We get one or two who come over interested . But all our students mus 
t go over there and take at least six credits of their courses . No t so in business, however . But in 
the communications, yes . PALAllI: Our internship program is also within ou r department, so we aggressively 
seek out employers or internship opportunities for our students . Some are paid, som e are unpaid, and 
that's up to the student I guess to decide or wor k that out with who the employer is, but we try to 
make sure and screen who the employers are going to be so that its a valuabl e internship experience, 
rather than I guess just like a gopher o r a coffee-maker in the morning . So that becomes really important 
to us because the studen t is getting school credit for it and we want to make sure it 's that kind of 
an experience . As far as other departments that weren't involved, we don' t have or haven't seen any 
interest from our communication s department, although there is a small T.V. station being started up 
now on our campus, and they have shown some interest in what we're doing . We also have interest from 
the psychology department , who's interested in doing some experimentation with colors and color theory 
. So we're talking to them right now about working with them . Q . I had a question about hard copy devices. 
I guess yo u alluded -- Maria alluded to having videotape equipment . No one else really said anything 
about it and I just wondered if people could comment on what facilities they have for that . CARLSON 
: Right now all we have is a Colorscript printe r and we've got in proposals of various camera devices 
fo r output, but currently only the color printer . LUCAS : We have similar equipment . We're not happy 
base d upon our economic situation and what we can afford . We're no t happy with the quality of hard 
copy . I don't think that's a bi g surprise . We output to video and when we need good copy -­and we 
do, by the way, shoot off the screen to get -- after a while you can get pretty decent transparencies 
that way . We will send our discs out. We have a variety of resources that w e have simply found in magazines 
and trade journals, to have ou r disks sent there and have hard copy output -- eithe r transparencies 
or print, even video -- to come back to its whe n we need it . That's a big investment -- to get a decent 
syste m that will do that, and right now we're borrowing from Peter t o pay Paul . So we're not willing 
to spend that kind of money o n decent output yet, although we're looking here at SIGGRAPH a t optical 
disk output. We think that's probably our nex t investment. SCHWEPPE : We have a Dunn camera, which we 
take 3 5 millimeter slides and 16 millimeter film width, and we also have a three-quarter inch deck for 
single frame recording and we have several different printers . We have Inkjet printers an d then we 
have some older printers . Some of them have color ribbons, some of them are just black and white, and 
particularl y with the older ones, we do some other techniques like makin g our own carbon paper using 
pastels and layering it with anothe r piece of paper and putting it through the printer . You have t 
o clean the printer rather frequently . Just we try all differen t kinds of experiments with whatever 
equipment we happen t o have available . YANILMAZ: In my case at Northwestern University we have some 
lnkjet printers and we have some laser printers and som e other -- another printer that I have available 
for very larg e scale integrated circuit layout, which I also tied it up to th e computer graphics equipment, 
and if for any reason we have any problem with that, we always can send our files to the major computing 
facility of the University and they also have a series of Inkjet printers and some laser printer plotters 
an d some other type of equipment, but we do not have -- in our department -- any video output at this 
point . PALAllI: We have a 35 millimeter recorder also . Right no w basically it works with our artronics 
system . We're trying t o figure out some sort of interface to work with the Amiga . We just purchased 
a color Inkjet printer and Apple was kind enoug h to loan us a laser printer, and I guess pretty much 
like Rick , we're really unhappy with just hard copy output in general . I'm looking for a better solution 
. It seems really terrible to ask ar t students to be trapped into an 8-1/2 x 1 1 piece of paper, and 
I guess we're trying to find a way around that right now . We're interesting in pen plotters and looking 
into that, but onc e again, you run into the financial problems . So it's an ongoing problem for us, 
along with the resolution of the Amiga, whic h causes another problem, as far as output goes . So again, 
w e certainly haven't solved the color output . PREPARING FOR THE FUTURE 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
</content>
</proceeding>

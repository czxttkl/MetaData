<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date></start_date>
		<end_date></end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[]]></city>
		<state></state>
		<country></country>
	</conference_loc>
	<conference_url></conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES382</series_id>
		<series_title><![CDATA[International Conference on Computer Graphics and Interactive Techniques]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>37401</proc_id>
	<acronym>SIGGRAPH '87</acronym>
	<proc_desc>Proceedings of the 14th annual conference</proc_desc>
	<conference_number></conference_number>
	<proc_class>conference</proc_class>
	<proc_title>Computer graphics and interactive techniques</proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn>0-89791-227-6</isbn>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>1987</copyright_year>
	<publication_date>08-01-1987</publication_date>
	<pages>352</pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<publisher>
		<publisher_id>PUB27</publisher_id>
		<publisher_code>ACMNY</publisher_code>
		<publisher_name>ACM</publisher_name>
		<publisher_address>2 Penn Plaza, Suite 701</publisher_address>
		<publisher_city>New York</publisher_city>
		<publisher_state>NY</publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>10121-0701</publisher_zip_code>
		<publisher_contact>Bernard Rous</publisher_contact>
		<publisher_phone>212 869-7440</publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url>www.acm.org/publications</publisher_url>
	</publisher>
	<sponsor_rec>
		<sponsor>
			<sponsor_id>SP932</sponsor_id>
			<sponsor_name>ACM Special Interest Group on Computer Graphics and Interactive Techniques</sponsor_name>
			<sponsor_abbr>SIGGRAPH</sponsor_abbr>
		</sponsor>
	</sponsor_rec>
	<categories>
		<primary_category>
			<cat_node>I.3.0</cat_node>
			<descriptor/>
			<type/>
		</primary_category>
		<other_category>
			<cat_node>I.4.0</cat_node>
			<descriptor></descriptor>
			<type></type>
		</other_category>
	</categories>
	<ccs2012>
		<concept>
			<concept_id>0.10010147.10010178.10010224</concept_id>
			<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371.10010382</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371.10010382.10010383</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Image processing</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
			<concept_significance>500</concept_significance>
		</concept>
	</ccs2012>
	<general_terms>
		<gt>Design</gt>
	</general_terms>
	<chair_editor>
		<ch_ed>
			<person_id>PP39112911</person_id>
			<author_profile_id><![CDATA[81100388123]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>1</seq_no>
			<first_name><![CDATA[Maureen]]></first_name>
			<middle_name><![CDATA[C.]]></middle_name>
			<last_name><![CDATA[Stone]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[]]></affiliation>
			<role><![CDATA[Editor]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
	</chair_editor>
	<ccc>
		<copyright_holder>
			<copyright_holder_name>ACM</copyright_holder_name>
			<copyright_holder_year>1987</copyright_holder_year>
		</copyright_holder>
	</ccc>
</proceeding_rec>
<content>
	<article_rec>
		<article_id>37403</article_id>
		<sort_key>15</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[1987 Stephen A. Coon's Award]]></title>
		<page_from>15</page_from>
		<doi_number>10.1145/37401.37403</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37403</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor>Biographies/autobiographies</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>K.2</cat_node>
				<descriptor>People</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003456.10003457.10003521.10003522</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->History of computing->Historical people</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122.10002948</concept_id>
				<concept_desc>CCS->General and reference->Document types->Biographies</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P241413</person_id>
				<author_profile_id><![CDATA[81407594230]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Beach]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37404</article_id>
		<sort_key>16</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[1987 ACM/SIGGRAPH Achievement Award]]></title>
		<page_from>16</page_from>
		<doi_number>10.1145/37401.37404</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37404</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor>Biographies/autobiographies</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>K.2</cat_node>
				<descriptor>People</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003456.10003457.10003521.10003522</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->History of computing->Historical people</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122.10002948</concept_id>
				<concept_desc>CCS->General and reference->Document types->Biographies</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P241413</person_id>
				<author_profile_id><![CDATA[81407594230]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Beach]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37405</article_id>
		<sort_key>17</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[A muscle model for animation three-dimensional facial expression]]></title>
		<page_from>17</page_from>
		<page_to>24</page_to>
		<doi_number>10.1145/37401.37405</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37405</url>
		<abstract>
			<par><![CDATA[The development of a parameterized facial muscle process, that incorporates the use of a model to create realistic facial animation is described.Existing methods of facial parameterization have the inherent problem of hard-wiring performable actions. The development of a muscle process that is controllable by a limited number of parameters and is non-specific to facial topology allows a richer vocabulary and a more general approach to the modelling of the primary facial expressions.A brief discussion of facial structure is given, from which a method for a simple modelling of a muscle process that is suitable for the animation of a number of divergent facial types is described.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010342</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Model development and analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010342.10010344</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Model development and analysis->Model verification and validation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P159188</person_id>
				<author_profile_id><![CDATA[81100026581]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Keith]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Waters]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Middlesex Polytechnic, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>806812</ref_obj_id>
				<ref_obj_pid>965161</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Badier N I "Animating Facial Expression" Proceedings Computer Graphics 1981 Vol 15 No 3 245-252]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Boston D W "Synthetic Facial Communication" British Journal of Audiology 1973 Vol 7 95-101]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15892</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Oppenheimer P E "Real.Time Design and Animation of Fractal Plants and Trees" Proceedings Computer Graphics 1986 Vot 20 No 4 55- 64]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Parke F I "A Parameterized Model for Facial Animation" IEEE Computer Graphics and Applications 1982 Nov]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Parke F I "A Parameteric Model for Human Faces" Technical Report UTEC-CSc75-047 University of Utah 1984]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Parka F I "Measuring Three-Dimensional Surfaces with a Two- Dimensional Data Tablet" Computer and Graphics 1975 Vol 1 5- 7 Pergamon Press]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Bergeron P "Techniques for Animating Characters" Advanced Computer Animation Course Notes Siggraph 1985]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Duncan J P "Anatomical Definition and Modeling" Engineering in Medicine 1986 Vol 15 No 3]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Ekman P and Friesea W "Unmasking the Human Face" Prentice Hall Inc 1975]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Ekman P and Friesen W "Manual for the the Facial Action Coding System" Consulting Psychologist 1977 Press Palo Alto California]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Frornkin V Lip "Postions in English American Vowels" Journal of Language and Speech No 7 215-225 1964]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>906875</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Gillension M L "The Interactive Generation of Facial Images on a CRT using a Heuristic Stratergy" PhD Thesis Ohio State University 1974]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hight R L Lip Reader Trainer: "A Computer Programme for the Hearing Impaired" Proc. John Hopla'ns, First National Search for Application of Computing to Aid the Handicapped. IEEE Computer Society 1981 LA 4-5]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Kelso et al "A qualitative dynamic analysis of reiterant speech production: Phase portraits, kinematics and dynamic modelling" Journal of Accoustical Society American Vol 77 Nol 1985]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Moore J "Towards an Integrated Computer Package for Speech Therapy Training", "Taiking Heads". Microtech Solutions Report Bradford College of Art and Design 1986]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Summerfield Q "Roles of the Lips and Teeth in Lipreading Vowels" Proceedings of the Institute of Acoustics 1984]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Summerfield Q "Analysis, Synthesis and Perception of Visible Articalatory Movements", Academic Press lnc 1983]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Warwick R "Grey's Anatomy" 35th edition Longman 1973]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Waters K "Expressive Three Dimensional Faces" Procceedings Computer Graphics Online Wembley 1986]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Wood P D "An Interactive Graphics System for Planning Reconstructive Surgery" National Procceedings Computer Graphics Association Chicago 130-135 1986]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>911638</ref_obj_id>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Zelter D L "Representation and Control of Three-dimensional Computer Animated Figures" PhD Thesis Ohio State University 1984]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 21, Number 4, July 1987 A Muscle Model for Animating Three-Dimensional Facial 
Expression Keith Waters "P Animation Research and Development National Centre for Computer Aided Art 
and Design Middlesex Potytechnic England Abstract The development of a parameterized facial muscle process, 
that incorporates the use of a model to cream realistic facial animation is described. Existing methods 
of facial parametedzation have the inherent problem of hard-wiring performable actions. The development 
of a muscle process that is controllable by a limited number of parameters and is non-specific to facial 
topology allows a richer vocabulary and a more general approach to the modelling of the primary facial 
expressions. A brief discussion of facial structure is given, from which a method for a simple modelling 
of a muscle process that is suitable for the animation of a number of divergent facial types is described. 
Cr Categories and Subject Descriptors:I.3.7 [Computer Graphics]: Three dimensional Graphics and Realism-Animation 
1.3.5[Computer Graphics]:Computational Geometry and Object modelling - Curve, surface, solid and object 
representations. 1.6.4 [Computer Graphics]:Simulation and Modelling-Model Validation and Analysis General 
Terms: Animation, Facial Expression. Additional Keywords and Phrases: Minimum Set System, Digitization. 
 ~" Middlesex Polytechnic Cat Hill Barnet Herts England 01 440 5181 Permission to copy without fee all 
or part of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM copyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, 
or to republish, requires a fee and/or specific permission. &#38;#169; 1987 ACM-O-89791- 227-6 / 8 7 
/ O07 [O017 $00.75 1. Introduction There are two fundamental approaches to three-dimensional facial animation: 
key framing and parameterization [4][7]. Each has been exploited with varying degrees of success, but 
both have drawbacks. Key framing requires the complete specification of the model at each extreme, or 
at least the storage of the differences between facial positions [15]. Additionally, any unique subtle 
movement of the face must be constructed as a complete model, with the result that key framing is data-intensive 
and lacks specific manipulation. Parameterization avoids this problem of rigidity by grouping vertices 
together to preform specified tasks. However, generality is lost as soon as the process is applied to 
a new facial topology. Only by maintaining the same topological mesh will the parameterization hold tn/e. 
Investigation by Parke [4] on the conformation of faces deals with the problem of utilizing these constraints, 
but it is doubtful whether the generality of such a topology will hold true over a wider range of facial 
types. Facial parameterization techniques have dealt principally with the surface characteristics of 
the skin and have not been concerned with the motivators of the dynamics. Investigations by Badler [ 
1] into the structural bases for the upper face dealt with the elastic nature of muscle and skin. The 
process is iterative in nature and deals adequately with the motivators of the actions. However, the 
complexities of the lower face jaw rotations render the processes unperformable. It is evident from such 
investigations that the motivators of the dynamic characteristics are complex, and that a simple and 
more general approach needs to be taken if muscle parameterization is to st~cceed. This present research 
is concerned with the development of a more general and flexible muscle model for parameterization that 
will allow facial control without the requirement for hard-wiring the performable actions. 2, Motivation 
The diversity of facial forms in terms of sex, age and race is enormous. It is these forms that allow 
us to recognize individuals and send complex non- verbal signals to one another. For the deaf and hard-of-hearing 
the face is a vital mode of communication, with the majority of attention placed on the observation of 
the lips [16][11]. As a result, a variety of models have been developed to imitate the actions of the 
lips [13]. Evidence from reasearch by Quentin Summerfield [17] for the deaf and hard- of-heuring has 
shown that real people speaking are unsatisfactory subjects for experiments into visual speech perception, 
because real people cannot produce specific and graded articulatory gestures. Furthermore it is evident 
that bi- or multi-modal emphasis in teaching the deaf tip reading should not be undervalued, as we are 
predisposed to relate what we hear to what we see. Computer pre-operative surgical techniques need to 
determine the mobility remaining in the face after surgery. Surgical reconstruction of faces [20] uses 
a number of techniques to collect three-dimensional data: Moire patterning, lofting of CAT or EMR scans 
and lasers. The resultant data can vary enormously from one face to another, and so any resultant parameterization 
would, at best, be tedious to implement. [7  SIGGRAPH '87, Anaheim, July 27-31, 1987 I~~1 The facial 
muscle process described in this paper avoids direct hard-wiring of performable actions to the data slructure, 
and offers a simple method to determine the motional bounds of the key facial nodes. 3. Developing parameter 
sets for the face Parameterization is the most desirable method of generating and controlling complex 
articulated models. Isolating the appropriate parameters to use for the face is perplexing but fundamental. 
Inanimate objects, such as the geometric primitives, "cube, cone, sphere", can be described in terms 
of width, length, height, diameter, coloar, weight and material, that represent basic parameters. The 
advantage of this approach allows concise criteria to encapsulate every member of that group or class. 
Few living forms can be determined by such precise parameters. Trees [3] and other recursively generated 
forms seem to be the only objects belonging to such bounded sets, and consequently they can be created 
from a small kernel of data that is easy to produce. Unfortunately the inherent nature of the face does 
not allow the formation of such discrete criteria, where the terminating description of an unbounded 
class becomes vague and is usually discerned by the resulting visual image. The Minimum Set System [19] 
accepts the complexities of the unbounded class and describes the smallest number of parameters required 
to preform definable facial expression. It remains very difficult to extract the necessary facial parameters 
from real faces. The individual facial muscles beneath the skin (and the deeper layered muscle) have 
not been accurately measured. Work by the nineteeth century physiologist Duchenne, applied electrical 
currents to freshly guillotined heads to observe the facial contortions. Later he applied the same techniques 
to old inmates of alms houses to create artificial expressions. In 1906 Sir Charles Bell, the anatomist, 
illustrated the mechanisms of the major expressions in his book Anatomy and Physiology of Expression, 
and, as he explained, a muhimde of processes coalesce to produce what we instinctively recognize as an 
expression. This being the case, it is still open to question as to whether there are techniques to extract 
the necessary facial parameters from actual faces. Investigations by Quentin Summerfield [17] into the 
perception of visible articulatory movements measured the face using video tape techniques. Three major 
problems were encountered. Firstly, an axis frame must be defined to which the measured movements may 
be referred. Secondly, movements of the primary articulators such as the lips and jaw must be separated 
from the effects of global movements. Thirdly, the measurements must be sensitive since, relative to 
the size of the head, significant articulatory excursions are small and seldom exceed about 25mm. Despite 
these inherent problems, reasonable results were obtained that describe the surface displacements of 
the skin. Figure 1 The Action Unit AU1 activates the inner brow miser pulling the inner frontalis muscle. 
This action, with the combination of wide eyelids, pupils dilated, jaw rotated and the angular depressor 
pulled, displays the appearance of fear.  Significant work by Paul Ekman and Wallice Friesden, psychologists 
of non-verbal communication, created The Facial Action Coding System (FACS) [10], which is a notational-based 
environment that determines emotional states from the visible facial distortion. Individual muscles, 
or small groups of muscles, are described as Action Units (ALl) that distort the skin tissue. This appears 
to be the best technique for the extraction of facial parameters useful for computer synthesis. /  Figure 
2 The Action Unit AU9 activates the Levator labii superioris alaqne nasi muscle that runs from the zygomatic 
process to the upper lip. When it is activated the skin around the nose is pulled up dilating the nostrils 
and sometimes raising the upper lip. The fifty independent facial actions can give rise to to several 
thousands of muscle combinations. The facial muscles can be trained, but activating them alone is not 
visually communicative. Six categories are described by Ekman [9]: Anger, Fear, Suprise, Disgust, Happiness 
and Sadness. Each of these uses multiple combinations of the Action Units. For example, one activity 
of the upper face in Fig l operates AU1, the inner brow raiser by contracting the inner frontalis muscle. 
In fig 2 AU9 is used, known as the 'nose wrinkler', this activates the levator labii superioris alaqne 
nasi causing the nostrils to dilate, pulling the skin around the base of the nose up and sometimes raising 
the upper lip. My own research ascribes, to individual muscles, or groups of muscles, particular parameters 
that remain consistant between one face and the next, in the same way that FACS is universal across a 
spectrum of facial types. Importantly, any contradiction between FACS and the computer parameters can 
easily be compared and corrected using this principle of Action Units. The goal is to model the basic 
facial expressions described by Ekman using FACS to validate the results. 4. The muscle and bone of the 
face The cranium consists of fourteen major bones of which the manible is the only jointed structure. 
The mandible rotates horizontally about an axis near the ear. Inserted into the manible are the lower 
teeth, and the upper teeth are embeded into the maxilla process. From the front view, the teeth are the 
only visible bone structure, and should not be underestimated in the modelling of speech segments. The 
muscles of facial expression, are subcutaneous voluntary muscles. In general they arise from the bone 
or facia of the head, and insert into the skin as in Fig 3. The muscle can be defined according to the 
orientation of the fasciculi (the individual fibres of the muscle) that may be parallel/linear, oblique 
or spiralized relative to the direction of pull at their attachment. There are a variety of these muscle 
types apparent on the face and they can be broadly divided into the upper and lower face. In the lower 
face there are five major groupings: |8  ~ Computer Graphics, Volume 21, Number 4, July 1987 -Uppers 
and downers, that move the face upwards towards the brow and conversely towards the chin. Those that 
contract horizontally towards the ears and conversely towards the center line of the face.  Oblique 
muscles that contract in an angular direction from the lips, upwards and outwards to the cheek bones. 
 The orbitals that are circular or elliptical in nature, and run round the eyes and mouth.  Sheet muscle, 
that carries out miscellaneous actions, particularly over the temporal zones, and the platysma muscle 
which extends downwards into the neck close beneath the skin.  The upper facial muscles are responsible 
for the changing appearance of the eyebrows, forehead and the upper and lower lids of the eyes (Fig 1). 
The muscles conllact isotonically towards the static insertion into the cranium, consequently the surface 
tissue bunches and wrinkles perpendicularly to the direction of the muscle. Figure 3 The major muscles 
of the face. The muscles of the mouth have the most complex musclar interaction. The primary muscle 
being the Obicolaris Oris which is a sphincter muscle with no bony attachment. Additionally the deep 
Buccinator muscle fibres decussate into the upper and lower lip and continue round the face to the opposite 
point of attachment. Three primary muscles, M Levator, Labii Superioris and Alaeque Nasi, join from above. 
The deeper muscles M Buccinator joins at the modiolus (the major node of the mouth) and contracts horizontally. 
From below, the M Depressor, Anguli Oris, M Depressor Labii Inferioris and Mentalis, all contract obliquely 
and vertically. 5. Factors determining the modelling of muscles It is evident that the skin, being supported 
by bone and multiple layers of muscle, produces literally thousands of movement combinations. What is 
required is not the exact simulation of neurons, muscles and joints, but a model with a few dynamic parameters 
that emulate the primary characteristics. These parameters are relatively abstract, and do not attempt 
to model the biomechanical or neurophysiological mechanisms. Since the muscles themselves are grouped 
together to perform specific tasks, two. broad types of muscles are considered: linear/parallel muscles 
that pull and sphincter muscles that squeeze. Defining the surface skin as a mesh determines that each 
node has a finite degree of mobility (DOM). The primary factors determining the nodal mobility are: 
Tensile strength of the muscle and skin  Proximity to the muscle node of attachment  Depth of tissue 
at the node and the proximity to the bone  The elastic bounds of the relaxed tissue, and the interaction 
of other muscles.  The physical displacements of the facial nodes, especially around the mouth, have 
been measured by Summerfield [14] and his results indicate that displacements rarely exceed 25mm during 
the articulation of a/b/a sounds. Therefore assuming the node of bony attachment is static, a relationship 
for any intermediate node is required. The structural-based representation suggested by Badler [1] simulates 
points on the skin which is distorted around an ovoid. Arcs connect points with their neighbours, so 
that one skin movement affects the position of its neighbour in much the same way as a network of springs. 
When a force F is applied to a node p the change in location is computed by: p' = F/k where k = sum 
of the spring constants at that point. The iteration continues until a force is propagated out from the 
initiating point across the face. Badler's simulation is effective, but it does require specified facial 
models to operate upon, with tie points for the fixing of muscles to the bone and skin. This in turn 
requires information about length and elasticity to be determined before the iteration can begin. With 
all the muscle forms it is evident that they have a highly complex three-dimensional structure endowed 
with viscous, elastic and other mechanical properties that result in the displacement of the skin. The 
simulation of such interactions would be formidible, and is not the object of this paper, however some 
basic issues can be established. Only a proportion of the force is effective along the line of contraction, 
especially as the fibres become more oblique in relation to the node of attachment. This can be determined 
from the length of the muscle fibre x cosine of the angle of attachment of the muscle fibres to the tendon 
or surface tissue [18]. This gives a general indication of the displacement of the remaining tissue. 
The elasticity of the skin varies with age. Young skin has a higher elasticity than older flesh and this 
factor too should be accommodated in the muscle model. In addition to the static surface displacement 
features of the skin there are the motional characteristics. Here the requirement is to discern suitable 
motional criteria. Investigations by Kelso [14] into reiterant speech production outlined the dynamic 
properties during articulatory movement. For this process LED's were placed on the subject and monitored 
on an oscilloscope. Despite the inherent multi-dimensional process involved with speech, evidence showed 
that the system displayed near sinusoidal uniform motions, as if generated by a simple non-dissipative 
mass-spring system. This supports the early work of Parke [4] who produced convincing results utilizing 
the principle of cosine acceleration and deceleration. Subsequently this principal has been adopted as 
a first order approximation for this research, since the facial displacements are small and the rate 
at which the motions occur is extremely fast. 6. The Computer Model of muscles for the face The research 
presented in this paper represents the action of muscles using the primary motivators on a non-specific 
deformable topology of the face. The muscle actions themselves are tested against FACS which employs 
action units directly to one muscle or a small group of muscles. Any differences found between real action 
units and those performed on the computer model are easily corrected by changing the parameters for the 
muscles, until reasonable results were obtained. The muscle model was designed to be as 'naturalistic' 
as possible, in the representation. Two types of muscles were created: linear/parallel muscles that pull 
and sphincter muscles that squeeze. The key nodes of muscle attachment were measured on a number of faces, 
to establish the extremes of displacement and the maximum and minimum zone of influence. At best this 
proved to be difficult, as only the surface points could be measured, and the range of surface characteristics 
varies a great deal from face to face. However, it was confirmed that nodal displacements rarely exceed 
25mm, the largest displacements originating from the mouth groups. The zone of influence depended upon 
the degree of contraction and, using FACS as a basis, it was established that the angle varied from 15 
to 160 degrees, creating a convex zone. Additionally, using data from Summerfield [17], it was possible 
to establish degrees of freedom (DOF) for nodes around the mouth. SIGGRAPH '87, Anaheim, July 27-31 
1987 I~@~1 The fundamentals of most facial muscles determine that one end of a linear muscle has a bony 
attachment that remains static, while the other end is embedded in the soft tissue of the skin. When 
the muscle is operated, it contracts isotonically. Looking at the concept of muscle vectors, the zone 
of influence in the simplest form can be viewed as circular, and the fall-off is along the radius as 
illuslrated in Fig 4 on the three-dimensional grid. Muscle vectors can be described with direction and 
magnitude, both in two and three-dimensions. The direction is towards the point of attachment, and the 
magnitude that is zero at the point of attachment and increases to maximum at the other point of insertion 
into the skin. ,, ,;;; ...... , i i i | / i i i i i i i 1 i [ ~il| i i .ill Figure 4 A muscle vector 
displacing a three dimensional grid with a circular cosine falloff.  The next problem is to describe 
how the adjacent tissue, such as the node p (Fig 5) is affected by this muscle vector contraction. At 
the point of attachment to the skin we can assume maximum displacement, and at the point of bony attachment 
zero displacement. A fall-off of the displacement is dissipated through the adjoining tissue, both across 
the sector Pm,Pn and V1, Ps. Using a non-linear interpolant, it is possible to represent the simple action 
of a muscle such as in Fig 6. Fig 5 describes the muscle vector in two dimensions. By applying the same 
principles to the third dimension, point p (x,y,z) is displaced p' (x',y'~z'). RI P'-i /'"--. ;   
I '. / Figure 5 The muscle vector model influencing the sector V1 Pr Ps. Rs and Rf represent the fallstart 
fall f'mish of the muscle pull along the vector VI V2. Fig 5 V1 and V2 are two points located in two-dimensional 
space. Rs represents the fall-off radius start, as a real distance from VI. Rf represents the falloff 
radius fimsh, as a real distance from V1.  Given any point P(x,y) located at a mesh node, within the 
zone V1 Pr Ps is displaced towards VI along the vector P V1, this creates P' (x',y') where: x' oe f (K.A.R.x) 
 y' o¢ f (K.A.R.y) wh~e: K is the muscle spring constant D is the maximum zone of influence D is the 
vector V1 P distance The angular displacement factor A is defined as: A = cos (la/n. n/2) where It is 
the angle between V1 V2 and V1 P The radial displacement factor R is def'med as: R = cos ((1 - D/Rs) 
if, r2) for P inside V 1 Pn Pro, and R = cos ((D - Rs) / (Rf - Rs) x/2) for P inside Pn Pr Ps Pm I IIlllll 
I lLIIllll~d tlllll II I 1 I I I f 11 I I I I ] t i Illltlll IIIIIIIII1111111111 i IIIilll I I I I r 
I I I I I.t 11 I I I I Ill I ..... I I I I t I I I ? ]3 ]3~.~7,,l~''/~/",~"l"-/-'ll'q'-1 i luk#'f"/-'#l 
I//II//IlZI/Ill ! III I ~'~I/I' ,ll,.//./rf/# l l Ill I fr#'fti/f//if I I IIII ~ ¢(~'(t f.+'# #u I III 
I Ill I I tll [ I I 1 11 I 1 111 I 11 11111 I 11ti tl t I t I III11 " IIIII1! N I I I I I ! *~ "I I 
I'~LI I I I ! "1 t I I t kl I I I /1tlii11N II *tllllltlll~,kl IIIIIit1111]'1 I 1111111111111 II k I 
I I I ",i.. , "l'l I I I I I I I I I I !11111 '" tllllll :' IIIIIIII IIIIIIIIIIIIIIIIitll i: IIIIIIII 
[lllllllll[lll[lllll I II Figure 6 A three dimensional muscle vector laying in the x y plane. Zone of 
influence 35.0, fallstart 7.0, fallfin 14.0, muscle spring constant 0.75, elastisity 1.0. i tl i I'i"i 
i II I IIIII|I II "SI4jH i II II I [IIIIII i i i iJiL~i~- Ii ,'/II,'//[/'Z l il "/././/.//.'.l I / il 
il tl g tl il LI g il tl tl g g il il i' g tl  -g il ,III il ~ II] ll'i tlllll-LI il I I I I I II 
I II ::::::_-;:: I IIIIILI II I llllllil il :::~:-:::::: I I I I I I I~I II I IIIIII~L II b I-- P"I" 
F I I !!!!!!!!!! il I i i i i i] It il lllllllk il t IIIIIII iiiiiiiiii I  Figure 7 The same muscle 
vector parameters as in figure 6 but with the elasticity raised to a power 10.0. i Fig 6 illustrates 
the cosine interpolant, while Fig 7 shows the cosine raised to a power to decrease the elasticity of 
the mesh. The sphincter muscle that squeezes the skin tissue can be described from a single point around 
which the surface contracts as if drawn together like a sizing bag. This can be described as occurring 
uniformly around the point of conlxaction, therefore the angular displacement is no longer required: 
x' o¢ f (K.R.x) y, oc f (K.R.y) This results in the following activity in Fig 8. LLIIll LLIIl|lllil|11t11|l[1111LLIIIl 
IIIIII Illllllllllllllllillllll Illllllllllllllllltlllll Illlllllll|tllllllllllll11 II IIIIIIIII IIIIIII 
LLIllt lllll lLII I1]ltl Ill llttliiii tl I  '" lilliii ;I llli:i l - lLI I I I1~ |111 II  " , '"i 
H Figure 8 Sphincter muscle Obviously muscles do not behave in such a regular fashion, therefore elliptical 
shapes axe created that represents the shape of the oris by the addition of a longitudinal and vertical 
axis (Fig 9). IIII III II II IIIIIII IIII III ,, l~,,Illl ,,, II II++ IIIIIII IIII JILl Ill II Jl IIIll 
LLLI Iil II II IIIIIII IIII III II LLLLLLJ II1111 I llll Illl IIIIIIII I fillIIII IIII IIIIIIllIIIIIlll 
II!!11 IIF1~1111!!1~]~11II I Illl II Illlllll II II III II] IILI II lillllll II II III I i Ll~ul II Illlllll 
II II Ill III Figure 9 Eliptical sphincter muscle The limits of a muscle action can be determined by 
the spring constant K, which represents the maximum displacement of the muscle. The problem associated 
with this model is that each muscle action is independent, and the actual nodal displacement is determined 
by a succession of muscle actions. This is more extreme when the contractions become isometric and nodes 
are shifted out of the zone of influence of adjoining muscle vectors. In this way there is a danger of 
exceeding the degree of freedom (DOF) of any node. The nodal structure of the face determines that each 
vertex has a finite DOF. By positioning the facial muscles, both feasible and impossible, and then preprocessing 
the structure, the DOF of each node can be determined. In this manner the order of the muscle contractions 
will not become isometric, as each node will store information about its common attractors (Fig 10). 
 Computer Graphics, Volume 21, Number 4, July 1987 u i li iii i % / / % / ,]  IIII Illl,, ,,,, ~IIII 
lllll '~,, It11 llllll kl II1 llll ttl IiIlll I'1 J I I II1 II:II Iltll bl I11 111111 ill I t | I I11 
IIII1 IIIII IIJli llllll hi I I I I hi Illll lilll~ljLIIIIIII I'1 I I i I I'1 iI:lllll~ j -~J Id J ll}%[llll 
I p~ 111 IIq t I I I,fl I I'~i 1 Ill lltl I li"l li Itll lilll,I]l Ill IIII LVllLIII~t I11 IIII1[111 
 III IIII YIIIIIIII&#38;~,III IIII"'I,,,,  \ I+/ I Figure 10 The confluence of tWO muscles The modelling 
of the visco-elastic nature of skin as discussed has many variables and the cosine model is one possible 
solution to establishing a non-linear interpolant. Provided that the point of attachment is static and 
the muscle insertion into the skin has maximum displacement, any 'ramp' can be described to control the 
interpolant. The following examples Fig 11, where Fig 12 relates to (a), Fig 13 relates to (b), Fig 14 
relates to (c). Illustrate the displacement activity where f is a function of (K.A.R.x). This allows 
a more flexible approach to the modelling of the elastic nature of skin. :,::k :+::t/ :,:::L/ ~/t 1.0 
~/f 1.0 ~/f i.O (a) (b) (c) Figure 11 k\ \ \ \ R7777 ~ 777777 ~774177777~77 77 11111111Ill411FIIIIIIIPt 
IIIIII IlllllllllllllKIIIl/llhi Illi|lllllllllhlrlllllrl IIIIII IIIi|lllll|l|ll:llllllllll IIIl]llllllllll41111111'l 
lIT p~lq4Llllllllllllllllll t S I /H I I I I # I71~l~J I I ht IIlll#llJl, lll|lil~l Ill1111111111 l~llllllll 
Vtlll I,IIIIII'11111 Illlll .llflllt IIIllll ~11 IIII IIIlll 1,1 .rill I ~111 IIII ,.., ~ H it?rl II 
I II?Ll I I'IIIIIIIDt'IIIItl t 11N IIII lllllll IIItlll~llllllil It III I i itil Ilii l[I[L I  ~,~|,llll,,,lll 
IIIII I Figure 12 A three-dimensional muscle vector laying in the x y plane. Zone of influence 35.0, 
failsiart "7.0, fallfin 14.0, muscle spring constant 0.3 relating to (a)  ~ SIGGRAPH '87, Anaheim, July 
27-31, 1987 i ['7777 777P.q - n7777777777777777777~77777777q77 l]ill ii[i ii iiiiii llill if|ill Ill 
I I I I I I I I I I I I I q1177 Illlhl III IIIIIIii11111 II1, tl IIIIrl -IIll I I I I I I I I I I I I 
I I I i i i]1 i I I I I I!1 I-LLLI IIIit111 IlPtl II111'1 ~/L/I / ~ ~ P P-l-.4 --I d. 11 I i Ill I I 
I ] I Ill / l I I I I I I I I1"/'hf-I--]33111111 11 II IIIIIIItlI, IIIIIJIEI'~" I I/" I"1 ~ -  llllfJl'lltllll~ll 
I~11 f IIIItlllI I II[ll I IAIII t #11 I I 1.11111 I/lllll ,I 11 I I I rllllll IlJlllll ~IJP,,I I f 
I I I I I - ] I~,1.11 I I I I q I Ill I,I I I I t I I L I I I,rl i i i I W'I~I I I I Ill I I'.l I I 11 
t I I I l~l I / I t I I t I1~111 Ill llq I I I I I ILrl I I I Ill I [ I I N I IIIIIIII) 111|111 II IIIIN 
Ill : Lt'¢l ,r', ', l ', I 1 ', ', ', :' ', : ', : : ', ', \ Figure 13 Same parameters as in figure 12 
renting to (b) 7777777777777777777~7777777777-77 I I IJ J / lAJJll I I I Itl I I I | [ I I I I I I I 
I / I I I Itl I I I t [I I I ~1111111111]111 I |ill II II!1 I I -~/-LLI111111|111 I ill I I I I I'1 I 
I //rt~1-C44Ll I ill I I I t Ill I I /I//////177~l--[-JJ I t Ill 1///////// / / I I I-Er-t-  ~~" /lllltll 
"1111 II ~~11/|llll I I I I I I I I IIIIIII . I~tl IIII1  " I1 i i'~kt III J_IJ_l_J._k.ld-l LL,L~ ~ 
~'~'~L, ~" III I I'I~t I I I I I III I I IKI I I "ill III II]INI I I III I I I I III I I~1 7 I I I I 
Ll~,rl'rl I I I I I II II II Illll .-... Figure 14 Same parameters as in figure 12 relating to (c) 7. 
The image synthesis and model operation Polygonal data structures have been shown to be an acceptable 
mode of modelling facial topologies [5][7], and were adopted in this research for ease of use. The nature 
of the muscle model described above allows a free range in polygonal construction. This has proved to 
be important in the modelling of real people's faces that require specific topologies for recognition 
purposes Fig 15. However it remains important to maintain a mesh that is as regular as possible, to avoid 
polygonal intersections and 'facet popping' when the model is articulated. This can be remedied by increasing 
the density of polygonal detail where the curvature is higher. Additionally, all the facets need to be 
triangulated to maintain planer polygons for the renderer. The heads shown Fig 15- 22 were modelled using 
photographic techniques [6] and mirrored about the meridian of the face. Although neither real faces 
nor the motional dynamics are symmetrical these are not problems as the muscles can operate independently 
on both sides of the face. For the simplicity of use, the faces illustrated were assumed to be symetrical 
in order to reduce the time-consuming effort of data duplication. The eyelids were constructed from the 
existing vertices of the face to create five curves, three for the upper lid and two for the lower. The 
upper lids rotate about a horizontal axis to close the eyelids. Swept revolutions of profdes created 
the eyeballs that have controls for the dilation of the pupil and the focusing of the eyes. Highlights 
were important in giving a realistic effect and this was achieved either by using the Phong renderer 
or by extracting facets and shading them white. The teeth were simply formed from sets of Bezier curves 
that were set back into the mouth cavity. The lower teeth are rotated with the jaw. The positioning of 
the muscles was achieved by identifying key nodes on the face [18] and relating them to the computer 
model in three-dimensional space for the location of the muscle vector head and tail. The model is implemented 
as a program that is parameter driven. The parameters are created in data files that control all the 
muscles, jaw rotations, eye focusing and the eyelids. The program generates polygonal or vector descriptions 
that can be rendered as desired. Ten muscles were implanted into the facial topology, representing those 
that are the required action units (AU) for FACS. Each linear muscle has parameters for:. Zone of influence 
half angle in degrees Fallstart real radial distance Fs FaUfin real radial distance Ff Muscle spring 
constant 0<K<I Elasticity E >= 1 For the sphincter muscle: Tension 0<T<I Lx Ly longitude and latitude 
real distances Figure 15 Illustrated are nine different facial expressions in both the upper and lower 
face on an alternative facial topology. Seven muscles (linear/parallel and sphincler muscles) were utilized 
with the jaw rotation to represent some of the actions from the Facial Action Coding System   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37406</article_id>
		<sort_key>25</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Flocks, herds and schools: A distributed behavioral model]]></title>
		<page_from>25</page_from>
		<page_to>34</page_to>
		<doi_number>10.1145/37401.37406</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37406</url>
		<abstract>
			<par><![CDATA[The aggregate motion of a flock of birds, a herd of land animals, or a school of fish is a beautiful and familiar part of the natural world. But this type of complex motion is rarely seen in computer animation. This paper explores an approach based on simulation as an alternative to scripting the paths of each bird individually. The simulated flock is an elaboration of a particle systems, with the simulated birds being the particles. The aggregate motion of the simulated flock is created by a distributed behavioral model much like that at work in a natural flock; the birds choose their own course. Each simulated bird is implemented as an independent actor that navigates according to its local perception of the dynamic environment, the laws of simulated physics that rule its motion, and a set of behaviors programmed into it by the "animator." The aggregate motion of the simulated flock is the result of the dense interaction of the relatively simple behaviors of the individual simulated birds.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.10</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010227</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Scene understanding</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31091812</person_id>
				<author_profile_id><![CDATA[81100469355]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Craig]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Reynolds]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Symbolics Graphics Division, Los Angeles, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Abelson, H., and diSessa, A., "Maneuvering a Three Dimensional Turtle" in Turtle Geometry: The Computer as a Medium for Exploring Mathematics, The MIT Press, Cambridge, Massachusetts, 1981, pp. 140-159.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>7929</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Agha, G., Actors: A Model of Concurrent Computation in Distributed Systems, The MIT Press, Cambridge, Massachusetts, 1986.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Amkraut, S., personal communication, January 8, 1987.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Amkraut, S., Girard, M., Karl, G., "motion studies for a work in progress entitled "Eurythmy' " in SIGGRAPH Video Review, Issue 21 (second item, time code 3:58 to 7:35), 1985, produced at the Computer Graphics Research Group, Ohio State University, Columbus, Ohio.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Austin, H., "The Logo Primer," M|T A.I. Lab, Logo Working Paper 19, 1974.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Braitenberg, V., Vehicles: Experiments in Synthetic Psychology, The MIT Press, Cambridge, Massachusetts, 1984.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Burton, R., Bird Behavior, Alfred A. Knopf, Inc., 1985.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Davis, J. R., Kay, A., Marion, A., unpublished research on behavioral simulation and animation, Atari Research, 1983.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325244</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Girard, M., Maciejewski, A. A., "Computational Modeling for the Computer Animation of Legged Figures," in Computer Graphics V 19 #3, 1985, (proceedings of acre SIGGRAPH '85), pp. 263-270.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>273</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Goldberg, A., Robson, D., SMALLTALK-80, The Language and its Implementation, Addison-Wesley Publishing Company, Reading Massachusetts, 1983.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Goldberg, A., Kay, A., SMALLTALK-72 Instruction Manual, Learning research group, Xerox Palo Alto Research Center, 1976.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>512975</ref_obj_id>
				<ref_obj_pid>512950</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hewitt, C., Atkinson, R., "Parallelism and Synchronization in Actor Systems," acm Symposium on Principles of Programming Languages 4, January 1977, Los Angeles, California.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kahn, K. M., Creation of Computer Animation from Story Descriptions, MIT Artificial Intelligence Laboratory, Technical Report 540 (doctoral dissertation), August 1979.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807416</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Kahn, K. M., Hewitt, C., Dynamic Graphics using Quasi Parallelism, May 1978, proceedings of ACM SIGGRAPH, 1978.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4552</ref_obj_id>
				<ref_obj_pid>4547</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Kleinrock, L., "Distributed Systems," in Communications of the ACM, V28 #11, November 1985, pp. 1200-1213.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Lipton, J., An Exaltation of Larks (or, The Venereal Game), Grossman Publishers, 1977. Reprinted by Penguin Books 1977, 1980, 1982, 1983, 1984, 1985.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Maciejewski, A. A., Klein, C.A., "Obstacle Avoidance for Kinematically Redundant Manipulators in Dynamically Varying Environments," to appear in International Journal of Robotic Research.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4132</ref_obj_id>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Magnenat-Thalmann, N., Thalmarm, D., Computer Animation: Theory and Practice, Springer-Verlag, Toyko, 1985.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Marion, A., "Artificially Motivated Objects;' {installation]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>28698</ref_obj_id>
				<ref_obj_pid>28697</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Moon, D. A., "Object-oriented Programming with Flavors" in Proceedings of the First Annual Conference on Object-Oriented Programming Systems, Languages, and Applications, ACM, 1986]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Myers, R., Broadwell, P., Schaufler, R., "Plasm: Fish Sample," {installation piece}, ACM SIGGRAPH art show, 1985.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Papert, S., "Teaching Children to be Mathematicians vs. Teaching Them About Mathematics" International Journal of Mathematical Education and Sciences, V3, pp. 249-262, 1972.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Partridge, B. L., "The Structure and Function of Fish Schools," Scientific American, June 1982, pp. 114-123.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Pitcher, T. J., Partridge, B. L.; Wardle, C. S., "Blind Fish Can School," Science 194, #4268 (1976), p. 964.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Potts, W. K., "The Chorus-Line Hypothesis of Manoeuver Coordination in Avian Flocks," letter in Nature, Vol 309, May 24, 1984, pp. 344-345.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_obj_id>948587</ref_obj_id>
				<ref_obj_pid>948576</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Pugh, J., '~ctors--The Stage is Set," acre S1GPLANNotices, VI9 #3, March 1984, pp. 61-65.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357320</ref_obj_id>
				<ref_obj_pid>357318</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Reeves, W., T., "Particle Systems--A Technique for Modeling a Class of Fuzzy Objects," acm Transactions on Graphics, V2 #2, April 1983, and reprinted in Computer Graphics, V17 #3, July 1983, (acm S{GGRAPH '83 Proceedings), pp. 359-376.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Reynolds, C. W., Computer Animation in the World of Actors and Scripts, SM thesis, MIT (the Architecture Machine Group), May 1978.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801293</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Reynolds, C. W., "Computer Animation with Scripts and Actors," Computer Graphics, V16 #3, July 1982, (acm SIGGRAPH '82 Proceedings), pp. 289-296.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Reynolds, C. W., "Description and Control of Time and Dynamics in Computer Animation" in the notes for the course on Advanced Computer Animation at acm SIGGRAPH '85, and reprinted for the notes of the same course in 1986.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Selous, E., Thought-transference (or what?) in Birds, Constable, London, 1931.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Scheffer, V. B., Spires of Form: Glimpses of Evolution, Harcourt Brace Jovanovich, San Diego, 1983 (reprinted 1985 by Harvest/ HBJ), p. 64.]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Shaw, E., "Schooling in Fishes: Critique and Review" in Development and Evolution of Behavior. W. H. Freeman and Company, San Francisco, 1970, pp. 452-480.]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Shaw, E., "Fish in Schools," Natural History 84, no. 8 (1975), pp. 40~16.]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Sims, K., Locomotion of Jointed Figures Over Complex Terrain, SM thesis, MIT Media Lab, currently in preparation, April 1987.]]></ref_text>
				<ref_id>35</ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Symbolics Graphics Division, S-Dynamics (user's manual), Symbolics Inc., November 1986.]]></ref_text>
				<ref_id>36</ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Symbolics Graphics Division, S-Geometry (user's mafiual), Symbolics Inc., October 1986.]]></ref_text>
				<ref_id>37</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5431</ref_obj_id>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Pinker, S. (editor), Visual Cognition, The MIT Press, Cambridge, Massachusetts, 1985.]]></ref_text>
				<ref_id>38</ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Thomas, F., Johnson, O., Disney Animation: The Illusion of Life, Abbeville Press, New York, 1981, pp. 47-69.]]></ref_text>
				<ref_id>39</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617556</ref_obj_id>
				<ref_obj_pid>616011</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Wilhelms, J., "Toward Automatic Motion Control," IEEE Computer Graphics and Applications, V7 #4, April 1987, pp. ! 1-22.]]></ref_text>
				<ref_id>40</ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Zeltzer, D., "'Toward an Integrated View of 3-D Computer Animation," The Visual Computer, V1 #4, 1985, pp. 249-259.]]></ref_text>
				<ref_id>41</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~) ~ Computer Graphics, Volume 21, Number 4, July 1987 Flocks, Herds, and Schools: A Distributed Behavioral 
Model Craig W. Reynolds Symbolics Graphics Division 1401 Westwood Boulevard Los Angeles, California 
90024 (Electronic mail: cwr@Symbolics.COM)  Abstract The aggregate motion of a flock of birds, a herd 
of land ani- mals, or a school of fish is a beautiful and familiar part of the natural world. But this 
type of complex motion is rarely seen in computer animation. This paper explores an approach based on 
simulation as an alternative to scripting the paths of each bird individually. The simulated flock is 
an elaboration of a particle system, with the simulated birds being the particles. The aggregate motion 
of the simulated flock is created by a distributed behavioral model much like that at work in a natu- 
ral flock; the birds choose their own course. Each simulated bird is implemented as an independent actor 
that navigates ac- cording to its local perception of the dynamic environment, the laws of simulated 
physics that rule its motion, and a set of behaviors programmed into it by the "animator." The aggre- 
gate motion of the simulated flock is the result of the dense interaction of the relatively simple behaviors 
of the individual simulated birds. Categories and Subject Descriptors: 1.2.10 [Artificial Intelli- gence]: 
Vision and Scene Understanding; 1.3.5 [Computer Graphics]: Computational Geometry and Object Modeling; 
1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism--Animation; 1.6.3 [Simulation and Modeling[: 
Appli- cations. General Terms: Algorithms, design. Additional Key Words, and Phrases: flock, herd, school, 
bird, fish, aggregate motion, particle system, actor, flight, behav- ioral animation, constraints, path 
planning. Introduction The motion of a flock of birds is one of nature's delights. Flocks and related 
synchronized group behaviors such as schools of fish or herds of land animals are both beautiful to watch 
and intriguing to contemplate. A flock* exhibits many contrasts. It is made up of discrete birds yet 
overall motion seems fluid; it is simple in concept yet is so visually complex, Permission to copy without 
fee all or part of this material is granted provided that the copies are not made or distributed for 
direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. &#38;#169; 1987 ACM-0-89791-227-6/87/007/0025 
$00.75 it seems randomly arrayed and yet is magnificently synchro- nized. Perhaps most puzzling is the 
strong impression of inten- tional, centralized control. Yet all evidence indicates that flock motion 
must be merely the aggregate result of the actions of individual animals, each acting solely on the basis 
of its own local perception of the world. One area of interest within computer animation is the de- scription 
and control of all types of motion. Computer anima- tors seek both to invent wholly new types of abstract 
motion and to duplicate (or make variations on) the motions found in the real world. At first glance, 
producing an animated, com- puter graphic portrayal of a flock of birds presents significant difficulties. 
Scripting the path of a large number of individual objects using traditional computer animation techniques 
would be tedious. Given the complex paths that birds follow, it is doubtful this specification could 
be made without error. Even if a reasonable number of suitable paths could be described, it is unlikely 
that the constraints of flock motion could be main- tained (for example, preventing collisions between 
all birds at each frame). Finally, a flock scripted in this manner would be hard to edit (for example, 
to alter the course of all birds for a portion of the animation). It is not impossible to script flock 
motion, but a better approach is needed for efficient, robust, and believable animation of flocks and 
related group motions. This paper describes one such approach. This approach assumes a flock is simply 
the result of the interaction between the behaviors of individual birds. To simulate a flock we simu- 
late the behavior of an individual bird (or at least that portion of the bird's behavior that allows 
it to participate in a flock). To support this behavioral "control structure" we must also simu- late 
portions of the bird's perceptual mechanisms and aspects of the physics of aerodynamic flight. If this 
simulated bird model has the correct flock-member behavior, all that should be required to create a simulated 
flock is to create some in-stances of the simulated bird model and allow them to inter- act. ** Some 
experiments with this sort of simulated flock are de- scribed in more detail in the remainder of this 
paper. The suc- *In this paperflock refers generically to a group of objects that exhibit this general 
class of polarized, noncolliding, aggregate motion. The term polarization is from zoology, meaning align- 
ment of animal groups. English is rich with terms for groups of animals; for a charming and literate 
discussion of such words see An Exultation of Larks. [16] **This paper refers to these simulated bird-like, 
"bird-old" objects generically as "boids" even when they represent other sorts of creatures such as schooling 
fish.  ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 cess and validity of these simulations is difficult 
to measure objectively. They do seem to agree well with certain criteria [25] and some statistical properties 
[23] of natural flocks and schools which have been reported by the zoological and behav- ioral sciences. 
Perhaps more significantly, many people who view these animated flocks immediately recognize them as 
a representation of a natural flock, and find them similarly de- lightful to watch. Our Forefiocks The 
computer graphics community has seen simulated bird flocks before. The Electronic Theater at SIGGRAPH 
'85 pre- sented a piece labeled "motion studies for a work in progress entitled 'Eurythmy'" [4] by Susan 
Amkraut, Michael Girard, and George Karl from the Computer Graphics Research Group of Ohio State University. 
In the film, a flock of birds flies up out of a minaret and, passing between a series of columns, flies 
down into a lazy spiral around a courtyard. All the while the birds slowly flap their wings and avoid 
collision with their flockmates. That animation was produced using a technique completely unlike the 
one described in this paper and apparently not spe- cifically intended for flock modeling. But the underlying 
con- cept is useful and interesting in its own right. The following overview is based on unpublished 
communications [3]. The software is informally called "the force field animation sys- tem." Force fields 
are defined by a 3 x 3 matrix operator that transform from a point in space (where an object is located) 
to an acceleration vector; the birds trace paths along the "phase portrait" of the force field. There 
are "rejection forces" around each bird and around static objects. The force field associated with each 
object has a bounding box, so object in- teractions can be culled according to bounding box tests. An 
incremental, linear time algorithm finds bounding box inter- sections. The "animator" defines the space 
field(s) and sets the initial positions, orientations, and velocities of objects. The rest of the simulation 
is automatic. Karl Sims of MIT's Media Lab has constructed some be- haviorally controlled animation of 
groups of moving objects (spaceships, inchworms, and quadrupeds), but they are not or- ganized as flocks 
[35]. Another author kept suggesting [28, 29, 30] implementing a flock simulation based on a distributed 
behavioral model. Particle Systems The simulated flock described here is closely related to parti-cle 
systems [27], which are used to represent dynamic "fuzzy objects" having irregular and complex shapes. 
Particle systems have been used to model fire, smoke, clouds, and more re-cently, the spray and foam 
of ocean waves [27]. Particle sys- tems are collections of large numbers of individual particles, each 
having its own behavior. Particles are created, age, and die off. During their life they have certain 
behaviors that can alter the particle's own state, which consists of color, opacity, location, and velocity. 
Underlying the bold flock model is a slight generalization of particle systems. In what might be called 
a "subobject sys- tem," Reeves's dot-like particles are replaced by an entire geo- metrical object consisting 
of a full local coordinate system and a reference tO a geometrical shape model. The use of shapes instead 
of dots is visually significant, but the more fundamen- tal difference is that individual subobjects 
have a more com- plex geometrical state: they now have orientation. Another difference between bold flocks 
and particle sys- tems is not as well defined. The behavior of boids is generally more complex than the 
behaviors for particles as described in the literature. The present bold behavior model might be about 
one or two orders of magnitude more complex than typical particle behavior. However this is a difference 
of degree, not of kind. And neither simulated behavior is nearly as complex as that of a real bird. Also, 
as presented, particles in particle systems do not in- teract with one another, although this is not 
ruled out by defini- tion. But birds and hence boids must interact strongly in order to flock correctly. 
Bold behavior is dependent not only on in-ternal state but also on external state. Actors and Distributed 
Systems The behavioral model that controls the boid's flight and flock- ing is complicated enough that 
rather than use an ad hoc ap-proach, it is worthwhile to pursue the most appropriate formal computational 
model. The behaviors will be represented as rules or programs in some sense, and the internal state of 
each bold must be held in some sort of data structure. It is conve- nient to encapsulate these behaviors 
and state as an object, in the sense of object-oriented programming systems [10, 11, 21]. Each instance 
of these objects needs a computational process to apply the behavioral programs to the internal data. 
The computational abstraction that combines process, proce- dure, and state is called an actor [12, 26, 
2]. An actor is essentially a virtual computer that communicates with other virtual computers by passing 
messages. The actor model has been proposed as a natural structure for animation control by several authors 
[28, 13, 29, 18]. It seems particularly apt for situations involving interacting characters and behavior 
simula- tion. In the literature of parallel and distributed computer sys- tems, flocks and schools are 
given as examples of robust self-organizing distributed systems [15].  Behavioral Animation Traditional 
hand-drawn eel animation was produced with a me- dium that was completely inert. Traditional computer 
anima- tion uses an active medium (computers running graphics software), but most animation systems do 
not make much use of the computer's ability to automate motion design. Using different tools, contemporary 
computer animators work at al- most the same low level of abstraction as do eel animators. They tell 
their story by directly describing the motion of their characters. Shortcuts exist in both media; it 
is common for computer animators and eel animators to use helpers to inter- polate between specified 
keyframes. But little progress has been made in automating motion description; it is up to the animator 
to translate the nuances of emotion and characteriza- tion into the motions that the character performs. 
The animator cannot simply tell the character to "act happy" but must tedi- ously specify the motion 
that conveys happiness. Typical computer animation models only the shape and physical properties of the 
characters, whereas behavioral or character-based animation seeks to model the behavior of the character. 
The goal is for such simulated characters to handle many of the details of their actions, and hence their 
motions. These behaviors include a whole range of activities from sim- ple path planning to complex "emotional" 
interactions be- tween characters. The construction of behavioral animation characters has attracted 
many researchers [19, 21, 13, 14, 29,  ~/~ SIGGRAPH '87, Anaheim, July 27-31, 1987 keeps the lift from 
the airfoils of the wings pointed in the most efficient direction ("accelerational up"), it keeps the 
passen- gers' coffee in their cups, and most importantly for animation, it makes the flying boid fit 
the viewer's expectation of how flying objects should move and orient themselves. On the other hand, 
realism is not always the goal in animation. By simply reversing the angle of bank we obtain a cartoony 
motion that looks like the object is being flung outward by the centrifugal force of the turn. Boids 
and Turtles The incremental mixing of forward translations and local rota- tions that underlies geometric 
flight is the basis of "turtle graphics" in the programming language Logo [5]. Logo was first used as 
an educational tool to allow children to learn ex- perimentally about geometry, arithmetic, and programming 
[22]. The Logo turtle was originally a little mechanical robot that crawled around on large sheets of 
paper laid on the class- room floor, drawing graphic figures by dragging a felt tip marker along the 
paper as it moved. Abstract turtle geometry is a system based on the frame of reference of the turtle, 
an ob- ject that unites position and heading. Under program control the Logo turtle could move forward 
or back from its current position, turn left or right from its current heading, or put the pen up or 
down on the paper. The turtle geometry has been extended from the plane onto arbitrary manifolds and 
into 3D space [1]. These "3d turtles" and their paths are exactly equiv- alent to the boid objects and 
their flight paths. Natural Flocks, Herds, and Schools "... and the thousands of fishes moved as a huge 
beast, piercing the water. They appeared united, inexorably bound to a common fate. How comes this unity?" 
--Anonymous, 17th century (from Shaw) For a bird to participate in a flock, it must have behaviors that 
allow it to coordinate its movements with those of its flockmates. These behaviors are not particularly 
unique; all creatures have them to some degree. Natural flocks seem to consist of two balanced, opposing 
behaviors: a desire to stay close to the flock and a desire to avoid collisions within the flock [34]. 
It is clear why an individual bird wants to avoid collisions with its flockrnates. But why do birds seem 
to seek out the airborne equivalent of a nasty traffic jam? The basic urge to join a flock seems to be 
the result of evolutionary pressure from several factors: protection from predators, statis- tically 
improving survival of the (shared) gene pool from at- tacks from predators, profiting from a larger effective 
search pattern in the quest for food, and advantages for social and mating activities [33]. There is 
no evidence that the complexity of natural flocks is bounded in any way. Flocks do not become "full" 
or "over- loaded" as new birds join. When herring migrate toward their spawning grounds, they run in 
schools extending as long as 17 miles and containing millions of fish [32]. Natural flocks seem to operate 
in exactly the same fashion over a huge range of flock populations. It does not seem that an individual 
bird can be paying much attention to each and every one of its flock- mates. But in a huge flock spread 
over vast distances, an indi- vidual bird must have a localized and filtered perception of the rest of 
the flock. A bird might be aware of three categories: itself, its two or three nearest neighbors, and 
the rest of the flock [23]. These speculations about the "computational complexity" of flocking are meant 
to suggest that birds can flock with any number of flockmates because they are using what would be called 
in formal computer science a constant time algorithm. That is, the amount of "thinking" that a bird has 
to do in order to flock must be largely independent of the number of birds in the flock. Otherwise we 
would expect to see a sha W upper bound on the size of natural flocks when the individual birds became 
overloaded by the complexity of their navigation task. This has not been observed in nature. Contrast 
the insensitivity to complexity of real flocks with the situation for the simulated flocks described 
below. The complexity of the flocking algorithm described is basically O(N2). That is, the work required 
to run the algorithm grows as the square of the flock's population. We definitely do see an upper bound 
on the size of simulated flocks implemented as described here. Some techniques to address this performance 
issue are discussed in the section Algorithmic Considerations. Simulated Flocks To build a simulated 
flock, we start with a boid model that supports geometric flight. We add behaviors that correspond to 
the opposing forces of collision avoidance and the urge to join the flock. Stated briefly as rules, and 
in order of decreasing precedence, the behaviors that lead to simulated flocking are: 1. Collision Avoidance: 
avoid collisions with nearby flockmates  2. Velocity Matching: attempt to match velocity with nearby 
flockmates 3. Flock Centering: attempt to stay close to nearby flockmates  Velocity is a vector quantity, 
referring to the combination of heading and speed. The manner in which the results from each of these 
behaviors is reconciled and combined is significant and is discussed in more detail later. Similarly, 
the meaning nearby in these rules is key to the flocking process. This is also discussed in more detail 
later, but generally one boid's aware- ness of another is based on the distance and direction of the 
offset vector between them. Static collision avoidance and dynamic velocity matching are complementary. 
Together they ensure that the members of a simulated flock are free to fly within the crowded skies of 
the flock's interior without running into one another. Collision avoidance is the urge to steer away 
from an imminent impact. Static collision avoidance is based on the relative position of the flockmates 
and ignores their velocity. Conversely, velocity matching is based only on velocity and ignores position. 
It is a predictive version of collision avoidance: if the boid does a good job of matching velocity with 
its neighbors, it is unlikely that it will collide with any of them any time soon. With veloc- ity matching, 
separations between boids remains approximately invariant with respect to ongoing geometric flight. Static 
colli- sion avoidance serves to establish the minimum required sepa- ration distance; velocity matching 
tends to maintain it. Flock centering makes a boid want to be near the center of the flock. Because each 
boid has a localized perception of the world, "center of the flock" actually means the center of the 
nearby flockmates. Flock centering causes the boid to fly in a direction that moves it closer to the 
centroid of the nearby boids. If a boid is deep inside a flock, the population density in its neighborhood 
is roughly homogeneous; the boid density is  ~' Computer Graphics, Volume 21, Number 4, July 1987 approximately 
the same in all directions. In this case, the cem troid of the neighborhood boids is approximately at 
the center of the neighborhood, so the flock centering urge is small. But if a boid is on the boundary 
of the flock, its neighboring boids are on one side. The centroid of the neighborhood boids is displaced 
from the center of the neighborhood toward the body of the flock. Here the flock centering urge is stronger 
and the flight path will be deflected somewhat toward the local flock center. Real flocks sometimes split 
apart to go around an obstacle. To be realistic, the simulated flock model must also have this ability. 
Flock centering correctly allows simulated flocks to bifurcate. As long as an individual boid can stay 
close to its nearby neighbors, it does not care if the rest of the flock turns away. More simplistic 
models proposed for flock organization (such as a central force model or a follow the designated leader 
model) do not allow splits. The flock model presented here is actually a better model of a school or 
a herd than a flock. Fish in murky water (and land animals with their inability to see past their herdmates) 
have a limited, short-range perception of their environment. Birds, especially those on the outside of 
a flock, have excellent long-range "visual perception." Presumably this allows widely separated flocks 
to join together. If the flock centering urge was completely localized, when two flocks got a certain 
dis- tance apart they would ignore each other. Long-range vision seems to play a part in the incredibly 
rapid propagation of a "maneuver wave" through a flock of birds. It has been shown that the speed of 
propagation of this wavefront reaches three times the speed implied by the measured startle reaction 
time of the individual birds. The explanation advanced by Wayne Ports is that the birds perceive the 
motion of the oncoming "maneuver wave" and time their own turn to match it [25]. Potts refers to this 
as the "chorus line" hypothesis. Arbitrating Independent Behaviors The three behavioral urges associated 
with flocking (and others to be discussed below) each produce an isolated suggestion about which way 
to steer the boid. These are expressed as acceleration requests. Each behavior says: "if I were in charge, 
I would accelerate in that direction." The acceleration request is in terms of a 3D vector that, by system 
convention, is truncated to unit magnitude or less. Each behavior has sev- eral parameters that control 
its function; one is a "strength," a fractional value between zero and one that can further attenuate 
the acceleration request. It is up to the navigation module of the boid brain to collect all relevant 
acceleration requests and then determine a single behaviorally desired acceleration. It must combine, 
prioritize, and arbitrate between potentially conflicting urges. The pilot module takes the acceleration 
de- sired by the navigation module and passes it to the flight mod- ule, which attempts to fly in that 
direction. The easiest way to combine acceleration requests is to aver- age them. Because of the included 
"strength" factors, this is actually a weighted average. The relative strength of one be- havior to another 
can be defined this way, but it is a precarious interrelationship that is difficult to adjust. An early 
version of the boid model showed that navigation by simple weighted av- eraging of acceleration requests 
works "pretty well." A bold that chooses its course this way will fly a reasonable course under typical 
conditions. But in critical situations, such as po- tential collision with obstacles, conflicts must 
be resolved in a timely manner. During high-speed flight, hesitation or indeci- sion is the wrong response 
to a brick wall dead ahead. The main cause of indecision is that each behavior might be shouting advice 
about which way to turn to avoid disaster, but if those acceleration requests happen to lie in approxi- 
mately opposite directions, they will largely cancel out under a simple weighted averaging scheme. The 
boid would make a very small turn and so continue in the same direction, perhaps to crash into the obstacle. 
Even when the urges do not cancel out, averaging leads to other problems. Consider flying over a gridwork 
of city streets between the skyscrapers; while "'fly north" or "fly east" might be good ideas, it would 
be a bad idea to combine them as "fly northeast." Techniques from artificial intelligence, such as expert 
sys- tems, can be used to arbitrate conflicting opinions. However, a less complex approach is taken in 
the current implementation. Prioritized acceleration allocation is based on a strict priority ordering 
of all component behaviors, hence of the consider- ation of their acceleration requests. (This ordering 
can change to suit dynamic conditions.) The acceleration requests are con- sidered in priority order 
and added into an accumulator. The magnitude of each request is measured and added into another accumulator. 
This process continues until the sum of the accu- mulated magnitudes gets larger than the maximum acceleration 
value, which is a parameter of each boid. The last acceleration request is trimmed back to compensate 
for the excess of accu- mulated magnitude. The point is that a fixed amount of accel- eration is under 
the control of the navigation module; this acceleration is parceled out to satisfy the acceleration request 
of the various behaviors in order of priority. In an emergency the acceleration would be allocated to 
satisfy the most pressing needs first; if all available acceleration is "'used up," the less pressing 
behaviors might be temporarily unsatisfied. For exam- ple, the flock centering urge could be correctly 
ignored tempo- rarily in favor of a maneuver to avoid a static obstacle. Simulated Perception The bold 
model does not directly simulate the senses used by real animals during flocking (vision and hearing) 
or schooling (vision and fishes' unique "lateral line" structure that provides a certain amount of pressure 
imaging ability [23, 24]). Rather the perception model tries to make available to the behavior model 
approximately the same information that is available to a real animal as the end result of its perceptual 
and cognitive processes. This is primarily a matter of filtering out the surplus infor- mation that is 
available to the software that implements the boid's behavior. Simulated boids have direct access to 
the geo- metric database that describes the exact position, orientation, and velocity of all objects 
in the environment. The real bird's information about the world is severely limited because it per- ceives 
through imperfect senses and because its nearby flock- mates hide those farther away. This is even more 
pronounced in herding animals because they are all constrained to be in the same plane. In fish schools, 
visual perception of neighboring fish is further limited by the scattering and absorption of light by 
the sometimes murky water between them. These factors combine to strongly localize the information available 
to each animal. Not only is it unrealistic to give each simulated boid perfect and complete information 
about the world, it is just plain wrong and leads to obvious failures of the behavior model. Before the 
current implementation of localized flock centering behavior was implemented, the flocks used a central 
force model. This leads to unusual effects such as causing all mem- bers of a widely scattered flock 
to simultaneously converge   ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 toward the flock's centroid. 
An interesting result of the experi- ments reported in this paper is that the aggregate motion that we 
intuitively recognize as "flocking" (or schooling or herd- ing) depends upon a limited, localized view 
of the world. The behaviors that make up the flocking model are stated in terms of "nearby flockmates." 
In the current implementa- tion, the neighborhood is defined as a spherical zone of sensi- tivity centered 
at the boid's local origin. The magnitude of the sensitivity is defined as an inverse exponential of 
distance. Hence the neighborhood is defined by two parameters: a radius and exponent. There is reason 
to believe that this field of sensi- tivity should realistically be exaggerated in the forward direc- 
tion and probably by an amount proportional to the boid's speed. Being in motion requires an increased 
awareness of what lies ahead, and this requirement increases with speed. A forward-weighted sensitivity 
zone would probably also im-prove the behavior in the current implementation of boids at the leading 
edge of a flock, who tend to get distracted by the flock behind them. Because of the way their heads 
and eyes are arranged, real birds have a wide field of view (about 300 de- grees), but the zone of overlap 
from both eyes is small (10 to 15 degrees). Hence the bird has stereo depth perception only in a very 
small, forward-oriented cone. Research is currently under way on models of forward-weighted perception 
for boids. In an early version of the flock model, the metrics of at- traction and repulsion were weighted 
linearly by distance. This spring-like model produced a bouncy flock action, fine per- haps for a cartoony 
characterization, but not very realistic. The model was changed to use an inverse square of the distance. 
This more gravity-like model produced what appeared to be a more natural, better damped flock model. 
This correlated well with the carefully controlled quantitative studies that Brian Partridge made of 
the spatial relationships of schooling fish [23]; he found that "a fish is much more strongly influenced 
by its near neighbors than it is by the distant members of the school. The contribution of each fish 
to the [influence] is in- versely proportional to the square or the cube of the distance." In previous 
work he and colleagues [23, 24] demonstrated that fishes school based on information from both their 
visual sys- tem and from their "lateral line" organ which senses pressure waves. The area of a perspective 
image of the silhouette of an object (its "visual angle") varies inversely with the square of its distance, 
and that pressure waves traveling through a 3D medium like water fall off inversely with the cube of 
the dis- tance. The boid perception model is quite ad hoc and avoids actu- ally simulating vision. Artificial 
vision is an extremely com- plex problem [38] and is far beyond the scope of this work. But if boids 
could "see" their environment, they would be better at path planning than the current model. It is possible 
to construct simple maze-like shapes that would confuse the current boid model but would be easily solved 
by a boid with vision. Impromptu Flocking The flocking model described above gives boids an eagerness 
to participate in an acceptable approximation of flock-like mo- tion. Boids released near one another 
begin to flock together, cavorting and jostling for position. The boids stay near one another (flock 
centering) but always maintain prudent separa- tion from their neighbors (collision avoidance), and the 
flock quickly becomes "polarized"--its members heading in ap-proximately the same direction at approximately 
the same speed (velocity matching); when they change direction they do it in synchronization. Solitary 
boids and smaller flocks join to become larger flocks, and in the presence of external obstacles (discussed 
below), larger flocks can split into smaller flocks. For each simulation run, the initial position (within 
a speci- fied ellipsoid), heading, velocity, and various other parameters of the boid model are initialized 
to values randomized within specified distributions. A restartable random-number generator is used to 
allow repeatability. This randomization is not re-quired; the boids could just as well start out arranged 
in a regular pattern, all other aspects of the flock model are com- pletely deterministic and repeatable. 
When the simulation is run, the flock's first action is a reaction to the initial conditions. If the 
boids started out too closely crowded together, there is an initial "flash expansion" where the mutual 
desire to avoid collision drives the boids radially away from the site of the initial over-pressure. 
If re- leased in a spherical shell with a radius smaller than the "neighborhood" radius, the boids contract 
toward the sphere's center; otherwise they begin to coalesce into small flockettes that might themselves 
begin to join together. If the boids are confined within a certain region, the smaller flocks eventually 
conglomerate into a single flock if left to wander long enough. Scripted Flocking The behaviors discussed 
so far provide for the ability of indi- vidual birds to fly and participate in happy aimless flocking. 
But to combine flock simulations with other animated action, we need more direct control over the flock. 
We would like to direct specific action at specific times (for example, "the flock enters from the left 
at :02.3 seconds into the sequence, turns to fly directly upward at :03.5, and is out of the frame at 
:04.0"). The current implementation of the bold model has several facilities to direct the motion and 
timing of the flock action. First, the simulations are run under the control of a general- purpose animation 
scripting system [36]. The details of that scripting system are not relevant here except that, in addition 
to the typical interactive motion control facilities, it provides the ability to schedule the invocation 
of user-supplied software (such as the flock model) on a frame-by-frame basis. This scripting facility 
is the basic tool used to describe the timing of various flock actions. It also allows flexible control 
over the time-varying values of parameters, which can be passed down to the simulation software. Finally 
the script is used to set up and animate all nonbehavioral aspects of the scene, such as backgrounds, 
lighting, camera motion, and other visible ob- jects. The primary tool for scripting the flock's path 
is the migra-tory urge built into the boid model. In the current model this urge is specified in terms 
of a global target, either as a global direction (as in "going Z for the winter") or as a global position--a 
target point toward which all birds fly. The model computes a bounded acceleration that incrementally 
turns the boid toward its migratory target. With the scripting system, we can animate a dynamic pa- rameter 
whose value is a global position vector or a global direction vector. This parameter can be passed to 
the flock, which can in turn pass it along to all boids, each of which sets its own "migratory goal register." 
Hence the global migratory behavior of all birds can be directly controlled from the script. (Of course, 
it is not necessary to alter all boids at the same time, for example, the delay could be a function of 
their present position in space. Real flocks do not change direction simultaneously [25], but rather 
the turn starts with a single bird and spreads quickly across the flock like a shock wave.)   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37407</article_id>
		<sort_key>35</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Principles of traditional animation applied to 3D computer animation]]></title>
		<page_from>35</page_from>
		<page_to>44</page_to>
		<doi_number>10.1145/37401.37407</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37407</url>
		<abstract>
			<par><![CDATA[This paper describes the basic principles of traditional 2D hand drawn animation and their application to 3D computer animation. After describing how these principles evolved, the individual principles are detailed, addressing their meanings in 2D hand drawn animation and their application to 3D computer animation. This should demonstrate the importance of these principles to quality 3D computer animation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor>Arts, fine and performing**</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P144720</person_id>
				<author_profile_id><![CDATA[81100243559]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lasseter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pixar, San Rafael, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Abel Image Research, 953 N. Highland Ave., Los Angeles, CA 90038-2481]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Alias Research Inc., 110 Richmond St. East, Suite 500, Toronto, Ontario, Canada m5c- lpl]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Blair, Preston, Animation, Walter T. Foster, Santa Ana CA, 1949.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Burmyk, Nester and Wein, Marceli, "Computer Generated Keyframe Animation," Journal of the SMVrE 80, pp.149-153, March 1971.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360357</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Burtnyk, Nester and Wein, Marceli, "Interactive Skeleton Techniques for Enhanced Motion Dynamics in Key Frame Animation," Communications of the ACM 19 (10), pp 564-569, October, 1976.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>569952</ref_obj_id>
				<ref_obj_pid>800193</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Catmull, Edwin, "A System for Computer Generated Movies," Proceedings ACM Annual Conference, pp. 422-431, August 1972.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807414</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Catmull, Edwin, "The problems of Computer- Assisted Animation," SIGGRAPH '78, Computer Graphics, Vol. 12, No. 3, pp. 348-353, August 1978.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., "Stochastic Sampling in Computer Graphics," ACM Transactions on Graphics, Vol. 5, No. 1, pp. 51-72, January 1986.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., Porter, Thomas, and Carpenter, Loren, "Distributed Ray Tracing," SIGGRAPH '84, Computer Graphics, Vol. 18, No. 3, pp.137-145, July, 1984.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Walt Disney Productions, Three Little Pigs, (film), 1933.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Gracer, F., and Blagen, M. W., "Karma" A System for Storyboard Animation," Procee.ding Ninth Annual UAIDE Meeting, pp. 210-255, 1970.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Graham, Don, The Art of Animation, unpublished.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Graham, Don, transcripts of action analysis class at the Walt Disney Studio, June 21, 1937.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Graham, Don, transcripts of action analysis class with Bill Tytla at the Walt Disney Studio, June 28, 1937.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Hardtke, lnes, and Bartels, Richard, "Kinetics for Key-Frame Interpolation," unpublished.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808575</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Kochanek, Doris, and Barrels, Richard, "Interpolating Splines with Local Tension, Continuity, and Bias Control," SIGGRAPH '84, Computer Graphics, Vol. 18, No. 3, pp. 33-41, July, 1984.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563871</ref_obj_id>
				<ref_obj_pid>965141</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[I.~voy, Marc, "A Color Animation System Based on the Multi-Plane Technique," SIGGRAPH '77, Computer Graphics, Vol. 11, No. 2, pp. 64-71, July, 1977.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Lucasfilm Ltd. Computer Graphics Div., The Adventures of Andre and Wally B., (fdm), 1984.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Ostby, Eben, Duff, Tom, and Reeves, William, Md (motion doctor), animation program, Lucasfilm Ltd., 1982-1986.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Perine, Robert, Chouinard, An Art Vision Betrayed , Artra Publishing, Encinitas CA, 1985.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Pixar, Luxo Jr., (film), 1986.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806814</ref_obj_id>
				<ref_obj_pid>965161</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Reeves, William, "Inbetweening for Computer Animation Utilizing Moving Point Constraints," SIGGRAPH '81, Computer Graphics, Vol. 15, NO. 3, pp. 263-270, August 1981.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Rydstrom, Gary, Soundtraek for Luxo J r ., Sprocket Systems Div., Lucasfilm Ltd., July, 1986.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Stem, Garland, "Bboop--A System for 3D Keyframe Figure Animation," Tutorial Notes: Introduction to Computer Animation , SIGGRAPH '83, July 1983.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Symbolics Inc., 1401 Westwood Blvd., Los Angeles, CA 90024]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Thomas, Frank and Johnston, Ollie, Disney Animation-- The Illusion of Life, Abbeville Press, New York, 1981.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Thomas, Frank, "Can Classic Disney Animation Be Duplicated On The Computer?" Computer Pictures, Vol. 2, Issue 4, pp. 20-26, luly/August 1984.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Vertigo Systems International Inc., 119 W. Pender St., Suite 221, Vancouver, BC, Canada v6b ls5]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Wavefront Technologies, 530 East Montecito, Santa Barbara, CA 93101]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Whitakcr, Harold and Halas, John, Timing for Animation , Focal Press, London, 1981.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[White, Tony, The Animator's Workbook, Watson-Gupfill, New York, 1996.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 PRINCIPLES OF TRADITIONAL ANIMATION APPLIED TO 
3D COMPUTER ANIMATION John Lasseter Pixar San Rafael California "There is no particular mystery in 
animation.., it's really very simple, and like anything that is simple, it is about the hardest thing 
in the world to do." Bill Tytla at the Walt Disney Studio, June 28, 1937. [14] ABSTRACT This paper describes 
the basic principles of traditional 2D hand drawn animation and their application to 3D computer animation. 
After describing how these principles evolved, the individual principles are detailed, addressing their 
meanings in 2D hand drawn animation and their application to 3D computer animation. This should demonstrate 
the importance of these principles to quality 3D computer animation. CR Categories and Subject Descriptors: 
1.3.6 Computer Graphics : Methodology and Techniques -Interaction techniques; 1.3.7 Computer Graphics 
: Three-dimensional Graphics and Realism -Animation; J.5 Computer Applications : Arts and Humanities 
-Arts, fine and performing. General Terms: Design, Human Factors. Additional Keywords and Phrases: Animation 
Principles, Keyframe Animation, Squash and Stretch, Luxo Jr. I. INTRODUCTION Early research in computer 
animation developed 2D animation techniques based on traditional animation. [7] Techniques such as storyboarding 
[11], key/tame animation, [4,5] inbetweening, [16,22] scan/paint, and multiplane backgrounds [17] attempted 
to apply the eel animation process to the computer. As 3D computer animation research matured, more resources 
were devoted to image rendering than to animation. Because 3D computer animation uses 3D models instead 
of 2D drawings, fewer techniques from traditional animation were applied. Early 3D animation systems 
were script based [6], followed by a few spline-interpolated key/rome systems. [22] But these systems 
were developed by companies for internal use, and so very few traditionally trained animators found their 
way into 3D computer animation. "Luxo" is a trademark of Jae Jacobsen Industries AS. Permission to copy 
without fee all or part of this material is granted provided that the copies are not made or distributed 
for direct commercial advantage, the ACM copyright notice and the title of the pubfication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery. 
To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169; 1987 ACM-0-89791-227-6/87/007/0035 
$00.75 The last two years have seen the appearance of reliable, user friendly, keyframe animation systems 
from such companies as Wavefront Technologies Inc., [29] Alias Research Inc., [2] Abel Image Research 
(RIP), [1] Vertigo Systems Inc., [28] Symbolics Inc., [251 and others. These systems will enable people 
to produce more high quality computer animation. Unfortunately, these systems will also enable people 
to produce more bad computer animation. Much of this bad animation will be due to unfamiliarity with 
the fundamental principles that have been used for hand drawn character animation for over 50 years. 
Understanding these principles of traditional animation is essential to producing good computer animation. 
Such an understanding should also be important to the designers of the systems used by these animators. 
In this paper, I will explain the fundamental principles of traditional animation and how they apply 
to 3D keyframe computer animation. 2. PRINCIPLES OF ANIMATION Between the late 1920's and the late 1930's 
animation grew from a novelty to an art form at the Walt Disney Studio. With every picture, actions became 
more convincing, and characters were emerging as true personalities. Audiences were enthusiastic and 
many of the animators were satisfied, however it was clear to Walt Disney that the level of animation 
and existing characters were not adequate to pursue new story lines-- characters were limited to certain 
types of action and, audience acceptance notwithstanding, they were not appealing to the eye. It was 
apparent to Walt Disney that no one could successfully animate a humanized figure or a life-like animal; 
a new drawing approach was necessary to improve the level of animation exemplified by the Three Little 
Pigs. [10] FIGURE 1. Luxo Jr.'s hop with overlapping action on cord. Flip pages from last page of paper 
to front. The top figures are frames 1-5, the bottom are frames 6-10. J ~    ~ SIGGRAPH '87, Anaheim, 
July 27-31, 1987 Disney set up drawing classes for his animators at the Chouinard Art Institute in Los 
Angeles under instructor Don Graham. When the classes were started, most of the animators were drawing 
using the old cartoon formula of standardized shapes, sizes, actions, and gestures, with little or no 
reference to nature. [12] Out of these classes grew a way of drawing moving human figures and animals. 
The students studied models in motion [20] as well as live action film, playing certain actions over 
and over. [131 The analysis of action became important to the development of animation. Some of the animators 
began to apply the lessons of these classes to production animation, which became more sophisticated 
and realistic. The animators continually searched for better ways to communicate to one mother the ideas 
learned from these lessons. Gradually, procedures were isolated and named, analyzed and perfected, and 
new artists were taught these practices as rules of the trade. [26] They became the fundamental principles 
of traditional animation: 1. Squash and Stretch --Defining the rigidity and mass of an object by distorting 
its shape during an action. 2. Timing --Spacing actions to define the weight and size of objects and 
the personality of characters. 3. Anticipation -- The preparation for an action. 4. Staging ,. Presentating 
an idea so that it is unmistakably clear. 5. Follow Through and Overlapping Action --The termination 
of an action and establishing its relationship to the next action.  6. Straight Ahead Action and Pose-To-Pose 
Action -- The two contrasting approaches to the creation of movement. 7. Slow In and Out --The spacing 
of the inbetween frames to achieve subtlety of timing and movement. 8. Arcs --The visual path of action 
for natural movement. 9. Exaggeration --Accentuating the essence of an idea via the design and the action. 
 10. Secondary Action --The action of an object resulting from another action, 11. Appeal .-Creating 
a design or an action that the audience enjoys watching.  The application of some of these principles 
mean the same regardless of the medium of animation. 2D hand drawn animation deals with a sequence of 
two dimensional drawings that simulate motion. 3D computer animation involves creating a three dimensional 
model in the computer. Motion is achieved by setting keyframe poses and having the computer generate 
the inbetween frames. Timing, anticipation, staging, follow through, overlap, exaggeration, and secondary 
action apply in the same way for both types of animation. While the meanings of squash and stretch, slow 
in and out, arcs, appeal, straight ahead action, and pose-to-pose action remain the same, their application 
changes due to the difference in medium. 2.1 SQUASH AND STRETCH The most important principle is called 
squash and stretch. When an object is moved, the movement emphasizes any rigidity in the object. In real 
life, only the most rigid shapes (such as chairs, dishes and pans) remain so during motion. Anything 
composed of living flesh, no matter how bony, will show considerable movement in its shape during an 
action. For example, when a bent arm with swelling biceps straightens out, only the long sinews are apparent. 
A face, whether chewing, smiling, talking, or just showing a change of expression, is alive with changing 
shapes in the cheeks, the lips, and the eyes. ]26] The squashed position depicts the form either flattened 
out by an external pressure or constricted by its own power. The stretched position always shows the 
same form in a very extended condition. [26] The most important rule to squash and stretch is that, no 
matter how squashed or stretched out a particular object gets, its volume remains constant. If an object 
squashed down without its sides stretching, it would appear to shrink; if it stretched up without its 
sides squeezing in it would appear to grow. Consider the shape and volume of a half filled flour sack: 
when dropped on the floor, it squashed out to its fullest shape. If picked up by the top comers, it stretched 
out to its longest shape. It never changes volume. [26] The standard animation test for all beginners 
is drawing a bouncing ball. The assignment is to represent the ball by a simple circle, and then have 
it drop, hit the ground, and bounce back into the air. A simple test, but it teaches the basic mechanics 
of animating a scene, introducing timing as well as squash and stretch. If the bottom drawing is flattened, 
it gives the appearance of bouncing. Elongating the drawings before and after the bounce increases the 
sense of speed, makes it easier to follow and gives more snap to the action. [26,3] (figure 2) FIGURE 
2. Squash &#38; stretch in bouncing ball. Squash and stretch also defines the rigidity of the material 
making up an object. When an object is squashed flat and stretches out drastically, it gives the sense 
that the object is made out of a soft, pliable material and vice versa. When the parts of an object are 
of different materials, they should respond differently: flexible parts should squash more and rigid 
parts less. An object need not deform in order to squash and stretch. For instance, a hinged object like 
Luxo Jr. (from the film, Lv, xo Jr. I21]), squashes by folding over on itself, and stretches by extending 
out fully. (figure 3) FIGURE 3. Squash &#38; stretch in Luxo Jr.'s hop. Squash and stretch is very important 
in facial animation, not only for showing the flexibility of the flesh and muscle, but also for showing 
the relationship of between the parts of the face. When a face smiles broadly, the comers of the mouth 
push up into the cheeks. The cheeks squash and push up into the eyes, making the eyes squint, which brings 
down the eyebrows and stretches the forehead. When the face adopts a surprised expression, the mouth 
opens, stretching down the cheeks. The wide open eyes push the eyebrows up, squashing and wrinkling the 
forehead. ~)' Computer Graphics, Volume 21, Number 4, July 1987 Another use of squash and stretch is 
to help relieve the disturbing effect of strobing that happens with very fast motion because sequencial 
positions of an object become spaced far apart. When the action is slow enough, the object's positions 
overlap, and the eye smooths the motion out. (figure 4a) However, as the speed of the action increases, 
so does the distance between positions. When the distance becomes far enough that the object does not 
overlap from frame to frame, the eye then begins to perceive separate images. (figure 4b) Accurate motion 
blur is the most realistic solution to this problem of strobing, [8,9] but when motion blur is not available, 
squash and stretch is an alternative: the object should be stretched enough so that its positions do 
overlap from frame to frame (or nearly so), and the eye will smooth the action out again. (figure 4c) 
FIGURE 4a. In slow action, an object's position overlaps from frame to frame which gives the action a 
smooth appearance to the eye. FIGURE 4b. Strobing occurs in a faster action when the object's positions 
do not overlap and the eye perceives seperate images. FIGURE 4c. Stretching the object so that it's positions 
overlap again will relieve the strobing effect. In 3D keyframe computer animation, the scale transformation 
can be used for squash and stretch. When scaling up in Z, the object should be scaled down in X and Y 
to keep the volume the same. Since the direction of the stretch should be along the path of action, a 
rotational transformation may be required to align the object along an appropriate axis. 2.2 TIMING Timing, 
or the speed of an action, is an important principle because it gives meaning to movement-- the speed 
of an action defines how well the idea behind the action will read to an audience. It reflects the weight 
and size of an object, and can even carry emotional meaning. Proper timing is critical to making ideas 
readable. It is important to spend enough time (but no more) preparing the audience for: the anticipation 
of an action; the action itself; and the reaction to the action. If too much time is spent on any of 
these, the audience's attention will wander. If too little time is spent, the movement may be finished 
before the audience notices it, thus wasting the idea. [30] The faster the movement, the more important 
it is to make sure the audience can follow what is happening. The action must not be so fast that the 
audience cannot read it and understand the meaning of it. [30] More than any other principle, timing 
defines the weight of an object. Two objects, identical in size and shape, can appear to be two vastly 
different weights by manipulating timing alone. The heavier an object is, the greater its mass, and the 
more force is required to change its motion. A heavy body is slower to accelerate and decelerate than 
a light one. It takes a large force to get a cannonball moving, but once moving, it tends to keep moving 
at the same speed and requires some force to stop it. When dealing with heavy objects, one must allow 
plenty of time and force to start, stop or change their movements, in order to make their weight look 
convincing. [30] Light objects have much less resistance to change of movement and so need much less 
time to start moving. The flick of a finger is enough to make a balloon accelerate quickly away. When 
moving, it has little momentum and even the friction of the air quickly slows it up. [30] Timing can 
also contribute greatly to the feeling of size or scale of an object or character. A giant has much more 
weight, more mass, more inertia than a normal man; therefore he moves more slowly. Like the cannonball, 
he takes more time to get started and, once moving, takes more time to stop. Any changes of movement 
take place more slowly. Conversely, a tiny character has less inertia than normal, so his movements tend 
to be quicker. [30] The way an object behaves on the screen, the effect of weight that it gives, depend 
entirely on the spacing of the poses and not on the poses themselves. No matter how well rendered a cannonball 
may be, it does not look like a cannonball if it does not behave like one when animated. The same applies 
to any object or character. [30] The emotional state of a character can also be defined more by its movement 
than by its appearence, and the varying speed of those movements indicates whether the character is lethargic, 
excited, nervous or relaxed. Thomas and Johnston [26] describe how changing the timing of an action gives 
it new meaning: Just two drawings of a head, the first showing it leaning toward the right shoulder and 
the second with it over on the left and its chin slightly raised, can be made to communicate a multitute 
of ideas, depending entirely on the Timing used. Each inbetween drawing added between these two "extremes" 
gives a new meaning to the action. NO inbetweens ........... The Character has been hit by a tremendous 
force. His head is nearly snapped off. ONE inbetweens ......... The Character has been hit by a brick, 
rolling pin, frying pan. TWO inbetweens ......... The Character has a nervous tic, a muscle spasm, an 
uncontrollable twitch. THREE inbetweens ..... The Character is dodging a brick, rolling pin, frying pan. 
FOUR inbetweens ........... The Character is giving a crisp order, "Get going!" "Move it!" FIVE inbetweens 
........... The Character is more friendly, "Over here." "Come on-hurry!" SIX inbetweens ........... 
The Character sees a good looking girl, or the sports car he has always wanted. SEVEN inbetweens ........... 
The Character tries to get a better look at something.   5< f J  '~ SIGGRAPH '87, Anaheim, July 
27-31, 1987 i i n,i i In The Adventures of Andre and Watly B., this principle was used extensively on 
Wally B.'s feet, antennae and stinger. They all dragged behind his head and body, and continued to move 
well after the body had stopped. To convey that these loose appendages were made of different materials 
and different masses, the rate of the follow through was different for each type. His antennae were fairly 
light, so they dragged behind just slightly. His stinger was like stainless steel, so it dragged behind 
the action more than the antennae. And his feet were heavy and very flexible, as though they were water 
balloons; therefore, they always followed far behind the main action with a lot of squash and stretch. 
In the zip off illustrated above (figure 5), the action of Wally B.'s body was so fast and the feet weighed 
so much that they dragged far behind. They were even left on screen frames after the body had disappeared. 
Often, slight variations are added to the timing and speed of the loose parts of objects. This overlapping 
action makes the object seem natural, the action more interesting. In Wally's zip off (figure 5), his 
feet zipped off, one after the other, about one or two frames apart. The action was so fast that it was 
difficult to see each foot going off separately, but It made the action as a whole more interesting. 
Perhaps more important, overlapping is critical to conveying main ideas of the story. An action should 
never be brought to a complete stop before starting another action, and the second action should overlap 
the first. Overlapping maintains a continual flow and continuity between whole phrases of actions. Walt 
Disney once explained overlapping this way, "It is not necessary for an animator to take a character 
to one point, complete that action completely, and then turn to the following action as if he had never 
given it a thought until after completing the first action. When a character knows what his is going 
to do he doesn't have to stop before each individual action and think to do it. He has #planned in advance 
in his mind. For example, the mind thinks, "I'll close the door - lock it - then I'm going to undress 
and go to bed." Well, you walk over to the door - before the walk is finished you're reaching for the 
door - before the door is closed you reach for the key -before the door is lockedyou're turning away 
- while you're walking away you undo your tie - and before you reach the bureau you have your tie off. 
In other words, before you know it you're undressed - and you've done it in one thought, "I'm going to 
bed.' " [12] 2.6 STRAIGHT AHEAD ACTION AND POSE-TO-POSE ACTION (KEYFRAMES) There are two main approaches 
to hand drawn animation. The first is known as straight ahead action because the animator literally works 
straight ahead from his first drawing in the scene. He knows where the scene fits in the story and the 
business it has to include. He does one drawing after another, getting new ideas as he goes along, until 
he reaches the end of the scene. Thig process usually produces drawings and action that have a fresh 
and slightly zany look, because the whole process was kept very creative. Straight ahead action is used 
for wild, scrambling actions where spontaneity is important. The second approach is called pose-to-pose. 
Here the animator plans his actions, figures out just what drawings will be needed to animate the business, 
makes the drawings concentrating on the poses, relates them to each other in size and action, and then 
draws the inbetweens. Pose-to-pose is used for animation that requires good acting, where the poses and 
timing are all important. The pose-to-pose technique applies to keyframe computer animation with timing 
and pose control of extremes and inbetweens. The difficulty in controlling the inbetweens makes it incorrect 
to approach keyframe computer animation exactly as one would pose-to-pose hand drawn animation. In working 
with a complex model, creating a complete pose at a time would make the inbetweens too unpredictable. 
The path of action will in general be incorrect and objects will intersect one another. The result is 
much time-consuming reworking of inbetweens. There is a much better approach in the context of a hierarchical 
modelling system, which works "layer by layer" down the hierarchy. Instead of animating one complete 
pose to another, one transformation is animated at a time, starting with the trunk of the hierarchical 
tree structure, working transformation by transformation down the branches to the end. Fewer extremes 
are used. Not all translates, rotates and scales have extremes on the same frames; some have many extremes 
and others very few. With fewer extremes, the importance of the inbetweens increases, Tension and direction 
controls on the interpolating splines are helpful in controlling the spacing of the inbetween and to 
achieve slow in and out. [16] (See Slow In and Out) This layer approach to animation shares many important 
elements with the pose-to-pose technique in hand drawn animation. Planning the animation out in advance, 
as in pose-to-pose, becomes even more important. The action must be well thought out, the timing and 
poses planned so that even in the early layers, the poses and actions are clear. The Aventures of Andre 
and Wally B. and Luxo Jr. were both animated using a keyframe animation system called Md (Motion Doctor). 
[19] Luxo Jr. was animated using this layered approach to the keyfranles. Jr.'s hop (figure 1) was animated 
by first setting the keyframes for his forward movement only: two keyframes were set for the X translation, 
the first where the hop starts and the second where he lands. This defined the timing of his hop. The 
height of his hop was then defined by setting a keyframe in the Z translation (Z being up in this case). 
The next step, animating the rotation of Jr.'s arms, was important because the arms define the anticipation, 
squash and stretch, and follow through of the action. Keyframes were set for just about every frame, 
rotating the arms together before the hop for the anticipation, then immediately far apart for the stretch 
of the jump. The arms were rotated together again at the top of the arc where the action slows slightly, 
then rotated far apart, stretching to anticipate the landing. To indicate the shock of the landing, the 
arms were rotated quickly together two frames after the base lands on the floor. This is the follow through 
of the action. His base and shade were animated in the next two steps. Like the arms, many keyframes 
were set to define the rotation of the base and shade because their movement was important for anticipation 
and follow through.  2.7 SLOW IN AND OUT Slow in and slow out deals with the spacing of the inbetween 
drawings between the extreme poses. Mathematically, the term refers to second- and third-order continuity 
of motion. In early animation, the action was limited to mainly fast and slow moves, the spacing from 
one drawing to the next fairly even. But when the poses of pose-to-pose animation became more expressive, 
animators wanted the audience to see them. They found that by grouping the inbetweens closer to each 
extreme, with only one fleeting drawing halfway between, they could achieve a very spirited result, with 
the character zipping from one attitude to another. "Slowing out" of one pose, then "slowing in" to the 
next pose simply refers to the timing of the inbetweens. The animator indicates the placement of the 
inbetweens, the slow in or slow out, with a "timing chart" drawn on the side of the drawing. This tells 
himself, or his assistant who will be doing the inbetweens later, how he wanted the timing to be and 
where he wanted the inbetween drawings placed. (figur~ 9) EXTREME EXTREME FIGURE 9. Timing chart for 
ball bounce. (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 In most 3D keyframe computer animation 
systems, the inbetweening is done automatically using spline interpolation. Slow in and slow out is achieved 
by adjusting the tension, direction or bias, and continuity of the splines. [16] This works well to give 
the affect of slow in and out, but a graphical representation of the spline is required to see the effect 
of tension, direction, and continuity have on its shape. With this type of spline interpolation, a common 
problem is the spline overshooting at extremes when there is a large change in value between them, especially 
over a small number of frames. This also happens when the direction control of an extreme is adjusted. 
The danger is that, depending on the variable the spline controls (translate, rotate, or scale), the 
value will shoot in the wrong direction just before (or just after) the large change in value. Sometimes 
this effect works out well when it occurs just before a large movement, it may appear to be an anticipation. 
However, more often than not, it gives an undesirable effect. In Luxo Jr., there was an example of this 
problem of overshooting splines. Jr.'s base was very heavy and when he hopped, we wanted the base to 
start stationary, then pop up in the air from the momentum of his jump, arc over, then land with a thud, 
suddenly stationary again. For the up translation, there were three keyframes, the two stationary positions 
and the highest point of his jump. The spline software forced continuity, so that his base would move 
down under the surface of the floor just before and after the jump. (figure 10a) The solution was to 
put two new extremes, equal to the two stationary extremes, on the frames just before and just after 
the extremes. This "locked" down the spline, so that the up translation stayed the same value, popped 
up in the air, landed and then stayed the same value again. This gave the desired feeling of weight to 
his little base, (figure 10b) The same solution can be achieved by breaking the spline using its continuity 
parameter [16] at the two stationary extremes. This solution requires a graphical display of the spline 
so that the correct shape can be achieved. FIGURE 10a. This spline controls the Z (up) translation of 
Luxo Jr. Dips in the spline cause him to intersect the floor. FIGURE 10b. Two extra extremes are added 
to the spline which removes the dips and prevents Jr. from going into the basement. 2.8 ARCS The visual 
path of action from one extreme to another is always described by an arc. Arcs in nature are the most 
economical routes by which a form can move from one position to another. In animation, such arcs are 
used extensively, for they make animation much smoother and less stiff than a straight line for the path 
of action. In certain cases, an arc may resolve itself into a straight path, as for a falling object, 
but usually,, even in a straight line action, the object rotates. [12] In most 3D keyframe computer animation 
systems, the path of action from one extreme to another is controlled by the same spline that controls 
the timing (slow in and out) of the inbetween values. This may simplify computating the inbetweens but 
it has unfortunate effects. When a motion is slow, with many inbetweens, the arc of the path of action 
is curved, as desired. But when the action is fast, the arc flattens out: the faster the action, the 
flatter the arc. Sometimes this is desirable, but more often, the path of even a fast motion should be 
curved or arced. Straight inbetweens can completely kill the essence of an action. The spline that defines 
the path of action should be separate from the spline that defines the timing or spacing of the inbetweens 
for several reasons: so that the arc of a fast acdon doesn't flatten out; so that you can adjust the 
timing of the inbetweens without effecting the path of action; so that you can use different splines 
to define the path of action (where a B-spline is appropriate for its smoothness) and the timing (a CatmuU 
- Rom spline so you can adjust it's tension and direction controls to get slow in and out). This technique 
is not common, but research is being done in this area. [15] 2.9 EXAGGERATION The meaning of exaggeration 
is, in general, obvious. However, the principle of exaggeration in animation does not mean arbitrarily 
distorting shapes or objects or making an action more violent or unrealistic. The animator must go to 
the heart of anything or any idea and develop its essence, understanding the reason for it, so that the 
audience will also understand it. If a eharacter is sad, make him sadder; if he is bright, make him shine; 
worried, make him fret; wild, make him frantic. A scene has many components to it: the design, the shape 
of the objects, the action, the emotion, the color, the sound. Exaggeration can work with any component, 
but not in isolation. The exaggeration of the various components should be balanced. If just one thing 
is exaggerated in an otherwise lifelike scene, it will stick out and seem unrealistic. f  @ Computer 
Graphics, Volume 21, Number 4, July 1987 3. PERSONAHTY This final section discusses the underlying goal 
of all the principles discussed earlier. Personality in character animation is not a principle unto itself, 
but the intelligent application of all of the principles of animation. When character animation is successful 
and the audience is thoroughly entertained, it is because the characters and the story have become more 
important and apparent than the technique that went into the animation. Whether drawn by hand or computer, 
the success of character animation lies in the personality of the characters In character animation, 
all actions and movements of a character are the result of its thought processes. "The thinking animation 
character becomes a character." [12] Without a thought process, the actions of a character are just a 
series of unrelated motions. With a thought process to connect them, the actions bring a character to 
life. In order to get a thought process into an animation, it is critical to have the personality of 
a character clearly in mind at the outset, so that it makes sense to ask at any moment, "What mood is 
the character in. How would he do this action?" One character would not do a particular action the same 
way in two different emotional states. An example of this, in Luxo Jr., is the action of Jr. hopping. 
When he is chasing the ball, he is very excited, happy, all his thoughts on the ball. His hops are fast, 
his head up looking at the ball, with very little time on the ground between hops because he can't wait 
to get to the ball. After he pops the ball, however, his hop changes drastically, reflecting his sadness 
that the object of all of his thoughts and energy just a moment ago is now dead. As he hops off, each 
hop is slower, with much more time on the ground between hops, his head down. Before, he had a direction 
and purpose to his hop. Now he is just hopping off to nowhere. No two characters would do the same action 
in the same way. For example, in Luxo Jr., beth Dad and Jr. bat the ball with their heads. Yet Dad, who 
is larger and older, leans over the ball and uses only his shade to bat it. Jr., however, who is smaller, 
younger, and full of excited energy, whacks the ball with his shade, putting his whole body into iL When 
defining the character, it is important to make the personality distinct, and at the same time have characteristics 
that are familiar to the audience. If the actions of a character ring true, the audience will be able 
to relate to the character, and he will be believable to them. 4. CONCLUSION Whether it is generated 
by hand or by computer, the first goal of the animator is to entertain. The animator must have two things: 
a clear concept of exactly what will entertain the audience; and the tools and skills to put those ideas 
across clearly and unambiguously. Tools, in the sense of hardware and software, are simply not enough. 
The principles discussed in this paper, so useful in producing 50 years of rich entertainment, are tools 
as well.., tools which are just as important as the computers we work with. 5. ACKNOWLEDGMENTS The author 
would like to express sincere thanks to Bill Reeves and Eben Ostby for their unending support, education 
and creativity with the technical aspects of computer animation. Steve Upstill for making it sound like 
I know English. Nancy Tague for her ruthless editing even-on my birthday. Kate Smith and Michael Shantzis 
for their assistance in editing this paper even when they could have been watching Willie Wonka on video 
tape. Craig Good for helping with the video tape portion of this paper. Joey Tague for being pals and 
for telling us what happened in Willie Wonka. And especially to Frank Thomas and Ollie Johnston for their 
instruction in animation when the author was at the Disney Studio, and for their continued inspiration 
with their book. [26]  6. REFERENCES 1. Abel Image Research, 953 N. Highland Ave., Los Angeles, CA 90038-2481 
 2. Alias Research Inc., 110 Richmond St. East, Suite 500, Toronto, Ontario, Canada m5c- lpl 3. Blair, 
Preston, Animation, Walter T. Foster, Santa Ana CA, 1949. 4. Burmyk, Nester and Wein, Marceli, "Computer 
Generated Keyframe Animation," Journal of the SMVrE 80, pp.149-153, March 1971. 5. Burtnyk, Nester and 
Wein, Marceli, "Interactive Skeleton Techniques for Enhanced Motion Dynamics in Key Frame Animation," 
Communications of the ACM 19 (10), pp 564-569, October, 1976. 6. Catmull, Edwin, "A System for Computer 
Generated Movies," Proceedings ACM Annual Conference, pp. 422-431, August 1972. 7. Catmull, Edwin, "The 
problems of Computer- Assisted Animation," SIGGRAPH '78, Computer Graphics, Vol. 12, No. 3, pp. 348-353, 
August 1978. 8. Cook, Robert L., "Stochastic Sampling in Computer Graphics," ACM Transactions on Graphics, 
Vol. 5, No. 1, pp. 51-72, January 1986. 9. Cook, Robert L., Porter, Thomas, and Carpenter, Loren, "Distributed 
Ray Tracing," SIGGRAPH '84, Computer Graphics, Vol. 18, No. 3, pp.137-145, July, 1984. 10. Walt Disney 
Productions, Three Little Pigs, (film), 1933. 11. Gracer, F., and Blagen, M. W., "Karma" A System for 
Storyboard Animation," Procee.ding Ninth Annual UAIDE Meeting, pp. 210-255, 1970. 12. Graham, Don, The 
Art of Animation, unpublished. 13. Graham, Don, transcripts of action analysis class at the Walt Disney 
Studio, June 21, 1937. 14. Graham, Don, transcripts of action analysis class with Bill Tytla at the 
Walt Disney Studio, June 28, 1937. 15. Hardtke, lnes, and Bartels, Richard, "Kinetics for Key-Frame 
Interpolation," unpublished. 16. Kochanek, Doris, and Barrels, Richard, "Interpolating Splines with 
Local Tension, Continuity, and Bias Control," SIGGRAPH '84, Computer Graphics, Vol. 18, No. 3, pp. 33-41, 
July, 1984. 17. I.~voy, Marc, "A Color Animation System Based on the Multi-Plane Technique," SIGGRAPH 
'77, Computer Graphics, Vol. 11, No. 2, pp. 64-71, July, 1977.  . ~ SIGGRAPH '87, Anaheim, July 27-31, 
1987 18. Lucasfilm Ltd. Computer Graphics Div., The Adventures of Andre and Wally B., (fdm), 1984.  
 19. Ostby, Eben, Duff, Tom, and Reeves, William, Md (motion doctor), animation program, Lucasfilm Ltd., 
1982-1986.  20. Perine, Robert, Chouinard, An Art Vision Betrayed , Artra Publishing, Encinitas CA, 
1985.  21. Pixar, Luxo Jr., (film), 1986.  22. Reeves, William, "Inbetweening for Computer Animation 
Utilizing Moving Point Constraints," SIGGRAPH '81, Computer Graphics, Vol. 15, NO. 3, pp. 263-270, August 
1981.  23. Rydstrom, Gary, Soundtraek for Luxo Jr., Sprocket Systems Div., Lucasfilm Ltd., July, 1986. 
 24. Stem, Garland, "Bboop--A System for 3D Keyframe Figure Animation," Tutorial Notes: Introduction 
to Computer Animation , SIGGRAPH '83, July 1983.  25. Symbolics Inc., 1401 Westwood Blvd., Los Angeles, 
CA 90024 26. Thomas, Frank and Johnston, Ollie, Disney Animation-- The Illusion of Life, Abbeville Press, 
New York, 1981.  27. Thomas, Frank, "Can Classic Disney Animation Be Duplicated On The Computer?" Computer 
Pictures, Vol. 2, Issue 4, pp. 20-26, luly/August 1984.  28. Vertigo Systems International Inc., 119 
W. Pender St., Suite 221, Vancouver, BC, Canada v6b ls5  29. Wavefront Technologies, 530 East Montecito, 
Santa Barbara, CA 93101 30. Whitakcr, Harold and Halas, John, Timing for Animation , Focal Press, London, 
1981.  31. White, Tony, The Animator's Workbook, Watson-Gupfill, New York, 1996.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37408</article_id>
		<sort_key>45</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Principles and applications of pencil tracing]]></title>
		<page_from>45</page_from>
		<page_to>54</page_to>
		<doi_number>10.1145/37401.37408</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37408</url>
		<abstract>
			<par><![CDATA[Pencil tracing, a new approach to ray tracing, is introduced for faster image synthesis with more physical fidelity. The paraxial approximation theory for efficiently tracing a pencil of rays is described and analysis of its errors is conducted to insure the accuracy required for pencil tracing. The paraxial approimation is formulated from a 4x4 matrix (a system matrix) that provides the basis for pencil tracing and a variety of ray tracing techniques, such as beam tracing, ray tracing with cones, ray-object intersection tolerance, and a lighting model for reflection and refraction. In the error analysis, functions that estimate approximation errors and determine a constraint on the spread angle of a pencil are given.The theory results in the following fast ray tracing algorithms; ray tracing using a system matrix, ray interpolation, and extended 'beam tracing' using a 'generalized perspective transform'. Some experiments are described to show their advantages. A lighting model is also developed to calculate the illuminance for refracted and reflected light.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Experimentation</gt>
			<gt>Measurement</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP36029177</person_id>
				<author_profile_id><![CDATA[81100495695]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mikio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shinya]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NTT Electrical Communications Laboratories, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14171823</person_id>
				<author_profile_id><![CDATA[81100491040]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Takahashi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NTT Electrical Communications Laboratories, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P261502</person_id>
				<author_profile_id><![CDATA[81100603244]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Seiichiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Naito]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NTT Electrical Communications Laboratories, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[T.Whitted, 'An improved illumination model for shaded display', Comm. ACM, 23, No.6, pp.343- 349 (1980)]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808588</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[P.S.Heckbert and P. Hanrahan, 'Beam tracing polygonal object', Computer Graphics, 18, No.3, pp.119- 127 (1984)]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>492</ref_obj_id>
				<ref_obj_pid>441</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J.Amanatides, 'Ray tracing with cones', Computer Graphics, 18, No.3, pp.129-135 (1984)]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15918</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A.H.Barr, 'Ray tracing deformed surfaces', Computer Graphics, 20, No.4, pp.287-296 (1986)]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M.Born and E.Wolf, Principles of Optics, pp.190- 196, New York: Pergamon, 1959]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[G.A.Deschamps, 'Ray techniques in electromagnetics', Proceedings of the IEEE, 60, No.9, pp.1022- 1035 (1972)]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807479</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S.M.Rubin and T.Whitted, 'A three dimensional representation for fast rendering of complex scenes', Computer Graphics, 14, No.3, pp.110-116 (1980)]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J.T.Kajiya, 'The rendering equation', Computer Graphics, 20, No.4, pp.143-150 (1986)]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325169</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[T.Nishita and E.Nakamae, ~Continuous tone representation of three-dimensional objects taking account of shadows and interreflection', Computer Graphics, 19, No.3, pp.23-30 (1985)]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[R.L.Cook, T.Porter, and L.Carpenter, 'Distributed ray tracing', Computer Graphics, 18, No.3, pp.137- 145 (1984)]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~ ¢ Computer Graphics, Volume 21, Number 4, July 1987 Principles and Applications of Pencil Tracing 
Mikio Shinya Tokiichiro Takahashi Seiichiro Naito NTT Electrical Communications Laboratories 3-9-11, 
Midori-cho, Musashino-shi Tokyo 180, Japan Abstract Pencil tracing, a new approach to ray trac- ing, 
is introduced for faster image synthesis with more physical fidelity. The paraxial approxima- tion theory 
for efficiently tracing a pencil of rays is described and analysis of its errors is conducted to insure 
the accuracy required for pencil tracing. The paraxial approximation is formulated from a 4x4 matrix 
(a system matrix) that provides the basis for pencil tracing and a variety of ray trac- ing techniques, 
such as beam tracing, ray tracing with cones, ray-object intersection tolerance, and a lighting model 
for reflection and refraction. In the error analysis, functions that estimate approx- imation errors 
and determine a constraint on the spread angle of a pencil are given. The theory results in the following 
fast ray tracing algorithms; ray tracing using a system ma- trix, ray interpolation, and extended 'beam 
trac- ing' using a 'generalized perspective transform'. Some experiments are described to show their 
ad- vantages. A lighting model is also developed to calculate the illuminance for refracted and reflected 
light. CR Categories and Subject Descriptors: 1.3.3 [Com-pute~" Graphics]: Picture/Image Generation; 
1.3.7 [Com-puter Graphic@ Three-Dimensional Graphics and Re- alism Additional Keywords and Phrases: Ray 
Tracing, Parax- ial Theory  Introduction The ray tracing algorithms [1] provide powerful tools for creating 
realistic images. However, from a practical view- Permission to copy without fee all or part of this 
material is granted provided that the copies are not made or distributed for direct commercial advantage, 
the ACM copyright notice and the title of the publication and its date appear, and notice is given that 
copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, 
requires a fee and/or specific permission. &#38;#169; 1987 ACM-0-89791-227-6/87/007/0045 $00.75 point, 
there have been problems such as high computa- tional cost and aliasing. Many attempts have been made 
to tackle those problems, and some of them have pro- duced good results by tracing a pencil 1 (or bundle) 
of rays, instead of an individual ray. However, as the meth- ods lack sufl%cient mathematical bases, 
they are limited to specific applications. Heekbert proposed a method called 'beam tracing'[2] which 
works well for reflecting polygonal objects. His method uses a pencil to be traced by introducing affine 
transformations in an object space. Unfortunately, the method finds only limited applications because 
of the way in which it approximates refractions. Moreover, since an error estimation method has not been 
proposed for guaranteeing the image accuracy, the accuracy cannot be controlled. Amanatides proposed 
a 'ray tracing with cones' tech- nique for anti-aliasing, fuzzy shadows, and dull reflec- tions[3], where 
a conic pencil is traced. However, it failed to present a general equation for characterizing the spread- 
angle change of a conic pencil through an optical system. Such an equation is also required for the calculation 
of ray-object intersections proposed by Barr[4], where the calculation tolerance is related to the pencil 
spread-angle. In a lighting model, the equation wilt also play an im- portant role, because the illuminance 
distribution results from the calculation of how the light pencils converge and diverge according to 
reflections and refractions. This paper describes the theory of pencil tracing and its applications to 
provide general mathematical tools for efl%iently tracing a pencil and also for conducting error analysis 
to insure the image accuracy. In the theory, a linear approximation approach is taken, because, in gen- 
eral, the exact behavior of a pencil cannot be analytically obtained. The theory is based on the paraxial 
approxima- tion theory[5,6], where a pencil transformation through an optical system is formulated from 
a 4x4 matrix (a system matrix). This formulation is well-known in op- tical design and electromagnetic 
analysis[6]. The error analysis provides functioris that estimate approximation 1The rays that are near 
to a given axial ray are called paraxial and are said to form a pencil. ~ SIGGRAPH '87, Anaheim, July 
27-31, 1987 errors and determine a constraint on the spread angle of a pencil to insure the required 
accuracy of generated images. Applications of the theory result in the following fast ray tracing algorithms: 
ray tracing using a system ma-trix, ray interpolation, and extended 'beam tracing' using a 'generalized 
perspective transform'. Some experiments are described to show their advantages. A lighting model from 
which to calculate the illuminance for refracted and reflected light is also developed. 2 Paraxial approximation 
theory The paraxial approximation theory provides a linear ap- proximation for ray changes due to refraction, 
reflection, and 'transfer', where ~transfer' means propagation in a homogeneous medium. A linear ray 
change can be rep- resented by a matrix, and thus, paraxial ray tracing by a matrix product. Since the 
paxaxial approximation theory seems little known in computer graphics today, it will be briefly reviewed 
here. For details, see [5],[6].  2.1 Definitions Ray: A t~araxial ray is a ray extending along the vicinity 
of a given axial ray 2. Thus, it is appropriate to represent a paraxial ray with respect to the axial 
ray. In the theory, a paraxial ray is represented by a four-dimensional vector (ray vector) in a coordinated 
system formed with respect to the axial ray (ray coordinate system). Ray coordinate system In Figure 
1, an orthog-onal coordinate system xl-x2-z, called a 'ray coordinate system', is used to represent a 
paraxial ray. The origin O is a point on the axial ray, and the ~-axis is the direction of the axial 
ray. The il-and i2-axes can be arbitrar- ily chosen, and the ~1-~2 plane is perpendicular to the ~-axis. 
 Ray vector for a paraxial ray Generally, a ray is uniquely specified by its direction and the position 
it passes. Thus, referring to xl and x2, a paraxial ray can be representedby two kinds of vectors: the 
position vector = (xlx2) t to represent the intersection of the paraxial ray with the xl-x2 plane relative 
to the origin O, and the direction vector ~ = (~1~) t which is the projection of the normalized ray direction 
vector s of the paraxial ray onto the Xl-X2 plane. Combining those two vectors, the paraxial ray is defined 
by a four-dimensional vector ¢ at O by the equality 2An axial ray has nothing to do with the axes of 
optical systems having special physical or mathematical meanings in the systems, such as a lens axis. 
An adequate ray can be chosen as the axial ray for a pencil to trace, e.g., the center line of a cone 
in the case of a conic pencil. J \-~-----~ paraxial ray 0 " z / axial ray ] ~ i-:~2plane /I / Figure 
1 Definition of ray vector (-) ¢= ~ - The four-dimensional vector ¢ is called a ray vector. Pencil: 
A pencil is made up of an axial ray and a bundle of paxaxiM rays around it represented by ray vectors. 
A pencil is mathematically represented by a domain in four- dimensional space, x-~, representing the 
deviations in po- sitions and directions of its paraxial rays from its axial ray. In image synthesis, 
all rays to be traced usually start at a common point, or a pin hole. In this case, a pencil can be simply 
represented by its direction deviation from its axial ray at the pin hole, or the pencil spread angle. 
 System matrix: When a ray goes through an optical system, the ray vector changes due to reflections, 
refractions and trans-fers. The deviation of a paraxial ray from the axial ray can be chosen small enough 
that the transformation rep- resenting a ray vector change is regarded as linear and can be represented 
by the matrix ¢' = T¢, where ¢ is the input ray vector and ¢' is the output vector. T is a 4 x 4 matrix 
called a system matrix. When a system consists of two sub-systems in cascade and their respective system 
matrices are known, the overall system matrix is simply the product of the two matrices.  2.2 System 
matrices In computer graphics, optical systems usually consist of homogeneous regions separated by smooth 
surfaces, where axly optical phenomenon can be represented by a reflec- tion, a refraction or a transfer. 
Therefore, an overall system matrix for any system can easily be obtained, if system matrices are given 
for each element system, i.e., a transfer, a reflection, or a refraction. Surface smoothness ~ is an 
essential condition for the system matrix approach; the surface in a system should have continuous second- 
order differentials. If discontinuities or edges exist in a system, it should be spatially divided into 
sub-systems so that no system contains an edge. Element-system matrices are given analytically by us- 
ing Snell's law and geometry. They are formulated as follows: (1) Transfer: In a homogeneous region, 
rays are straight. Thus, the propagation along the axial ray from z = 0 to z0 shown in Figure 2 is represented 
by   (10) T= 0 1 ' (1) where each element is a 2x2 matrix and 1 means a 2x2 identity matrix. (2) 
Refraction. Consider a refraction on the surface N in Figure 3. The optical indices of the two media 
are n and n ~. At the origin O, the incident axial ray meets N. The orthogo- hal coordinate systems :Cl-X2 
and ~-~ are the incident ray coordinate system and the refracted ray coordinate system, respectively, 
and both coordinate planes are per- pendicular to their respective axial rays. Another or-thogonal coordinate 
system fil-fi2 is perpendicular to the normal of ~ at 0 and is used to represent ~. For sim- plicity, 
the coordinates are chosen such that 372=fi2=~?~. The formulation of the system matrix for a refraction 
on is performed by approximating N to a paraboloid; an approach somewhat similar to Barr's tangent plane 
ap- proximation[4]. Thus, the transformation is analytically derived using Snell's law as ®'0 -1 1 ) 
T= (O,,)_lhOO_ 1 (n/n,)(O,t)_~O , , (2) where O= (~1"~1 ~1"~ ~ ~.% ),O, = (~ a, ~.~% ~'~ , - h = cos 
0' (~t~') cos 0, Figure 2 System matrix for transfer Computer Graphics, Volume 21, Number 4, July 1987 
III IIII I and ~1 is a unit vector of the ~1 axis direction. When the coordinate systems are chosen 
as in the figure, the matrices 0 and 0 t are diagonalized as 0 1 ' 0 1 ' The matrix Q is the curvature 
matrix of ~ in the ul-fi2 coordinate. For example, when ~ is a sphere of radius r, 0) 0 1/r ' (3) Reflection: 
The system matrix for a reflection is derived mathe- matically as a special case of a refraction. It 
is obtained by simply replacing O' with (rr-0) and n' with n in Eq.(2). 3 Tolerance and error analysis 
In this section, pencit tracing approximation errors and tolerances for calculated ray-object intersections 
are dis- cussed to show that they are given as functions of the system matrices. This leads to a discussion 
of how to determine a limit on the spread angle of a pencil in order to retain accuracy and fidelity 
in calculated images. 3.1 Tolerances The criterion used here is similar to Barr's[41, which is based 
on pixel width and ray sampling interval. Since the sampling interval limits the resolution of a ray-traced 
im- age, an approximation error smaller than the interval has little effect on the resolution. Although 
Barf's tolerance equation is not applicable to refracted or reflected pen- cils, it can easily be extended 
by using a system matrix. Consider the situation shown in Figure 4, where ~ is a four-dimensional vector 
representing a ray interval, i.e., a sampling interval of position and direction, and T = t3 t4 E 1 0 
o1' * "r~. f incident ray refracted ray :c'2 Figure 3 Refraction of a pencil. A circle with a dot denotes 
a vector emarging perpendicular to the page.   ~,~ SIGGRAPH '87, Anaheim, July 27-31, 1987 is an overall 
system matrix. The sampling interval of the intersection points on the xl-x2 plane becomes ( tl t2 ) 
~, and the tolerance r on the plane is given in terms of pa- rameter p as where p indicates the ratio 
of the tolerance to the inter- val, and it represents the image accuracy. When one: pixel-width resolution 
is required, p should be less than 1/2. Equation (3) is also applicable to Barr's intersection calculation 
method. 3.2 Error estimation function When a paraxial ray ¢i~ is changed into jolt through an optical 
system, ¢o~t may be expressed in terms of a power series of ¢i,~. The i-th component of the vector ¢o~t 
is represented by 4 4 ,(1)/.inx .(2)/~ina /.in~ (~°~')~ = z_,r~j ~, )~+ ~ r~k~ )j~w )k+-.- j=l j,k=l 
  = (¢,o~,), + (~¢), + o((¢,~)~), where t!J ) is an element of the system matrix, and to) = a~( ¢o~,),/ 
a( ¢%a( ¢,o )~ ijk Since higher-order terms are considered to be neg- ligible for small ¢i~ value, the 
second-order term de alone is enough to estimate the linear approximation er- ror (¢°~'t - ¢'°~t). The 
coefficients tl~k ) for each element system, e.g., re-fraction, can be derived analytically and they 
can be applied to general systems. However, a straightforward computation of ,~ ¢ is rather cumbersome 
because of the complicated forms of its elements. Furthermore, since the absolute values of error vectors, 
,~x and ,~, are far more important than their directions in terms of error estimation, we introduce the 
more compact error estima- tion functions, e= and e~, to estimate the absolute values of errors. This 
results in the expressions  e~(x0,~0) = Ax~ + Bxo&#38; + CQ 2 ~_ I,~1 and  ee(x0,40) = Dx~ + Exo~o 
+ F(~ >-I~l, (4) where d~ =~¢ x0 = I~01, 40 = I~0l screen optical system x1-:~:2 plane Figure 4 Sampling 
interval and tolerance ~o) = ¢in. ~0 A - F are constants and depend on the system matri- ces, axial 
incident angles, optical indices, and so on. As the derivation is very complicated, the details are omitted 
here. The results are presented in the appendix. Equations (3) and (4) provide the condition for pencil 
tracing with the required accuracy. If all paraxial rays in a pencil satisfy the inequality e=(x0, 40) 
_< r, (5) the generated image is accurate enough. In the case where a pencil emerges from a pin hole, 
Xo is 0 and Eq. (5) is simplified as C~o~ _< r, (6) J to provide the maximum pencil spread angle for 
the re- quired accuracy. 4 Applications Since the theory describes general pencil behaviors, it can be 
used in many places in computer graphics. In this section, three fast ray tracing methods are proposed, 
and a general illuminance formula for refracting and reflect- ing environments is introduced that demonstrates 
actual applications of the theory. 4.1 Pencil tracer as a fast ray tracer (1) Ray tracing with system 
matrix: This method is a straight-forward installation of the theory, and accelerates image systhesis 
of smooth refract- ing and reflecting objects by replacing conventional re- fraction and reflection calculations 
with matrix-vector manipulations. Paraxial rays are traced by a system matrix, calcu- lated by Eqs. (1) 
and (2). The pencil spread angle is controlled to satisfy tolerance condition (6). Since ray tracing 
with a system matrix is not applicable in the neighborhoods of object edges because of the smoothness 
requirement, individual rays in those regions are traced with a conventional ray tracer. ~) '~ Computer 
Graphics, Volume 21, Number 4, July 1987 The procedure is as follows: 1) Divide the screen into n x m 
initial domains of a certain number of pixels a. Do the following process for each domain: 2) Set the 
axial ray at the center of a domain, and trace it with the conventional ray tracer. Calculate the system 
matrix. 3) Check the smoothness condition (to be discussed below). If an edge exists in the domain, trace 
all the rays with the conventional ray tracer. 4) If there is no edge, calculate the tolerance and the 
maximum pencil-spread angle by using Eqs. (4) and (6). Then, according to the maximum pencil- spread 
angle, do the following: a) Trace all paraxial rays in the domain with the system matrix if the maximum 
spread angle of the domain is smaller than that of the pencil. b) Trace all paraxial rays with the ray 
tracer, if the maximum pencil spans an area less than one pixel wide. c) Otherwise, divide the domain 
into sub-domains so that their maximum spread angles are less than that of the pencil. Repeat 2)- 4) 
for each sub-domain. Anti-aliasing by subpixel sampling can be achieved in the same way by using the 
system matrix, except in the neighborhood of an edge. In our preliminary implementation, the smoothness 
condition is roughly checked by comparing the ray trees among the neighboring domains, and the condition 
is assumed to be satisfied when no difference is detected among the ray trees. It is possible for an 
object smaller than the initial domain area to vanish from the image. This problem can be solved by estimating 
the distances between an axial ray and object surfaces, as in the case of ray tracing with cones [3]. 
Amanatides' method can deal with the estimation for simple objects such as spheres and polygons. It is 
considered that the bounding volume techniques(J7] among others) will be effective for this es- timation. 
However, further investigation is required to solve the problem. (2) Ray interpolation: In this method, 
the intersection point and the direc- tion of an interior paraxial ray are linearly interpolated without 
a system matrix calculation in order to provide further computational saving. Consider the situation 
shown in Figure 5, where two rays, ¢0 and ¢0 + 6, are traced and ~ and ~ give their aLarger initial domains 
do not necessarily lead to faster image synthesis. There is a certain point in a domain area (5x5 pixels 
in our experiment) beyond where She speed of image synthesis no longer improves. rI 1 Po - optical system 
object Figure 5 Ray interpolation intersections with the object. A paraxial ray represented by ¢' = % 
+ a6 can be considered to intersect with the object at the point that can be linearly interpolated by 
the expression =a 4+(1-a)4. The direction vector of the paraxial ray can also be in- terpolated in the 
same manner. A precise analysis of the interpolation error is not an easy task. However, if a second 
order approximation is good enough to estimate the true a~, the error can be estimated by evaluating 
first and second order interpola- tions. For this, one more intersection of another ray is necessary. 
For example, when the intersection ~'-1 of the ray %50 - 6 is given, the error is estimated by e~,, = 
1(second order interpolatlon)-(liner interpolation)l , where (second order interpolation) = a(a -1)ml_l/2 
+ (1 - a)(1 + a)~ + a(1 + a)m'l/2 In case that the second-order approximation is not good, ein t simply 
checks the linearity of m with respect to a. Comparing with the system matrix method, the ray interpolation 
has the advantage in computation speed, but a disadvantage in the precision of the error estima-tion. 
Thus, it is considered that the method is effective for tracing a thin pencil, e.g., in the case of subplxel 
sam- pling for anti-aliasing. This will be shown in the section 5. Note that if linearity is assumed 
for brightness 1(~), the brightness can also be interpolated by /(mr) = al(m'1) + (1 --a)I(4 ). (3) Generalized 
perspective transforlnatloll: This method is a modification of Heckbert's beam tracing[2], and it is 
effective for refracting and reflect-ing polygonal environments. Although the beam tracing ~ SIGGRAPH 
'87, Anaheim, July 27-31, 1987 fl% / ~ 0 ° T= C object screen pin hole optical system Figure 6 Generalized 
perspective transformation method works well for reflections, it provides a rather poor approximation 
for refraction. It assumes either that incident rays are nearly perpendicular to a surface~ or that all 
rays are parMlel. The system matrix provides a better approximation using local linearity. Consider the 
situation shown in Figure 6. The ray ~b = (0, ~)* goes from the pin hole to the object point w/through 
the optical system, where z ] is represented in the ray coordinate system. Using the system matrix, it 
is expressed as, x' = A~, where A is a 2 × 2 sub-matrix of the system matrix. The screen point x, is 
directly calculated by ~, wherein the linear approximation is represented by x~ = S~, where S is a 2x2 
inatrix. Thus, the transformation from an object point to a screen point is given by *s = SA-lx ' = P~. 
(7) Here, P is considered as a 'local' perspective transfor- mation for refracting and reflecting systems. 
The trans- formation P coincides with the usual perspective trans- formation for a transfer, and with 
the ones of the beam tracing for a reflection and the perpendicular incident re- fraction. The transformation 
can be implemented in almost the same way as the beam tracing: a pencil formed by a polygon boundary 
is approximated by a pyramidal pencil that is represented also by a polygon on the ~-plane or on the 
screen. The system matrix is calculated by Eqs. (1) and (2), and the polygons in the object space are 
mapped onto the screen by Eq. (7) to allow searching for visible polygons through a polygon clipping 
technique and a hidden surface technique by referring to z-values in the ray coordinate system. Anti-aliasing 
can be performed by the techniques for the scan line algorithm. Errors can be estimated by using Eq. 
(4), and dividing the pencil can assure image accu- racy though this has not been implemented yet. This 
method is free from the edge problem of the system ma- trix. 4.2 Illuminance formula A light is converged 
or diverged by refractions, and reflec- tions on curved surfaces. This makes a variety of shadow patterns 
caused by light concentration. Conventional il- lumination models fail to simulate this phenomena and 
they create unnatural sharp shadows for transparent ob- jects. Kajlya succeeded in creating realistic 
shadows of transparent objects by using his powerful rendering equa- tion and a Monte Carlo method[8]. 
However, there are two problems with his method. First, the equation he point source Id~ EdS dft dS Figure 
7 Light pencil emitted from a point source (~) @  used is based on the inverse square law of light inten- 
sity which is not valid for refracted or reflected light. Strictly speaking, the calculated illuminance 
is theoreti- cally incorrect. Second, it requires a tremendous amount of computation time, even for a 
very simple situation. It is easy to extend the intensity law by using a system matrix[6], and the illuminance 
is analytically calculated for point light sources and parallel light beams when us- ing it. Consider 
a pencil emitted from a point source and passing through an optical system onto an object sur- face, 
as shown in Figure 7. For simplicity, assume that the same medium, e.g. air, surrounds both the source 
and the object. Let the luminous intensity of the source be I, the illuminance on the surface E, and 
the trans- mittance of the system t~. Then, energy preservation is represented by t~Idf~ = EdS, where 
df~ is the emitted pencil solid angle, and dS is the illuminated area on the surface. Using the system 
matrix and the ray coordinate systems gives ~' A B m o)(,) E1 x 1 and () () = ~2 ' ~ = X2' ' and df~ 
and dS are given by df~ = Id~ld~2h and dS = [dxldx2/ cos~], where oe is the angle between the axial 
ray and the surface normal. Thus, the illuminance is given by E = t~I cos ald~ld(2/dx[dx~] = trIcos ~ll/det(B)]. 
(8) In the case of a transfer, det(B) is z 2, where z is the distance between the source and the illuminated 
point, and thus, Eq. (8) represents the inverse square law. How- ever, for a refracted light pencil, 
the inverse square law is not valid, because in general det(B) # z 2. Likewise, for a parallel light 
source, it is derived that Z = t~Icos a/ll/det(A)l. (9) Using Eq. (8) instead of the inverse square 
law, Ka- jiya's equation becomes perfectly correct. However, for a simple situation where point sources 
illuminate transpar- ent objects, the pencil tracer traces light pencils from the sources, simulating 
caustics and shadows more efficiently. This becomes more distinctive in the case of the proposed generalized 
perspective transformation for polygonal ob- jects, as will be shown in Section 5. Furthermore, the illuminanee 
formula (8) and the generalized perspective transformation can be applied to Nishita and Nakamae's radiosity 
method[9] for simulating interreflection between both refracting and diffusive polyhedra. Computer Graphics, 
Volume 21, Number 4, July 1987 5 Experimental Results Figure 8 shows an image generated through ray tracing 
with a system matrix and anti-aliased by nine rays per pixel subpixel-sampling using the ray interpolation 
tech- nique. The computation time is about 230 seconds on a VAXll/780 for 256x256 pixels, which is 7.6 
times faster than our conventional ray tracing program. Since ray in- terpolation is a eomputationally 
inexpensive process, the improvement in speed becomes more significant as the subpixel sampling rate 
increases. Figure 9 shows the ratio of the CPU time of the pencil tracer to the time of the conventional 
one, with respect to the number of ray samples per pixel. The time ratio decreases to less than 1/10 
as the sampling ratio increases to 49. This suggests that the method is particularly effi- cient in creating 
'high quality' anti-aliased images. The tolerance used here is one-half pixel width, or p= 1/2. Figure 
10 shows the error distribution of the image, where the error is measured by the distance between ray- 
object (checkerboard) intersections obtained by the pen- oil tracer and by the ray tracer normalized 
by one pixel- interval on the checkerboard. Errors are less than the specified tolerance, 1/2, in over 
99.8% of the image area, and the largest error is only 0.66 pixel width. This sug- gests that errors 
are estimated strictly enough. Since the error estimation is a worst case estimation, the actual er- 
rors are considered to be much smaller than the tolerance in most areas, as shown in the figure. Figure 
11 shows an image of a transparent polyhedron consisting of 100 polygons generated by th(~ generalized 
perspective transformation without error estimation and anti-aliasing. The illuminance on the three-colored 
rect- angle is calculated by illuminance formula (8), simulating the light pencil concentration effect 
caused by refractions. The shadows and the image are created individually, and each computation time 
is about 200 seconds and 74 sec- onds, respectively, on a VAXll/780 for 512x512 pixels. The ray tracing 
program takes about 49 minutes and it creates only a non-shadowed image using a rectangular solid bounding 
volume. It is estimated that it would take several tens of times more to calculate precise shadows like 
in Fig. 11 by the ray tracer, because, from Kajiya's experiment[8] and our experiences, it is believed 
that sev- eral tens of rays per pixel sampling might be necessary for a good approximation. 6 Conclusion 
In this paper, the theory and applications of pencil trac- ing have been described. In the theory, we 
introduced a system matrix approximation and analyzed the approxi- mation errors. The system matrix describes 
general pen- cil behavior, and it provides the basis for pencil trac-ing. From approximation error analysis, 
we derived a parabolic error estimation function that enables pencil (~ @ Computer Graphics, Volume 
21, Number 4, July 1987 , , i i tracers to assure a required image accuracy. The theory solves a variety 
of ray tracing problems in the following ways: The system matrix provides a better approximation of 
refraction and error estimation tools for beam tracing[2].  The system matrix provides a general calculation 
method to obtain a pencil-spread angle which is necessary for ray tracing with cones[3].  The system 
matrix provides a general method for tolerance calculation which is es.scntial for Barr's ray tracing 
method[4].  The system matrix provides a general illuminance formula that describes the light concentration 
ef- fect.  The system matrix provides fast ray tracing and anti-aliasing methods for smooth refracting 
and re- flecting objects. Image accuracy is assured due to the error estimation function.  As applications, 
we proposed three fast ray tracing algorithms, ray tracing with a system matrix, ray inter- polation, 
and generalized perspective transformation. An illuminance formula that describes the intensity law for 
general situations is also presented. Using the formula, pencil tracers can analytically calculate illuminances 
for refracted and reflected light emitted by point sources. Experiments confirmed their efficiency in 
speed, accu-racy and reality for smooth transparent objects. The edge problem still remains in ray tracing 
with the system matrix, and further research is required. As the theory provides general tools for pencil 
trac- ing, it is considered that pencil tracing is applicable to many situations that require tracing 
many close rays. These situations include, for example, when creating a motion-blurred picture, demonstrating 
the dispersion ef- fect of transparent objects, making many pictures from a continuously moving view 
point, and distributed ray tracing[10]. Acknowledgment We would like to th~nk Dr. S. Shimada, for his 
con- tinuous support. We would also like to thank Dr. K. Tsukamoto, Dr. I. Masuda, Mr. If. Ueno, Dr. 
T. Mashiko, Mr. T. Naruse, Mr. M. Yoshida, and Mr. H.Murase for their invaluable advice and encouragement. 
We are greatly indebted to Dr. N. Osumi for preparing the pa- per, and to the reviewers for their useful 
comments. References [1] T.Whitted, 'An improved illumination model for shaded display', Comm. ACM, 23, 
No.6, pp.343- 349 (1980) [2] P.S.Heckbert and P. Hanrahan, 'Beam tracing polyg- onal object', Computer 
Graphics, 18, No.3, pp.119- 127 (1984) [3] J.Amanatides, 'Ray tracing with cones', Computer Graphics, 
18, No.3, pp.129-135 (1984) [4] A.H.Barr, 'Ray tracing deformed surfaces', Com- puter Graphics, 20, No.4, 
pp.287-296 (1986) [5] M.Born and E.Wolf, Principles of Optics, pp.190- 196, New York: Pergamon, 1959 
[6] G.A.Deschamps, 'Ray techniques in electromagnet- ics', Proceedings of the IEEE, 60, No.9, pp.1022- 
1035 (1972) [7] S.M.Rubin and T.Whitted, 'A three dimensional representation for fast rendering of complex 
scenes', Computer Graphics, 14, No.3, pp.110-116 (1980) [8] J.T.Kajiya, 'The rendering equation', Computer 
Graphics, 20, No.4, pp.143-150 (1986) [9] T.Nishita and E.Nakamae, ~Continuous tone rep-resentation of 
three-dimensional objects taking ac- count of shadows and interreflection', Computer Graphics, 19, No.3, 
pp.23-30 (1985) [10] R.L.Cook, T.Porter, and L.Carpenter, 'Distributed ray tracing', Computer Graphics, 
18, No.3, pp.137- 145 (1984) Appendix Error estimation functions, e~ and ee (1) Transfer: Since the second 
term of a ray change 4~' is zero, the error estimation function is equal to zero. (2) Refraction or reflection: 
e= = ax 2 + bx~ + c~ 2 ~ = d~ + ~ + f~2 (A-l) where a = (eose'/2Rcos~a)i~+~tane'l, b = (l<,<lt-y)(~/~'), 
C -~ O, d = (1~11 cos ~ e)[(l/4R3){tan e + (2 + Inl) tan e'} + v~4.,], e = I-ytan8'-- (1/-y)tanSi/(RcosS)(nln'), 
f = (-yl~l/2)(nln'), = tan ~ -- -y tan S', = l--y, -y = n cos ~/n' cos 6' and R is the maximum curvature 
of the surface at the origin, ~ and e ~ are the incident and refracted axial ray angles, and d3,~ is 
the maximum third differential value at the point, defined by a~ = max (lO~ f lOuiOujOukl). i,j,k=l,3 
 ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 (3) General system Consider a system composed of n element 
systems, wherein the system matrix is T = T,,T,~_, ..-T~, where 2q is the system matrix of an i element 
system. For simplicity, let the 4x4 matrices Tf and T~ be = { TnT,-ll fOrfori=ni= ""T~+I 1,2,...,n-1 
( A~i A~i ) a a , A3i A41 = { 1 fori=l Ti_ITi-2...T1 for i = 2,3,-.-,n where A~i and A~i are 2 x 2 
matrices. Tho orr()l' estimation functions are given by n i=l i~nd i=1 w[lere M~ = (m' m2), Pi3 /~14 
( ai bl/2) Pi = bi/2 ci ' ( di e,/2) Qi = el~2 fl " The values #ij and A 0 are square roots of the larger 
eigen values of b b t a a t A,~(A,j) and Aij(A,~) , respectively. The value al to fi is a coefficient 
of the error estimation func- tion for the i element system, given by Eq. (A-l).  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37409</article_id>
		<sort_key>55</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Fast ray tracing by ray classification]]></title>
		<page_from>55</page_from>
		<page_to>64</page_to>
		<doi_number>10.1145/37401.37409</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37409</url>
		<abstract>
			<par><![CDATA[We describe a new approach to ray tracing which drastically reduces the number of ray-object and ray-bounds intersection calculations by means of 5-dimensional space subdivision. Collections of rays originating from a common 3D rectangular volume and directed through a 2D solid angle are represented as hypercubes in 5-space. A 5D volume bounding the space of rays is dynamically subdivided into hypercubes, each linked to a set of objects which are candidates for intersection. Rays are classified into unique hypercubes and checked for intersection with the associated candidate object set. We compare several techniques for object extent testing, including boxes, spheres, plane-sets, and convex polyhedra. In addition, we examine optimizations made possible by the directional nature of the algorithm, such as sorting, caching and backface culling. Results indicate that this algorithm significantly outperforms previous ray tracing techniques, especially for comples environments.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Measurement</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14183802</person_id>
				<author_profile_id><![CDATA[81100529394]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Arvo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Apollo Computers, Inc., Chelmsford, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14068580</person_id>
				<author_profile_id><![CDATA[81100166914]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kirk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Apollo Computers, Inc., Chelmsford, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>808589</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Amanatides, John., "Ray Tracing with Cones," Computer Graphics, 18(3), July 1984, pp. 129-135.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., Thomas Porter, and Loren Carpenter., "Distributed Ray Tracing," Computer Graphics 18(3), July 1984, pp. 137-145.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Fujimoto, Akira,, and Kansei Iwata., "Accelerated Ray Tracing," Proceedings of Computer Graphics Tokyo '85, April 1985.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Glassner, Andrew S., "Space Subdivision for Fast Ray Tracing," IEEE Computer Graphics and Applications, 4(10), October, 1984, pp. 15-22.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Johnson, Lee W., and Riess, Dean R., "Numerical Analysis," Addison-Wesley, 1977.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kajiya, James T., "The Rendering Equation," Computer Graphics 20(4), August 1986, pp. 143-150.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Kaplan, Michael R., "Space Tracing: A Constant Time Ray Tracer," ACM SIGGRAPH '85 Course Notes 11, July 22-26, 1985.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15916</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kay, Timothy L. and James Kajiya., "Ray Tracing Complex Scenes," Computer Graphics, 20(4), August 1986, pp. 269-278.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>23953</ref_obj_id>
				<ref_obj_pid>23944</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Kirk, David B., "The Simulation of Natural Features using Cone Tracing," Advanced Computer Graphics (Proceedings of Computer Graphics Tokyo '86), April 1986, pp. 129-144.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Newman, William M., and Robert F. Sproull., "Principles of Interactive Computer Graphics," 1st edition, McGraw-Hill, New York, 1973.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Ortega, James M., "Numerical Analysis, A Second Course," Academic Press, New York, 1972.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4333</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Preparata, Franco P., and Michael I. Shamos., "Computational Geometry, an Introduction," Springer-Verlag, New York, 1985.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Press, William H., Brian P.Flannery, Saul A. Teukolsky, William T. Vetterling., "Numerical Recipes," Cambridge University Press, Cambridge, 1986.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807479</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Rubin, Steve, and Turner Whitted., "A Three-Dimensional Representation for Fast Rendering of Complex Scenes," Computer Graphics 14(3), July 1980, pp. 110-116.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>20315</ref_obj_id>
				<ref_obj_pid>20313</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Speer, L. Richard, Tony D. DeRose, and Brian A. Barsky., "A Theoretical and Empirical Analysis of Coherent Ray Tracing," Computer-Generated Images (Proceedings of Graphics Interface '85), May 27-31, 1985, pp. 11-25.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>905316</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Warnock, John E., "A Hidden-Surface Algorithm for Computer Generated Half-tone Pictures,", Ph.D. Dissertation, University of Utah, TR 4-15, 1969.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357335</ref_obj_id>
				<ref_obj_pid>357332</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Weghorst, Hank, Gary Hooper, and Donald Greenberg., "Improved Computational Methods for Ray Tracing," ACM Transactions on Graphics, 3(1), January 1984, po. 52-69.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 21, Number 4, July 1987 Fast Ray Tracing by Ray Classification James Arvo 
David Kirk Apollo Computer, Inc. 330 Billerica Road Chelmsford, MA 01824 Abstract We describe a new 
approach to ray tracing which drastically reduces the number of ray-object and ray-bounds intersection 
calculations by means of 5-dimensional space subdivision. Collections of rays originating from a common 
3D rectangular volume and directed through a 2D solid angle are represented as hypercubes in 5-space. 
A 5D volume bounding the space of rays is dynamically subdivided into hypercubes, each linked to a set 
of objects which are candidates for intersection. Rays are classified into unique hypercubes and checked 
for intersection with the associated candidate object set. We compare several techniques for object extent 
testing, including boxes, spheres, plane-sets, and convex polyhedra. In addition, we examine optirnizations 
made possible by the directional nature of the algorithm, such as sorting, caching and backface culling. 
Results indicate that this algorithm significantly outperforms previous ray tracing techniques, especially 
for complex environments. CR Categories and Subject Descriptors: 1.3.3 [Computer Graphics] : Picture/Image 
Generation; 1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism; General Terms: Algorithms, 
Graphics Additional Key Words and Phrases: Computer graphics, ray tracing, visible-surface algorithms, 
extent, bounding volume, hierarchy, traversal  1. Introduction Our goal in studying algorithms which 
accelerate ray tracing is to produce high-quality images without paying the enormous time penalty traditionally 
associated with this method. Recent algorithms have focused on reducing Permission to copy without foe 
all or part of this material is granted provided that the copies are not made or distributed for direct 
commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to repuNish, requires a fee and/or specific permission. &#38;#169; 1987 ACM-O-89791-227-6/87/007/0055 
$00.75 the number of ray-object intersection tests performed since this is typically where most of the 
time is spent, especially for complex environments. This is achieved by using a simple-to-evaluate function 
to cull objects which are clearly not in the path of the ray. 1.1 Previous Work Rubin and Whitted [14] 
developed one of the first schemes for improving ray tracing performance. They observed that "exhaustive 
search" could be greatly improved upon by checking for intersection with simple bounding volumes around 
each object before performing more complicated ray-object intersection checks. By creating a hierarchy 
of bounding volumes, Rubin and Whirred were able to reduce the number of bounding volume intersection 
checks as well. Weghorst, et. al. [17] studied the use of different types of bounding volumes in a hierarchy, 
and discussed how ease of intersection testing and "tightness" of fit determine the bounding volume's 
effectiveness in culling objects. The object hierarchy of Rubin and Whitted made the crucial step away 
from the linear time complexity of exhaustive search but still did not achieve acceptable performance 
on complex environments. This was due in part to the top down search of the object hierarchy required 
for every ray. Another factor was the difficulty of obtaining a small bound on the number of ray-object 
intersection tests and ray-bounds comparisons required per ray since this depended strongly on the organization 
of the hierarchy. Another class of algorithms employs 3D space subdivision to implement culling functions. 
The initial candidates for intersection are associated with a 3D volume containing the ray origin. Successive 
candidates are identified by regions which the ray intersects. Concurrently and independently, Glassner 
[4], and Fujimoto, et. al. [3] pursued this approach. Glassner investigated partitioning the object space 
using an octree data structure, while Fujimoto compared octrees to a rectangular linear grid of 3D voxels. 
Kaplan [7] proposed a similar scheme and observed that a binary space partitioning tree could be used 
to accomplish the space subdivision. A drawback common to all of these approaches is that a ray which 
misses everything must be checked against the contents of each of the regions or voxels which it intersects. 
  ~Z~ SIGGRAPH '87, Anaheim, July 27-31, 1987 None of these algorithms made use of the coherence which 
exists between similar rays. Speer, et. al. [15] examined the concept of "tunnels" as a means of exploiting 
ray-tree coherence. Speer attempted to construct cylindrical "safety regions" within which a ray would 
miss all objects, but observed that despite considerable coherence, the cost of constructing and using 
the cylindrical tunnels negated the benefit of the culling they accomplished. Kay and Kajiya [8] introduced 
a new type of bounding volume, plane-sets, and a hierarchy traversal algorithm which is able to check 
objects for intersection in a particular order, regardless of the locality of the bounding volume hierarchy. 
This algorithm had the key advantage over previous object hierarchy schemes that objects could be checked 
for intersection in approximately the order that they would be encountered along the ray length. 1.2 
A New Approach Our ray classification approach differs significantly from previous work in that it extends 
the idea of space subdivision to include ray direction. The result is an extremely powerful culling function 
that is, empirically, relatively insensitive to environment complexity. A key feature of the algorithm 
is that a single evaluation of its culling function is capable of producing a small but complete set 
of candidate objects, even if the ray misses everything. This is accomplished by adaptively subdividing 
the space of all relevant rays into equivalence classes, El, E2, ..., Era, and constructing candidate 
object sets C1, C2, ..., Cm, such that Ci contains all objects which the rays in Ei can intersect. Evaluating 
the culling function reduces to classifying a given ray as a member of an equivalence class and retrieving 
the associated candidate set. The algorithm strives to keep J Ci I small for all i, and several new techniques 
are employed which lessen the impact of those sets for which it fails to do so.  2. 5-Space and Ray 
Classification In many ray tracing implementations, rays are represented by a 3D origin coupled with 
a 3D unit direction vector, a convenient form for intersection calculations. However, geometrically a 
ray has only five degrees of freedom, as evidenced by the fact that the same information can be conveyed 
by only five values: for instance, a 3D origin and two spherical angles. Consequently, we can identify 
rays in 3-space with points in 5-space, or, more precisely, with points in the 5-manifold R3xS2, where 
$2 is the unit sphere in R3. It follows that any neighborhood of rays, a collection of rays with similar 
origins and directions, can be parametrized by a subset of R5. We shall use such parametrizations in 
constructing a culling function which makes use of all five degrees of freedom of a ray. The ray classification 
algorithm can be broken into five subtasks. All but the last operate at least partly in 5-space. These 
are: [] 5D Bounding Volume: Find a bounded subset, E c R5, which contains the 5D equivalent of every 
ray which can interact with the environment. [] 5D Space Subdivision: Select subsets El, ..., Emwhich 
partition E c R5 into disjoint volumes. [] Candidate Set Creation: Given a set of rays represented by 
a 5D volume Ei, create a set of candidates, Ci, containing every object which is intersected by one of 
the rays. [] Ray Classification: Given a ray corresponding to a point in E, find a set, El, of a partitioning, 
E1 .... , Em, which contains the point, and return the associated candidate set Ci. [] Candidate Set 
Processing: Given a ray and a set of candidate objects, Ci, determine the closest ray-object intersection 
if one exists. For each ray that is intersected with the environment, [] is used to retrieve a set of 
candidate objects and [] does the actual ray-object intersections using this set. As we shall see, [] 
is carried out only once while [] and [] incrementally refine the partitioning and candidate sets in 
response to ray classification queries in []. Ideally we seek a partitioning in [] such that corresponding 
candidate sets created in [] contain fewer than some predetermined number of objects. These subtasks 
are described in detail in sections 3 through 7. 2.1 Beams as 5D Hypercubes Because much of the algorithm 
involves 5D volumes it is important to choose volumes which have compact representations and permit efficient 
point-containment queries and subdivision. For these reasons we use 5D axis-aligned parallelepipeds, 
or hypercubes. These are stored as five ordered pairs representing intervals along the five mutually 
orthogonal coordinate axes which we label X, Y, Z, U, and V. Each hypercube, representing a collection 
of rays, has a natural 3D manifestation which we call a beam. This is the unbounded 3D volume formed 
by the union of semi-infinite lines, or rays in the geometrical sense, defined by the points of the hypercube. 
Beams play a central role in candidate set creation since they comprise exactly those points in 3-space 
which are reachable by a set of rays. Given the importance of this role it is essential that hypercubes 
define beam volumes which are easily represented, such as convex polyhedra. This geometry is completely 
determined by the way we identify rays with 5D points.  2.2 Rays as 5D Points In this section we describe 
the means of associating a unique point in R5 with each distinct ray in R3. As mentioned earlier, a ray 
can be mapped to a unique 5-tuple, (x,y,z,u,v), consisting of its origin followed by two spherical angles. 
Unfortunately the beams associated   ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 of a ray are found to 
reside in a hypercube which is too large. Thus, beginning with the six bounding hypercubes, we construct 
the entire hierarchy by lazy evaluation. When a ray causes new paths to be formed in the hypercube hierarchy, 
two heuristics determine when subdivision terminates. We stop if either the candidate set or the hypercube 
falls below a fixed size threshold. A small candidate set indicates that we have achieved the goal of 
making the associated rays inexpensive to intersect with the environment. The hypercube size constraint 
is imposed to allow the cost of creating a candidate set to be amortized over many rays. 5. Candidate 
Set Creation Given a hypercube, the task of creating its candidate set consists of determining all the 
objects in the environment which its rays can intersect. This is done by comparing each object's bounding 
volume with the beam defined by the hypercube. If the volumes intersect, the object is classified as 
a candidate with respect to that hypercube and is added to the candidate set. The six bounding hypercubes 
are assigned candidate sets containing all objects in the environment. As subdivision proceeds, candidate 
sets are efficiently created for the new hypercubes by making use of the hierarchy. Only those objects 
in an ancestor's candidate set need be reclassified. For space efficiency, we need not create a candidate 
set for every intermediate hypercube in the hierarchy. When a hypercube is subdivided along one axis, 
the beams of the resulting hypercubes usually overlap substantially, and are quite similar to the parent 
beam. Consequently, a single subdivision eliminates few candidates. This suggests performing several 
subdivisions before creating a new candidate set. A strategy which we have found to be effective is to 
subdivide each of the five axes before creating a new candidate set. While this allows up to 2 s hypercubes 
to derive their candidate sets from the same ancestor, the reduction in storage is significant. Also, 
due to lazy evaluation of the hierarchy, it is rare that all descendants are even created. 5.1 Object 
Classification The object classification method used in candidate set creation is critical to the performance 
of the ray tracer. A very fast method may be too conservative, creating candidate sets which are much 
too large. This causes unnecessary overhead in both candidate set creation and processing. A classifying 
method which performs well in rejecting objects may be unacceptable if it is too costly. As with object 
extents used for avoiding unnecessary ray-object intersection checks, there must be a compromise between 
the cost of the method and its accuracy [17]. In the following subsections we discuss the tradeoffs of 
three object classification techniques which can be used independently or in combination. 5.1.1 Classifying 
Objects with LP The first object classification method we describe employs linear programming to test 
for object-beam intersection, and requires objects to be enclosed by convex polyhedra. A polyhedral bounding 
volume is conveniently represented by its vertex list, or hull points, and can be made arbitrarily close 
to the convex hull of the object. Since the beam is itself a polyhedron, the object classification problem 
reduces to testing for intersection between two polyhedra. This is easily expressed as a linear program 
using the hull points [12] and then solved using the simplex method [13]. The result is an exact classification 
scheme for this type of bounding volume. That is, an object is classified as a candidate of a hypercube 
if and only if some ray of the beam intersects its bounding polyhedron. Unfortunately, our experience 
has shown that the computation required to solve the linear program is prohibitively high, precluding 
its use as the primary object classification method. It is overly complex for handling the very frequent 
cases of objects which are either far from the beam or inside it. Nevertheless, it is a useful tool for 
testing and evaluating the effectiveness of approximate object-classification methods. 5.1.2 Classifying 
Objects with Planes The linear programming approach rejects an object from the candidate set if and only 
if there exists a separating plane between the beam and the object's bounding polyhedron. This suggests 
a simpler approach which tests several planes directly, classifying an object as a candidate if none 
of the planes are separators. For every beam there are several planes which are particularly appropriate 
to test, each with the entire beam in its positive half-space. Four of these planes are parallel to the 
faces of the UV pyramid, translated to the appropriate XYZ extrema of the hypercube. Up to three more 
are found "behind" the beam, containing faces of the XYZ hypercube extent. If all of the vertices of 
an object's bounding polyhedron are found to be in the negative half-space of one of these planes, the 
object is rejected. The half-space tests are greatly simplified by the nature of these planes, since 
all are parallel to at least one coordinate axis. This method is fast and conservative, never rejecting 
 an object which is actually intersected by the beam. It is also approximate, since objects will be erroneously 
classified as candidates when, for example, their bounding polyhedra intersect both a U and a V plane 
without intersecting the beam. 5.1.3 Classifying Objects with Cones Another approach to object classification 
uses spheres to bound objects and cones to approximate beams. This is similar to previous uses of cones 
in ray tracing. Amanatides [1] described the use of cones as a method of area sampling, providing accurate 
and inexpensive anti-aliasing. Kirk [9] used cones as a tool to calculate proper texture filtering apertures, 
and to improve anti-aliasing of bump-mapped surfaces. In our context, cones prove to be very effective 
for classifying objects bounded by spherical extents.   (~ ~ TO create a candidate set for a hypercube 
we begin by constructing a cone, specified by a unit axis vector, W, a spread angle, 0, and an apex, 
P, which completely contains the beam of the hypercube. If this cone does not intersect the spherical 
extent of an object, the object is omitted from the candidate set. The details of the cone-sphere intersection 
calculation are given in both [1] and [9]. We describe the construction of the cone below with the aid 
of function F in Equation 3, which defines inverse mappings of those described in section 2.2. ( 1, u, 
v) if +Xis dominant (-1, u, v) if -Xis dominant F(u, V) = ( ( u, 1, u,-1, v) v) if +Y is dominant if 
-Yis dominant 131 ( u, v, 1) if +Z is dominant ( u, v,-1) if -Zis dominant The cone axis vector, W, 
depends only on the dominant axis of the hypercube and its U and V intervals, (umin,umax) and (vmin, 
vmax). It is constructed by bisecting the angle between the vectors A and B, which are given by Equations 
4 and 5. A --F( umin, vmax ) [4] B = F( umax, vmin ) [5] To find the cone spread angle we also construct 
vectors C and D using Equations 6 and 7. We then compute 0 as shown in Equation 8. C = F( umin, vmin 
) [6] D --F( umax, vmax ) [7] 0 = ~¢[AX( A/W, B/W, CgW, D/W ) [8] Once the axis and spread angle are 
known, the apex of the cone, P, is determined by the 3D rectangular volume, R, defined by the XYZ intervals 
of the hypercube. The point P is located by displacing the centroid of R in the negative cone axis direction 
until the cone exactly contains the smallest sphere bounding R. The resulting expression for P is given 
in Equation 9, where R0 and R1 are the min and max extrema of R. 1% + R1 II R0- R1 IIz P -W [9] 2 2 SINe 
The cone is used to classify all potential candidates of the hypercube and is constructed only once per 
hypercube. The comparison between the cone and the object's bounding sphere is fast, making the cost 
of a distant miss low. This reduces the penalty of infrequent candidate list creation, the space saving 
measure discussed in section 5. A linear transformation, M, applied to an object can also be used to 
modify its bounding sphere. By  Computer Graphics, Volume 21, Number 4, July 1987 transforming the center 
of the sphere by M and scaling its radius by II M 112, we obtain a new sphere which is guaranteed to 
contain the transformed object. The matrix 2-norm is given by x/( P( M 7M ) ) [11], where 0, the spectral 
radius, is the largest absolute eigenvalue of a matrix. If MTM is sparse, the eigenvalue calculation 
is quite simple. An iterative technique like the power method can be used for the remaining cases [5]. 
6. Ray Classification Every ray-environment intersection calculation begins with ray classification, 
which locates the hypercube containing the 5D equivalent of the ray. This entails mapping the ray into 
a 5D point and traversing the hypercube hierarchy, beginning with the bounding hypereube indexed by the 
dominant axis of the ray, until we reach the leaf containing this point. Due to lazy evaluation of the 
hierarchy, this traversal may have the side effect of creating a new path terminating at a sufficiently 
small hypercube containing the ray if such a path has not already been built on behalf of another ray. 
If the candidate set associated with the leaf hypercube is empty, we are guaranteed that the ray intersects 
nothing. Otherwise, we process this set as described in the next section. 7. Candidate Set Processing 
Once ray classification has produced a set of candidate objects for a given ray, this set must be processed 
to determine the object which results in the closest intersection, if one exists. To optimize this search 
we continue to make use of object bounding volumes for coarse intersection checks. We also reject objects 
whose bounding volumes intersect the ray beyond a known object intersection. This can further reduce 
the number of ray-object intersection calculations, but still requires that the ray be tested against 
all bounding volumes of the candidate set. We can remove this latter requirement by taking advantage 
of the fact that all rays of a given beam share the same dominant axis. By sorting the objects of the 
candidate sets by their minimum extents along this axis, then processing them in ascending order, we 
can ignore the tail of the list if we reach a candidate whose entire extent lies beyond a known intersection. 
This is an enormous advantage because it can drastically reduce the number of bounding volume checks 
in cases where the ray intersects an object near the head of the list. For example, in Figure 2 only 
the first two objects are tested because all subsequent objects are guaranteed to lie beyond the known 
intersection. By sorting the candidate sets of the six bounding hypercubes along the associated dominant 
axes before 5D space subdivision begins, the correct ordering can be inherited by all subsequent candidate 
sets with no additional overhead. Object bounding boxes provide the six keys used in sorting these initial 
candidate sets.   (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 The ray classification algorithm 
benefits in a number of ways from the special nature of first-generation rays. Because they originate 
from a degenerate 3D volume, the eye point, first-generation rays can be classified using u and v alone. 
This increases the efficiency of ray classification by simplifying the traversal of the hypercube hierarchy, 
which becomes a hierarchy of 2D rectangles. Candidate set creation also benefits because the beams associated 
with the degenerate hypercubes are non-overlapping pyramids. Candidate sets are therefore cut in half, 
on average, with every subdivision. This makes it feasible to obtain smaller candidate sets, thereby 
speeding up candidate set processing as well. The result of these optimizations for first-generation 
rays is an image-space algorithm which closely resembles the 2D recursive subdivision approach introduced 
by Warnock [16]. 12. Summary We have described a method which accelerates ray tracing by drastically 
reducing the number of ray-object and ray-bounds intersection checks. This is accomplished by extending 
the notion of space subdivision to a 5D scheme which makes use of ray direction as well as ray origin. 
Rays are classified into 5D hypercubes in order to retrieve pre-sorted sets of candidate objects which 
are efficiently tested for intersection with each ray. The computational cost of intersecting a ray with 
the environment is very low because similar rays share the benefit of culling far-away objects, thereby 
exploiting coherence. This technique can be used to accelerate all applications which rely upon ray-environment 
inter-sections, including those which perform Monte Carlo integration [2][6]. Empirical evidence indicates 
that performance is closer to constant time than previous methods, especially for very complex environments. 
13. Results All test images were calculated at 512 by 512 pixel resolution with one sample per pixel 
for timing purposes. All of the images in the figures were calculated at 512 by 512 pixel resolution 
and anti-aliased using adaptive stochastic sampling with 5x5 subpixels and a cosine-squared filter kernel. 
Figures 5a and b are false color images of the recursive pyramid with four levels of recursion, from 
[8]. The hue of the false color indicates the number of ray-bounds checks which were performed in the 
course of computing each pixel. The scale proceeds from blue for 0 bounding volume checks to red for 
50 or more. Figure 5a depicts the performance of the ray classification algorithm without the first-generation 
ray optimization, and Figure 5b shows how performance improves when this optimization is enabled. The 
same basic model is instanced to ten levels of recursion in Figure 5c. This environment contains over 
four million triangles and was ray traced in 1 hour and 28 minutes (see table in Figure 6). Figure 7 
is a reflective teapot on a checkerboard, and Figure 8 shows the original five Platonic Solids and the 
newly discovered Teapotahedron. Figure 9a shows the Caltech tree with leaves as they might appear rather 
late in the year. Figure 9b is a false color rendering with the same scale as described above. The fine 
yellow and red lines at the edge of the dark blue shadows in the false color image indicate shadow calculations 
which required processing a candidate set. The interior areas of the shadows are dark blue, indicating 
very few bounding volume checks, due to the shadow cache optimization. The same tree is shown in Figure 
10 rendered in false color without leaves. Even though there are fewer primitives, the number of ray-bounds 
checks is not much different from that of the tree with leaves. This is due to the difficulty of accurately 
classifying long arbitrarily oriented cylinders. Figure 11a is a true color image of a grove of 64 instanced 
trees with leaves. This environment contains 477,121 objects and was ray traced in 4 hours and 53 minutes. 
Figure 11b is a false color rendering of the grove of trees. We wish to compare the performance of our 
algorithm with that of previous methods. Due to the generosity of Tim Kay at Caltech, we were able to 
run benchmarks using the same databases used in [8]. Since we did not have access to a Vax 11/780 for 
our benchmarks, we chose an Apollo DN570, which has roughly the same level of performance. Kay and Kajiya 
compared the performance of their program on the recursive pyramid of Figure 9 with the performance reported 
by Glassner [4]. Glassner's program took approximately 8700 Vax 11/780 seconds to render the scene, while 
Kay's program took approximately 2706 seconds, which translates roughly to a factor of 2.6 improvement 
after accounting for differences in the scene. Our program took approximately 639 seconds on an Apollo 
DN570, representing a further factor of 4.2 improvement.  Acknowledgements We would like to thank Rick 
Speer, both for organizing an informal ray tracing discussion group at the 86 SIGGRAPH conference, and 
for directing' the discussion toward coherence and directional data structures. Pat Hanrahan deserves 
credit for supplying the insight that directional classification of rays need not be tied to objects. 
Thanks to Christian Bremser, John Francis, Olin Lathrop, Jim Michener, Semyon Nisenzon, Cary Scofield, 
and Douglas Voorhies for their diligent critical reading of early drafts of the paper. Special thanks 
to Olin Lathrop and John Francis for help in defining and implementing the "ray tracing kernel", the 
testbed used for this work, and to Jim Michener for his many helpful technical comments. Resounding applause 
to Tim Kay for making his pyramid and tree databases available. Last but by no means least, thanks to 
Apollo Computer and particularly to Christian Bremser and Douglas Voorhies for making time available 
to perform this work.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37410</article_id>
		<sort_key>65</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Generating antialiased images at low sampling densities]]></title>
		<page_from>65</page_from>
		<page_to>72</page_to>
		<doi_number>10.1145/37401.37410</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37410</url>
		<abstract>
			<par><![CDATA[Ray tracing produces point samples of an image from a 3-D model. Constructing an antialiased digital picture from point samples is difficult without resorting to extremely high sampling densities. This paper describes a program that focuses on that problem. While it is impossible to eliminate aliasing totally, it has been shown that nonuniform sampling yields aliasing that is less conspicuous to the observer. An algorithm is presented for fast generation of nonuniform sampling patterns that are optimal in some sense. Some regions of an image may require extra sampling to avoid strong aliasing. Deciding where to do extra sampling can be guided by knowledge of how the eye perceives noise as a function of contrast and color. Finally, to generate the digital picture, the image must be reconstructed from the samples and resampled at the display pixel rate. The nonuniformity of the samples complicates this process, and a new nonuniform reconstruction filter is presented which solves this problem efficiently.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14128889</person_id>
				<author_profile_id><![CDATA[81100360165]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Don]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Mitchell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Bell Laboratories, Murray Hill, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>325177</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Abram, Greg, Lee Westover, Turner Whitted, "Efficient Alias-free Rendering using Bit-masks and Look-up Tables", Computer Graphics, Vol. 19, No. 3, July 1985, p. 57.]]></ref_text>
				<ref_id>ABR85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808589</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Amanatides, John, "Ray Tracing with Cones", Computer Graphics, Vol. 18, No. 3, July 1984, pp. 129-135.]]></ref_text>
				<ref_id>AMA84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Brown, Earl F., "Television: The Subjective Effects of Filter Ringing Transients", Journal of the SMPTE, Vol. 78, No 4, April t969, pp. 249-255.]]></ref_text>
				<ref_id>BRO69</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Caelli, Terry~ Visual Perception: Theory and Practice, Pergamon Press, Oxford (1981).]]></ref_text>
				<ref_id>CAEgl</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L, Thomas Porter, Loren Carpenter, "Distributed Ray Tracing", Computer Graphics, Vol. 18, No. 3, July 1984, pp. 137-145.]]></ref_text>
				<ref_id>COO84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L, "Stochastic Sampling in Computer Graphics", ACM Trans. Graphics, Vol. 5, No. 1, January 1986.]]></ref_text>
				<ref_id>COO86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359869</ref_obj_id>
				<ref_obj_pid>359863</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Crow, Franklin C., "The Aliasing Problem in Computer- Generated Shaded Images", Comm. ACM, Vol. 20, No. 11, November 1977, pp 799-805.]]></ref_text>
				<ref_id>CRO77</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325182</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Dippe, Mark A. Z. and Erling Henry Wold, "Antialiasing Through Stochastic Sampling", Computer Graphics, Vol. 19, No. 3, July 1985, pp. 69-78.]]></ref_text>
				<ref_id>DIP85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Floyd, R. and L. Steinberg, "An Adaptive Algorithm for Spatial Grey Scale", SID Digest. 1975, 36-37.]]></ref_text>
				<ref_id>FLO75</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Franke, Richard, "Scattered Data Interpolation: Tests of Some Methods", Mathematics of Computation, Vol. 38, No. 157, January 1982.]]></ref_text>
				<ref_id>FRA82</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kajiya, James T., Engineering and Science, Vol 48, No. 2, California Institute of Technology: November 1984.]]></ref_text>
				<ref_id>KAJ84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Kajiya, James T., "The Rendering Equation", Computer Graphics, Vol. 20, No. 4, July 1986, pp. 143-150.]]></ref_text>
				<ref_id>KAJ86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325179</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Lee, Mark, Richard A. Redner, Samuel P. Uselton, "Statistically Optimized Sampling for Distributed Ray Tracing", Computer Graphics, Vol. 19, No. 3, July 1985, pp. 61-67.]]></ref_text>
				<ref_id>LEES5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Limb, J. O., "Design of Dither Waveforms for Quantized Visual Signals", Bell System Tech. J., Vol 48, pp. 2555- 2582, 1969.]]></ref_text>
				<ref_id>LIM69</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Limb, John O., "Digital Coding of Color Video Signals-- A Review", IEEE Trans. Comm., Vol. COMM-25, No. 11, November 1977, pp. 1349-1382.]]></ref_text>
				<ref_id>LIM77</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Mitchell, Don P., "Antialiased Ray Tracing By Nonuniform Sampling", unpublished Bell Labs report, April 1985.]]></ref_text>
				<ref_id>MIT85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Netravali, Arun, Personal Communication.]]></ref_text>
				<ref_id>NET86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Petersen, Daniel P., David Middleton, "Sampling and Reconstruction of Wave-Number-Limited Funetions in N-Dimensional Euclidean Spaces", Information and Control, Vol. 5, t962, pp. 279-323.]]></ref_text>
				<ref_id>PET62</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Ripley, B. D., "Modeling Spatial Patterns", J. Roy. Statist. Soc. B, Vol. 39, 1977, pp. 172-212.]]></ref_text>
				<ref_id>RIP77</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Roth, S. D., "Ray Casting for Modeling Solids", Computer Graphics and Image Processing, Vol. 18, 1982, pp. 109-144.]]></ref_text>
				<ref_id>ROT82</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Sakrison, David J., "On the Role of the Observer and a Distortion Measure in Image Transmission.", IEEE Trans. Comm., Vol. COM-25, No. 11, November 1977, pp 1251-1267.]]></ref_text>
				<ref_id>SAK77</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Shannon, C.E., "Communication in the presence of noise.", Proc. IRE Vol. 37, 1949, pp. 10-21.]]></ref_text>
				<ref_id>SHA49</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Shapiro, Harold S. and Richard A. Silverman, "Alias- Free Sampling of Random Noise", J. SLAM, Vol. 8, No. 2, June 1960, pp. 225-248.]]></ref_text>
				<ref_id>SHA60</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Whitted, Turner, "An Improved Illumination Model for Shaded Display", Comm. ACM, Vol. 23, No. 6, June 1980, pp. 343-349.]]></ref_text>
				<ref_id>wHIg0</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Yellott, John I. Jr., "Spectral Consequences of Photoreceptor Sampling in the Rhesus Retina", Science, Vol. 221, 1983, pp. 382-385.]]></ref_text>
				<ref_id>YEL83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Yen, J. L., "On Nonuniform Sampling of Bandwidth- Limited Signals", IRE Trans. Circuit Theory, Vol. 3, Dec. 1 1956, pp. 251-257.]]></ref_text>
				<ref_id>YEN56</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~) ~ Computer Graphics, Volume 21, Number 4, July 1987 Generating Antialiased Images at Low Sampling 
Densities Don P. Mitchell AT&#38;T Bell Laboratories Murray Hill, New Jersey 07974 ABSTRACT Ray tracing 
produces point samples of an image from a 3-D model. Constructing an antialiased digital picture from 
point samples is difficult without resorting to extremely high sampling densities. This paper describes 
a program that focuses on that problem. While it is impossi- ble to'eliminate aliaslng totally, it has 
been shown that nonuniform sampling yields aliasing that is less conspicu- ous to the observer. An algorithm 
is presented for fast generation of nonuniform sampling patterns that are optimal in some sense. Some 
regions of an image may require extra sampling to avoid strong aliasing. Deciding where to do extra sampling 
can be guided by knowledge of how the eye perceives noise as a function of contrast and color. Finally, 
to generate the digital picture, the image must be reconstructed from the samples and resampled at the 
display pixel rate. The nonuniformity of the samples complicates this process, and a new nonuniform reconstruc- 
tion filter is presented which solves this problem efficiently. CR Categories and Subject Descriptions: 
1.3.3 [ Computer Graphics ]: Picture/Image Generation General Terms: Algorithms Additional Keywords and 
Phrases: Adaptive Sampling, Antialiasing, Filtering, Noise Perception, Nonuniform Sampling, Ray Tracing, 
Reconstruction  1. Introduction While ray tracing is a straightforward technique for image synthesis, 
it has in some ways proven to be one of the most perverse. On the one hand, impressive effects of shading, 
reflection, and refraction can be simulated by ray tracing [WHI80], and it remains one ,of the simplest 
methods for evaluating constructive solid geometry models [ROT82]. On the other hand, ray tracing is 
expensive, and because it is based on point sampling it is especially prone to aliasing problems. Permission 
to copy without fee all or part of this material is granted provided that the copies are not made or 
distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169; 
1987 ACM-0-89791-227-6/87/007/0065 $00.75 This paper describes a method that uses the point-sampling 
charac- teristics of ray tracing more effectively than alternative techniques. The ray tracer itself 
is viewed as a black box capable of supplying samples of a two-dimensional image signal (by casting rays 
into a scene). A separate antialiasing module decides where to take samples, how densely to sample each 
region of the image, and how to construct a digital picture from all the sample information. The only 
data passed from the ray tracer to the antialiasing module are sample values. This cleanly isolates the 
aliasing problem from ray-tracing issues, and allows a variety of ray tracers (and other sample-generating 
algorithms) to be used. The antialiasing module is composed of three principal stages. First, the entire 
image is sampled at a relatively low density. Then, on the basis of these initial sample values, some 
regions of the image may be sampled further at a higher density to reduce noise. Finally, in the reconstruction 
phase, all of the samples of the image are used to gen- erate the pixel values for a displayed image. 
Of the many issues involved in optimizing ray tracing, this paper will focus on reducing sampling density 
while still producing an image of high quality. The approach has been to consider the perception of noise 
and operate near its threshold. While perception of noise is a complex subject, basic facts learned from 
work in color-television encoding and image noise measurement can be applied to this problem [LIM77, 
SAK77]. By varying position and density of the sampling, a more optimal sam- pling pattern can be obtained. 
For example, certain nonuniform sam- pling patterns have been shown to scatter aliasing into high-frequency 
random noise lYEL83]. Deciding where to concentrate sampling can be guided by estimation of the noise 
visibility as a function of contrast and color. 2. The Preliminary Sampling Pattern The choice of sampling 
strategy is now known to be closely related to the aliasing problem. The history of this problem began 
with Crow's realization that the "jaggies" in synthetic pietures were an example of aliasing, a well-known 
phenomenon of signal processing [CRO77]. According to the Sampling Theorem [SHA49], aliasing can only 
be reduced by either filtering out the high-frequency components of the image (above the Nyquist frequency) 
or by increasing the sampling density to an appropriate level. Both of these techniques have been used 
to combat aliasing in ray tracers lAMA84, WHI80], but neither is completely satisfactory. Prefiltering 
has been done only approxi- mately and for scenes built up from a restricted class of primitive objects. 
The alternative of increasing the sampling density means a corresponding increase in computing cost. 
An entirely different approach to the problem is suggested by Yellott's work [YEL83]: when aliasing cannot 
be removed, it can still be made less conspicuous by sampling nonuniformly. Uniform sampling tends  
 SIGGRAPH '87, Anaheim, July 27-31, 1987 I~~ I to produce highly visible forms of noise because regular 
structure in the image can "beat" with the sampling pattern producing Moir6 pat- terns and "jaggies". 
With nonuniform sampling, aliasing noise can be random and structureless. Yeilott realized this by studying 
the layout of photoreceptors in the retina of the eye. This concept was first applied to image synthesis 
by researchers at Lucasfilm and has since been explored by a number of others [COO84, KAJ84, ABR85, DIP85, 
LEE85, MIT85, COO86, KAJ86]. Unfortunately, nonuniform sampling of nonbandlimited signals is poorly understood. 
For the most part, only problems that are very remote to the image-synthesis problem have been studied 
by signal processing experts (e.g., the extraction of statistics from nonbandlim- ited stationary noise 
[SHA69D. In the application to graphics, several important questions remain unanswered. In particular, 
the quality of images produced by nonuniform sampling has been questioned [ABRg5], and systems which 
definitely do produce high-quality images [COO84, LEE85] use rather high lower bounds on sampling densities 
(16 and 8 samples per pixel, respectively). For fixed-density (i.e., nonadaptive) sampling, two common 
forms of nonuniform sampling have been discussed. Yellott [YEL83] recom-mends using the distribution 
he observed in retinal cells, a Poisson-disk distribution (a Poisson distribution with a minimum-distance 
con- straint between points). Except for a few experimental pictures [DIP85], I know of no rendering 
system that uses this pattern. Instead, the more easily generated jitter pattern is commonly used [COO86]. 
A jitter pattern is formed by randomly perturbing the points of a uniform sampling pattern. Theoretical 
evidence in favor of the Poisson-disk sampling pattern was presented by Yellott [YEL83]. He proposed 
that the least-conspicuous form of aliasing would be produced if the spectrum of the sampling pattern 
had two properties. First, the spectrum should be noisy and lack any concentrated spikes of energy. If 
present, such spikes could yield coherent aliasing in the same way that uniform sampling can. Secondly, 
the spectrum should have a deficiency of low-frequency energy. This causes aliasing noise to be concentrated 
in higher, less conspicuous frequencies. These conditions will be referred to as the blue-noise criteria. 
Figure l shows an instance of such a sampling pattern (generated by the dart-throwing algorithm described 
below) and its Fourier transform. Studies have shown that the eye is most sensitive to noise in intermedi- 
ate frequencies [SAK77]. While frequencies up to 60 cycles per degree can be visible, the maximum response 
to noise is at about 4.5 cycles per degree. Taking advantage of this response is also how ordered dither 
improves the quality of halftoned images [LIM69]. By adding high-frequency noise to an image before quantizing, 
Limb discovered that annoying contour effects were masked. Although more noise was added to the image, 
the results were far more pleasing when viewed at a reasonable distance. Figure 2 shows the pattern 
and spectrum of a jitter process. The sam- pling pattern is clumpier, or more "granular', and the spectrum 
shows a smaller noise-free region around the origin. This implies that noise with tower frequencies (i.e., 
larger features) would be generated by this type of sampling. Figures 3 through 5 give a more direct 
visual demonstration of uni- form, jitter, and Poisson-disk sampling, respectively. For these figures, 
a test pattern has been designed specifically to generate aliasing. It is given by the following simple 
formula: 100x I rood2 (1) x +yJ Images of this test pattern were originally 160 by 160 pixels, and in 
figures 3 to 5, an average of one sample per pixel was made. The images were then enlarged by digital 
resampling to 512 by 512 to magnify the details of aliasing. As expected, uniform sampling (Figure 3) 
yields large Moir~ patterns, which are visible even at a dis- tance. Comparing Figures 4 and 5, both 
lack Moir6 patterns, but jitter sampling (Figure 4) has introduced significantly more "grain noise" into 
the picture. The pits and bumps along edges are much less severe when Poisson-disk sampling (Figure 5) 
is used. What has made jitter sampling attractive is undoubtedly its simplicity. Poisson-disk sampling 
is somewhat more complicated. Several point processes could be referred to as "Poisson-disk" [R1P77], 
but by strict definition, a true Poisson-disk process is realized by generating com-plete patterns with 
Poisson statistics until one is found that meets the minimum-distance constraint. A more practical point 
distribution is realized by a "dart-throwing" algorithm [MIT85, COO86], in which points are generated 
randomly with uniform distribution over the area being filled (this by itself closely approximates a 
Poisson distribution). Each new point is rejected if it falls within a certain distance of any previously 
chosen points, otherwise it is added to the pattern, and the process continues. This process is repeated 
until no new points can be added to the pat- tern This is an expensive algorithm (several hours of VAX 
780 time to generate 1024-point pattern), which is only practical for precomputing a small pattern with 
periodic boundary conditions to be permanently stored and replicated over the entire picture. As mentioned 
above, this pattern satisfies the blue-noise criteria. I have found that Poisson-disk samples can be 
generated cheaply on the fly by an algorithm inspired by the Floyd-Steinberg halftoning algorithm [FLO75]. 
To generate a pattern with an average of one sample per pixel, the algorithm selects points from a uniform 
two-dimensional grid four times finer than the display pixel lattice (i.e., there are 16 grid points 
per pixel area). A .small amount of random jitter can be added to these sample positions to dislocate 
them from the grid. As the algorithm proceeds, the grid points are operated on in a scan-line order. 
Each point on the grid is associated with a diffusion value Dq, which is computed from previously computed 
diffusion values and a noise source R: T n 4Di-l'y+Di-l'J-I +2Di, j-i +Di+l,j_ 1 ~'R (2) 8 The noise 
source R is a uniform random value in a range of 1/16 -1/64 to 1/16 + 1/64. This will ensure that about 
one out of 16 grid points will be selected as a sampling point and provides enough fluctuation to prevent 
orderly structures from appearing in the pattern. The diffusion values (defined below) correspond to 
the diffusing quanti- zation error in the Floyd-Steinberg algorithm. The temporary value T is used to 
decide whether to select a grid point as a sampling position: SELECT= (~ ifT<0.5 (3) Otherwise If SELECT 
is 1, the grid point is a sampling position. Finally, a local diffusion value is computed as: Di, j --T 
--SELECT (4) Only two scan lines of D values must be stored to execute this algo- rithm. Equation 2 assumes 
a scanning from left to right. A more iso- tropic pattern is produced if scanning sweeps back and forth. 
Figure 6 shows the pattern and spectrum produced by this algorithm. The error-diffusion weights in (2) 
have been chosen experimentally to pro- duce a sampling pattern that satisfies the blue-noise criteria. 
In addi- tion, these weights do not require any multiplications in an efficient implementation. This 
method of generating Poisson-disk patterns is  (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 
called the point-diffusion algorithm. 3. Adaptive Sampling Nonuniform sampling by itself does not eliminate 
aliasing; it merely changes the characteristics of aliasing to make it less noticeable. How-ever, when 
a region of an image contains an edge or some other type of high-frequency pattern, the sampling density 
must be increased to get a genuine reduction of aliasing noise. Adaptive sampling is not a new idea. 
Whitted describes an adaptive sampling algorithm based around uniform sampling [WHI80]. Two basic types 
of adaptive nonuniform sampling have been described in the literature. One approach allows sampling density 
to vary as a function of local image variance [LEE85, KAJ86]. An example of another approach is in [COO86] 
where two levels of sampling density are used, a regular pattern for most areas and a higher-density 
pattern for troublesome spots. For low densities, a two-level strategy is appeal- ing because it allows 
the optimal blue-noise pattern to be used easily. In the prototype antialiasing module, the entire image 
is sampled in a base pattern with an average of one sample per pixel. Additional local supersampling 
is typically done at a density of 4 to 9 samples per pixel. At 4 samples per pixel, aliasing noise is 
barely visible, and at 9 sam- ples per pixel, the image looks perfect. Much higher supersampling densities 
may be required if "distributed ray tracing" is being done. Having chosen to use two levels of sampling, 
where should the high density sampling be invoked? For this purpose, the image is divided into small 
square supersampling cells each containing eight or nine of the low-density samples. The samples within 
each cell (or withing some neighborhood of the cell) are tested to determine whether the entire cell 
should be supersampled. Theoretically, it is not possible to detect infallibly the presence of high frequency 
regions in an image by sampling at such a low rate. The success of this algorithm depends on additional 
assumptions about the structure of typical images. For example, this method is likely to detect edges, 
and it is known that edges are a common type of region that needs high-density sampling. On the other 
hand, coarse base sampling can miss minute isolated features; special action would have to be taken to 
ensure that they will be sampled. Objects which are going to appear small in the scene could be surrounded 
by a larger invisible bounding surface [WHI80], but this cannot be applied to small features resulting 
from shadows, reflections or highlights. Given the set of eight or nine samples in a supersampling cell, 
some quantitative measure of variation in signal is needed to decide whether supersampling should be 
done. The variance of the sample values can be used to indicate high frequency [LEE85]; however, variance 
is a poor measure of visual perception of local variation. The nonlinear response of the eye to rapid 
variations in light intensity is more closely modeled by contrast [CAE81]: ]max --/rain c (5) lmax q- 
/rain Each sample value actually consists of three separate intensities for red, green, and blue. These 
could be combined into a luminance value before contrasts are computed, but a safer method is to compute 
three separate contrasts for red, green, and blue. These three contrasts are each tested against separate 
thresholds, and supersampling is done if any one is higher than threshold. In a prototype system, red, 
green, and blue thresholds are set to 0.4, 0.3, and 0.6 respectively. This test is most sensitive to 
green in accordance with the human eye's known response to noise as a function of color. Because green-sensitive 
cone cells are far more common in the human retina (and thus green is sampled more densely), sensitivity 
to green-colored noise is twice as great as to red-colored noise and four times greater than to blue-colored 
noise. This knowledge has been used in the encoding of color television transmission to make the most 
economical use of bandwidth [LIM77]. Figure 7 shows an image generated by a prototype antialiasing module 
combined with a basic ray tracer. Figure 8 indicates with white where supersampling had been selected. 
In the thin shadow of the tripod's leg (seen between the footpads) a couple of small gaps can be seen. 
This is a failure of the high-frequency detection (as discussed above), but overall detection is remarkably 
good for such coarse sampling (one base sample per pixel). This small flaw can be removed by doubling 
the density of the base sampling, and thus doubling the cost of the pic- ture; a typical dilemma when 
rendering is entrenched in point sam-piing. 4. Reconstruction from Nonuniform Samples A digital picture 
is a uniform array of pixel values. These must be computed from the nonuniform sample values obtained 
by the methods described above. Ideally, this is done by constructing a surface that interpolates the 
sample values and can be resampled at the uniform pixel locations. At the same time, this surface must 
be bandlimited so that the resampling process does not itself introduce aliasing. This bandlimited interpolation 
is known as reconstruction in the signal-processing domain. Little practical information exists for dealing 
with nonuniform samples. Yen discusses the reconstruction problem and presents solutions for several 
one-dimensional cases [YEN56]. Unfortunately, these formulas--as Yen points out--are too unstable to 
be of real use. Many ad hoc algorithms exist for "smooth" interpolation of nonuniform data (Franke gives 
a good review of this subject. [FRA82D, but none of these algorithms are suited for the problem at hand. 
In general, they are not meant to deal with such a large number of points (on the order of a million 
samples must be processed in a typical digital color picture), and they are not designed with any digital 
filtering charac- teristics in mind. If the samples had been made uniformly, the problem would be quite 
a bit simpler. Reconstruction can then be done by convolving the sam-ples with an appropriate filter 
k. In one dimension, this is: f (x) -G ~ f(xn)k(x -xn) (6) where f(x,) are the sample values. It is important 
to note that a con- stant factor G is needed for normalization. This is inversely propor- tional to sampling 
density. The summation is infinite, but in practice, filter kernels are zero beyond some finite width. 
If any filter could be used in the reconstruction, its design would be a complex problem. In addition 
to well-understood quantitative criteria such as bandpass and leakage characteristics, filters for images 
must deal with poorly understood subjective criteria. Ringing and blurring effects must be traded off 
[BRO69], and because the filter is two-dimensional, there are conflicts between isotropy and interpolation 
[PET62]. High-frequency leakage is a particularly important filter characteristic because aliasing can 
result during resampling if the reconstruction from the nonuniform samples is not properly bandlimited. 
Figures 9 and 10 demonstrate this fact. Each of these figures has been sampled nonuniformly 100 times 
per pixel. Figure 9 is reconstructed with a box filter, and some faint aliasing can be seen near the 
origin. This alias- ing is reduced in Figure 10 where a better filter has been used (a sine filter with 
a Hamming window). When samples are nonuniform, there are many added complications, and the convolution 
in (6) is no longer valid. If samples clump together in a small region, (6) would make that area too 
bright; and similarly, regions where the samples were sparse would be too dark. This unwanted effect 
of sample-density fluctuation is called grain noise. If the sampling pattern is not too clumpy, grain 
noise can easily be handled by turning the filter in (6) into a weighted-average filter. In  +~ SIGGRAPH 
'87, Anaheim, July 27-31, 1987 one dimension this would be: ~a k (x -xn) f (x.) f (x) -. ---(7) k (x 
-x,) This filter has been used in a number of implementations of nonuni- form sampling [COO86, DIP85], 
but unfortunately, it does not handle extreme variation in local sampling density. An example of this 
failure can be seen in Figure 11. in this 3D plot, height represents the gray level in a 2D image. This 
figure has been generated by sampling a step function nonuniformly. In a narrow region about the step, 
sam- pling is 16 times more dense than in the rest, simulating the effects of adaptive sampling. The 
surface shown is a weighted-average recon-struction from those samples. A simple weighted average fails 
because it allows dense clumps of supersamples to overwhelm the influence of near-by base samples, as 
demonstrated by a simple thought experiment: Imagine a white circle being rendered against a black background 
with simple box filtering (i.e. area averaging). In one pixel, the edge of the circle may barely graze 
a corner. However, that tiny corner may be covered with many supersamples, while only one base sample 
at the opposite corner of the pixel lies on the black background. If all the samples in the pixel are 
averaged, the whole pixel will be nearly white, possibly creating a visi- ble bump on the edge. A practical 
solution, used in the prototype antialiasing module, is a multi-stage filter. Weighted-average filters 
are repeatedly applied with ever-narrowing low-pass cutoff until the proper bandwidth for the display 
is reached (i.e. until frequencies above the Nyquist frequency for the display are eliminated). This 
filter operates on a discrete two- dimensional grid much finer than the display pixels; 16 grid points 
per pixel area. For efficiency, each individual stage is a box filter. Figure 12 shows the result of 
applying the first stage of this filter. For each grid square, all samples lying within it are added 
up and the result divided by the number of samples. This is equivalent to filtering with a weighted-average 
box filter one grid square in width (one fourth the width of a display pixel). Figure 13 shows the second 
stage after applying a box filter twice as wide (i.e. with half the frequency bandwidth) as the first. 
This half- pixel filter is applied twice in the prototype antialiasing module to improve the filter characteristics. 
Figure 14 shows the result of applying the final stage of the filter. A weighted-average box filter one 
full pixel wide has been applied to complete a smooth surface. There are three relevant properties of 
this filter that make it successful. First, it is quite simple and efficient. The evaluation of the multi-stage 
filter dominates the computing cost of the antialiasing module, but because it is made up of box filters 
and because fixed-point arithmetic is used in the filter evaluation, only about two minutes of CPU time 
(on a VAX 8650) are used for a 640-by-480 picture. That time is more or less constant for all pictures, 
and it is almost always dwarfed by the time spent in the ray tracer computing sample values for a pic- 
ture (which is typically 30 minutes to several hours). Secondly, the multistage filter deals well with 
highly variable sampling density. This filter is a generalization of the reconstruction used by Whitted 
[WHIg0] in his adaptive sampling scheme. Dense clusters of supersamples are averaged and normalized locally 
before being com-bined with nearby base-sample values. Finally, the low-pass filter characteristics are 
adequate. The stages of the filter can be described by the convolution of four box filters: k (x) -box 
(x) * box (2x) * box (2x) * box (4x) (8) This results in a piece-wise cubic filter. As shown below, the 
multi- stage filter has much less leakage of signal above the low-pass cutoff than a simple box filter. 
The following figures have been scaled to set the cutoff frequency to 1. 1 - 0.5 I I I I I 0 1 2 3 4 
Box Filter Spectrum 1 - 0.5 - 0- I I I I 0 1 2 3 Multi-Stage Filter Spectrum This filter fits into a 
general scheme for nonuniform reconstruction pro- posed by Netravali [NET86]. He suggests that the interpolation 
and bandwidth properties of the reconstruction be separated. First, the nonuniform samples can be interpolated 
with any simple algorithm that does not attenuate too much signal below the display bandwidth. In a second 
stage, the surface resulting from the first step is then filtered in a more sophisticated manner to remove 
frequencies above the display bandwidth. The multi-stage filter accomplishes this, but in a sequence 
of gradual steps. 5. Conclusions Constructing a digital picture from a point-sampling function (e.g., 
a ray tracer) is complicated by the problem of aliasing. Nonuniform sampling is now recognized as a method 
for making aliasing noise less conspicuous to the viewer. Experiments with test patterns indicate that 
sampling patterns that meet the blue-noise criteria of Yellott produce results that are superior to those 
produeed by sampling at the same density with jitter. The point-diffusion algorithm for generating such 
blue-noise sampling patterns is presented. Some regions of an image may contain a large high-frequency 
com- ponent and require local supersampling to reduce the intensity of alias- ing noise. Rather than 
sample many times in one pixel area, a larger neighborhood of low-density base samples are used to detect 
high fre- quency, and this entire neighborhood is supersampled if necessary. This allows a lower overall 
sampling density to be used at the expense of less-precise targeting of supersampling.  ~) ~ Computer 
Graphics, Volume 21, Number 4, July 1987 Ideally, the decision of whether or not to supersample should 
be based on whether or not aliasing would be visible if supersampling were not done. A step in that direction 
is to measure local variation in sample intensity by a function reflecting the eye's non-linear response 
to con- trast. In color images, red, green, and blue contrasts are calculated and compared against three 
separate thresholds. The red, green, and blue thresholds can be adjusted to account for the eye's highly 
variable sensitivity to noise as a function of color. Having gathered all samples, the final step in 
producing a digital pic- ture is to reconstruct and resample at the display pixel rate. The nonuniformity 
of the samples and the sudden changes in sampling den- sity (on the boarders of supersampled regions) 
make reconstruction difficult. A multi-stage filtering algorithm is presented that solves these problems 
efficiently. 6, Acknowledgements I would like to thank Jim Kaiser, Henry Landau, John Limb, and Arun 
Netravali for many educational discussions about image and sig- nal processing. Tom Duff wrote the program 
which produced figures 11 though 14. 7. References [ABR85] Abram, Greg, Lee Westover, Turner Whitted, 
"Efficient Alias-free Rendering using Bit-masks and Look-up Tables", Computer Graphics, Vol. 19, No. 
3, July 1985, p. 57. lAMA84] Amanatides, John, "Ray Tracing with Cones", Computer Graphics, Vol. 18, 
No. 3, July 1984, pp. 129-135. [BRO69] Brown, Earl F., "Television: The Subjective Effects of Filter 
Ringing Transients", Journal of the SMPTE, Vol. 78, No 4, April t969, pp. 249-255. [CAEgll Caelli, Terry~ 
Visual Perception: Theory and Practice, Pergamon Press, Oxford (1981). [COO84] Cook, Robert L, Thomas 
Porter, Loren Carpenter, "Dis- tributed Ray Tracing", Computer Graphics, Vol. 18, No. 3, July 1984, pp. 
137-145. [COO86] Cook, Robert L, "Stochastic Sampling in Computer Graphics", ACM Trans. Graphics, Vol. 
5, No. 1, Janu- ary 1986. [CRO77] Crow, Franklin C., "The Aliasing Problem in Computer- Generated Shaded 
Images", Comm. ACM, Vol. 20, No. 11, November 1977, pp 799-805. [DIP85] Dippe, Mark A. Z. and Erling 
Henry Wold, "Antialias- ing Through Stochastic Sampling", Computer Graphics, Vol. 19, No. 3, July 1985, 
pp. 69-78. [FLO75] Floyd, R. and L. Steinberg, "An Adaptive Algorithm for Spatial Grey Scale", SID Digest. 
1975, 36-37. [FRA82] Franke, Richard, "Scattered Data Interpolation: Tests of Some Methods", Mathematics 
of Computation, Vol. 38, No. 157, January 1982. [KAJ841 Kajiya, James T., Engineering and Science, Vol 
48, No. 2, California Institute of Technology: November 1984. [KAJ86] Kajiya, James T., "The Rendering 
Equation", Computer Graphics, Vol. 20, No. 4, July 1986, pp. 143-150. [LEES5] Lee, Mark, Richard A. Redner, 
Samuel P. Uselton, "Sta- tistically Optimized Sampling for Distributed Ray Trac- ing", Computer Graphics, 
Vol. 19, No. 3, July 1985, pp. 61-67. [LIM691 Limb, J. O., "Design of Dither Waveforms for Quantized 
Visual Signals", Bell System Tech. J., Vol 48, pp. 2555- 2582, 1969. [LIM771 [MIT85] [NET86] [PET62] 
[RIP77] [ROT82] [SAK771 [SHA49] [SHA60] [wHIg0I IYEL831 [YEN56] Limb, John O., "Digital Coding of Color 
Video Signals-- A Review", IEEE Trans. Comm., Vol. COMM-25, No. 11, November 1977, pp. 1349-1382. Mitchell, 
Don P., "Antialiased Ray Tracing By Nonuni- form Sampling", unpublished Bell Labs report, April 1985. 
Netravali, Arun, Personal Communication. Petersen, Daniel P., David Middleton, "Sampling and Reconstruction 
of Wave-Number-Limited Funetions in N-Dimensional Euclidean Spaces", Information and Control, Vol. 5, 
t962, pp. 279-323. Ripley, B. D., "Modeling Spatial Patterns", J. Roy. Sta- tist. Soc. B, Vol. 39, 1977, 
pp. 172-212. Roth, S. D., "Ray Casting for Modeling Solids", Com-puter Graphics and Image Processing, 
Vol. 18, 1982, pp. 109-144. Sakrison, David J., "On the Role of the Observer and a Distortion Measure 
in Image Transmission.", IEEE Trans. Comm., Vol. COM-25, No. 11, November 1977, pp 1251-1267. Shannon, 
C.E., "Communication in the presence of noise.", Proc. IRE Vol. 37, 1949, pp. 10-21. Shapiro, Harold 
S. and Richard A. Silverman, "Alias- Free Sampling of Random Noise", J. SLAM, Vol. 8, No. 2, June 1960, 
pp. 225-248. Whitted, Turner, "An Improved Illumination Model for Shaded Display", Comm. ACM, Vol. 23, 
No. 6, June 1980, pp. 343-349. Yellott, John I. Jr., "Spectral Consequences of Photore- ceptor Sampling 
in the Rhesus Retina", Science, Vol. 221, 1983, pp. 382-385. Yen, J. L., "On Nonuniform Sampling of Bandwidth- 
Limited Signals", IRE Trans. Circuit Theory, Vol. 3, Dec. 1 1956, pp. 251-257. I+u~+ ~ a~ml SIGGRAPH 
'87, Anaheim, July 27-31, 1987 . . . , .- ;*'.e"-~.-)~.2~'1~+~ _"~Z," '~','¢I~.,'~', ":+"~'I+T.~,~:? 
ir:~:~- ",.': .,'" L'..." ..':'..., .:...'..':..'.. .... ..... , ..-;.- ~,~,p..*'-'. ~.~..~ ~,~.'~..~,. 
-' ~,-~ .-'- :;i--~ %)w- ~+.- ~..~. ~ ;~ ~,<,. + ~p:+=r..:::+,. ~, .,..:, ..,.,:,. ,.....+ ;+;,;.g+",,;+ 
~.'+.~.-;,++ ~.-ia,;; ~ ~ +, .p;+i'e,,..,,. ",'~',:, ..,-,+ ,,.,"-_.-, -" --:..'+. ~',i~,~-,_'/'.,, "+-~,,, 
+,-.., %'..[:,~ .~ .~:-, "   i ii iii! , ,++,,,....... ,.~ ~ . !3~.., .,,.:,~ +;'~e J,; ~:9.'~4 . 
'. ~, _~+~ u+ e I-N, ! ,-"s,;. ,:~..~.+ " .' .m ,'.,.'P~. +,,r ' .L'.+~-_+Y ~-,. +'VL:.".--,.~,E.,,~e- 
 ---.::.,~,-',"..,:, ,,...P'2_-'~:' ', T.,;' .'.+t*'7~alr-,+..+ ,. ...,4,,,..;"+.,;.,k'./L.,e. :,L'.,~'.,+':,i",; 
~ -,..~.~,-~:-;:=_+~Y~,.~ I~ ,~a~.; ~:~f-~, ,'-':~ 2~:~--.+, +.- -::.~-~,~.'P@:~--~Sx-% ..... :.<.£-~ 
,~,"~<.-.;;~ .,-+.-'~." ,. ~.-lp,:.~p~qr~L2~r;.-~. -%~.%~,; '.~',-,-.', ' ~'" ",'~'-~l,'~k* ,.~-*,,l-r'~-..~ik. 
.,.w-+~, ,.-L.,,,i~+*_~.~..~Ik:~.,-~:, ':-~++-~°.,it* F..o ,°" ', ; "-i 411~~-.... :4" .'~"L +" . ",~.'+ 
~ "+.,'+:'-;~2-'.-m':"--..%;~-~,. :+-2,-'-' ~. ;.7; ~.'+ :~'~i'.r.~.~, + +.~7.~ ~4,.,~,.~.-.~ ~_-.'{. 
~,.+ ~, ~ ~.:.~ ,-OL;- +'+~----~.~_4 +,~.T- ~ :~ %? li~,,";,'+-~",~--E'~-". "-" ~" ;.;Z~-.';~ ~(/+,':'. 
~ ~."2.~2~ ~-T+" :i ~I"~'-: -<c.v1p'.~."~ ~.E'l.2; .P'2t ]i. r ~ ~ 0' ,",'P.-,,,-:,..~'+..;::~ +k.e +` 
-E',"--+",, ".'+ -~'+C.,,, ',,'r." ~"-'k + .".liP-' =..r|. "'. ".+,',:~.-',,',,,,~:,- ;,'..'. '.E¢+~. 
". ¢2~1~" "~ -"IZ': +~ " ~+-" "+'" '..:iP-/",~'~ ' L. "4," " ~'I"-" .~41.',. :[" '-",~'..eZr..," 4" 
.-.-~'Ii.'4 ~,.++'+~.:~ ,+'..-~+..~. ~ .-. 0,'r+-".-" ~, ~ op ~'~ -,.~".~ ~,:g+j, ~,.0..0.,;~'#.'-'~." 
".2+~.~. "+. -~+..¥" .,.-.:'~+ ,.~ :t,; .'.,.+ .q .it ~....-,-'1. ,1~-,, . . ,. . ,1--~.--"'-.m. ., ~.,~.: 
,.-:_>:,".;'~ .,.-. . . .+.. ,..,++~. ,.':-%.~..'..,f~,- ~-,",.~ -:a~r,l'.T~ ".: "' ", " . ' ~I "; "~'%'+'~ 
"~ +i ~ ", ,~lr'-, . . . . . ,,-'~" ' "~L ;- ..~'';r.L~.l"- '~' ~'~]<+IN+~',-'.--'. ~-.::+~.:,'~;.;'. 
: ~-c+~I.2-. "~.~, . .:~+,,... ' ,, ~-~ . -, 1~ .-P--~-" ~ . "~..+-~e + .." .... ~ u'% .~'" "'t" ". 
+.;~':~e'-e ,:e .... ..Je.2;.,~. ~..,, .+'~'~.-++ ..~o ~ . ... ?'~,,0-.. +-+.;..+, 'e-'X ' ~ ,: . -. 
.,.~,~-. ..:.'#, ~..~.--.. :,# ~." .~'..:,- -...~.._- ~ .... P,. :, + ~ -.o _+- ."2 ;'~:, +'N P.l~" 
. "e ;, g'~r ~-. .~ ~,,~+.. ,e.~+,... .0: .-' '~.:" ;~,. ;~. !#5~ ~ 171~.o + ; ,l I .-5.:°I~ "k.%,?! 
..ej;_:+..~. ~, ,~e~.. v2~;".! ~ Figure Figure k:i. :.! S.:iiiii i.li :i -. :"i.:.:.:-:" :.'.ZZ.'.:.:'.)7.--:.:i:..i 
:.'.)("-"t'::.t:.:-:-: 1. ."' .... .--'.. "'. ." .'..." . ." '4 ". .+ .. **  . . . . , -. .. .,. 
... ... .o. o . :* .. * .: . .. o  .. *...  ". ..... ..... "o..-." .o ..-.. :-.-...'. ; ¢  : L. 
:'" ..... : .... : -':.'.. "..'. ".... ~ ...-:.-." .'.," ,... , ., "..'. -. :. ...-...-....-:....-.: 
.. : .'-.:....'....:.:'..::...._. : ":: "**'." *o''" " i * "..*" * *'* ** "* * ... ° r.': . ". . 
*.-% "-'". " * .*'** ; *o* .+.***  .. -. . .. :.:.j  :.".':'.: "-.L':.'.:'."."...-I.'.-'! '"""'--... 
, ; "" :':-:::  ::""" :'i: .- . . * ** .... ....., . -..: ....;,. -: :.'. .." ..:.:  .. **;* . .. 
i : i : . ." . ..:.:. ....... :-... ; .'.'...... -...'. .... .,....: .-., , . .... . ..... .. . .. 
o .. . ,.. .-:.:.........: :.,.. .:-::/j ;. :":"- ~-...." .;.,." ;..'... .....: ..': ." : ...: ; 
.'..- --**  .......o . .. . ... "~ .'...+..'..... . .-.-.'.. :...... ...... : . ~. .... -:.. -.....:-. 
.... o -+-. . . i .+.  .* .. .o o . . . "** -*o *% * ." .* .**." : i* ".* "*°* .- % +. .. ..... 
.+. ... ., :. ... .- .. ... -..0 o '. "." ...'.: . ; , " -.-'l'. "  ". . " ..  . . :.. ....'. 
. .. ;. .: "...'.'....:'" : ..':: ...;.'.-.,...'....'. ... ,. ".,+ **  . . .. .--l.." ..-. +,o ....%... 
"" ':" .. ''",i.':-"-.." :".-; i: : .-": " : .'; .... "'"" . . :':: . 2. %g°": ". i" ..... a. : 'I~.,,. 
I~' ', ,+',,.,,5 ,." ". " ,,,,~ +:"t-,:a ~..:,.+ .1 ~,~c 2~ .,.% +. -:..... .... ~ + .,, Figure 6. 
 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37411</article_id>
		<sort_key>73</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Ray tracing JELL-OTM Brand Gelatin]]></title>
		<page_from>73</page_from>
		<page_to>74</page_to>
		<doi_number>10.1145/37401.37411</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37411</url>
		<abstract>
			<par><![CDATA[Ray tracing has established itself in recent years as the most general image synthesis algorithm. Researchers have investigated ray-surface intersection calculations for a number of surface primitives, including checkerboards, glass balls, green fractal <i>hills, mandrills, abstract blue surfaces</i>, more glass balls, robot arms, pool balls, low-resolution clouds, morphine molecules, aquatic blobby things making strange noises, fantastic cities, and running skeletons. Unfortunately, <i>nobody has ray traced any food</i>. The <i>Dessert Realism Project</i> here at Pixar is addressing this problem. This paper presents new technology for ray tracing Jell-O&amp;reg; brand gelatin. We believe the method may have application to other brands of gelatin and perhaps pudding as well.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Health</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>C.1.2</cat_node>
				<descriptor>Array and vector processors</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010449</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Health informatics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010528.10010535</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Parallel architectures->Systolic arrays</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010446</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Consumer health</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Human Factors</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P221481</person_id>
				<author_profile_id><![CDATA[81100383628]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Heckbert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pixar, San Rafael, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>15918</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Barr, Alan H., "Ray Tracing Deformed Surfaces", SIGGRAPH '86 Proceedings, 20(4), Aug. 1986, pp. 287-296.]]></ref_text>
				<ref_id>Barr, 1986</ref_id>
			</ref>
			<ref>
				<ref_obj_id>908845</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Blinn, James F., "Computer Display of Curved Surfaces' ', PhD thesis, CS Dept., U. of Utah, 1978.]]></ref_text>
				<ref_id>Blinn, 1978</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Fuller, R. Buckminster, Synergetics, MacMillan Publishing Co., 1975, p. 125.]]></ref_text>
				<ref_id>Fuller, 1975</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Graham, Eric, "Graphic Scene Simulations", Amiga World, May/June 1987, pp. 18-95.]]></ref_text>
				<ref_id>Graham, 1987</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Haeberli, Paul, and Paul Heckbert, "A delr-O ~ Calculus", ACM Transactions on Graphics, special issue on ray tracing moist surfaces, 1872, to appear.]]></ref_text>
				<ref_id>Haeberli, 1872</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kajiya, James T., "The Rendering Equation", SIG- GRAPH "86 Proceedings, 20(4), Aug. 1986, pp. 143- 150.]]></ref_text>
				<ref_id>Kajiya, 1986</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Plastock, Roy A., and Gordon Kalley, Schaum's Outline of Computer Graphics, McGraw-Hill, New York, 1986.]]></ref_text>
				<ref_id>Plastock, 1986</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Sales, Soupy, The Soupy Sales Show, 1966.]]></ref_text>
				<ref_id>Sales, 1966</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Well~r, Tom, Science Made Stupid, Houghton Mifflin Co., Boston, 1985.]]></ref_text>
				<ref_id>WeUer, 1985</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Whitted, Turner, "An Improved Illumination Model for Shaded Display", Communications of the ACM, 23(6), June 1980, pp. 343-349.]]></ref_text>
				<ref_id>Whitted, 1980</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Williams, Lance, personal communication, 1980.]]></ref_text>
				<ref_id>Williams, 1980</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 O ~ Computer Graphics, Volume 21, Number 4, Judy 1987 Ray Tracing J ELL-O ® Brand Gelatin Paul S. Heckbert 
Dessert Foods Division Pixar San Rafael, CA ABSTRACT Ray tracing has established itself in recent years 
as the most general image synthesis algorithm. Researchers have investigated ray-surface intersec- tion 
calculations for a number of surface primitives, including checkerboards, glass balls, green fractal 
hills, mandrills, abstract blue surfaces, more glass balls, robot arms, pool balls, low-resolution clouds, 
morphine molecules, aquatic blobby things making strange noises, fantastic cities, and running skele-tons. 
Unfortunately, nobody has ray traced any food. The Dessert Realism Project here at Pixar is addressing 
this problem. This paper presents new technology for ray tracing OelI-O ® brand gelatin. We believe the 
method may have application to other brands of gelatin and perhaps pudding as well. CR Categories: C.1 
[Processor Architectures]: Multiproces-sots -Array and vector processors; 1.3.7 [Computer Graph- ics]: 
Three-Dimensional Graphics and Realism -color, shad- ing, shadowing, and texture; J.3 [Life and Medical 
Sciences]: Health. General Terms: algorithms, theory, food. Additional Key Words and Phrases: ray tracing, 
lattice algo- rithm, Jeli-O ® , gelatin. Permission to copy without fee all or part of this material 
is granted provided that the copies are not made or distributed for direct commercial advantage, the 
ACM copyright notice and the title of the publication and its date appear, and notice is given that copying 
is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires 
a fee and/or specific permission. &#38;#169; 1987 ACM-0-89791-227-6/87/007/0073 $00.75 Introduction Ray 
tracing has established itself in recent years as the most general image synthesis algorithm [Whitted, 
1980]. Ray tracing food has remained an open problem, however. So far the most realistic foods were Blinn's 
classic orange and strawberry images, but these were created with a scanline algo- rithm [Blinn, 1978]. 
This paper presents new technology for ray tracing a restricted class of dessert foods, in particular 
Jell- O®I" brand gelatin. Our paper is divided into three parts: methods for model- ing static dolI-O 
®, simulation of delI-O ® motion using impres- sive mathematics, and ray-Jeli-O ® intersection calculations. 
Jeli-O ® Shape To model static Jeli-O ® we employ a new synthesis tech- nique wherein attributes are 
added one at a time using abstract object-oriented classes we call ingredients. Ingredient attri-butes 
are combined during a preprocessing pass to accumulate the desired set of material properties (consistency, 
taste, tor- sional strength, flame resistance, refractive index, etc.). We use the RLS orthogonal basis 
(raspberry, lime, and strawberry), from which any type of Jell-O ® can be synthesized [Weller, 1985]. 
Ingredients are propagated through a large 3-D lattice using vectorized pipeline SIMD parallel processing 
in a sys- tolic array architecture which we call the Jell-O ® Engine. Furthermore, we can compute several 
lattice points simultane-ously. Boundary conditions are imposed along free-form sur- faces to control 
the Jeli-O ® shape, and the ingredients are mixed using relaxation and annealing lattice algorithms until 
the matrix is chilled and ready-to-eat. JelI-O ® Dynamics Previous researchers have observed that, under 
certain conditions, Jeli-O ® wiggles [Sales, 1966]. We have been able to simulate these unique and complex 
Jeli-O ® dynamics using spatial deformations [Barr, 1986] and other hairy mathematics. From previous 
rescarch with rendering systems we have learned that a good dose of gratuitous partial differential equa- 
tions is ncedcd to mcet the paper quota for impressive formu- las. Therefore, we solve the Schr6dinger 
wave equation for the Jeli-O ® field J: 2m "E V2J + ---~-( -V)J = 0  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37412</article_id>
		<sort_key>75</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[GRAPE: An environment to build display processes]]></title>
		<page_from>75</page_from>
		<page_to>84</page_to>
		<doi_number>10.1145/37401.37412</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37412</url>
		<abstract>
			<par><![CDATA[New modelling primitives and new rendering techniques are appearing at a rapid rate. To be able to implement and evaluate them easily, we need a very flexible display environment. We describe an environment which allows experimenting both with the basic modelling and rendering operations and with the process structure of the display system.The desired operations are implemented in <i>nodes</i>, coded in a traditional programming language, which can then be structured into arbitrary directed acyclic graphs. These nodes are all "plug compatible", and pass streams of <i>appels</i>, which are generalized pixels, that is data structures containing information necessary for pixel evaluation. In addition, synchronization parameters are used to allow the expansion or the reduction of the stream of appels.This approach allows the assembly of new display systems from existing modules without coding, making it easy to experiment with different architectures and display processes. Algorithm designers are also able to test an algorithm at any point of the display process with a minimum of new coding.We describe an implementation of the scheme with a library of nodes written in C and the assembly of the graphs made through the use of the directory manipulation tools provided under UNIX&amp;trade;. We give examples of the uses of the implementation to build basic nodes, variations in compositing and texture mapping and special-purpose display systems.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P283646</person_id>
				<author_profile_id><![CDATA[81100062610]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tom]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nadas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Univ. of Toronto, Toronto, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42051322</person_id>
				<author_profile_id><![CDATA[81100345881]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alain]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fournier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Univ. of Toronto, Toronto, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Agerwala, T. and Arvind, "Data Flow Systems", Computer, Volume 15, Number 2, February 1982, pp. 10-13.]]></ref_text>
				<ref_id>AgAr82</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Blythe, D., Kitamura, J., Galloway, D. and Snelgrove, M,, "Virtual Patch-Cords for the Katosizer", Proceedings of the 1986 International Computer Music Conference, October 1986, pp. 359-364.]]></ref_text>
				<ref_id>BKGS86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37414</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cook, R. L., Carpenter, L. and Catmuil, E., "'The Reyes Image Rendering Architecture", These Proceedings.]]></ref_text>
				<ref_id>COCC87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808602</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cook, R. L., "Shade Trees," Computer Graphics. Volume 18, Number 3, July 1984, pp. 223-231.]]></ref_text>
				<ref_id>Cook84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801253</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Crow, F. C., "'A More Flexible Image Generation Environment," Computer Graphics. Volume 16, Number 3, July 1982, pp. 9-18.]]></ref_text>
				<ref_id>Crow82</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Duff, T., The Soid and Roid Manual, NYIT Computer Graphics Laboratory internal memorandum, 1980.]]></ref_text>
				<ref_id>Duff80</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325174</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Duff, T., "Compositing 3-D Rendered Images," Computer Graphics, Volume 19, Number 3, July 1985, pp. 41-44.]]></ref_text>
				<ref_id>Duff85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Gouraud, H., "Continuous Shading of Curved Surfaces," IEEE Transactions on Computers, Volume 20, Number 6, June 1971, pp. 623-629.]]></ref_text>
				<ref_id>Gour71</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6023</ref_obj_id>
				<ref_obj_pid>6020</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Greene, N. and Heckbert, P. S., "Creating Raster Omnimax Images from Multiple Perspective Views Using Elliptical Weighted Average Filter," IEEE Computer Graphics and Applications, Volume 6, Number 6, June 1986, pp. 21-27.]]></ref_text>
				<ref_id>GrHe86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Haeberli, P. "A Data Flow Manager for an Interactive Programming Environment", Proceedings of USENIX Summer Conference, Atlanta, GA, 1986.]]></ref_text>
				<ref_id>Haeb86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Hall, R. A. and D. P. Greenberg, "A Testbed for Realistic Image Synthesis," 1EEE Computer Graphics and Applications, Volume 3, Number 11, November 1983, pp. 10-20.]]></ref_text>
				<ref_id>HaGr83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hedelman, H., -A Data Flow Approach to Procedural Modeling", IEEE Computer Graphics and Applications, Volume 4, Number 1, January 1984, pp. 16-26.]]></ref_text>
				<ref_id>Hede184</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Nadas, T. P., The Computation of Appearance Elements, M. Sc. Thesis, Department of Electrical Engineering, University of Toronto, 1986.]]></ref_text>
				<ref_id>Nada86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>16581</ref_obj_id>
				<ref_obj_pid>16564</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Paeth, A. W. and K. S. Booth, "Design and Experience with a Generalized Raster Toolkit," Graphics Interface 1986 Proceedings, May 1986, pp. 91-97.]]></ref_text>
				<ref_id>PaBo86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Perlin, K., "Art Image Synthesizer," Computer Graphics. Volume 19, Number 3, July 1985, pp. 287-296.]]></ref_text>
				<ref_id>Per185</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Bui-Tuong Phong, "illumination for Computer Generated Pictures," Communications of the ACM, Volume 18, Number 6, June 1975, pp. 311-317.]]></ref_text>
				<ref_id>Phon75</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808606</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Porter, T. and T. Duff, "'Compositing Digital Images," Computer Graphics. Volume 18, Number 3, July 1984, pp. 253- 259.]]></ref_text>
				<ref_id>PoDu84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37413</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Potmesil, M. and Hoffert. E. M., "'FRAMES: Software Tools for Modeling, Rendering and Animation of 3D Scenes", These Proceedings.]]></ref_text>
				<ref_id>Polio87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Robinson, J. and S. Zimmerman, "Exploiting Texture in an Integrated Training Environment", CIG Technical Report, Evans &amp; Sutherland, 1984.]]></ref_text>
				<ref_id>RoZi84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Reeves, W. T. Salesin, D. H. and Cook, R. L., "Shadowing with Texture Maps", These Proceedings.]]></ref_text>
				<ref_id>ReSC87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357295</ref_obj_id>
				<ref_obj_pid>357290</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Whitted, T. and D. M. Weimer, "A Software Testbed for the Development of 3D Raster Graphics Systems," ACM Transactions on Graphics. Volume 1, Number 1, January 1982, pp. 43-58.]]></ref_text>
				<ref_id>WhWe82</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 21, Number 4, JuJy 1987 GRAPE: An Environment to Build Display Processes 
Tom Nadas t Alain Fournier ¢: Computer Systems Research Institute University of Toronto Toronto, Ontario 
M5S 1 A4 { tomlalain [@csri.toronto .edu Abstract New modelling primitives and new rendering techniques 
are appearing at a rapid rate. To be able to implement and evaluate them easily, we need a very flexible 
display environment. We describe an environment which allows experimenting both with the basic modelling 
and rendering operations and with the process structure of the display sys- tem. The desired operations 
are implemented in nodes, coded in a tradi- tional programming language, which can then be structured 
into arbitrary directed acyclic graphs. These nodes are all "plug compatible", and pass streams of appels, 
which are generalized pixels, that is data structures containing information necessary for pixel evaluation. 
In addition, syn-chronization parameters are used to allow the expansion or the reduction of the stream 
of appels. This approach allows the assembly of new display systems from existing modules without coding, 
making it easy to experiment with dif- ferent architectures and display processes. Algorithm designers 
are also able to test an algorithm at any point of the display process with a minimum of new coding. 
We describe an implementation of the scheme with a library of nodes written in C and the assembly of 
the graphs made through the use of the directory manipulation tools provided under UNIX TM. We give examples 
of the uses of the implementation to build basic nodes, varia- tions in compositing and texture mapping 
and special-purpose display sys- tems. CR Categories: 1.3.2 [Computer Graphics]: Graphics Systems; 1.3.3 
[Computer Graphics]: Picture/Image Generation --display algorithms; 1.3.4 [Computer Graphics]: Graphics 
Utilities; 1.3.7 [Computer Graph- ics]: Three-Dimensional Graphics and Realism, --Color, shading, sha- 
dowing and textures. General Terms: display systems. Additional Keywords and Phrases: data flow. -~Address 
until September 1987: Departement de la Recherche Prospective, INA, 4 Avenue de I'Europe, Bry-sur-Marne. 
94360, France :~ Address until September 1987 CSL Xerox PARC, 3333 Coyote Hill Road, Palo Alto, CA. 94304 
ARPAnet: fournier.pa@XEROX.COM rM UNIX is a registered trademark of AT&#38;T Bell Laboratories. Permission 
to copy without fee all or part of this material is granted provided that the copies are not made or 
distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. ¢ 1987 ACM-0-89791-227-6/87/007/0075 
$00.75 1. Introduction Systems to produce raster images from three-dimensional models are not as simple 
as they used to be (if they ever were). The past few years have seen a large increase in the number of 
modelling primitives, illumination models, filtering techniques, manipulations on raster images, and 
even a few new geometric operations. The simple pipeline described in Figure In, with a single flow of 
information between the modelling, geometric and display operations, is still useful for a global description 
of a generic display system, but is not representative of what most real sys- tems are doing. At the 
very least current systems deal with many types of modelling primitives, which are kept in separate parallel 
streams until they are merged into a common stream of geometric primitives (Figure lb). Gen- erally, 
these geometric primitives are polygons, and adding a new model- ling primitive is relatively simple 
if one knows a reasonable way to break it down into polygons. In the class of rendering techniques which 
includes ray-tracing and ray-casting, the flow of information is different, but the topology of the display 
system is very much the same (Figure It). In this case, a single geometric primitive, the ray, fans out 
to multiple modelling primitives. Adding a modelling primitive again simply reduces to being able to 
compute its intersection with a ray. In spite of their dif- ferent process flows, many operations in 
these systems, such as shading, can be the same, and should not need to be rewritten. In most existing 
systems any internal change to the display process is a serious job that only brave souls dare undertake. 
Remarks by Porter and Duff in [PoDu84] about Reyes, and by Greene and Heckbert [GrHe86] about the NYIT 
display system are indicative of how hard modifications can be.  2. Previous Work Of course we are not 
the first ones to perceive these problems and needs, and many solutions, some of them very effective, 
have been pro- posed and/or implemented. It is interesting to note that most of the earlier work was 
to achieve more flexibility at the level of the structure of the process, while most of the recent work 
bore on the functional level. 2.1. General Environments Several workers addressed the problems by designing 
flexible test- ing environments. Whitted and Weimer [WhWe82] designed a testbed whose structure is diagramed 
in Figure 2a. The various flows from the various modelling primitives eventually converge into common 
span buffers. While certainly a useful system, especially to experiment with new modelling primitives 
and fully integrate them quickly with the rest of the display process, it does not have much flexibility 
either at the global or at the local level. Crow [Crow82] discusses a system which is notable in this 
context mainly for the attempt to decouple the scene analysis from the rendering operations. The scene 
analysis step is intended to facilitate the processing of objects in parallel, as long as they are determined 
not to interfere with each other's visibility. The resulting images are merged on the screen according 
to the priorities determined during the scene analysis. The rendering processes themselves are specified 
by the objects, and therefore considerable flexibility is gained in mixing different model- ling primitives. 
In addition one of the goals was to allow for more flexibil- ity in the assignment of the various processes 
to the available processors. ~~ SIGGRAPH '87, Anaheim, July 27-31, 1987 Modelling Geometry L Display 
Simplified view of the display pipeline Disptay Geomeu'y tj J.~ Structure of many current display systems 
Primitive 1 ~ Primitive 2 Display --~ Geometry Primitive i Structure of conventional raytracing Figure 
I. Various display structures Hall and Greenberg [HaGr84] describe another testbed, this one oriented 
more towards ray-tracing. Within our context, the interesting point is that the structure resembles the 
one diagramed in Figure 2h. The new factor is that there is an additional fanout at the end of the system 
into several rendering processes. The other main characteristic is that the communica- tion between the 
various modules of the system is through files. This has the advantage of simplicity and flexibility, 
but the distinct disadvantage (besides inefficiency, which might not be of prime concern in testing) 
is that there is no guaranteed common interface between modules. The structure of the information contained 
in the files has to be known by each module which uses them. 2.1.1. Reyes Reyes is the rendering system 
designed and implemented at Pixar and described in [COCC87]. The overall structure of Reyes is similar 
to the one diagramed in Figure lb, with many modelling primitives reduced to a common geometric primitive, 
in this case micro-polygons. Reyes represents probably the best implementation for that type of structure. 
In particular it achieves additional flexibility by the use of shade trees (see below) for shade computations, 
and by the introduction of many "hooks" to extend its capabilities [ReSC87]. In summary these types of 
general environment indeed facilitate experiments with new modelling primitives and sometimes make it 
easier to replace modules, but do not allow experiments with the very structure of the display system. 
2.1.2. Data Flow Systems Much closer to the present work are systems based on data flow, Hedelman [Hede184] 
describes a data flow approach to modelling, which also includes functions for display. He clearly shows 
the advantages of a data flow approach for modelling and rendering. Haeberli [Haeb861 describes a data 
flow manager implemented under UNIX. The processes communicate through files, and the data exchanged 
are typed messages. The emphasis is on interactive control of the processes, and the system has an excellent 
user interface for that purpose. Similar work has been conducted in the area of sound processing. Virtual 
Patch-Cords [BKGS86] is an example of a system which creates standard interfaces to facilitate the connection 
of a library of modules. 2.2. Compositing Environments Compositing in essence merges the output of several 
independent display pipelines at the latest stage of the process (see Figure 3). Primitive 1 ~ Display 
Compositing Figure 3. The process structure in compositing The variations in compositing are about what 
kind of information and/or operation is used to compute the final image as a function of the original 
ones. In one early such environment [Duff80/, each of several specialized renderers used the depth-buffer 
left by the preceding ones. The obvious advantage of such a system is the ease with which specialized 
renderers may be added since the only restriction is that they adhere to the depth- buffer format. To 
solve the aliasing problem this might cause, one can add infor- mation about the amount of coverage (often 
called the opacity) to each pixel value [PoDu84]. This also allows one to define many interesting operations 
based on the opacity values. One can of course, get better results by combining the two techniques [Duff85/. 
Compositing is a very powerful and useful technique, especially in the form described in [PoDu84] and 
[Duff85/. It is relatively easy to implement, and allows one to merge pictures from very different systems. 
It is both a strength and a drawback of compositing that it is not con- cemed with the structures of 
the display processes which generated the pictures on which it operates. As a result, many global effects 
such as sha- dows and reflections are out of reach. It also offers no help in building the display processes 
themselves. 2.3. Pixel Evaluators In many ways, the compositing operations are too late in the display 
process, and an environment which aids in the creation ofpixel evaluators would prove to be an invaluable 
tool. A pixel evaluator may be defined as a specialized process that converts a list of parameters associated 
with a single pixel (such as normals, st~rface characteristics, depth) into a pixel eolour. Note that 
in this context we use the word pixel in its generic sense of picture element, rather than as one entry 
in an array of raster values. 2.3.1. Shade Trees The first notable attempt at providing an environment 
in which pixel evaluators could be created stemmed from the need to provide a more flexible shading module 
in a traditional rendering system [Cook84]. It was recognized that the shading process could be broken 
down into a number of basic operations which could then be organized in a tree-like structure. Hence, 
these particular, pixel evaluators have been dubbed shade trees. ) ~ Computer Graphics, Volume 21, Number 
4, July 1987 Primitive 2 Span buffer ~-~ Display a) Struc'iure of testbed described in [WhWe82] Geometry 
Display b) Structure of testbed described in [HaGe83] Figure 2. The structure of two testbeds. In the 
implementation described in [Cook84], the tree nodes are basically function calls, and the writing of 
a node is equivalent to writing a C function. Each "node" interface is therefore unique and, as with 
any function, the user must ensure that it is called with appropriate values and ihat it is used properly. 
As a result, the user must be an experienced pro- grammer, since the tree description is an actual program. 
Shade trees are driven by a traditional general rendering program that calls the appropri- ate shade 
trees for each pixel (even though shade trees are object specific, in the Reyes implementation they are 
called at the micropolygon level, which is at the sub-pixel level). The program passes a standard list 
of parameters to the shade tree, and expects a final colour and opacity value to be returned. 2.3.2. 
Pixel Stream Editors A pixel stream editor is a pixel evaluator which is used to edit or manipulate 
a pixel stream [Per1851. A pixel stream is simply a list of an arbitrary number of pixels, where a pixel, 
in this context, is any combina- tion of appearance parameters. The pixel evaluator edits one pixel at 
a time and either alters one or more appearance parameters or converts the pixel format by adding and/or 
removing appearance parameters. Although the ultimate goal is to provide a pixel stream whose pixel format 
is a colour, any individual pixel stream editor may output a stream of any type of format. In fact, there 
is not even a requirement that the number of pixels in the incoming and outgoing streams be the same. 
A single pixel stream editor may be as simple or as complex as desired, and is therefore analogous to 
a sub-tree in the shade tree environ- ment. However, a complex combination of pixel stream editors may 
suffer from the same problem as the shade tree program, in that it may become a seemingly unrelated list 
of commands. Some advantages have been lost from the shade trees; in a shade tree, a node or sub-tree 
only inputs the required appearance parameters and only outputs those which it alters or generates. In 
contrast, any single pixel stream editor may input and output other seemingly redundant appearance parameters 
to be used by other pixel stream editors later on. 2.4. Pipe-Based Systems Since UNIX pipes constitute 
a very convenient tool for linking processes it is natural to use them to link the modules of a display 
system. This approach to build a flexible tool for image manipulation has been proposed by Paeth and 
Booth [PaBo86]. Their Image Manipulator is essentially a set of modules inputing a stream of pixels and 
outputting same, and communicating through pipes. This yields a system which is powerful, easy to use 
and easy to add on to. In its method of communica- tion between modules, it is similar to the system 
described in [HaGr84]. Their system has the additional benefit of a flexible pixeL representation, so 
that each module can determine the information which is passed to it. In this respect, their pixel files 
are very similar to the streams of appels we will define later. Its main weakness is to be limited to 
what amounts to single operand operations on stream of pixels. The topology of the system is restricted 
by the use of pipes to a single-flow pipeline. Potmesil and Hoffert /Polio87] have, in their system named 
FRAMES, developed a set of software tools which are linked through pipes. Their modules are meant to 
implement all the operations of a rendering system. There is no standardization as to what type of data 
flows through the pipes. Their system offers much flexibility in the rear- rangement of the modules, 
and in the distribution of their execution to multiple processors. The main drawback is again that the 
overall system is constrained to a pipeline structure. It is interesting to note that a linear flow of 
information is not as much a restriction in building display systems as it may appear at first. Because 
it is always possible to embed a partial order into a linear order by topological sorting, any directed 
graph corresponding to a partial order can be "squeezed" into a pipeline. The drawback of course is that 
the true relationships between modules are lost, and that potentially large amounts of data are passed 
around needlessly. 3. GRAPE 3.1. Goals of GRAPE We designed and implemented a system called a General 
Render- ing Applications Programming Environment, or GRAPE, to facilitate exper- iments with the structure 
and basic algorithms of a display system. It was not intended as a production system or as a demonstration 
of any particu- lar algorithm (more details about the implementation of GRAPE can be found in [Nada86]). 
The main goals were: to permit flexibility in the rendering environment. In particular we did not want 
the system to be biased toward any particular render- ing solution. A look at all the systems described 
above shows that most have at least a "conceptual bottleneck", where all the data has to be converted 
to the same primitives. We wanted to avoid this phenomenon, which limits experimentation and inhibits 
new solu-tions.  to provide the reusability of the software components. Even if we create different 
systems with different structures, it is very likely that they will share some of the basic components. 
We wanted to make it easy to reuse these without reprogramming.  to facilitate standardization of the 
software tools. At first glance this seems in contradiction with the goal of flexibility. But in fact 
the standardization is not in the content of the tools, but in their inter- face with each other.  to 
allow experimentation with the basic operations. This is the kind of flexibility which is normally achieved 
in a well designed modular software system. We did not want to lose it.  to allow experimentation with 
the flow of processes. This is the most powerful aspect of shade trees and pixel stream editors. We also 
wanted to allow these experiments to be conducted with very little or no code writing.  To meet these 
goals, we created a programming environment on two levels. At the micro level, it is very much like a 
traditional program- ming environment, in which code is written in a conventional language (C in our 
current implementation), to create nodes implementing basic algo- rithms which can be placed in a library. 
At the macro level, the user puts together these nodes into graphs which belong to the class of directed 
acy- clic graphs, or dags. That is the most general class of data flow graphs without cycles. To work 
at either level one does not have to know or worry about the other level. At the micro level, GRAPE will 
automatically create the standard interface to ensure interconneetivity of the nodes. At the macro level, 
the user only has to know the functionality of the nodes to be able to use them, and GRAPE will connect 
them together in the manner described through a dag compiler. The distinction between the levels is not 
merely one of functionality, but also signifies a difference ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 
between the skills required of the users at each level. At the micro level, users are algorithm designers 
and programmers. At the macro level, users work more like system designers. If the environment created 
is really suc- cessful and complete, then the users of the macro level can be picture and animation designers. 
That is to say they can build without coding a display system specifically for a given picture, a given 
effect or a given animation sequence. 3.2. Appels Basically, GRAPE is an environment to build dataflow 
systems. That is, once designed and compiled, the working rendering system obtained is a data flow system 
[AgArS2]. But since our targets are specifically display processes, all the nodes communicate through 
a common data ele- ment which we call appels,a contraction of appearance elements. Appels are the common 
datatypes on which the nodes operate, They were designed for rather conflicting roles: they have to be 
general enough to contain any information any node in the rendering system would operate on, and they 
have to be the "standard format" through which all nodes communicate. The way to meet both of these goals 
was to have an appel be made of any number of appel slices, that is specific appearance ele- ments (such 
as colour, transparency, normal, shading parameters), and each collection of similar appels is preceded 
by an appel core which identifies their content. Obviously, in most applications, an appel core will 
be followed by a large stream of appels, so there is very little overhead introduced by the appel core. 
It is important to note that there is no prescribed correspondence between pixels and appels. As the 
process gets closer to the final image, appels will look more and more like pixels, but farther "upstream", 
appels can be polygons, parametric surfaces, spans, etc. Appels play their roles as standard connectors 
in the following sim- ple way. The only data the nodes input and output are appels identified by an appel 
core. Therefore the nodes can be connected in any way after they have been written, with the only requirement 
being that the appel core for the input of a node is a subset of the union of the appel cores output 
by the nodes connected to its input. The system verifies this automatically when the dag is compiled. 
As an example we show below an appel core used as the header of a file full of appels. The first two 
lines give the name of the core and the resolution. The rest is the appel core proper. Notice that the 
appel core allows the specification of both the semantics and the data type of the slices. This makes 
it easy to use "foreign" files as input to GRAPE, since most of the time the only thing to do is to insert 
the appropriate header. span 512by512 masterName as string instanceName as string identNum as I byte 
screenP~s as 2ira colour as 3byte dcolour as 3float normal as 3float dnormy as 3float depth as lfloat 
devicePos as 3float eyepos as 3float worldpos as 3float objectpos as 3float dobjectY as 3float textarepos 
as 2float dlextureY as 2float 4. The Micro Environment The micro environment is a fairly traditional 
programming environ- ment, where the user codes the nodes in the C programming language. The purpose 
of the environment is to ensure that the nodes created con- form to the standard format so that they 
can be used and linked freely in the macro environment. The nodes implement operations on streams of 
appels, and appels are their only input and output. Ideally these opera- tions should be rather specific, 
and affect only a small number of appel slices. For example, typically, a node would perform a shading 
operation and therefore output only a colour. This is how the user can obtain max- imum reusability of 
the nodes. Figure 4 gives the diagram of such a shad- ing node. But this is only a guideline; the only 
rule is "appels in, appels out". As a consequence the nodes are guaranteed to have no side effect. The 
fact that each node and node writer does not have to know or care where the appel slices it needs come 
from means not only that nodes are easy to use, but can be used in ways that were totally unpredicted 
when they were written. colour i~l_]g~h!!~~_.colour eye normal Figure4. A simple case of aGRAPE shade 
node 4.1. Goforsand Servers To ensure proper communication with the other nodes, each node is surrounded 
by two functions, agofor to deal with its input and a serverto deal with its output. The gofors and servers 
standardize the nodes by forcing all the communications through them, and for the rest of the world (the 
macro environment) the nodes are only gofor and server functions (see Figure 5). slice slice slice slice 
slice slice slice slice (a) (b) Figure 5. A GRAPE node, as indicated functionally (a), and as it exists 
in the micro environment (b). Note that the actual node function has only one input and one output branch, 
regardless of the number of links in the graph. Every time a node needs an appel slice, it calls its 
gofor indicating the slice required, and the gofor calls the appropriate server. Note that which server 
is appropriate is only dependent on the particular graph in which the node is used, and therefore the 
linkage has to be made by the dag compiler at the macro level (more in the next section). The server 
has several roles. The simplest one is to pass the appel slices its client node produces to the gofor(s) 
to which it is connected. Its crucial role is to make sure that its client is only called when necessary. 
For that purpose it buffersthe appels produced by the node, supplies them to the gofors, and only actually 
calls its node when the buffer is empty. Most nodes need specific information which is not and should 
not be in the appels, such as constants, light position for a shade node, etc. This is provided through 
static parameters, and it is also the role of the server to provide these to its client node. For that 
purpose, the server calls an ini- tialization routine the first time it is called, to read in the static 
parameters. Those parameters can be read from a file, or computed by the initializa- tion routine. They 
are then stored by the server, and provided to the client node with each call. In our current implementation, 
each node is placed in its own UNIX subdirectory, which contains the source code, the header definition 
con- taining the code for the gofor and server, files for the static parameters, and files which list 
the input and output slices the node uses, for the benefit of the macro environmem (see Figure 6). (~ 
~ Computer Graphics, Volume 21, Number 4, July 1987 parameters  Figure 6. The directories corresponding 
to the shade node. Names of directories are in ellipses, names of files in rectangles. A node mold is 
provided as a template to help in writing nodes. Of course, the programmer does not write the gofors 
and servers, this is part of the role of the dag compiler. 5. The Macro Environment The role of the 
macro environment is to help the user put together the available nodes into display systems. The system 
to be built is described by its graph, that is, for each node in the graph, the user indi- cates the 
nodes to which it is to be connected, and the appel slices to be passed at each connection. The dag compiler 
then creates the gofors and servers for that graph and invokes the UNIX linker to link the code. Dur- 
ing execution, each gofor is called with the name of the slice which is required so it can call the appropriate 
server. This assumes that at compile time those servers exist, and therefore the compilation of the dag 
is done in a bottom-up fashion. A mechanism is included in the compiled dag to synchronize the flow of 
appels. For each node that initiates an output request, there is a dag driver function that calls the 
node server with an input request and generates a synchronization value which is then propagated down 
the dag by all servers, nodes and gofors. Each server can then determine whether it is necessary to call 
its client node. As mentioned before, each node is given a directory, and the corresponding gofor and 
server are stored in this directory. This was chosen to take advantage of the existing UNIX directory 
tools to list, navigate through and display graphically the directory structure. A node can output to 
more than one other node, which is why the graphs are dags, not trees. To allow this in the UNIX directory 
structure, symbolic links have to be used. Figure 7 shows a typical GRAPE graph. Each graph has one or 
more roots, that is nodes without any output, and one or more leaves, which generate the initial streams 
of appels. The usual root node is a WriteFile node, which simply writes the appels to a file. A slight 
variant of the WriteFile node is one which writes directly to a frame buffer. The typical leaf node is 
a ReadFile node, which does the obvious. Clearly these nodes can be connected to any appel producing 
or appel consuming process instead of files. In the UNIX environment, this is trivial thanks to the availability 
of pipes. In this manner entire external display systems can be virtual leaf nodes for a GRAPE graph, 
and in turn a GRAPE graph can provide appels to any external system, including other GRAPE graphs. Once 
a given GRAPE graph as been made, tested and found useful, it can be stored and subsequently used as 
a node for other systems. The only requirement is that it has one designated root, which will be given 
a server when it is used as a node. 6. Examples The goal of GRAPE is to limit as little as possible 
the variety of nodes and topology of the display systems that can be easily built. Conse- quently we 
can here present only a small sample of what can he done. We will limit ourselves to variations on familiar 
themes. ~te .~me ! ', ,, col~acity f°~pagrTtynd/~~~N, background // background ~ opacity ...-------&#38;g" 
¢olour x.~---.~ ( readfile ")foreground (" read tile ~'~ lille name file name I [ filename LParameters 
~~ ~~ parameters parameters filename filename Figure 7. A simple GRAPE graph and its corresponding directory 
structure. Symbolic links are indicated by dashed lines. 6.1. Node Examples 6.1.1. A Composite Node This 
example of a Composite node inputs two appel-streams in pixel format, the foreground and background images, 
and outputs a single pixel-format appel-stream, the composited image. This node is examined since it 
contains an assortment of process and control flows typically found in a number of other nodes, while 
the actual algorithm involved is rather simple. The composite node can perform a variety of composite-related 
Boolean operations as described in [PoDu84], but for simplicity, it is presented here with the standard 
foreground OVER background operation. In the following pseudo-code description, it should be noted that 
the con- stant and static parameter definitions are those that would appear in the ".h °' file, and the 
initializations would be done in the associated initializa- tion procedure. /* Composite description 
*/ [* constant definitions */ FOREGROUND_COLOUR FOREGROUND_OPACITY BACKGROUND_COLOUR BACKGROUND_OPACITY 
/* static parameters */ int operation: /* to indicate the compositing operation */ /* Initialization 
*/ OpenFile (parameters); s.GGRAP. 8, Anaheim Jo.y2731 ,987 ii nUll |lm nl GetParam (operation); /* 
The Basic Node procedure */ Composite: /* local variables *[ Colour foreCol, backCol; /* foreground and 
background colours "1 Opacity foreOp, backOp; /* foreground and background opacities*/ float foreWeight, 
backWeight; /* foreground and background weights */ l* get opacities *1 gofor (FOREGROUND_OPACITY, &#38;foreOp, 
sync); if (gofor (BACKGROUND_OPACITY, &#38;backOp, sync) == INACTIVE) backOp = 1.0; t* calculate colour 
factors */ switch (operation) { case OVER: /* basic composite operation */ foreWeight = foreOp; backWeight 
= backOp * ( l-foreOp); break: as described in [PoDu841} /* get colours only if needed */ if (foreWeight 
!= 0.0) gofor (FOREGROUND_COLOUR, &#38;foreCol, sync); if (backWeight != 0.0) gofor (BACKGROUND_COLOUR, 
&#38;backCol, sync); resuh->colour = foreWeight*foreCol + backWeight*backCol; end Composite. The above 
code illustrates a number of functions commonly found in other nodes. Note how the constant definitions 
of input branch alias are set up and used, how the parameters file is initially used to set the desired 
composite operation, and how the result is returned by a simple assign- ment. The composite node also 
illustrates a number of ways in which the input slices may be obtained. The most common is the way the 
fore- ground opacity is retrieved, by a straightforward gofor call. When the background opacity is requested, 
a check is made to see if the slice actu- ally exists in the input. If not, the gofor returns the value 
INACTIVE and a default value of 1.0 is set. In this way, the background opacity branch in the graph is 
optional. Finally, since the factors used to weight the colours upon a compo- site may be zero, the foreground 
and background colours are retrieved only if they are required. This is a way of incorporating lazy evaluation 
into a GRAPE graph, where sub-graphs are executed only when necessary. In this particular case, if the 
background weight is zero (when the fore- ground completely occludes it), the background colour is not 
requested. If the sub-graph linked to the corresponding branch is complex (possibly containing a number 
of texturing nodes, for example), then the run time savings could be quite substantial. It should be 
noted, however, that this assumes a forward random access to the input stream (as provided by the ReadFile 
node previously described). 6.1.2. The SpanToAppel Node The SpanToAppel node converts a span stream into 
a general appel stream. Each span is expanded into a stream of pixels that make up the span. The values 
of the span ends are linearly interpolated to derive the individual pixel values. Note that the resulting 
stream is indeed an appel stream and not a pixel stream since only those pixels contained within a span 
will be present in the stream. The SpanToAppel node is typical of nodes that control the input and output 
flow rate independently, It acts as a leaf node for the sub- graph above it, and as a root node for the 
sub-graph below it. This means that for every call it returns the next appel in the output stream, but 
it only requests appels from the input stream when required. The following is a pseudo-code version of 
the SpanToAppel node: /* SpanToAppel description *l /* static parameters */ Appel nextValue: /* The next 
call's output appel */ Appel increment; /* The pixel increment across the span */ int pixelsLefl; /+ 
Number of pixels left in the span */ int inputSync: /* The input stream sync value */ /* Initialization 
*/ pixelsLeft = - I ; /* To get the first span ~'/ sync = - 1 ; /* To start at the beginning of the stream 
*/ /* The Basic Node procedure */ SpanToAppel: /* local variables */ Appel spanLeft, spanRight; /* the 
span-end appels */ if (pixelsLeft < 0) [ /* get next span */ inputSync+÷; gofor (APPEL, &#38;spanLeft, 
inputSync); inputSync++; gofor (APPEL, &#38;spanRight, inputSync); [*reset static parameters */ nextValue 
= spanLeft: pixelsLefl = spanRight.screenPos.x - spanLeft.screenPos.x; increment = (spanRight - spanLeft) 
/pixelsLeft; } /* assign resultant output appel and setup for next call */ resultAppel = nextValue: nextValue 
+= increment: pixelsLeft--; end SpanToAppel. Note how the information is retained for one span at a time 
and a new span is retrieved only when required. The input synchronization value is always incremented 
immediately before each input appel request, which is the typical method used by nodes that control flow. 
6.2. Building Applications Designing and writing nodes is again very similar to designing and writing 
programs in an ordinary programming language (in fact any C programmer can do it). The power of GRAPE 
really comes from the ability to assemble the existing nodes in various dags of different functionality. 
As a straightforward example of the use of nodes within GRAPE graphs, consider a 'basic' compositing 
operation. In its simplest form it may be used to composite a foreground onto a background as expected. 
A minor variation of this graph can take advantage of the fact that each appel slice is provided as a 
separate input branch. Instead of taking the foreground opacity from the same node as the colour, it 
may be taken from a completely independent one (Figure 8). The result is a mask pro- vided by the opacity 
channel appl.ied to the foreground as before; however in this case they are totally unrelated. This technique 
(texture mapping under mask) is extensively used in flight simulators [RoZi84] Another example illustrates 
something that a user would probably not do in a different environment. The difference between Gouraud 
and Phong shading interpolation is well known. In GRAPE, to implement one rather than the other .consists 
merely of exchanging the order of the shad- ing and the span expansion node. One could muse about whether 
the same trick could be used for texture mapping. That is, the texture map- ping would be done before 
the scan conversion rather than after. Again, in GRAPE, to test this idea, one merely exchanges the order 
of some nodes. As shown in Figure 9, in one dag the order of the nodes is scan polygon, texture map and 
shade and in the other one, the same nodes are ordered as texture map, shade and scan polygon. The first 
order is the traditional order, while the second could be dubbed "Gouraud texture mapping". In the system 
used, this part of the graph took 8.5 minutes for the first sub- graph and about 0.5 minute for the second. 
So one can, at only the cost of a GRAPE graph compile, judge the look of pictures produced with the second 
approach, compare the costs and assess the worth of the technique. It is clear that while the second 
picture is not good enough for a final pic- ture, it might be sufficient for quick previews while still 
having an indica- tion of the effect of the textures. As a final example, the picture of Figure 10 was 
generated by several GRAPE dags implemented specifically for this purpose. The rock, walls and floors 
were rendered together. The rock is made of parametric surfaces which have been "bump-mapped". A special 
node created the floor by separating the tiles into three categories: pink marble, dark green marble 
(both solid textures a la Perlin) and nothing. The clouds and the shadow of the rock on the clouds were 
generated as another picture. Clouds are again a solid texture on a plane. The shadow was computed as 
a perspective view of the rock on the cloud plane, which was then defocused by a gaussian filter and 
composited with the clouds. The result was then composited with "the rest of the scene. All the nodes 
already existed in some form, except for the node to categorize the floor tiles and the node to blur, 
which were written for the occasion. Note that in this example we did not compile the whole GRAPE graph, 
but used several sub- graphs to better examine the intermediary results. ~ Computer Graphics, Volume 
21, Number 4, July 1987 7. Evaluation The actual implementation described is not an ideal one. Neverthe-less, 
it has been shown to be the powerful tool we expected, and it clearly illustrates that the concepts within 
GRAPE are sound and easily applied. We will review some of the problems with the implementation, and 
explore some further applications and extensions of GRAPE. 7.1. The Macro Environment Most of the drawbacks 
of the current implementation stem from the dependence on "~be UNIX directory structure. Since this structure 
cannot support the true multiple parent nodes required by the GRAPE dag struc- ture, symbolic links are 
used instead. This results in the macro users hav- ing the extra responsibility of differentiating true 
directories from sym- bolic links. Also, these symbolic links may be easily corrupted whenever the associated 
directory is moved. In fact, entire GRAPE dags are suscepti- ble to corruptions since the macro environment 
has no control over the UNIX utilities that may alter the dag format. This is only one aspect of the 
issue of the GRAPE user interface in general. So far there had been no serious attempt at providing the 
current implementation with a proper user interface, since its only purpose was to illustrate the principles 
behind GRAPE. The work of Haeberli [Haeb86], who built an excellent user interface to control the flow 
of processes, is a good pointer to the possibilities for an activity very similar to the design of GRAPE 
graphs. 7.2. The Micro Environment The current micro environment does not suffer from as serious problems 
as the macro environment, even though it is also UNIX depen-dent. The main reason is that both UNIX and 
the micro environment are meant to be programming environments. The only potential problem of the micro 
environment is that there is nothing to guard against users not obeying the standard format rules. However, 
it is assumed that micro users are competent enough programmers so that this problem is not significant. 
7.3. Making GRAPE More Efficient The main use of GRAPE is as a development environment. How-ever, GRAPE 
is equally useful for the design of specialized renderers. Such applications often require execution 
times to be minimized, since small time savings per pixel result in many hours of savings per frame or 
per second of animation. In addition, GRAPE may be used to develop more general rendering tools, such 
as compositors and image processors. In these cases, since the resulting appel-stream editors are used 
as utilities, it would also be desirable for them to be time and space efficient as well. Space can be 
wasted because each node allocates space for a com- plete output appel, even though it may only use a 
single slice. This may be cured by having the server only allocate memory for the individual out- put 
slices which are recorded in the output file in the master node library. There are basically two major 
causes of time inefficiency in GRAPE. The most obvious is the increased number of functions calls, and 
the other is due to unnecessary type conversions. For example in general the com- posite operations may 
be just as easily performed using colour in byte for- mat as opposed to the internal float format. As 
another example, a copy dag, which simply reads and copies GRAPE format file, uses about two minutes 
of CPU time (VAX 11/780) for a 512 by 512 pixel stream of colour slices recorded as three bytes. Most 
of this time is due to the type conversions from bytes to floats and back. It is easy to conceive of 
a simple optimizing compiler that would connect master node functions together directly, without the 
use of gofors and servers. In this case each node instance would be an almost identical copy of the master 
node. The resulting nodes would differ from the present nodes in a few minor ways. The function call 
would include an appel slice request, and the function would return the requested appel. Also, each gofor 
call could be replaced by a direct call to another master function. In addition, the optimizing compiler 
could hard-code all static parameter initializations not provided by the parameter server. In this way, 
the resulting program can be completely stand-alone. More comprehensive optimizing compilers, that reduce 
type conversions for example, would require more specific information about each particular case, and 
this would result in a more complicated set of rules for the micro environment. 7.4. Multiprocessing 
and parallel processing In its present format GRAPE is biased towards a sing]e processor sys- tem. However, 
the data flow approach used in GRAPE greatly facilitates both the prototyping and the implementation 
of distributed processing. In a parallel multi-processing environment, each processor may execute a particular 
sub-graph. However, care must be taken in making such assignments in order to even the load. In a pipeline 
multi-processing environment, each processor may execute a level or set of levels of the graph. This 
requires that appel streams be globally passed between levels much like in the pixel-stream-editor environment. 
Finally, in an array-processor environment individual appels from the stream may be pro- cessed in parallel 
on separate processors. The main point here is that GRAPE facilitates the exploration of the issues of 
multiprocessing and of the characteristics of different structures and differeut assignments to processors. 
All that is needed to determine the load distribution is to profile the GRAPE graphs once built, and 
to assign weights to the different nodes according to the processors to which they would be assigned. 
8. Conclusions The General Rendering Applications Programming Environment described here helps solve 
some of the problems associated with tradi- tional graphics systems, by providing a flexible environment 
that may be used by people with various degrees of expertise. It permits graphics pro- grammers to implement 
and test algorithms that may be easily and quickly integrated into existing systems. It also allows one 
to develop specialized rendering systems without new coding by piecing together a number of standard 
library operations, The lack of bias toward any particular rendering solution should let new ideas bloom, 
both good and bad. Quick and easy implementation will help us decide which are which. 9. Acknowledgements 
The authors benefited from much useful advice in Toronto from John Amanatides, Dave Blythe, Ed Chillack, 
Eugene Fiume, Ralph Hill and Colin Hui. John in particular contributed much code which formed the core 
of GRAPE nodes. This work was partially sponsored by Canada NSERC and by the CAE Ltd. Avi Naiman provided 
macros, critical review, and considerable help in the preparation of the camera-ready ver- sion of this 
paper. The first author thanks Thomson Digital Image in gen- eral, and Alain Nicolas and Herve Loizeau 
in particular, for help in pro- ducing the illustrations. Credits for the picture in Figure 10 go to 
Herve Loizeau and Alain Nicolas, in addition to the two of us. The second author also thanks the Imaging 
group at Xerox PARC for providing a very congenial environment while this paper was written and Hewlett 
Packard Co for the use of their typesetting facilities. And finally, we thank the Siggraph referees and 
the ad hoc committee led by Rick Beach for many suggestions which considerably improved the readability 
of this paper. I0. References AgArS2 Agerwala, T. and Arvind, "Data Flow Systems", Computer, Volume 15, 
Number 2, February 1982, pp. 10-13. BKGS86 Blythe, D., Kitamura, J., Galloway, D. and Snelgrove, M,, 
"Virtual Patch-Cords for the Katosizer", Proceedings of the 1986 International Computer Music Conference, 
October 1986, pp. 359-364. COCC87 Cook, R. L., Carpenter, L. and Catmuil, E., "'The Reyes Image Rendering 
Architecture", These Proceedings. Cook84 Cook, R. L., "Shade Trees," Computer Graphics. Volume 18, Number 
3, July 1984, pp. 223-231. Crow82 Crow, F. C., "'A More Flexible Image Generation Environ- ment," Computer 
Graphics. Volume 16, Number 3, July 1982, pp. 9-18. Duff80 Duff, T., The Soid and Roid Manual, NYIT Computer 
Graph- ics Laboratory internal memorandum, 1980. Duff85 Duff, T., "Compositing 3-D Rendered Images," 
Computer Graphics, Volume 19, Number 3, July 1985, pp. 41-44. Gour71 Gouraud, H., "Continuous Shading 
of Curved Surfaces," IEEE Transactions on Computers, Volume 20, Number 6, June 1971, pp. 623-629. Grlte86 
Greene, N. and Heckbert, P. S., "Creating Raster Omnimax Images from Multiple Perspective Views Using 
Elliptical Weighted Average Filter," IEEE Computer Graphics and Applications, Volume 6, Number 6, June 
1986, pp. 21-27.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37413</article_id>
		<sort_key>85</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[FRAMES: Software tools for modeling, rendering and animation of 3D scenes]]></title>
		<page_from>85</page_from>
		<page_to>94</page_to>
		<doi_number>10.1145/37401.37413</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37413</url>
		<abstract>
			<par><![CDATA[FRAMES is a set of flexible software tools, developed for the UNIX programming environment, that can be used to generate images and animation of 3D scenes. In FRAMES, each stage of the image-rendering pipeline is assigned to a UNIX System filter. The following is a typical FRAMES pipe sequence where each filter performs a task implied by its name:cat scene.frm|euclid|mover|shade|camera|abufFRAMES was designed to be easy to use, to permit flexible experimentation with new ideas in image rendering and geometric modeling, to allow distribution of different parts of the rendering pipeline to different processors, and to specify images in a common format for display on a variety of devices.The user communicates with FRAMES via a command language. This language is extended whenever a software developer needs to incorporate a new idea into the system by adding new commands. Data flowing through the pipeline is modified by a collection of filter programs and passed through the pipe in text or binary format.The modular and pipe-based nature of FRAMES allows for multi/parallel processor implementations and device independence. FRAMES has generated images on a local-area network of minicomputers (each filter runs on a different processor) and on a 64-processor hypercube machine (one filter runs on 64 processors). Applications of FRAMES have ranged from reconstruction of neurons from serial sections to rendering of antialiased octree objects with subpixel detail.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.2</cat_node>
				<descriptor>Distributed/network graphics</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Languages</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14194891</person_id>
				<author_profile_id><![CDATA[81100561593]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Potmesil]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Bell Laboratories, Murray Hill, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P78163</person_id>
				<author_profile_id><![CDATA[81538031556]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Eric]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Hoffert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Bell Laboratories, Murray Hill, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>15897</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bishop, G., and Weimer, D., "Fast Phong Shading," ACM Computer Graphics 20, 3 (August 1986), 103-106.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Blinn, J., "System Aspects of Computer Image Synthesis and Computer Animation," SIGGRAPtt 1984 Advanced Image Synthesis Course Notes (July 1984).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808585</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Carpenter, L., "The A-buffer, An Antialiased Hidden Surface Method," ACM Computer Graphics 18, 3 (July 1984), 103-108.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808602</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cook, R., "Shade Trees," ACM Computer Graphics 18, 3 (July 1984), 223-231.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801253</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Crow, F. C., "A More Flexible Image Generation Environment," ACM Computer Graphics 16, 3 (July 1982), 9-18.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[DeBenedictis, E., The Bell Labs Hypercube Machine, personal communication (April 1986).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808606</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Duff, T., and Porter, T., "Compositing Digital Images," ACM Computer Graphics 18, 3 (July 1984), 253-259.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325174</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Duff, T., "Compositing 3D Rendered Images," ACM Computer Graphics 19, 3 (July 1985), 41-44.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Hoffert, E. M., and Bishop, G., "Exact and Efficient Area Sampiing Techniques for Spatial Antialiasing," Technical Memorandum, AT&amp;T Bell Laboratories (December 1985).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Hoffert, E. M., and Potmesit, M., "Generation and Display of Self-Similar and Volume-Diminishing Cubes in 3D," accepted for presentation at Eurographies "87, Amsterdam, Holland (August 1987).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>577766</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kernighan, B., and Pike, R., The UNIX Programming Environment, Englewood Cliffs, N J: Prentice Hall, 1984.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357322</ref_obj_id>
				<ref_obj_pid>357318</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Pike, R., "Graphics in Overlapping Bitmap Layers, * ACM Transactions on Graphics 2, 2 (April 1983), 135-160.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Potmesii, M., "A Parallel Z-Buffer Implementation on a 64- Processor Hypercube Machine," Technical Memorandum, AT&amp;T Bell Laboratories, {in preparation}.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801293</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Reynolds, C. W., "Computer Animation with Scripts and Actors," ACM Computer Graphics 16, 3 (July 1982), 289-296.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>33905</ref_obj_id>
				<ref_obj_pid>33899</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Selfridge, P., "Using a Simple Shape Measftre to Improve Automatic 3D Reconstruction," Pattern Recognition Letters 5, 5 (May 1987).]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>894517</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Sequin, C., et. al., "More .. Creative Geometric Modeling," Technical Report UCB/CSD 86/278, Berkeley, University of California (December 1985).]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>894515</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Sequin, C., "The Berkeley UNIGRAFIX Tools, Version 2.5," Technical Report UCB/CSD 86/281, Berkeley, University of California (December 1985).]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357295</ref_obj_id>
				<ref_obj_pid>357290</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Whitted, T., and Weimer, D., "A Software Testbed for the Development of 3D Raster Graphics Systems," ACM Transactions on Graphics l, 1 (January 1982), 43-77.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Zimmer, C., "A Portable 5620 Terminal with a Hand Held Viewer," Technical Memorandum, AT&amp;T Bell Laboratories (October 1985).]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 G ~ Computer Graphics, Volume 21, Number 4, July 1987 FRAMES: Software Tools for Modeling, Rendering 
and Animation of 3D Scenes Michael Potmesil Eric M, Hoffert A T&#38; T Bell Laboratories Holmdel, NJ 
07733 ABSTRACT FRAMES is a set of flexible software tools, developed for the UNIX* programming environment, 
that can be used to generate images and animation of 3D scenes. In FRAMES, each stage of the image-rendering 
pipeline is assigned to a UNIX System filter. The following is a typical FRAMES pipe sequence where each 
filter performs a task implied by its name: eat scene.frm I euclid I ..... I ~hade I camera I abuf FRAMES 
was designed to be easy to use, to permit flexible experimen- tation with new ideas in image rendering 
and geometric modeling, to allow distribution of different parts of the rendering pipeline to different 
processors, and to specify images in a common format for display on a variety of devices. The user communicates 
with FRAMES via a command language. This language is extended whenever a software developer needs to 
incor-porate a new idea into the system by adding new commands. Data flowing through the pipeline is 
modified by a collection of filter pro- grams and passed through the pipe in text or binary format. The 
modular and pipe-based nature of FRAMES allows for multi/parallel processor implementations and device 
independence. FRAMES has generated images on a local-area network of minicom- puters (each filter runs 
on a different processor) and on a 64-processor hypercube machine (one filter runs on 64 processors). 
Applications of FRAMES have ranged from reconstruction of neurons from serial sec- tions to rendering 
of antialiased octree objects with subpixel detail. CR Categories and Subject Descriptors: 1.3.2 [Computer 
Graphiesh Graphics Systems--Distributed/network graphics; 1.3.3 [Computer Graphicsh Picture/Image Generation--Display 
algorithms--Viewing algorithms; 1.3.5 [Computer Graphiesh Computational Geometry and Object Modeling--Curve, 
surface, solid and object representations; 1.3.7 [Computer Grnphlesl: Three Dimensional Graphics and 
Realism--Animation--Visible line/surface algorithms. General Terms: algorithms, computer graphics systems. 
 Additional Key Words and Phrases: UNIX System; pipeline; filter; a- buffer; parallel image rendering. 
* Registered trademark of AT&#38;T. Permission to copy without fee aU or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the pubhcation and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. 1987 ACM-0-89791-227-6/87/007/0085 $00.75 I. Introduction FRAMES (Flexible Rendering, 
Animation and Modeling Experimenta- tion System) is a set of tools that can be used to model, render, 
and animate 3D objects in the UNIX programming environment. FRAMES was designed to fulfill the following 
major objectives: To be a tool for experimenting with the process of image rendering, i.e., to try out 
new shaders, visible-surface algo- rithms, or texturing techniques.  To function as a canned system, 
one that can be used in its current state by novice users to generate still images and anima- tion. 
 To manage growth in a controlled and flexible manner, so that programs written for any particular application 
become part of the system rather than be discarded.  To experiment with distribution of image rendering 
tasks over local-area networks and parallel processors.  To allow generation of images specified in 
a common format on diverse output devices, so that only a high-level filter needs to be written for each 
device.  FRAMES consists of a number of UNIX System filters linked together by a common interpreter 
which controls the flow of data through each filter. Flexibility arises from adding, removing, or modifying 
filters in the modeling, rendering, and animation pipeline. A user can specify input commands describing 
a 3D scene (Figure 1) and produce a high-quality image (Figure 2) by invoking a pipeline of basic FRAMES 
tools, as in: eat salt.frm I molecule I euclid I shade I camera I abuf where salt. frm is a text file 
containing all of the FRAMES com- mands relevant to making an image called salt. img. The filter molecule 
generates molecular models as sphere and cylinder object descriptions, euclid converts these descriptions 
into polygons, and shade computes surface illumination at vertices of the polygons. Filter camera transforms, 
clips, and projects these polygons into screen coordinates. Finally, abuf performs scan conversion, visible- 
surface determination, pixel shading and antialiasing. The computed image salt. img in Figure 2 shows 
a lattice structure of a simple cubic molecule--one half of a salt molecule. This example illustrates 
the basic capabilities of the system. 2. Raster Testbed Revisited In addition to the design goals for 
FRAMES mentioned above, it was desired to address many of the shortcomings found in the experimental 
image-rendering systems described in the literature. The following is a brief look at some of these 3D 
graphics systems and their features and drawbacks. Whitted and Weimer built a 3D raster testbed [18]. 
Their system was designed to allow for the rendering of different object types, such as bicubic surface 
patches, quadric surfaces, and polygon meshes by using a common data structure called a span buffer. 
However, the raster testbed contains too cumbersome a data structure for someone writing   (~) ~ Computer 
Graphics, Volume 21, Number 4, July 1987 4. FRAMES System Overview We wanted to mirror the pipeline processes, 
described above, in the UNIX System by assigning each stage of the graphical pipeline to a UNIX System 
filter. This filter is a program that reads some input, performs a transformation on it, and writes some 
output [ 11 ]. The use of filters and pipes in the UNIX System provides a powerful method for modeling 
pipeline processes in software. We wanted to exploit the flexibility inherent in the use of these filters 
and pipes, but in the context of 3D computer graphics. Each stage of the 3D model- ing and image rendering 
pipeline is a separate filter in FRAMES. The use of a pipeline of filters in conjunction with an interpretive 
mechanism common to every filter are the basic components of FRAMES. The command language interpreter 
selectively focuses on those parts of the data stream that each filter needs to do its process- ing. 
All other parts of the data stream are passed on to the next filter for processing in the pipeline sequence. 
The command language and pipeline structure are discussed briefly in the following sections. 4.1 Command 
Language Format Input to FRAMESconsists of *. frm files containing all commands relevant to executing 
a pipeline of filters. Commands as well as other messages are passed through a pipeline and interpreted 
by filters. There are three types of messages that can be seat through a pipeline: command messages, 
comment messages, and error messages. Com-mand messages are specified in either text (ascii) format or 
in binary format. In text format, a command name is prefixed with the '.' symbol and followed by a list 
of parameters. A binary command mes- sage is prefixed with the '%' symbol followed by an opcode, parameter 
size and parameters, all specified in the internal representation of the computer being used. Most error 
signals generated by the UNIX Sys- tem are detected by FRAMES and produce error messages in the FRAMES 
format. These error messages can be interpreted by other filters downstream in a pipeline. 4.2 Command 
Language Extensions FRAMESwas designed for maximum ease-of-use. A novice user can perform new tasks by 
arranging existing filters into pipelines; a sophis- ticated user can easily extend the command language 
and add func-tionality to the system by writing a new FRAMES filter. FRAMES is built on a library of 
C functions that handles all input/output data stream processing and on a list of graphical data types 
(command parameters) shared by all filters. To write a new FRAMES filter, a developer writes the C functions 
that perform the graphics processing; declares all the commands that will be read by the filter from 
the data stream and the commands that will be written by the filter to the data stream; and, if necessary, 
defines new commands that will be processed by the filter. Once written and compiled, the filter is linked 
with the FRAMES library, which services all requests for data stream input/output and formats the data 
for the current mode (binary or text). The complexity of a graphics task performed by a command ranges 
from flipping the sign of a normal vector to con-structing a detailed geometric model. 4.3 Pipeline 
Structure The execution time of a pipeline is always constrained by the slowest element in the pipeline. 
If one filter is significantly slower than any of the other ones, then either more effort should be devoted 
to optimizing the slow filter (for a single processor pipeline) or the filter should be broken down into 
a number of smaller filters (for a multi-processor pipeline). Ideally, the computational load should 
be distributed equally among all of the filters in a pipeline. In practice, however, this can be difficult 
to achieve. Pipes cost more to use than function calls. Timing profiles of typical FRAMES filters reveal 
that about one-third of the total CPU time can be spent performing text input/output of command messages. 
How-ever, the input/output overhead can be reduced to only one-tenth of the total CPU time by using binary 
input/output mode. Commands in binary format reduce the amount of data sent through a pipe and elim- 
inate the time required to encode and decode command parameters. When comparing only the time spent reading 
and writing command messages, binary mode is five times faster than text mode. We feet that the extra 
cost of using pipes is justified by the power gained from the filter and pipeline design. With pipes, 
the interface between filters can be loosely defined; with function calls, the interface between subroutines 
must be explicitly defined. Pipes are useful for debugging because they permit examination of the data 
stream at the interface between any two filters. In addition, filter pipelines can be reconfigured in 
more than one way to perform different tasks, whereas a large program cannot be reconfigured for a new 
task without being rewritten and recompiled. 4.4 Pipeline Constraints When reconfiguring filters to 
perform a new task, it is important to understand that certain filters are limited to the number of tasks 
they can perform. For example, some filters are capable of only one myopic function, while others can 
be used for a broad variety of applications; some filters can be used at a number of different points 
in the pipeline (i.e., triangulation can occur in object space, eye space, and screen space), while others 
can be used at only one point in the pipeline. Therefore, to utilize the FRAMES system, the user must 
understand the constraints on the capabilities of individual FRAMES filters. The pipelines described 
in this paper are all linear pipes, with the data flowing in only one direction. We hope to add a FRAMES 
shell to con- trol the execution of a pipeline and allow filter configurations other than linear pipes. 
This should include the capability to have a filter performing input/output on more than one data stream 
at a time. 5. FRAMES Software Tools The following sections illustrate the flexibility in image rendering 
afforded by the pipeline implementation of 3D graphics. These sec-tions are presented according to the 
stages of the image-rendering pipeline. The description of each filter inctudes both a general over-view 
and methods that exploit its flexibility.  5.1 Geometric Modeling [euc i id, ...] Geometric modeling 
in FRAMESis performed by two types of filters-- filters that generate 3D objects and filters that operate 
on the represen- tations of the objects. Examples of the object generators are filters that create Euclidean 
solids, parametric and implicitly defined sur-faces, and octree objects. Examples of object operators 
are filters that perform Boolean operations and global or local deformations of shape. FRAMES offers 
a number of object generators, such as euclid, patch, tube, and genoct. The euclid filter creates object 
descriptions of spheres, cylinders, hemi-spheres, hemi-cylinders, topless and bottomless cylinders, suporquadric 
ellipsoids, and objects of revolu- tion. The tube filter generates generalized cylinders by dragging 
a template 2D curve along a 3D space curve, such as Hermite or Bezier, defined in turn by the spline 
filter. The genoct filter generates octree objects, described by finite-state tables [10] and outputs 
leaf nodes (voxels) tessellated into polygonal faces. The patch filter generates a number of different 
types of bieubie patches. An image containing all of these objects can be generated by:  cat assorted.frm 
l euelidltube I genoctlpatehl... Figure 3 shows an image of a chair model generated by the tube and euclSd 
filters. FRAMES allows easy construction of hierarchical and high-level objects. These objects are created 
by stringing together a number of filters that sequentially decompose a high-level description of an 
object into its most primitive elements. A simple example is the use of the molecule filter, which takes 
as input high-level descriptions of molecular structures and outputs appropriate sphere and cylinder 
loca- tions, sizes, colors, and other model properties. The euclid filter   (~ ~ Computer Graphics, 
Volume 21, Number 4, July 1987 Geometric objects are placed into their absolute locations, orientations, 
and sizes in the object coordinate system by specifying the -obj option: cat hierarchy.frmleuclid I mover 
-obj flat.frm The filter can also place geometric objects into an eye coordinate sys- tem when the 
-eye option is specified: cat zztop.frm l e=elidlmover -eye I.-. l shade I-.. In this context, the filter 
can be used to prepare objects for shading with the view point at the origin of the eye space and the 
view vector in the z direction. 5.3 Shading [shadel Following the placement of all geometric entities 
into their absolute locations in the object or eye coordinate system, we are ready to per- form shading 
computations. The shade filter starts the user off with a few well-known shading models. A simple Lambertian 
reflection model (diffuse shader only) and Gouraud shading (diffuse and specu- lar). are included: cat 
shaded_picture.frm I mover l shade lcameral... We assume that each scan-conversion program can evaluate 
flat, Gouraud and Phong interpolations on a per-pixel basis. Shading is a complex issue in computer image 
synthesis. Typically, a user will want to have a variety of shading models to choose from, as well as 
a variety of options for the specification of light sources. The distribution of these shaders over the 
objects in a scene is not uniform. A scene may have a diffuse shader for most objects, a specular model 
for one object, a textured shader for another, and a Torrance-Sparrow model for yet another. FRAMES allows 
the user to attach easily different shaders to individual objects or groups of objects. The current shader 
specified in the input file is active until another is specified. As new shaders evolve, shade can be 
updated, replaced entirely, or augmented with a number of small specialized shading filters. 5.4 Cameras 
[cameral The camera filter performs geometric transformations, clipping, and projections of points, lines, 
and polygons from a 3D object or eye coor- dinate system into a 3D screen coordinate system. Also, other 
geometric data, such as surface-normal vectors and light source loca-tions and orientations, can be transformed 
by camera but not clipped or projected. Commands interpreted by camera can be divided into the following 
categories: Modeling transformations--specify translations, rotations, and scale factors applied to 
3D data in matrix M.  Viewing transformations--specify the location and orientation of camera in matrix 
V.  Projection transformations--specify projection type (perspective or orthographic) and projection 
parameters (locations of the six clipping planes) in matrix P.  Viewport--specify the size and location 
of a rectangular viewport in screen (image) coordinates.  Transformation control--specify control of 
a stack of transforma- tion matrices T -MVP.  ,, Viewport control--specify control of a stack of viewport 
parame- ters. Geometric data--define points, lines, polygons, their colors, surface-normal vectors and 
other attributes, and positions, orien- tations and colors of light sources. The clipping algorithm 
in the camera filter clips all points, lines, and polygons to the inside of a viewing pyramid and to 
the near (hither) and far (yon) clipping planes. Any data associated with a clipped line or edge, such 
as normal vectors, texture parameters or colors, are also properly clipped (interpolated). The filter 
maintains a stack of transformation matrices, T, and an independent stack of viewport parameters. Transposed 
inverse versions of transformation matrices are again used for the transformation of surface-normal vec- 
tors. This filter is normally used to transform, clip, and project geometric data into a screen viewport. 
The camera filter can also transform all geometric data to an eye coordinate system, in a manner similar 
to mover, using the -eye option. The major difference is that unlike mover -eye, cam- era -eye performs 
clipping. A second option -screen is then used to perform projection of the eye space coordinates to 
an image viewport in screen coordinates. A shading filter can be inserted between these two uses of camera 
to perform shading on clipped polygons in the eye coordinate system before they are distorted by pro- 
jection: ... I camera -eye I fphong I camera -screen I .., In this context, camera -eye outputs the 
x, y, z, w homogeneous coordinates of clipped points, lines, and polygons. Light sources are also transformed 
into this space, but they are not clipped. Next, fphong computes the coefficients of shading interpolation 
[1] from the eye space coordinates of polygons. Finally, camera -screen projects the eye space coordinates 
into the X, Y, Z screen space coordi- nates. The Z value represents the distance (depth) from the screen. 
 5.5 Visible Surfaces, Scan Conversion, and Antialiasing [abuf, zbuf, ...I The final steps in the image-rendering 
pipeline are scan conversion, determination of visibility, pixel shading, and antialiasing. We have implemented 
an a-buffer filter, abuf, which performs all these steps. The original a-buffer [3], as well as many 
other visible-surface algo- rithms, is scan-line order based. We felt that scan-line order was not necessary 
for the a-buffer. This requirement adds an extra sorting step to the image-rendering pipeline (use of 
the a-buffer already includes sorting in depth) and, therefore, more complexity. In addition, pro- cess 
sizes are getting larger under the UNIX System and memory prices continue to drop, making scan-line algorithms 
less of a require- ment. Instead, FRAMES uses a fully active image-sized a-buffer, rasterizing on-the-fly 
and writing into any part of the screen image at any time. When abuf runs out of fragment memory, it 
has to com- pact all fragment lists into pixels and release the fragments' memory for future reuse. Because 
we maintain a full image-sized a-buffer, tri- angles can be sent to abuf in arbitrary order without any 
prior sort- ing. Antialiasing is accomplished with an exact-area box filter [9]. The approach using a 
fully active image-sized a-buffer simplifies the pipeline and allows for a novel type of 3D digital compositing. 
Objects or parts of scenes can he computed as separate a-buffer images. Each image has its a-buffer data 
written as a binary file. When the ele- ments are composited, each input a-buffer binary file is read 
in, and the individual a-buffers are merged. The complete image is the result of compacting the merged 
a-buffers. A-buffers contain pixels that are empty (contain no object), full (z and rgb, as in a z-buffer), 
or partial (fragment list with detailed suhpixel data). A data compression for- mat, similar to run-length 
encoding, was developed for a-buffers to decrease disk storage and input/output time. It is often desirable 
to use different hidden-surface techniques for different purposes when producing an image. For example, 
if one needs high-quality images for film recording or slides, an a-buffer would be most appropriate. 
A scene is processed using the a-buffer as: eat pretty_pieture.frm I ... I camera I abuf However, at 
times, only a quick look at a dirty (jagged) image may be necessary. In this context, a z-buffer without 
antialiasing would be more appropriate. FRAMES supplies a simple z-buffer algorithm, zbuf, as well: cat 
ugly_picture.frm I ... I camera I zbuf A promising approach to the problem of scan conversion, which 
we consider to be the bottleneck of the rendering processes, is the use of I~,~1 SIGGRAPH '87, Anaheim, 
July 27-31, 1987 parallel processing. We have been experimenting with a parallel z-buffer algorithm [13] 
implemented on a 64-processor (node) hypercube machine [6]. The parallel z-buffer filter, pzbaf, is used 
similarly to the other visible-surface filters: cat tabby, frm I ... Icamera I pzbuf The nodes of the 
hypercube machine are assigned to image pixels in an interleaved pattern. Typically, a node will process 
every eighth pixel in every eighth scan line. Scan conversion, z depth, and pixel shading are performed 
by incrementally evaluating an expression in the form ax + by + c for each edge, depth, and color of 
a triangle. Preliminary results indicate that this algorithm is 10 to 20 times faster than zbuf running 
on a super minicomputer. Currently, we are planning the addition of a parallel a-buffer algorithm, pabuf, 
which will evolve from pzbuf and probably use the antialiasing bit-mask technique described in [9]. Our 
experience with the a-buffer leads us to conclude that it is only a temporary solution to the long-standing 
problem of visible-surface determination. Although it is capable of good to excellent quality images, 
it is, unfortunately, difficult to implement, inefficient, and prone to errors. Therefore, when the next 
generation hidden-surface technique is perfected, the use of newbuf is recommended. A user unenchanted 
with buffer-type, visible-surface algorithms could always implement something different and use it at 
the end of the pipeline. We have also found that abuf is a bottleneck in the rendering pipe- line. Therefore, 
our next step is to look at ways to break up abuf into two or three smaller filters that can be distributed 
over a network of computers. We are considering a filter that performs scan conver- sion and fragment 
generation, a filter that creates and maintains frag- ment lists for an a-buffer image array, and a filter 
that, given a frag-ment list, computes a pixel color. We would also like to add a ray-tracing filter 
to FRAMES that can be used in place of all the image-rendering filters to process objects directly from 
geometric modeling filters. A typical pipeline sequence might be: cat tango.frm [ patch [ euclid [ poly 
[ ... ] rays 5.6 Back-Face Removal [noba ck] The most popular method of back-face removal is culling 
those polygons that have either back facing polygon-normal vectors or all back facing vertex-normal vectors. 
We developed a filter, called noback, that removes back faces of opaque solid objects and leaves back 
faces of transparent objects untouched. Optionally, the filter can also remove all transparent faces 
and front-facing faces. We felt that back-face removal was not something that should be hard-wired into 
FRAMES, again, for the sake of flexibility. For example, an object clipped by a hither clipping plane 
may show some of its back-facing polygons while only its front-facing faces are visible before hither 
clip- ping. If back-face removal is active, the back faces will not be ren-dered and the object will 
appear incorrect. For this case, back-face removal is counter-productive. To sum up, if back-face removal 
is desired, we recommend the use of noback when polygons are in the eye coordinate system: cat food.frm 
I .--I mover -eye I noback I -.. I zbuf Back-face removal can also be performed on a per-object basis. 
This is done by turning the back-face removal command on and off for selected objects in an input file. 
Back-face removal is an example of a graphics function that can be controlled on an individual basis 
in the data stream or globally over the data stream by just invoking the filter. 5.7 Diversity of Devices 
{irview, plotviewl Our graphical-device environment is typical of that found in many graphics laboratories. 
We have a number of devices, each with its own unique commands to draw lines and curves, write and read 
pixels, etc. There is no commonality between any two devices. In addition, some devices perform part 
of the image-rendering pipeline, such as geometric transformations in hardware, while others do not; 
some dev- ices are raster-based and some are vector-based. Given these facts, we wanted a system capable 
of specifying pictures using only one description method and displaying them on all of the available 
devices without having to exert much programming effort. By modularizing the graphical process, it becomes 
trivial to use different devices in this manner. To deal with device independence for batch-type image 
creation, the last stage of the rendering pipeline (abuf or other) writes a device independent rgb image 
file (run-length encoded or dumped). For dev- ices of a more interactive or (closer to) real-time nature 
(typically for our purposes, the former are frame buffers and the latter are vector displays), FRAMES 
is structured so that the last stage of the pipeline is a filter that outputs rendering/drawing commands 
unique to that dev- ice. The following are two examples of using FRAMES to obtain out- put on our display 
devices. The Silicon Graphics IRIS terminal performs 3D geometric transfor- mations, clipping, and perspective 
projection in hardware. We can exploit this hardware feature by piping 3D objects, generated by FRAMES, 
into an IRIS system without using the FRAMES filters camera and mover. This is possible because all camera 
and mover operations can be performed by the IRIS hardware, thereby saving host CPU time. We also do 
not need to use shade, abuf, and other filters since we are only generating vector-drawings, as in: cat 
ehair.frm I chair maker I ..- I irview -2D where chair, frm is an input file for a chair picture, chair 
maker generates 3D models of designer chairs and 5.rview with the -2D option draws a wire-frame image. 
If the option -3D is invoked, irview loads the 3D scene into a display list. The 3D model can then be 
previewed interactively on the screen. The AT&#38;T Teletype* 5620 terminal, formerly known as the blit 
ter-minal, has bit-mapped graphics with the bitblt operations [ 12] in mul- tiple overlapping windows. 
This terminal is a good candidate to pre- view scenes for animation or to design models of objects, especially 
if an IRIS system is not readily available and particularly if not remotely near a civilizationt [19]. 
Unlike the IRIS system, there is no hardware performing transformations, clipping, and projections in 
the Teletype 5620 terminal. Hence, the camera filter must be used here. An advantage of FRAMES is its 
ability to easily convert geometric data from one representation to another by filtering it. This advantage 
has been exploited to interface FRAMES to the standard UNIX Sys-tem plot utilities. A filter called plotview 
converts FRAMES commands to the UNIX System plot language. By piping the out- put of plotview into any 
one of the UNIX System plot filters, one can view FRAMES pictures on a variety of devices. For example, 
the following sequence outputs bieubic patches in wire-frame represen- tation to the Teletype 5620 terminal: 
cat blit.frm I patch I camera I plotview [ t5620 where t 5620 takes plot language as input and displays 
the input data as lines on the Teletype 5620 terminal in the window from which the command was executed. 
Figure 6 illustrates the use of plot-view in a multi-window environment. It is also possible to output 
to hard-copy printers with the plot tools. For example, the following sequence will output some 2D splines 
using the FRAMES spline filter: eat imagen.frm [ spline -i [ plotview [ plot -printer where -printer 
selects a laser printer for output. The interface to plot is useful for hard-copy output and fast terminal 
previewing of 2D and 3D objects. * Registered trademark of AT&#38;T. "{" Recent work has yielded a portable 
Teletype 5620 terminal with a hand-held viewer--SD graphics work in Death Valley, CA is now not far off. 
 ~ Computer Graphics, Volume 21, Number 4, July 1987 I III IIIIIIIIIIIIII dmi~y) cat hicubi¢.fri I pitch 
l] I camera I plotvi~ I t~L'e !Z~t3 lad IM 8=~ --bin/csh -i [~1 Z83Z2 tad I 4=1Z 2~'S1~1 pcl I 8:~] -Ibin/c~h 
(csh) ZEFd~3 pd I 0:~ (itroff) ZBBTZ pd S 8:e~ (~at) Z83174 pd S O:lBl (pie}28375 pJ S e:SZ tL~n) 283"?8 
pJ R t:43 (toot'f) Z~79 q~ IN O:~ "-birll'csh li (~) daisy> Iq dais)'> cat axe~_and_cube.frm I emera 
I plotvi~ I tsraze dais~v) ell rield.frm I petch I PQr~pine I ci I plotvi~ I t5620 Figure 6 Previewing 
3D objects on diverse devices. This figure shows three windows of a Teletype 5620 terminal. Each window 
shows a FRAMES pipeline and the picture it generated. The top window shows a bicubic patch generated 
by patch (option -1 outputs lines, default is to output triangles), the middle window shows an object 
con- tained entirely in the input file axes and cube. frm, and the bottom window shows the usage of the 
poz-eupine filter which displays normal vectors to illustrate surface curvature. 6. Distributed Rendering 
The distribution of graphical and modeling tasks among multiple filters allows for flexibility in multiprocessing. 
A primary objective of modu- larity was to study the computing requirements of each rendering module 
and, subsequently, to tailor specialized hardware to each module. For example, the camera and mover filters 
should be supported by an array or digital-signal processor and the renderers, abuf and zbuf, would be 
optimized by distributing their tasks on a parallel processor. By using FRAMES extensively and analyzing 
how and where CPU time is spent in each filter, we hope to improve our understanding of the best method 
for distributing FRAMES Over various classes of hardware. We have experienced significant speed improvements 
when using FRAMES with the Remote File System (RFS)--a public-domain tran- sparent file-sharing system, 
analogous to the Sun Mierosystems' Net- work File System--running on an Ethernet* local-area network 
of VAX% minicomputers. By running each stage of the FRAMES pipeline on a different VAX machine and piping 
from one VAX to another, we obtain the benefits of distributed processing without special hardware. Distributing 
the filters in a pipeline over (comparable) machines in a network decreases the real time elapsed for 
pipeline execution, while the CPU time consumed by all filters in the pipeline remains constant. Each 
filter is run on a separate machine by invoking the remote shell command (rsh) for each filter. The following 
is a typical example of each filter running on a distinct VAX computer called daisy, dixie, and pixie: 
 cat morris.frml /daisy/tube -bl... .. I /dixie/camera -b [/pixie/abuf  To run the parallel z-buffer 
on a hypercube machine attached to a Sun Workstations named cube, with all other filters again on VAX 
com-puters, we enter: cat morris.frml /daisy/tube -b I -.. ... I/dixie/camera -a I /eube/pzbuf Note 
that the pipe between the last VAX (dixie) and the Sun (cube) must be done in text (ascii) format, by 
specifying the -a option, rather than in binary format because the two systems have incompatible internal 
integer and floating-point representations. 7. Further Examples FRAMESwas tested on a few guinea-pig 
projects. The first application was the reconstruction of neurons from serial sections [15]. Figure 7 
shows an image of four serial cross sections of neurons in the crusta- cean Daphnia. This image was generated 
by converting each original section image into an array of 3D polygons (squares) with rdimg". Figure 
8 shows two 3D neurons (the front neuron branches), modeled by polygons, reconstructed from 22 such serial 
sections. FRAMESwas used to display 3D fractal volumes modeled by octrees [10]. Figure 9 shows two images 
of the Mengcr sponge, which has a sponge property that its volume approaches zero, while its surface 
area approaches infinity as the number of recursion levels increases. Each sponge object in Figure 9 
has three levels of recursion. The sponge in Figure 9(b) was generated by inverting the octree representation 
of the sponge in Figure 9(a). We have also been using FRAMES as a testbed for simulating image- rendering 
algorithms on various parallel computer architectures. Fig-ure 10 shows a bicubic patch rendered with 
depth-cued aliased and antialiased lines. This image was generated by filter de, which per- forms depth-cueing 
of lines, and filter psim, which simulates an mxn array of rendering processors where each processor 
accesses only every ruth pixel on every nth scan line. We have also been experiment- ing with various 
texturing techniques. In Figure 11, the walls and columns are solid-textured (clouds and marble, respectively) 
and the gallery picture is a summed-area table texture map. 8. Conclusions and Summary We have described 
a flexible system for 3D modeling and image syn- thesis. The system is made of relatively small and simple 
UNIX Sys- tem filter programs that ean be flexibly configured into pipes to per- form more complex tasks. 
We feel that we have developed the basic image-rendering tools and now need to start developing front-end 
geometric modeling and anima- tion tools with higher-level commands and constructs. Analogous to the 
UNIX typesetting tools, we have developed the equivalents of troff, tbl, and eqn and now should continue 
by developing the equivalents of pic and grap. The notions of both loose coupling and combining a number 
of small not-so-powerful programs to form a more powerful whole allow usage of a system in ways not intended 
a priori. They also permit gradual evolution of the system as image-rendering techniques advance. * Trademark 
of Xerox Corp. ~" Trademark of Digital Equipment Corp. * Registered trademark of Sun Microsystems, Inc. 
    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37414</article_id>
		<sort_key>95</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[The Reyes image rendering architecture]]></title>
		<page_from>95</page_from>
		<page_to>102</page_to>
		<doi_number>10.1145/37401.37414</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37414</url>
		<abstract>
			<par><![CDATA[An architecture is presented for fast high-quality rendering of complex images. All objects are reduced to common world-space geometric entities called micropolygons, and all of the shading and visibility calculations operate on these micropolygons. Each type of calculation is performed in a coordinate system that is natural for that type of calculation. Micropolygons are created and textured in the local coordinate sysem of the object, with the result that texture filtering is simplified and improved. Visibility is calculated in screen space using stochastic point sampling with a z buffer. There are no clipping or inverse perspective calculations. Geometric and texture locality are exploited to minimize paging and to support models that contain arbitrarily many primitives.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP35024317</person_id>
				<author_profile_id><![CDATA[81100111623]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Cook]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pixar, San Rafael, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31024422</person_id>
				<author_profile_id><![CDATA[81100040066]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Loren]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Carpenter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pixar, San Rafael, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P75663</person_id>
				<author_profile_id><![CDATA[81100160637]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Edwin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Catmull]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pixar, San Rafael, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>801135</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[ATHERTON, PETER R., "A Scanline Hidden Surface Removal Procedure for Constructive Solid Geometry," Computer Graphics (SIGGRAPH '83 Proceedings) 17(3), pp. 73-82 (July 1983).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[BARR, ALAN H., "Decal Projections," in S1GGRAPH '84 Developments in Ray Tracing course notes (July 1984).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360353</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[BLINN, JAMES F. AND MARTIN E. NEWELL, "Texture and Reflection in Computer Generated Images," Communications of the ACM 19(10), pp. 542-547 (October 1976).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[BLINN, JAMES F., "Simulation of Wrinkled Surfaces," Computer Graphics (SIGGRAPH '78 Proceedings) 12(3), pp. 286-292 (August 1978).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357310</ref_obj_id>
				<ref_obj_pid>357306</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[BLINN, JAMES F., "A Generalization of Algebraic Surface Drawing," ACM Transactions on Graphics 1(3), pp. 235- 256 (July 1982).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[BRACEWELL, RONALD N., The Fourier Transform and Its Applications, McGraw-Hill, New York (1978).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807478</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[CARPENTER, LOREN, "Computer Rendering of Fractal Curves and Surfaces," Computer Graphics (SIGGRAPH '80 Proceedings) 14(3), pp. 9-15, Special Issue (July 1980).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>907242</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[CATMULL, EDWIN E., "A Subdivision Algorithm for Computer Display of Curved Surfaces," Phd dissertation, University of Utah, Salt Lake City (December 1974).]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807440</ref_obj_id>
				<ref_obj_pid>965103</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[CLARK, JAMES H., "A Fast Algorithm for Rendering Parametric Surfaces," Computer Graphics (SIGGRAPH '79 Proceedings) 13(2), pp. 7-12, Special Issue (August 1979).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[COOK, ROBERT L., THOMAS PORTER, AND LOREN CAR- PENTER, "Distributed Ray Tracing," Computer Graphics (SIGGRAPH "84 Proceedings) 18(3), pp. 137-145 (July 1984).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808602</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[COOK, ROBERT L., "Shade Trees," Computer Graphics (SIGGRAPH '84 Proceedings) 18(3), pp. 223-231 (July 1984).]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[COOK, ROBERT L., "Stochastic Sampling in Computer Graphics," ACM Transactions on Graphics 5(1), pp. 51- 72 (January 1986).]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[COOK, ROBERT L., "Practical Aspects of Distributed Ray Tracing," in SIGGRAPH "86 Developments in Ray Tracing course notes (August 1986).]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808600</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[CROW, FRANKLIN C., "Summed-Area Tables for Texture Mapping," Computer Graphics (SIGGRAPH "84 Proceedings) 18(3), pp. 207-212 (July 1984).]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325174</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[DUFF, TOM, "Compositing 3-D Rendered Images," Computer Graphics (SIGGRAPH '85 Proceedings) 19(3), pp. 41-44 (July 1985).]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>578513</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[FAUX, I. D. AND M. J. PRATT, Computational Geometry for Design and Manufacture, Ellis Horwood Ltd., Chichester, England (1979).]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807507</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[FEIBUSH, ELIOT, MARC LEVOY, AND ROBERT L. COOK, "Synthetic Texturing Using Digital Filtering," Computer Graphics 14(3), pp. 294-301 (July 1980).]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358553</ref_obj_id>
				<ref_obj_pid>358523</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[FOURNIER, ALAIN, DON FUSSELL, AND LOREN CAR- PENTER, "Computer Rendering of Stochastic Models," Communications of the ACM 25(6), pp. 371-384 (June 1982).]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13027</ref_obj_id>
				<ref_obj_pid>13021</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[HECKBERT, PAUL S., "Survey of Texture Mapping," IEEE Computer Graphics and Applications (November 1986).]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[KAPLAN, MICHAEL R., "Space-Tracing, A Constant Time Ray-Tracer," in SIGGRAPH '85 State of the Art in Image Synthesis seminar notes (July 1985).]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15916</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[KAY, TIMOTHY L. AND JAMES T. KAIIYA, "Ray Tracing Complex Scenes," Computer Graphics (SIGGRAPH '86 Proceedings) 20(4), pp. 269-278 (Aug. 1986).]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358815</ref_obj_id>
				<ref_obj_pid>358808</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[LANE, JEFFREY M., LOREN C. CARPENTER, TURNER WHIFFED, AND JAMES F. BLINN, "Scan Line Methods for Displaying Parametrically Defined Surfaces," Communications of the ACM 23(1), pp. 23-34 (January 1980).]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808581</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[LEVINTHAL, ADAM AND THOMAS PORTER, "Chap - A SIMD Graphics Processor," Computer Graphics (SIG- GRAPH "84 Proceedings) 18(3), pp. 77-82 (July 1984).]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[NEWMAN, WILLIAM M. AND ROBERT F. SPROULL, Principles of Interactive Computer Graphics (2nd ed.), McGraw-Hill, New York (1979). pp. 361-363]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[PARAMOUNT PICTURES CORPORATION, Young Sherlock Holmes, Stained glass man sequence by Pixar and Lucasfilm Ltd. 1985.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[PEARSON, D. E., Transmission and Display of Pictorial Information, Penteeh Press, London (1975).]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[PIXAR, The Adventures of AndrE and WaUy B., July 1984.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[PIXAR, Luxo Jr., July 1986.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[PIXAR, Red' s Dream, July 1987.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357320</ref_obj_id>
				<ref_obj_pid>357318</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[REEVES, WILLIAM T., "Particle Systems - A Technique for Modeling a Class of Fuzzy Objects," ACM Transactions on Graphics 2(2), pp. 91-108 (April 1983).]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325250</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[REEVES, WILLIAM T. AND RICKI BLAU, "Approximate and Pmbabilistic Algorithms for Shading and Rendering Structured Particle Systems," Computer Graphics (S1G- GRAPH "85 Proceedings) 19(3), pp. 313-322 (July 1985).]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[REEVES, WILLIAM T., DAVID H. SALESIN, AND ROBERT L. COOK, "Shadowing with Texture Maps," Computer Graphics (SIGGRAPH '87 Proceedings) 21 (July 1987).]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[ROTH, S. D., "Ray Casting for Modeling Solids," Computer Graphics and Image Processing(18), pp. 109-144 (1982).]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807479</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[RUBIN, STEVEN M. AND TURNER WHITTED, "A 3- Dimensional Representation for Fast Rendering of Complex Scenes," Computer Graphics (SIGGRAPH '80 Proceedings) 14(3), pp. 110-116 (July 1980).]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808571</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[SMITH, ALVY RAY, "Plants, Fractals, and Formal Languages," Computer Graphics (SIGGRAPH '84 Proceedings) 18(3), pp. 1-10 (July 1984).]]></ref_text>
				<ref_id>35</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801126</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[WILLIAMS, LANCE, "Pyramidal Parametrics," Computer Graphics (SIGGRAPH "83 Proceedings) 17(3), pp. 1-11 (July 1983).]]></ref_text>
				<ref_id>36</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~ ~' Computer Graphics, Volume 21, Number 4, July 1987 The Reyes Image Rendering Architecture Robert 
L. Cook Loren Carpenter Edwin Catmull Pixar P. O. Box 13719 San Rafael, CA 94913 An architecture is 
presented for fast high-quality rendering of complex images. All objects are reduced to common world-space 
geometric entities called micropolygons, and all of the shading and visibility calculations operate on 
these micropo- lygons. Each type of calculation is performed in a coordinate system that is natural for 
that type of calculation. Micropo-lygons are created and textured in the local coordinate system of the 
object, with the result that texture filtering is simplified and improved. Visibility is calculated in 
screen space using stochas- tic point sampling with a z buffer. There are no clipping or inverse perspective 
calculations. Geometric and texture locality are exploited to minimize paging and to support models that 
contain arbitrarily many primitives. CR CATEGORIES AND SUBJECT DESCRIPTORS: 1.3.7 [Computer Graphics]: 
Three-Dimensional Graphics and Realism; ADDITIONAL KEY WORDS AND PHRASES: image render- ing, computer 
image synthesis, texturing, hidden surface algorithms, z buffer, stochastic sampling 1. Introduction 
 Reyes is an image rendering system developed at Lucasfilm Ltd. and currently in use at Pixar. In designing 
Reyes, our goal was an architecture optimized for fast high-quality rendering of com- plex animated scenes. 
By fast we mean being able to compute a feature-length film in approximately a year; high-quality means 
virtually indistinguishable from live action motion picture pho- tography; and complex means as visually 
rich as real scenes. This goal was intended to be ambitious enough to force us to completely rethink 
the entire rendering process. We actively looked for new approaches to image synthesis and consciously 
tried to avoid limiting ourselves to thinking in terms of tradi- tional solutions or particular computing 
environments. In the process, we combined some old methods with some new ideas. Some of the algorithms 
that were developed for the Reyes archi- tecture have already been discussed elsewhere; these include 
sto- chastic sampling [12], distributed ray tracing [10, 13], shade trees [11], and an antialiased depth 
map shadow algorithm [32]. Permission to copy without fee all or part of this material is granted provided 
that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice 
and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. 1987 ACM-0-89791-227-6/87/007/0095 $00.75 This paper includes short descriptions 
of these algorithms as necessary, but the emphasis in this paper is on the overall archi- tecture. Many 
of our design decisions are based on some specific assumptions about the types of complex scenes that 
we want to render and what makes those scenes complex. Since this archi- tecture is optimized for these 
types of scenes, we begin by exa- mining our assumptions and goals. Model complexity. We are interested 
in making images that are visually rich, far more complex than any pictures rendered to date. This goal 
comes from noticing that even the most complex rendered images look simple when com- pared to real scenes 
and that most of the complexity in real scenes comes from rich shapes and textures. We expect that reaching 
this level of richness will require scenes with hundreds of thousands of geometric primitives, each one 
of which can be complex.  Model diversity. We want to support a large variety of geometric primitives, 
especially data amplification primi- tives such as procedural models, fractals [18], graftals [35], and 
particle systems [30, 31].  Shading complexity. Because surface reflection charac- teristics are extremely 
varied and complex, we consider a programmable shader a necessity. Our experience with such a shader 
[tl] is that realistic surfaces frequently require complex shading and a large number of textures. Textures 
can store many different types of data, including surface color [8], reflections (environment maps) [3], 
nor- mal perturbation (bump maps) [4], geometry perturbation (displacement maps) [111, shadows [32], 
and refraction [25].  Minimal ray tracing. Many non-local lighting effects can be approximated with 
texture maps. Few objects in natural scenes would seem to require ray tracing. Accordingly, we consider 
it more important to optimize the architecture for complex geometries and large models than for the non-local 
lighting effects accounted for by ray tracing or radios- ity.  Speed. We are interested in making animated 
images, and animation introduces severe demands on rendering speed. Assuming 24 frames per second, rendering 
a 2 hour movie in a year would require a rendering speed of about 3 minutes per frame. Achieving this 
speed is especially chal- lenging for complex images.  Image Quality. We eschew aliasing and faceting 
artifacts, such as jagged edges, Moir6 patterns in textures, temporal strobing, and highlight aliasing. 
 Flexibility. Many new image rendering techniques will undoubtedly be discovered in the coming years. 
The archi- tecture should be flexible enough to incorporate many of these new techniques.   ~ SIGGRAPH 
'87, Anaheim, July 27-31, 1987 2. Design Principles These assumptions led us to a set of architectural 
design princi- ples. Some of these principles are illustrated in the overview in Figure 1. 1. Natural 
coordinates. Each calculation should be done in a coordinate system that is natural for that calculation. 
For example, texturing is most naturally done in the coordinate system of the local surface geometry 
(e.g., uv space for patches), while the visible surface calculations are most naturally done in pixel 
coordinates (screen space). 2. Vectorization. The architecture should be able to exploit vectorization, 
parallelism and pipelining. Calculations that are similar should be done together. For example, since 
the shading calculations are usually similar at all points on a surface, an entire surface should be 
shaded at the same time. 3. Common representation. Most of the algorithm should work with a single type 
of basic geometric object. We turn every geometric primitive into micropolygons, which are flat-shaded 
subpixel-sized quadrilaterals. All of the shad- ing and visibility calculations are performed exclusively 
on micropolygons. 4. Locality. Paging and data thrashing should be minimized. a. Geometric locality. 
Calculations for a geometric primitive should be performed without reference to other geometric primitives. 
Procedural models should be computed only once and should not be kept in their expanded form any longer 
than necessary. b. Texture locality. Only the textures currently needed should be in memory, and textures 
should be read off the disk only once.  5. Linearity. The rendering time should grow linearly with 
the size of the model. 6. Large models. There should be no limit to the number of geometric primitives 
in a model. 7. Back door. There should be a back door in the architec- ture so that other programs can 
be used to render some of the objects. This give us a very general way to incorporate any new technique 
(though not necessarily efficiently). 8. Texture maps. Texture map access should be efficient, as we 
expect to use several textures on every surface. Tex-tures are a powerful tool for defining complex shading 
characteristics, and displacement maps [11] can be used for model complexity.  We now discuss some of 
these principles in detail. 2.1. Geometric Locality. When ray tracing arbitrary surfaces that reflect 
or refract, a ray in any pixel on the screen might generate a secondary ray to any object in the model. 
The object hit by the secondary ray can be determined quickly [20,21,34], but that object must then be 
accessed from the database. As models become more complex, the ability to access any part of the model 
at any time becomes more expensive; model and texture paging can dominate the rendering time. For this 
reason, we consider ray tracing algo- rithms poorly suited for rendering extremely complex environ- ments. 
In many instances, though, texture maps can be used to approxi- mate non-local calculations. A common 
example of this is the use of environment maps [3] for reflection, a good approxima- tion in many cases. 
Textures have also been used for refractions [25] and shadows [32, 36]. Each of these uses of texture 
maps represents some non-local calculations that we can avoid (princi- ples 4a and g). MODEL read model 
 bound N on screen?-~ cull split 4-- diceable? dice TEXTURES --~ shade sample BACK DOOR --~ visib~ility 
filter  PICTURE Figure 1. Overview of the algorithm. 2.2. Point sampling. Point sampling algorithms 
have many advantages; they are sim- ple, powerful, and work easily with many different types of primitives. 
But unfortunately, they have been plagued by atias- ing artifacts that would make them incompatible with 
our image quality requirements. Our solution to this problem is a Monte Carlo method called stochastic 
sampling, which is described in detail elsewhere [12]. With stochastic sampling, aliasing is replaced 
with noise, a less objectionable artifact. We use a type of stochastic sampling called tittering [ 12]. 
Pixeis are divided into a number of subpixels (typically 16). Each sub- pixel has exactly one sample 
point, and the exact location of that sample point within the subpixel is determined by jittering, or 
adding a random displacement to the location of the center of the subpixel. This jittered location is 
used to sample micropolygons that overlap the subpixel. The current visibility information for each sample 
point on the screen is kept in a z buffer [8]. The z buffer is important for two reasons. First, it permits 
objects to be sent through the rest of the system one at a time (principles 2, 4, 5 and 6). Second, it 
provides a back door (prin- ciple 7); the z buffer can combine point samples from this algo- rithm with 
point samples from other algorithms that have capa* bilities such as ray tracing and radiosity. This 
is a form of 3-D eompositing; it differs from Duff's method [15] in that the corn- positing is done before 
filtering the visible samples.  (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 example, in the 
case of patches, micropolygon boundaries are parallel to u and v. The result of dicing is a two-dimensional 
array of micropolygons called a grid (principle 2). Micropo-lygons require less storage in grid form 
because vertices shared by adjacent micropolygons are represented only once. Dicing is done in eye space, 
with no knowledge of screen space except for an estimate of the primitive's size on the screen. This 
estimate is used to determine how finely to dice, i.e., how many micropolygons to create. Primitives 
are diced so that micropo- lygons are approximately half a pixel on a side in screen space. This adaptive 
approach is similar to the Lane-Carpenter patch algorithm [22]. The details of dicing depend on the type 
of primitive. For the example of bicubic patches, screen-space parametric derivatives can be used to 
determine how finely to dice, and forward dif- ferencing techniques can be used for the actual dicing. 
All of the micropolygons in a grid are shaded together. Because this shading occurs before the visible 
surface calculation, at a minimum every piece of every forward-facing on-screen object must be shaded. 
Thus many shading calculations are performed that are never used. The extra work we do is related to 
the depth complexity of the scene, which is the average number of surfaces at each sample point. We expect 
pathological cases to be unusual, however, because of the effort required to model a scene. Computer 
graphics models are like movie sets in that usually only the parts that will be seen are actually built. 
There are advantages that offset the cost of this extra shading; the tradeoff depends on the particular 
scene being rendered. These are some of the advantages to using micropolygons and to shading them before 
determining visibility: Vectorizable shading. If an entire surface is shaded at once, and the shading 
calculations for each point on the surface are similar, the shading operations can be vector- ized (principle 
2).  Texture locality. Texture requests can be made for large, contiguous blocks of texture that are 
accessed sequentially. Because shading can be done in object order, the texture map thrashing that occurs 
in many other algorithms is avoided (principle 4b). This thrashing occurs when texture requests come 
in small pieces and alternate between several different texture maps. For extremely complex models with 
lots of textures, this can quickly make a renderer unusable.  Texture filtering. Many of the texture 
requests are for rectilinear regions of the texture map (principle 1). This is discussed in detail in 
the next section.  Subdivision coherence. Since an entire surface can be subdivided at once, we can 
take advantage of efficient techniques such as forward differencing for patch subdivi- sion (principles 
1 and 2).  Clipping. Objects never need to be clipped along pixel boundaries, as required by some algorithms. 
 Displacement maps [11]. Displacement maps are like bump maps [4] except that the location of a surface 
can be changed as well as its normal, making texture maps a means of modeling surfaces or storing the 
results of model- ing programs. Because displacement maps can change the surface location, they must 
be computed before the hidden surface calculation. We have no experience with the effects of large displacements 
on dicing.  No perspective. Because micropolygons are small, there is no need to correct for the perspective 
distortion of inter- polation [24]. Because shading occurs before the perspec- tive transformation, no 
inverse perspective transformations are required.  CAT CSG depth complexity dicing displacement maps 
plane eye space ,,rid eometrle locality hither plane ltter nlcropolygon RAT s and t screen space shade 
tree splitting stochastic sampling texture locality u and v world space  yon plane 2.3. Micropolygons. 
Glossary a coherent access texture, in which s is a Linear function of u and t is a linear function of 
v. constructive solid geometry. Defines objects as the un- ion, intersection, or difference of other 
objects. the average number of surfaces (visible or noO at each sample point the process of taming geometric 
primitives into grids ol micropolygons. texture maps used to change the location of points in grid. a 
plane parallel to the hither plane that is slightly in fro~ of the eye. The perspective calculation may 
be unreli- able for points not beyond this plane. the world space coordinate system rotated and translated 
so that the eye is at the origin looking down the +z axis. +x is to the right, +y is down, a two<limensional 
array of micropolygons. the principle that all of the calculations for a geometric primitive should be 
performed without reference to oth- er geometric primitives. the z=min plane that is the front of the 
viewing frustum. the random perturbation of regularly spaced points for stochastic sampling the basic 
geometric object for most of the algorithm, flat-shaded quadrilateral with an area of about IA pixel. 
a random access texture. Any texture that is not a CAT parameters used to index a texture map. the perspective 
space in which the x and y values correspond to pixel locations. a method for describing shading calculations 
[11 ]. the process of turning a geometric primitive into one or more new geometric primitives. a Monte 
Carin point-sampling method used for antialias- ing [12]. the principle that each texture should be read 
off the disk only once. coordinates of a parametric representation of a surface. the global right-handed 
nonperspective coordinate sys- tem. the z=max plane that is the back of the viewing frustum. Micropolygons 
are the common basic geometric unit of the algo- rithm (principle 3). They are flat-shaded quadrilaterals 
that are approximately 1/2 pixel on a side. Since half a pixel is the Nyquist limit for an image [6, 
26], surface shading can be ade- quately represented with a single color per micropolygon. Turning a 
geometric primitive into micropolygons is called dic-ing. Every primitive is diced along boundaries that 
are in the natural coordinate system of the primitive (principle 1). For 16~® ® ~~ SIGGRAPH '87, Anaheim, 
July 27-31, 1987 2.4. Texture Locality. For rich, complex images, textures are an important source of 
information for shading calculations [3, g]. Textures are usually indexed using two parameters called 
u and v. Because u and v are also used for patch parameters, we will call the texture parameters s and 
t to avoid confusion. Surfaces other than patches may also have a natural coordinate system; we will 
use u and v for those surface coordinates too. For many textures, s and t depend only on the u and v 
of the patch and can be determined without knowing the details of the shading calculations. Other textures 
are accessed with an s and t that are determined by some more complex calculation. For example, the s 
and t for an environment map depend on the nor- mal to the surface (though that normal might in turn 
depend on a bump map that is indexed by u and v). We accordingly divide textures into two classes: coherent 
access textures (CATs) and random access textures (RATs). CATs are textures for which s=au+b and t=ev+d, 
where a, b, c, and d are constants. All other textures are RATs. Many CATs have s=u and t=v, but we have 
generalized this relationship to allow for single textures that stretch over more than one patch or repeat 
multiple times over one patch. We make this distinction because CATs can be handled much more easily 
and often significantly faster than RATs. Because st order is the same as uv order for CATs, we can access 
the texture map sequentially if we do our shading calculations in uv order (principles 1 and 4b). Furthermore, 
if micropolygons are created so that their vertices have s and t values that are integer multiples of 
powers of l/z, and if the textures are prefiltered and prescaled and stored as resolution pyramids [36], 
then no filtering calcula- tions are required at run time, since the pixels in the texture line up exactly 
with the micropolygons in the grid (principle 1). Fig- ure 2 shows a primitive diced into a 4x4 grid 
and the correspond- ing texture map; notice how the marked micropolygon corresponds exactly to the marked 
texture region because we are dicing along u and v, the texture's natural coordinate system.   o , 
0oy0ooo diced .primitive ~texture map in screen space Figure 2. With CATs, micropolygons map exactly 
to texture map pixels. With the inverse pixel method, pixels map to quadrila- teral areas of texture 
that require.filtering. By contrast, in the more traditional pixel texture access, the pixel boundary 
is mapped to texture space, where fihedng is required. Filtering without a resolution pyramid gives good 
results but can be expensive [17]. Using a resolution pyramid requires interpo- lating between two levels 
of the pyramid, and the filtering is poor [19]. Summed area tables [14] give somewhat better filter- 
ing but can have paging problems. RATs are more general than CATs, but RAT access is slower. RATs can 
significantly reduce the need for ray tracing. For example, reflections and refractions can frequently 
be textured onto a surface with environment maps. Environment maps are RATs because they are indexed 
according to the reflection direc- tion. Another example of a RAT is a decal [2], which is a world-space 
parallel projection of a texture onto a surface, so that s and t depend on x, y and z instead of on u 
and v. Initialize the z buffer. For each geometric primitive in the model, Read the primitive from the 
model file If the primitive can be bounded, Bound the primitive in eye space. If the primitive is completely 
outside of the hither-you 2 range, cull it. If the primitive spans the e plane and can be split, Mark 
the primitive undieeable. Else Convert the bounds to screen space. If the bounds are completely outside 
the viewing frustum, cull the primitive. If the primitive can be diced, Dicethe primitive into a grid 
of micropolygons. Compute normais and tangent vectors for the micropolygons in the grid. Shade the micropolygons 
in the grid. Break the grid into micropolygons. For each mleropolygon, Bound the micropolygon in eye 
space. If the micropolygon is outside the hither-yon range, cull it. Convert the mieropolygon to screen 
space. Bound the micropolygon in screen space. For each sample point inside the screen space bound, 
If the sample point is inside the mlcropolygon, Calculate the z of the micropolygon at the sample point 
by interpolation. If the z at the sample point is less than the z in the buffer, Replace the sample in 
the buffer with this sample. Else Split the primitive into other geometric primitives. Put the new primitives 
at the head of the unread portion of the model file. Filter the visible sample hits to produce ptxels. 
Output the pixels.  Figure 3. Summary of the algorithm. (~ ~ Computer Graphics, Volume 21, Number 4, 
July 1987 micropolygon pixels Figure 4a. A sphere is split into patches, and one of the patches is diced 
into a 8×8 grid of micropolygons. 3. Description of the Algorithm The algorithm is summarized in Figure 
3. In order to emphasize the basic structure, this description does not include tran-sparency, constructive 
solid geometry, motion blur, or depth of field. These topics are discussed later. Each object is turned 
into micropolygons as it is read in. These mietopolygons are shaded, sampled, and compared against the 
values currently in the z buffer. Since only one object is pro- cessed at a time, the amount of data 
needed at any one time is limited and the model can contain arbitrarily many objects. Primitives are 
subdivided only in uv space, never in screen space. The first part of the algorithm is done in uv space 
and world space, and the second half is done in screen space. After the transformation to screen space, 
there is never any need to go back to world space or uv space, so there are no inverse transfor- mations. 
Each type of geometric primitive has the following routines: Bound. The primitive computes its eye-space 
bound; its screen-space bound is computed from the eye-space bound. A primitive must be guaranteed to 
lie inside its bound, and any primitives it is split into must have bounds that also lie inside its bound. 
The bound does not have to be tight, however. For example, a fractal surface can be bounded if the maximum 
value of its random number table is known [7, 18]. The fraetal will be guaranteed to lie within this 
bound, but the bound probably will not be ve~ tight. The effect of displacement maps must be considered 
in the cal- culation of the bound.  grid litte samples Figure 4b. The micropolygons in the grid are 
transformed to screen space, where they are stochastically sampled. Dice. Not all types of primitives 
need to be dieeable. The only requirement is that each primitive be able to split itself into other primitives, 
and that this splitting eventually leads to primitives that can all be diced.  Split. A primitive may 
split itself into one or more primi- rives of the same type or of different types.  Diceable test. This 
test determines whether the primitive should be diced or split and returns "diceable" or "not dieeable" 
accordingly. Primitives should be considered not diceable if dicing them would produce a grid with too 
many micropolygons or a large range of micropolygon sizes.  The bound, split, and dice routines are 
optional. If the diceable routine ever returns "diceable", the dice routine must exist; if the diceable 
routine ever returns "not diceable", the split routine must exist. If the bound routine exists, it is 
used for culling and for determining how finely a primitive should be diced in order to produce micropolygons 
of the correct size on the screen. For example, consider one possible set of routines for a sphere. The 
sphere diceable routine returns "diceable" for small spheres and "not diceable" for large spheres. The 
sphere dice routine turns a sphere directly into mieropolygons. The sphere split rou- tine turns the 
sphere into 32 patches [16]. The patch dice routine creates a rectangular grid of micropolygons so that 
the vertices differ in u and v by integer multiples of powers of 1/2. This is done to obviate CAT filtering, 
but in this case it is also necessary for the prevention of patch cracks [9]. Figure 4a shows a sphere 
being split into patches and one of those patches being diced into an 8x8 grid of mieropolygons. Figure 
413 shows tiffs grid in screen space with jittered sample locations in one of the pixels. ~ ,~ SIGGRAPH 
'87, Anaheim, July 27-31, 1987 I eye i I I I I I I I I I I I I I I O' epsilon hither yon Figure 5. 
A geometric primitive that spans the C and hither planes is split until its pieces can be culled or processed. 
The culled pieces are marked. This algorithm does not require clipping. The viewing frustum consists 
of a screen space xy range and an eye space hither-yon z range. Objects that are known to be completely 
outside of this region are culled. Objects that are partly inside the frustum and partly outside are 
kept, shaded and sampled. Regions of these objects that are outside of the viewing frustum in the x ory 
direc- tions are never sampled. Regions that are in front of or behind the viewing frustum may be sampled, 
but their hits are rejected if the sampled surface point lies outside the hither-yon z range. Note that 
if the filter that is used to sample the z buffer to pro- duce pixels is wider than a pixel, the viewing 
frustum must be expanded accordingly because objects that are just off screen can affect pixels on the 
screen. Sometimes an object extends from behind the eye to inside the viewing frustum, so that part of 
the object has an invalid per- spective calculation and another pax is visible. This situation is traditionally 
handled by clipping to the hither plane. To avoid clipping, we introduce the e plane, a plane of constant 
z that lies slightly in front of the eye as shown in Figure 5. Points on the z<e side of this plane can 
have an invalid perspective calculation or an unmanageably large screen space x and y because of the 
perspective divide. If a primitive spans both the c plane and the hither plane, it is considered "not 
diceable" and is split. The resulting pieces are culled if they are entirely outside of the viewing frustum, 
diced if they lie completely on the z>c side of the e plane, and split again if they span both the e 
plane and the hither ~lane. As long as every primitive can be split, and the splits eventually result 
in primitives with smaller bounds, then this procedure is guaranteed to terminate successfully. This 
split-until-cullable procedure obviates clipping. Objects that cannot be bounded can still be protected 
against bad perspective situations, since micropolygons are created in eye space. Their micropolygons 
can be culled or be run through a split-until-cullable procedure. 4. Extensions Since this algorithm 
was first developed, we have found it easy to add a number of features that were not specifically considered 
in the original design. These features include motion blur, depth of field, CSG (constructive solid geometry) 
[ 1, 33], shadows [32] and a variety of new types of models. The main modification for transparency and 
CSG'calculations is that each sample location in the z buffer stores multiple hits. The hits at each 
sample point are sorted in z for the transparency and CSG calculations. Motion blur and depth of field 
are discussed elsewhere in detail [10, 12, 13]. In the case of motion blur, micropolygons are moved for 
each sample point to a jittered time associated with that sample. For depth of field, they are moved 
in x and y according to a jittered lens location. Both motion blur and depth of field affect the bound 
calculations; the details are described elsewhere [13].  5. Implementation We had to make some compromises 
to implement this algorithm on a general purpose computer, since the algorithm as described so far can 
require a considerable amount of z buffer memory. The screen is divided into rectangular buckets, which 
may be kept in memory or on disk. In an initial pass, each primitive is bounded and put into the bucket 
corresponding to the upper left corner of its screen space bound. For the rest of the calculations, the 
buckets are processed in order, left-to-right and top-to-bottom. First all of the primitives in the bucket 
are either split or diced; as primitives are diced, their micropolygons are shaded and put into every 
bucket they overlap. After all of the primi- fives in a bucket have been split or diced, the micropolygons 
in that bucket are sampled. Once a bucket is empty, it remains empty, so we only need enough z buffer 
memory for one bucket. The number of micropolygons in memory at any one time can be kept manageable by 
setting a maximum grid size and forcing primitives to be considered "not diceable" if dicing them would 
produce too large a grid. We have implemented this revised version of the algorithm in C and have used 
it to make a number of animated films, including The Adventures of Andre and Wally B. [27], the stained 
glass man sequence in Young Sherlock Holmes [25], Luxo Jr. [28], and Red's Dream [29]. The implementation 
performs reasonably well, considering that the algorithm was designed as a testbed, without any requirement 
that it would run efficiently in C. For a given shading complexity, the rendering time is proportional 
to the number of micropolygons (and thus to screen size and to the number of objects). An example of 
a image rendered with this program is shown in Figure 6. It is motion blurred, with environment maps 
for the reflections and shadow depth maps for the shadows [32]. The picture is by John Lasseter and Eben 
Ostby. It was rendered at 1024x614 pixels, contains 6.8 million micropolygons, has 4 light sources, uses 
15 channels of texture, and took about 8 hours of CPU time to compute. Frames in Andre were 512x488 pixels 
and took less than ½ hour per frame. Sherlock frames were 1024x614" and took an hour per frame; Luxo 
frames were 724x434 and took 1½ hours per frame. Statistics on Red's Dream frames are not available yet. 
All of these CPU times are for a CCI 6/32, which is 4-6 times faster than a VAX 11/780.  ~ SIGGRAPH 
'87, Anaheim, July 27-31, 1987 13. COOK, ROBERT L., "Practical Aspects of Distributed Ray Tracing," 
in SIGGRAPH "86 Developments in Ray Trac- ing course notes (August 1986). 14. CROW, FRANKLIN C., "Summed-Area 
Tables for Texture Mapping," Computer Graphics (SIGGRAPH "84 Proceed- ings) 18(3), pp. 207-212 (July 
1984). 15. DUFF, TOM, "Compositing 3-D Rendered Images," Com-puter Graphics (SIGGRAPH '85 Proceedings) 
19(3), pp. 41-44 (July 1985). 16. FAUX, I. D. AND M. J. PRATT, Computational Geometry for Design and 
Manufacture, Ellis Horwood Ltd., Chi- chester, England (1979). 17. FEIBUSH, ELIOT, MARC LEVOY, AND ROBERT 
L. COOK, "Synthetic Texturing Using Digital Filtering," Computer Graphics 14(3), pp. 294-301 (July 1980). 
 18. FOURNIER, ALAIN, DON FUSSELL, AND LOREN CAR- PENTER, "Computer Rendering of Stochastic Models," 
Communications of the ACM 25(6), pp. 371-384 (June 1982). 19. HECKBERT, PAUL S., "Survey of Texture 
Mapping," IEEE Computer Graphics and Applications (November 1986). 20. KAPLAN, MICHAEL R., "Space-Tracing, 
A Constant Time Ray-Tracer," in SIGGRAPH '85 State of the Art in Image Synthesis seminar notes (July 
1985). 21. KAY, TIMOTHY L. AND JAMES T. KAIIYA, "Ray Tracing Complex Scenes," Computer Graphics (SIGGRAPH 
'86 Proceedings) 20(4), pp. 269-278 (Aug. 1986). 22. LANE, JEFFREY M., LOREN C. CARPENTER, TURNER WHIFFED, 
AND JAMES F. BLINN, "Scan Line Methods for Displaying Parametrically Defined Surfaces," Communi-cations 
of the ACM 23(1), pp. 23-34 (January 1980). 23. LEVINTHAL, ADAM AND THOMAS PORTER, "Chap -A SIMD Graphics 
Processor," Computer Graphics (SIG- GRAPH "84 Proceedings) 18(3), pp. 77-82 (July 1984).  24. NEWMAN, 
WILLIAM M. AND ROBERT F. SPROULL, Princi-ples of Interactive Computer Graphics (2nd ed.), McGraw-Hill, 
New York (1979). pp. 361-363 25. PARAMOUNT PICTURES CORPORATION, Young Sherlock Holmes, Stained glass 
man sequence by Pixar and Lucas- film Ltd. 1985. 26. PEARSON, D. E., Transmission and Display of Pictorial 
Information, Penteeh Press, London (1975). 27. PIXAR,The Adventures of AndrE and WaUy B., July 1984. 
 28. PIXAR,Luxo Jr., July 1986. 29. PIXAR,Red' s Dream, July 1987. 30. REEVES, WILLIAM T., "Particle 
Systems -A Technique for Modeling a Class of Fuzzy Objects," ACM Transac- tions on Graphics 2(2), pp. 
91-108 (April 1983). 31. REEVES, WILLIAM T. AND RICKI BLAU, "Approximate and Pmbabilistic Algorithms 
for Shading and Rendering Structured Particle Systems," Computer Graphics (S1G- GRAPH "85 Proceedings) 
19(3), pp. 313-322 (July 1985). 32. REEVES, WILLIAM T., DAVID H. SALESIN, AND ROBERT L. COOK, "Shadowing 
with Texture Maps," Computer Graphics (SIGGRAPH '87 Proceedings) 21 (July 1987). 33. ROTH, S. D., "Ray 
Casting for Modeling Solids," Com-puter Graphics and Image Processing(18), pp. 109-144 (1982). 34. RUBIN, 
STEVEN M. AND TURNER WHITTED, "A 3-Dimensional Representation for Fast Rendering of Com- plex Scenes," 
Computer Graphics (SIGGRAPH '80 Proceedings) 14(3), pp. 110-116 (July 1980). 35. SMITH, ALVY RAY, "Plants, 
Fractals, and Formal Languages," Computer Graphics (SIGGRAPH '84 Proceedings) 18(3), pp. 1-10 (July 1984). 
 36. WILLIAMS, LANCE, "Pyramidal Parametrics," Computer Graphics (SIGGRAPH "83 Proceedings) 17(3), pp. 
1-11 (July 1983).   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37415</article_id>
		<sort_key>103</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[Accurate triangulations of deformed, intersecting surfaces]]></title>
		<page_from>103</page_from>
		<page_to>110</page_to>
		<doi_number>10.1145/37401.37415</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37415</url>
		<abstract>
			<par><![CDATA[A quadtree algorithm is developed to triangulate deformed, intersecting parametric surfaces. The biggest problem with adaptive sampling is to guarantee that the triangulation is accurate within a given tolerance. A new method guarantees the accuracy of the triangulation, given a "Lipschitz" condition on the surface definition. The method constructs a hierarchical set of bounding volumes for the surface, useful for ray tracing and solid modeling operations. The task of adaptively sampling a surface is broken into two parts: a subdivision mechanism for recursively subdividing a surface, and a set of subdivision criteria for controlling the subdivision process.An adaptive sampling technique is said to be robust if it accurately represents the surface being sampled. A new type of quadtree, called a <i>restricted quadtree</i>, is more robust than the traditional unrestricted quadtree at adaptive sampling of parametric surfaces. Each sub-region in the quadtree is half the width of the previous region. The restricted quadtree requires that adjacent regions be the same width within a factor of two, while the traditional quadtree makes no restriction on neighbor width. Restricted surface quadtrees are effective at recursively sampling a parametric surface. Quadtree samples are concentrated in regions of high curvature, and along intersection boundaries, using several subdivision criteria. Silhouette subdivision improves the accuracy of the silhouette boundary when a viewing transformation is available at sampling time. The adaptive sampling method is more robust than uniform sampling, and can be more efficient at rendering deformed, intersecting parametric surfaces.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.1</cat_node>
				<descriptor>Model classification</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010346</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation theory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010342</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Model development and analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP42052893</person_id>
				<author_profile_id><![CDATA[81100594687]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Brian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Von Herzen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology, Pasadena]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14034821</person_id>
				<author_profile_id><![CDATA[81100070192]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alan]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Barr]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Techbology, Pasadena]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Barr, Alan H., "Geometric Modeling and Fluid Dynamic Analysis of Swimming Spermatozoa," Ph.D. Thesis, Rensselaer Polytechnic Institute, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808573</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barr, Alan H. Local and Global Deformations of Solid Primitives. Proceedings of SIGGRAPH'84 (Minneapolis, Minnesota, July 23-27, 1984). In <i>Computer Graphics 18</i>, 3 (July 1984), 21-30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15918</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Barr, Alan H. Ray Tracing Deformed Surfaces. Proceedings of SIGGRAPH'86(Dallas, Texas, August 18-22, 1986). In <i>Computer Graphics 20</i>, 4 (August 1986), 287-296.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>908845</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Blinn, Jim, "Computer Display of Curved Surfaces," Ph.D. Thesis, University of Utah, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801288</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Carlson, Wayne E. An algorithm and data structure for 3D Object Synthesis using Surface Patch Intersections. Proceedings of SIGGRAPH'82 (Boston, Massachusetts, July 26-30, 1982). In <i>Computer Graphics 16</i>, 3 (July, 1982), 255.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Catmull, Ed, "Computer Display of Curved Surfaces," <i>IEEE Conference Proceedings on Computer Graphics, Pattern Recognition and Data Structures</i>, May 1975, p. 11.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15916</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Kay, Tim and Jim Kajiya. Ray Tracing Complex Scenes. Proceedings of SIGGRAPH86 (Dallas, Texas, August 18-22, 1986). In <i>Computer Graphics 20</i>, 4 (August 1986), 269.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kirkpatrick, David, "Optimal Search in Planar Subdivisions," <i>SIAM J. Comput.</i>, Volume 12, Number 1, February 1983, p. 28.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Lane, Jeff and Loren Carpenter, "A Generalized Scan Line Algorithm for the Computer Display of Parametrically Defined Surfaces," <i>Computer Graphics and Image Processing</i>, Volume 11, 1979, p. 290.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Lane, Jeff and Richard F. Riesenfeld, "A Theoretical Development for the Computer Generation and Display of Piecewise Polynomial Surfaces," <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, Volume PAMI-2, Number 1, January 1980, pp. 35-46.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Lin C. C., and L. A. Segel, <i>Mathematics Applied to Deterministic Problems in the Natural Sciences</i>. Macmillan Publishing Co., Inc., New York, 1974, pp. 56-57.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Rao, S. S., "Optimization Theory and Applications," Wiley Eastern Limited, New Delhi, India, 1984, pp. 248-249.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Samet, Hanan "Neighbor Finding Techniques for Images Represented by Quadtrees," <i>Computer Graphics and Image Processing</i>, Volume 18, 1982, p. 37.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356930</ref_obj_id>
				<ref_obj_pid>356924</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Samet, Hanan "The Quadtree and Related Hierarchical Data Structures," <i>Computing Surveys 16</i>, 2 (June 1984), 187-260.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15906</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Schmitt, Francis, Brian Barsky, Wen-Hui Du. An Adaptive Subdivision Method for Surface-Fitting from Sampled Data. Proceedings of SIGGRAPH86 (Dallas, Texas, August 18-22, 1986). In <i>Computer Graphics 20</i>, 4 (August 1986), 179-188.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801289</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Schweitzer, D., and E. S. Cobb. Scanline Rendering of Parametric Surfaces. Proceedings of SIGGRAPH'82 (Boston, Massachusetts, July 26- 30, 1982). In <i>Computer Graphics 16</i>, 3 (July, 1982), 265.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Sederberg, Tom and Scott Parry. Free-Form Deformation of Solid Geometric Models. Proceedings of SIGGRAPH'86 (Dallas, Texas, August 18-22, 1986). In <i>Computer Graphics 20</i>, 4 (August 1986), 151-160.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37417</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Snyder, John M. and Al Barr, "Ray Tracing Complex Models Containing Surface Tessellations," Proceedings of SIGGRAPH'87 (Anaheim, California, July 27-31, 1987). In <i>Computer Graphics 21</i>, 3 (July 1987),.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Wamock, J. E., "A Hidden-Line Algorithm for Halftone Picture Representation," Ph.D. thesis, University of Utah, 1969.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Whitted, Turner, "An Improved Illumination Model for Shaded Display," <i>Communications ACM</i>, Volume 23, Number 6, June 1980, p. 343.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Accurate Triangulations of Deformed, Intersecting Surfaces Brian Von Herzen Alan H. Barr California 
Institute of Technology Pasadena, CA 91125 Abstract A quadtree algorithm is developed to triangulate 
deformed, intersecting parametric surfaces. The biggest problem with adaptive sampling is to guarantee 
that the triangulation is accurate within a given tolerance. A new method guarantees the accuracy of 
the triangulation, given a "Lipschitz" condition on the surface definition. The method constructs a hierarchical 
set of bounding volumes for the surface, useful for ray tracing and solid modeling operations. The task 
of adaptively sampling a surface is broken into two parts: a subdivision mechanism for recursively subdividing 
a surface, and a set of subdivision criteria for controlling the subdivision process. An adaptive sampling 
technique is said to be robust if it accurately represents the surface being sampled. A new type of quadtree, 
called a restricted quadtree,is more robust than the traditional unrestricted quadtree at adaptive sampling 
of parametric surfaces. Each sub-region in the quadtree is half the width of the previous region. The 
restricted quadtree requires that adjacent regions be the same width within a factor of two, while the 
traditional quadtree makes no restriction on neighbor width. Restricted surface quadtrees are effective 
at recursively sampling a parametric surface. Quadtree samples are concentrated in regions of high curvature, 
and along intersection boundaries, using several subdivision criteria. Silhouette subdivision improves 
the accuracy of the silhouette boundary when a viewing transformation is available at sampling time. 
The adaptive sampling method is more robust than uniform sampling, and can be more efficient at rendering 
deformed, intersecting parametric surfaces. Categories and Subject Descriptors: 1.3.5 [Computer Graphics]: 
Computational Geometry and Object Modeling- curve, surface, solid, and object representations; geometric 
algorithms, languages and systems; J.6 [Computer Applications]: Computer-Aided Engineering-computer-aided 
manufacturing (CAM). General Terms: Algorithms Additional Key Words and Phrases: Restricted quadtrees, 
adaptive sampling of parametric surfaces. Permission to copy without fee all or part of this material 
isgranted provided that the copies are not made or distributed for direct commercial advantage, the ACM 
copyright notice and the title of the publication and its date appear, and notice isgiven that copying 
is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires 
a fee and/or specific permission. 1987 ACM-0-89791-227-6/87/007/0103 $00.75 Introduction Motivation 
for Studying Surface Sampling Techniques Interesting mathematical formulations for deformed surfaces 
have recently been developed [BARR84], [SEDERBERG86]. Robust and efficient algorithms for rendering these 
surfaces, however, do not currently exist We need to correctly render highly curved regions on deformed 
surfaces. In addition, we must accurately render such critical areas as silhouette boundaries and surface 
intersections. The simplest sampling algorithm covers a surface with a parametrically uniform grid of 
samples, and divides the surface into small polygons that are easy to render. Frequently, aliasing occurs 
in highly curved regions, due to the constant sampling rate. Regions of low curvature are oversampled, 
wasting polygons. An alternative approach is to concentrate samples where they are needed the most. A 
quadtree subdivision technique is presented here that concentrates samples in regions of high curvature 
and in other critical regions. The technique is more robust than uniform sampling of parametric surfaces, 
and is more efficient for the examples given here. With uniform sampling, a trade-off must be made between 
image quality and number of polygons in representing parametric surfaces. Adaptive sampling can produce 
better images with fewer polygons than the uniform sampling approach. The uniform chain in Figure 1 shows 
an image that took 53 minutes on an IBM 4341 using uniform sampling, because most of the time was spent 
on small regions of the image. The nearest link is not sampled adequately, as compared with the quadtree 
image of the same object, which took 45 minutes to compute, as shown in Figure 2. The CPU times represent 
the time required to sample complex bending and twisting deformation functions of parametric primitives 
for nearly 100,000 sample points. Background Quadtree algorithms have been developed for screen space 
and parametric space applications. Quadtrees have been used to rasterize polygons [WARNOCK69]. Quadtree 
subdivision in screen space has been used as an antialiasing technique in ray tracing [WHITTED80]. Bicubic 
patches have been rendered using recursive subdivision techniques in the parametric space of the surface 
[CATMULL75], [CARLSON82], [SCHWETTZER82]. Lane and Riesenfeld [LANE80] describe a method for the display 
and intersection of piecewise polynomial surfaces. Lane and Carpenter [LANE79] describe a recursive technique 
for sampling parametric surfaces using a curvature subdivision criterion. Scan-line techniques have been 
used to render a variety of parametric surfaces [BLINN78]. Adaptive subdivision has been used for fitting 
surfaces to sampled data [SCHMITT86]. It is often attractive when ray-tracing complex surfaces to break 
them into triangles before rendering [BARR86], [KAY86], [SNYDER87]. The memory required for such a decomposition 
varies directly with the number of triangles. Adaptive subdivision greatly reduces the number of triangles 
needed to accurately describe a surface. In addition, a new application of SIGGRAPH 87, Anaheim, July 
27-31, 1987  Figure 1: Uniform chain, 60,000 polygons, sampling time 53 minutes. the Lipschitz condition 
to parametric surfaces can guarantee the accuracy of polygonal approximations. A new type of quadtree, 
the restricted quadtree, is described here for subdividing a surface. Restricted quadtrees differ from 
unrestricted quadtrees in that neighboring squares may differ in width by at most a factor of two. While 
the unrestricted quadtree does not reliably follow features such as the local maximum of the curve in 
Figure 3, the restricted quadtree is much more robust at adequately sampling curves and surfaces. An 
efficient set of subdivision criteria control the sampling process for rendering deformed, intersecting 
surfaces. Several subdivision criteria are examined, including curvature subdivision, intersection subdivision, 
and potential intersection subdivision. A view-dependent subdivision criterion causes subdivision at 
the silhouette boundary from a given viewpoint. Each region is subdivided if any of the subdivision criteria 
are not met. Regions of low curvature are represented with a few relatively large polygons, while regions 
of high curvature are represented with many little polygons. Bounding Volumes for Parametric Surfaces 
Given a continuous parametric surface, we will show how to construct bounding volumes that contain the 
surface. Bounding volumes are useful for intersection operations, for collision detection, for ray tracing 
parametric surfaces, and for triangulating a parametric surface accurately. The ideal method guarantees 
that each part of the surface remains within its bounding volume. The task is impossible, however, if 
we are given a completely arbitrary parametric surface and no additional information. We know what the 
function values are, wherever we have sampled the surface. There is no way to guarantee what the function 
is doing where we haven t sampled, if the samples are the only information available to us. With a single 
additional value, however, called a Lipschitz constant, we can bound the surface. Figure 2: Quadtree 
chain, 50,000 polygons, sampling time 45 minutes. The Lipschitz Condition for a Parametric Curve Fit 
we define the Lipschitz condnion for a parametric curve F(u) over a domain 0 S u 5 1 (Figure 4) [LIN74]. 
The Lipschitz condiuon states that I F(q)  F(q,) I I K I u,  tro I, where K is the Lipschitz constant, 
and uo and u1 are m the interval 0 S ur S 1. The Lipschitz constant bounds the maximum parametric derivative 
of the function F(u): IlF/dul 2 K. Consider a value u2 between u=O and u=l. We have I F(uZ)  F(u=O) 
I S K I u2  (u=O) I, and I F(u=l) F(Q) I 4 K I (u=l)  u2 I. Adding the equations, I F(q)  F(u=O) 
I + I F(u=l)  F(uZ) I S Ku2 + K(l u2) = K. We take the limiting case: d, +d;?=K, dl = I F(q)  F(u=O) 
I, d2 = I F(u=l) F(q) I. The solution of the equation is an ellipsoid with foci F(u=O) and F(u=l) such 
that the sum of the distances from the foci to any point on the ellipsoid is equal to K. We basically 
have a strmg of fixed length, tied at both ends to the points F(u=O) and F(u=l). dl + d2 = K = constant 
 Figure 4: Bounding ellipsoid for a parametric curve F(u), 0 5 u I4 1. The length of the curve must 
be less than or equal to K.  Figure 3a: An unrestricted quadtree omits the local maximum in a curve. 
Figure 3b: A restricted quadtree adequately samples the same cubic curve. The Lipschitz Condition for 
a Parametric Surface Now we extend the result to parametric surfaces of two variables, F(u, v). The Lipschitz 
condition on a parametric surface F(P) over a domain P=(u,v) is defined by: I F(P) -F(P) I (Ax2 + Ay2 
II F(Pi) -F(Po) 112 K II PI -Po 112. The L2 norm represents the Euclidean distance between any two point 
in the plane or in three-space. In contrast, the LI norm represents the sum of perpendicular distances 
between any points in the plane or in three-space. The 1 norm is given by 1 = lAxl + lAyl + lAzl, and 
we always have 1, since the shortest distance between any two points falls along a straight line. Therefore 
we can use the L2 norm in modeling space and the LI norm in parametric space: KI P1-PI, where PO and 
P1 are any two points in the parametric space of the surface, and K is the Lipschitz constant The constant 
K determines a maximum distance between two points in modeling space, given the distance of the two points 
in parameter space. We use the L2 norm for the Lipschitz F(P) -F(P) 11 P-  K IPI P-112 K PI Po ll. 
The L1 norm is attractive because the distance from PO to P1 via P is independent of P (Fig. 5). 2  
We evaluate the Lipschitz condition from PO to P and from P to P1, where P is anywhere in the rectangle 
formed by opposite comers PO and PI: Figure 6: Bounding ellipsoid for the parametric surface F(P). 
[KAY86]. The hierarchy of bounding volumes is useful for ray tracing, for collision detection, and for 
guaranteeing the accuracy of a triangulation. Each region in a surface quadtree has a maximum error based 
on its bounding ellipsoid. Given a desired error tolerance, we can subdivide the regions until the tolerance 
is reached. We obtain an arbitrarily accurate sampling of the surface. Determining the Lipschitz Constant 
The Lipschitz constant may be derived directly from the parametric equation, by taking the global maximum 
of the parametric derivatives of the surface. If the surface is differentiable, we can use the parametric 
derivatives to obtain the Lipschitz constant K: max   F(P) - 0) 112 K I P -PO  P is feasible for surfaces 
such bicubics, superquadrics, and II F(PI) -F(P) 112 K II 1 -II. Adding the two equations, IIF(P)  
 Taking the limiting case, d + d2 = 2 + IIF(Pi) ­ K lIP -P 0111 + K I - ) + (v-vo)) + K((ul -u) + 
(v 1 -v)) = C, d +d2 = C,  where C = K((ul -uo)+( v- v)).  The solution of the equation is an ellipsoid 
with foci F(Po) and 1) such that the sum of the distances from the foci to any point on the ellipsoid 
is equal to C. We again have a string of fixed length, tied at both ends to the points F(Po) and 1) (Figure 
6). We now have a mechanism for enclosing any region or subregion of the parametric surface in a bounding 
ellipsoid. Given a quadtree that spans the parametric domain of a surface (a surface quadtree ),every 
region of the quadtree has a bounding ellipsoid that encloses it. The same hierarchy used in the quadtree 
may be used to construct a hierarchy of bounding volumes low order polynomials, because local maxima 
are easy to find in the parametric derivatives of these functions. If the surface is piecewise differentiable, 
then the maximum derivative of each of the pieces may be used. If the user does not require a guarantee 
about the bounding volume, then the Lipschitz constant may be estimated from samples and path lengths. 
A Recursive Subdivision Mechanism a surface into simple elements; 2) the subdivision criteria, determining 
where additional sampling is necessary. Here we examine the recursive subdivision mechanism for adaptively 
sampling a set of surfaces. An ideal recursive subdivision mechanism should smoothly adjust the sampling 
frequency over the parametric surface, adapting to variable sampling requirements. A quadtree technique 
is one approach for a subdivision mechanism. The parametric (u, v) space of a surface is broken into 
a set of regions. Whenever more accuracy is needed in the surface quadtree, a region is divided into 
four smaller regions. Samples are obtained at t he come rs of each region. 105  SIGGRAPH 87, Anaheim, 
July 27-31,1987  Figure 7: Uniformly sampled sphere.  Silhouette Boundary 0 u---b 1 0u+ 1 Figure 
8: Parametric space of Figure 10: Parametric space of the uniform sphere. the quaduee sphere. Basic Approach 
The subdivision technique uses the following steps: 1. The surface is sampled on a uniform parametric 
grid at some initial resolution.  2. Each region is evaluated using several acceptance criteria. 3. 
If the region isn t acceptable, then it is split into four smaller regions.  4. Steps 2. and 3. are 
repeated until the entire surface is sampled adequately.  5. The regions are broken into triangles. 
 6. The triangles are clipped at the intersection with other surfaces, forming a smooth boundary.  7. 
The triangles are rendered.  Figure 7 shows a uniformly sampled sphere. Lines are drawn on the surface 
of the sphere to show how it has been broken into polygons. The surface has been sampled at the corner 
of each square. The north pole has more samples than necessary. Figure 8 shows the parametric space (u. 
v) of the sphere. Figure 9 shows a sphere sampled using the quadtree technique. Squares have been concentrated 
along the boundary of the sphere as seen from the point of view in Figure 9, and reduced in the middle 
and on the back side of the sphere. Figure 10 shows the parametric space of the sphere. The sinusoidal 
line of small squares represents the silhouette boundary of the sphere, where more samples are needed 
to reduce visual artifacts of the sampling process. The north pole of the sphere has fewer samples than 
with uniform subdivision. Data Structure for Quadtrees The quadtree consists of pointers to regions 
arranged in a hierarchy that tessellate the parametric space of the surface. Samet describes basic data 
structures and access procedures for quadtrees [SAMET82], [SAMET84]. We attach a parametric sample to 
the standard quaduee data structure at the Figure 9: Quadtree sphere. Figure 1 la: A surf&#38;e quaduee 
in parametric space.  Y L x  Figure 1 lb: Cracks in the surface quadtree in modeling space. comer 
of each quadtree region. Several regions access the same comet sample, so the samples are stored in a 
two-dimensional bucket array for easy access. Quadrilaterals vs. Triangles Care must be taken in creating 
a polygon mesh from a quadtree. Adjacent squares in a quadtree frequently vary in size. Since the comers 
of these adjacent squares do not always match up, cracks appear in the surface wherever small squares 
adjoin larger squares (see Figure 11: Cracks in a surface quadtree). To eliminate cracks. it is necessary 
to construct a planar subdivision of the parametric space [KIRKPATRICK83]. A planar subdivision is a 
collection of line segments that intersect only at segment endpoints. A triangular subdivision (see Figure 
12) is a planar subdivision containing only triangles. Although a quadtree is not a planar subdivision, 
since corners touch edges, a triangular subdivision may be constructed from the quadtree, as shown in 
the next section. Restricted Quadtrees The adaptive sampling process relies on the limited sampling 
information available to decide whether to obtain additional samples. One indication to subdivide is 
that the neighboring regions have subdivided for some reason. 63 Computer Graphics, Volume 21, Number 
4, July 1987 A new type of quadtree, called a restricted quadtree, propagates the subdivision information 
to neighbors. The rule about restricted quadtrees is that neighboring regions must be within one level 
of each other in the quadtree hierarchy (Figure 3). Regions that share an edge are considered neighbors. 
Regions that only share a corner are not considered neighbors. The rule prevents sudden changes in the 
sampling rate over a surface. Artifacts associated with the change in sampling rate are minimized. Restricted 
quadtrees concentrate samples near important features, making the algorithm more robust. The rubostness 
of curve-finding algorithms is improved as well. Figure 3 shows the difference between an unrestricted 
quadtree and a restricted quadtree sampling near a cubic curve. The squares subdivide only if their corners 
span the cubic curve. The unrestricted quadtree misses a large portion of the curve, but the restricted 
quadtree is much more robust at exploring the complete curve. A square in a restricted quadtree is decomposed 
into triangles using a simple rule. Every square is broken into eight triangles, or two triangles per 
edge, unless the edge borders a larger square. In that case a single triangle is formed along the edge 
(see Figure 12). Neighbor-Finding Algorithm An efficient technique exists for finding neighbors in a 
quadtree [SAMET82]. The algorithm fmds the nearest common ancestor between a square and its neighbor, 
and requires an average of four node traversals of the quadtree, for quadtrees of arbitrary size. The 
algorithm is used to maintain the restricted quadtree. and to triangulate the quadtree. Alternatively, 
the neighbors may be explicitly stored with pointers at each square, which requires additional memory. 
 Parametric Space Wrap-Around For closed parametric surfaces such as a sphere, the east boundary must 
match the west boundary exactly. Otherwise cracks may appear at the date line. The neighbor-fmding algorithm 
may be extended at parametric boundaries. We defme squares on the west edge of the quadtree to be neighbors 
of squares on the east edge of the quadtree. For toroids, the squares on the north edge of the quadtree 
are neighbors of squares on the south edge of the quadtree. The seam at the parametric boundary is eliminated 
by forming a triangular subdivision across the boundary. Triangle Clipping After the squares of the 
quadtree are broken into triangles, the triangles are tested against inside-outside functions of other 
surfaces, and are clipped at the intersection boundary. The clipping removes the ragged appearance that 
otherwise occurs (Figure 13: Uniform sampling of a puzzle piece without triangle clipping). Figure 14 
shows the effects of clipping boundary triangles and quadtree sampling. The technique dramatically improves 
the quality of the images. Figure 14: Quadtree sampling with triangle clipping.  Recursive Subdivision 
Criteria A set of recursive subdivision criteria is needed to determine where subdivision should occur. 
The philosophy of the method is to mathematically measure the visible badness of each part of the surface, 
and subdivide until a prescribed tolerance is reached. The criteria should include a method to detect 
surface curvature, and to locate silhouette and surface intersection boundaries. We use three coordinate 
systems here: (u. v) parametric space, (x. y. z) modeling space, and (X, Y) screen space. Parametric 
space spans the domain of the parametric surface. The surface is embedded in three­dimensional modeling 
space. Screen space uses a viewing transformation to project modeling space coordinates onto the image 
plane. Screen space is useful for determining the visual size of a feature when a model is resampled 
each frame of an animation [BARR86]. The recursive sampling process is started with a coarse initial 
grid of samples. The grid provides basic information about the surface to make decisions about further 
subdivision. The following criteria control the subdivision process: Curvature Subdivision Curvature 
subdivision estimates the local curvature of an object. Where the curvature is high, a region is subdivided. 
The subdivision process terminates when a region becomes sufficiently planar. Curvature estimation may 
be performed in several ways. Lane and Carpenter [LANE79] measure the distance from a surface to its 
planar approximation. Alternatively, normal vectors may be computed approximately or analytically from 
the equation for the surface. Normal vectors are used here, since they are computed anyway for shading 
computations. A simple vector equation of these normals provides a curvature subdivision criterion. Every 
adjacent pair of normal vectors (Nl, NZ) of a region must satisfy (I  Nl. N2) c E, where E is determined 
 empirically by adjusting E until the image quality is satisfactory. The normal vectors are normalized 
to unit length Subdivision stops if the region is smaller than a pixel. The actual curvature K is given 
by K = (de/dx), where 0 is an angle and x is a distance. The normal vector estimation (1 Nl. N2) computes 
a term proportional to (A@2. where A0 is the change in 0 across the region. Tangent vectors must pass 
the same curvature test, (1 T,. TZ)< E. It is possible for all of the normal vectors to point in the 
same direction, but the tangent vectors may point in different directions. Distorting a rectangle into 
a U-shape is a good example (Figure 15). The sheet stays in the plane, but its tangent vectors are not 
parallel. Such highly curved regions must be sampled finely. Tangent curvature subdivision eliminates 
the problem (Figure 16: Drain with tangent curvature subdivision), improving the mbusmess of the curvature 
subdivision criterion. 107 SIGGRAPH 87, Anaheim, July 27-31, 1987   Intersection Subdivision A sharp 
boundary is created where surfaces intersect. The boundaries should be finely sampled to avoid aliasing 
artifacts. One approach is to subdivide boundary regions until they are smaller than a pixel. The technique 
is robust, but expensive, in computing the boundary of the surface. An alternative technique is explored 
here, which measures the straightness of the boundary. Subdivision occurs until the boundary is straight 
in modeling (x. y. z) space. In regions where the boundary forms a sharp comer, subdivision stops if 
the region is smaller than a pixel. Where the boundary is straight, larger triangles can be used. Triangle 
clipping at the boundary produces an accurate boundary if the boundary is straight. The test for straightness 
of a boundary curve across a region is computed using approximate tangent vectors of the boundary curve. 
Figure 17 shows a square with four comer vertices connected to a center vertex. Note that any straight 
line crossing the square must intersect the lines of the square in at least three places, Pt. P2, P3. 
The intersection points are found by interpolating between comer samples and a center sample on the square 
until a boundary point is obtained. A variation of the regula falsi iteration method is effective [RAO84]. 
We approximate the boundary by the line segments T1 = P8 PI, and T8 = P3 P2. T1 and T8 are approximate 
tangent vectors to the boundary curve. The two tangent vectors are normalized and tested with the condition 
(1 T1. T2) < E. The region is subdivided until the condition is met, unless the region is smaller than 
a pixel in screen space. Triangle clipping smooths the edges created. Samples may be classified as internal 
or external to an intersecting object in a couple of ways. A hierarchical set of bounding volumes determines 
the proximity of the sample to the intersecting surface. Alternatively, an Figure 16: Drain with tangent 
curvature subdivision.  inside-outside, or implicit, formulation for the surface classifies the sample 
point [BARR83], [SEDERBERG86]. Figure 18 shows an example of a deformed surface subtracted from a mold. 
Silhouette Boundaries Given a camera viewpoint, silhouette subdivision concentrates samples along the 
silhouette boundary to minimize artifacts at the silhouette. The eye is quick to pick up slight irregularities 
at the sharp border of an object, which has high spatial frequencies. Polygonal artifacts are easier 
to see near the silhouette boundary of a surface than on the interior. The silhouette criterion is evaluated 
in a similar manner to the intersection subdivision criterion. The sphere in Figures 9 and 10 demonstrates 
the silhouette subdivision process. The dot product between the surface normal N and the view vector 
V determines whether a sample is front-facing (N.V < 0). back-facing ( N.V > 0). or on the silhouette 
boundary (N.V = 0). Subdivision continues until the curvature of the silhouette boundary in screen space 
is less than a threshold value, or when the region is smaller than a pixel. The second termination condition 
prevents sharp comers from causing infinite recursion. Proximity Subdivision Proximity subdivision searches 
for intersectton points between surfaces. It is a precursor to the intersection criterion, which finds 
the entire intersection boundary given an intersection point, A surface is subdivided until either an 
intersection is found or a local minimum is found in the inside-outside functions of the other surfaces. 
If an implicit inside-outside function is not available, bounding volumes or surface regions may bc used 
to determine the need for additional subdivision. Computer Graphics. Volume 21, Number 4. Julv 1987 
6-3   Efficient Combination of Subdivision Criteria Each of the subdivision criteria described above 
are computed for each region. Sometimes it is possible to determine that a region requires further subdivision 
without computing all the criteria. In this case it makes sense to compute the inexpensive criteria first, 
and possibly avoid unnecessary computation. Once the region passes all subdivision criteria once (or 
is culled from further consideration), a flag is set to indicate that the region should not be reexamined 
during the next pass through the quadtree. Some of the criteria use view-dependent tests, since a viewing 
transformation may be available at sampling time. In addition to the criteria mentioned here, the region 
may be forced to subdivide due to the constraint of restricted quadtrees that neighboring regions remain 
the same width within a factor of two. The following tests are ordered roughly according to increasing 
computational cost: 1. If the square is bigger than the initial sampling grid, then subdivide. 2. Else 
if the square is facing away from the viewer, then end. 3. Else if the square is smaller than a pixel, 
then end. 4. Else if the proximity test reveals a potential intersection, then subdivide. 5. Else if 
the square is culled by a surface intersection. then end. 6. Else if the square fails the flatness test. 
then subdivide. 7. Else if the square contains curved intersection boundaries. subdivide. 8. Else if 
the square contains curved silhouette boundaries, subdivide. 9. end.   Imaging Results The following 
illustrations show the variety of deformed. intersecting parametric surfaces that may be rendered using 
the adaptive sampling techniques described. Puzzle The puzzle is modeled with six identical pieces that 
till the volume of the interior of the puzzle. An individual piece is formed by taking a superquadric 
block, and subtracting two similar blocks to cut wedges in the piece (Figure 14). Three pieces may be 
assembled to form the cluster shown in Figure 19: Triple Cluster. The completed puzzle is formed with 
a left-handed triple cluster and a right-handed triple cluster (Figure 20: Hex Puzzle). Bicycle Chainwheel 
The chainwheel uses the boolean subtraction operation extensively (Figure 21). Fifty-two cylinders are 
subtracted from a disk to form the teeth for the gear. The proximity subdivision criterion helps to locate 
the position of the teeth. Deformed cylinders cut holes in the gear to make it lighter. Superquadric 
cranks and pedals are added after the cutting process. Nut and Bolt A type of screw thread may be formed 
by taking a superquadric with a square profile and twisting it for several revolutions (Figure 22). The 
thread is subtracted from the nut, and merged with the bolt head, to form the nut and bolt combination. 
 Conclusions Surface quadtrees are an effective way to triangulate deformed, intersecting parametric 
surfaces. The adaptive sampling problem may be decomposed into two subproblems: the mechanism for subdivision, 
and the subdivision criteria. Images of these parametric surfaces have been created using a robust subdivision 
mechanism, and a small set of subdivision criteria. Restricted quadtrees are more robust than unrestricted 
quadtrees in the triangulation of parametric surfaces. Curvature. intersection, proximity and silhouette 
subdivision techniques provide a robust set of criteria for the recursive sampling of parametric surfaces. 
These techniques are found to be more efficient than uniform subdivision at producing triangulations 
of deformed, intersecting surfaces. 109 References Barr, Alan H., "Geometric Modeling and Fluid Dynamic 
Analysis of Swimming Spermatozoa," Ph.D. Thesis, Rensselaer Polytechnic Institute, 1983. Barr, Alan H. 
Local and Global Deformations of Solid Primitives. Proceedings of SIGGRAPH'84 (Minneapolis, Minnesota, 
July 23-27, 1984). In Computer Graphics18, 3 (July 1984), 21-30. Barr, Alan H. Ray Tracing Deformed Surfaces. 
Proceedings of SIGGRAPH'86(Dallas, Texas, August 18-22, 1986). In Computer Graphics20, 4 (August 1986), 
287-296. Blinn, Jim, "Computer Display of Curved Surfaces," Ph.D. Thesis, University of Utah, 1978. Carlson, 
Wayne E. An algorithm and data structure for 3D Object Synthesis using Surface Patch Intersections. Proceedings 
of SIGGRAPH'82 (Boston, Massachusetts, July 26-30, 1982). In Computer Graphics16, 3 (July, 1982), 255. 
Catmull, Ed, "Computer Display of Curved Surfaces," IEEE Conference Proceedings on Computer Graphics, 
Pattern Recognition and Data Structures, May 1975, p. 11. Kay, Tim and Jim Kajiya. Ray Tracing Complex 
Scenes. Proceedings of SIGGRAPH86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics20, 4 (August 
1986), 269. Kirkpatrick, David, "Optimal Search in Planar Subdivisions," SIAM J. Comput., Volume 12, 
Number 1,February 1983, p. 28. Lane, Jeff and Loren Carpenter, "A Generalized Scan Line Algorithm for 
the Computer Display of Parametrically Defined Surfaces," Computer GraphicsandImage Processing, Volume 
11, 1979, p. 290. Lane, Jeff and Richard F. Riesenfeld, "A Theoretical Development for the Computer Generation 
and Display of Piecewise Polynomial Surfaces," IEEE Transactionson PatternAnalysis and Machine Intelligence, 
Volume PAMI-2, Number 1,January 1980, pp. 35-46. Lin C. C., and L. A. Segel, Mathematics Applied to Deterministic 
Problems in the Natural Sciences. Macmillan Publishing Co., Inc., New York, 1974, pp. 56-57. Rao, S. 
S., "Optimization Theory and Applications," Wiley Eastern Limited, New Delhi, India, 1984, pp. 248-249. 
Samet, Hanan "Neighbor Finding Techniques for Images Represented by Quadtrees," Computer Graphics and 
Image Processing, Volume 18, 1982, p. 37. Samet, Hanan "The Quadtree and Related Hierarchical Data Structures," 
Computing Surveys 16, 2 (June 1984), 187-260. Schmitt, Francis, Brian Barsky, Wen-Hui Du. An Adaptive 
Subdivision Method for Surface-Fitting from Sampled Data. Proceedings of SIGGRAPH86 (Dallas, Texas, August 
18-22, 1986). In Computer Graphics20, 4 (August 1986), 179-188. Schweitzer, D., and E. S. Cobb. Scanline 
Rendering of Parametric Surfaces. Proceedings of SIGGRAPH'82 (Boston, Massachusetts, July 26­30, 1982). 
In Computer Graphics16, 3 (July, 1982), 265. Sederberg, Tom and Scott Parry. Free-Form Deformation of 
Solid Geometric Models. Proceedings of SIGGRAPH'86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics 
20, 4 (August 1986), 151-160. Snyder, John M. and Al Barr, "Ray Tracing Complex Models Containing Surface 
Tessellations," Proceedings of SIGGRAPH'87 (Anaheim, California, July 27-31, 1987). In Computer Graphics21, 
3 (July 1987),. Wamock, JE., "A Hidden-Line Algorithm for Halftone Picture Representation," Ph.D. thesis, 
University of Utah, 1969. Whitted, Turner, "An Improved Illumination Model for Shaded Display," CommunicationsACM, 
Volume 23, Number 6, June 1980, p. 343. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37416</article_id>
		<sort_key>111</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Adaptive forward differencing for rendering curves and surfaces]]></title>
		<page_from>111</page_from>
		<page_to>118</page_to>
		<doi_number>10.1145/37401.37416</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37416</url>
		<abstract>
			<par><![CDATA[An adaptive forward differencing algorithm is presented for rapid rendering of cubic curves and bicubic surfaces. This method adjusts the forward difference step size so that approximately one pixel is generated along an ordinary or rational cubic curve for each forward difference step. The adjustment involves a simple linear transformation on the coefficients of the curve which can be accomplished with shifts and adds. This technique combines the advantages of traditional forward differencing and adaptive subdivision. A hardware implementation approach is described including the adaptive control of a forward difference engine. Surfaces are rendered by drawing many curves spaced closely enough together so that no pixels are left unpainted. A simple curve anti-aliasing algorithm is also presented in this paper. Anti-aliasing cubic curves is supported via tangent vector output at each forward difference step. The adaptive forward differencing algorithm is also suitable for software implementation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P263510</person_id>
				<author_profile_id><![CDATA[81332512187]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sheue-Ling]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lien]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sun Microsystems, Inc., Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31093889</person_id>
				<author_profile_id><![CDATA[81332526795]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shantz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sun Microsystems, Inc., Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31036095</person_id>
				<author_profile_id><![CDATA[81100298352]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Vaughan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pratt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sun Microsystems, Inc., Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>282943</ref_obj_id>
				<ref_obj_pid>282918</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Jerry Van Aken and Mark Novak, "Curve-Drawing Algorithms for Raster Displays," ACM Transactions on Graphics, vol. 4, no. 2, pp. 147-169, April 1985.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>907242</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Edwin Catmull, A Subdivision Algorithm for Computer Display of Curved Surfaces, Thesis in Computer Science, University of Utah, UTEC-CSc-74-133, 1974.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[George M. Chaikin, "An Algorithm for High Speed Curve Generation," Computer Graphics and linage Processing, vol. 3, pp. 346-349, 1974.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>889976</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Steven A. Coons, Surfaces for Computer-Aided Design of Space Forms, Project MAC, MIT, MAC-TR-41, June 1967.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358815</ref_obj_id>
				<ref_obj_pid>358808</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Jeffrey Lane, Loren Carpenter, Turner Whitted, and James Blinn, "Scan Line Methods for Displaying Parametrically Defined Surfaces," CACM, vol. 23, no. 1, January 1980.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Jeffrey M. Lane and Richard F. Riesenfeld, "A Theoretical Development for the Computer Generation of Piecewise Polynomial Surfaces," IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. PAMI-2, no. 1, pp. 35-46, January 1980.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M.L.V. Pitteway, "Algorithm for drawing ellipses or hyperbolae with a digital plotter," Computer Journal, vol. 10, no. 3, pp. 282-289, Nov. 1967.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325225</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Vaughan Pratt, "Techniques for Conic Splines," Computer Graphics, vol. 19, no. 3, July 1985.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37425</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Michael Shantz and Sheue-Ling Lien, "Shading Bicubie Patches," Computer Graphics, vol. 21, no. 4, July 1987.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Adaptive Forward Differencing for Rendering Curves and Surfaces Sheue-Ling Lien, Michael Shantz and 
Vaughan Pratt Sun Microsystems, Inc. 2500 Garcia Avenue Mountain View, CA 94043 Abstract An adaptive 
forward differencing algorithm is presented tot rapid rendering of cubic curves and bicubic surfaces. 
This method adjusts the forward difference step size so that approximately one pixel is generated along 
an ordinary or rational cubic curve for each forward difference step. The adjustment involves a simple 
linear transformation on the coefficients of the curve which can be accomplished with shifts and adds. 
This technique combines the advantages of traditional forward differencing and adaptive subdivision. 
A hardware implementation approach is described including the adaptive control of a forward difference 
engine. Sur-faces are rendered by drawing many curves spaced closely enough together so that no pixels 
are left unpainted. A sim- ple curve anti-aiiasing algorithm is also presented in this paper. Anti-aliasing 
cubic curves is supported via tangent vector output at each forward difference step. The adaptive forward 
differencing algorithm is also suitable for software implementation. CR Categories and Subject Descriptors: 
1.3.5 [Computer Graphics]: Computational Geometry and Object Modelling -Curve, surface, solid, and object 
representations; Geometric algorithms, and systems; 1.3.3 [Computer Graphics]: Picture/Image Generation 
-Display algorithms; 1.3.7 [Computer Graphics]: Three-dimensional Graphics and Realism - Color, shading, 
shadowing, and texture. Additional Key Words and Phrases: image synthesis, adap- tive forward differencing, 
parametric curves and surfaces. Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. &#38;#169; 1987 ACM-0-89791-227-6/87/007/0111 $00.75 Introduction Parametric curves 
and curved surfaces are a common form of surface and object representation. In particular, non-uniform 
rational b-splines have gained popularity for mechanical CAD applications. Since high speed hardware 
capable of rendering vectors and polygons is widely avail- able, high speed curve and surface rendering 
is usually done by subdividing and rendering them as straight lines or planar polygons. For conics, non-parametric, 
incremental solutions of the implicit equations[7, 8, 3, 1] are well known and a few hardware curve generators 
have been built. Less progress has been made on hardware techniques for rendering higher order curves 
and surfaces. Research has focused largely on subdivision methods for rendering and modelling.J2,6] Recursive 
subdivision for curve and surface rendering is expensive to implement in hardware due to the high speed 
stack memory requirements and the fact that frame buffer memory access is easier to optimize if the pixels 
are being written to adjacent addresses. Lane and others[5] developed scan line methods for render- ing 
bicubic patches. They used Newton iteration to compute the intersections of the patch with the plane 
of the scanline. These approaches were not intended for, nor are they simple enough for hardware implementation. 
Our adaptive forward difference (AFD) technique is an extension of well known[4] ordinary forward differencing 
and is related to the adaptive subdivision methods in that it adjusts the step size to the next pixel 
by transforming the equation of the curve to an identical curve with different parameterization. AFD 
differs from recursive subdivision or traditional forward differencing by generating points sequen- tially 
along the curve while adjusting the parameterization to give pixel sized steps. AFD allows ~t surprisingly 
simple hardware implementation, and is compatible with frame buffer memory interleaving for high performance. 
This paper develops the theory of adaptive forward dif-ferencing and covers several related aspects and 
problem areas. 1) Reparameterization of cubic or rational cubic curves 2) Drawing surfaces by spacing 
curves 8s apart 3) Generating anti-aliased curves 4) Trimming and image mapping on patches ~,,~4 SIGGRAPH 
'87, Anaheim, JuDy 27-31, 1987 With special purpose hardware for rendering these curves and surfaces 
directly, the usual subdivision overhead is reduced, and the appearance of the rendered objects is more 
accurate. The method lends itself to hardware fast shading techniques by functional approximations of 
the unit normal function over a patch.[9] Principles The method of adaptive forward differencing unifies 
the processes of recursive subdivision and forward differencing. In this section we present the principles 
underlying the method. The key insights are that these processes axe both instances of linear substitution, 
and that efficiency is optim- ized by a choice of basis appropriate to the mix of substitu- tions. We 
consider curves and surfaces in a space S, taken for the sake of illustration to be R 4 (homogeneous 
coordinates x,y,z,w). A parametric object in S is a function f :X-~S where X is a set constituting the 
parameter space. The object is a curve, segment, surface, or patch when x is respectively the set R of 
reals, the real interval [0,1], the real plane R 2, or the unit square [0,1] 2. We take s and t for the 
parameters, making f either f (t) or f (s ,t ). A linear substitution transforms f (t) into f (at+b) 
and f (s,t) into f(as+b,et+d), expressible as the composition off with a linear or bilinear function 
respectively. The geometric effect of linear substitution is to translate and scale a segment or patch 
within the curve or surface containing it. Any segment of a curve can be mapped to any other segment 
of the same curve by some linear substitution, and likewise for patches. Let us denote by L the linear 
substitution t/2 and by R the linear substitution (t+l)r2. Then L and R act on a segment C to yield the 
"left" and "right" halves LC and RC of C. These are the transformations associated with recursive sub- 
division; they may be applied recursively to subdivide a curve segment into quarters LLC,LRC,RLC,RRC 
(Figure l(a)), eighths, etc. Let us denote by E the linear substitution t+l. Then E acts on a segment 
C to yield its "right neighbor" EC. One use for E is as the forward difference operator. To render a 
long segment C, start with a very small initial segment D of C (e.g. D=LL.--LC) and generate the remaining 
(also small) segments of C by El) ,EED ,EEED, . . This process is usually called forward differencing. 
Another use for E is as a substitute for R in recursive subdi- vision: we may represent R as EL, as illustrated 
by the top half of Figure l(b). However, rather than computing LC and RC separately we can compute LC 
once and then apply E to LC to get the right hall allowing us to discard C after apply- ing L to it and 
so avoiding a "stack pop" when the time comes to apply R. The lower half of Figure l(h) shows that this 
can be extended down another layer of recursion: we can get to RLC, LRC, and RRC by starting from LLC 
and repeat- edly applying E, thanks to the additional identity ER = LE (i.e. EEL =LE) which allows E 
to make the jump from RLC to LRC. This ability of E to run across the whole tree holds at any depth. 
At sufficient depth the method turns into ordinary forward differencing as per the previous paragraph. 
A disadvantage of forward differencing is that it may not traverse C with uniform velocity. Recursive 
subdivision C LC RC LRC RRC LLC RLC (a) LC ~-RC LRC ~ RRC (b) Figure 1. Relationship of linear substitutions 
L, R, and E. avoids this difficulty by stopping at different depths in dif- ferent parts of the reeursion 
tree. We may transfer this advantage of recursive subdivision to forward differencing by inserting an 
occasional L or L -~ (the substitution 2t) into the stream of E's whenever the velocity is too great 
or too small respectively. This has the effect of changing our level in the recursion tree as we forward-difference 
across it. We call this technique adaptive forward differencing. In order to implement the above we require 
concrete representations for C, L, E, etc. We do this in the usual way: independently for each dimension 
of s take C to be a poly- nomial in t (and s), regard the polynomial as a point in a vector space of 
dimension one more than its degree, regard linear substitutions as a particular kind of linear transforma- 
tion of this space, and perform the transformations in an appropriate basis for the space. One key property 
of linear substitution is that it does not increase polynomial degree, the other is that its action on 
a polynomial viewed as a vector is indeed that of a linear transformation. While any basis will do, certain 
bases favor certain transfor- mations. For example the total number of l's in the binary representation 
of a particular transformation may be quite small in a particular basis, permitting the transformation 
to be carried out with just a few shifts and adds. Catmull [2] gives a basis for which L and R can be 
cheaply computed with only three adds and four shifts. 1 o o, 8 ] Lc = 0 1/4 0 00 1/2-1/8 1/2 0 1/8 
0 1/2-1/8 1/2 71 Rc = 1/8 0 1 0 1 [i 0 0 l/4J (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 
A 0 Figure 2. Block diagram of an AFD unit. However, for forward differencing neither Catmull's basis 
for L and R nor any of the other bases usually considered for recursive subdivision are particularly 
well suited to the matrix representation of E. The best basis for E is the for- ward difference basis 
which allows parallel additions suit- able for a pipeline implementation. AdaptiveForward Difference 
Algorithm For adaptive forward differencing we require a basis that works well with L and L -~, especially 
with E, on the ground that E occurs significantly more often than L in practice. The following set is 
the forward difference basis which is considered to be the most appropriate. B3 : l (t3-3t2+2t) = 6 t(t-1)(t-2) 
1 2 t 1 B 2 = ~(t -) ='~-t(t-l) Bl=t B0=I The E matrix of this basis requires only three adds which 
can be done in parallel.  E= Ii °ll The L and L < matrices can be implemented with simple shifts and 
adds. L = 1/2-1/8 1 L-l= Ii00o /i001104 0 1/4 -u81 o 0 t/sJ o o This algorithm is implemented in hardware 
called an AFD unit. An AFD unit is a third order digital differential analyzer which implements an adaptive 
forward difference solution to a parametric cubic function of t. The parameter t varies from 0 to 1 along 
the curve. The dt step size for t is adaptively adjusted so that the curve steps along in approxi- mately 
one pixel steps in screen coordinates. Figure 2 shows a block diagram of an AFD unit. t t Sun Microsystems, 
Inc. is pursuing patent protection in the United States and abroad on the technology described in this 
paper. B 1 C D ] > 0 Four AFDUs can be used to generate the x,y,z,w values of the pixels along a cubic 
curve. Figure 3 shows the 4 required AFDUs and the divide by w circuit necessary for rendering rational 
curves. The filter unit is the controller for the adaptive step size, and performs other functions. con 
o, I x/~ r X AFDU y/w To Pixel -Frame Y AVOU I z/w Buffer Filter Arc length Z AFDU I Figure 3. Block 
diagram of the AFD hardware. Each AFDU computes a 3rd order parametric function. 1. Reparameterization 
A parametric cubic function f(t) can be represented in for- ward difference basis as f = aB 3(t)+bB 20)+cB 
~(t )+dB o(t) A cubic curve is defined by four cubic functions x(t), y(t), z(t), and w(t), each implemented 
by a separate AFD unit. x (t) = axBB+b:,B2+cxB l+d,B o y (t ) = ayB3+byB2+cyB l+dyB o z (t) = a, B 3+b~ 
B 2+c, B l+d, B o w (t) = aw B 3+b,, B 2+cw B i+d~B 0 The coefficients a, b, c, and d are loaded into 
the 4 coefficient registers of each AFD unit. At each clock event the parameter t increases by dt and 
the four AFDUs generate the coordinates of one pixel. If the x,y address step, corresponding to the dt 
step, is more than one pixel, dt is divided by two (adjusted down) so that each clock generates approximately 
one pixel along the curve. If the x,y address step is less than 112 pixel then dt is doubled (adjusted 
up) to increase the change in x,y coordi- nates. SIGGRAPH '87, Anaheim, July 27-31, 1987 I~~1 To reduce 
dt by half, we transform the cubic functions x(t), y(t), z(t), w(t) by applying the L matrix: x'(t)=x(2 
)= a '~83+b "xB2+c "zBl+d "xBo y'(t ) =y(2 ) = a'~B3+b'~n 2+c" fl~ ~+a'yB o z'(t)=2(2) w'(t)=w(-~) The 
coefficients of the two sets of cubic functions are related by 1 1 1 t," = ~-b ~a 1 1. 1 c p = --~c-gO+--~a 
d'=d TO double dt, we transform the cubic functions by applying the L -1 matrix: x'(t) =x(2t) y'(t)= 
y(2t) z'(t ) = z (2t) w "(t ) = w (2t) Here the coefficient transformation is a" = 8a b" --- 4b +4a 
c" = 2c +b aV =d If the step size is correct then we apply the E matrix. x'(t) =x(t+l) y'(t ) = y (t+l) 
Z'(t) = Z (t+l) w'(t) = w(t+l) The AFD units in this case generate a new pixel and advance to the next 
pixel with the corresponding coefficients transformed by a" =a b" = b+a C t ~ C +b d" = d+c The adaptive 
forward differencing mechanism is illustrated below. t=0 adjusted up/ ~ _ . Figure 4 Operations of "adjust 
up", "adjust down", and "for- ward step". We have measured the percentage of steps requiring an adjust 
up or adjust down using the Utah teapot at various scale factors. Drawing the cubic curves comprising 
a wire mesh on the blcubic patches making up the surface involved 73,000 forward steps, and 600 adjustment 
steps. The over- head for the adaptive nature of the forward difference scheme is therefore quite small. 
It increases when the curves being drawn have large accelerations. 2. Initial Setup To render a cubic 
curve C we first convert to the forward difference basis. We then start with a small initial segment 
D of the curve by applying Ln=L.L...... .L to the curve C. The initial scale down is not really required. 
However, if not done, the adaptive mechanism may adjust down many times until the pixel step size is 
approximately one pixel before it starts rendering. In practice the parameterization is scaled down before 
loading into the AFD units to be within the hardware register precision. The AFDUs adjust from there. 
3. Pixel filtering The pixel filter performs five functions. 1) It compares the current pixel coordinates 
with the previous pixel coordinates generated by the AFD units and tells the AFD units whether they should 
adjust up, adjust down, or step forward to the next pixet. 2) The pixel filter also detects and replaces 
"elbow" sequences of the form x,y to x,y+l to x+l,y+l with a diagonal move x,y to x+l,y+l. This is done 
to improve the appearance of generated curves. 3) It also generates arc length along the curve generated 
by the AFD units. It adds 1 to the are length if the curve steps either horizontally or vert- ically 
and adds 1.414 if the curve steps diagonally. The out- put arc length is used to address the pattern 
memory for mapping texture along curves. 4) The filter unit performs clipping on t, x, y, and z. t is 
clipped between a tmin register and a tmax register to assist in rendering trimmed patches. x, y, and 
z are clipped to their respective rnin and max regis- ter values. 5) The filter generates the instantaneous 
tangent and normal vectors for the purpose of anti-aliasing curves. The pixel filter thus acts as the 
controller for the AFD units and also computes arc length, and antialias weights. ~ Computer Graphics, 
Volume 21, Number 4, July 1987 4. Rendering conics and rational cubits One of the AFI) units generates 
the homogeneous coordinate w as a parametric cubic function of t. For rational cubic curves x, y, and 
z must be divided by w at each point. This is accomplished by using a reciprocal unit which computes 
a truncated Taylor series approximation of 1/w. The reciprocal 1/w is computed as follows which can be 
easily implemented with look-up tables, adders and muff- pliers. 1 1 8 W W 0 W02 The following example 
shows how to set up AFDUs to draw an ellipse with radius r~, ry centered at <x0, y0 > and rotated by 
an angle 0. A half ellipse with radius rx, ry can be defined in parametric form as t(l-t) Xl(t)=rx t2._t+0.5 
0.5-t yl(t) = ry tz_t+0.5 We can get the other half of the ellipse by mirroring the image. By rotating 
the ellipse by an angle 0 and then translating it to <x0, yo>, we get a set of cubic functions which 
describe an ellipse with radius r,, ry centered at xo, Yo and rotated by an angle 0: x (t) = r, t (l-t)cos0+ry 
(0.5-t)sin0+x o(t 2-t +0.5) = (Xo-r ~ eosO)t z + (r~ cosO-r:~ sinO--Xo)t + 0.5(ry sin0+xo) y (t) = -r~ 
t (1-t)sinO+ry (0.5-t)cos0+yo(t L-t +0.5) = (yo+rzsin0)t 2 - (r~sinO+rycosO+yo)t + 0.5 (ry cos0+y 0) 
w (t ) = t2--t +0.5 By converting the above cubic functions to DDA basis, we get a set of coefficients 
a~ = O b= = 2(Xo-r~cosO ) cx = (x0-rzcos0) + (rzcosO--rysinO-Xo) d, = 0.5(ry sin0+x0) %=0 t,, = 2(y0+~, 
sin0) cy = (y 0+rz sin0) -(r x sinO+rycosO+yo) dy = 0.5(ry cos0+Y0) aw = 0.0  t~, = 2.0 c w = 0.0 d~ 
=0.5 We can set up the AFD units with the above coefficients for drawing the ellipse (see Figure 6). 
5. Anti-aliasing cubic curves AFD gives a simple means of generating the instantaneous tangent vector 
¢t, ty, along the curve by simply subtracting the last point from the previous one. The instantaneous 
tangent vector gives an indication of whether the current pixel is in an x_major (t~>ty) or y_major (tz¢ty) 
slope. An approximate distance of the current pixel away from the center curve is computed from this 
tangent and the fractional portion of the pixel addresses as follows. Here c( is the ratio of variation 
of intensity, and c( is used to blend the curve color and the background color. This is a rather crude 
approximation but gives surprisingly improved curve appearance. Figure 5 shows the result of this curve 
anti-aliasing method drawn with the software simulation. If the tangent vector indicates x_major, we 
compute ct = (f,-0.5) + t~ (f'-0"5) where <t~, ty > is the tangent and f~ and fy axe the fractional portion 
of the pixel x and y address. If cc is positive, then the intensity of pixel <x,y> is blended by (l.0-c0, 
and pixel <x,y+l> by c~. In case of a negative c~, pixel <x,y> is blended by (l.0+c0, and pixel <x,y-1 
> by -c~. For y_major, c~ is t~  a= C/,-o.5) + Z-~:,-0.5) In this case, pixel <x,y> is blended by (1.0--c0, 
and pixel <x+l,y> by c~ if c~ is positive; otherwise pixel <x,y> by (1.0+cx) and pixel <x-l,y> by -c~. 
One advantage of this anti-aliasing scheme is that it applies as well to both nonrational and rational 
curves. Figure 6 shows a set of anti-aliased rational curves rendered with this scheme. Shading Bicubic 
Patches The AFD technique can be used to render shaded, curved, trimmed patches, generate anti-aliased 
curves, and map tex- ture and imagery onto curves and surfaces as a function of either are-length or 
parameter. Shading and image mapping onto bicubic or rational bicubic surface patches is performed by 
drawing many curves very close to each other. Each curve is a cubic in t formed by set- tings at a constant 
s=s~. We therefore need to find the spac- ing 85 from one curve to the next so that no pixel gaps exist 
in between them. To compute the spacing 8a in between the current curve f(s=si,t ) and the next curve, 
we run a series of testing curves in the orthogonal direction (i.e. s direction) at t =(0.0,0.125 ...... 
1.0) and examine the step size used by those curves at the positions s=s i. The minimum size used is 
then chosen as the spacing for the next curve f (s~+Ss,t). When the 85 gets smaller, it indicates that 
the next curve should be filled in closer to the current one; when 85 increases, the next curve can be 
a little less close.  ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 We explain next how AFD is used to adaptively 
adjust the spacing in between curves. For a bicubic patch F(s,t) represented in forward difference basis, 
F(s,t) = < fx(s,t),f y(s,t),fz(s,t),fw(s,t ) > each $ (s ,t ) is a bicubic function of s and t. For 
example the x component fx(s,t)=[Bo(t),Bl(t),B2(t),BB(t)] XloXHXI2XlB /B,<,)I ~2o ~2~ x~ x2 /B2(~)I 
LX3o x~1 x32 x3~j LB3(s)J where x~j are the x coordinates of the control points of the patch. A curve 
at a constant s, f(s=s~,t), is a cubic function represented in forward difference basis as f (s =si,t 
)=dB 0(t )+cB l(t)+bB z(t )+aB 3(t ) where the four coefficients a,b,c,d are cubic functions of s in 
forward difference basis: d (s)=Xoo B 0(s )+x 01 B 1 (s)+x 02 B 2(s )+Xo3 B B(s ) c (s)=XloBo(s)+x 11 
B l(S )+xi2 B2(s)+x13 B3(s ) b (s)=x20 B 0(s)+x 22 B ~(s)+x22 B 2(s)+x23 B 3(s) a (s )=x3o Bo(s )+x 31B 
l(s )+x 3z B2(s )+x33 B 3(s ) We apply AFD to these four cubic functions to generate the value of coefficients 
for the next curve. When the spacing 8s for the next curve is the same as the previous one, the E matrix 
is applied. If the spacing for the next curve doubles, L -1 and then the E matrix are applied to double 
the spacing. If the spacing halves, we apply L and then the E matrix to reduce it. We are still examining 
methods for minimizing this redundancy through subdivision and tuning of the adjustment criterion. Figure 
7 shows a Phong shaded Utah teapot rendered on a 1152 x 900 screen with 80 patches using the AFD technique, 
for comparison with the equivalent polygon shaded version in Figure 8 containing 4060 triangles. Trimmed 
patches are rendered by scan converting the trim- ming region in s,t space using the 8s seanline width. 
(Here a scanline in s,t space is different from a scanline in the screen space.) This produces a "scanline" 
curve segment at each constant si bounded by one or more tmin, tmax pairs. These curve segments are rendered 
with clipping to the appropriate tmin and tmax. Figure 9 shows a shaded, image mapped, bicubic patch 
trimmed with a SUN logo. Discussion In rendering curves we set the threshhold of adjustment to be 0.5 
and 1.0, i.e. we adjust up if x and y step by less than .5 pixel and we adjust down if x or y step by 
greater than 1 pixel. Using this threshhold we do not overpaint too many pixels, and neither do we leave 
gaps between pixels. Patches are rendered by filling many curves very close together. However, using 
the 0.5 and 1.0 threshhold in rendering a patch we tend to get missing pixels in the patch. This prob- 
lem is solved by reducing the pixel adjustment threshold down to 0.35 and 0.7, instead of by reducing 
the spacing in between adjacent curves. We are currently trying to estab- lish the optimal adjustment 
criterion for ensuring no pixel gaps. For performance comparison purposes, we used the follow- ing three 
schemes to render a wireframe mesh of curves for a piece of teapot handle on a 512 x 512 screen with 
ten curves in each direction: (1) ordinary forward differencing, (2) adaptive subdivision, and (3) adaptive 
forward differencing. In this test, the ordinary forward differencing technique took 8192 forward steps, 
the adaptive subdivision technique took 3887 subdivisions, and AFD took 49 adjust_up's, 36 adjust_down's 
and 3910 forward steps. It is obvious that the ordinary forward differencing technique usually requires 
more forward steps than our technique because it uses the smallest step required for no gaps and cannot 
adjust to a longer step when appropriate. Each forward operation takes three adds, each adjust_up or 
adjust_down takes 3 adds and 2 multiplies. The first scheme required a total of 24516 adds. Our technique 
required 11900 adds and 255 multi-plies. The subdivision technique took a total of 11661 adds and 15548 
multiplies, where a single subdivision requires 3 adds and 4 multiplies. We used the adaptive subdivision 
technique and our patch rendering technique to compare the patch rendering perfor- mance on rendering 
a piece of teapot body and a piece of teapot handle on a 512 x 512 screen. The termination condi- tion 
we used in the subdivision technique was to constrain the minimum bounding box of the control points 
of a Bezier patch within 1.0 by 1.0. The subdivision technique on the teapot body required 86380 subdivisions 
to fill the entire patch. Since a subdivision takes 36 adds and 48 multiplies, it requires approximately 
3 million adds and 4 million multi- plies. Our technique required 708 adjust up, 513 adjust down, and 
218513 forward step operations. Thus AFD used approximately 0.66 million adds and 3700 multiplies. Our 
method has a curve set up overhead of 12 adds per curve - a total of 6000 adds in this test case, which 
is negligible. In the ease of the teapot handle, it took 143379 subdivisions with adaptive subdivision, 
whereas the new method per-formed 537 adjust up, 727 adjust down, and 187386 forward step operations, 
i.e., 5.16 million adds and 6.88 million mul- tiplies against 0.56 million adds and 2528 multiplies. 
Clearly, both subdivision and AFD can be implemented with integer arithmetic given sufficient precision. 
In both methods the above multiplies can be performed using simple shifts. The shifts required for the 
L and L -~ matrices can be implemented with "wires" in hardware since all elements are integer powers 
of 2. A complete error analysis of a fixed point integer implementation of AFD is currently being con- 
ducted. The relatively poor performance of adaptive subdivision is due to the fact that a subdivision 
operation takes significantly more computation than a forward difference operation. This new method has 
the advantage of producing picture quality equivalent to adaptive subdivision without the memory stack 
management overhead of recursive subdi- vision and is thus more suitable for hardware implementa- tion. 
AFD also makes patch rendering performance com-petitive with polygon rendering. When doing image map- 
ping and patch trimming, our technique operates in s,t space but polygon methods operate in the screen 
seanline order, therefore, our method does not require a transformation from screen space to image coordinates 
as the polygon method does. (~ ~ Computer Graphics, Volume 21, Number 4, July 1987  Acknowledgements 
The following people contributed greatly to the ideas, simu- lations, and design of these algorithms: 
Jerry Evans, David Elrod, Nola Donato, Bob Rocchetti, Sue Carrie, Serdar Ergene, Jim Van Loo, Paul Tien, 
and Mark Moyer. References 1. Jerry Van Aken and Mark Novak, "Curve-Drawing Algorithms for Raster Displays," 
ACM Transactions on Graphics, vol. 4, no. 2, pp. 147-169, April 1985.  2. Edwin Catmull, A Subdivision 
Algorithm for Computer Display of Curved Surfaces, Thesis in Computer Sci- ence, University of Utah, 
UTEC-CSc-74-133, 1974. 3. George M. Chaikin, "An Algorithm for High Speed Curve Generation," Computer 
Graphics and linage Processing, vol. 3, pp. 346-349, 1974. 4. Steven A. Coons, Surfaces for Computer-Aided 
Design of Space Forms, Project MAC, MIT, MAC-TR-41, June 1967. 5. Jeffrey Lane, Loren Carpenter, Turner 
Whitted, and James Blinn, "Scan Line Methods for Displaying Parametrically Defined Surfaces," CACM, vol. 
23, no. 1, January 1980. 6. Jeffrey M. Lane and Richard F. Riesenfeld, "A Theoretical Development for 
the Computer Generation of Piecewise Polynomial Surfaces," IEEE Transactions on Pattern Analysis and 
Machine Intelligence, vol. PAMI-2, no. 1, pp. 35-46, January 1980. 7. M.L.V. Pitteway, "Algorithm for 
drawing ellipses or hyperbolae with a digital plotter," Computer Journal, vol. 10, no. 3, pp. 282-289, 
Nov. 1967. 8. Vaughan Pratt, "Techniques for Conic Splines," Com-puter Graphics, vol. 19, no. 3, July 
1985.  9. Michael Shantz and Sheue-Ling Lien, "Shading Bicu- bie Patches," Computer Graphics, vol. 21, 
no. 4, July 1987.  Figure 5. Comparison of antialiased and ordinary nonrational cubic curves rendered 
with adaptive for- ward difference scheme. Figure 6. Comparison of antialiased and ordinary con- ics 
rendered with adaptive forward difference scheme.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37417</article_id>
		<sort_key>119</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Ray tracing complex models containing surface tessellations]]></title>
		<page_from>119</page_from>
		<page_to>128</page_to>
		<doi_number>10.1145/37401.37417</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37417</url>
		<abstract>
			<par><![CDATA[An approach to ray tracing complex models containing mathematically defined surfaces is presented. Parametric and implicit surfaces, and boolean combinations of these, are first tessellated into triangles. The resulting triangles from many such surfaces are organized in a hierachy of lists and 3D grids, allowing efficient calculation of ray/model intersections.The technique has been used to ray trace models containing billions of traiangles and surfaces never before ray traced. The organizing scheme developed is also independently useful for efficiently ray tracing any complex model, whether or not it contains surface tessellations.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39079343</person_id>
				<author_profile_id><![CDATA[81100167784]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Snyder]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology, Pasadena]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14034821</person_id>
				<author_profile_id><![CDATA[81100070192]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alan]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Barr]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Insititute of Technology, Pasadena]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1300009</ref_obj_id>
				<ref_obj_pid>1299941</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Burr, Alan H., "Superquadrics and Angle Preserving Transformations," Computer Graphics and Appffcations, 1(1}.]]></ref_text>
				<ref_id>Burr 81</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15918</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Burr, Alan H., aRay Tracing Deformed Surfaces," Computer Graphics, 20(4}, August 1986, pp. 287-296.]]></ref_text>
				<ref_id>Baxr 86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cyrus, Iv{. and J. Beck, ~Generalized two and three dimensional Clipping~" Computers and Graphics, 3(1)~ 1978, pp. 23-28.]]></ref_text>
				<ref_id>Cyrus 78</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13044</ref_obj_id>
				<ref_obj_pid>13043</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[t Fujlmoto, Aklra, Takayuki Tanaka, and Kansel Iwata, "ARTS: Accelerated Ray-Tracing System ~, IEEE Computer Graphics and Applications, 6(4), April 1986, 16- 26.]]></ref_text>
				<ref_id>Pujimoto 86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Glassner, Andrew S., ~Space Subdivision for Fast Ray Tracing, ~ IEEE Computer Graphics and Applications, 4(10), October, 1984, pp. 15-22.]]></ref_text>
				<ref_id>Glassner 84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kalra, Devendra, M.S. dissertation in preparation.]]></ref_text>
				<ref_id>Kalra 86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Kaplan, Michael R., ~The Uses of Spatial Coherence in Ray Tracing," ACM SIGGRAPH '85 Course Notes 11, July 22-26 1985.]]></ref_text>
				<ref_id>Kaplan 85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801287</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kajiya, James T., ~Ray Tracing Parametric Patches," Computer Graphics, 16{3), July 1983, pp. 245-254.]]></ref_text>
				<ref_id>Kajiya 82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15916</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Kay, Timothy L., James T. Kajiya, "Ray Tracing Complex Scenes, ~ Computer Graphics, 20(4), August 1986, pp. 269-278.]]></ref_text>
				<ref_id>Kay 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15917</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Joy, Kenneth I., Murthy N. Bhetanabhotla, "Ray Tracing Parametric Surface Patches Utilizing Numerical Techniques and Ray Coherence, ~ Computer Graphics, 20(4}, August 1986, pp. 279-286.]]></ref_text>
				<ref_id>Joy 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807479</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Rubin, Steve M. and T. Whitted., ~A Three-Dimensional Representation for Fast Rendering of Complex Scenes, ~ Computer Graphics 14(3), July 1980, pp. 110-116.]]></ref_text>
				<ref_id>Rubin 80</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325233</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Toth, Daniel L., uOn Ray Tracing Parametric Surfaces, ~ Computer Graphics 19(3), July 1985, pp. 171-179.]]></ref_text>
				<ref_id>Toth 85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Von Hersen, Brian P.,"Sampling Deformed, Intersecting Surfaces with Quadtrees," Caltech CS Technical Report 5179:TR:85, pp. t-40.]]></ref_text>
				<ref_id>Von Hersen 85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37415</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Von Herzen, Brian P.,gAccurate Sampling of Deformed, Intersecting Surfaces," to appear in Computer Graphics, 1987.]]></ref_text>
				<ref_id>Vou Herzen 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Whltted, Turner, "An Improved II}umlnation Model for Shaded Display, ~ Communications of the ACM, 23(6), June 1980, pp. 343-349.]]></ref_text>
				<ref_id>Whirred 80</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ¢ Computer Graphics, Volume 21, Number 4, July "t987 I I iii Ray Tracing Complex Models Containing 
Surface Tessellations John M. Snyder Alan H. Barr California Institute of Technology Pasadena, CA 91125 
 Abstract  An approach to ray tracing complex models containing math- ematically defined surfaces is 
presented. Parametric and implicit surfaces, and boolean combinations of these, are first tessellated 
into triangles. The resulting triangles from many such surfaces are organized in a hierachy of lists 
and 3D grids, allowing efficient calcu]atlon of ray/model intersections. The technique has been used 
to ray trace models containing billions of triangles and surfaces never before ray traced. The orga- 
nizing scheme developed is also independently useful for efficiently ray tracing any complex model, whether 
or not it contains surface tessellations. KEYWORDS: Ray tracing, parametric surface, tessellation, trian- 
gle, llst, 3D grid  Introduction In the past, models suitable for ray tracing have contained too few 
and too simple primitives. Much work has been focused on solving these two problems independently. To 
extend the set of aray-traceable ~ surfaces beyond polygons and qnadric surfaces, several schemes for 
intersecting rays with surfaces have been developed. Kajiya [Kajiya 82] has described an algorithm for 
ray tracing bicubic patches. Toth [Toth 85], Barr [Barr 86], and Joy and Bhetanabhotla I Joy 86] have 
studied al- gorithms for intersecting rays with general parameteric surfaces. These schemes axe slow, 
require expensive evaluation of surface parameterizations, and axe hard to robustly implement. Alternatively, 
mathematically defined surfaces can be broken down into simple pieces. The resulting tessellation is 
an approxi- mation to the real surface which can be made arbitrarily close to it by using tiny enough 
pieces. This approach has been avoided because ray tracers were unable to handle the vast numbers of 
primitives needed to approximate a surface. Recently, organizing structures for large and complex collec- 
tions of primitives have been proposed which make feasible ray tracing of models containing many fine 
tessellations. These struc- tures fall into three categories -- lists, octrees, and 3D grids. Each organizes 
a collection of objects into a single unit which may later be incorporated into a higher level structure. 
Each allows the ray tracing algorithm to determine which objects in the collection can potentially be 
intersected by a ray. Permission to copy without fee all or part of this material is granted provided 
that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice 
and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. &#38;#169; 1987 ACM-0-89791-227-6/87/007/0119 $00.75 Lists were used in early ray 
tracers such as developed by Rubin and Whitted [Rubin 80]. A list is simply a grouping of objects. Hierarchies 
are built by grouping lists into higher level lists. Kay aztd Kajiya [Kay 86] investigated an algorithm 
to traverse the list hierarchy so that objects are considered in the order that they occur along the 
ray. This requires sorting of objects that can potentially be intersected by the ray. Octrees and 3D 
grids partition space rather than objects and thus avoid object sorting. In these structures, each cell, 
a rectan- gular volume in sp~ce, contains all the objects that occur within it. The difference between 
the two structures is that octrees are hierarchical with variable sized cells, while 3D grids are nonhierar- 
chical with cells of uniform size. Glassner [Glassner 84] and Kaplan [Kapian 85] investigated octrees. 
Fujimoto, et al. [Fujimoto 86] de- veloped 3D grids and compared their efficiency with octrees. Fujimoto 
found the 3D grid structure superior to an octree for ray tracing models containing large numbers of 
primitives homoge- nously scattered through space. This finding can be explained in light of two 3D grid 
properties. First, because grid cells are of uniform size, tracing a ray from one grid cell to the next 
is an extremely fast, incremental calculation. Second, because grids are nonhierarchical, determining 
which cell contains the ray origin can be done in constant time, while the same operation is logarithmic 
in the number leaf cells in an octree. In fact, both lists and octrees require hierarchy traversal; lists 
through a hierarchy of bounding volumes around objects, and octrees through a hierarchy of octree celia. 
Set up time for a ray/grid intersection is large, however, making it impractical for collections of a 
few objects. A single grid is also impractical for organizing objects at widely varying lengths of scale. 
 The proposed algorithm uses a hybrid, hierarchical approach to organizing a complex model. In it, both 
lists and 3D grids are used to organize model elements, which are primitives~ or themselves lists or 
3D grids. Grids axe used to organize large collections that axe evenly distributed through space. Lists 
axe used to organize small collections that are sparsely distributed through space. This scheme can 
adapt to complexity in a model at many scales; in fact, a hierarchy of 3D grids can be viewed as a generalization 
of an octree, in which arbitrary branching ratios are possible instead of a fixed branching ratio of 
eight. Using this technique, we have ray traced a model containing 400 billion triangles, more primitives 
than have previously been rendered into a single image. We have generated complex images containing 
such shapes a~ teapots, grass blades, clover leaves, flower petals, and bumpy, twisted, and self-intersecting 
parametric sur- faces. In short, this technique has established a new state of the art in the complexity 
of ray traced images.  2 Surface Tessellation A surface tessellation is a connected mesh of pieces which 
ap- proximates the surface. A triangle is the tessellation piece; a sur- face is thus approximated by 
a polyhedron with triangular faces. Triangles were chosen because their simplicity allowed fast con- 
   "~.~ SIGGRAPH '87, Anaheirn, July 27-31, 1987 A 81) gridis a three dimensional array of rectangular 
volumes, called cells,formed by regularly dividing a larger rectangular solid along the coordinate axes. 
Each cell contains a pointer to an object that is bounded by the cell extents. It is defined as: structure 
grid { double grid_extent[3] [2] ; int x_divlslons, y_dlvisions, z_divisions; structure object *cells[]; 
} Since many objects can occupy space within a cell extent, the object pointed to by a uonempty celt 
is always a list. This llst has its own bounding box which bounds all the objects inside the grid cell. 
Its transformation pointer is always null. Empty cells axe indicated by a null object pointer. Cells 
in the grid are stored in the cells field. The grid_extent field stores the extent of the volume that 
was divided into cells using x_divisions z divisions, y divisions y divisions, and z_divisions z divisions. 
3.2 Building the Model with Lists and Grids The modeler specifies lists and 3D grids by opening a list 
or 3D grid and inserting a series of objects into it. Only one list or grid can be open at a time. When 
a grid is opened, the modeler specifies the number of z, y, and z divisions in the grid, and the =, y, 
and z extent of the grid. Opening a list requires no parameters. The specification of a list or grid 
also includes a unique name so that lists or grids built by the modeler can later be instantiated into 
other lists and grids. The entire model is hierarchically built in a bottom-up fashion using instantiation. 
Triangles in a single surface tessellation are usually inserted into a single grid. This grid can then 
be instantiated many times in the model, and can be separately tranformed in each instance. This is accomplished 
by creating several objects whose root_obj ect fields all point to a single copy of the grid, but whose 
truss field point to different transformation structures. In the same way, the modeler can also replicate 
lists by multiple instantiation. Model building is currently a heuristic, modeller directed pro- cess. 
More work still remains to develop fully automatic algorithms that can organize complex models for efficient 
ray tracing. On the other hand, lists and 3D grids often naturally tit the model's or- ganizational 
structure. For example, our model of a grassy plain {see image in Section 6} is a list containing a plain 
polygon and a grass field grid. The grass field was hierarchically constructed using two different grass 
blade surface tessellations. First, a grass patch was built by replicating these two blades many times 
with various rotations, scales, and translations and inserting them into a grid. Two of these patches 
were then replicated and inserted into a larger grid to form a field of grass. Fields were then replicated 
into a grass plain. In this way, without much modeler effort, we constructed a very complex model (4 
x 1011 triangles) which could be ray traced quite quickly (12 hours on an IBM 4381).  4 Preprocessing 
Algorithm Figure 5 describes the ageneric" algorithm to insert a object into a llst. The term agenericS 
is used because the algorithm works for any object that can be bounded in a simple zyz extent bounding 
box. Figure 5 refers to transforming and enlarging bounding boxes. A bounding box is transformed by transforming 
each vertex of the original bounding box, and bounding the result in x, y, and z. A bounding box is 
enlarged by another bounding box with simple maximum/minimum operations to produce a bounding box that 
 Let 0 be an object to be inserted into list L Let B be O's bounding box Let T be the current transformation 
Transform B by T to give Create an object () whose root_object and object_type fields are equal to O's 
bounding_box field is B trans field points to T Enlarge L's bounding box by Add a pointer to 6 to L 
"S Jlnked list o£ objects Figure 5: Generic Object Enlist Algorithm Let 0 be an object to be inserted 
into grid G Let B be O's bounding box Let T be the current transformation ransYorm B by T to give For 
each ceil in G within or intersecting B Do clip 13 to this grM ce//yielding a bounding box create an 
object () whose root_obj ect and obj e ct_type fields equal O's bounding_box 6eId is B trans field points 
to T add ~) to the cell's objec# list, creating this list ff the eeL/ was previously empty Eudfor Figure 
6: Generic Object Eugrid Algorithm bounds both. Figure 6 describes the generic algorithm for inserting 
an object into a grid. The generic algorithms work for any primitive. Several opti- mlsatious can be 
made, however, to speed ray tracing of trian- gle and polygon primitives. First, instead of transforming 
objects by inverse transforming the ray (see Section 5), we coat transform the primitives directly during 
preprocessing. This avoids many ray transformations and yields tighter bounding boxes around the primitives, 
allowing the ray tracing algorithm to cull more objects from ray intersection consideration. Second, 
instead of clipping the primitive's bounding box to each grid cell, the primitive itself can be clipped 
as in Figure 7 i. This yields tight bounding boxes around the triangles and polygons in- side of every 
grid cell, and appropriately ignores grid cells which in- tersect the bounding box but not the primitive 
inside. The bound- ing box of the primitive inside a grid cell becomes its bounding box after clipping 
to the grid cell's extents. On the other ha~d, the object inserted into the grid cell's list is still 
the original us- clipped triangle or polygon. The unclipped primitive is inserted to conserve memory 
since only one copy of a triangle or polygon is stored instead of several clipped versions of the same 
thing. It is also more efficient to intersect a ray with a triangle than to inter- sect with the many-sided 
polygon that may result from clipping a triangle to a volume. 5 Ray/Model Intersection Algorithm To 
intersect a ray with an object, the algorithm first determines if the ray intersects the object's bounding 
box (see Figure 8) 2. If 1[Cyrus 78] discusses clipping polygons to convex volurnes. 2The ray/bounding 
box intersection algorithm is adapted from that found in [Kay 86] to avoid intersections with planes 
behind the ray origin.     ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 Title Primitives Rays/Pixel 
Hours graphics lab 100 16 12 teapot museum piece 10,000 16 8 reflective bristles 15,000 16 12 statue 
of liberty I00,000 16 14 brass ornament 100,000 16 9 flowers, grass, clovers 200,000 16 3.5 glass museum 
piece 400,000 16 8.5 grass and trees 2x109 16 16 field of grass 4x1011 16 12 Table I: Rendering Time 
For Pictures raster images in this paper were incorporated using software writ- ten by Wen King Su and 
Brian Von Herzen. References [Burr 811 Burr, Alan H., "Superquadrics and Angle Preserving Transformations," 
Computer Graphics and Appffcations, 1(1}. [Baxr 86] Burr, Alan H., aRay Tracing Deformed Surfaces," 
Com- puter Graphics, 20(4}, August 1986, pp. 287-296. [Cyrus 78] Cyrus, Iv[. and J. Beck, ~Generalized 
two and three di- mensional Clipping~" Computers and Graphics, 3(1)~ 1978, pp. 23-28. [Pujimoto 86 t 
Fujlmoto, Aklra, Takayuki Tanaka, and Kansel Iwata, "ARTS: Accelerated Ray-Tracing System ~, IEEE Computer 
Graphics and Applications, 6(4), April 1986, 16- 26. [Glassner 84] Glassner, Andrew S., ~Space Subdivision 
for Fast Ray Tracing, ~ IEEE Computer Graphics and Applications, 4(10), October, 1984, pp. 15-22. [Kalra 
86] Kalra, Devendra, M.S. dissertation in preparation. [Kaplan 85] Kaplan, Michael R., ~The Uses of Spatial 
Coherence in Ray Tracing," ACM SIGGRAPH '85 Course Notes 11, July 22-26 1985. [Kajiya 82] Kajiya, James 
T., ~Ray Tracing Parametric Patches," Computer Graphics, 16{3), July 1983, pp. 245-254. [Kay 86] Kay, 
Timothy L., James T. Kajiya, "Ray Tracing Com- plex Scenes, ~ Computer Graphics, 20(4), August 1986, 
pp. 269-278. [Joy 86} Joy, Kenneth I., Murthy N. Bhetanabhotla, "Ray Tracing Parametric Surface Patches 
Utilizing Numerical Techniques and Ray Coherence, ~ Computer Graphics, 20(4}, August 1986, pp. 279-286. 
[Rubin 80] Rubin, Steve M. and T. Whitted., ~A Three-Dimensional Representation for Fast Rendering of 
Complex Scenes, ~ Computer Graphics 14(3), July 1980, pp. 110-116. [Toth 85] Toth, Daniel L., uOn Ray 
Tracing Parametric Surfaces, ~ Computer Graphics 19(3), July 1985, pp. 171-179. [Von Hersen 85] Von Hersen, 
Brian P.,"Sampling Deformed, In-tersecting Surfaces with Quadtrees," Caltech CS Technical Report 5179:TR:85, 
pp. t-40. [Vou Herzen 87] Von Herzen, Brian P.,gAccurate Sampling of De- formed, Intersecting Surfaces," 
to appear in Computer Graphics, 1987. [Whirred 80] Whltted, Turner, "An Improved II]umlnation Model for 
Shaded Display, ~ Communications of the ACM, 23(6), June 1980, pp. 343-349.  Appendix --Ray/Trlangle 
Intersection This appendix describes an efficient algorithm to compute ray/triangle intersections. Let 
]~ for i E 0, 1,2 be the coordinates of the three vertices of the triangle. Let R/ be the corresponding 
normal vectors at these vertices which axe to be used for normal interpolation across the triangle. 
During the preprocessing stage, the above information is used to construct a triangle structure, the 
tessellation unit root object. We first compute and store the normal vector to the plane containing the 
triangle, N, by N = (PI-Po) x(P2-Po). We also compute and store a scalar d such that any point, P, in 
the triangle's plane satisfies P. N + d = 0. This scalar is computed by d = -Po.N. Lastly, we compute 
and store an index ~o such that 0 if [Nx [ is ma~ximum io = 1 if [Nu] is maximum 2 if [N=[ is maximum 
 The triangle structure also stores the three vertices and normals, P/and R/. To conserve memory, the 
triangle structure should store pointers to these since, on average, each vertex in a tessellation is 
shared by six triangles. To intersect a ray parametrized by O+ Dt with a triangle, first compute the 
t parameter of the ray's intersection with the triangle plane: d-N,O t N-D (1) Let it and £2 {ii,i2 
E {0, 1, 2)) he two unequal indices different from io. Using the t value obtained from Equation 1, compute 
the il and i2 components of the point of intersection, Q, by Q~s = Oi~ + Di, t. A point enclosure test 
can then be performed by computing scalars ~o, ill, and flz according to s p, = [(P,+~ -- e,+l) × (0, 
- e,+dl~0 (2) [~ho where a~ldltion in subscripts is modulo 3. Note that these ~'s are the barycentric 
coordinates of the point where the ray intersects the triangle plane. Only the io component of the cross 
product is computed; the value of Qi0 is therefore unnecessary. Q is inside the triangle if and only 
if0 < /~i -< 1 for i E {0,1,2}. Division by Nio can be eliminated by appropriate rearrangement of the 
test implied by Equation 2. The interpolated normal ~r is given by ~r = ~0Ro + ~iR1 + f12R2. S[X]# 
denotes the ith component of the vector X.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37418</article_id>
		<sort_key>129</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[Boundary evaluation of non-convex primitives to produce parametric trimmed surfaces]]></title>
		<page_from>129</page_from>
		<page_to>136</page_to>
		<doi_number>10.1145/37401.37418</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37418</url>
		<abstract>
			<par><![CDATA[To integrate a CSG-based solid modeler into an existing wireframe/surface modeling system, new boundary evaluation technology has been developed. This scheme uses exact representations for the simple quadric surfaces and both exact and approximate representations of higher-order curved surfaces. It supports parametric primitives (box, wedge, sphere, cylinder, cone, torus), procedural primitives (extrusion, revolution, tube) and a sculptured surface primitive. The output includes curves, parametric trimmed surfaces, and a data structure of adjacency information.An existing boundary evaluator (PADL-2's) has been enhanced to allow a general non-convex faceted primitive with planar and quadric facets. This new hybrid evaluator combines two techniques for curve/primitive classification. PADL-2's existing halfspace-based classification is reserved for the simple convex primitives, and a new ray firing based classification is applied to the non-convex primitives. After evaluation, approximate intersection curves (from intersections involving higher order surfaces) are refined to a specified tolerance by exploiting an exact parametric representation of the surfaces of the primitives. The refined curves and the quadric surface intersection curves are used to create a parametric trimmed surface representation of the solid. This combination of techniques and representations offers advantages in accuracy, robustness and efficiency suitable to a production environment.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Modeling packages</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011066.10011070</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Development frameworks and environments->Application specific development environments</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P93936</person_id>
				<author_profile_id><![CDATA[81100461017]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gary]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Crocker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Calma Company, San Diego, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P299836</person_id>
				<author_profile_id><![CDATA[81100650097]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Reinke]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Calma Company, San Diego, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baumgart B.G., "Geometric Modeling for Computer Vision," rep, STAN-CS-74-463, Stanford Artificial Intelligence Lab., Stanford Univ., Stanford, CA 1974.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Boyse, J.W., Gilchrist J.E., "GMSolid: Interactive Modeling for Design and Analysis of Solids," IEEE Computer Graphics and Applications, Vol. 2, No 2, pp. 27-40, Mar. 1982.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360727</ref_obj_id>
				<ref_obj_pid>360715</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Braid, l.C., "The Synthesis of Solids Bounded by Many Faces," Communications of the ACM, Vol. 18, No. 4, April 1975, pp. 209-216.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801288</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Carlson, W.E., "An Algorithm and Data Structures for 3D Object Synthesis Using Surface Patch Intersections," ACM Computer Graphics, Vol. 16, No. 3, July 1982, pp. 255-263.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Eastman C.M., Yessios C.J., "An Efficient Algorithm for Finding the Union, Intersection, and Differences of Spatial Domains," Tech. Rep 31, Institute of Physical Planning, Carnegie-Mellon Univ., Pittsburgh, PA. Sept. 1972.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Franklin, W.R., "Efficient Polyhedron Intersection and Union," Proc. Graphics Interface '82, (Toronto, Canada, May 17-21, 1982), pp. 73-80.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Glassner, A.S., "Space Subdivision for Fast Ray Tracing," IEEE Computer Graphics and Applications, Vot. 4, No. 10, October 1984, pp. 15-22.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hillyard R.C,, "The Build Group of Solid Modelers," 1EEE Computer Graphics and Applications, Vol. 2, No. 2, March 1982, pp. 43-52.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Katay Y.E., Eastman, C.M., "Shape Operations: An Algorithm for Spatial-Set Manipulations of Solid Objects," CAD Graphics Lab., Carnegie-Mellon Univ., Pittsburgh, PA, July 1980.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358643</ref_obj_id>
				<ref_obj_pid>358628</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Lee Y.T., Requicha, A.A.G., "Algorithms for Computing the Volume and Other Integral Properties of Solids. I. Known Methods and Open Issues," Communications of the ACM, Vol. 25, No. 9, September 1982, pp. 635-641.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Miller, J.R., "Sculptured Surfaces in Solid Models: Issues and Alternative Approaches," IEEE Computer Graphics and Applications, Vol. 6, No. 12, December 1986, pp. 37-48.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4159</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Mortenson, Michael E. Geometric Modeling. John Wiley &amp; Sons, New York, 1985, ch. 6.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Pfeifer, H., "Methods used for Intersecting Geometrical Entities in the GMP Module for Volume Geometry," Computer-Aided Desion, Vol. 17, No. 7, September 1985, pp. 311-318.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Putnam, L.K., Subrahmanyam, P.A., "Computation of the Union, Intersection and Difference of n-dimensional Objects via Boundary Classification," Department of Computer Science, University of Utah, Salt Lake City, UT, 1982.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Requicha, A.A.G., Voelcker, H.B., "Boolean Operations in Solid Modeling: Boundary Evaluation and Merging Algorithms," Proceedings of the IEEE, Vol, 73, No. 1, January 1985, pp. 30-44]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Requicha, A.A.G., Voetcker, H.B., "Boolean Operations in Solid Modeling: Boundary Evaluation and Merging Algorithms," Tech. Memo. 26, Production Automation Project, Univ, of Rochester, Rochester, NY, Jan 1984.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Requicha, A.A.G., Voelcker, H.B., "Solid Modeling: A Historical Summary and Contemporary Assessment," IEEE Computer Graphics and Applications, Vol. 2, No. 2, March 1982, pp. 9-24.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Requicha, A.A.G., Voelcker, H.B., "Solid Modeling: Current Status and Research Directions," IEEE Computer Graphics and Applications, Vol. 3, No. 7, October 1983, pp. 25-37.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Sarraga, R.F., Waters, W.C., "Free-Form Surfaces in GMSolid: Goals and issues," Solid Modeling by Computers. Plenum Press, New York, 1984, pp. 187-210.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Tilove, R.B., "Exploiting Spatial and Structural Locality in Geometric Modeling," Tech. Memo. 38, Production Automation Project, Univ. of Rochester, Rochester, NY, October 198t.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Tilove, R.B., "Set Membership Classification: A Unified Approach to Geometric Intersection Problems," IEEE Transactions on Computers, Vol. C-29, No. 10, October 1980, pp. 874-883.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Tilove, R.B., Requicha, A.A.G, "Closure of Boolean Operations on Geometric Entities," Computer-Aided Des., Vot. 12, No. 5, September 1980, pp. 219-220,]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807462</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Weiler, K., "Polygon Comparison Using a Graph Representation," ACM Computer Graphics, Vol 14, No 3, July 1980, pp. 10-18.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Weiler, K., "Edge-Based Data Structures for Solid Modeling in Curved-Surface Modeling Environments," IEEE Computer Graphics and Applications, Vol. 5, No. 1, January 1985, pp. 21-40.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Yamaguchi, F., Tokieda, T., "A Unified Algorithm for Boolean Shape Operations," IEEE Computer Graphics and Applications, Vol. 4, No 6, pp. 24-37, June 1984.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 Boundary Evaluation of Non-Convex Primitives 
to Produce Parametric Trimmed Surfaces Gary A. Crocker and William F. Reinke Calma Company Research 
and Development Center 9805 Scranton Road San Diego, CA 92121-1765 1. ABSTRACT To integrate a CSG-based 
solid modeler into an exist-ing wireframe/surface modeling system, new boundary evaluation technology 
has been developed. This scheme uses exact representations for the simple quadric surfaces and both exact 
and approximate representations of higher-order curved surfaces. It supports parametric primitives (box, 
wedge, sphere, cylinder, cone, torus), pro- cedural primitives (extrusion, revolution, tube) and a sculptured 
surface primitive. The output includes curves, parametric trimmed surfaces, and a data structure of adja- 
cency information. An existing boundary evaluator (PADL-2's) has been enhanced to allow a general non-convex 
faceted primitive with planar and quadric facets. This new hybrid evaluator combines two techniques for 
curve/primitive classification. PADL-2's existing halfspace-based classification is reserved for the 
simple convex primitives, and a new ray firing based classification is applied to the non-convex primitives. 
After evaluation, approximate intersection curves (from intersections involving higher order surfaces) 
are refined to a specified tolerance by exploiting an exact parametric representation of the sur-faces 
of the primitives. The refined curves and the qua-dric surface intersection curves are used to create 
a parametric trimmed surface representation of the solid. This combination of techniques and representations 
offers advantages in accuracy, robustness and efficiency suitable to a production environment. CR Categories 
and Subject Descriptors: 1.3.5 [Com. puter Graphics]: Computational Geometry and Object Modeling--Curve, 
surface, solid and object representa-tions; Geometric algorithms, and systems; Modeling pack- ages. Key 
Words and Phrases: Computational geometry, Boolean set operations, solid modeling, boundary evalua-tion, 
constructive solid geometry, surface/surface intersec-tion, parametric surfaces, curve/primitive classification. 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169; 
1987 ACM-0-89791-227-6/87/007/0129 $00.75 2. INTRODUCTION A Constructive Solid Geometry (CSG) representation 
is used by many solid modelers to define solids [17,181. In this representation, complex solids are defined 
in terms of volumetric Boolean operations to be performed on simpler solid "primitives." A boundary representation 
(Brep) is a representation of a solid in terms of the bounding sur-faces, curves and vertices, together 
with adjacency rela-tionships. Boundary evaluation is the process which calcu- lates a boundary representation 
of a solid from its CSG representation. Additional information on boundary evaluation can be found in 
[3,5,9,15,16,25]. Although the algorithms which perform boundary evaluation are very complex, at a high 
level of abstraction the overall approach is "generate-and-test"; that is gen-erate a "sufficient set" 
of bounding geometry (surfaces and curves), then test (classify) each element of the sufficient set to 
see whether it lies on the boundary of the resulting solid. The set of surfaces belonging to the primitives 
is a sufficient set of surfaces, but the set of curves belonging to the primitives is not a sufficient 
set of curves; we need to add (some subset of) all possible surface/surface inter-sections between primitives. 
Thus, in its simplest form, a boundary evaluator needs to perform surface/surface intersection to generate 
curves and curve classification to determine which curves lie on the boundary of the result- ing solid, 
This outlines an approach common to many boundary evaluators [15]. Differences between evaluators occur 
in areas such as geometric coverage (allowed input), methods of classification, algorithms for surface 
intersec-tion, use of topological information, computational com-plexity reduction schemes, and so on. 
A survey of published work on boundary evaluation algorithms shows two distinct classes of boundary evalua-tors: 
faceted and analytical [15,17,18]. Faceted evaluators approximate solids with planar facets [4,5,6,9,14,25]. 
Evaluation is then performed on the resulting polyhedron. These types of evaluators accept as input any 
primitive which can be expressed or approximated by planar facets. A limitation of this technique is 
that the intersection curves for nonplanar surfaces are all approximate. Analyt-ical evaluators perform 
actual intersection between curved surfaces [2,3,8,15]. The curves which are created using this type 
of evaluator represent exact surface intersec-tions. However, input to these evaluators is usually lim-ited 
to primitive~ which can be represented as intersec-tions of quadric and simple higher order halfspaces. 
Ways of extending the geometric coverage of the analytical evaluators are under investigation[13,19]. 
~ SIGGRAPH '87, Anaheim, July 27-31, 1987 We have designed and implemented a hybrid boun-dary evaluator 
which produces intersection curves and accurate trimmed sQrfaces for simple quadric primitives and for 
certain procedural (revolved, extruded) and sculp- tured surface primitives. This has been accomplished 
using a two-stage boundary evaluator and a dual represen- tation of the surfaces of the solid primitives. 
The first stage of the process is referred to as "Boolean evaluation" and the second stage as "parametric 
surface trimming." The Boolean evaluator consists of an existing analytical boundary evaluator (PADL-2) 
[15] which has been enhanced by adding a ray firing-based classification pro-cedure to allow a general 
non-convex faceted primitive. The faceted primitive is a two-manifold representation [24] of a solid 
which allows both planar and quadric facets (cylindrical and conical). Quadric surfaces of faceted primitives 
are represented exactly, while other curved sur-faces are approximated with planar or quadric facets. 
The output of the Boolean evatuator is a boundary file which contains analytical curves, approximate 
curves, topological information, and references to the original primitives. Because the original analytical 
primitive definitions have been maintained outside the Boolean evaluator, a set of parametric surfaces 
can be created which exactly represent the surfaces of the primitives. These together with the output 
of the Boolean evaluator are used to create parametric trimmed surfaces (surfaces restricted to a closed 
bounded subset of the parameter space) [11]. A general iterative intersection technique uses the exact 
sur-faces to refine the approximate curves (generated from intersections involving higher order surfaces) 
to a given tolerance. The refined curves and the analytical curves are used to create curves in the parameter 
space of the sur-faces. Loops formed from these parametric curves define the parametric trimmed surface 
boundaries. The trimmed surfaces and existing adjacency information create a boun- dary representation 
which binds the trimmed surfaces together in an edge-based topology. 3. DESIGN OBJECTIVES The main rationale 
for the development of a boun-dary evaluator was to integrate solid modeling into an existing wireframe/surface 
modeler (Prism/DDM). Given a constructive solid geometry definition of a solid, the boun- dary evaluator 
should produce curves for the various curve applications (dimensioning and tolerancing, graphic display, 
design documentation, etc.) and parametric trimmed surfaces suitable for the surface applications (NC 
tool path generation, hidden line/surface removal, mass properties, filleting, etc.). A boundary representation 
which explicitly represents the various face/edge/vertex adjacency relationships would also be useful 
for automatic NC tool path generation algorithms on multiple surfaces, and for other applications, The 
solid modeler would then be able to provide input to a large number of existing applications, and would 
thus be a viable piece of an end-to-end production system rather than simply a conceptual design tool 
for producing graphic images. To accomplish this in a production system, the fol-lowing goals were specified: 
1) The curves produced should be analytical for at least the quadric surface (planar, cylindrical, conical, 
spherical) intersections. 2) The surfaces should be trimmed to user-specifiable tolerances that can practically 
be set tight enough for existing manual/automatic tool path generation algorithms. 3) The evaluator should 
allow as input parametric primitives (box, wedge, sphere, cylinder, cone, torus), procedural primitives 
(solid of extrusion, solid of revolution, tube) and sculptured surface primitives, 4) The boundary evaluator 
should be reliable enough to be used in a production environment. 5) The evaluator should be able to 
process models with as many as 5000 primitive faces. 6) The performance of the evaluator should be competitive 
with existing production evaluators. 4. PADL 2 OVERVIEW PADL-2 is a welt known solid modeling system 
developed with industrial and public resources by the Pro- duction Automation Project (PAP) at the University 
of Rochester, Rochester, New York. Calma Company was a participant in the PAP's Industrial Associates 
program. The decision to use the PADL-2 boundary evaluator as the basis of our Boolean evaluator gave 
us a reliable and robust set of boundary evaluation algorithms and geometric utilities [16]. The PADL-2 
boundary evaluator accepts as input primitives Which can be expressed as intersections of halfspaces. 
The quadric halfspaces supported by PADL-2 are planar, spherical, cylindrical and conical. There is also 
a toroidal halfspace, but it is not fully supported. PADL-2 fully supports box, wedge, cylinder, cone, 
and sphere primitives, and the latest version of PADL-2 contains a general halfspace primitive. With 
this, a user can define a primitive as the intersection of up to 100 of the halfspaces. The PADL-2 evaluator 
is an edge-based analytical evaluator. It requires two major geometric operations: surface/surface intersection 
and curve/primitive classification. The surface intersection is analytical. The intersection curves are 
classified with respect tO each primitive in a three-step process. First, a curve is inter-sected with 
the surface of the halfspace and divided into segments. Second, each segment is classified as inside/on/outside 
the halfspace by classifying a point on the segment with respect to the halfspace. Third, the results 
of the halfspace classification are combined to determine curve/primitive classification results. The 
classification of a segment with respect to a primitive is simplified by the constraint of convexity 
placed upon the input primitives [21]. The primitive classification results are propagated up the CSG 
tree using a set of Boolean combination rules [16] to determine the relationship of the curve to the 
resulting solid. If a curve lies on the boundary of the resulting solid, it is stored into the PADL-2 
boundary file. When evaluation is finished, the boundary file contains a list of surfaces and the 3-D 
curves associated with each. (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 5. Boolean Evaluation 
of Non-Convex Primitives We wanted to extend the geometric coverage of the PADL-2 boundary evaluator 
by removing the requirement of convexity. Many non-convex primitives could be expressed as Boolean combinations 
of convex primitives, but it may require a large number of convex primitives to represent or approximate 
a single non-convex primitive. Moreover, such an approach would not be practical for representing sculptured 
surface primitives. We considered keeping the existing algorithms and adding new geometric entities (halfspaces 
and curves) corresponding to the non-convex primitive types. That is, a halfspace definition would be 
created for surfaces of revolution, extrusion and the sculptured surface type, in much the same way that 
a toroidal halfspace is used in PADL-2 to represent a (non-convex) torus. It would then be necessary 
to add surface intersection capabilities for these surface types -- but that is not a simple task, because 
these intersections cannot be computed analytically. Using an iterative intersection algorithm for these 
new halfspace types would carry a stiff penalty in terms of performance and/or reliability. Our reluctance 
to introduce iterative techniques into the evaluator led to the decision to add a general non-convex 
faceted primitive and change the PADL-2 evaluation algo- rithms to accommodate it. Convexity is needed 
only for the PADL-2 curve/primitive classification. More general classification techniques are available 
for non-convex solids, but there is a price to be paid in performance and in complexity of implementation 
[3]. The geometric coverage requirement overrode the considerations of complexity. Thus we have implemented 
a more general curve/primitive classification technique, based on ray firing, for the new non-convex 
primitives. The simpler technique has been retained for the convex primitives to which it is suited. 
All non-convex primitives are represented by a closed set of planar or quadric surfaces. The rest of 
the boundary evaluation algorithms (surface/surface intersection, curve/surface intersection, propagation 
of results up the CSG tree) remain largely unchanged. 5.1. New Non-Convex Primitive The non-convex primitive 
is itself a boundary representation. The new primitive is defined by a closed set of facets (bounded 
surfaces). The facets are bound together by an edge-based topology. In our implementa-tion, three facet 
types were allowed: convex planar, convex quadric, and non-convex planar. Note that we have broadened 
the term "facet" to remove the restriction of planarity. The first type is a planar facet bounded by 
a convex three- or four- sided polygon. A set of these facets is used to approximate the free form surfaces 
and noncylindrical and nonplanar surfaces of the extrusion. The second facet type is a convex quadric 
facet bounded by four curves. Our implementation limits these curves to linear and circular arcs, as 
the only two quadric facets required were the cylindrical facet and the conical facet. These facets, 
along with the planar facets, allow the exact representation of extrusion surfaces defined by linear 
and circular arcs; other curve types in the boundary of the extruded region result in surfaces which 
are approximated with convex planar facets. Linear arcs in a revolution create surfaces w~hich are represented 
exactly by cylindrical and conical facets. Other curve types in the boundary of the revolved region result 
in surfaces which are approximated by cylindrical and conical facets. For example, a torus is approximated 
by a relatively small number of conical facets. To achieve roughly the same accuracy as 16 conical facets 
would require at least 256 planar facets. The third facet type is a planar facet bounded by an unlimited 
number of linear or circular arcs, with no requirement of convexity. In fact, the curves may form nested 
loops, representing a facet with holes. This facet type is used to represent the end planes of an extrusion, 
planar surfaces in a revolution, and the end caps of the skinned solid. With these three facet types 
it is possible to represent the quadric surfaces exactly and approximate the rest of the surfaces with 
either planar or quadric facets. Removing the requirement of convexity allows the representation of non-convex 
quadric primitives, without necessitating a Boolean combination of convex primitives. When non-quadric 
surfaces are approximated by a set of facets, these facets are treated as a single composite sur-face. 
No attempt is made to intersect two facets from the same surface. This is important in efficiently evaluating 
a primitive approximated by a large number of facets, such as the sculptured surface primitive. 5.2. 
Classification Method for Non-Convex Primitive Ray firing can be used to determine if a point lies inside/outside/on 
tile boundary of a non-convex faceted primitive. A ray is created starting at the point of interest and 
goes to effective infinity in some direction. This ray is intersected with all of the facets of the primitive, 
and the number of intersections are counted. If there is an odd number of intersections, the point lies 
inside the primi-tive. If the number is even or zero, the point lies outside the primitive. If the start 
point of the ray ties on a facet of the primitive, the point is on the primitive boundary. A major problem 
with using ray firing in this applica- tion is processing speed. Typically, a large number of curves 
need to be classified for even moderately sized models. A single curve may intersect a primitive a number 
of times, creating several segments; each segment requir- ing a ray to be fired. Each ray then has to 
be intersected with each facet of the primitive. A procedure which we refer to as local transition detection 
is used to reduce the number of ray/facet inter- sections and increase the efficiency of the ray firing 
algo- rithm [3]. Local transition detection determines an in/out/on classification using information 
available at a single intersection point. The classification is determined by comparing the curve-tangents 
at the intersection point to the outward pointing normal of the facet at that point. If the tangent of 
the curve is in the same direction as the normal (dot product of tangent and normal greater then zero), 
then the curve segment is going out of the primitive. Special processing is required for cases where 
the curve ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 just touches the surface. In our implementation, 
this prob- lem was solved by stepping away from the intersection a small distance along the curve and 
recomputing the tangents on either side of the intersection, lfa curve goes through an curve or a vertex 
rather than through the inte- rior of the facet, the surface normals of facets adjacent to the curve 
or vertex are required for the transition detec- tion. When a curve intersects a facet of a primitive, 
local transition detection can be used to determine which por- tions of it are inside/outside/on the 
primitive. Therefore, only curves which do not intersect the primitive require ray firing. Two additional 
classification functions are used to apply ray firing to the bounded facets of the new primi-tive. A 
point-in-facet function determines ira point on the surface of a facet lies inside/outside/on the curves 
of the facet. An curve-in-facet function is also required to deter- mine which portions of a curve, lying 
on the surface of a facet, lie inside/outside/on the curves of the facet. These functions are simple 
for the convex facets; a set of planes is constructed which bounds the facet on the surface, using the 
fact that all bounding curves are planar. Existing halfspace classification functions are then used to 
classify the point or curve with respect to the facet [21]. The non-convex planar facet requires a special 
2-D processor in which the facet is bounded by curves rather than halfspaces. This processor is based 
on 2-D ray firing with 2-D local transition detection [23]. The performance of this evaluation scheme 
is improved using several well known techniques (spatial sorting, bounding box tests, etc.) to decrease 
both the number of surface/surface intersections during curve gen-eration and the number of facet/curve 
intersections dur- ing classification [7,20]. Without these techniques, this approach to boundary evaluation 
would be impractical for all but the simplest of models. 6. Parametric Surface Trimming The Boolean 
evaluator produces curves and some adjacency information referencing the surfaces of the primitives. 
For our applications, this information does not constitute a trimmed surface representation. Our trimmed 
surface is a parametric surface restricted to a closed bounded region of its 2-D parameter space. The 
2-D region is defined by closed oriented loops in parameter space. To obtain the parameter space loops 
we first obtain the model space loops. Edge chasing is the process of connecting the model space curves 
into loops, orienting the curves within the loops, and determining the relative loop containment. Up 
to this point the primitives have been represented by implicit surfaces and faceted approxi- mations. 
The next step is to create the corresponding exact parametric surfaces using the original primitive definition. 
A representation of each model space curve in the parameter space of its incident surfaces is derived 
using projection along surface normals. At this stage the approximated model space curves, from intersections 
involving approximated surfaces, are refined by exploiting the exact surface representation. The parameter 
space loops defined by these curves along with the parametric surface definition constitute our trimmed 
surface representation. This approach has an advantage over repatching in that it does not alter the 
original surface definition [19]. The trimmed surfaces are joined together using the adjacency data carried 
over from the Boolean evaluator to create our boundary representation of a solid. 6.1. Edge chasing At 
this point the boundary representation contains an unordered list of pointers to the curves bounding 
each surface. Seams are added to the list of curves bounding each closed surface, so that the model space 
loops formed from these curves will correspond to closed loops in the parameter spaces of the surfaces. 
Tolerance based com-parisons of the endpoints of the curves associated with a surface are used to connect 
the curves into loops. The loops are then nested to differentiate between outer boun- daries and holes 
of a surface, using a 2-D counterpart of the ray firing technique already discussed. Outer boun-daries 
are oriented clockwise, inner boundaries counter-clockwise, to maintain the convention that the part 
of the surface that is kept lies to the right of the boundary. 6.2. Parametric surface creation Many 
surfaces of primitives in the original CSG model will not contribute to the evaluated representation. 
Other surfaces will appear in disjoint pieces, and multiple sur-faces will have to be created, one for 
each piece. The information gained from edge chasing indicates how many copies of each surface need to 
be created. The parameters and positional information defining the parametric surface are extracted from 
the original CSG primitive definition. The normal direction of each surface is obtained from its dual 
in the Boolean evaluator; this allows us to expect that model space and parameter space loops will have 
the same orientation. The properly oriented surfaces are created and stored in the model database.  
6.3. Projection The role of surface projection is to find the parameter space representation of the curves 
that will bound each trimmed surface. For curves arising from intersections of simple surfaces, this 
could be done algebraically, but such an approach does not readily extend to all of the curves and surfaces 
which we support. An iterative algorithm based on Newton's method is used to project a sampling of points 
from each curve along surface normals [12]. A chord height test, using a user-specifiable tolerance, 
deter- mines the density of the sampling. The resulting parame- ter space points are then used to create 
a curve which is an approximate parameter space representation of the ori- ginal model space curve. The 
most important requirement of the trimmed sur-face boundaries is that adjacent surfaces actually meet 
in model space; i.e., that intersection curves are accurateJy represented by parameter space curves. 
Gaps occur when the images of one or both of the parameter space curves representing an intersection 
differ from the actual inter-section curve. For quadric surfaces, the Boolean evaluator obtains the actual 
analytical intersection curves, so any gaps in the trimmed surfaces will have been introduced by projection. 
The projection tolerance allows the user to specify an upper limit to the gap size relevant to the intended 
application. (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 6.4. Refinement of Approximated 
Curves Intersections involving more advanced surfaces intro- duce a new difficulty. The trimmed surface 
boundary can-not be guaranteed to be any more accurate than the curve from Boolean evaluation, and in 
these cases the curve is only as accurate as the chord height allowed by the sur-face tessellation parameters. 
The resulting gaps may be unacceptable for many applications. One way to increase the accuracy of the 
original curve is to re-evaluate with a reduced surface tessellation tolerance, greatly increasing the 
number of facets, thus lowering the performance and even stretching the limits of capacity of the evaluator. 
The dual representation of surfaces allows the refinement of approximate curves without re-evaluation 
at a higher reso-lution. The ideal result of boundary evaluation would include exact surface intersection 
curves and their exact representations in the parameter spaces of the surfaces. This method has achieved 
exact intersections for the sim- ple quadrics, and accurate if not exact parameter space curves; however, 
by itself, the projection algorithm cannot give accurate parameter space intersection curves if the model 
space curve it begins with is inaccurate. To refine the approximated curves and simultaneously generate 
accurate parameter space representations of the refined curves, an iterative surface intersection algorithm 
is applied [12]. This provides point sets to define the two parameter space curves and the model space 
curve. By guiding the intersection using the approximate curve from the Boolean evaluator, the "hunting 
phase" is unnecessary and the "tracing phase" is simplified. The resulting model space and parameter 
space curves are still approximations, but the tolerance value of the intersection may be orders of magnitude 
finer than the surface tessellation tolerance that first captured the intersection. Figures 1 through 
4 illustrate the success of this technique. Figure 2. Intersection curves of primitive surfaces before 
and after curve refinement. Figure 3. Example of gaps between trimmed surfaces in absence of curve refinement. 
 Figure 1. CSG wireframe display of sculptured primi- Figure 4. Boundary representation og torus sub- 
tive and torus. tracted from sculptured primitive. 133 ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 Applying 
this algorithm to adjacent curves of an approximated surface may pull those curves away from their common 
endpoint (figure 5). To prevent this, the approximate position of the vertex should be refined first 
(using a three-surface intersection with the common end-point of the incident approximated curves as 
a starting guess). Driven by constraints of time to a simpler approach, we found that we could clip or 
extend the refined parameter space curves to common endpoints without the vertex i'efinement preprocess, 
No effort has been made to implement a corresponding correction for the refined model space curves. Figure 
5. A detail from figure 2. The refined curves may tend to pull away from common verticies. The curve 
refinement technique cannot correct topo-logical errors caused by specifying tessellation values that 
are too coarse to capture the topology correctly. Also, the iterative technique may fail to attain its 
tolerances for completion within a maximum number of steps, particularly when adjacent surface normals 
are near-parallel along the intersection. Such failures can be detected, and the original coarse approximation 
used instead. Note that in the absence of such problems, the Boolean evaluator has only to approximate 
tessellated sur- faces to an accuracy sufficient to correctly capture the topology of the solid boundary 
in order for accurate trimmed surfaces to be produced. The parameter space curves are joined into loops 
according to the topology of their model space duals as derived from edge chasing. The loops can be tested 
for orientation, connectedness and disjointedness, each a test of the correctness of the final result. 
The parameter space loops are then stored with their original surfaces as parametric trimmed surfaces. 
The DDM/Prism system can use these surfaces in a variety of ways. The adjacency information is also stored, 
to simplify automatic NC tool path generation across multiple sur-faces. Work is in progress to expand 
the usefulness of this data. 7. Conclusion We believe that our approach to boundary evaluation is unique 
in several ways. The "hybrid" nature of this evaluation scheme provides both the geometric coverage of 
a faceted evaluator and the intersection capabilities of an analytical approach. To the best of our knowledge, 
it is the first evaluator to combine halfspace based classification for simple convex primitives with 
ray firing for non-convex primitives, yielding both performance and geometric coverage suitable to a 
production environment. The dual surface representation and curve refinement make it possible to create 
an accurate parametric trimmed surface representation of a CSG model. The main ideas discussed here have 
been implemented in a modeling sys- tem which we believe represents a significant advance-ment toward 
the complete integration of solids modeling into a concept-to-manufacturing CAD/CAM/CAE system. 8. Future 
Research It may be possible to extend these ideas and algo-rithms to allow incremental boundary evaluation 
for solids represented by quadric surfaces. For example, it should be possible to extend tile idea of 
non-convex planar facets to curved surfaces. Analytical intersection and inversion of certain higher 
order surfaces (toroidal, extruded, revolved) is also of great interest. Techniques to improve perfor- 
mance and capacity warrant investigation in any commer-cial CAD/CAM system. 9. Results Tests on a variety 
of models have demonstrated the suitability of this boundary evaluator in terms of reliabil- ity, capacity 
and performance, to a production environ-ment. This evatuator has been in actual production use for a 
number of months in Calma Company's Prism/DDM CAD/CAM/CAE system. Figures 6 through 8 represent a cross 
section of the test results. The shaded images are generated directly from the CSG model using Calma 
Company's proprietary scanline based CSG rendering algo- rithm. 10. Acknowledgements The boundary evaluator 
development team also included Kathleen Busker, Nga Dang, James Jou, Russell LaPuma, and Ted Valencia. 
Thanks also to Pierre Mal-raison, Thomas Check, Semyon Nisenzon and Pete Noel. Special thanks are due 
to Robert Smith for contributions to many of the ideas discussed here and for his encouragement and support. 
 "~ SIGGRAPH '87, Anaheim, July 27-31, 1987 BIBLIOGRAPHY [1} Baumgart B.G., "Geometric Modeling for 
Computer Vision," rep, STAN-CS-74-463, Stanford Artificial Intelli-gence Lab., Stanford Univ., Stanford, 
CA 1974. [2] Boyse, J.W., Gilchrist J.E., "GMSolid: Interactive Modeling for Design and Analysis of Solids," 
IEEE Computer Graph- ics and Applications, Vol. 2, No 2, pp. 27-40, Mar. 1982. [3] Braid, l.C., "The 
Synthesis of Solids Bounded by Many Faces," Communications of the ACM, Vol. 18, No. 4, April 1975, pp. 
209-216. [4] Carlson, W.E., "An Algorithm and Data Structures for 3D Object Synthesis Using Surface Patch 
Intersections," ACM Computer Graphics, Vol. 16, No. 3, July 1982, pp. 255-263. 15] Eastman C.M., Yessios 
C.J., "An Efficient Algorithm for Finding the Union, Intersection, and Differences of Spatial Domains," 
Tech. Rep 31, Institute of Physical Planning, Carnegie-Mellon Univ., Pittsburgh, PA. Sept. 1972. [6] 
Franklin, W.R., "Efficient Polyhedron Intersection and Union," Proc. Graphics Interface '82, (Toronto, 
Canada, May 17-21, 1982), pp. 73-80. [7] Glassner, A.S., "Space Subdivision for Fast Ray Tracing," IEEE 
Computer Graphics and Applications, Vot. 4, No. 10, October 1984, pp. 15-22. [8] Hillyard R.C,, "The 
Build Group of Solid Modelers," 1EEE Computer Graphics and Applications, Vol. 2, No. 2, March 1982, pp. 
43-52. [9] Katay Y.E., Eastman, C.M., "Shape Operations: An Algo- rithm for Spatial-Set Manipulations 
of Solid Objects," CAD Graphics Lab., Carnegie-Mellon Univ., Pittsburgh, PA, July 1980. [10] Lee Y.T., 
Requicha, A.A.G., "Algorithms for Computing the Volume and Other Integral Properties of Solids. I. Known 
Methods and Open Issues," Communications of the ACM, Vol. 25, No. 9, September 1982, pp. 635-641. [11] 
Miller, J.R., "Sculptured Surfaces in Solid Models: Issues and Alternative Approaches," IEEE Computer 
Graph- ics and Applications, Vol. 6, No. 12, December 1986, pp. 37-48. [12] Mortenson, Michael E. Geometric 
Modeling. John Wiley &#38; Sons, New York, 1985, ch. 6. [13] Pfeifer, H., "Methods used for Intersecting 
Geometrical Entities in the GMP Module for Volume Geometry," Computer-Aided Desion, Vol. 17, No. 7, September 
1985, pp. 311-318. [14] Putnam, L.K., Subrahmanyam, P.A., "Computation of the Union, Intersection and 
Difference of n-dimensional Objects via Boundary Classification," Department of Com- puter Science, University 
of Utah, Salt Lake City, UT, 1982. [15t Requicha, A.A.G., Voelcker, H.B., "Boolean Operations in Solid 
Modeling: Boundary Evaluation and Merging Algo- rithms," Proceedings of the IEEE, Vol, 73, No. 1, January 
1985, pp. 30-44 [16] Requicha, A.A.G., Voetcker, H.B., "Boolean Operations in Solid Modeling: Boundary 
Evaluation and Merging Algo- rithms," Tech. Memo. 26, Production Automation Project, Univ, of Rochester, 
Rochester, NY, Jan 1984. [17] Requicha, A.A.G., Voelcker, H.B., "Solid Modeling: A His- torical Summary 
and Contemporary Assessment," IEEE Computer Graphics and Applications, Vol. 2, No. 2, March 1982, pp. 
9-24. !18] Requicha, A.A.G., Voelcker, H.B., "Solid Modeling: Current Status and Research Directions," 
IEEE Computer Graphics and Applications, Vol. 3, No. 7, October 1983, pp. 25-37. [19] Sarraga, R.F., 
Waters, W.C., "Free-Form Surfaces in GMSolid: Goals and issues," Solid Modeling by Computers. Plenum 
Press, New York, 1984, pp. 187-210. [20] Tilove, R.B., "Exploiting Spatial and Structural Locality in 
Geometric Modeling," Tech. Memo. 38, Production Auto- mation Project, Univ. of Rochester, Rochester, 
NY, October 198t. [21] Tilove, R.B., "Set Membership Classification: A Unified Approach to Geometric 
Intersection Problems," IEEE Tran- sactions on Computers, Vol. C-29, No. 10, October 1980, pp. 874-883. 
122] Tilove, R.B., Requicha, A.A.G, "Closure of Boolean Operations on Geometric Entities," Computer-Aided 
Des., Vot. 12, No. 5, September 1980, pp. 219-220, [23] Weiler, K., "Polygon Comparison Using a Graph 
Representation," ACM Computer Graphics, Vol 14, No 3, July 1980, pp. 10-18. [24] Weiler, K., "Edge-Based 
Data Structures for Solid Modeling in Curved-Surface Modeling Environments," IEEE Computer Graphics and 
Applications, Vol. 5, No. 1, January 1985, pp. 21-40. [25] Yamaguchi, F., Tokieda, T., "A Unified Algorithm 
for Boolean Shape Operations," IEEE Computer Graphics and Applications, Vol. 4, No 6, pp. 24-37, June 
1984. t36   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37419</article_id>
		<sort_key>137</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Discrete Beta-splines]]></title>
		<page_from>137</page_from>
		<page_to>144</page_to>
		<doi_number>10.1145/37401.37419</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37419</url>
		<abstract>
			<par><![CDATA[Goodman (1985) and Joe (1986) have given explicit formulas for (cubic) Beta-splines on uniform knot sequences with varying &amp;szlig;1 and &amp;szlig;2 values at the knots, and nonuniform knot sequences with varying &amp;szlig;2 values at the knots, respectively. The advantage of the latter formula is that it can also be used for knot sequences with multiple knots. Discrete Beta-splines arise when a Beta-spline curve is subdivided, i.e. the knot sequence is refined so that the curve is expressed in terms of a larger number of control vertices and Beta-splines. We prove that discrete Beta-splines satisfy the same properties as discrete B-splines, and present an algorithm for computing discrete Beta-splines and the new control vertices using the explicit formula of Joe (1986).]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
			<gt>Verification</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P28031</person_id>
				<author_profile_id><![CDATA[81100288378]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Barry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Joe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Univ. of Alberta, Edmonton, Alberta, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B. A. Barsky (1981), The Beta-sptine: a local representation based on shape parameters and fundamental geometric measures, Ph.D. Dissertation, Dept. of CompUter Science, Univ. of Utah.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357321</ref_obj_id>
				<ref_obj_pid>357318</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[B. A. Barsky and J. C. Beatty (1983), Local control of bias and tension in Beta-splines, ACM Transactions on Graphics, 2, pp. 109-134.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>43406</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[B. A. Barsky (1986), Computer Graphics and Geometric Modelling Using Beta-splines, Springer-Verlag, Tokyo.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R. H. Barrels and J. C. Beatty (1984), Beta-splines with a difference, Technical Report CS-83-40, Dept. of Computer Science, Univ. of Waterloo.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>26962</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. H. Bartels, J. C. Beatty, and B. A. Barsky (1987), An Introduction to the Use of Splines in Computer Graphics, to be published by Morgan Kaufman Publishers, Los Altos, Califor- Ilia.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[W. Boehm (1980), Inserting new knots into B-spline curves, Computer-AidedDesign, 12, pp. 199-201.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[W. Boehm and H. Prautzsch (1985), The insertion algorithm, Computer-AidedDesign, 17, pp. 58-59.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>5102</ref_obj_id>
				<ref_obj_pid>5096</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[W. Boehm (1985), Curvature continuous curves and surface~, Computer Aided Geometric Design, 2, pp. 313-323.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[E. Cohen, T. Lyche, and R. Riesenfeld (1980), Discrete B-splines and subdivision techniques in computer-aided geometric design and computer graphics, Computer Graphics and Image Processing, 14, pp. 87-111.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[G. Farin (1982), Visually C 2 cubic splines, Computer-Aided Design, 14, pp. 137-139.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>5103</ref_obj_id>
				<ref_obj_pid>5096</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[G. Farin (1985), Some remarks on V2-splines, Computer Aided Geometric Design, 2, pp. 325-328.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[T. N. T. Goodman (1985), Properties of Beta-splines, J. Approximation Theory, 44, pp. 132-153.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[T. N. T. Goodman and K. Unsworth (1985), Generation of Betaspline curves using a recurrence relation, in Fundamental Algorithms for Computer Graphics, Springer-Vedag, Berlin, pp. 325-357.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[T. N. T. Goodman and K. Unsworth (1986), Manipulating shape and producing geometric continuity in Beta-spline curves, IEEE Computer Graphics and Applications, 6, No. 2, pp. 50-56.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[B. Joe (1986), An explicit formula for nonuniform Beta-splines, Technical Report TR86-21, Dept. of Computing Science, Univ. of Alberta.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[B. Joe (1987), Rational Beta-spline curves and surfaces and discrete Beta-splines, Technical Report TR87-04, Dept. of Computing Science, Univ. of Alberta.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>13164</ref_obj_id>
				<ref_obj_pid>13152</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[T. Lyche and K. Morken (1986), Making the Oslo algorithm more efficient, SIAM J. Numer. Anal., 23, pp. 663-675.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[H. Prautzsch (1984), A short proof of the Oslo algorithm, Computer Aided Geometric Design, 1, pp. 95-96.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[H. Prautzsch (1985), Letter to the editor, Computer Aided Geometric Design, 2, p. 329.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[G. W. Stewart (1973), Introduction to Matrix Computations, Academic Press, New York.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~) ~ Computer Graphics, Volume 21, Number 4, July 1987 Discrete Beta-Splines Barry Joe Department of 
Computing Science University of Alberta Edmonton, Alberta, Canada T6G 2H1 Abstract Goodman (1985) and 
Joe (1986) have given explicit formulas for (cubic) Beta-splines on uniform knot sequences with varying 
~1 and ~2 values at the knots, and nonuniform knot sequences with varying [~2 values at the knots, respectively. 
The advantage of the latter formula is that it can also be used for knot sequences with multiple knots. 
Discrete Beta-splines arise when a Beta-spline curve is subdivided, i.e. the knot sequence is refined 
so that the curve is expressed in terms of a larger number of control vertices and Beta-splines. We prove 
that discrete Beta-splines satisfy the same properties as discrete B-splines, and present an algorithm 
for computing discrete Beta-splines and the new control vertices using the explicit formula of Joe (1986). 
CR Categories and Subject Descriptors: 1.3.5 [Computer Graph|es]: Computational Geometry and Object Modeling 
- Curve, surface, solid, and object representations Additional Key Words and Phrases: B-splines, subdivision, 
knot refinement, geometric continuity, computer-aided geometric design 1. Introduction B-splines, discrete 
B-splines, and subdivision techniques are used in computer-aided geometric design and computer graphics 
for designing free-form curves and surfaces. B-spline curves can be described as weighted averages of 
control vertices, in which B- splines are taken as the weighting functions. The shape of the curve approximates 
the control polygon, which is formed by con- necting consecutive control vertices by line segments. The 
subdi- vision problem for a B-spline curve is to express the curve in terms of a larger number of control 
vertices and B-spline weighting func- tions. The reasons for subdivision are (a) to allow a more local 
change to the B-spline curve (moving a new control vertex affects a smaller part of the curve than moving 
an original control vertex), (b) to split the B-spline curve into two separate pieces which are represented 
in a similar form, and (c) to use the new control polygon as a good approximation to the B-spline curve 
when the number of new control vertices is sufficiently large. Permission to copy without fee all or 
part of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM copyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permission of the Association ['or Computing Machinery. To copy otherwise, 
or to republish, requires a fee and/or specific permission. &#38;#169; 1987 ACM-0-89791-227-6/87/007/0137 
$00.75 Discrete B-splines are used to express the new control ver- tices in terms of the original control 
vertices, and to express the original B-splines in terms of the new B-splines which are defined on a 
refined knot sequence. Cohen, Lyche, and Riesenfeld (1980) have presented the theory of discrete B-splines 
and the Oslo algo- rithm for computing the discrete B-splines and new control vertices using a recurrence 
relation. Lyche and Morken (1986) recently gave an improved version of the Oslo algorithm. An alternative 
way to compute the new control vertices, based on inserting one new knot at a time, was given by Boehm 
(1980) and Boehm and Prautzsch (1985). Barsky (1981) introduced (cubic) Beta-splines as a generali- zation 
of cubic B-splines. They provide a means of constructing parametric spline curves in which the shape 
of a curve is controlled by bias parameter [~t and tension parameter ~2. A cubic B-spline curve has second 
degree parametric continuity while a Beta-spline curve has second degree geometric continuity, i.e. continuity 
of the curve, the unit tangent vector, and the curvature vector. Barsky (1981) used a uniform knot sequence 
and constant 131 and 152 values at all knots or joints of the curve, and introduced the exten- sion to 
varying 151 and [32 values at the joints to provide local con- trol of bias and tension in the curve. 
This resulted in the paper of Barsky and Beatty (1983) in which quintic Hermite interpolation is used 
to give continuous [31 and 152 values throughout the curve. Recently, Bartels and Beatty (1984) and Goodman 
(1985) have extended Beta-splines to nonuniform knot sequences and varying ~1 and 1~2 values at the knots 
without using interpolation. Goodman (1985) has shown that these more general Beta- splines satisfy the 
local support, convex hull, and variation-diminishing properties, and gave an explicit formula for these 
Beta-splines on a uniform knot sequence. Goodman and Unsworth (1986) described the effects on the Beta-spline 
curve when ~1 and [~2 values at the knots are varied. Joe (1986) gave an alternative explicit formula 
for these Beta-splines on a nonuniform knot sequence with constant [St = 1 and varying [~2 values at 
the knots. For distinct knot sequences, these two formulas are equivalent since it is possible to transform 
between the two knot sequences by appropriately changing the 131 and ~2 values at the knots. The advantage 
of the latter formula is that it can also be used for knot sequences with multiple knots. The books by 
Barsky (1986) and Bartels, Beatty, and Barsky (1987) provide background information on the above topics. 
The papers by Farin (1982), Farin (1985), and Boehm (1985) describe other ways to construct curvature 
continuous cubic spline curves. Boehm (1985) also gave a geometric approach for the insertion of a new 
knot. Discrete Beta-splines are analogous to discrete B-splines, i.e. they arise in the subdivision of 
Beta-spline curves. Subdivision of a Beta-spline curve allows ,a more local change to the curve by  
 ~~ SIGGRAPH '87, Anaheim, July 27-31, 1987 modifying a new bias or tension parameter as well as moving 
a new control vertex. In Section 2, notation and definitions are given. In Section 3, we prove that discrete 
Beta-splines satisfy the same properties as discrete B-splines. In Section 4, we present an algorithm 
for computing discrete Beta-splines and the new control vertices using the explicit formula of Joe (1986). 
In Section 5, we give examples of refined control polygons obtained from this algo- rithm. 2. Notation 
and definitions Let to <_tl < _ - " <_tin+ 4 be a sequence of knots in which no knot has multiplicity 
greater than four. Let 131 i = 1 and [~21 _>0 be the bias and tension parameter at t i, 1 <i _<m+3, and 
h i =t i --ti_t, I <i <m+4. There is no loss of generality in assuming [~l i = 1 for all i, since any 
distinct knot sequence with varying 131 and [52 values at the knots can be linearly transformed to a 
different nonuniform distinct sequence with constant 61 = 1 and different 1t2 values. An effect similar 
to bias can be obtained by varying the spacing between knots. Let F i (t) be the Beta-spline with nonzero 
support on the interval [ t i , ti+ 4 ], 0 <_<_ i < m. The explicit formula of Joe (1986) for the Fi(t 
) is as follows (any term with a zero denominator has a zero value). Let Wi =~2ihlhi+t/[2(hi +h~+l)], 
1 ~i _<m+3 (2.1) ~i =hi4-hi+l+hi+2+ ~li(hi+l+hi+2)+ Xlli+l(hi+hi+l) + XlliXlli+lhi+l, 1 <i <m+2. Si,l(t 
)=di,lu 3, u =(t-tl)lhi+ I, t i <t < ti+ 1 s i 2(t ) = a i,2÷bi,2 u 4-c i ,2 u 2+d i 2u 3 u = (t -t i+l)/hi+2, 
 ti+l <t <ti+2 Fi(t)= "£i ,3( t ) = ai ,3+bi,3 u 4-ci ,3 u 24-di ,3 u 3, u = ( t i +3-t )/hi+3, (2.2) 
ti+2 <_t ,~ ti+ 3 sl.4(t)=di,4u 3, u ~--(ti+4-t)/hi+ 4, ti+3<-t <" ti+ 4 0, otherwise where di,l= ai,2 
= ( I + ~tfi+2)hi21 / [~i+l(hi+; 4- hi+2)] (2.3) hi, 2 = 3( 1 + xlfi+2)hi+lhi+2/ [ddi+l(hi+ 1 + hi+2)] 
ci2 = 3(1 + qli+2)hi+2[hi+21(hi+l + hi+z) + xl/i+ t ]/dPi+ I d i 2. =-( 1 + Igi+3)hi2+2 / [~i+2(hi+2 
+ hi+3)] - hi+2[( 1 + Ig i+2) (hi +2/(hi+l + hi+2) + I[/i +1) + ( 1 + Igi+l)(hi+2/(hi+ 2 + hi+3) + lgi+2)]/ddi 
+l di ,4 = ai,3 = (1 + ¥i+2)hi2+4 / [¢i+2(hi+3 + hi+n)] bi ,3 = 3( 1 + Igi +2)hi +3hi+4/ [d# i +2( hi+ 
3 4-hi+n) ] ci,3 = 3( 1 + xgi+2)hi+3[hi+3/(hi+3 + hi+4) + ill i +3]/ddi+2 di ,3 =-(1 + ~i+l)hi2+31 l~i+l 
(hi+2 + hi+3)] - ¢ hi+3[ ( 1 4- llli+2)(hi+31(hi+ 3 4- hi+n) 4- Xgi+ 3) + (1 + Xlli+3)(hi+31(h i+2 + 
hi+3) + q//+2)]/~i+2" The geometric, continuity conditions satisfied by F i (t) are as follows. Let p 
be the multiplicity of knot tj, i <_j <_i+4, in the sequence ti,t~+l,'",ti+4. If p=l then (a) Fi(tj--)=Fi(t:), 
(b) t ---I F i (tj)-F i (tj+), and (c) Fi"(tT)4-~2jFi'(tT)--Fi"(t~). If p =2 then only conditions (a) 
and (b) are satisfied, and (c) is not satisfied. Ifp =3 then only condition (a) is satisfied, and (b) 
is not satisfied. Ifp =4 then condition (a) is not satisfied. Goodman (1985) showed that the Fi(t ) are 
linearly indepen- dent and satisfy the convex hull property. The Fi(t ) also satisfy the reflection symmetry 
property : if the knots are negated to get --_tin+ 4 <-- --tin+ 3 <-- " " " <----t 0 with tension parameter 
~2 i at --t i , and Fi(t) is the Beta-spline with nonzero support on the interval [-ti+n,-t i ], then 
E(-t )=Fi(t ). A Beta-spline curve is defined by nt Q(t)= ~ViFi(t), t3 <<-t < tin+ 1 (2.4) i--o where 
the V i are two- or three-dimensional control vertices. If the tension parameters 132i are set to zero 
at all knots, then Q (t) reduces to a cubic B-spline curve. Q (t) does not depend on h 1, hm+n, [~21, 
and [~2m+ 3. In general, at a double (triple, quadruple, respectively) knot t i, the curve Q(t) has only 
first degree geometric continuity (only continuity, no continuity, respectively). In general, at all 
simple knots and non-knot values, Q(t) has second degree geometric continuity, i.e. it has position, 
unit tangent vector, and curvature vector continuity. Exceptions to these geometric continuity conditions 
may occur for a few configurations of control vertices (Goodman and Unsworth (1986)). The shape of the 
curve can be controlled locally by changing a control vertex, a tension parameter, or a spacing between 
two knots. For subdivision of the Beta-spline curve, the knot sequence is refined and new Beta-splines 
and control vertices are obtained. Let Uo<-Ut < . <un+ 4, n >_.m, be a refined sequence of knots such 
that no knot has multiplicity greater than four, u 0 = t 0, u, +4 = t,,,+4, and for all i, ti=U j for 
some j. Let I~=uj-uj_ l, l<j<n+4, and let [~2) be the tension parameter at uj, 1 <j <n+3. lfuj is one 
of the n -m new knots, then [~2j =0, otherwise ~2j has the same tension value as the corresponding knot 
in the t i sequence. If the multiplicity of a knot in the t i sequence has been increased in the ~29 
equence, then it does not matter how the tension parameters are assigned to these multiple knots since 
the tension at a mul- tiple knot t i is effectively zero by (2.1) (because ag i =0). Let Gj(t), O<j <_'n, 
be the Beta-splines defined on the refined knot sequence. The coefficients, segment polynomials, and 
other variables associated with the Gj(t) are similar to those for the Fi(t), and will be denoted using 
variables with hats, e.g.d./~, t~, k, dj~, d:~, s'j,z, ~tj, ~/. The Beta-spline curve Q(t) can also be 
represented as O(t)= ~WjGj(t), t3<_t ~ tin+ 1 (2.5) where the W) are the new (refined) control vertices. 
If new knots are added in the subinterval [ t o, t 3 ] or [ tin+ 1, tin+ 4 ], then Gj (t) = 0 in the 
interval [ t3, tin+ 1 ) for j < L and j > U, where L > 0 is the number of new knots added in [ t o, t3] 
and n -U _>0 is the number of new knots added in [ tin+l, tin+ 4 ]. So it may appear that it is use- 
less to add knots in these two subintervals, but these knots must be added if it is desired to get a 
closer approximation to the cur~e at its two ends (see figures in Section 5). The new control polygon 
contains the vertices Wt.,"',Wv, since the Wj for j <L and j > U do not contribute to (2.5). Since the 
space of functions spanned by the Fi(t ) is a sub- space of that spanned by the Gj(t) (Goodman (1985), 
Prautzseh (1984,1985)), n Fi(t)= ~_~cqQ')Gj(t) fori =O,'",m (2.6) G ,i~ Computer Graphics, Volume 21, 
Number 4, July 1987 for some constants t~ i (j) called discrete Beta-splines. Substituting (2.6) into 
(2.4) results in ~V i ~_~Ot, i(j)Gj(t)= O~i(j)V i Gj(t). (2.7) i =o j=o j =o By comparing the coefficients 
of Gj(t) in (2.5) and (2.7), and using the linear independence of the Gj(t), Wj = ~,t~i(j)V i forj =0," 
" ,n. (2.8) i=0 3. Properties of discrete Beta-splines In this section, we prove that the discrete Beta-splines 
ct i (j) satisfy the same properties as discrete (cubic) B-splines. To sim- plify the proof, we add three 
arbitrary knots at the beginning and end of both knots sequences, so that the t i sequence becomes t_ 
3 < t_ 2 < t_ I < t o < " " < tra+4 < tin+ 5 < tin+ 6 < tin+7, and u i = t i for i =-3, -2, -1 and u~+ 
i =t~+i for i =5, 6, 7. The tension parame- ters at these six additional knots as well as t o and tin+ 
4 can be arbi- trarily set to zero. With these additional knots, (2.6) becomes n+3 El(t)= ~ o~i(j)Gj(t 
) fori=-3,-" ,m+3. (3.1) j~3 The properties satisfied by the discrete Beta-splines are: m+3 (1) ~ (xi(j) 
= 1 for j =-3,  ,n+3. i~3  (2) For each index i, (xi(j')=0 for all j<~i) and for all j > 8(i), where 
~(i) and ~(i) are defined below. For each index j, there are at most four indices i such that cti(j) 
;~0. (3) cqG) >0 for all i, j.  The proof of property (1) is the same as for discrete B-splines. From 
the convex hull property of Beta-splines, m+3 Fi(t)= 1, to<_t <.t,n+4 (3.2) i~3 n+3 )-', Gj(t)= 1 , to<-t 
<-tin+ 4. (3.3) j~3 Substituting (3.1) into (3.2) results in m+3 n+3 n+3 rm÷3 ] ~_~ ~_, txiO')Gj(t)=j~3[i~3oti(j)JGj(t)=l, 
(3.4) i~3 j~3 to <_t <-tin+ 4 By comparing the coefficients of Gj (t) in (3.3) and (3.4), and using the 
linear independence of the Gj (t), property (1) is obtained. Now we show when ~i(j') is zero, first for 
fixed index i and then for fixed index j. From (3.1) and the linear independence of the Gj(t), cq(j)=0 
if the nonzero part of Gj(t) is partially outside interval [ti,ti+4] (where Fi(t) is nonzero), i.e. if 
uj<t i or uj+ 4 > ti+ 4. In addition, it is possible that ctl (j) = 0 if uj = ti and uj is a multiple 
knot or uj+4=ti+ 4 and uj+ 4 is a multiple knot. Letp and q be the integers such that t i = ti+p_ 1 < 
ti+ p and ti+4-q < ti+5--¢ = ti+4 (note that 1 <p, q -4). Suppose t i =uj < uj+n<ti+4 and uj =uj+t,. 
Then Gj(t) has a lower degree of geometric continuity at uj than Fi(t ) has at t i, hence ct~(/')=0 (if 
ct i (j) ¢ 0 then F i (t) has a higher degree of geometric continuity n+3 at t i than T. ~i(k)Gk(t), 
which contradicts (3.1)). Similarly, k=-3 oq(j)=0 if t i <_uj < uj+4=ti+4 and uj+~_q =uj+4. Therefore, 
for fixed index i, it is possible to determine which indices j satisfy ¢ti(j)=0. Given that t i =t/+p_l 
< ti+ e, we define T(i) to be the index such that uv(i) =t i and U~i) =U~i(i)+p_ 1 < U~i)+ p . Similarly, 
given that ti_ q < ti_q+t=t i, we define ~(i)to be the index such that u~l(i)=t i and u~l(i)._ q < url(i)..q+l=UB(i). 
(Note that T(i)=rl(i ) if the multiplicity of knot t i has not been increased in the refined knot sequence.) 
We also define ~(i ) =r1(i+4)-4. These indices satisfy y(i)<8(i),-3=~-3) <'~-2)< "-" <'~m+3), and 5(-3)<$(-2)< 
"" <$(m+3)=n+3. From the previous para-graph, txi(j)=O ifj <Hi) orj > $(i), i.e. ~(i) Fi(t)= ~_~ aifd')Gj(t 
). (3.5) j--~i) We note that $(i )-Hi ) is the number of new knots added in inter- val ( ti, ti+, 1 ), 
and for all indices i between 0 and m inclusive, the total number of possibly nonzero cq (j) is m ~. 
[$(i ) -~(i) + 1] < m + 1 + 4(n-m ) (3.6) i=0 since n-m is the number of new knots and each new knot 
uj is in at most four intervals ( t k , tk+ 4 ). Now, for fixed index j, we determine the indices i for 
which ct i (j) ¢ 0 is possible. There is at least one such index i by property (1). Also, these indices 
must be consecutive since the interval of nonzero support of the Fi(t ) moves from left to right as i 
increases. Therefore o~i(])#0 is possible for i =),Q')," ",p(j) where )~(j)=min{i I ~(i)<j <_5(i)}, (3.7) 
p(j)=max{i I ~(i)<_j <_8(i)}. These indices satisfy -3=~.(-3)_<~L(-2)_< .-. _<2~(n+3) and p(-3)_<p(-2)<-" 
_<p(n+3)=m+3. As discussed above, h(j) and p(j) satisfy tpU)<_u j < uj+4<tx(i>+4 . Hence, p(j') ~ Mj)+3 
and there are at most four indices i such that t~ i (j) ~: 0. This completes the proof of properly (2). 
Now we prove that the (t i (j') are nonnegative for all i and j. We consider the effect of adding the 
n-m new knots one at a time into the refined knot sequence. The Beta-splines change as fol-lows: ej =c:)--, 
- Gj where G/k)(t),-3 <_j <-m +k+3, are the Beta-splines resulting from adding k new knots. For the 
same reason as (2.6), these Beta- splines satisfy m -t-k+4 Gj(k)(t)= ~_~ tx(jk)(r)Gr(k+l)(t), -3<j <re+k+3, 
(3.8) r~3 O<k <n-m-1 for some constants t~}k)(r). If we can show that o~:t)(r)>-O for all j, k, r, i.e. 
adding one additional knot to a knot sequence results in normegative discrete Beta-splines, then the 
following induction argument shows that the otiO') are all nonnegative. Suppose the inductive hypothesis 
is that m +k+3 Fi(t)= ~ [$i(k)(j)Gfk)(t),--3<i <m+3, (3.9) j~3 where [~/(t)(j )>0 for all i, j. Note 
that cq(j')=13[~-~)U). The basis step, in which k =0, is true since [$/(°)(i)= 1 and ~/(°)(j)=0 if j 
~i. Suppose (3.9) is true for k ( n-re. Substituting (3.8) into (3.9) results in  ~ SIGGRAPH '87, Anaheim, 
July 27-31, 1987 re+k+4 Fi(t)= ~_~ ~i(k+1)(r)G(i+l)(t),--3<_i _<m+3 r~3  where re+k+3 ~Y+'>(~)= E 
~:*~O')~J*~(r) j~3  IfCtJk)(r) >. 0 for all j, r, then (3.9) is true for k+l. Therefore the problem 
of proving property (3) has been reduced to the case in which the refined knot sequence contains one 
additional knot. Hence, for the remainder of this proof, we assume that n =m+l. There are two cases to 
consider: (i) the new knot is not equal to t i for any i, (ii) the new knot increases the multiplicity 
of some knot 1, i .  First suppose case (i) occurs. Suppose the new knot ut+ ~ is added in the nonvacuous 
interval (t~, t~+l ) where 0 < k <m +3, so that ui=t i for -3<i <k, Ui+l=tl for k+l<i <_m+7, and the 
~2i are similarly defined with 1~21+1=0. For i <_k--4, Fi(t)=Gi(t), so ~i(i)=1 and ~i(j)=0 for j:~i. 
For i>k+l, Fi(t)=Gi+l(t), so c~i(i+l)= 1 and c~i(])=0 for j ~i+1. For i =k-3, k-2, k-l, and k, ~i(j)=0 
forj < i andj > i+1 by property (2), so (a) Fi_3(t )=~t_3(k-3)Gt_3(t )+o~l~_3(k-2)Gk_2(t ) (b) Ft~_2(t 
) = c~k_2(k-2)Gi_2(t ) + ~t_2(k- 1)G,~_l(t) (c) Fk_l(t)=otk_l(k-1)Gk_l(t)+~l~_l(k)G/c(t) (3.10) (d) 
Ft(t)=~k(k)Gk(t)+ctk(k+l)Gi+l(t ) .  We will show that ~t_3(k-3), ~tk_3(k--2), (~_2(k-2), and ~_z(k-1) 
are nonnegative, which implies that ~_l(k-l), ~l_l(k), ~(k), and ~(k+l) are also nonnegative by the reflection 
sym- metry property mentioned in Section 2. First, we consider the discrete Beta-splines in (3.10a). 
~xt_3(k-3) = 1 since m+3 cq(k--3)= 1 and o~i(k-3)=0 for i ~k-3. In interval i~3 [ ut+~, ui+2 ] = I u~+~, 
1,~+~ 1, Fk-3(1' ) = Sk -3,4(1') = dk-3,4[(1'k + 1-1' )/hk+ 1] 3 Gk_2(t ) = s~ _2.4(t ) = dk_2, 4 [(t,~ 
+l-t )/h~k +2] 3 , G k_3(1, ) -0. Hence, by comparing coefficients of (tk+l-t)3 in (3.10a), O~k_3(k--2) 
= di_3,4h~3+2/(dk_2,4h3+l ) > 0 (3.11) since all four variables are positive. Now, we consider the discrete 
Beta-splines in (3.10b). If 1'~_ 2 < ti_ 1, then in interval [ 1,i_2, ti_ 1 ], Fk -2( 1' ) m S k -2,1 
( t ) m dk -2,1 [ (t --t l _2)~hi _ 1 ] 3 Gk-2(t ) = S~k-2,1( 1' ) = dk-2,1 [(t-t*-2)/hk-1]3, Gk_l(t 
) --- 0. Hence, by comparing coefficients of (t-tg_2) 3 in (3.10b), Otk_2(k --2) ----dk_2,1/ dk_2,1 
> 0 since both variables are positive. If t~_ 2=t~_~, then ot~_2(k-2)= 1-t~k_3(k-2 ) where the value 
of ott_3(k-2 ) is given in (3.11). The explicit formula given by (2.1) and (2.3), along with h~_~=0, 
[~2i+ 1 =0 and hk+~=h~+l+hk+2, imply that W,-~ =~t~+l =0 and dk_3,4/ h3+1 = 1/[hk+l(hk-t-hk+l)(hk+hk+l+~lk 
hk)] (3.12) dk_2,4/h~3+2 = (l+~k)/[t~k+2hk+l(hk+ht+l+fflkhk+l)]. From (3.11) and (3.12), c~t_2(k-2 ) 
> 0 if and only if ~t_3(k-2) < 1 if and only if I~k+2(hk+hk+l) +~:il~k+2hk+l (3.13) < (ht+hk+l)(hk+hk+l+~Fk 
h t ) + ~i (hi +hi +1 )(hi +h,~+ l+Wk h k ). h~i+2 < hi+ 1 implies that (3.13) is true, hence c~k_2(k-2 
) > 0. If tk+ 1 < tl+ 2, then in interval [ tk+l, tk+ 2 ] = [ uk+2, uk+ 3 ], Fi-2(t ) = si_2,4(t ) = 
dt_2,4[(tt+2-t )~hi+2] 3 Gk-l(t )=~Ck_l.4(t )=clk_l,4[(tk+2--t )/hk+2] 3 , Gk_2(t )=O. Hence, by comparing 
coefficients of (tk+z-t)3 in (3.10b), ~i_2(k-1)=di_2,41dt_l,4 > 0 since both variables are positive. 
If tt+l=tk+2 (i.e. hl+2=O), then in interval [ Ui+l, tk+ 1 ], FI-2(t ) = st-2,3(t) = ct-2,3[(tk+l-t )/hi 
+1 ]2 + dk-2,3 [(ttc+l--t )/h i +l ]3 G k-z( t ) = ~t~_z,4( t ) = dl_2,4[ ( t/~ +l-t )/h~t +2 ] 3 Gk-l(t 
) ---£k-l,3(t ) ---¢k_l,3t(ti+l-t )//~ +212 + dk-l.3[( ti +1--t )Zl~k +2] 3 ^ since ai_2,3=bi_2,3=ffi_1,3=bi_1,3=O. 
By the linear indepen- dence of (ti+1-t) 2 and (ti+l-t) 3, and by comparing coefficients of (ti+l_ t 
)2 in (3.10b), O~k_2(k--1) = Ck_2,3hk221 (c'k_l,3h2+l) > 0 since all four variables are positive. Now 
suppose case (ii) occurs. Suppose the new knot uk+ 1 satisfies u k =ut+l=t k < tk+ l for index k in the 
range 0_<k <m+3 (the case of k > m+3 can be taken care of by using the reflection symmetry property). 
For i <_k--4, Fi(1,)=Gi(1,), so ~i(i)= 1 and o~i(j)=0 for j~i. For i >_k, Fi(t)=Gi+l(1,), so cti(i+l)=l 
and cti(j)=O for j ~i+1. For i =k-3, k-2, and k-l, ~i(j)=0 for j <i andj > i+1 by property (2), so (a) 
Fk_3(1, )=~t_3(k-3)Gk_3(t )+~k_3(k-2)Gk_2(t ) (b) F k_2(t) = ~t_2(k--2)Gk_2(1,) + ~i_2(k --1)Gk_l(t) 
 (e) Fk_ 1 (t) = c~i_ l(k-1)Gk_l(t ) + ~k-l(k )Gk (1,)  The proof that ~xk_3(k-3), c~k_3(k--2), ~t_2(k-2), 
o~k_2(k-1), ~k_l(k-1), and ~k_l(k) are nonnegative is similar to that for ease (i). For the same reason 
as for ~k_s(k--3) in case (i), ~_3(k-3)=~_~(k)= 1. For the same reason as for ~k_3(k--2) in case (i), 
~t_3(k -2) = dt_3,~/all_2, 4 > 0 (note that hi+ ~ = hi+2). If 1,k_ 2 < t~_t, then for the same reason 
as for ~t_2(k-2) in case (i), cXi_z(k-2 ) > 0. If t~_2= ti_l, then ~_2(k-2)= 1--~k_3(k--2) where the 
value of ~_3(k-2) is given above. The explicit formula given by (2.1) and (2.3), along with hk_t =0 and 
hi+ 1 =0, imply that W~-I =~ =~k+l =0 and dk_3,4 = h~+2 1 / [(hi + hi+l)(h~ + hk+l + ~Ifk hk )] d,_2, 
4 = hi+ 1 / (h i + h,~+l). Clearly, ct,_3(k-2) = d,_3.4/dt_z. 4-< 1, therefore ~_2(k-2) _> 0. For the 
same reason as for ~t_2(k-l) in case (i), o~,_a(k-1)>0 if t,+l<t~+ z or tt+l=t,+ ~. If t~_~<1,k, then 
ai_l(k-1)>0 for a reason similar to that for c~,_2(k-2) when tk_2< tk_ 1. If tk_l=tk, then ot~_t(k-1)=0 
since Fi_~(t)=Gk(t). This completes the proof of property (3).  (~ ~ Computer Graphics, Volume 21, Number 
4, July 1987 Now we look more closely at the cqQ') restricted to 0 < i <m and 0 -< j -< n. The indices 
L and U, which were defined in Sec- tion 2, satisfy L =7(3)-3 and U =rl(m+l)- 1 =5(m-3)+3. Also, from 
(3.7), 3.(L)>0 since uL+3mt3 and [uL+3, uL+4]K [t3, t4] , and p(U)<m since uu+~=tm+ ~ and [Uu,Uu+t]~ 
[tm,tm+~]. (~.(L)>0 or O(U)<m can occur only if t3=t 4 or tin=tin+l, respectively.) So property (1) becomes: 
rn (1') ~-'.cq(j)=l forj=L,...,U; i=0 ttl Y'~ccl (j)-< 1 forj =0, " "" ,L-l, U+I, " , n. i=0 The indices 
~i), 6(i) for 0<i <m, and g(j), p(j) for 0 _< j _< n, used in determining the nonzero c~ i (j), can be 
computed in O (n) time by the pseudocode below. For this computation, we restrict the index i in the 
definition of ~.(j ) and pQ' ) in (3.7) to the range 0 _< i _< m. We note that ~(0) >- 0 and ~(rn ) _< 
n ; ~0) and n -5(m ) are the increase in the multiplicity of knots t o and tin+a, respectively, in the 
refined knot sequence. For j ~(0) and j > 8(m ), oq (j) = 0 for i = 0, -  , m, so it is useless to increase 
the multiplicity of t o and tin+ ~. For these indices j, the following pseudocode sets p(j ) -X.(j ) 
=-1. i :=m+3 forj :=n+3 to 0 by-1 do if i >O and ti =u ~ then if i <m then ~i) :=j endif i :=i-1 endif 
endfor i :=1 forj := 1 to n+4 do if i -< m +4 and t i ----uj then if i ->4 then ~(i--4) :=j-4 endif 
 i :=i+1 endif endfor i:=0 forj :=0 to n do if/<rn andj > ~i(i) then i :=i+1 endif ~,(./) :=i endfor 
i :----m forj :=n to 0by-ldo ifi >_0 andj <y(i) then i :=i-1 endif OU):=i endfor  4. Computation of 
discrete Beta-splines In this section, we give an algorithm for computing the discrete Beta-splines o~i(./) 
defined in Section 2. Our approach is to use (3.5) and the explicit formula given by (2.1), (2.2), and 
(2.3) to compute the discrete Beta-splines of fixed index i in the order ot i (~(i)),""", Ix i (8(i)). 
This is different from the Oslo algorithm for computing discrete B-splines in which the nonzero oq,~(j) 
of fixed index j are computed using a recurrence relation (k is the order of the B-splines). If y(i ) 
= ~(i), then ~t i (~i)) = 1. Hence, suppose y(i ) < ~(i ). There are four cases to consider for index 
j between y(i) and ~(i) inclusive: (1) uj < u j+ 1 (2) uy=uj+ l<ui+ 2 (3) Uj = Uj+ i = Uj+ 2 < Uj+ 3 
(4) Uj =Uj+I=Uj+2=Uj+3< Uj+ 4 . Case (1) : Let k =1, 2,3, or 4 be the index such that [ uj, uj+ t ] ~ 
[ ti+k_l, ti+ ~ ]. Due to the local support of the Gj(t ), in interval [ u j, uj+ 1 ], J J Fi(t)= ~" 
cxi(r)Gr(t)= ~. O~i(r)Yrj+l_,(t ) (4.1) r=j-3 r=j-3 where o~i(r), r <j, is zero if r <~i), or already 
computed other- wise. From the linear independence of t 3, t 2, t, and 1, the follow- ing equation for 
~i(-]) is obtained by comparing the coefficients of t 3 in (4.1): "3 3 +dj_3,nO~i(j_3)+ (4.2) ~i (J ) 
= [¢Jdi ,k hj+l / hi +k where o= 1 ifk _<2 and ~=-1 if k->3. Case (2) : Let k be the index such that 
[Uj+l, Uj+2]~ [ ti+k_l, ti+ k ]. In interval [ uj+ l, uj+ 2 ], j+l /+1 F/(t)= ~ ~i(r)Gr(t)= ~. O~i(r)~r,j+2_r(t 
) (4.3) r=j-2 r~j-2 where ~i(r), r ~ j, is zero if r < ~i), or already computed other- wise. Since/~j+l 
=0,   +gj,:(,-.j÷,)/ Sj+l,l(t )=dj+l,l[(t-Uj+l)/ l~+2] 3. From the linear independence of (t-Uj+l) 
3, (t-Uj+l) 2, t-uj+ 1, and 1, o~ i (j) can be obtained by comparing the coefficients of (t-uj+l) 2 in 
(4.3). If s~_2,4(t ), s~_l,3(t), and si k(t) are rewritten as linear combinations of (t-u./+|) 3, (t--Uj+l) 
~, t--Uj+l, and 1, then the coefficients of (t-Uj+l) 2 are, respectively, 3dy-2 d h~f+2, ( ~-,,3 + 3dj-,,3)/ 
l~2+z, and c, where t3did c J hi3+Ic, if k = 1 or 4 c= ci,k/ hi2+i: + 3di~eJ hi3+k , ifk=2or3, Uj+l--ti+k_ 
i , ifk <2 E= [ti+ k -Uj+l , ifk ->3. Therefore o~i (.1") = [c1~j2+2 -3d: _z,4o~i U-2) - (4.4) (6¢j _l,3+3Jj 
_1,3)~i (j -1)]/Cj,2" Case (3) : Let k be the index such that [uj+2,uj+3]~ [ ti+k_i, ti+ k ]. In interval 
[ uj+ z, uj+ 3 ], j+2 j+2 El(t)= ~_~ (~i(r)Gr(t)= ~_~ O~i(r)~r,j+3_r(t ) (4.5) r=j-1 r~j-I where ~i(r), 
r <j, is zero if r ~ ~(i), or already computed other- wise. Since h'j+2=0, S'j,3(/) : aj,3 + b~-,3/~ 
+ ej.3/~ 2 -t- 4, 3u3' U = (Uj+3--t )[ h*j +3 s'j+l,2(t)=ej+i,2[(t-uj+2)l h~j +3] a +dj+l,2[(t-u7+2): 
hj+3] 3 S~+2,1(t)=d/+2,1[(t iUj+2)l h~+3] 3 . From the linear independence of (t-uj+2) 3, (t-uj+2) 2, 
t-uj+ 2, and 1, ~i (J) can be obtained by comparing the coefficients of t-u j+ 2 in i~N~ SIGGRAPH '87, 
Anaheim, July 27-31, 1987 (4.5). If~_ 1 4(t), s" i 3(0, and Sij~(t ) are rewritten as linear combi- nations 
of(t"--'Uj+2)S,'(t--Uj+2) 2, t--Uj+2, and 1, then the coefficients of respec.vely,-3dj_l,,: + ,- 6, +2ej.3+ 
3dj ,3)/hi+ 3 = 3/hi+ 3, and b, where [3t~di, k e2/hi3+k, if k = 1 or 4 b = J~(bi, k + 2ci, k El hi+ 
k + I [ 3di,kl~Z/hi2k )/hi+ k , ifk =2 or3, iS= 1, e=uj+z-ti+tc_t, if k<2 ff=-l, e--ti+ k-uj+2, ilk _>3. 
 Therefore tx i (j) = [bh'j + 3 + 3~_1,4ct i Q' -1)]/3. (4.6/ Case (4) : Let k be the index such that 
[u j+ 3,uj+4] [ ti+k_l, ti+, ]. In interval [ uj+3, u j+4 ], j+3 j+3 Fi(t)= ~_~ (~i(r )Gr(t )= ~ (~i(r 
)~r j+4_r(t ) . (4.7) r=j r~j Since Gj+](t), Gj+2(t), and Gj+3(t ) are continuous at t =uj+ 3 and Gj(t) 
is not continuous at t=uj+ 3, Gj+l(uj+3)=Gj+2(uj+3)= Gj+3(uj+3) = 0 and Gj (u j+ 3) = dj,4(uj+3)= 1. 
Therefore, from (4.7), txifj)=Fi(uj+Z) =sidt(uj+3). (4.8) In summary, the algorithm for computing the 
nonzero discrete Beta-splines is to first compute the coefficients of the Fi(t) and Gi(t) using the explicit 
formula (2.1/and (2.3), and then, for each index i, compute the o~i(j) in the order j=~(i),... ,$(i) 
using (4.21, (4.41, (4.6), and (4.8). If the nonzero oci(j) are to be saved, then they can be stored 
in an n+l by 4 array alpha[O..n ,0..3] where txi(j) is stored in alphalj,i-X(j)]. If the nonzero cq(/') 
are to be computed only for determining the new control vertices Wy using (2.8), then, except for the 
four most recem values oti(k), k =j-3, " ,j, they do not have to be saved, since cti(j)V i can be computed 
and accumulated immediately into Wj. We now establish an upper bound on the number of floating point 
operations required to compute the discrete Beta-splines using our algorithm. From Joe (1986), the number 
of floating point operations required to compute the coefficients of Fi(t), 0<i <m, and Gj(t), O<j <_n, 
for distinct knot sequences (the worst case) is 26+34(re+n+2) multiplications/divisions and 12+ 19(re+n+2) 
additions/subtractions. The computation of each nonzero ct i Q') requires at most 11 multiplications/divisions 
and 5 additions/subtractions (these counts are 8 and 4, respectively, for distinct knot sequences). From 
(3.6), the number of nonzero tx i (j) is at most 4n -3m + 1. Therefore computation of all the nonzero 
¢ti(.j ) requires an upper bound of 78n +m +105 mul-tiplications/divisions and 39n +4m +55 additions/subtractions. 
In addition, the computation of the new control vertices Wj requires at most (4n -3m + 1)d multiplications 
and (3n -3m )d additions where d = 2 or 3 is the dimension of the control vertices. Finally, we discuss 
the numerical stability of the algorithm. The computation of ct i (j), j = ~i ),  , fi(i), is equivalent 
to solv- ing a lower triangular banded system of linear equations using for- ward substitution. Hence 
the algorithm is stable in the sense that the forward substitution algorithm is stable (Stewart (1973)). 
However, if the tension parameters or knot spacings vary a lot, then the lower triangular matrix may 
be ill-conditioned and consid- erable roundofferrors can occur in the computed txiO'). Therefore double 
precision should be used in these cases. 5. Examples Examples of new control polygons, obtained from 
the algo- rithm of Section 4, are given in Figure 1. The same control poIygon VoV I -  V 9 is used with 
different tension parameters and knot spacings. The control polygon is drawn in dashed lines, and the 
refined control polygons W L WL+ l  - Wry are drawn in solid lines. Figures l(a) to l(d) are refined 
control polygons for a Beta- spline curve with knots t i =i, O<i < 13, and tension parameters 1321=0, 
~22=10, ~12~--9, 13z~=8, 1325=7, 1326=6, and 132 i =0 for 7<i _< 12. For Figure l(a), knots i +.5, 3<i 
<9, are added to get the refined knot sequence. For Figure l(b), knots i + .25, i + .5, and i+.75, 3<i<9, 
are added. For Figure l(c), knots i+.5, 0<i < 12, are added. For Figure l(d), knots i +.25, i +.5, and 
i + .75, 0<i _.% 12, are added. These figures illustrate that refined knots must be added in the intervals 
[t0,t3] and [tm+t,tm+4] in order for the refined control polygon to be a good approximation to the Beta-spline 
curve at its two ends. If no knots are added in these two intervals, then W L = V o and W u = I/=. Figures 
l(e) and l(f) are refined control polygons for a Beta- spline curve with quadruple knots at to and t13 
so that V 0 and V 9 are interpolated by the curve. The knots are t i =i-3, 3<i < I0, and the tension 
parameters are 1324= 10, 1325 = 8, 1326=6, 1327 =4, [32s=2, and [~2i=0 otherwise. For Figure l(e), knots 
i+.5, 0 < i < 6, are added to get the refined knot sequence. For Figure 1(0, knots i +.2, i + .4, i + 
.6, and i +.8, 0<i <6, are added. V3 V4 V8 V7 l I ~i I ~ ' Ii ~l I \ I I Vo I I Vs I V2 Vi V6 (a) new 
knots i+.5, 3<i<9 i/ \l [ "~l tt' V I \ I I I I I ! ! I I I I (b) new knots i+.25, i+.5, i +.75, 3<i<9 
 (~ @ Computer Graphics, Volume 21, Number 4, July 1987 i! \i i i" ~"ti  I I \i i \ i   l ,t' J 
l I (c) new knots i+.5, 0<i-<12 I/ \l I" ~ , I{ Ill I~1 II 1 I~ I i I I I I I I I (d) new knots i+.25, 
i+.5, i+.75, 0-<i-<12 '1 ~i I \ i  I t' I (e) new knots i +.5, 0-<i_<6 i / i / ~l \l ~ I \ \ i I 'tI 
I ! I I I I L ~'-'-'-''~ J L ~ ~ J (o new knots i+.2, i+.4, i+.6, i+.8, 0<i<6 Figure 1 Examples of 
refined control polygons 6. Concluding remarks Discrete Beta-splines arise when a Beta-spline curve 
is subdi- vided, i.e. the knot sequence is refined so that the curve is expressed in terms of a larger 
number of control vertices and Beta- splines. We have proved that discrete Beta-splines satisfy the same 
properties as discrete B-splines, and presented an algorithm for computing discrete Beta-splines and 
the new control vertices using the explicit formula of Joe (1986). An alternative approach to computing 
discrete Beta-splines and the new control vertices, based on the proof of property (3) in which the new 
knots are inserted one at a time, is given by Joe (1987). An open problem is whether discrete Beta-splines 
can be computed using a recurrence relation like the Oslo algorithm for discrete B-splines. Goodman and 
Unswo~h (1985) have given a recurrence for Beta-splines in terms of quadratic B-splines, in which the 
coefficients of the recurrence are piecewise linear poly- nomials. Because of these piecewise linear 
polynomials, it is not possible to derive a recurrence for discrete Beta-splines in terms of discrete 
quadratic B-splines using the approach of Prautzsch (1984). Acknowledgment The author would like to thank 
R. H. Bartels for his com- ments on a preliminary draft of this paper, and the referees for their useful 
comments. This work was partially supported by grants from the Central Research Fund of the University 
of Alberta and the Natural Sciences and Engineering Research Council of Canada. References B. A. Barsky 
(1981), The Beta-sptine: a local representation based on shape parameters and fundamental geometric measures, 
Ph.D. Dissertation, Dept. of CompUter Science, Univ. of Utah. B° A° Barsky and J. C. Beatty (1983), Local 
control of bias and tension in Beta-splines, ACM Transactions on Graphics, 2, pp. 109-134. B. A. Barsky 
(1986), Computer Graphics and Geometric Model- ling Using Beta-splines, Springer-Verlag, Tokyo. R. no 
Barrels and J. C. Beatty (1984), Beta-splines with a difference, Technical Report CS-83-40, Dept. of 
Computer Science, Univ. of Waterloo. R. H. Bartels, J. C. Beatty, and B. A. Barsky (1987), An Introduc- 
tion to the Use of Splines in Computer Graphics, to be pub- lished by Morgan Kaufman Publishers, Los 
Altos, Califor- Ilia. W. Boehm (1980), Inserting new knots into B-spline curves, Computer-AidedDesign, 
12, pp. 199-201. W. Boehm and H. Prautzsch (1985), The insertion algorithm, Computer-AidedDesign, 17, 
pp. 58-59. W. Boehm (1985), Curvature continuous curves and surface~, Computer Aided Geometric Design, 
2, pp. 313-323. E. Cohen, T. Lyche, and R. Riesenfeld (1980), Discrete B-splines and subdivision techniques 
in computer-aided geometric design and computer graphics, Computer Graphics and Image Processing, 14, 
pp. 87-111. G. Farin (1982), Visually C 2 cubic splines, Computer-Aided Design, 14, pp. 137-139. G. Farin 
(1985), Some remarks on V2-splines, Computer Aided Geometric Design, 2, pp. 325-328. ~ SIGGRAPH '87, 
Anaheim, July 27-31, 1987 ill u T. N. T. Goodman (1985), Properties of Beta-splines, J. Approxi- mation 
Theory, 44, pp. 132-153. T, N° T. Goodman and K. Unsworth (1985), Generation of Beta- spline curves using 
a recurrence relation, in Fundamental Algorithms for Computer Graphics, Springer-Vedag, Ber- lin, pp. 
325-357. T. No T. Goodman and K. Unsworth (1986), Manipulating shape and producing geometric continuity 
in Beta-spline curves, IEEE Computer Graphics and Applications, 6, No. 2, pp. 50-56. B. Joe (1986), An 
explicit formula for nonuniform Beta-splines, Technical Report TR86-21, Dept. of Computing Science, Univ. 
of Alberta. B. Joe (1987), Rational Beta-spline curves and surfaces and discrete Beta-splines, Technical 
Report TR87-04, Dept. of Computing Science, Univ. of Alberta. T. Lyche and K. Morken (1986), Making the 
Oslo algorithm more efficient, SIAM J. Numer. Anal., 23, pp. 663-675. H. Prautzsch (1984), A short proof 
of the Oslo algorithm, Com-puter Aided Geometric Design, 1, pp. 95-96. H. Prautzsch (1985), Letter to 
the editor, Computer Aided Geometric Design, 2, p. 329. G. W. Stewart (1973), Introduction to Matrix 
Computations, Academic Press, New York.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37420</article_id>
		<sort_key>145</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[Direct least-squares fitting of algebraic surfaces]]></title>
		<page_from>145</page_from>
		<page_to>152</page_to>
		<doi_number>10.1145/37401.37420</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37420</url>
		<abstract>
			<par><![CDATA[In the course of developing a system for fitting smooth curves to camera input we have developed several direct (i.e. noniterative) methods for fitting a shape (line, circle, conic, cubic, plane, sphere, quadric, etc.) to a set of points, namely exact fit, simple fit, spherical fit, and blend fit. These methods are all dimension-independent, being just as suitable for 3D surfaces as for the 2D curves they were originally developed for.Exact fit generalizes to arbitrary shapes (in the sense of the term defined in this paper) the well-known determinant method for planar exact fit. Simple fit is a naive reduction of the general overconstrained case to the exact case. Spherical fit takes advantage of a special property of circles and spheres that permits robust fitting; no prior direct circle fitters have been as robust, and there have been no previous sphere fitters. Blend fit finds the best fit to a set of points of a useful generalization of Middleditch-Sears blending curves and surfaces, via a nonpolynomial generalization of planar fit.These methods all require (<i>am</i>+<i>bn</i>)<i>n</i><sup>2</sup> operations for fitting a surface of order <i>n</i> to <i>m</i> points, with <i>a</i> = 2 and <i>b</i> = 1/3 typically, except for spherical fit where <i>b</i> is larger due to the need to extract eigenvectors. All these methods save simple fit achieve a robustness previously attained by direct algorithms only for fitting planes. All admit incremental batched addition and deletion of points at cost <i>an</i><sup>2</sup> per point and <i>bn</i><sup>3</sup> per batch.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.1.2</cat_node>
				<descriptor>Least squares approximation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003636</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Approximation algorithms analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003736.10003737</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Functional analysis->Approximation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Measurement</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31093074</person_id>
				<author_profile_id><![CDATA[81100298352]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Vaughan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pratt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sun Microsystems, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Albano, Representation of Digitized Contours in Terms of Conic Arcs and Straight-Line Segments, Computer Graphics and Image Processing 3, 23-33, 1974.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R.H. Biggerstaff, Three Variations in Dental Arch Form Estimated by a Quadratic Equation, Journal of Dental Research 51, 1509, 1972.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[F.L. Bookstein, Fitting Conic Sections to Scattered Data, Computer Graphics and Image Processing 9, 56-71, 1979.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D.B. Cooper and N. Yalabik, On the Computational Cost of Approximating and Recognizing Noise-Perturbed Straight Lines and Quadratic Arcs in the Plane, IEEE Transactions on Computers (3-25, 10, 1020- 1032~ October 1976.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C. de Boor, A P r a c t i c a l Guide t o Splines, Springer-Verlag, 1978.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>578513</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[I.D. Faux and M.J. Pratt, Computational Geometry for Design and Manufacture, Ellis Horwood, 1978.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Y. Gordon, Numerical Methods for CAD, MIT Press, 1986.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>577191</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A.A. Giordano and F.M. Hsu, L e a s t Squares E s t i m a t i o n w i t h A p p l i c a t i o n s t o D i g i t a l S i g n a l P r o c e s s i n g , Wiley, 1985.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[R. Gnanadesikan, Methods for S t a t i s t i c a l Data A n a l y s i s o f M u l t i v a r i a t e O b s e r v a t i o n s , Wiley, 1977.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[C. Hoffman and J. Hopcroft, Automatic Surface Generation in Computer Aided Design, The Visual Computer, 1, 2, 92-100 (1985).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>14288</ref_obj_id>
				<ref_obj_pid>14287</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[C. Hoffman and J. Hopcroft, Quadratic Blending Surfaces, Computer Aided Design, 18, 6, 301-306 (Jnl-Aug. 1986).]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[C.L. Lawson and R.J. Hanson, Solving Least-Squares P r o b - lems, Prentice-Hall, 1974.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[E.A. Lord and C.B. Wilson, The Mathematical D e s c r i p t i o n o f Shape and Form, Ellis Horwood, Chichester, 1984.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325231</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[A.E. Middleditch and K.H. Sears, Blend Surfaces for Set Theoretic Volume Modelling Systems, Computer Graphics 19, 3 (Siggraph-85), 161-170, July 1985.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[V.S. Nalwa and E. Pauchon, Edgel-Aggregation and Edge-Description, Eighth International Conference on Pattern Rccogrdtion, 604-609, Paris, Oct. 1986,]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[K. Paton, Conic Sections in Chromosome Analysis, Pattern Recognition 2, 39-51, 1970.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357315</ref_obj_id>
				<ref_obj_pid>357314</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[T. Pavlidis, Curve Fitting with Conic Splines, ACM Transactions on Graphics 2, 1, 1-31, January 1983.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[K. Pearson, On lines and planes of closest fit to systems of points in space, Philos. Mag. Eer. 6, 2,559, 1901.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[C. Pearson, Numerical Methods in Engineering and Science, Van Nostrand Reinhold, 1986.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6757</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[M.A. Penna and R.R. Patterson, P r o j e c t i v e Geometry and i t s A p p l i c a t i o n s t o Computer G r a p h i c s , Prentice-HMl, New Jersey, 1986.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801153</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[M. Plass and M. Stone, Curve-Fitting with Piecewise Parametric Cnbics, Computer Graphics 17, 3 (Siggraph-83), 229-239, July 1983.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325225</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[V. Pratt, Techniques for Conic Splines, Computer Graphics 19, 3 (Siggraph85), 151-159, July 1985.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[D. Proflltt, The Measurement of Circularity and Ellipticity on a Digital Grid, Pattern Recognition 15, 5, 383-387, 1982.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[P.D. Sampson, Fitting Conic Sections to "Very Scattered" Data: An Iterative R.efinement of the Bookstein Algorithm, Computer Graphics and Image Processing 18, 97-108, 1982.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[K. Turner, Computer Perception of Curved Objects using a Television Camera, Ph.D. Thesis~ Dept. of Machine Intelligenc% University of Edinburgh, Nov. 1974.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 I I1| Direct Least-Squares Fitting of Algebraic 
Surfaces Vaughan Pratt Sun Microsystems Inc. and Stanford University Abstract. In the course of developing 
a system for fitting smooth curves to camera input we have developed several direct [i.e. noniterative) 
methods for fitting a shape (line, circle, conic, cubic, plane, sphere, quadric, etc.) to a set of points~ 
namely exact fit, simple fit~ spherical fit, and blend fit. These methods are all dimension-independent, 
being just as suitable for 3D surfaces as for the 2D curves they were originally developed for. Exact 
fit generalizes to arbitrary shapes (in the sense of the term de- fined in this paper) the well-known 
determinant method for planar exact fit. Simple fit is a naive reduction of the general overconstrained 
case to the exact case. Spherical fit takes advantage of a special prop- erty of circles and spheres 
that permits robust fitting; no prior direct circle fitters have been as robust, and there have been 
no previous sphere fitters. Blend fit finds the best fit to a set of points of a useful generalization 
of Middlediteh-Sears blending curves and surfaces, via a nonpolynomial generalization of planar fit. 
These methods all require (am + bn)n 2 operations for fitting a surface of order n to rn points, with 
a = 2 and b --- 1/3 typically, except for spherical fit where b is larger due to the need to extract 
eigenvectors. All these methods save simple fit achieve a robustness previously attained by direct algorithms 
only for fitting planes. All admit incremental batehed addition and deletion of points at cost an 2 per 
point and bn s per batch. 1. Introduction Background. We began this project with the problem of recovering 
outline fonts from scanned-in camera images of large-scale drawings, as part of a larger project to automate 
the entry of such drawings. Such entry is usually done by hand, typically by entering points around the 
curve via a tablet and postediting the result to achieve smoothness and fidelity to the original. Such 
manual entry of curves is not only an expensive use of human resources but also less accurate than what 
can be achieved by working algorithmically with scanned-in camera images. The techniques we developed 
for this application are of general interest to other domains where curve fitting is needed, as well 
as to situa- tions involving surface fitting in three or more dimensions. This paper therefore emphasizes 
these general techniques at the expense of their motivating application, which we hope to report on elsewhere. 
Our application is also the main application of similar work reported by Plass and Stone in this forum 
[21]. The two main differences of our work from theirs are our emphasis on algebraic as opposed to parametric 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169; 
1987 ACM-0-89791-227-6/87/007/0145 $00.75 curves (in the 2D case), and on one-step application of matrix-inversion- 
style least-squares methods, which we refer to as direct methods in distinction to slower iterative methods. 
Problem Statement. We wish to fit an algebraic curve or surface of a given shape to m points in d-dimensional 
space R d. We cater for such shapes as circle, line-pair, cubic, cone, sphere, and quadric, all of which 
are definable in the form f (xt ..... xe) = 0 where f is a polynomial in its arguments, but not, e.g, 
for space curvesj which are defined as the intersection of two surfaces and require two such equations. 
Goodness of fit is taken to be the length of the m-vector of distances of the m points from the surface. 
The fit is called exact, best, or good when this length is respectively zero, least possible, or close 
to least possible. We take the length of an m-vector to mean its Euclidean length. Best fit then amounts 
to least-squared-dlstance fit. We take the geometric distance of a point p from a surface S to be the 
distance from p to the nearest point of ~q, i.e. the minimum, over all points p' of S, of the Euclidean 
distance from p to p'. Unfortu-nately geometric distance is neither computationally nor algebraically 
convenient, particularly for higher-order surfaces. This leads to the use of distance metrics that approximate 
geometric distance. A distance metric is more or less robust when the best fit under it is a more or 
less good fit under geometric distance. Performance. The main emphasis of this paper is on fast computation 
of good fits, to which end we confine ourselves to direct methods, by which we mean those least-squares 
methods that require roughly the work of a matrix inversion or an extraction of eigenvalues. Our typical 
cost to fit a surface of order n to m points is on the order of (m + n}n 2 operations, e.g. to fit circles 
to 20 points m = 20 and n = 4, so a few hundred operations. By contrast iterative methods may be much 
slower; Figure 2 of [21] suggests that an iterative method may require on the order of a hundred iterations 
to fit a parametric cubic to a set of m = 20 points~ with each iteration itself requiring the application 
of a least squares algorithm. Why algebraic surfacesf An algebraic presentation of a surface is an implicit 
presentation ](xl,..., :ca) = 0 for which f is a polynomial in its d arguments. The main rationale for 
our interest in algebraically presented surfaces is that they lend themselves to direct least-squares 
techniques at least as naturally as parametric surfaces. In addition, in some situations parameters constitute 
an inconvenient or unnatu- ral artifact. Thirdly, although all algebraic surfaces are representable parametrically 
they are not all representable with a polynomial or even rational polynomial representation, whence algebraic 
methods have a greater domain of applicability. And fourthly, parametric curves and surfaces have received 
the llon's share of attention in the fitting liter- ature, creating the misleading impression that algebraically 
presented curves and surfaces are less suitable for fitting purposes. Indeed our own experience has been 
that the situation is quite the opposite: we find the algebraic form more convenient and efficient for 
fitting. SIGGRAPH '87, Anaheim, July 27-31, 1987 uml Related work. There appears to be relatively little 
written about fit- ting algebraic curves. A fairly thorough search turned up only a few treatments of 
least-squares fitting of algebraic curves [1, 2, 3, 4, 9, 15, 16, 24, 25] and none whatsoever of least-squares 
fitting of nonplauar algebraic surfaces. By comparison least-squares fitting of parametric polynomial 
curves and surfaces is routinely treated in many papers and a number of textbooks [5, 7, 8, 13, 19]. 
In the case of least-squares fit- ting of surfaces there seems to be a universal impression that fitting 
is only feasible for parametrically presented surfaces. Perhaps the single commonest failing of those 
papers that do treat alge- braically presented carves is their casual adoption of computationally convenient 
distance metrics. These metrics generally measure the dis- tance of a point (Zo, Yo) to a curve q(x, 
y) = 0 (q(x, y) a polynomial in x and y} by first normalizing q according to some quadratic constraint 
on its coefficients and then taking the distance to be q(x0, Y0)- We shall call this a quadratic-norm 
distance metric. Bookstein [3] faults several authors [1,2,4,91 for adopting quadratic-norm metrics that 
depend on choice of basis, and gives a similarity-invariant metric {relative to geo- metric distance) 
that is usable for both conic-fitting and circle-fitting, arguing that this is the only similarity-invariant 
exact-fit-preserving quadratic-norm metric. Sampson [24] points out that even with these properties Bookstein~s 
metric still departs sufficiently from geometric distance that when fit- ting highly elliptic conics 
to "very scattered ~ data the resulting fit can be perceptibly inferior. One might conclude that the 
application of Bookstein distance to circle-fitting would be less problematic since the ellipticivy problem 
addressed by Sampson cannot arise. Actually it is the other way around: for circle fitting Bookstein's 
measure can fail far more convincingly than envisaged by Sampson, which we illustrate below with an example 
where curvature of the fitted circle increases when it should be decreasing. Turner [25] and Sampson 
[24] apply the nonalgebraic distance metric q/]Vql to curve fitting. We show how to modify this metric 
to be algebraic - a quadratic normalization -for the case of circles (extending immediately to spheres], 
ironically the one case of ellipses to which Sampson did not evisage applying q/IVql. Results. The techniques 
we have developed are as follows. (i) Exact fit. We give a simple method for exact fitting of a surface 
of a given shape to the ~ppropriate number of points~ generalizing the well- known determinant method 
for fitting a hyperplane in d dimensions to d points. (ii) Simple fit. We naively translate the problem 
of finding the best fitting surface for a surfeit of points into the exact-fit problem, via normal equations. 
The translation is very simple, has excellent perfor- mance, but lacks robustness. We give a variation 
on the method that substantially improves its robustness at negligible performance cost. (iii) Spherical 
fit. We give a distance metric that leads to a robust direct algorithm for fitting spheres in d dimensions. 
For d ~ 2 this algorithm is the first direct least-squares circle fitter to achieve this level of robustness. 
For higher d this is still true, albeit vacuously since the problem of fitting spheres to points seems 
not to have previously been considered. (iv) Blend fit. We first give a useful generalization of the 
Middleditch- Sears [141 approach to blending surfaces. Then, given a set of base surfaces to be blended, 
along with a set of points, we give a simple direct method for finding a blending surface of a given 
shape best fitting those points. 2. Samples, Surfaces, and Shapes Given a sample consisting of an rn-tuple 
of points in 1~ ~, we wish to find a surface of the form Z(q) C 1~ d consisting of the zeros of a function 
q : R ~ --* 17~, that comes close to minimizing the sample-to-surface distance, which we define as the 
Euclidean norm (length) of the m-vector of the true (geometric} point-to-surface distances. The function 
q is to be drawn from a given set Q; for example if we are fitting circles then Q is the set Qc of all 
polynomials of the form A(x 2 + yZ) + Dx + Ey+ F. The techniques of this paper apply to sets of functions 
closed under linear combinations. For example it should be apparent that Qc is so closed. Such a subset 
of the ring of all functions q : R a --. R, is called an idealofthat ring; it also constitutes a vector 
space (R being a field). For example Qc is a 4-dimensional vector space {of polynomials q : R 2 --~ R) 
one of whose bases is x ~ + yZ, x, y, 1. (The reader accustomed to thinking about the set of cubic polynomials 
as a four-dimensional vector space with 1, t, t2,$ 3 as one basis and {1 - t)3,3t(1 -t)z, 3tz(1 -t},t 
z as another should have no difficulty adapting to these concepts.) Our techniques are limited to the 
case where this space is of finite dimension n. We call a set of surfaces defined by an n-dimensional 
ideal a shape of order n, e.g. the set of all 2D circles constitutes a shape of order 4. It is customary 
in geometry to work with just the ideals of the ring of all polynomials q : R d --~ 1~. However our methods 
extend immediately to the larger ring of all functions f : 1~ a --* R, which we take advantage of for 
blend fitting. /~very such Q contains the identically zero polynomial 0, defining the trivial surface 
consisting of the whole space. One additional require- ment when fitting surfaces is that we do not allow 
this trivial fit. We nevertheless leave 0 in Q for algebraic convenience. Examples. Many useful shapes 
are definable by finite-dimensionM ide- als. We list a few below along with suitable generators for their 
defining ideals~ each set of generators constituting a basis for the ideal as a vec- tor space. horizontal 
line 1, y diagonal line 1, z + y line* 1, z, y upright parabola 1, x, y, x 2 upright hyperbola 1, =c, 
y, xy diagonal hyperbola 1, z, y, ~z _ y2 circle at origin 1, z 2 + y2 circle 1, z, y, x 2 + y~ right 
hyperbola 1, z, y, 2xy, z 2 - y2 conic* 1, z, V, z 2, xy, y2 or circle U right hyperbola cubic* conic 
t.j xS~ xZy, xy2 y3 plane* 1, x, y, z z-axis cylinder 1, x 2 + y2 z-ax/s cone x2 + yZ, z 2 )[=z-axis 
coue yZj 2:Z:2: z-aligned cylinder 1, z, y, x z + y2 sphere 1, z, y, z, z 2 + y2 + z 2 right hyperboloid 
1, z, y, z, x z -yZ, y2 _ z 2, 2xy, 2yz, 2zx quadric* 1, x, y, z, x ~, yz, z 2, xg, yz, zx or sphere 
U right hyperboloid Asterisks denote shapes invariant under linear transformations (and hence under 
change of basis), meaning that a linear transformation maps any object of that shape to an object of 
the same shape. Al-though the circle, right hyperbola (orthogonal asymptotes, useful for converting spherical 
fit to conic fit), sphere, and right hyperboloid (3D analog of the right hyperbola) shapes are not so 
invariant, they are in- variant under similarities (angle-preservlng linear transformations, i.e. rotations, 
scalings, and translations}, while the properties of being a line of a given orientation (horizontal, 
diagonal, etc.}, upright parabola, upright or diagonal hyperbola (asymptotes parallel to or at 45 degrees 
to the axes), or z-aligned cylinder are iavariant under translations. The remaining properties are not 
even invariant under translations. 3. Algebraic Distance A commonly used surrogate for geometric distance 
from a point p to a surface Z(q} is the value of q at p. Since Z(q) = Z(eq) for c # 0 q is first normalized 
in order to make this value meaningful, typically by scaling it so as to set to a constant (unity for 
definiteness) some quadratic function of its coefficients, which we call quadratic normallzatioa. Since 
we seek to minimize the sum of the squares of the distances it changes nothing if we take the negation 
of a normal polynomial to also be normal. We shall refer to distance computed in this manner as algebraic 
distance; the essential characteristic ofalgebralc distance from p to Z(q) (~ ~ Computer Graphics, Volume 
21, Number 4, July 1987 is that it is computed by evaluating a fixed representative polynomial cq, chosen 
independently of p. An important aspect of quadratic normalization for our purposes is that the best 
fit under such a distance metric can be computed directly via the computation of an n × n eigenvector 
in O(n 3) operations [12]. Hence any distance metric defined by a quadratic normalization leads automatically 
to a fitting method meeting our performance requirement. The remaining concern is then with the quahty 
of fit, which can vary substantially between normalizations. Normalization can be visualized geometrically 
by thinking of the set {cqlc real} for any given q as the line containing the polynomials q and 0 in 
the vector space Q. This hue is called the principal ideal generated by q, and pervades the algebraic 
geometry of surfaces. Normal polynomials then appear as complementary pairs of points (equidistant from 
the origin of Q) on principal ideals, and we may think of the set of all normal polynomials as forming 
a surface in the space Q, which we may call a normalizlnq surface in Q (not to be confused with surfaces 
comprising shapes, which exist in Rd). If the normalizing surface is say a sphere then it will intersect 
all prin- cipal ideals {in two complementary points}, but if it is say a cylinder then the principal 
ideal along its axis will contain no normal polyno- mial (equivalently, the normal polynomial can be 
regarded as being at the "end" of the ideal, i.e. at infinity). In this case a fitting algorithm will 
never fit such a principal ideal; furthermore, principal ideals very close to it will have very large 
normal polynomials and so will appear to be bad fits. We think of the unfittable polynomials as the singularities 
of the normalization, and their neighbors as being very hard to fit. In the actual fitting process the 
presence of singularities is felt as a sort of repulsive force pushing the fitted shape well away from 
the singularity. A number of authors have proposed such normalizations for the conic shape. Paros [16] 
normalizes conics Az2+Bxy+Cy2+Dz+Ey+F .= 0 subject to A~+B2+C2+D2+EZ+F 2 = 1, corresponding to taking 
the normalizing surface to be the unit sphere with center 0 (with respect to the basis x ~, ~y,y~, x, 
y, 1), having no singularities. Biggerstaff [2], Albano ill, and Cooper and Yalabik [4] take the plane 
F = 1 (equiva- lently, the two planes F = -4-1)~ whose singularities correspond to those conics that 
pass through the origin. Gnanadeslkan [9} takes the unit cylinder along the F-axis, that is, AS+ B2+ 
C2+ Dz+ E 2 = 1, missing only the F-ax~s itself, defining the empty conic Z(I},which is no great loss. 
Bookstein uses the ellipsoidal cylinder A2+ Bz/2 + C 'z = 2, ruling out the subspace A = B = C = 0 of 
Q which can be seen to make straight lines singular and so unfittable. Each of these metrics save Bookstein's 
varies (relative to geometric distance) under similarities (rotations, translations, and scaling) of 
the plane, as Bookstein points out. It is worth adding that the most popular normalization: F = 1, is 
a particularly poor one due to the singularity at the origin, which tends to push the fit away from the 
origin. (Hence to lle with statistics when fitting curves to data it suffices to choose as the origin 
for that data a point you want the curve to stay away from regardless of what the data says.) Gnanadesllcan's 
normalization has the opposite problem, tending to push the fit towards the origin to keep D and E smalh 
For the circle shape, definable as the subshape A = G, B = 0 of the conic shape, Bookstein's normalization 
speciahzes to A 2 + O 2 = 2, i.e. A = =t=1, still having lines as its singularities. One might then pre- 
dict that Bookstein's normalization should prefer slightly more curved fits than the true best fit; in 
actuality it is easily encouraged to prefer absurdly curved fits, as we shall see in the section on spherical 
fits. To correct this we propose a new normalization for circles, namely D 2 + E 2 -4AF = 1 (D 2 + E 
2 + F 2 - 4AG = 1 for spheres). Like Book- stein's normalization this is invariant relative to geometric 
distance un- der similarities but has only points (zero-radius circles) as singularities, which appear 
to cause less havoc than lines. 4. iNTonalgebraic Distance We mention here some of the principles behind 
metrics whose normal- izations do depend on p, i.e. nonalgebraic distance metrics. Curiously enough, 
one of the insights from this section leads us to our above-mentioned algebraic distance metric for circles. 
Beyond this, an un-derstanding of the principles will improve perspective on surface fitting techniques 
in general. Sink or Swim. In visualizing the correspondence between geometric and algebraic distance 
we find the sink or swim picture helpful. In dimen- sion d = 2, think of a point p = (x, y) on the plane 
R ~ as a swimmer in the ocean and the 3D surfa .... q(x, y) as the land below him. Z(q) is the shoreline, 
geometric distance D(p, Z(q)) is swimming distance to shore, uunormalized algebraic distance (the sign 
is unimportant) is sinking distance to bottom, and normalization is vertical rescaling. In this connection 
a useful additional concept is the gradient operator ~7: Vq = (Oq/Oz, Oq/Oy) is a function which assigns 
to each point p on the ocean surface a vector Vq(p) lying in the ocean surface whose direction is the 
uphill direction of the ocean bottom immediately below p and whose length ]~Tq(p)] is the slope of the 
ocean bottom there. When the surface z = q(x, y) is planar, Vq and hence [Vq[ are constant. We can therefore 
normalize q to q/IVq[ to yield a surface with slope 1, for which algebraic distance coincides with geometric 
distance [18]. If q{x, y) = Dx + Ey + F then ]X7ql = v/-D--'ff + E 2, so the appropriate normalization 
is D 2 + E 2 = 1, with only the trivial degeneracy F = 0. This leads to an eigenvector-based direct method 
for best geometric fit- ting of lines and planes in any R ~. (A slope-1 normalization is possible also 
for cones, pyramids, and much more complex surfaces; unfortu- nately none of these shapes appear to be 
definable in terms of an ideal of polynomials. They can in some cases be defined in terms of an ideal 
of algebraic functions, typically involving square roots of polynomials, but unlike the convenient setup 
with blending surfaces that we present below these ideals appear not to be of finite dh-nension, ruling 
out any direct application of our methods.) Turner [25] and Sampson I24] have independently proposed 
using the above normalization q/[Vq[ for nonplanar shapes, for which [Vq] is not constant. This normalization 
is a function of p and gives a nonalge- braic distance metric, albeit one that remains computationally 
more tractable than geometric distance. Nalwa and Pauchon [15] refine this metric to take into account 
second-order derivatives of q, which can be helpful with very scattered data. These metrics offer the 
following benefits. First q/IVq[ is insensitive to scaling of q. Secondly it is as invariant as geometric 
distance, being invariant under translations and rotations and varying in proportion to geometric distance 
under change of scale; hence the best fit is invari- ant under similarities (angle-preserving transformations 
or changes of basis). Thirdly it coincides with geometric distance for plane surfaces. Fourthly, for 
nonplanar surfaces, q(p)/]Vq(p) I approximates geometric distance to the extent that q is approximately 
planar (i.e. approximates a linear combination of 1, xl,..., Xa} on the (d-dimensional) ball with center 
p and radius q(pJ/IVq(p)l, which is almost invariably the case for only slightly scattered data. The 
Turner-Sampson and Nalwa-Pauchon metrics are both nonalge- braic and seemingly unusable with direct methods. 
Rather, at least as envisaged by Sampson [24], one iteratively computes an algebraic fit q by a direct 
method, weighting the algebraic distance from each sample point p to Z(q) by 1/]Vq(-X)(p)[ where q(-1) 
is the surface found at the previous iteration, using unit weights in the first iteration. This appears 
to us to be the most robust method for those situations where there is no appropriate quadratic normalization, 
e.g. highly elliptical conics, as we discuss in the section on spherical fits. 5. Exact Fit We give a 
straightforward method for exactly fitting a surface of order n to n -1 points Px,-..,Pa-1, which we 
want mainly for the more general problem of approximately fitting such a shape to at least that many 
points. The method is well-known for the case of planes, appears occasionally in textbooks for the case 
of circles, and in [22] and [20] (p.369) for conics. However we have been unable to locate any reference 
to the general method. Let A : Q --+ 1% m map each polynomial q E Q to the m-vector of values of q at 
the rn points, evidently a linear transformation. The exact fits are then the ~eros of A. Given any basis 
bl,... ,bn for Q, q is representable as the n-vector q of coefficients of bi's A is representable as 
the m × n matrix A whose i]-th element is b$'(pi), and A(q) is given by the product Aq. To fit a circle 
to five points we would have SIGGRAPH '87, Anaheim, July 27-31, 1987 t~~l 1 xl Yl x~ + y~ 2 2 1 X2 Y2 
x2 + Y2 1 2:2 + 2~ = 1 2:3 Y3 3 Y3 [ 1 ~g4 Y4 X42 + Y42 ] X2 + ~/ 1 x5 Ys s Y5-" Then the matrix A amounts 
to a change of coordinates for [defining polynomials of) surfaces, namely from the given basis to a coordinate 
system in which the i-th coordinate gives the algebraic distance of the surface from Pi. ~or the case 
rn = n -1 an exact fit is possible, and is easily found as follows. Let A + denote the square matrix 
obtained from A by adjoining an n-th row consisting of the basis polynomials themselves, making A + a 
matrix over polynomials, and form its determinant. In the circle example this determinant is 2 2 1 zt 
Yi Zl + Vl x2 +. 2 1 x2 y2 2 ~2 x 2 + 1 ~s Y3 s Ys 1 x y x 2 + y~ This determinant, a polynomial q, 
can be seen to be a linear combina- tion of the n (here n = 4) basis polynomials and so is in Q, whence 
we have a legal surface. Since the value of row n at p; is row i it follows that the determinant vanishes 
at each Pl, so the surface passes through alI m = n -- 1 points. We may compute q as the cofactors of 
the elements of the n-th row, giving its representation in terms of coefficients of the b~s. For large 
n it is worthwhile to triangularize A first (i.e. make A~] = 0 for i > j via row operations) at cost 
O(n 3) and then compute the cofactors at an additional cost of O(n2). The one uninteresting case of 
this situation is when q is identically 0, which it is if and only if the rank of A is strictly less 
than n - 1. In this case the points underdetermine the shape, a situation we do not treat here. When 
rn >_ n but the rank of A is n --1 we may select n -1 linearly independent rows of A to form an (n -1) 
× m matrix whose rank is still n -1. The above technique may then be applied to this matrix to yield 
a surface passing through these n- 1 selected points. This surface will also pass through all points 
whose corresponding matrix rows are linear combinations of the n - 1 selected rows, which is the case 
for the m -(n -1) unselected rows, the rank of A being only n -1. Again, if the rank of A is less than 
n -1 the points still underdetermine the shape. 6. Simple Fit The only ~emaining case now is m > n 
and rank(A} = n. This is the overdetermined case (no exact fit), our primary interest. The goal is to 
find a good fit Z(q) to the sample The following method is of interest partly for its simplicity, partly 
for its connection to Exac~ Fit, and partly for how it circumvents singularities. We first ~tate the 
method for the normalization which holds the last coefficient constant. This normalization has the obvious 
drawback that a fit having this coefficient zero constitutes a singularity, which we will attend to shortly. 
The first step of the method is the basic step for the method of normal equations, the second step is 
novel in that the normal equations method is usually applied to systems with an independent variable, 
whereas here we are solving an implicit system in which none of the d variables can be identified as 
independent. The Simple Fit algorithm can be obtained by combining the non- geometric ideas from equation 
[19.10) of [12] (taking their U to be our U) with the above geometrically-oriented exact fit algorithm, 
as follows. 1. Given A as above, of size rn×n, compute the Cholesky decomposition AIA = UrU [7,8,12,19]. 
That is, compute the unique n x n upper triangular U with nonnegative diagonal entries such that U~U 
= A'A. 2. Delete the last row of U to yield an (n- 1) x n matrix and treat the result as though it were 
the (n -1) × n matrix A in the exact fit case. That is, append a row of polynomials and form the determinant. 
The discussion of equation 19.10 in [12] shows that the resulting surface is the best algebraic fit subject 
to holding the n-th coefficient of q constant. (Hence the best algebraic fit under the normalization 
in which the n-th coefficient is 1 may be obtained by dividing q by its n-th coefficient.) The quality 
of fit (square root of sum of squares, amounting to standard deviation times vr~ is given by U,n (p in 
19.10 [12]), the one nonzero element of the discarded last row. Cholesky Without Square Roots. While 
the U'U decomposition has the merit of conceptual simplicity it has the drawback of requiring the extraction 
of n square roots. Cholesky decomposition without square roots (Exercise 19.40 of [12]) modifies step 
1 above by finding ~ x n matrices U and D satisfying ArA = U'DU where D is diagonal and the leading diagonal 
of U consists of l's. Step 2 is left unchanged. A suitable procedure for this decomposition is as follows. 
An n × n matrix P is initialized to A~A. Only the upper triangles of P and U require storage since A~A 
is symmetric and U is upper triangular. fori:= ltondo {U~ := 1; forj:=i+l tondo {u~ i := P~j/P.; fork:= 
jtondo Pjk := DE -Vo × P~k}} Note that the procedure modifies P. D is obtained as the diagonal of the 
final P. If P~ _< 0 (with negative Pii being possible only on account of roundoff error) then Uiy is 
set to 0 for all j _> i. The diagonal of U being 1 simplifies the computation of the cofactors in Step 
2, which requires only O(n 2} operations. The quality of fit is now obtained as Dun rather than U~n, 
the latter now always being 1. D~ is actually the square of the old U,~ and so is the sum of squares 
rather than its square root {amounting to vari- ance times n). The rest of D may be discarded since q 
and hence each row of U need only be determined up to a constant factor. Besides avoidance of square 
roots this decomposition has the property that the last coefficient of q produced in Step 2 is 1; the 
resulting q is as for the UPU decomposition after division by its n-th coefficient. (In this respect 
the method acts as though the n-th coordinate were the inde- pendent variable in a conventional least-squares 
regression.) Hence for conics the popular F = 1 normalization can be implemented with this method by 
putting 1 at the end of the basis, and for circles Bookstein's normalization A = 1 can be used by putting 
x 2 + y2 at the end, when these normalizations are appropriate. The principle novelty in the above is 
the application of well-understood least squares techniques, using normal equations and Cholesky decom- 
position, to fitting algebraic surfaces. Basis Order Independer*ce. Ideally a procedure for selecting 
a member of Q would be independent of the choice of basis for Q. This is possible using a somewhat more 
elaborate procedure than we shall consider here. With considerably less effort we are able to achieve 
independence of the order in which the elements of the basis are presented, via a procedure we shaft 
now describe. A corollary of this property is that no one coefficient is singled out as having to be 
nonzero, eliminating this source of singularities from this application of Cholesky decomposition. It 
would be particularly convenient if the algorithm were to hold con- stant (namely.l) the coefficient 
with maximum absolute value. Un-fortunately this is not the case for the procedure we shaft give -we 
have seen coefficients as large as n -1 (n the size of the matrix). It is tempting to conjecture that 
this is the limit on size of coefficients. We do not understand at all the mechanism by which the algorithm 
selects which coefficient is to be held constant.  ~ Computer Graphics, Volume 21, Number 4, July 1987 
The idea is to perform row-and-column permutations of the (more or less) as-yet unprocessed P during 
the Cholesky decomposition. Just before the assignment of 1 to Uii, the maximum Pyy for 3" >- i is found, 
and if 3" ¢ i a row-and-column permutation of P is performed in place, exchanging i with j; in effect 
the i-th and 3"-th basis elements are exchanged. We omit the proof that the result is independent of 
basis order. The method lends itself to partial permutations, in which some ele-ments of the basis are 
not permuted. In fitting lines and planes for example the constant basis element (1) can be left undisturbed 
if it is put at the beginning of the basis, though we have not encountered a situation where it is actually 
beneficial to leave it alone. Incremental addition and deletiou o/points. The matrix A'A is n x n, which 
is considerably smaller than A when rn >> n. Yet despite the extent of the data reduction implied by 
this compaction it is very easy to update A'A to reflect the addition or deletion of points. Each point, 
as a row of A, forms a 1 × n matrix Z, with Z'Z the same size as A'A. To add or delete point Z from Aj 
add or subtract Z'Z from A'A. In our implementation we compute A'A exclusively by this method. Weiqhtinq. 
To increase or decrease the contribution of a point~ scale either Z or Z'Z (as convenient) appropriately. 
Doubling Z'Z has the same effect as having two occurrences of the point. One might decrease the weight 
of a point if it is relatively unreliable; conversely one might increase its weight to force the surface 
to pass closer to it. Cost. If AJA is maintained incrementally the cost to add or delete a point is n 
~ multiplications (to form ZIZ) and n 2 additions (to add or subtract it). Hence adding or deleting m 
points in a b~tch (without then running Cholesky) costs mn 2 such operations. The constant factor in 
the cost of Choleski decomposition of A'A makes it quite cheap in comparison with Gaussian elimination; 
the procedure requires only n3/6 multiplications and additions. Because U is triangular computing the 
determinant of the modified U requires only n 2 multiplications and additions. Thus for circles, with 
n = 4, the cost is 16m + 26 multiplications and additions. For conics, with n = 6, the cost rises to 
36m + 36. The additional cost of the row-and-column-permuting variant is 0(n 2) exchanges, which is dominated 
by the other costs. Quality of Fit. We have not been able to analyze this method directly. Experience 
with its use however demonstrates the need for the basis- permuting varian% in the absence of which the 
singularities consisting of fits with zero n-th coefficient are very noticeable. Permuting the basis 
eliminates those singularities, but we have noticed in the case of planar fits a tendency to avoid exact 
45-degree fits when the data is very badly scattered. It would be of considerable interest to know whether 
this situation could be understood in terms of the shape of a normalization surface associated with the 
algorithm. Stability. In the method of normal equations, all steps save the compu- tation of A~A are 
numerically very stable; the replacement of A by AtA has the destabilizing effect of squaring the condition 
number. When A is ill-conditloned, such as when sampling points from two nearly paral- lel coplanar lines 
to determine their common plane, normal equations aggravate the situation. This effect may be offset 
by either (i) doubling precision, (ii) using an alternative method based on Householder or Givens transformations 
of A [12], or (iii) designing the application to avoid geometric instabilities. Our preference has been 
a combination of (i) and (iii), (ii) having somewhat inferior performance to Cholesky decomposition, 
and considerably worse performance when points are to be added and deleted incrementally, which our application 
makes extensive use of. 7. Spherical leit In this section we give a quadratic-norm metric for circles 
and spheres which is substantially more robust than the only other such metric to have previously been 
proposed for circles, namely Bookstein's. As pointed out in the section on algebraic distance, the singularities 
for Bookstein's metric are lines. Such singularities tend to increase the curvature of the fit. The following 
illustration of this nonrobustness of Bookstein's metric should give some idea of the rate at which the 
fit deteriorates as the curve of best fit approaches a line. Figure 1 shows, under each of the A = 1 
and geometric distance metrics, the best fitting circle to the points (-1,0), (-.3,y), (.3, .1), (1,0) 
for y = .1,.02,-.02~-.06. The A = I circle is in each case the one with higher curvature~ with equality 
only at y = .1. ...~o! i y=.02 y=-. 02   +~.~,,~\ "+ y=-.06 Figure 1. Best fitting circles under 
A = 1 and geometric metrics. The A = 1 circle can be seen to become a very poor fit as the best geometric 
fit increases in radius. We repair this problem as follows. The circle ideal consists of all poly- nomials 
q(z,y) = A(x 2 + yZ) + Dx + Ey + F. For any such q the 3D surface z = q(x, y) (z being the direction 
of sinking in the sink-or-swim model of Section 4) is a paraboloid of revolution. Our observation is 
that although IVql is not constant, it is constant on Z(q), by the circu- lar symmetry of the paraboloid. 
This motivates normalizing q to make IVqt = 1 on Z(q). Now the partial derivatives of q are Oq/Ox = 2Ax 
+ D and Oq/Oy = 2Ay + E. Hence [Vq[~ = 4A2x 2 + 4DAx + D 2 + 4A2y 2 + 4EAy + E 2 = 4A(Dx + Ey + A(x ~ 
+ y~)) + D 2 + E 2 = 4A(q(z,y) -F) + D ~ + E ~. The term q(x,y) vanishes on Z(q), where 1~7q]2 = D 2 
+ S z -4AF. Hence we obtain the invariant D "~ + E ~ -4AF = 1. (The normalization itself~ meaning the 
quantity by which q must be divided to be normalized, is x/D 2 + E 2 - 4AF. However we need not actually 
perform this operation; for finding the circle of best fit it suffices to hold the invariant constant.) 
The circles fitted with this metric to the data of Figure 1 are indistinguishable from the best geometric 
fits. One way to visualize the effect of this invariant is to picture an inverted cone (apex at top) 
with vertical axis and 45-degree side. This cone may be translated arbitrarily (three degrees of freedom) 
to intersect the plane in an arbitrary circle. The normal paraboloid for that circle is the one which 
is tangent to the cone at the circle; our invariant finds exactly that paraboloid. For spheres in R 3, 
q(x, y, z) = A(x2+y2+z2)+Dx+Ey+Fz+G = O, for which the corresponding form to be held constant is D2+E2+F2-4AG, 
and similarly for higher dimensions. Our normalization, like Bookstein's (taking his to be ~fA), is a 
Eu- clidean invariant, that is, its quotient with Euclidean distance is in- variant, under similarities 
-translations, rotations, and scalings -of the plane. Bookstein argues that a normalization containing 
D, E, or F cannot be invariant even under translations because these quantities can individually grow 
without bound. The inapplicability of this ar- gument to our normalization should be clear: although 
D and E can indeed grow without bound, their growth can nevertheless be cancelled by the growth of 4AF. 
Bookstein also argues that a normalization which is not positive-definite will fail to fit data lying 
exactly on certain curves. This seems to assume that when such a normalization passes through zero on 
its way to becoming negative it must represent an exact fit to something. The inapplicability of Bookstein's 
argument to our normalization follows from the fact that D 2 + E 2 - 4AF is nonpositive only for circles 
of zero radius, which is not the exact or even best fit for any sample not having infinitely many exact 
fits. ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 The main adverse effect with our invariant arises from 
the radial cur- vature of the paraboloid, i.e. its departure from a cone. For scattered data l~Tq] will 
be larger for more outlying data, increasing linearly with distance from the axis of the paraboloid. 
This makes the fit more responsive to data lying further out, which tends to decrease the cur- vature 
of our fit. However this is a second order phenomenon, being tied to the radial curvature of the paraboloid, 
as opposed to the first order phenomenon illustrated by Figure 1, which depends on the value of IVql 
itself rather than its radial variation. The other drawback of our invariant is that it involves the 
extraction of eigenvectors. Bookstein's invariant A = 1 is simple enough to be used with our Simple Fit 
algorithm, taking the A coordinate to be the final basis element, which the nonpermuting version of our 
algorithm auto- matically sets to 1. The permuting version of our algorithm typically picks some other 
coefficient to be 1; in the case of the data of Figure 1 it picks E, the coefficient of y, which has 
the effect of yielding circles whose radius is larger than that of the best fitting circle by factors 
of 1, 1.03, 1.1, 1.5 respectively (top to bottom), rather than smaller. How- ever in the absence of a 
good understanding of what Permuting Simple Fit is up to we remain uncertain as to its reliability for 
circle fitting. The conclusion then is, for safety use the invariant D 2 q- E 2 - 4AF, but if you are 
willing to take risks then use either Simple Fit with Bookstein's invariant, or Permuting Simple Fit 
which supplies its own incompletely understood invariant. Application to Conics and Quadries. Our method 
for circles does not generalize directly to ellipses and other conics, since these lack the circular 
symmetry on which our method depended. This problem is addressed by Sampson's iterative method [24], 
as we saw at the end of Section 4. In this method Sampson repeatedly fits a conic using Bookstein's invariant 
A 2 + B2/2 + C 2, at each stage weighting each point p by 1/[~7q(p) I using the q fitted at the previous 
stage. The difficulty we have observed with Bookstein's invariant for circles carries over to conics: 
conics of low curvature are avoided. Hence this problem can be inherited by Sampson's algorithm. We cure 
this by showing how to generalize our circle solution to conics. Our solution is to use the basis x 2 
+ y2, 2xy, x 2 - y2, x, y, 1. The ad-vantage of this basis over the customary conic basis z 2, zy, y2, 
z, y, 1 is that it more cleanly separates out the circular (rotationally invariant) component of a toni% 
namely the x 2 + y2 basis element. Taking the coefficients to be A(x 2 + y2) + 2Bxy q- C(x 2 - y2) + 
Dx + Ey + F, we may continue to use our invariant D 2 + E z - 4AF, simply ignoring the coefficients B 
and C The effect is as though we had a circle whose diameter is in between the lengths of the major and 
minor axes, in the case of an ellipse; this is adequate to get a good initial fit of a conic. (Note that 
if B and C are normalized to B 2 + C 2 = 1 then they are respectively sin(2~) and cos(20) where d is 
the orientation of an axis of the conic to the X axis. This is where the 2 in 2xy is used.) The generalization 
of this basis to higher dimensions is to take the sum of the squares (in four dimensions: to 2 + x 2 
+ y2 q_ z 2) along with the differences of consecutive squares (w 2 - ~2, x2 _ y2, y2 _ z 2) and the 
cross terms (2wx, 2wy, 2wz, 2xy, 2zz, 2yz), along with all degree 0 and 1 terms (w, x, y, z, 1). 8. Blend 
leit Given a set bi = O, i = 1,...,k, of base surfaces, a blending surface is a surface tangent to all 
of them. (In two dimensions substitute curve for surface.) The problem of finding blending surfaces has 
received considerable attention in the literature. Some particularly interesting recent approaches are 
those of Middleditch and Sears [14] and Hoffman and Hopcroft [10,11]. In this section we first describe 
a new method of constructing blend-ing surfaces that generalizes both the Middleditch-Sears and Hoffman- 
Hopcroft methods. We then apply this construction to give a method of least-squares fitting of such surfaces; 
however the construction should prove to be of considerable utility in the theory and applications of 
blending surfaces independent of our fitting application. The principle behind our construction can be 
understood in 2D by considering the lines Z(x) and Z(y), respectively the Y-axis and the X-axis. The 
zeros of any linear combination c~x + fly will pass through the intersection of Z(x) and Z(y), but need 
not be tangent to either of these lines there. However the zeros of any linear combination (xx~+fly with 
~ # 0 will be tangent to Z(y) (consider the curve y = ax 2 for any c~). The principle is that c~x 2 initially 
grows more slowly with movement away from Z(x} than does fly with movement away from Z(y), provided #6 
# 0. Hence in the neighborhood of the intersection the zeros of czx 2 5- BY will tend to "stick" to Z(y). 
The higher the power ~7 the less "sticky" is Z(xU). This principle generalizes to two arbitrary polynomials 
in xl,..., xd in place of x and y; raising the first to a sufficiently high power will make it negligibly 
sticky compared to the second at the intersection of their respective zeros, whence the zeros of their 
linear combination will stick to the second. For our blending surface construction the two polynomials 
are the prod- uct 1-L bl of polynomials defining the base surfaces, and a polynomial t, defining the 
truncating surface, which intersects each base surface in the point(s) of tangency of the blending surface 
to that base surface. Then by the above principle there is an integer ~/large enough that the zeros of 
any linear combination c~t 7 + fl l]i bl, fl # 0, will be tangent to each bi where Z(bi) intersects Z(t). 
The canonical example of this in the plane is given by the conic spline, which is a conic section inscribed 
in a triangle ABC, tangent to AB at A and to BC at C. If a,b,c are linear combinations of x,y, 1 such 
that their respective zeros are the lines BC, CA, and AB, then such conics are given by the zeros of 
the linear combinations of b 2 and ac. Here Z(b) is the truncating surface, or rather llne, and Z(a), 
Z(c) are the two base lines. A more interesting example, in 3D, is given by the problem of finding a 
blending surface (fillet) between equal-diameter cylinders x 2 + z 2 = 1 and y2 + z 2 = 1 (unit radius 
cylinders along the Y and X axes respectively). We take Z(t) to be the ellipsoid Ax 2 q-/~y2 + z 2 = 
1, where A and ~u are reals less than unity. This ellipsoid is tangent to both cylinders where they intersect 
the Z-axis, and otherwise intersects each cylinder in the curve where the blending surface will be tangent 
to that cylinder, with A and u providing some variety in the choice of curve. The blending surface is 
then the degree 4 surface Z(a(Az 2 + #y2 q_ z 2 __ 1)2 q_ fl(x 2 q_ z 2 _ 1)(y2 .4_ z 2 -- 1)), with 
c~//3 determining how "fat" the fillet is: larger is fatter (more metal if the fillet were a weld). This 
generalizes the Middleditch-Sears method by allowing t to be ar-bitrary; Middleditch and Sears restrict 
t to be a linear combination of bl, ..., bk, 1 (the 1 being essential), which rules out the truncating 
surface we used to solve the above cylinder-blending problem. It also considerably simplifies the Hoffman-Hopcroft 
potential method [10], in particular eliminating the complexity in the case when the intersection curve 
is reducible (e.g. with the above equal-diameter-cylinders prob- lem), as well as generalizing it by 
permitting more than two surfaces to be blended simultaneously. Given this notion of a blending surface 
we turn to the problem of find- ing such a surface tangent to a given set of base surfaces that best 
fits a given set of data points. For example we may have two rods welded together, along with a large 
number of measurements of the fillet be- tween them, and we want to reduce these samples to a good analytical 
model of the fillet. This includes discovery of the appropriate truncat-ing surface Z(t); in the rod-blending 
example we would assume that it was an ellipsoid~ leaving only A and ~ to be found in order to deter-mine 
t, corresponding to selecting a surface having the shape of order 3 generated by the basis x2,y 2, z 
2- 1. A weaker version of this problem assumes that the truncating surface is completely specified, as 
for example in [15]. This is not always a good assumption. While it is usually easy to determine the 
base surfaces -they are typically either given or are large enough as to be easily mea- sured -the exact 
points of intersection of a sampled blending surface with the base surfaces are not so easily measured, 
since these points can move a long distance under a very small perturbation of the blending surface. 
Tangency is an inherently unstable condition in this respect. We give a very simple method for choosing 
t of a given shape of order n so as to get the blending surface of best fit. Write the implicit equation 
of the blending surface as (c~t) 7 = Hi b~. Rewrite it as c~t = (]-Ii b,) 1/~. (~ ~ 2~reat this as 
the problem of fitting the shape whose ideal has the n+ 1 basis functions tl,..., t~, (YL bl) a/~, where 
the ti's are the basis for the truncating shape. Previously all our ideals consisted of polynomials. 
We now have an ideal Q (of the ring of all functions q : R a --+ R) containing the nonpolyno- mial (['L 
hi) 1/~" The beauty of least-squares fitting is that nothing in the theory depends on what functions 
appear in Q, just so long as Q forms a finite-dimensional vector space, here n + 1. Of course we need 
to be able to compute the functions in order to construct the rn× (n+l} matrix A, but ([L bi} a/~ is 
easily evaluated at each of the m sample points. We also need to be sure that the functions in the basis 
are independent; it is easily seen that this will be the case if there is only one nonpolynomial in the 
set and the polynomials form an independent set, which describes the case at hand. In the case of conics 
we are given tangents Z(a) and Z(c), a and c being linear combinations of x, y, 1, and seek a linear 
combination b of x, y, 1 such that Z{c~b 2 +flac) best fits a given set of data points. In this case 
the above rather dry algebraic solution to this problem has a beautiful geometric visualization. If we 
take a, v, c to be the coordinates of a 3D space then the 3D surface v 2 = 4ac turns out to be the cone 
illustrated in Figure 2 (which is taken from Figure 2 of [22], where we give a relatively novel analytic 
treatment of conic sections by treating them literally as plane sections of a cone). For each data point 
p let a(p) denote the value of a at p (the result of evaluating a given the x and y coordinates of p) 
and similarly for c(p). Each such point then corresponds to a pair of points (a(p), :£v, c(p))on the 
cone, obtainable as v = +x/-4~(p)c(p).Discard the -v point. The resulting points, ranging over all the 
given data, should now approxi- mate a plane in Ave space if as points in XY space they approximate a 
conic. Then the equation b = 0 of this plane yields the desired b. A conic of good fit is obtained by 
finding the plane of best fit. This is the geometric description of our method for the case of conics. 
It will be noted that the method is more sensitive to noise in points in the neighborhood of either tangent. 
This is due to the cone being B 0 Figure 2. The AVC cone and ABC conic. steeper (treating V as up) near 
the tangents. This increased sensitivity there corresponds to looking at the points more closely as they 
approach the tangent in order to tell exactly where the point of tangency is. This insight into the stability 
of the method is very easily deduced from this geometric picture of our fitting process. Additional Constraints. 
Sometimes the truncating surface t will be partially constrained, e.g. one or more points or curves of 
tangency may be given. When such a constraint can be represented as a finear dependence between the coefficients 
to be found, the dependence can be used to reduce the order of the shape of the truncating surface, thereby 
transforming the fitting problem to a simpler one. This is the situation that obtains when either or 
both of the points of tangency are known when fitting a conic given two of its tangents. Typography Application. 
Our application for blend fit has been as part of a two-stage process for reconstructing font outlines 
from scanned-  Computer Graphics, Volume 21, Number 4, July 1987 in images. The first stage finds tangents 
at lines, extrema, inflexion points, and other suitable articulation points. The second stage then fills 
in the remainder of the outline by finding the best fitting conic splines as blending curves to these 
tangents. Acknowledgments I am grateful to Gene Golub for some informative discussions. Bibliography 
[1] A. Albano, Representation of Digitized Contours in Terms of Conic Arcs and Straight-Line Segments, 
Computer Graphics and Image Pro- cessing 3, 23-33, 1974. [2] R.H. Biggerstaff, Three Variations in Dental 
Arch Form Estimated by a Quadratic Equation, Journal of Dental Research 51, 1509, 1972. [3] F.L. Bookstein, 
Fitting Conic Sections to Scattered Data, Computer Graphics and Image Processing 9, 56-71, 1979. [4] 
D.B. Cooper and N. Yalabik, On the Computational Cost of Approx- imating and Recognizing Noise-Perturbed 
Straight Lines and Quadratic Arcs in the Plane, IEEE Transactions on Computers (3-25, 10, 1020- 1032~ 
October 1976. [5] C. de Boor, A Practical Guide to Splines, Springer-Verlag, 1978. [6] I.D. Faux and 
M.J. Pratt, Computational Geometry for Design and Manufacture, Ellis Horwood, 1978. [7] Y. Gordon, Numerical 
Methods for CAD, MIT Press, 1986. [8] A.A. Giordano and F.M. Hsu, Least Squares Estimation with Applications 
to Digital Signal Processing, Wiley, 1985. [9] R. Gnanadesikan, Methods for Statistical Data Analysis 
of Multivariate Observations, Wiley, 1977. [10] C. Hoffman and J. Hopcroft, Automatic Surface Generation 
in Computer Aided Design, The Visual Computer, 1, 2, 92-100 (1985). [11] C. Hoffman and J. Hopcroft, 
Quadratic Blending Surfaces, Com-puter Aided Design, 18, 6, 301-306 (Jnl-Aug. 1986). [12] C.L. Lawson 
and R.J. Hanson, Solving Least-Squares Prob- lems, Prentice-Hall, 1974. [13] E.A. Lord and C.B. Wilson, 
The Mathematical Description of Shape and Form, Ellis Horwood, Chichester, 1984. [14] A.E. Middleditch 
and K.H. Sears, Blend Surfaces for Set Theoretic Volume Modelling Systems, Computer Graphics 19, 3 (Siggraph-85), 
161-170, July 1985. [15] V.S. Nalwa and E. Pauchon, Edgel-Aggregation and Edge-Descrip- tion, Eighth 
International Conference on Pattern Rccogrdtion, 604-609, Paris, Oct. 1986, [16] K. Paton, Conic Sections 
in Chromosome Analysis, Pattern Recog- nition 2, 39-51, 1970. [17] T. Pavlidis, Curve Fitting with Conic 
Splines, ACM Transactions on Graphics 2, 1, 1-31, January 1983. [18] K. Pearson, On lines and planes 
of closest fit to systems of points in space, Philos. Mag. Eer. 6, 2,559, 1901. [19] C. Pearson, Numerical 
Methods in Engineering and Science, Van Nostrand Reinhold, 1986. [20] M.A. Penna and R.R. Patterson, 
Projective Geometry and its Applications to Computer Graphics, Prentice-HMl, New Jersey, 1986. [21] M. 
Plass and M. Stone, Curve-Fitting with Piecewise Parametric Cnbics, Computer Graphics 17, 3 (Siggraph-83), 
229-239, July 1983. [22] V. Pratt, Techniques for Conic Splines, Computer Graphics 19, 3 (Siggraph85), 
151-159, July 1985. [23] D. Proflltt, The Measurement of Circularity and Ellipticity on a Digital Grid, 
Pattern Recognition 15, 5, 383-387, 1982. [24] P.D. Sampson, Fitting Conic Sections to "Very Scattered" 
Data: An Iterative R.efinement of the Bookstein Algorithm, Computer Graph- ics and Image Processing 18, 
97-108, 1982. I~ ~®®~*J SIGGRAPH '87, Anaheim, July 27-31, 1987 [25] K. Turner, Computer Perception 
of Curved Objects using a Televi- sion Camera, Ph.D. Thesis~ Dept. of Machine Intelligenc% University 
of Edinburgh, Nov. 1974. Appendix The following was generated using most of the techniques described 
in the paper. The first image is the result of filtering and thresholding an 18-polnt sans-serif m digitized 
using a Datacopy camera. The second is the result of fitting conic spllnes to the first. The fitted outline 
consists of 8 conic splines (2 per curve) and 11 lines. This example is intended only to demonstrate 
potential applications of the method and should not be regarded as any indication of the limits of general 
applicability of the fitting methods of this paper. In particular the curves are not particularly faithful 
to the original (the arrows point to two of the more objectionable portions}, due to overemphasis of 
position fidelity at the expense of tangent fidelity. We plan to further apply the techniques of this 
paper to correct this.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37421</article_id>
		<sort_key>153</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[Set operations on polyhedra using binary space partitioning trees]]></title>
		<page_from>153</page_from>
		<page_to>162</page_to>
		<doi_number>10.1145/37401.37421</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37421</url>
		<abstract>
			<par><![CDATA[We introduce a new representation for polyhedra by showing how Binary Space Partitioning Trees (BSP trees) can be used to represent regular sets. We then show how they may be used in evaluating set operations on polyhedra. The BSP tree is a binary tree representing a recursive partitioning of d-space by (sub-)hyperplanes, for any dimension d. Their previous application to computer graphics has been to organize an arbitrary set of polygons so that a fast solution to the visible surface problem could be obtained. We retain this property (in 3D) and show how BSP trees can also provide an exact representation of arbitrary polyhedra of any dimension. Conversion from a boundary representation (B-reps) of polyhedra to a BSP tree representation is described. This technique leads to a new method for evaluating arbitrary set theoretic (boolean) expressions on B-reps, represented as a CSG tree, producing a BSP tree as the result. Results from our language-driven implmentation of this CSG evaluator are discussed. Finally, we show how to modify a BSP tree to represent the result of a set operation between the BSP tree and a B-rep. We describe the embodiment of this approach in an interactive 3D object design program that allows incremental modification of an object with a tool. Placement of the tool, selection of views, and performance of the set operation are all performed at interactive speeds for modestly complex objects.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P300127</person_id>
				<author_profile_id><![CDATA[81100074144]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Thibault]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology, Atlanta]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P33653</person_id>
				<author_profile_id><![CDATA[81100625208]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bruce]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Naylor]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Bell Laboratories, Murray Hill, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>3975</ref_obj_id>
				<ref_obj_pid>3973</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[D. Ayala, P. Brunet, R. Juan, and 1, Navazo, "Object Representation by Means of Nonminimal Division Quad trees and Octrees," ACM Transactions on Graphics Vol. 4(1) pp. 41-59 (January 1985).]]></ref_text>
				<ref_id>Ayal85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356797</ref_obj_id>
				<ref_obj_pid>356789</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Jon Louis Bentley and Jerome H. Friedman, "Data Structures for Range Searching," Computing Surveys Vol. 11(4), pp. 397-409 (December 1979).]]></ref_text>
				<ref_id>Bent79</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Ingrid Carlbom, Indranil Chakravarty, and David Vanderschel, "A Hierarchical Data Structure for Representing the Spatial Decomposition of 3-D Objects," 1EEE Computer Graphics and Applications, pp. 24-31 (April 1985).]]></ref_text>
				<ref_id>Carl85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807481</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[H. Fuchs, Z. Kedem, and B. Naylor, "On Visible Surface Generation by a Priori Tree Structures," Computer Graphics 1Iol. 14(3), (June 1980).]]></ref_text>
				<ref_id>Fuch80</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801134</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Henry Fuchs, Gregory D. Abram, and Eric D. Grant, "Near Real-Time Shaded Display of Rigid Objects," Computer Graphics VoL 17(3) pp. 65-72 (July 1983).]]></ref_text>
				<ref_id>Fuch83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Yehuda E. Kalay, "Determining.the Spatial Containment ofa Point in General Polyhedra," Computer Graphics and Image Processing Vol. 19 pp. 303-334 (1982).]]></ref_text>
				<ref_id>Kala82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15904</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[David H. Laidlaw, W. Benjamin Trumbore, and John F. Hughes, "Constructive Solid Geometry for Polyhedral Objects," Computer Graphics Vol. 20(4)pp. 161-170 (August 1986).]]></ref_text>
				<ref_id>Laid86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801159</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Martii Mantyla and Markku Tamminen, "Localized Set Operations for Solid Modeling," Computer Graphics I/ol. 17(3) pp. 279-288 (July 1983).]]></ref_text>
				<ref_id>Mant83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[D. Meagher, "Geometric Modeling using Octree Encoding," Computer Graphics and Image Processing 1Iol. 19(June 1982).]]></ref_text>
				<ref_id>Meag82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>909951</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Bruce F. Naylor, "A Priori Based Techniques for Determining Visibility Priority for 3-D Scenes," Ph.D. Thesis, University of Texas at Dallas (May 1981).]]></ref_text>
				<ref_id>Nayl81</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Bruce F. Naylor and William C. Thibault, "Application of BSP Trees to Ray-Tracing and CSG Evaluation," Technical Report GIT-ICS 86/03, School of Information and Computer Science, Georgia Institute of Technology, Atlanta, Georgia 30332 (February 1986).]]></ref_text>
				<ref_id>Nay186</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4333</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Franco P. Preparata and Michael ion Shamos, Computational Geometry: An Introduction, Springer-Verlag, New York (1985).]]></ref_text>
				<ref_id>Prep85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6024</ref_obj_id>
				<ref_obj_pid>6020</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[L. K. Putnam and P. A. Subrahmanyam, "Boolean Operations on n-Dimensional Objects," IEEE Computer Graphics and Applications, pp. 43-51 (June 1986).]]></ref_text>
				<ref_id>Putn86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Aristides A. G. Requicha and Robert B. Tilove, "Mathematical Foundations of Constructive Solid Geometry: General Topology of Closed Regular Sets," TM-27a, Production Automation Project, University of Rochester, Rochester, New York 14627 (June 1978).]]></ref_text>
				<ref_id>Requ78</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356833</ref_obj_id>
				<ref_obj_pid>356827</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Aristides A. G. Requicha, "Representations for Rigid Solids: Theory, Methods, and Systems," Computing Surveys 1Iol. 12(4) pp. 437-464 (December 1980).]]></ref_text>
				<ref_id>Requ80</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Aristides A. G. Requicha and Herbert B. Voelcker, "Boolean Operations in Solid Modeling: Boundary Evaluation and Merging Algorithms," Proceedings of the IEEE Vol. 73(1) pp. 30-44 (January 1985).]]></ref_text>
				<ref_id>Requ85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Scott D. Roth, "Ray Casting for Modeling Solids," Computer Graphics and Image Processing Vol. 18 pp. 109-144 (1982).]]></ref_text>
				<ref_id>Roth82</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[R. A. Schumacker, R. Brand, M. Giltitand, and W. Sharp, "Study for Applying Computer-Generated Images to Visual Simulation," AFHRL-TR-69-14, U.S. Air Force Human Resources Laboratory (t969).]]></ref_text>
				<ref_id>Schu69</ref_id>
			</ref>
			<ref>
				<ref_obj_id>913766</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[William C. Thibault, "Application of Binary Space Partitioning Trees to Geometric Modeling and Ray-Tracing", Ph.D. Dissertation, Georgia Institute of Technology, Atlanta, Georgia, (1987).]]></ref_text>
				<ref_id>Thib87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Robert B. Tilove, "Set Membership Classification: A Unified Approach to Geometric Intersection Problems," IEEE Transactions on Computers VoL C-2900) pp. 874-883 (October 1980).]]></ref_text>
				<ref_id>Tilo80</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358195</ref_obj_id>
				<ref_obj_pid>358105</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Robert Tilove, "A Null-Object Algorithm for Constructive Solid Geometry," Communications of the ACM Vol. 27(7) (July 1984).]]></ref_text>
				<ref_id>Tilo84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[J. R. Woodwark and K. M. Quinlan, "Reducing the effect of complexity on volume model evaluation," Computer Aided Design Vol. 14(2) (1982).]]></ref_text>
				<ref_id>Wood82</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~) ~ Computer Graphics, Volume 21, Number 4, July 1987 Set Operations on Polyhedra Using Binary Space 
Partitioning Trees William C. Thibault Georgia Institute of Technology Atlanta, G,4 30332 and Bruce 
F. Naylor ,4 T&#38; T Bell Laboratories Murray Hill, NJ 07974 Abstract We introduce a new representation 
for polyhedra by showing how Binary Space Partitioning Trees (BSP trees) can be used to represent regular 
sets. We then show how they may be used in evaluating set operations on polyhedra. The BSP tree is a 
binary tree representing a recursive partitioning of d-space by (sub-)hyperplanes, for any dimension 
d. Their previous application to computer graphics has been to organize an arbitrary set of polygons 
so that a fast solution to the visible surface problem could be obtained. We retain this pro- perty (in 
3D) and show how BSP trees can also provide an exact representation of arbitrary polyhedra of any dimension. 
Conversion from a boundary representation (B-reps) of polyhedra to a BSP tree representation is described. 
This technique leads to a new method for evaluating arbitrary set theoretic (boolean) expressions on 
B-reps, represented as a CSG tree, producing a BSP tree as the result. Results from our language-driven 
implementation of this CSG evaluator are discussed. Finally, we show how to modify a BSP tree to represent 
the result of a set operation between the BSP tree and a B-rep. We describe the embodiment of this approach 
in an interactive 3D object design program that allows incremental modification of an object with a tool. 
Placement of the tool, selection of views, and per- formance of the set operation are all performed at 
interactive speeds for modestly complex objects. CR Categories 1.3.5 [Computer Graphics]: Computational 
Geometry and Object Modeling - object representation and geometric algorithms. Keywords -polyhedra, set 
operations, geometric modeling, geometric search, point location. I. Introduction While the study of 
polyhedra has an ancient history, computer science has given it renewed attention in the various sub-disciplines 
of compu- tational geometry, geometric modeling, computer graphics, robotics, and computer vision. Its 
attractiveness stems from the relative simpli- city of linear computations when compared to non-linear, 
coupled with the fact that linear approximations of non-linear sets can often be quite satisfactory. 
An important example of this comparative simplicity is set operations: union, intersection, difference 
and exclusive-or (and their complements). The algebra of set operations defined on the col- lection of 
linear sets of any dimension ~< some d is closed (assuming a Permission to copy without fee all or part 
of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM copyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, 
or to republish, requires a fee and/or specific permission. &#38;#169; 1987 ACM-0-89791-227-6/87/007/0153 
$00.75 countable number of operations). This is not true of non-linear sets; for example, the intersection 
of two quadrics (second degree) can be a fourth degree curve. When computational speed is important, 
such as in interactive object design, using polyhedral approximations of non-linear solids can provide 
a very effective alternative to non-linear com- putations. On the other hand, for operation~ which are 
not speed-critical, a second unapproximated non-linear representation can be used, if the greater accuracy 
is needed. The most prominent method of representing polyhedra at this time would appear to be boundary 
representations (B-reps): in a d dimen-sional space, a d-polyhedron (also called a d-polyto]ge) is represented 
by a set of (d-1)-polyhedra, called faces, which are in turn represented by (d-2)-polyhedra, and so on 
until d equals 0, at which point the d coordinates of a vertex are used. An alternative suitable for 
representing convex polyhedra is provided by the volumetric approach, where the intersection of a set 
of halfspaees determines a polyhedron. In this paper, we develop a new approach first presented in [Nay186] 
and describe in greater detail in [Thib87]. It is based on the dimen- sion independent concept embodied 
in the Binary Space Partitioning Tree, abbreviated BSP tree, which, at its simplest, is a binary tree 
whose non-leaf nodes are labeled with hyperplanes and whose leaves correspond to cells of a convex polyhedral 
tessellation (partitioning) of d-space. The approach provides what is essentially a volumetric representation 
of general linear polyhedra. What we mean by general is that any genus (handles/holes) is permissible, 
any number of con- netted components (separate objects), and regions of connectivity with no interior, 
such as two parts connected only by a vertex. More gen- erality is available in that the interior of 
the polyhedra need not be completely bounded, i.e. it may be (semi-)infinite. Previous work has established 
the BSP tree as an effective representa- tion of polyhedra for efficient visible surface determination, 
both in polygon tiling environments [Schu69] [Fueh80] [NaylSl] [Fueh83] and for ray-tracing [Nay186] 
(Figure RAY-TRACING). In this paper, we concentrate on the problem of evaluating set operations, the 
set theoretic analog of boolean operations, defined on 3D polyhedra. This takes two forms. One begins 
with a set (theoretic) expression represented as a tree (i.e. a CSG tree) defined on a set of polyhedra 
represented by B-reps. The method produces the polyhedron defined by the CSG tree by constructing its 
(non-unique) BSP tree representa-tion. The resulting tree can then be used for rendering by the tech- 
niques referred to above or as input to the second approach. The second approach takes a BSP tree as 
one operand and a B-rep as the other and produces a new BSP tree determined by the set operation via 
modification of the original tree. We have used this technique as the basis for an interactive program 
that supports modification of a work piece, represented by a BSP tree, through the adding, subtracting 
or  ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 intersecting of a tool, represented by a B-rep. 2. Representation 
of Polyhedra by BSP Trees 2.1 Generic BSP Trees l A BSP tree represents a recursive, hierarchical partitioning, 
or subdivi- sion, of d-dimensional space. It is most easily understood as a process which takes a subspace 
and partitions it by any hyperplane that inter- sects the interior of that subspace. This produces two 
new subspaces that can be further partitioned. Figure BSPT illustrates the relation- ship between the 
partitioning of space and the corresponding BSP tree. In (a), we see a recursive partitioning of the 
plane. Note how parti- tioning first by u produces two subspaces whose subsequent partition- ings proceed 
independently of each other. The distinction between the two halfplanes formed by a line is indicated 
by the orientation of the normal vector to each line (indicated by arrows). Which of the two possible 
orientations is used is typically arbitrary. Now referring to (b), we see that in the corresponding BSP 
tree, each (sub-)line is asso- ciated with an internal node of the tree. The right subtree of each internal 
node represents the region of the plane lying to the side of the line pointed to by the normal. The left 
subtree represents the other side. The resulting partitioning produces a set of unpartitioned sub-spaces 
that correspond to leaves of the tree (labeled with digits). , / f\ /\  Y' 6 /\ ' /\ 5 6 Ca) (b) 
Figure BSPT. Geometry of a 2D partitioning (a) and its BSP tree (b). More formally, for a hyperplane 
H = {(xl ..... xd)la~xl + '  + adxd+ aa+l ffi 0}, the right (or in B-rep parlance, the "front") halfspace 
of H is H-I-~ {(3fl ..... xa)lalxl d- , d- adXd+ aa+j > 0}, and the left (or "back") halfspace of H 
is H-= {(xl ..... xa)[alxl + " " + adXd+ aa+l < 0}). The right side of H lies to the side of H in the 
direction of the hyperplane's normal, (al,...,aa). Each node v represents a region of space R (v) (to 
be defined below). Leaves correspond to un-partitioned polyhedral regions, which we call cells. Each 
internal node v of the tree is associated with a partitioning hyperplane, Hv, which intersects the interior 
of R (v). The hyperplane partitions R(v) into three sets: R(v) f') H~ +, R(v) f') H~, and R (v) A Hr. 
The d-dimensional region in H + is represented by the right child of v, v.right, and the region in H~- 
is represented by the left child, v.left. The intersection of H~ and R (v) is called the sub-hyperplane 
of Hv, indicated by SHp (v), and is of dimension d-1. e(v) is the intersection of open halfspaces on 
the path from the root to v. More precisely, for each edge (VhV2) in the tree we associate a half space 
HS(vl,v2) defined as follows: for any node v, let I. This section is an adaptation of work presented 
in [NaylSI]. HS(v,v.left) denote H~, and HS(v,v.right) denote Hv +. Let E(v) denote the set of edges 
on the path from the root to v. Then R(v)~e~vHS(e). For the root node, whose E(v) is empty, R(v) is defined 
to represent all of d-space. Thus, R (v) is convex, non-empty, may not be completely bounded, and is 
topologically open. It also fol- lows that sub-hyperplanes have the same properties. An important relationship 
between sub-hyperplanes and regions is that the sub-hyperplanes associated with nodes on the path from 
the root to v con-tain the boundary of R (v). Finally, a trivial BSP tree consists of only a single node 
(a cell). 2.2 Representation of Regular Sets A regular set S has an interior, an exterior, and a boundary 
denoted by int S, ext S, and bd S, respectively. A set is regular if it is the closure of its interior 
[Requ78], i.e S = el( int S ), where cl denotes closure. (The closure of a set consists of the set together 
with its boundary.) Given a BSP tree, we can use it to represent linear regular sets, and polyhedra in 
particular. We need to simply classify each cell as either in the set or out of the set. Each leaf then 
has at least one attribute, membership, with values E { in, out }. For example, in Fig- ure BSPT, consider 
the set defined when cells 1 and 5 are assigned the value in and the rest are assigned out. Since each 
cell is open (and therefore, has an interior) and is non-empty by construction, we can take the union 
of all in-cells and then form the closure of this union, to produce a regular set. S cl( y Ci), forallCiffiin 
Note that points lying between two in-cells are included in S and are in int S. The boundary of the set 
consists of points between in-cells and out-cells, and all such points lie in sub-hyperplanes of the 
tree. bd S ~ ~ cl(C~) 0 cl(Cj), for alI Ciffi in, Cj= out Methods of constructing such representations 
will be described in sub- sequent sections. 2.3 Point Classification We can show the sufficiency of 
the above representation by solving a problem studied in computational geometry [Prep85]. The point classification 
problem can be stated: Given a set S and a point p, determine if p lies in int S, ext S, or bd S. We 
assume S is regular and we have a BSP tree representing S. Figure POINT-CLASSIFY gives an algorithm for 
solving this problem in d-space. The recursive process begins at the root of the tree and uses location 
of a point with respect to a hyperplane to control the search. To solve the problem, we must know whether 
the neighborhood of p is homogeneous, and therefore in or out, or non-homogeneous, and therefore on. 
If p lies in a cell, its neighborhood is known to be homogeneous. When p lies on some Hv, the search 
must be performed on both subtrees to deter- mine all cells in whose closure p lies. If the value of 
all such cells are not the same, p is known to be on, otherwise it is known to be in or out, depending 
upon the value. (Note that the search could terminate whenever the first on value is encountered). While 
bd S has measure zero, it is given non-zero measure numerically by specifying an interval about zero 
which is mapped to "on the hyperplane", thus giving thick- ness to the hyperplanes. Machine precision 
determines a lower bound on this interval. In [Kala82], this problem is solved for 3D in O(n) for a B-rep 
with n faces. A result in [Nayi81] shows that this could be at most O(n) for any BSP tree constructed 
from n faces (the tightest known upper-bound on tree size is O(n d) ). However, when a balanced BSP tree 
is of size O(n) (which may or may not be possible for a given set of faces), this can be solved in O 
(log n).   ~ Computer Graphics, Volume 21, Number 4, July 1987 procedure point_classify (p : point; 
v : BSPTreeNode) returns {in, out, on} if v is a leaf return the leaf's value (in or out) else let d 
m dot_product(p, Hv). if d < 0 then return point_classify (p, v.left) else if d > 0 then return point_classify 
(p, v.right) else (* p lies on the partitioning hyperplane *) I :~ point_classify (p, v.left) r := point_classify 
(p, v.right) if I ~ r then return r else return "on" end point classify ; Figure POINT-CLASSIFY. 2,4 
Augmented BSP Trees A common means of augmenting the generic BSP tree is to include other sets within 
the BSP tree structure, In particular, leaves can each include a collection of sets (objects) contained 
completely within the corresponding cell, e.g. [Schu691, and similarly, internal nodes can include sets 
lying in the corresponding sub-hyperplane, e.g. [Fuch80]. Traditionally, the motivation for this has 
been the visible surface prob- lem in 3D. Given an arbitrary viewing position, a traversal of the tree 
can induce a visibility priority ordering on the contents of the various subspaces (cells and sub-hyperplanes). 
Because of the usefulness of boundary representations for polygon tiling, polygons have been stored at 
the various nodes. We retain this visibility property by associating sets of polygons with internal nodes, 
where each set lies on the node's sub-hyperplane, and are in the boundary of the represented polyhedron. 
At each node v, these faces are separated into those whose normals have the same orientation as the normal 
of Hv and those whose orientation is opposite. 3. B-rep --' BSP tree We now examine converting a B-rep 
into an equivalent BSP tree. Essentially any of the many varieties of B-reps can be used, as long as 
they are sufficient and form a valid representation of a polyhedron. We use the term face to refer to 
the (d-i)-dimensional boundaries of a d-polyhedron, H/ to denote the hyperplane containing a face f, 
and we assume that face norma|s point to the exterior. The approach is essentially one that first appeared 
in [Fuch80] with one significant extension : assignment of values to leaves. The algo- rithm begins with 
a set of faces forming one or more disjoint polyhe- dra. At each stage, the recurslve process selects 
a hyperplane H and partitions the current set of faces F into three sets of faces, F(H+), F(H-), F(H), 
corresponding respectively to the three subspaces H +, H-, H. The partitioning of a face, f E F, is defined 
as the result of forming the following three sets, one or two of which will be empty: f+ =cl(H÷ ("1 int 
f ), f- mcl(H- ("1 int f), fo zcl(int(H 0 int f )), where int is with respect to Hf. Partitioning all 
faces of F produces F(H+), F(H-), F(H), respectively. The set F(H) is retained at a new BSP tree node 
v (separated into same and opposite lists). The process then proceeds recursiveiy on the other two sets 
until the current list of faces is empty (Figure BUILD-BSPT). Figure CONCAVE shows how the algorithm 
can create a BSP tree from a concave polygon. One note worthy consequence of this process is that each 
polyhedron is decomposed into a set of convex regions (in- a in out in out in out Figure CONCAVE. A concave 
set and its BSP tree. procedure Build_BSPT ( F : set of faces ) returns BSPTreeNode Choose a hyperplane 
H that embeds a face of F; new BSP := a new BSP tree node with H as its partitioning plane; <F_right, 
F_left, F_coincident, > : - partition faces of F with H; Append each face of F_coincident to the appropriate 
face list of new_BSP; if (F_left is empty) then if (F coincident has the same orientation as H) then 
(* faces point "outward" *) new_BSP.left : ~ "in"; else new_BSP.left :- "out"; else new_BSP.left :-- 
build_BSPT( F_left ); if (F_right is empty) then if (F coincident has the same orientation as H) then 
new BSP.right :~ "out"; else new_BSP.right : - "in"; else new_BSP.right :- build BSPT( F_right );  return 
new_BSP; end; (* Build_BSPT *) Figure BUILD-BSPT. Algorithm to build a BSP tree from a boundary representation. 
cells). Note that the only aspect of this algorithm dependent upon the particular B-rep variant is the 
splitting of a face by a hyperplane. While any order of selection wilt produce a BSP tree representing 
the same set, some orders produce more desirable trees. The issue of selecting partitioning hyperplanes 
can be somewhat complicated, and is discussed briefly in section 5.1. It is necessary, however, that 
all points on the boundary of the polyhe- dra lie in sub-hyperplanes of the resulting BSP tree (section 
2.2 above). This is accomplished most simply by always choosing a hyper- plane that embeds some face 
among the current set of faces. Eventu-ally, all points on the original fades will lie in snb-hyperplanes. 
The second requirement is the correct classification of cells. Assignment of values to leaves occurs 
when the partitioning of a set of faces finds no faces on one side of the partitioning hyperplane. That 
region is then known to be homogeneous, i.e. the region lies either entirely within the interior of one 
of the polyhedra or entirely in the exterior of all the polyhedra. We know this because for it to be 
non-homogeneous, there would be some part of a boundary to make it so, i.e. to mark the tran- sition 
between inside and outside. Therefore, the region forms a cell and can be classified as in or out. In 
this algorithm, differentiating between the two cases is simple. When hyperplanes are chosen from the 
(hyper)plane equation of some face, we use the fact that normals point to the exterior to deduce the 
fact that a left leaf must be in (in the back-halfspace of the face) and a right leaf out (in the front- 
 ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 halfspace). Also, it is not difficult to show that when 
one subtree of v is a cell, any faces coincident with H~ wilt all have the same orienta- tion. Another 
quite similar approach involves an idea that we will need later: the concept of inserting a face into 
a BSP tree. Let us say that we had used the above algorithm to build a BSP tree out of only n-1 of the 
n faces. We could "add" the last face f to the tree in the fol- lowing way. Let v be some node in the 
tree, initially equal to the root. Partition f by Hr. If it is coincident, add it to the appropriate 
face list of v. Otherwise, pass any part of f lying in H~- to v.left, and simi- larly any part in H + 
to v.right. Now repeat the process recursively on the subtrees. If and when a part of f reaches a leaf, 
create a new node. Now, if one begins with a trivial BSP tree, and inserts each face one-at-a-time, a 
BSP tree representing the polyhedra will be con-structed. Before leaving this discussion, we should point 
out that a much simpler case occurs when the input is a single convex polyhedron P of n faces. The above 
algorithm, when restricted to partitioning hyperplanes that embed a face, will always produce the same 
tree structure with n nodes independent of the order in which faces/hyperplanes are selected (Figure 
CONVEX). Each right child is a leaf with value out and the only left leaf has a value in representing 
int P. This structure is very similar to a list of the minimal set of (closed) halfspaces whose inter- 
section equals P. /\o t  /\out Figure CONVEX. A convex set and its BSP tree. 4. Evaluation of Set Operations 
Using BSP trees Since we are concerned with regular sets, we are interested only in the regularized set 
operations [Requ78], which are denoted as such by an asterisk: O *, U *, -*, and ~*. First, consider 
the unary comple- mentation operator. Given a BSP tree representing a set S, a BSP tree representing 
its complement, ~*S, can be formed by simply com- plementing the cell values: all in-cells are changed 
to out-celts and all out-cells to in-cells. Any boundary polygons at internal nodes must have their orientations 
reversed as well. A boundary representation can be similarly complemented by reversing the orientation 
of every face. To evaluate binary operators, we wilt use expression simplification in a geometric setting. 
Consider for example the expression S~ f"l * $2. If we have determined that, for some region R, that 
R C_ ext $2, then the expression in R may be simplified to Sl I"1 * 0 -0, where 0 denotes the empty set. 
If instead R ~ int $2, the expression reduces to $1 I"1 * UR -Si, where /JR is the universal set restricted 
to R. In either ease, we can perform the simplification without any knowledge of the structure in R of 
St, which could be an arbitrarily complex sub-expression on arbitrarily complex objects. Analogous cases 
exist for the other operations (Figure SIMPLIFY). This has been called "pruning" in the context of CSG 
trees. To utilize this technique we must partition the space into regions such that at least one operand 
is homogeneous in each region. That is, given the expression S i op $2 defined on some space, one must 
find a partitioning of that space such that for each region Ri of the partition- op left operand right 
operand result S in in U* S out S in S in out S S S in S N, S out out in S S out S out S in out S out 
S in S out S out Figure SIMPLIFY. Expression simplification rules. S is an arbitrary regular set. ing, 
Ri cint S) or R~ c_ ext S),j ~ 1 or 2. For an expression ofn operands, this property may need to hold 
in each Ri for up to n-I of the operands, depending on the expression. This technique appears in a number 
of places, e.g. [Wood82] [Tilo84], and seems fundamental to the problem, We use a BSP tree to partition 
space to achieve these conditions. 4.1 BSP Tree <op> B-rep ---' BSP Tree Given a BSP tree 7~ representing 
a polyhedron T, and a B-rep /~ representing a polyhedron B, we wish to evaluate Top B or Bop T, where 
op is a regularized set operation. In the case of the difference operator S~ -* $2, we choose to complement 
the right operand and evaluate the equivalent Sl A* ~* $2 3. Now, the approach is to perform the set 
operations on open sets only, since these are closed under standard (non-regularized) union and intersection. 
If the boun- dary of the result is needed, it is explicitly computed (see section 4.3 below). We will 
need to classify T and B with respect to each other. This is achieved by discovering parts of one that 
lie in the interior or exterior of the other. We refer parenthetically to Figure SET-OP, which illustrates 
T -* B. We begin by inserting collectively into T all of the faces of/~. As the faces filter down into 
T we can discover which if any of the subtrees of lie entirely in int B or ext B. When at some node v, 
no part of/Y is found to lie on one side of Hv, say, the left side, then R (v.left) must be homogeneous 
with respect to B (e.g., x.right and z.right in the figure), as explained in section 3. A general method 
for determining whether the region is in int B or ext B is given below in Section 4.5. When this occurs, 
the subtree rooted at v.left is either left untouched, or is replaced by a leaf, depending upon the simplification 
rules (in our example, both x.right and z.right are not modified). If it is also the ease that no face 
of B is coincident with Hv, then the sub-hyperplane of v has also been classified with respect to B. 
The faces of v are kept or deleted according to the same simplification rules (e.g, x's sub-hyperplane 
is in ext B and its face is kept). Deletion of v may also be possible (see section 4.4). The insertion 
process results in/~ being distributed among some subset of the subspaces of T, i.e. cells or sub-hyperplanes. 
The reaching of a leaf l by some subset of the boundary, Bt, means that Bt has been classified with respect 
to T (e.g. the faces in y.right and z.left in (3)). The operation can then be evaluated since we have 
a region in which one operand, T, is homogeneous. The result is either T's value (e.g. y.right) or B's 
value (e.g.z.left) in the region represented by the leaf, depending upon the particular operation and 
the value of the leaf, as given in Figure SIMPLIFY. If the value is T's, then the faces of/Yi it is possible 
to gain a little in efficiency by performing the ¢omplementation as part of the evaluation so that only 
the parts included in the result are actually complemented.  ~ Computer Graphics, Volume 21, Number 
4, July 1987 x -* (pq,qr,rs,sp) x /\ /\ y out y out ("1 * out /\ /\ z out z out i~ * (s's,sr,rr') x 
Y \ /\ /\ in out in I~ * (r'q,qp,ps') out A * out (1) Initial geometry. (2) Initial representations. 
(3) BSP tree after classifying (qp,rq,sr,ps). / ~z \ (4) Resulting partitioning. Figure SET-OP. BSP 
tree -* are discarded (as in y.right); otherwise ]b is "extended" by replacing the leaf with a subtree 
built from the faces of/~t (as in z.left). This can be performed by the procedure Build-BSPT, given earlier. 
Thus, the cell is "refined" to reflect B's value in the region. The tree now represents the desired set. 
We refer to this algorithm as the incremen-tal set-op evaluation algorithm because it can be used to 
create a polyhedron by a series of "incremental" modifications to an initial polyhedron. The algorithm 
is summarized in Figure INCREMEN-TAL SET-OP. 4.2 CSG on B-reps ~ BSP Tree A Constructive Solid Geometry 
representation (CSG) of a set S is a binary tree in which the internal nodes represent (regularized) 
set operations and leaves are instanced primitives (such as blocks, cones, etc.) [Requ80]. One can classify 
some arbitrary set s with respect to S by first classifying s with respect to each primitive, and then 
com-bining the classifications according to the set theoretic expression represented by the CSG tree 
[TiloS0][Roth82]. An alternative is to convert the CSG representation to a more explicit form, such as 
a B-rep or BSP tree, and classify with respect to that representation. The algorithm we now present provides 
this latter approach. We define a CSG evaluation problem 71" as a pair (7, R), where 7 is a CSG tree 
with polyhedral primitives represented as B-reps or as trivial BSP trees (representing o or U), and where 
R is a convex region of d-space on which 7" is defined. The algorithm returns a BSP tree which represents 
the same set in R as r. Starting with the problem 71" = (T, R), the algorithm chooses a hyperplane H 
to partition the prob- lem into two sub-problems, 7fleft = (Tleft, R (7 H-), and 7r,ight = (7"rigm, R 
('] H+). The root of the tree returned has H as its partitioning hyperplane, and its left and right subtrees 
are the results of the recursive evaluation of "Wleftand "n'right, respectively. The recursion is terminated 
when the current CSG tree reduces to a trivial BSP tree (a cell). The algorithm is quite similar to Build-BSPT 
of section 3, with one important difference: rather than having just a simple list of faces to partition, 
we have a CSG tree with faces at its leaves. Figure CSG- EVALUTATION describes the algorithm. As before, 
a hyperplane H is chosen at each stage that embeds a face using a heuristic (Section 5.1). Two copies 
of the CSG tree are generated and modified to represent the set in each of the two halfspaces of H. This 
entails for x / \ /Y\ OUt X OUt / \ u out ./ \ in v / \ in w in out (5) Final BSPtree. B-rep ~ BSP 
tree. if op = -* then B :-- Negate B-rep( B ) op:= ~* procedure Ineremental_Set_op ( op : set_operation 
; v : BSPTreeNode ; B : set of Face ) returns BSPTreeNode if v is a leaf then case op of U * : case 
v.value of in : return v out : return Build_BSPT( B ) N * : case v.value of in : return Build BSPT( 
B ) out : return v else <B_left, B_right, B_coincident> :--partition B with H v if B left has no faces 
then status := Test_in/out(H,, B coincident, B_right) ease op of U * : case status of in : discard BSPT( 
v.left ) v.left :- new "in" leaf out : do nothing A * : case status of in : do nothing out : discard_BSPT( 
v.left ) v.left :m new "out" leaf else v.left := |neremental_Set._op( op, v.left, B_left ) if B_right 
has no faces then (* similar to above *) else v.right : z lncremental_Set..op(np, v.right, B__right) 
return v end lncremental_Set_op ; Figure INCREMENTAL SET-OP. Psuedo code for the incremental set evaluation 
algorithm. each primitive replacing the faces of that primitive in the respective CSG trees with the 
subset of the faces that lies in each halfspace.  ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 I~U~l Faces 
coincident with H are retained at the new node. Detection of homogeneous regions allows CSG tree simplification 
using the rules in Figure SIMPLIFY. If the CSG tree is reduced to, in effect, a single value (in/out), 
the problem in that region has been solved and is represented by a cell of the BSP tree. The entire problem, 
then, is solved through the discovery/creation of regions which are homogene-ous with respect to the 
defined set, where each region is represented by a different cell of the resulting BSP tree. procedure 
Evaluate_CSG ( r : CSGTree ) returns BSPTree choose a face f of a primitive of r v := new BSPTreeNode; 
Hv := Hf Tleft * ~.right > l_.m. Split_CSG ( r, Hv ) fief, :J Simplify_CSG ( rleft ) if rteft represents 
O then v.left : = new "out" leaf else if rteft represents U then v.left := new "in" leaf else v.left 
:= Evaluate_CSG ( rte/t ) (* similar code for z~igh z *) return v end; (* Evaluate_CSG *) procedure 
Split_CSG ( r : CSGTree; H : plane_equation ) returns < CSGTree, CSGTree > if r is not a primitive then 
rteft := copy ( r.root ) r,ight := copy ( r.root ) <rtefl.left , r~ight.left> := Split_CSG ( r.left, 
H ) <rteft.right , fright.right> : = Split_CSG ( r.right, H ) else <rlefi, fright , rcoincide m > : = 
partition r with H if rleft = 0 then T~ft = Test in/out ( H, rcoinciaent, Tright ) elseif 7right ~ 0 
then Trlght ~ Test_in/out ( H, Tcoincident , Tleft ) Add Tcoincident to V'S face lists return <fief t, 
"[right :> end; (* Split_CSG *) Figure CSG-EVALUATION. Algorithm for converting from a CSG tree to a 
BSP tree. 4.3 Boundaries The two algorithms described above produce, in effect, a generic BSP tree which 
is sufficient for point classification and ray-tracing. While certain faces were retained at internal 
nodes, these no longer correspond necessarily to the boundary of the set S represented by the tree S. 
Since B-reps are useful for rendering via polygon tiling, and the BSP tree can induce a priority ordering 
on the faces, we may wish to generate the boundary faces of S. This requires that for each node v of,~, 
we find and store at v, bd S N SHp(v) (where SHp(v) is the sub-hyperplane of v). There are two alternatives. 
One is to dis- card the old faces entirely and generate the boundary faces directly from the generic 
BSP tree using a technique described in [Thib87]. The second, which- we will describe here, constructs 
the new faces from the faces of the operands. The boundary of the result of any set operation is known 
to be a subset of the boundaries of the operands. Now, since bd S is known to lie entirely within the 
sub-hyperplanes of S, only the parts of the original faces which lie in these sub-hyperplanes can possibly 
be in bd S. These two facts imply that the faces retained at S's nodes form a superset of bd S, i.e. 
their union contains bd S, and the discarded faces do not contain any subset of bd S. It also immediately 
follows that for a given node v, any part of bd S lying in the SHp (v) must be a contained in the region 
covered by the faces retained at v. How- ever, parts of these faces may lie in either int S or ext S. 
To find the on parts of these faces, we can insert them into the subtrees of v, analogous to the technique 
used in point classification for points lying in sub-hyperplanes. This produces a set of new faces, a 
subset of which form bd S I") SHp(v), and this subset is retained at v (as opposed to extending the 
tree as in sections 3 and 4.1). 4.3.1 Classifying Faces. Consider for the moment the case where v.right 
is a cell with value out, as at node y in Figure SET-OP. Then the boundary contained in the SHp(v) is 
precisely the points lying between this out-cell and those in-cells in v.left whose closure intersects 
Hr. Moreover, the orientation of the boundary faces must be that of Hv, since they are to point to the 
exterior, which by construction lies in v.right. Therefore, faces in the opposite-face list cannot be 
in bd S. Now, if we classify the same-faces by inserting them into v.left, the resldting faces which 
are classified as in with respect to v.left, i.e those which reach in-cells, must lie in bd S. Those 
in out-cells would be between two out-cells and thus known to lie in ext S. These can be discarded. As 
an example, in Figure SET-O, a face of the original tree at node y, when inserted into y.left would be 
split into three pieces, two of which are in and the third (middle piece) is out. Now, to extend this 
for an arbitrary v.right, we first take the in-faces from the v.left insertion/classification above and 
insert/classify then with respect to v.right. The faces resulting from this insertion that are classified 
as out are then known to lie between an in-cell and an out- cell, and therefore in bd S. Now, the same 
process applied to the opposite-faces, but with the insertion sequence reversed (v.right then v.left), 
produces faces in bd S whose orientation is opposite of H~. In the case of the incremental algorithm, 
we can exploit the fact that a single set operation is being evaluated, and use its semantics to avoid 
inserting faces into both subtrees. Consider union. We know that the neighborhood [n the back-halfspace 
of a face of either operand is in the interior of the result. Therefore, we know a priori that same-faces 
inserted into v.left will all land in in-cells, and similarly for opposite- faces inserted into v.right. 
Thus, each face needs only to be classified with respect to one subtree: same-faces with respect to v.right, 
and opposite-faces with respect to v.left. The resulting faces that land in out-cells lie on the boundary, 
since the other side is known to be in- cells. For intersection, a similar analysis indicates that same-faces 
should be inserted into v.left, opposite-faces into v.right, and that resulting faces lying in in-cells 
should be kept. While the above technique guarantees that the union of the remaining faces is exactly 
bd S, it does not guarantee that the set of faces at each node are disjoint. If the faces are given the 
same attributes, such as color, this redundancy will not affect renderings of the object, other than 
to possibly increase time and space requirements. However, this redundancy can be eliminated by merging 
the faces, i.e. by forming for each node independently the union of the same-faces and separately the 
union of the opposite-faces. 4.3.2 Face Merging. Merging of faces can be performed by the CSG evaluation 
algorithm in the dimension of the faces, optimizing for the fact that there is only one type of operator: 
union. Conceptually, we have a CSG tree representing ft I,.,I f2 U " " " U f,, for n faces. The result 
is a BSP tree, in (d-1)-space, where the (d-l) value of "in" corresponds to the d-value of "on", and 
similarly "out" corresponds to "not-on". Faces lying in a hyperplane H are orthogonally projected into 
a coordinate hypcrplane by dropping the coordinate corresponding 15g ~ Computer Graphics, Volume 21, 
Number 4, July 1987 to the largest coordinate of H's normal. The tree building process proceeds as before, 
but in the lower dimension. The recursion ter-minates when regions are discovered that are either completely 
covered by some face or contain no faces. Let us consider the case where d = 3. If convex polygons are 
the desired output, it is relatively straightforward to maintain a vertex-list representation of the 
regions of the 2D tree. All in-regions yield polygons whose vertices are projected back into H. Now, 
for concave polygons, we must find the (d-2) boundary of the in-regions. This means that finding the 
2D boundary of a 3D set requires recursing in dimension and finding the 1D boundary of 2D set and subsequently 
the 0D boundaries of 1D sets. Thus, to perform the complete boundary evaluation requires that we apply 
our algorithm recursively in dimen- sion. The recursion forms 1D BSP trees for each internal node of 
a 2D BSP tree. The in-cells of these trees lie on polygon edges. In this I D-space, hypcrplanes are forced 
to the form [ 1 -x ]. Vertices lie on these hyperplanes and have value x, and the left subtree of a node 
contains values < x while the right subtree values are >x, i.e. they are binary search trees. To find 
the minimum boundary of these 1D in-regions, i.e. the pairs of vertices bounding each edge, we can traverse 
each 1D tree using the procedure in Figure GENERATE-EDGES. The vertices are projected back from tD to 
2D which are then projected back into H defined in 3D. This then produces a merged set of edges bounding 
the on-regions (with respect to the 3D polyhedron) lying in a given sub-hyperplane 4. Global variables 
vl,v2 : scalar, last value : { in,out } :.- out edge_list : LIST OF ( vl,v2 ) GenerateEdges( root, [ 
1 --ool ) procedure Generate_Edges( v : BSPTreeNode, rain : 1D-Hyperplane ) if v = leaf then case ( last_value, 
v.value ) ( out,in ) -> vl :ffi min.x ( in,out ) -> v2 :ffi min.x edge_list + ffi NewEdge( vl, v2 ) last 
value :- v.value else Generate_Edges( v.left, min ) Generate_Edges( v.right, Hv ) end Generate_Edges 
Figure GENERATE-EDGES Another alternative for boundary generation from the CSG evalnator, described 
in [Thib87], uses a technique where each same-face is inserted into v.left and a copy, but with orientation 
reversed, is inserted into v.right. The complementary operation is performed for the opposite-faces. 
The resulting in-cell faces are retained and merged together as above, but with the following "glue" 
operator in place of union: (same, same) -> same (same, opposite) -> not-on (opposite, same)-> not-on 
(opposite, opposite) -> opposite The I D boundaries of same and opposite regions are constructed independently. 
This kind of operation has appeared elsewhere, e.g. 4. Represeming a set of arbitrary non-overlapping 
polygons by a set of edges is sufficient for many polygon processing algorithms. [Putn86], to "regularize" 
the set, 4.4 BSP Tree Reduction Once a BSP tree has been constructed as the result of the evaluation 
of set operations, it may be possible to reduce the tree by eliminating cer- tain nodes without changing 
the represented set. We identify two cases in which this reduction is possible. The first case occurs 
when both subtrees of a node v are cells with identical values (Node z in Figure REDUCE), Since R (v) 
is homogeneous, the subtree rooted at v can be replaced by a cell with the same vatue. Note that no boun- 
dary faces could lie in the sub-hyperplane of such a node, This case arises naturally from expression 
simplification during which a formerly non-homogeneous region is simplified to a homogeneous one, and 
is analogous to the "condensation" of quad/oct-trees. It can be performed as part of the tree construction. 
We may also remove a node that has as one child a cell and, in addi- tion, has no part of the boundary 
in its sub-hyperplane (node u in Fig- ure REDUCE). This means that all cells in the other subtree bounded 
by this node's hyperplane have the same value as the cell. Since the sub-hyperplane does not contribute 
to the differentiation of space, the tree rooted at this node can be replaced by the node's non-trivial 
sub- tree (Node w). This reduction can be performed during the phase that generates the boundary faces. 
(With the incremental algorithm, this can be detected and effected during set-op evaluation.) u w out 
/\ U x out /\ out \ \ Z out ./\ In In Figure REDUCE. Nodes u and z can be eliminated.  4.5 The In/Out 
Test In all three of our algorithms that produce BSP tree representations of polyhedra, we discover regions 
that do not contain any faces of a polyhedron B represented by a B-rep B. In these cases, we must determine 
whether that region lies in int B or ext B. In procedure Build_BSP, we saw that we could use the normal 
of a face, coincident with H, to answer this question. However, in the set operation algo- rithms, no 
such face may exist. We must then decide the status of this region based upon the subset of bd B lying 
on the non-homogeneous side of H. We solve this for dimensions 1, 2 and 3. Let By =/~ f') R(v). (Note 
that since R(v) is open, 0 bd R(v) is not included in By). We assume, without loss of generality, that 
B~ lies entirely in H~ +, and therefore in R(v.right). We are then interested in determining the status 
of R (v.left) with respect to B. In the case where B O R (v) is convex, this is rela- tively simple. 
We can test some point lying in SHp (v) for inclusion in the back half-spaces of all faces of/~. If the 
point is "behind" all of these faces, then R (v.left) C int B, otherwise R(v.left) c ext B. Such a point 
can be easily produced if each sub-hyperplane embeds some face: we use the centroid of three non-collinear 
vertices of this face. We now address the problem for (sets of) arbitrary polyhedra. One alternative 
is the ray casting test [Laid86]. This method would inter- sect a ray emanating from a point.on the sub-hyperplane 
with /~ to find the closest face, from whose orientation the classification can be obtained. If the closest 
intersection point lies on more than one face, the process is repeated with a randomly perturbed ray. 
We have, ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 however, discovered a simpler method which uses the 
closest vertex b of/Y~, to H. This b can be found trivially during the partitioning of /Y~ by Hr. In 
the following, letp be a point in SHp(v). In ID, the problem is solved exactly as in Build-BSPT, i.e 
from the orientation of the single face (a point). For 2D, the problem is illus- trated in Figure 2D-IN/OUT. 
Vertex b is either in bd R(v) or in int R(v). If b lies in bdR(v), then there is a single edge e in Bv 
incident with b. (A second edge could only lie in bdR(v) or ext R(v)). Ifp lies in He +, then R(v.left) 
lies in ext B. Otherwise, R(v.left) is in int B. Now, if b is in int R(v), b is incident with two edges, 
el and e2. The region R(v.left) is in ext B if el and e2 lie in each other's back halfspace, i.e., if 
el c H~-and e2 C HeT. This means that b is a point of "local convexity" of B. Otherwise R (v.left) is 
in int B (and b is a point of "local concavity"). tt" .......... . .... i t t / / t P " ", L~ 2 )' ~ 
L %"i 3/ ', ."Riv, t_ ........ ." "R(v) (a) closest vertex in bdR (v). (b) closest vertex in 'int'R 
(v). Figure 2D-IN/OUT. In 3D, the situation is somewhat similar: either b lies in bd R(v) and is not 
shared by any other face of/~, or b is shared by more than one face of/~ (and may lie in either bd R 
(v) or int R (v)). The test for the first case is the same as above: p is tested against the hyperplane 
of the single face containing b. When b is shared by more than one face of/~v, we select the edge which 
forms the smallest angle with the plane H~ (think of b lying on H~), In the neighborhood of b, this is 
the closest edge of/~ to H~ (Figure 3D-IN/OUT). If fl and f2 are the faces that share this edge, then 
R (v.left) is in ext B if, in a local region of b, fl and f2 lie in each other's back halfspace; otherwise, 
R (v.left) lies in int B. To determine this we first find a vertex of fl adjacent (connected by an edge) 
to b but not lying in fz- The loca- tion with respect to the plane of f2 of this vertex provides the 
same answer as in the 2D case above. If the faces are convex, any vertex of f l not lying in f2 will 
do. If there is a tie for the closest vertex, we can choose the one that allows the simplest test. ~ 
---~.~-~- 1= -2 --- ~-~ - - -~ ~ -I ' I I I I t I I I I I I I I q I I I I I I I - ''I I I I I I ~ --+-) 
I ~- fl .,t- .... I I''I I I I I I .[ _ -/L L : .) __.~____'_J/__-. ~.-- ........ _W___:" (a) vertex 
b on only one face. (b) vertex b on more than one face. Figure 3D-IN/OUT. 5. Experience 5.1 Selection 
of Partitioning Hyperplanes While a thorough discussion of methods by which to select partitioning hyperplanes 
is beyond the scope of this paper, we will at least describe the primary ones we have been using. The 
two principal properties of BSP trees that we are wanting to optimize are size and balance. Because finding 
the optimal is considered to be computationally hard, heuristics are employed. Most of our work has been 
with heuristics that select a hyperplane from among those that embed faces. For a set of faces, we define 
the candidate set to be those faces that are to be considered for generating partitioning hyperplanes. 
The test set con-sists of the faces against which each candidate hyperplane is tested, with possible 
outcomes being "in front oP', "in back of", and "inter-sected by". The heuristic is a function of the 
number of outcomes of each type that occurred when a candidate was tested against the test set. The candidate 
chosen is that member of the candidate set that maximizes the heuristic. We investigated three heuristic 
functions: Heurl (front,back,split) ~ (-]back-front[) -w~git * split Heur2 (front,back,split) -(front 
* back) -wspm * split Heur 3 (front,back,split) ~ front -w~ptit * split The weight wsptit allows "tuning" 
of the heuristics. The reason for applying a negative weight to intersected candidates is that splitting 
of faces tends to increase tree size and total computation time. The first two heuristics try to balance 
the number of faces on each side of the candidate. The third is motivated by CSG trees with convex primitives 
and attempts to maximize the number of faces in the exterior of some primitive. This can facilitate CSG 
tree simplification, since in one of the two subspaces, the value of the primitive will be out. 5.2 Implementation 
of the CSG evaluation algorithm The CSG evaluation algorithm has been implemented in a dialect of Pascal 
running under Unix BSD 4.3. The CSG tree is described in a simple language of our design, translated 
using lex and yacc. Statis-tics obtained for various test objects are given in Figure STATS. Objects 
"stand" and "holed head" are depicted in Figure RAY-TRACING. In Figure CLUTCHPLATE, the edges (highlighted) 
reveal the spatial partitioning of that object. Tests were run on a VAX 8650. For each heuristic, wwm 
--8, the candidate set consisted of 5 polygons chosen at random from each primitive in the current sub-problem, 
and the test set consisted of all polygons in the sub-problem. Early experience with various candidate 
set sizes shows that heuristics Heurl and Heur3 are comparable. Heur2 produces trees with a larger number 
of nodes, but with less CPU time than is required by the other heuristics for the same objects. 5.3 
Implementation of the Incremental Algorithm We have implemented the algorithm for incremental set operations 
in C on a Silicon Graphics IRIS workstation. The user modifies a "work piece", represented by a BSP tree, 
with a "tool", represented by a B-rep. The user can interactively control the view and the tool's position. 
Moving the tool results in a temporary union of the current work piece with the tool at its current position. 
Visibility is accomplished by transmitting the polygons in back to front order, using the visibility 
priority ordering produced from the BSP tree. The union we use for this is a "lazy" union because we 
do not re-evaluate boundary polygons in nodes of the resulting tree. We can do this because the visible 
sur- face of two objects that interpenetrate is the same as the visible sur- face of their union. Re-evaluation 
would only serve to eliminate invisi- ble faces in the interior or overlapping faces on the boundary. 
Our impression is that the time required to draw the extra polygons is less than that needed to update 
the boundaries. In addition, subtrees lying inside the tool are saved and former cells that were refined 
by the tool's faces are noted. Thus to restore the original tree for use in the next frame requires reinstating 
the "removed" subtrees and cells, and removing any of the tool's faces lying in internal nodes of the 
tree. Finally, once the tool is positioned, the user chooses a set operation and the BSP tree is modified 
to reflect the result. The initial work piece is obtained by either converting some B-rep to a BSP tree 
or using the result of the CSG evaluator. We have restricted the tools to be convex polyhedra so that 
we can take advantage of the (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 number of number 
of heuristic cpu tree size tree height number of object primitives polygons used (seconds) (nodes) 1 
8.3 368 43 clutchplate 8 158 2 7.2 408 27 3 8.3 369 47 1 41.9 713 31 stand 31 623 2 41.1 814 31 3 152.9 
896 93 1 30.6 1536 104 holed head 3 955 2 24,5 1811 61 3 32.8 1532 90 Figure STATS. Statistics for some 
test cases. polygons 353 362 353 1781 1825 1850 1982 2167 2067 simpler algorithms for tree building 
and in/out testing. We have not found this to be an unnatural limitation for the user. Also, the IRIS 
workstation requires polygons to be convex. In forming the' boundary during set operations, we take advantage 
of the convex decomposition generated by the BSP tree to provide us with convex polygons. 6. Concluding 
Comments 6.1 Comparison to Alternative Approaches Space limitations prevent any but a limited discussion 
of the relation- ship of our work to others. The octree [Meag82] is similar in ways to the BSP tree. 
Both are tree structures that recursively subdivides space and assigns values to leaves, and both are 
dimension-independent. The most obvious difference is that octrees require the partitioning to be axis-aligned 
and the subdivision to be uniform. Of course, any partitioning of space by an octree can be modeled by 
a BSP tree 5. The simplicity of octrees is attractive, and this can lead to certain advantages. But, 
for representation of polyhedra, the octree in general provides only an approximation, and it is typically 
a very ver- bose one. However, work described in [Carl85] [Aya185] attempts to addresses these problems. 
While the verbosity is reduced, it still remains a problem. Set operations (in [Aya185] and described 
for 2D only) require identifying and handling a number of cases, an aspect that tends to complicate implementations 
and makes extension to higher dimensions difficult. More importantly, axis-aligned partition- ing schemes 
do not transform. To transform an octree it must be rebuilt. BSP trees do transform: simply apply the 
transformation to each hyperplane (the inverse of what would be applied to points). Also, we expect the 
generality of orientation to lead to smaller representations. In B-rep algorithms, e.g. [Mant83] [Requ85] 
[Laid861 [Putn861, the geometric search structure, the set operations, and the visible surface determination 
are independent. In the BSP tree, they are all unified in a single structure (also true of octrees). 
While boundary representa- tions transform, the search structures are typically axis-aligned. With one 
exception [Putn86], the algorithms for set operations are not dimension-independent and are somewhat 
complex with, once again, considerable case analysis. The principal "case analysis" per se for the BSP 
tree is the partitioning of a face by a hyperplane. On the other hand, B-reps are typically more concise 
(although not always). 6.2 Future Work Other operations that we have examined include the calculation 
of metric properties such as volume, surface area, center of mass, etc. (see [Thib87]). We have also 
made a potentially important step by 5. To make the cost of determining the location of a point in a 
BSP tree more comparable to an octree, we use plane-equation-type -- ( x-axis, y-axis, z-axis, arbitrary 
) and optimize when not "arbitrary". devising a closed set theoretic (boolean) algebra on BSP trees, 
thus dispensing with B-reps per se. In addition, the original ray-tracing techniques have been extended 
considerably, now exploiting non-linear hyperplanes, Utilization of non-linear hyperplanes is also possible 
with the fundamental techniques presented in this paper. However, the sim- plicity of linear computations 
would be lost in doing so. Nonetheless, we intend to explore this option. Heuristics are another area 
requiring greater study. All partitioning hyperplanes do not need to embed faces. One technique we have 
begun investigating is the use of a "median cut" algorithm similar to that used to build k-d trees [Bent79]. 
This can result in more well-balanced trees, especially for convex regions bounded by many faces. 6.3 
Conclusions A new representation for something as fundamental as polyhedra intro- duces a new "algorithm 
space" to explore. Divide-and-conquer algo- rithms are often simple and efficient and we believe this 
is reflected in the BSP tree algorithms. Also, the dimension independent aspect allowed a solution to 
the boundary problem without introducing a different methodology. The unified framework provided for 
geometric searching, set operations, and visible surface rendering reduces the con- ceptual complexity 
as well as the complexity of implementations. The representation can be viewed as something of a cross 
between octrees and boundary representations, it has the unifying quality of octrees, but is not as simple. 
It has the exactness, transformability and conciseness of boundary representations, although not generally 
as concise. In fact, one might view the greater verbosity as the cost of the unity, something which must 
be weighed against the other gains. References [Aya185] D. Ayala, P. Brunet, R. Juan, and 1, Navazo, 
"Object Representation by Means of Nonminimal Division Quad trees and Octrees," ACM Transactions on Graphics 
Vol. 4(1) pp. 41-59 (January 1985). [Bent79] Jon Louis Bentley and Jerome H. Friedman, "Data Struc-tures 
for Range Searching," Computing Surveys Vol. 11(4), pp. 397-409 (December 1979). [Carl85] Ingrid Carlbom, 
Indranil Chakravarty, and David Vander-schel, "A Hierarchical Data Structure for Representing the Spatial 
Decomposition of 3-D Objects," 1EEE Computer Graphics and Applications, pp. 24-31 (April 1985). [FuchS0] 
H. Fuchs, Z. Kedem, and B. Naylor, "On Visible Surface Generation by a Priori Tree Structures," Computer 
Graphics 1Iol. 14(3), (June 1980). [Fuch83] Henry Fuchs, Gregory D. Abram, and Eric D. Grant, "Near Real-Time 
Shaded Display of Rigid Objects," Computer Graph- ics VoL 17(3) pp. 65-72 (July 1983). [Kala82] Yehuda 
E. Kalay, "Determining.the Spatial Containment of    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37422</article_id>
		<sort_key>163</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[Marching cubes: A high resolution 3D surface construction algorithm]]></title>
		<page_from>163</page_from>
		<page_to>169</page_to>
		<doi_number>10.1145/37401.37422</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37422</url>
		<abstract>
			<par><![CDATA[We present a new algorithm, called <i>marching cubes</i>, that creates triangle models of constant density surfaces from 3D medical data. Using a divide-and-conquer approach to generate inter-slice connectivity, we create a case table that defines triangle topology. The algorithm processes the 3D medical data in scan-line order and calculates triangle vertices using linear interpolation. We find the gradient of the original data, normalize it, and use it as a basis for shading the models. The detail in images produced from the generated surface models is the result of maintaining the inter-slice connectivity, surface data, and gradient information present in the original 3D data. Results from computed tomography (CT), magnetic resonance (MR), and single-photon emission computed tomography (SPECT) illustrate the quality and functionality of <i>marching cubes</i>. We also discuss improvements that decrease processing time and add solid modeling capabilities.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.3</cat_node>
				<descriptor>Health</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.4.9</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245.10010254</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems->Reconstruction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010446</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Consumer health</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010449</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Health informatics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Human Factors</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P299459</person_id>
				<author_profile_id><![CDATA[81100054474]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Lorensen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[General Electric Company, Schenectady, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P108190</person_id>
				<author_profile_id><![CDATA[81100021650]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Harvey]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Cline]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[General Electric Company, Schenectady, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Artzy, E., Frieder, G., and Herman, G.T. The Theory, Design, Implementation and Evaluation of a Three-Dimensional Surface Detection Algorithm. Comptlter Graphics and Ima~,,e Processinj,, 15, 1 (January 1981), 1-24.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barillot, C., Gibaud, B., Scarabin, J., and Coatrieux, J. 3D Reconstruction of Cerebral Blood Vessels. IEEE Comlmwr Graphk's attd Applk'ations 5, 12 (December 1985), 13-19.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bates, R. H., Garden, K. L., and Peters, T. M. Overview of Computerized Tomography with Emphasis on Future Developments. Proc. of the IEEE 71, 3 (March 1983), 356-372.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bloch, P. and Udupa, J. K. Application of Computerized Tomography to Radiation Therapy and Surgical Planning. Proc. oi' the IEEE 71, 3 (March 1983), 351-355.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Brewster, L. J., Trivedi, S. S., Tut, H. K., and Udupa, J. K. Interactive Surgical Planning. IEEE Computer Graphics and Applications 4, 3 (March 1984), 31-40.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Burk, D. L., Mears, D. C., Kennedy, W. H., Cooperstein, L. A., and Herbert, D. L. Three-Dimensional Computed Tomography of Acetabula Fractures. Radiology 155, 1 (1985), 183-186.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Chen, L., Herman, G. T., Reynolds, R. A., and Udupa, J. K. Surface Shading in the Cuberille Environment. IEEE Computer Graphics and Applications 5, 12 (December 1985), 33-43.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807388</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Christiansen, H. N. and Sederberg, T. W. Conversion of Complex Contour Line Definitions into Polygonal Element Meshes. Computer Graphics 12, 3 (August 1978), 187-192.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Cline, H. E., Dumoulin, C. L., Lorensen, W. E., Hart, H. R., and Ludke, S. 3D Reconstruction of the Brain from Magnetic Resonance Images. Magnetic Resonance Imaging (1987, to appear).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Cline, H. E., Lorensen, W. E., Ludke, S,, Crawford, C. R., and Teeter, B. C. High-Resolution Three- Dimensional Reconstruction of Tomograms. Medical Physics (1987, to appear).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Cook, L. T., Dwyer, S. J., Batnitzky, S., and Lee, K. R. A Three-Dimensional Display System for Diagnostic Imaging Applications. IEEE Computer Graphics and Applications 3, 5 (August 1983), 13-19.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Farrell, E. J. Color Display and Interactive Interpretation of Three-Dimensional Data. IBM J. Res. Develop 27, 4 (July 1983), 356-366.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Farrell, E. J., Zappulla, R., and Yang, W. C. Color 3D Imaging of Normal and Pathologic Intracranial Structures. IEEE Computer Graphics and Applications 4, 9 (September 1984), 5-17.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359846</ref_obj_id>
				<ref_obj_pid>359842</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H., Kedem, Z. M., and Uselton, S. P. Optimal Surface Reconstruction from Planar Contours. Comm. o{'the ACM 20, 10 (October 1977), 693-702.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Gordon, D. and Reynolds, R. A. Image Space Shading of 3-Dimensional Objects. Computer Graphics and Image Processing 29, 3 (March 1985), 361-376.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Hale, J. D., Valk, P. E., and Watts, J. C. MR Imaging of Blood Vessels Using Three-Dimensional Reconstruction: Methodology. Radiolo,xv 157, 3 (December 1985), 727-733.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Hemmy, D. C., David, D. J., and Herman, G. T. Three-Dimensional Reconstruction of Craniofacial Deformity Using Computed Tomography. Neurosurgery 13, 5 (November 1983), 534-541.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Hemmy, D. C. and Tessier, P. L. CT of Dry Skulls with Craniofacial Deformities: Accuracy of Three- Dimensional Reconstruction. Radiology 157, 1 (October 1985), 113-116.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Herman, G. T. and Udupa, J. K. Display of 3D Digital Images: Computational Foundations and Medical Applications. IEEE Computer Graphics and Applications 3, 5 (August 1983), 39-46.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Hinshaw, W. S. and Lent, A. H. An Introduction to NMR Imaging: From the Bloch Equation to the Imaging Equation. Proc. of the IEEE 71, 3 (March 1983), 338-350.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Hoffman, E. A. and Ritman, E. L. Shape and Dimensions of Cardiac Chambers: Importance of CT Section Thickness and Orientation. Radiology 155, 3 (June 1985), 73%744.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Hohne, K. H. and Bernstein, R. Shading 3D-Images from CT Using Gray-Level Gradients. IEEE Trans. on Medical Imaging MI-5, 1 (March 1986), 45-47.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Keppel, E. Approximating Complex Surfaces by Triangulation of Contour Lines. IBM J. Res. Develop 19, 1 (January 1975), 2-11.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Knoll, G. F. Single-Photon Emission Computed Tomography. Proc. of the IEEE 71, 3 (March 1983), 320-329.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Meagher, D. J. Geometric Modeling Using Octree Encoding. Computer Graphics and Image Processing 19, 2 (June 1982), 129-147.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Robb, R. A., Hoffman, E. A., Sinak, L. J., Harris, L. D., and Ritman, E. L. High-Speed Three-Dimensional X-Ray Computed Tomography: The Dynamic Spatial Reconstructor. Proc. of the IEEE 71, 3 (March 1983), 308-319.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807390</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Sunguroff, A. and Greenberg, D. Computer Generated Images for Medical Application. Computer Graphics 12, 3 (August 1978), 196-202.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360802</ref_obj_id>
				<ref_obj_pid>360767</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. E. and Hodgman, G. W. Reentrant Polygon Clipping. Comm. of the ACM 17, 1 (January 1974), 32-42.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Trivedi, S, S., Herman, G. T., and Udupa, J. K. Segmentation Into Three Classes Using Gradients. 1EEE Trans. on Medical Imaging MI-5, 2 (June 1986), 116-119.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Udupa, J. K. Interactive Segmentation and Boundary Surface Formation for 3-D Digital Images. Computer Graphics and Image Processing 18, 3 (March 1982), 213-235.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Vannier, M. W., Marsh, J. L., and Warren, J. O. Three Dimensional CT Reconstruction Images for Craniofacial Surgical Planning and Evaluation. Radiology 150, 1 (January 1984), 179-184.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Zucker, S. W. and Hummel, R. A. A Three- Dimensional Edge Operator. IEEE Trans. on Pattern Analysis and Machine Intelligence PAMI-3, 3 (May 1981), 324-331.]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 MARCHING CUBES: A HIGH RESOLUTION 3D SURFACE 
CONSTRUCTION ALGORITHM William E. Lorensen Harvey E. Cline General Electric Company Corporate Research 
and Development Schenectady, New York 12301 Abstract We present a new algorithm, called marching cubes, 
that creates triangle models of constant density surfaces from 3D medical data. Using a divide-and-conquer 
approach to gen- erate inter-slice connectivity, we create a case table that defines triangle topology. 
The algorithm processes the 3D medical data in scan-line order and calculates triangle vertices using 
linear interpolation. We find the gradient of the origi- nal data, normalize it, and use it as a basis 
for shading the models. The detail in images produced from the generated surface models is the result 
of maintaining the inter-slice connectivity, surface data, and gradient information present in the original 
3D data. Results from computed tomography (CT), magnetic resonance (MR), and single-photon emission computed 
tomography (SPECT) illustrate the quality and functionality of marching cubes. We also discuss improve- 
ments that decrease processing time and add solid modeling capabilities. CR Categories: 3.3, 3.5 Additional 
Keywords: computer graphics, medical imaging, surface reconstruction 1. INTRODUCTION. Three-dimensional 
surfaces of the anatomy offer a valu- able medical tool. Images of these surfaces, constructed from multiple 
2D slices of computed tomography (CT), mag- netic resonance (MR), and single-photon emission computed 
tomography (SPECT), help physicians to understand the complex anatomy present in the slices. Interpretation 
of 2D medical images requires special training, and although radiol- ogists have these skills, they must 
often communicate their interpretations to the referring physicians, who sometimes have difficulty visualizing 
the 3D anatomy. Researchers have reported the application of 3D medical images in a variety of areas. 
The visualization of complex Permission to copy without fee all or part of this material is granted provided 
that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice 
and the title of the publication and its date appear, and notice is given that copying ks by permission 
of the Association for Computing Machinery. To copy acetabular fractures [6], craniofacial abnormalities 
[17,18], and intracranial structure [13] illustrate 3D's potential for the study of complex bone structures. 
Applications in radiation therapy [27,11] and surgical planning [4,5,31] show interac- tive 3D techniques 
combined with 3D surface images. Cardi-ac applications include artery visualization [2,16] and non-graphic 
modeling applications to calculate surface area and volume [21]. Existing 3D algorithms lack detail and 
sometimes intro- duce artifacts. We present a new, high-resolution 3D surface construction algorithm 
that produces .models with unpre-cedented detail. This new algorithm, called marching cubes, creates 
a polygonal representation of constant density sur-faces from a 3D array of data. The resulting model 
can be displayed with conventional graphics-rendering algorithms implemented in software or hardware. 
After describing the information flow for 3D medical ap- plications, we describe related work and discuss 
the draw-backs of that work. Then we describe the algorithm as well as efficiency and functional enhancements, 
followed by case studies using three different medical imaging techniques to il- lustrate the new algorithm's 
capabilities. 2. INFORMATION FLOW FOR 3D MEDICAL ALGORITHMS, Medical applications of 3D consist of four 
steps (Fig-ure 1). Although one can combine the last three steps into one algorithm, we logically decompose 
the process as follows: 1. Data acquisition. This first step, performed by the medical imaging hardware, 
samples some property in a patient and pro- duces multiple 2D slices of information. The,data sam-pled 
depends on the data acquisition technique.  MDataAcquisition C ' CTSPECT.~.~/ / R Image I J ode, Vie.,og 
t--.(Oi.p,ay I Processing I "] Creation I IOperati°?s/L------J otherwise, or to republish, requires 
a fee and/or specific permission. ConnectivityMask Surface Value Booleans ViewingClippingAnimation ¢~ 
1987 ACM-0-89791-227-6/87/007/0163 $00.75 Figure 1. 3D Medical Information Flow.  ~ SIGGRAPH '87, Anaheim, 
July 27-31, 1987 X-ray computed tomography (CT) measures the spatially varying X-ray attenuation coefficient 
[3], CT images show internal structure. For 3D applications, CT is fre- quently used to look at bone 
structure, although we have had success visualizing soft tissue. Magnetic resonance (MR) measures three 
physical prop- erties [20]. One property is the distribution of "mobile" hydrogen nuclei and shows overall 
structure within the slices. The other two properties measure relaxation times of the nuclei. MR, a recent 
technique, shows ex-cellent contrast between a variety of soft tissues. How-ever, the variety of surfaces 
presents a challenge to 3D surface construction and requires techniques for selec-tive surface extraction 
and display. A third acquisition technique, single-photon emission computed tomography (SPECT) measures 
the emission of gamma rays [24]. The source of these rays is a ra-dioisotope distributed within the body. 
[n addition to structure, SPECT can show the presence of blood in structures with a much lower dose than 
that required by CT. 2. Image processing. Some algorithms use image processing techniques to find structures 
within the 3D data [1,32,30,29] or to filter the original data. MR data, in particular, needs image pro-cessing 
to select appropriate structure. 3. Surface construction. Surface construction, the topic of this paper, 
involves the creation of a surface model from the 3D data. The model usually consists of 3D volume elements 
(voxels) or polygons. Users select the desired surface by specify- ing a density value, This step can 
also include the crea-tion of cut or capped surfaces. 4. Display. Having created the surface, the final 
step displays that surface using display techniques that include ray casting, depth shading, and color 
shading. 3. RELATED WORK. There are several approaches to the 3D surface generation problem. An early 
technique [23] starts with contours of the surface to be constructed and connects contours on consecu-tive 
slices with triangles. Unfortunately, if more than one contour of surface exists on a slice, ambiguities 
arise when determining which contours to connect [14]. Interactive in-tervention by the user can overcome 
some of these ambigui- ties [8]; however, in a clinical environment, user interaction should be kept 
to a minimum. Another approach, developed by G. Herman and col-leagues [19] creates surfaces from cuberilles. 
A cuberille is "dissection of space into equal cubes (called voxels) by three orthogonal sets of parallel 
planes [7]." Although there are many ways to display a cuberille model, the most realistic im- ages result 
when the gradient, calculated from cuberilles in a neighborhood, is used to find the shade of a point 
on the model [15]. Meagher [25] uses an octree representation to compress the storage of the 3D data, 
allowing rapid manipu- lation and display of voxels. Farrell [12] uses ray casting to find the 3D surface, 
but rather than shade the image with a gray scale, uses hue light- ness to display the surface. In another 
ray casting method, Hohne [22], after locating the surface along a ray, calculates the gradient along 
the surface and uses this gradient, scaled by an "appropriate" value, to generate gray scales for the 
image. A different approach, used at the Mayo Clinic [26], dis-plays the density volume rather than the 
surface. This method produces, in effect, a conventional shadow graph that can be viewed from arbitrary 
angles. Motion enhances the three-dimensional effect obtained using the volume model. Each of these techniques 
for surface construction and dis- play suffer shortcomings because they throw away useful in-formation 
in the original data. The connected contour algo-rithms throw away the inter-slice connectivity that 
exists in the original data. The cuberille approach, using thresholding to represent the surface as blocks 
in 3D space, attempts to recover shading information from the blocks. The ray cast-ing methods either 
use depth shading alone, or try to approx- imate shading with an unnormalized gradient. Since they display 
all values and not just those visible from a given point of view, volume models rely on motion to produce 
a three-dimensional sensation. Our approach uses information from the original 3D data to derive inter-slice 
connectivity, surface location, and sur-face gradient. The resulting triangle model can be displayed 
on conventional graphics disptay systems using standard rendering algorithms. 4. MARCHING CUBES ALGORITHM. 
There are two primary steps in our approach to the sur-face construction problem. First, we locate the 
surface corresponding to a user-specified value and create triangles. Then, to ensure a quality image 
of the surface, we calculate the normals to the surface at each vertex of each triangle. Marching cubes 
uses a divide-and-conquer approach to lo-cate the surface in a logical cube created from eight pixels; 
four each from two adjacent slices (Figure 2). The algorithm determines how the surface intersects this 
cube, then moves (or marchs) to the next cube. To find the surface intersection in a cube, we assign 
a one to a cube's vertex if the data value at that vertex exceeds (or equals) the value of the surface 
we are constructing. These vertices are inside (or on) the surface. Cube vertices with values below the 
surface receive a zero and are outside the surface. The surface intersects those cube edges where one 
vertex is out- side the surface (one) and the other is inside the surface (zero). With this assumption, 
we determine the topology of the surface within a cube, finding the location of the intersec- tion later. 
  / /<"J+I'"U {+, , ,+ Shee~ i ~,~j . pixel I Figure 2. Marching Cube.  ~ SIGGRAPH '87, Anaheim, July 
27-31, 1987 In summary, marching cubes creates a surface from a three-dimensional set of data as follows: 
1. Read four slices into memory. 2. Scan two slices and create a cube from four neighbors on one slice 
and four neighbors on the next slice. 3. Calculate an index for the cube by comparing the eight density 
values at the cube vertices with the surface con- stant. 4. Using the index, look up the list of edges 
from a precal- culated table. 5. Using the densities at each edge vertex, find the surface- edge intersection 
via linear interpolation. 6. Calculate a unit normal at each cube vertex using central differences. 
Interpolate the normal to each triangle ver- tex. 7. Output the triangle vertices and vertex normals. 
 5. ENHANCEMENTS TO THE BASIC ALGORITHM. We have made several improvements to the original marching 
cubes that make the algorithm run faster and that add solid modeling capabilities. 5.1 E~ciency Enhancements. 
The efficiency enhancements allow the algorithm to take advantage of pixel-to-pixel, line-to-line, and 
slice-to-slice coherence. For cubes interior to the original data limits (those not including slice 0, 
line 0, or pixel 0), only three new edges need to be interpolated for each cube. We can obtain the other 
nine edges from previous slices, lines, or pixels. In Figure 5, the shaded circles represent values avail- 
able from prior calculations; only edges 6, 7, and 12 have to be calculated for the new cube. Special 
cases are present along the boundaries of the data, but, by enumerating these cases, we can limit vertex 
calcula- tions to once per vertex. In practice, we only save the previ- ous pixel and line intersections 
because the memory required to save the previous slice's intersections is large. Using the coherence 
speeds up the algorithm by a factor of three. C 7 e6 ® y ×  Reducing the slice resolution, by averaging 
four pixels into one, decreases the number of triangles, improves the surface construction efficiency 
and smooths the image. Although there is some loss of detail in the averaged slices, the averaging makes 
the number of triangles more manage-able for high-resolution slices. 5.2 Functional Enhancements. We 
have added a solid modeling capability to the algo- rithm. Boolean operations permit cutting and capping 
of solid models, as well as the extraction of multiple surfaces. In a medical application, cutting is 
analogous to performing surgery and capping (and texture mapping) is analogous to the medical imaging 
technique of reformatting. We use the cube index described earlier to do Boolean operations on the surfaces. 
Here, just consider three values of the index: index = 0 for cubes outside the surface. index = 255 for 
cubes inside the surface. 0 < index < 255 for cubes on the surface.  Solid modeling uses these notions 
of inside, outside, and on to create a surface. Analytic functions also provide the same information; 
so, for example the equation of a plane, ax + by + cz-d, tells where a given point lies with respect 
to the plane. Let --S, 8S, and S represent sets of points that are outside, on, and inside a surface, 
respectively. Referring to Figure 6, we build a truth table, shown in Figure 7, for the Boolean intersection 
operation. Nine entries in the .truth table describe what to do when two surfaces have a given index. 
With x's representing no operation, the entry for (S, --P) shows that the cube in question is inside 
one surface but outside the other, resulting in no triangles. The (8S, P) entry produces triangles from 
the S surface, while the (S, 8P) entry produces triangles from the P surface. The (8S, 8P) entry, created 
when a cube is on both surfaces, requires special processing. We clip -p Figure 6. Point/Surface Relations. 
p '-P dP S x x p -S x x x dS S x ,  Figure 5. Coherence. Figure 7. Truth Table.   (~ ~ Computer Graphics, 
Volume 21, Number 4, July 1987 10. REFERENCES [1] Artzy, E., Frieder, G., and Herman, G.T. The Theo- 
ry, Design, Implementation and Evaluation of a Three-Dimensional Surface Detection Algorithm. Comptlter 
Graphics and Ima~,,e Processinj,, 15, 1 (January 1981), 1-24. [2] Barillot, C., Gibaud, B., Scarabin, 
J., and Coatrieux, J. 3D Reconstruction of Cerebral Blood Vessels. IEEE Comlmwr Graphk's attd Applk'ations 
5, 12 (December 1985), 13-19. [3] Bates, R. H., Garden, K. L., and Peters, T. M. Over-view of Computerized 
Tomography with Emphasis on Future Developments. Proc. of the IEEE 71, 3 (March 1983), 356-372. [4] Bloch, 
P. and Udupa, J. K. Application of Computer- ized Tomography to Radiation Therapy and Surgical Planning. 
Proc. oi' the IEEE 71, 3 (March 1983), 351-355. [5] Brewster, L. J., Trivedi, S. S., Tut, H. K., and 
Udupa, J. K. Interactive Surgical Planning. IEEE Computer Graphics and Applications 4, 3 (March 1984), 
31-40. [6] Burk, D. L., Mears, D. C., Kennedy, W. H., Cooper- stein, L. A., and Herbert, D. L. Three-Dimensional 
Computed Tomography of Acetabula Fractures. Ra-diology 155, 1 (1985), 183-186. [7] Chen, L., Herman, 
G. T., Reynolds, R. A., and Udu- pa, J. K. Surface Shading in the Cuberille Environ- ment. IEEE Computer 
Graphics and Applications 5, 12 (December 1985), 33-43. [8] Christiansen, H. N. and Sederberg, T. W. 
Conversion of Complex Contour Line Definitions into Polygonal Element Meshes. Computer Graphics 12, 3 
(August 1978), 187-192. [9] Cline, H. E., Dumoulin, C. L., Lorensen, W. E., Hart, H. R., and Ludke, S. 
3D Reconstruction of the Brain from Magnetic Resonance Images. Magnetic Reso- nance Imaging (1987, to 
appear). [10] Cline, H. E., Lorensen, W. E., Ludke, S,, Crawford, C. R., and Teeter, B. C. High-Resolution 
Three- Dimensional Reconstruction of Tomograms. Medical Physics (1987, to appear). [11] Cook, L. T., 
Dwyer, S. J., Batnitzky, S., and Lee, K. R. A Three-Dimensional Display System for Diagnos- tic Imaging 
Applications. IEEE Computer Graphics and Applications 3, 5 (August 1983), 13-19. [121 Farrell, E. J. 
Color Display and Interactive Interpreta- tion of Three-Dimensional Data. IBM J. Res. Develop 27, 4 (July 
1983), 356-366. [13] Farrell, E. J., Zappulla, R., and Yang, W. C. Color 3D Imaging of Normal and Pathologic 
Intracranial Struc- tures. IEEE Computer Graphics and Applications 4, 9 (September 1984), 5-17. [14] 
Fuchs, H., Kedem, Z. M., and Uselton, S. P. Optimal Surface Reconstruction from Planar Contours. Comm. 
o['the ACM 20, 10 (October 1977), 693-702. [151 Gordon, D. and Reynolds, R. A. Image Space Shad- ing 
of 3-Dimensional Objects. Computer Graphics and Image Processing 29, 3 (March 1985), 361-376. [16] Hale, 
J. D., Valk, P. E., and Watts, J. C. MR Imaging of Blood Vessels Using Three-Dimensional Recon- struction: 
Methodology. Radiolo,xv 157, 3 (December 1985), 727-733. [17] Hemmy, D. C., David, D. J., and Herman, 
G. T. Three-Dimensional Reconstruction of Craniofacial De- formity Using Computed Tomography. Neurosurgery 
13, 5 (November 1983), 534-541. [18] Hemmy, D. C. and Tessier, P. L. CT of Dry Skulls with Craniofacial 
Deformities: Accuracy of Three-Dimensional Reconstruction. Radiology 157, 1 (Oc- tober 1985), 113-116. 
[19] Herman, G. T. and Udupa, J. K. Display of 3D Digi- tal Images: Computational Foundations and Medical 
Applications. IEEE Computer Graphics and Applications 3, 5 (August 1983), 39-46. [20] Hinshaw, W. S. 
and Lent, A. H. An Introduction to NMR Imaging: From the Bloch Equation to the Imag- ing Equation. Proc. 
of the IEEE 71, 3 (March 1983), 338-350. [21] Hoffman, E. A. and Ritman, E. L. Shape and Dimen- sions 
of Cardiac Chambers: Importance of CT Section Thickness and Orientation. Radiology 155, 3 (June 1985), 
73%744. [22] Hohne, K. H. and Bernstein, R. Shading 3D-Images from CT Using Gray-Level Gradients. IEEE 
Trans. on Medical Imaging MI-5, 1 (March 1986), 45-47. [23] Keppel, E. Approximating Complex Surfaces 
by Tri- angulation of Contour Lines. IBM J. Res. Develop 19, 1 (January 1975), 2-11. [24] Knoll, G. F. 
Single-Photon Emission Computed To- mography. Proc. of the IEEE 71, 3 (March 1983), 320-329. [25] Meagher, 
D. J. Geometric Modeling Using Octree Encoding. Computer Graphics and Image Processing 19, 2 (June 1982), 
129-147. [26] Robb, R. A., Hoffman, E. A., Sinak, L. J., Harris, L. D., and Ritman, E. L. High-Speed 
Three-Dimensional X-Ray Computed Tomography: The Dynamic Spatial Reconstructor. Proc. of the IEEE 71, 
3 (March 1983), 308-319. [27] Sunguroff, A. and Greenberg, D. Computer Generat- ed Images for Medical 
Application. Computer Graphics 12, 3 (August 1978), 196-202. [28] Sutherland, I. E. and Hodgman, G. W. 
Reentrant Po- lygon Clipping. Comm. of the ACM 17, 1 (January 1974), 32-42. [29] Trivedi, S, S., Herman, 
G. T., and Udupa, J. K. Seg-mentation Into Three Classes Using Gradients. 1EEE Trans. on Medical Imaging 
MI-5, 2 (June 1986), 116-119. [30] Udupa, J. K. Interactive Segmentation and Boundary Surface Formation 
for 3-D Digital Images. Computer Graphics and Image Processing 18, 3 (March 1982), 213-235. [31] Vannier, 
M. W., Marsh, J. L., and Warren, J. O. Three Dimensional CT Reconstruction Images for Craniofacial Surgical 
Planning and Evaluation. Radiol-ogy 150, 1 (January 1984), 179-184. [32] Zucker, S. W. and Hummel, R. 
A. A Three-Dimensional Edge Operator. IEEE Trans. on Pattern Analysis and Machine Intelligence PAMI-3, 
3 (May 1981), 324-331.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37423</article_id>
		<sort_key>171</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[Efficient algorithms for 3D scan-conversion of parametric curves, surfaces, and volumes]]></title>
		<page_from>171</page_from>
		<page_to>179</page_to>
		<doi_number>10.1145/37401.37423</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37423</url>
		<abstract>
			<par><![CDATA[<i>Three-dimensional (3D) scan-conversion algorithms</i>, that scan-convert 3D parametric objects into their discrete voxelmap representation within a Cubic Frame Buffer (CFB), are presented. The parametric objects that are studied include Bezier form of cubic parametric curves, bicubic parametric surface patches, and tricubic parametric volumes. The converted objects in discrete 3D space maintain pre-defined application-dependent connectivity and fidelity requirements.The algorithms introduced here emply third-order forward difference techniques. Efficient versions of the algorithms based on first-order decision mechanisms, which employ only integer arithmetic, are also discussed. All algorithms are incremental and use only simple operations inside the inner algorithm loops. They perform scan-conversion with computational complexity which is linear in the number of voxels written to the CFB. All the algorithms have been implemented as part of the <i>CUBE Architecture</i>, which is a voxel-based system for 3D graphics.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Digitizing and scanning</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010506</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Document scanning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP77026170</person_id>
				<author_profile_id><![CDATA[81406594489]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Arie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kaufman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[State Univ. of New York at Stony Brook, Stony Brook]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bezier, P., "UNISURF System: Principles, Program, Language", in Computer Languages for Numerical Control, J. Hatvany, (ed.), North-Holland, Amsterdam- London, 1972, 417-426.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bezier, P., Numerical Control Mathematics and Applications, A. R. Forrest (Trans.), Wiley,-London, 1972.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bezier, P., "Mathematical and Practical Possibilities of UNISURF", in Computer Aided Geometric Design, R. E. Barnhitl and R. F. Riesenfeld, (eds.), Academic, New York, 1974, 127-152.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358815</ref_obj_id>
				<ref_obj_pid>358808</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F., Carpenter, L., Lane, J. and Whirred, T., "Scan Line Methods for Displaying Parametrically Defined Surfaces", Communications of the ACM, 23, 1 (January 1980), 23-34.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bresenham, J. E., "Algorithm for Computer Control of a Digital Plotter", IBM Systems Journal, 4, 1 (1965), 25- 30.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>892734</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Clark, J. H., "Parametric Curves, Surfaces, and Volumes in Computer Graphics and Computer-Aided Geometric Design", Technical Report 221, Computer Systems Laboratory, Stanford University, Stanford, CA, November 1981.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>889976</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Coons, S. A., "Surfaces for Computer-Aided Design of Space Forms", MIT Project MAC Teeh. Rep.-41, June 1967.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[deBoor, C., "On Uniform Approximation with Splines", Journal of Approximation Theory, 1, (1968), 249-274.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6684</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Foley, J. D. and van Dam, A., Fundamentals of Interactive Computer Graphics, Addison-Wesley, Reading, MA, 1982.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Forrest, A. R., "On Coons and Other Methods for the Representation of Curved Surfaces", Computer Graphics and Image Processing, 1, 4 (December 1972), 341-354.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Goldwasser, S. M., "A Generalized Object Display Processor Architecture", IEEE Computer Graphics and Applications, 4, 10 (October 1984), 43-55.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Jackel, D., "The Graphics PARCUM System: A 3D Memory Based Computer Architecture for Processing and Display of Solid Models", Computer Graphics Forum, 1985, 21-32.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kaufman, A. and Bakalash, R., "CUBE An Architecture Based on a 3-D Voxel Map", in Theoretical Foundations of Computer Graphics and CAD, R. A. Earnshaw, (ed.), Springer-Verlag, 1987.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Kaufman, A. and Bakatash, R., "A 3-D Cellular Frame Buffer", Proc. EUROGRAPHICS'85, Nice, France, September 1985, 215-220.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Kaufman, A. and Bakalash, R., "Memory and Processing Architecture for 3-D Voxel-Based Imagery", Technical Report 87/06, Department of Computer Science, SUNY at Stony Brook, February 1987.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Kaufman, A., "An Algorithm for 3D Scan-Conversion of Polygons", Proc. EUROGRAPHICS'87, Amsterdam, Netherlands, August 1987.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Kaufman, A., "Voxel-Based Architectures for Three- Dimensional Graphics", Proc. IFIP'S6, Dublin, Ireland, September 1986, 361-366.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>319126</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Kaufman, A. and Shimony, E., "3D Scan-Conversion Algorithms for Voxel-Based Graphics", Proc. AGM Workshop on Interactive 3D Graphics, Chapel Hill, NC, October 1986.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Kim, C. E., "Three-Dimensional Digital Planes", IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-$, 5 (September 1984), 639-645.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Lane, J. M. and Riesenfeld, R. F., "A Theoretical Development for the Computer Generation and Display of Pieeewise Polynomial Surfaces", IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-2, 1 (January 1980), 35-46.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Ohashi, T., Uchiki, T. and Tokoro, M., "A Three- Dimensional Shaded Display Method for Voxel-Based Representation", Proe. EUROGRAPHICS'85, Nice, France, September 1985, 221-232.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>538576</ref_obj_id>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Pavlidis, T., Algorithms }or Graphics and Image Processing, Computer Science Press, Rockvilte, MD, 1982.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Riesen feld, R. F., "Applications of B-spline Approximation to Geometric Problems of Computer Aided Design", University of Utah UTEC-CSc-73-126, March 1973.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Rosenfeld, A., "Three-Dimensional Digital Topology", Computer Science Center, Univ. of Maryland, Teeh. Rep.-936, 1980.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356862</ref_obj_id>
				<ref_obj_pid>356859</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Srihari, S. N., "Representation of Three-Dimensional Digital Images", Computing Surveys, 4, 13 (December 1981), 399-424.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~ ¢ Computer Graphics, Volume 21, Number 4, July 1987 Efficient Algorithms for 3D Scan-Conversion o£ 
Parametric Curves, Surfaces, and ~rolumes Arie Kaufrrmn Department of Computer Science State University 
of New York at Stony Brook Stony Brook, NY 11794-4400 Abstract Three-dimensional (SD) scan-conversion 
algorithms,, that scan-convert 3D parametric objects into their discrete voxel- map representation within 
a Cubic Frame Buffer (CFB), are presented. The parametric objects that are studied include Bezler form 
of cubic parametric curves, blcubic parametric surface patches, and trieublc parametric volumes. The 
con-verted objects in discrete 3D space maintain pre-defined application-dependent connectivity and fidelity 
requirements. The algorithms introduced here employ third-order forward difference techniques. Efficient 
versions of the algorithms based on first-order decision mechanisms, which employ only integer arithmetic, 
are also discussed. All algorithms are incremental and use only simple operations inside the inner algorithm 
loops. They perform scan-conversion with compu-tational complexity which is linear in the number of voxels 
written to the CFB. All the algorithms have been imple-mented as part of the CUBE Architecture~ which 
is a voxel- based system for 3D graphics. OR Categories and Subject Descriptors: 1.3.3 [Computer Graphics]: 
Picture/Image Generation; 1.3.5 [Computer Graphics]: Computational Geometry and Object Modeling; 1.3.7 
[Computer Graphles]: Three-Dimensional Graphics and Realism. General Terms: Algorithms, Computer Graphics. 
Additional Key Words and Phrases: Bezier curves, Bezier sur- faces, Bezler volumes, cubic frame buffer, 
three-dimensional scan conversion, voxel. This work was supported by the National Science Foundation 
under grant DCR-86-03603. Permission to copy without fee all or part of this material is granted provided 
that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice 
and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. &#38;#169; 1987 ACM-0-89791-227-6/87/007/0171 $00.75 1. Introduction Three primary 
representation domains are common for graph- ical data: the continuous geometric model, the discrete 
plxel image~ and the discrete vozcl image. The former two representations have received considerable 
attention in the literature, and there is an abundance of 2D scan-converslon algorithms which are fundamental 
to raster systems. Such an algorithm converts a 2D continuous geometric representation into a set of 
plxels in the plxel-lmage plane. Recent papers [16, 18] have introduced and developed the notion of a 
three-dimensional (3D) scan-conversion algorithm, which converts a 3D analytic representation into a 
set of voxels in the discrete voxel domain. We focus here on 3D scan-conversion algo-rithms for the following 
3D parametric objects: Cubic parametric curves Bicubic parametric surface patches a Tricubic parametric 
volumes There are four voxel-image space architectures, CUBE [13-15], GODPA [11], PARCUM [12], and 3DP 
4 [21], and many other voxel-based software systems that have been reported in the literature. The theme 
of these systems is that the 3D inherently continuous scene is discretized, sampled, and stored in a 
large 3D cubic frame buffer of unit cells called volume ele- ments or voxels. A CFB with 5123 resolution 
and 8-bit-deep voxels, for example, is a large memory buffer of size 128M bytes. As computer memories 
are getting significantly cheaper and more compact, such huge memories and consequently voxel-based hardware 
systems are becoming more and more practical. All the four voxel-based architectures utilize high performance 
multi-processing architecture to generate shaded projections of the 3D scene within the cubic buffer. 
They all assume that a database of voxel-based objects exists for loading into the CFB. Unlike the other 
systems that operate solely in the discrete voxel-image space, CUBE further provides object space capabilities 
and ways to intermix the two ([17]). The object-space capabilities are enabled using a spectrum of 3D 
scan-conversion algorithms [16, 18], those that pertain to parametric curves, surfaces and volumes are 
discussed in this paper. All these algorithms have been implemented as part of the 3D geometry processor 
of the CUBE architecture. They enable CUBE to cater to a wide variety.of applications which accept a 
geometric representation of the 3D scene as well as sampled experimental data.  ~ SIGGRAPH '87, Anaheim, 
July 27-31, 1987 Although the voxel representation is more effective for empiri- cal imagery, it also 
has a significant utility in synthetic 3D graphics or in applications merging empirical and synthetic 
images. For example, a synthetic ir~jectlon needle or a scalpel can be superimposed on an ultrasound 
image, or a model of the skull can be overlaid, possibly with semi-transparent colors, upon a computed 
tomography scan of the skull. As a consequence of the proliferation of voxel-based systems, there is 
a growing need for mechanisms to input geometric models into such systems. The uniqueness of the CUBE 
architecture is in providing such a mechanism for a geometric model to be discretlzed and optionally 
overlaid upon and/or compared with the experimental data. Terms used in the rest of the paper and the 
requirements from a 3D scan-converter are outlined in Section 2. The basic avenues to access the CFB 
are sketched in Section 3, followed by the 3D scan-conversion algorithms for curves (in Sections 4, 5 
and 6), for surfaces (in Sections 7, 8 and 9), and for volumes (in Sections 10 and 11). The algorithms 
are described in pseudo-C where the C keywords are in bold face. Vari-ables are shown in italics font. 
Comments are enclosed between a pair of double quotes and printed in "italics". Definitions are (3 language 
type definitions. Subscripts, super- scripts and array notations are used interchangeably. 2. Terminology 
and Requirements Most of the terms used in this paper for 3D discrete topology are generalizations of 
those used in 2D discrete topology (see e.g., [19, 22, 24, 25]). Let us mark the continuous 3D space 
by R 3, and the discrete 3D voxel-lmage space, which is a 3D array of grid points, by Z s. We shall term 
a vozel or the region contained by a 3D discrete point (z , y , z ), as the con-tinuous region (u, v, 
w) such that z-O.5<u<_x+0.5, y-0.5<v <y +0.5 and z-0.5<w _<z +0.5. This assumes that the voxel "occupies" 
a unlt cube centered at the grid point (z,y,z), and the array of voxels tessellates Z a. Although there 
is a slight difference between a grid point and a voxel, they will be used interchangeably. Each voxel 
(x ,y ,z )EZ 3 has three kinds of neighbors: (1) It has six direct neighbors (face neighbors): (z +l,v,z), 
(x-l,y,z), (x,y+l,z), (z,y-l,z), (z,y,z+l), and (~ ,v ,* -1). (2) It has twelve indirect neighbors {edge 
neighbors): (x +l,y +l,z ), (x-l,y +l,z ), (x +l,y-l,z ), (z-l,y-l,z), (x +l,y ,z +1), (x-l,y ,z +1), 
(x +l,y ,z-l), (z -l,y ,z -1), (z ,y +l,z +1), (z ,y-l,z +1), (x ,y +l,z-1), and (x ,y-l,z-1). (3) It 
has eight remote neighbors (corner neighbors): (~ +I,v +1,~ +1), (~ +l,v +l,~-l), (~ +l,v-l,~ +1), (x 
+l,y-l,z-1), (x-l,y +l,z +1), (x-l,y +l,z-1), (z-l,y-l,z +l), and (z-l,y-l,z-1).  We further define 
in Z a the six direct neighbors as 6-neighbors. Both the six direct and twelve indirect neighbors are 
defined as 18-neighbors. All three kinds of neighbors are defined as 26-neighbors. A 6-connected path 
is a sequence of voxels such that consecutive pairs are 6-neighbors. An 18-connected path is a sequence 
of IS-neighbor voxels, while a 26-connected path is a sequence of 26-neighbor voxels. Three metrics on 
Z a, which correspond to the three connec-tivity kinds, are defined. The 6-distance between two voxels 
(zl,y 1,Zl) and (a:2, Y2,Z2) iS:  d6= 1~2-~,1 + I v~-vl I + I ~2-z, I (1) which is the length of the 
shortest 6-connected path between them. The 26-distance between two voxels is: d26= max ( I z2-xl l, 
[Y2-~/1 t, I z2-Zl I ) (2) which is the length of the shortest 26-connected path between them. The 18-distance 
between two v0xels is: dis=max d28, 7- (3) which is the length of the shortest 18-connected path between 
them. A 3D scan-converter is required to obey some fidelity, connec-tivity, and efficiency requirements. 
These requirements are met by the algorithms presented in this paper. The basic fidelity requirements 
in scan-converting an object from R a to Z 3 are: 1) The discrete points, for which the region contained 
by them is entirely inside the continuous object, are in the con-verted discrete object. 2) The discrete 
points, for which the region contained by them is entirely outside the continuous object, are not in 
the converted discrete object. Obviously, some discrete points will not belong to either of the above 
eases, and more guidelines are necessary. Those are: 3) If the object is a curve (1D object), the converted 
object will meet certain connectivity requirements. The converted endpoints will be in the converted 
object. 4) If the object is a surface (2D object), it will meet certain "tack of tunnels" connectivity 
requirements. The converted curved "edges" will be in the converted object. 5) tf the object is a volume 
(313 object), its "inside" will be converted according to requirement 1. Other points will be treated 
by majority decision -the discrete point is in the object, if more than half its region is in the continuous 
object. For curves we shall require 6-connectivity, 18-connectivity or 26-connectivlty, depending on 
implementation needs. For sur- faces we shall require lack of 6-connected tunnels. 18-connectivity or 
26-connected tunnels can also be disallowed depending on implementation requirements. For solid volumes 
6-connectivity will be required in order to avoid any internal cavities. As we show later the computational 
complexity of the algo-rithms is equal to the number of discrete points converted multiplied by a constant. 
The goals are, thus, to attempt to decrease t, he constant, and to use simple operations within inner 
algorithm loops. Furthermore, we will strive to use integer arithmetic whenever possible, and fixed-point 
arith-metic only when impossible otherwise. 3. Cubic Frame Buffer Access We assume here that the CFB 
access system of the CUBE architecture accepts the point/voxel location in three (X, Y and Z) registers, 
and its color in a fourth register, COLOR. The algorithms access the CFB using the following auxiliary 
functions. Each of the first 3 functions executes in one machine instruction and should therefore be 
fast:  '~ Computer Graphics, Volume 21, Number 4, July 1987 mmn mll I I) NEW_POS (axis, value); This 
function assigns value to the axis register (X, Y, or Z). 2) UPDATE_POS (a~cis, increment); Increments 
(decrements) the axis register in one machine instruction, where increment is the coordinate step. 3) 
PUT_VOXEL O; Writes the voxel, whose address is in the X, Y, and Z regis- ters with color as in the COLOR 
register, into the CFB. 4) WRITE VOXEL (x, y, z, e); Updates the X, Y, Z and COLOR registers with the 
specified parameters, and then calls PUT_VOXEL to ~'put" the voxel into the CFB. 4. Parametric Polynomial 
Curves A parametric polynomial 3D curve is defined as polynomials of some parameter t, one for cach z, 
y, and z. Varying the parameter, e.g., from 0 to 1, defines all the points along the curve segment. 
Many systems, including ours, use polynomi-als of the third degree, since this is the lowest degree parametric 
polynomial that can describe a well-formed 3D curve with four boundary constraints. Matrix notation of 
the cubic polynomial of the curve f is: f (t) : T M G 0 < t < 1 (4) Gz r=i~ ~ t~ t 4 c = c~ (s) G4 the 
4)<4 matrix M is the geometric basis matrix, G is the geometric vector (G i are the geometric control 
points), and M G is the coefficients of the cubic polynomial. Common cubic representations are Hcrmite 
form [7, 10], B- Splint form [8, 23], and Bezier form [1-3]. In the latter, G 1 and G 4 are the curve 
endpoints, while 3(G~-G1) and 3(G,-Ga) are the end tangents. The matrix M for the Bezier representation 
is: [-1 3-3 1 3 -6 3 0 M~ = _ 3 0 0 (6) 1 0 0 0 In Bezier form the curve resides wholly within the convex 
hull of its control points G i . In this paper, curves are assumed to be in Bezier form which is widely 
used in graphics and geometric design. There is no loss of generality in this assumption, since all cubic 
curves have their Beater represen- tation. Direct evaluation of the 3D curve points from the polynomial 
of Equation 4 is computationally intensive, even when Homer's rule is employed. An alternative method 
for scan-conversion is repeated bisection of the curve until the seg-ments reside within a single discrete 
point (e.g., [6, 20]). Another mechanism, which is the one explored in this paper, is using the curve's 
third order finite forward difference matrix for a step size along the parameter t [6, 9]. The initial 
difference vector Af 0 is obtained by: o e 3 c 2 e 0   0101 :001 =E, MC--= M c (7) [a3f0 L6 3 0 0 
0 Now, it is used to repeatedly obtain the differences of the next step using the following third order 
DDA (Digital Differential Analyzer) calculations: A0fi+l : AOfi + Alfi Alfi+a = Alfi + A2fi 0 _< i < 
1 (8) /X2fi+l = A2f i + /k3f i A3fi+l --A31~ and A°fi+a is the next step polynomial value. These calcu- 
lations require only three additions per step per ordinate, while the alternative method of utilizing 
the Hornet's rule requires three additions and three multiplications per step per ordinate. 5. 3D Scan-Conversion 
of Curves The formal data type curve is: typedef struct curve { int g/s//d]; " x, y, z for 4 co,Urot 
points" color c; " color of curve" } curve; where the 3)<4 control matrix g is the four Bezier geometric 
control points. The coordinates are assumed to be integers or fixed-point which can be scaled up to some 
finite resolution integer domain. The algorithm CURVE, presented in Figure 1, scan-converts a 3D third 
degree parametric curve in the parameter t according to the forward difference equations (Eq. 8). The 
only problem remaining is to calculate a step size along the parameter t so as to guarantee at least 
26- connectivity, that is, guaranteeing that the first difference along any dimension is not greater 
than 1 in magnitude. In first approximation, this is the same as: 0<t <1 To find the maximum, the extrema 
of the second degree derivatives of the parametric equations in the range 0< t <1 are found by differentiation. 
The maximum for each com-ponent is thus: ,10, where ~, /3, and 3' are the t values for which the linear 
second derivatives of the curve equation are respectively 0, provided that 0<~,/3,7<1. The maximum magnitude 
of these extrema, n = max (n= ,n v ,n z ), is the inverse of the required algorithm step e. A small term 
is first added to n, e.g., round- ing up, to compensate for the approximation. The one time  ~ SIGGRAPH 
'87, Anaheim, July 27-31, 1987 Find maximum absolute value of dx ~dr, dy ~tit , dz /dt for 0 < t < 1 
(Eqs. 10-12), set n to maximum of these maxima; = 1/CEZLI~ (n); Calculate initial difference vectors 
Az ,Ay ,Az by multiplying matrix E e by matrix M b and control points g (Eq. 7);  WR1r~_VOX~L (ROt'~'D(aO=),ROL'N.(aO 
y ), RO~N.(a% ), ~); for (t = O; t <_ 1; t += e) { "follow the curve" AOx +~ Alx ; "apply Eq. 8 far 
x" Alg +_~ A2:~ ; A2x +~ Asx ; A°y -t-~ Aly ; "apply Eq. 8 for ~'  Aly -I-~ A2y ; A2y -t-~ A3y ; AOz 
-]-~ Alz ; "apply Eq. 8 for z;' Alz ~ A2z ; A2z -i-~-- ASz ; WR'r~-VO~L(RO~"D?' O ~ ),RO~(~x O Y ),Ro~'ND( 
a ° ~ ),d; Figure 1: Cb'RFE- Algorithm for 3D Scan-Converting Curves floating-point computation of the 
step e requires 9 multiplica- tions, 9 additions, 4 divisions, 8 comparisons, and one round-ing. Algorithm 
time complexity is linear in the maximum magni-tude n, which should come near the number of painted voxels. 
This is so for all curves which are not too oscillative, wavy or self-intersecting. It is reasonable 
to assume that the curves, or series of sub-curves, dealt with here, which are third degree Bezier polynomials, 
belong to this class. Each step of the algorithm loop, i.e., each voxel written into the CFB, takes 10 
floating-point additions, one floating-point test, 3 roundings of floating-point numbers to integer coordi- 
nates, and one WRITE_VOXBL. These heavy floating-point computations are a result of the fact that the 
forward differences, being the first, second, and third order slopes, are floating-point numbers or fractional 
binary numbers (powers of the step e). These difficulties with CURVE computations can be overcome by 
converting the variables to integers. A more efficient curve algorithm, FAST CURVE, which uses only integer 
arithmetic, is discussed in the next section. 6. Eftieient 3D Scan-Conversion of Curves The forward differences 
are acting as first, second, and third order DDA's, where the vector Alfi is the first order x ,Y ,z 
slopes of the curve, which is used incrementally to update the voxel position A°fi+x at step i+1 (Equation 
8). The rounded coordinates of A°fi+l are then used as the three integer coordinates of the (i+l)-st 
voxel written into the CFB. Instead, a decision process can determine at each step of the algorithm which 
of the 26 neighbors of the current voxel lies closer to the curve being approximated. The process selects 
the next voxel by considering one dimension at a time, and the decision on any dimension, i.e., no change, 
increment, or decrement the coordinate, is independent of the other two dimensions. The variables A°z 
,A°y ,A°z are used now as the decision variables of the algorithm, representing the residual change in 
the respective coordinate. The decision process for x, for example, is as follows. Assum- ing that x 
is the current coordinate, then if A°z >0.5, i.e., the curve is passing closer to x +1 than to x, the 
register X is incremented (using UPDATE POS function) and A% is decre- mented by 1. Similarly if A°z 
<-0.5, then X is decremented and A°x is incremented. Otherwise, X and A°z are unchanged. The residual 
value of A% is passed to the next step, where it is first being updated by the first order slopes. Similar 
decision processes hold for y and z. These decision processes enable the algorithm to avoid the rounding 
of the three coordinates. Furthermore, since the same decision processes hold also after scaling up the 
algorithm variables by a positive value, they can be transformed to all-integer processes (cf. [5]). 
In order to convert the forward differences to integers and to avoid the use of the fractional step e 
at all, the E~ matrix of Equation 7 is redefined by scaling it up by the positive integer scalar 2n s: 
I 0 0 2i3 1 ~ 2n 2n 2 ] (lz)E, ^n.ZnZl~e ~ 12 4n 0 12 0 0 As a result the initial difference vector is 
redefined as: E. M G (14) [Asf Since both E, and M G are integer matrices the initial difference vector 
and consequently the forward differences (computed by Equation 8) are all integers. The variables of 
the algorithm are also scaled up by 2n 3, and thus the use of the step e and the floating-point variables 
within the loop of the algorithm are completely avoided. In particular, the parameter t is now an integer, 
stepping by one from 0 to n. Note that the constants n 3 and 2n 3 should be computed only once at initialization. 
The algorithm FAST CURVE, displayed in Figure 2, is the algo- rithm CURVE modified to include the all-integer 
decision processes. The time complexity of this efficient version of the algorithm is also linear with 
the number of voxels written into the CFB. However, writting a single voxel requires now between 9 to 
12 additions, 4 to 7 tests, an increment, all in integer, and 0 to 3 UPDATE POS calls and one PUT VOXEL. 
Note also that 0 to 3 calls to UPDATE_POS and one PUT VOXEL are faster than a single WRITE_VOXEL (see 
Section 3). This cost per voxel is much more attractive than the original all floating-point loop (cf. 
Section 5).  ~ Computer Graphics, Volume 21, Number 4, July 1987 Find maximum absolute value of dx/dt, 
dy ~dr, dz ~dr for 0 < t < i (Eqs. 10-12), set n to maximum of these maxima; Calculate initial difference 
vectors Ax, Ay, Az by Eq. 14; Set A°x, A°y, A°z to0; N~w:os (~fo1[o/, 9p//o/, g121/o/); "start point" 
 for(t=0; t <_ n: t++) ( "follow the curve" if (AOx > aS) { "decision for z" UPDA TE_POS (Z~Y); "increment 
z" A°x -= 2n3; } else if/A°z <-nO){ UPDA TE_POS {X,-i); "decrement z" A% += 2n3; ) A°z += Alz ; AI~ += 
A2x ; A2x += A3x ; if (A°y > ha){ "decision for y" VPDA rE POS (Y,i); "increment if' A°y -=2n3; } else 
if (A°y < -n3) { wpA TE eOS (Y,-S); "decrement y" A~y +--__ 2n3; } A°y +: Aly ; Aly += A~y ; A2y += ASy 
; if (A°z > n3)( "decision for £' UPDA TE_POS [Zfl); "increment 2' AOz _= 2n3; } else if [A°z < -n s) 
{ UPDA TE POS (Z,-i); " decrement z" A°z +:2nS; } A°z += Alz ; Alz 4: A2z ; A2z +: A3z ; PUT_VOXEL O; 
"in CFB " Figure 2: FAST_CURVE-An Efficient Algorithm for 3D Scan-Converting Curves Both algorithms CURVE 
and FAST CURVE handle the three coordinates independently, and therefore one, two and/or three coordinates 
may be simultaneously changed at any step. Consequently, the resulting curve is a 26-connected path in 
Z 3 of length n zs=max(n ~,n u ,n~) voxels. In order to obtain a 6-connected path, that is, one coordinate 
at the most changes at any step, the algorithm may increment (decrement) only the coordinate with the 
largest magnitude decision variable. For example, if I A0x I is the largest, then x is the only can- 
didate for a change, which is contingent to I A°x I >n3' The length in voxels of this curve is ns=n ~ 
+n~ +n~. Similarly, in order to obtain an 18-connected path, i.e., two coordinates at the most change 
at any step, the algorithm does not change the coordinate with the smallest magnitude of the decision 
variable. The other two coordinates, however, may or may not be incremented (decremented), depending 
on whether their respective decision variable magnitude is greater than n 3 The length in voxels of this 
curve is n,~= max (~20, rnUzl). 7. Parametric Polynomial Surfaces Bieubie parametric polynomial surfaces 
are cubic polynomials of two parameters t and u. As both parameters vary across the (0, 1) range, all 
the points on the surface patch are defined. The two-parameter representation is: f (t,u)= T M C M ~ 
U~ 0 < t, u _< 1 (15) u=[.3 .2 ~ 1] (16) T and M are the same as for curves. Again, we use the Bezier 
form where G is the 4X4 control point matrix, and Gn, G 14, G 41, G 44 are the surface patch "corners". 
The properties of the Bezier curves also hold for the Bezier surfaces. There-fore, the forward difference 
method can be used for surfaces too. The initial 45<4 forward difference matrix Af 00 is obtained by 
multiplying the difference operator by the alge-braic matrix M G M l [9]: Afoo= E~M G M tE~ ~ (17) where 
e and 6 are the step size in the t and the u parame-ters, respectively. A bicubic surface in t and u 
can be drawn as a sequence of cubic curves, where u is a constant and t varies from 0 to 1 using a curve 
forward difference process. The inter-curve iteration is very similar to that of the intra- curve, but 
it is performed on all rows of Af 00-This is further explained in the next section in the context of 
the 3D scan-conversion algorithm for surfaces. 8. 3D Scan-Conversion of Surfaces The formal data type 
surface represents a blcubic surface patch: typedef struct surface { int g/3]/4]:4]; "x, y, z for 16 
control points" color c; "surface color" ) surface; The 3X4X4 control matrix g is the 16 Bezier geometric 
con- trol points of the bicubic ]3ezier patch. When scan-converting such a surface we guarantee lack 
of 6-connected tunnels. This is achieved if the first difference (in first upproximation -the partial 
derivative) of the surface in each of the parameters is bounded by 1 in magnitude. Thus, we must find 
the extrema of the derivatives over the surface patch, n for t and m for u, and set the step size in 
each parameter to their inverse. These extrema are difficult to compute, so we shall use the maxima of 
the derivatives of the components, and require that they be less than l/x/3 to guarantee the above requirement. 
Unfortunately, even finding these extrema is not trivial and requires solving high-degree equations which 
is very time con-suming, and therefore not acceptable. Instead, we will show that the derivatives of 
a Bezier surface are also Bezier surfaces, and the convex hull property guaran- tees bounding derivatives. 
Finding the bound on Of /at is as follows. The D~-differentiating operator and the derivative of the 
surface with respect to the parameter t are: 1 means transposed ~,~ SIGGRAPH '87, Anaheim, July 27-31, 
1987 i0o0 3000 08) Dr= 200 Of (t,u) = T Dt Mb G Mb~ U t (19) Ot T Mb (Mb -1Dr Mb G) Mb t U f The term 
in parentheses in Equation 19 is the control point matrix G/ for the 0) e lot surface in Bezier representation, 
thus its Dq-differentiating operator in Bezier representation is: -~ 3 0 0 - -1 2 0 (20) Dq = M b 1Dr 
Mb ~ -2 1 1 [ t 0 3 3 Now we find the bound on the derivative as the maximum of the offset between all 
the control points of the O.f ~or sur-face. After finding all the offsets, set: n=' --max(C=' )-min(G.' 
) %f = max(C. )-rain(C() n z' max( G z' )-rain( G z' ) (21) E__I= ~min[ 1_, 1 1 t n "~3 ( nz ' %' ' nz' 
J Similarly, calculate 5 and m using the D= matrices. Note that symmetry provides D= =D t t. The algorithm 
to scan-convert a 3D bicubic parametric sur-face employs the forward differences iteration to evaluate 
the surface as a sequence of cubic curves f (t,0), f (t,5), f (t,25), " ", each of which is computed 
using a 1D curve forward difference iteration similar to the one described for curves. The computation 
of the initial endpoint of each of the curves is done by a similar 2D iteration. The algorithm first 
calculates the difference matrix A f 00 (using Equation 17) for each of its components, i.e., the 4X4 
matrices Aztu, /',yt,,. , and Azt, , . The zero column of £xx,= contains the initial values A°ze, Alzt, 
A2zt , Aazt used as the x forward differences of the curve f (t ~u0) for the current u0 (u 0 is constant, 
¢ varies). Similarly the zero column of Aye, and Azt~ are utilized for the g and z components. After 
scan-converging the curve f (t ,u0) the difference matrices Azt~ , AyL~ , and Azt~ are updated as 2D 
forward differences. Namely, column I of these matrices is added to their column 07 column 2 is added 
to column I, and column 3 is added to column 2. Now column 0 contains the initial difference vectors 
for the next curve f (t,u0q-1). The algorithm complexity is O(n rn) which is linear in the number of 
painted voxels. Each voxel drawn in the inner loop of such an algorithm requires the calculation of 10 
non-integer additions, a voxel write (including 3 ROUND operations), and an inner loop completion test. 
This is in addition to 37 non-integer additions, copying 12 elements, and a loop completion test for 
each u. Initialization involves the non-integer compu- tation of the coefficients, e, 5, and the initial 
difference matrices. 9. Efficient 3D Scan-Conversion of Surfaces Like for the curve algorithm, the heavy 
non-integer computa- tions can be replaced by a mord efficient all-integer algorithm, FAST_SURFACE, presented 
in Figure 3. The idea is very simi- lar to that used by the FAST_CURVE algorithm, namely, scal- ing the 
program variables up by a large constant so that all the algorithm variables, including the forward differences, 
are integers, and using decision processes to set the coordinates of the next voxeh More specifically, 
the matrix E a is redefined aS ~Trr ~ : l 00m3] 1 m m ~ 0 (22) Ern = m a E~ 2m 0 0 0 0 0 while the matrix 
E~ is redefined as E~ (Equation 13). As a result the initial difference matrix ~k] 0o, defined originally 
in Equation 17, is redefined as: "~f O0--En P Em | = 2namaE¢ P Fa~ 1 (23) The coordinates of the next 
voxel along the curve .f (t ,Uo) are selected based on three decision processes, one for each dimen- 
sion. In the x decision process, for example, the absolute mag- nitude of the decision variable A°xt 
is tested against the threshold ham 3 to determine whether ~,o increment, decre-ment or leave unchanged 
the X register holding the x ordi- nate. These inner loop decision processes are identical to those employed 
by the FAST CUR VE algorithm. The curve scan-conversion process is repeated for all the m +1 curves, 
u=O,1,...,m. In order to get the initial difference values for the next curve, the algorithm updates 
the difference matrices as a 2D forward difference and then steps along the curve f (0,u) (see Figure 
3). The scan-conversion of this curve also involves three decision processes. The decision process for 
x: for exampl% tests the decision variable AOOxtu , and the variable x, is accordingly incremented, decremented, 
or remains unchanged. The point (x~, y=, z,) is the starting point of the next curve to he scan-converted 
by the inner loop. Note, that unlike the variables Azt=, Ayt=, Az,= which are scaled up by the scalar 
2nam a, the coordinates (z~, y~ , z, ), starting at the first endpoint, represents all along actual voxel 
coordinates. The time complexity of the efficient version of the algorithm is also linear in the number 
of voxels written into the CFB. However, writting one voxel in the inner loop requires the same number 
of integer operations as for FASTCURVE, namely, 9-12 additions, 4-7 tests, an increment, 0-3 UPDATEPOS 
calls, and one PUTVOXEL. The outer loop requires the following integer operations for each u: 36-39 additions, 
1-4 increments, 4-7 tests, 15 copies, and one NEW_POS call. This is much more attractive than the original 
surface scan-conversion algorithm (el. Section 8). 10. Parametric Polynomial Volumes Parametric polynomial 
curves and surfaces have their trivari- ate version, i.e, a volume element. Varying the three parame- 
ters t, u, v from 0 to 1 defines all the points of the volume element. The extension to volumes is similar 
to the way curves have been extended into surfaces. Namely, if one parameter, say v, is assigned a constant 
value, and the other ~ Computer Graphics, Volume 21, Number 4, July 1987 Find n and m as described by 
Eq. 21; Find initial difference matrices Azt~ , Aytu , Azt,~ using Eq. 17; Set A°°z~. A°°yt~. A°°zt~ 
to 0; ~ = gio]lollol; y~ = gll/lotio/; for (u = O; u < m; u++) { NEW_POS(z~ ,Yu ,z~ ); "start point" 
Copy column 0 of Axt~ to Ax t ; Set A°zt to 0; Copy column 0of Ayt~ to Ay t; Set A% t to0; Copy column 
0 of Aztu to Az t; Set A0zt to0; for (t = O; t < n; t++) { "follow f(*,u)" if (A°x, > n ~m 9 { ueoarE_eoS 
(X,Q; AOzt -~ 2r~ 3m 3 } else if (A°zt < -nZm z) { UPDATE POS (X, 1); A°xt +~ 2n 3m 3 ) A°zt +~ Alzt; 
Alzt +~- AZzt ; Azzt +~ A3zt; Same decisions for Ay t and Az t ; PUT_VOXEL O; } Update Aztu : col 0 
+~ col 1; col 1 += col 2; col 2 +~ col 3; Same update for ~xyt~ and Azt. ; if (A°°xt~ > n 3m 3) { "decision 
for frO, 9" X n +4-; /k°°xt~ -~ 2n 3m 3; ) else if (A°°zt~ < -n3m 3) { x u --; AOOxt~" +~ 2n am 3; } 
Same decisions for Ayt~ and Azt. ; } Figure 3: FAST_SURFACE-An Efficient Algorithm for 3D Scan-Converting 
Surfaces two parameters, t and u, are varied in the range 0 to 1, a bivariate surface is defined. As 
v varies from 0 to 1 a sequence of bivariate surfaces sweeps the entire volume element. Since the geometric 
matrix for volume representations is a tensor of 3-component vectors, the following summation nota-tion 
is used: 3 3 3 f (t,u,v)= ~ ~ ~ hi(t)hi(u)hj:(v)giik (24) i =0 i =0 k =0 where h i (t), hj (u). and h~ 
(v } are the geometric basis func- tions, and gijk are the components of the geometric tensor. The properties 
of the Bezier curves and surfaces hold also for the Bezier type volumes. More specifically, the forward 
difference method can be generalized to volumes. 11. 3D Scan-Conversion of Volumes The trivariate Bezier 
volume is formally represented by the data type volume: typedef struet volume { int g/3]/4/[4]/4/; " 
x, y, z for 64 control points" color c; "volume color" } volume; The 3X4X4X4 control matrix g is the 
64 Bezier geometric control points of a tricubic Bezier volume element in the parameters t, u, and v, 
each varies from 0 to 1. A volume ele- ment is scan-converted as a sequence of bicubic surfaces, where 
v is constant and t and u vary. Consequently~ the scan-conversion algorithm for tricubic volumes is an 
extension of the associated algorithm for bicubic surfaces. Furthermore, the all-integer version of the 
surface algorithm, FAST SURFACE: can be generalized to volumes. An efficient volume algorithm, FASTVOLUME, 
employing only integer arithmetic is displayed in Figure 4. The complexity of the algorithm is O(n m 
l), which is linear in the number of painted voxels. The numbers n~ m and I are the inverse of the stel5 
sizes in t, u and v, respectively, and their computation is similar to that for surfaces and 6-connected 
curves. In order to avoid internal cavities in the solid volume, the algorithm generates a 6-connected 
volume, i.e., at each step of the algo- rithm only one coordinate may be changed. This coordinate is 
the one with the largest magnitude decision variable. 12. Concluding Remarks We have described 3D scan-conversion 
algorithms for Bezier parametric cubic curves, bicubie surfaces, and trieubie volumes, from their geometric 
R 3 representation to the Z 3 voxel-image space. The conversion was achieved while obey- ing the fidelity, 
connectivity and efficiency requirements. For the curve algorithms 6-, 18- and 26-connected versions 
have been discussed. The surface algorithm guarantees lack of 6-connected tunnels in the converted surface, 
while the volume element generated by the volume algorithm has no internal cavities. All the algorithms 
are incremental and use only sim- ple operations within their inner loops. Furthermore, efficient integer-only 
algorithms for 313 scan-conversion of curves, sur-faces and volumes have been developed. All the algorithms 
do scan-conversion with computational and temporal complexities which are linear in the number of vox- 
els in the object. An object given for scan-conversion is assumed to be completely within the CFB bounds. 
However, if it extends slightly outside the CFB, scissoring can be applied, which can be easily incorporated 
within all the algo- rithms with no added time complexity. All the 3D scan-converslon algorithms were 
implemented as part of the 3D geometry processor of the CUBE architecture. The geometry processor has 
been simulated in software, writ-ten in C under UNIX running on VAX computers and SUN workstations. Special 
purpose hardware (third order DDAs) has also been designed to improve conversion speed. Figure 5, generated 
in less than 30 seconds on a color SUN 3/160(3, shows a straw dipped in a semi-transparent goblet filled 
with semi-transparent wine. The goblet was scan-converted by the geometry processor into a 1283 CFB using 
the efficient surface algorithm. The image was then projected and rendered (with semi-transpareney and 
shading) by the viewing processor of  (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 1'3. References 
1. Bezier, P., "UNISURF System: Principles, Program, Language", in Computer Languages for Numerical Control, 
J. Hatvany, (ed.), North-Holland, Amsterdam- London, 1972, 417-426. 2. Bezier, P., Numerical Control 
Mathematics and Applications, A. R. Forrest (Trans.), Wiley,-London, 1972. 3. Bezier, P., "Mathematical 
and Practical Possibilities of UNISURF", in Computer Aided Geometric Design, R. E. Barnhitl and R. F. 
Riesenfeld, (eds.), Academic, New York, 1974, 127-152. 4. Blinn, J. F., Carpenter, L., Lane, J. and 
Whirred, T., "Scan Line Methods for Displaying Parametrically Defined Surfaces", Communications of the 
ACM, 23, 1 (January 1980), 23-34. 5. Bresenham, J. E., "Algorithm for Computer Control of a Digital 
Plotter", IBM Systems Journal, 4, 1 (1965), 25- 30. 6. Clark, J. H., "Parametric Curves, Surfaces, 
and Volumes in Computer Graphics and Computer-Aided Geometric Design", Technical Report 221, Computer 
Systems Laboratory, Stanford University, Stanford, CA, November 1981. 7. Coons, S. A., "Surfaces for 
Computer-Aided Design of Space Forms", MIT Project MAC Teeh. Rep.-41, June 1967. 8. deBoor, C., "On 
Uniform Approximation with Splines", Journal of Approximation Theory, 1, (1968), 249-274. 9. Foley, 
J. D. and van Dam, A., Fundamentals of Interactive Computer Graphics, Addison-Wesley, Reading, MA, 1982. 
 10. Forrest, A. R., "On Coons and Other Methods for the Representation of Curved Surfaces", Computer 
Graphics and Image Processing, 1, 4 (December 1972), 341-354. 11. Goldwasser, S. M., "A Generalized 
Object Display Processor Architecture", IEEE Computer Graphics and Applications, 4, 10 (October 1984), 
43-55. 12. Jackel, D., "The Graphics PARCUM System: A 3D Memory Based Computer Architecture for Processing 
and Display of Solid Models", Computer Graphics Forum, 1985, 21-32. 13. Kaufman, A. and Bakalash, R., 
"CUBE An Architecture Based on a 3-D Voxel Map", in Theoretical Foundations of Computer Graphics and 
CAD, R. A.  Earnshaw, (ed.), Springer-Verlag, 1987. 14. Kaufman, A. and Bakatash, R., "A 3-D Cellular 
Frame Buffer", Proc. EUROGRAPHICS'85, Nice, France, September 1985, 215-220. 15. Kaufman, A. and Bakalash, 
R., "Memory and Processing Architecture for 3-D Voxel-Based Imagery", Technical Report 87/06, Department 
of Computer Science, SUNY at Stony Brook, February 1987. 16. Kaufman, A., "An Algorithm for 3D Scan-Conversion 
of Polygons", Proc. EUROGRAPHICS'87, Amsterdam, Netherlands, August 1987. 17. Kaufman, A., "Voxel-Based 
Architectures for Three-Dimensional Graphics", Proc. IFIP'S6, Dublin, Ireland, September 1986, 361-366. 
 18. Kaufman, A. and Shimony, E., "3D Scan-Conversion Algorithms for Voxel-Based Graphics", Proc. AGM 
Workshop on Interactive 3D Graphics, Chapel Hill, NC, October 1986. 19. Kim, C. E., "Three-Dimensional 
Digital Planes", IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-$, 5 (September 
1984), 639-645. 20. Lane, J. M. and Riesenfeld, R. F., "A Theoretical Development for the Computer Generation 
and Display of Pieeewise Polynomial Surfaces", IEEE Transactions on Pattern Analysis and Machine Intelligence, 
PAMI-2, 1 (January 1980), 35-46. 21. Ohashi, T., Uchiki, T. and Tokoro, M., "A Three-Dimensional Shaded 
Display Method for Voxel-Based Representation", Proe. EUROGRAPHICS'85, Nice, France, September 1985, 
221-232. 22. Pavlidis, T., Algorithms ]or Graphics and Image Processing, Computer Science Press, Rockvilte, 
MD, 1982. 23. Riesen feld, R. F., "Applications of B-spline Approximation to Geometric Problems of Computer 
Aided Design", University of Utah UTEC-CSc-73-126, March 1973. 24. Rosenfeld, A., "Three-Dimensional 
Digital Topology", Computer Science Center, Univ. of Maryland, Teeh. Rep.-936, 1980. 25. Srihari, S. 
N., "Representation of Three-Dimensional Digital Images", Computing Surveys, 4, 13 (December 1981), 399-424. 
   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37424</article_id>
		<sort_key>181</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[Real-time manipulation of texture-mapped surfaces]]></title>
		<page_from>181</page_from>
		<page_to>188</page_to>
		<doi_number>10.1145/37401.37424</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37424</url>
		<abstract>
			<par><![CDATA[A system for real-time texture mapping was constructed, Here, "real-time" means that the system reacts to changes in parameter values which define the shape of surfaces and the viewing point that are given by its operator 30 times per second. This real-time processing enables interactive manipulation of texture-mapped free-form surfaces and various application software has been developed taking advantage of this ability. The system owes its performance to a new algorithm for texture mapping which is based on a newly proposed approximation scheme of mapping functions. In this scheme, a mapping function from the texture plane into the output screen is approximated by a linear function on each of the small regions which form the texture plane altogether. The algorithm is very simple and applicable to any smooth surface. It is especially efficient when implemented by a special-purpose hardware.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>C.3</cat_node>
				<descriptor>Real-time and embedded systems</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.2</cat_node>
				<descriptor>Linear approximation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.10</cat_node>
				<descriptor>Texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.7</cat_node>
				<descriptor>Texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010240.10010243</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision representations->Appearance and texture representations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003736.10003737</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Functional analysis->Approximation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003636</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Approximation algorithms analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010570</concept_id>
				<concept_desc>CCS->Computer systems organization->Real-time systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010553</concept_id>
				<concept_desc>CCS->Computer systems organization->Embedded and cyber-physical systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP309834400</person_id>
				<author_profile_id><![CDATA[81547424556]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Masaaki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Oka]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sony Corporation, Atsugi-shi, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P164187</person_id>
				<author_profile_id><![CDATA[81332532581]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kyoya]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tsutsui]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sony Corporation, Atsugi-shi, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP309834500</person_id>
				<author_profile_id><![CDATA[81542035256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Akio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ohba]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sony Corporation, Atsugi-shi, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P306754</person_id>
				<author_profile_id><![CDATA[81100024767]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Yoshitaka]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kurauchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sony Corporation, Atsugi-shi, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P277830</person_id>
				<author_profile_id><![CDATA[81100008821]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Takashi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tago]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sony Corporation, Atsugi, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>360353</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Blinn, James F., Newell, Martin E. Texture and Reflection in Computer Generated Images. Communic~itions of the ACM, 19,10 (October 1976), 542-547.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Catmull, Edwin. Computer Display of Curved Surfaces. P~oceedings of IEEE Conference on Computer Graphics, Pattern RecognitiOn, and Data Structures (Los Angeles, California, May 1975), 11-17.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807505</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Catmull, Edwin., Smith, Alvy R. 3-D Transformation of Images in Scanline Order. Proceedings of SIGGRA.PH'80. In Computer Graphics 14,3 (July 1980), 279-285.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808600</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Crow, Franklin C. Summed-Area Tables for Texture Mapping. Proceedings of SIGGRAPI-P84 (Minneapolis, Minnesota, July 23-27). In Computer Graphics 18,3 (July 1984), 207-212]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15919</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Glassner, Andrew. Adaptive Precision in Texture Mapping. Proceedings of SIGGRAPH'86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics 20,4 (August 1986), 297-306.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801126</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Williams, Lance. Pyramidal Parametrics. Proceedings of SIGGRAPH'83 (Detroit, Michigan, July 25-29, 1983). In Computer Graphics 17,3 (luly 1983), 1-11.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 O ,f~ Computer Graphics, Volume 21, Number 4, July 1987 Real-Time Manipulation of Texture-Mapped Surfaces 
Masaaki Oka, Kyoya Tsutsui, Akio Ohba Yoshitaka Kurauchi, Takashl Tago Information Systems Research 
Center Sony Corporation Asahi-cho, Atsugi-shi 243 Japan ABSTRACT A system for real-time texture mapping 
was con- structed. Here, "real-time" means that the system reacts to changes in parameter values which 
define the shape of surfaces and the viewing point that are given by its operator 30 times per second. 
This real-time processing enables interactive manipulation of texture-mapped free-form surfaces and various 
appli- cation software has been developed taking advantage of this ability. The system owes its performance 
to a new algorithm for texture mapping which is based on a newly proposed approximation scheme of mapping 
functions. In this scheme, a mapping function from the texture plane into the output screen is approxi-mated 
by a linear function on each of the small regions which form the texture plane altogether. The algorithm 
is very simple and applicable to any smooth surface. It is especially efficient when implemented by a 
special-purpose hardware.  1. Introduction Texture mapping is one of the most popular techniques in 
computer graphics and several algorithms have been proposed for it. Catmull [2] first introduced texture 
mapping and developed a subdivision algorithm. Blinn and Newell [1] pro- posed an algorithm which calculates 
the inverse image of each pixel on the output screen and assigns the average intensity of the inverse 
image to the pixel. Catmull and Smith[3] proposed a 2- pass algorithm which works in scardine order and 
can be imple- mented by video-rate hardware if the inverse mapping function for the 2nd pass is available. 
Unfortunately, in order to obtain the inverse mapping function, it is necessary to solve various equations 
and this difficulty restricts the kinds of surfaces avail- able in these algorithms. The goal of our 
research is to provide a means for easy manipulation of texture-mapped surfaces and to make texture mapping 
useful in such applications as free-form surface design and facial animation production. This requires 
a fast texture-mapping algorithm applicable to surfaces of arbitrary shapes. In this paper, we introduce 
a new algorithm which suits such pur- poses. It is very simple and efficient and is applicable to a wide 
variety of surfaces. The algorithm approximates a mapping ftme- tion by a linear function on each of 
small regions which form the texture plane altogether (locally linear approximation). Its only constraint 
is that the mapping function be smooth enough. (The meaning of "smooth" is discussed later.) A practical 
method for anti-aiiasing which works well with this algorithm is also pro- posed. A real-time texture-mapping 
system was constructed using the above-mentioned algorithm. The system runs in real time in the sense 
that it not only transforms 30 images per second but also reacts to changes in transformation parameter 
values which are given by its operator at the same rate. The system is flexible in the sense that it 
can deal with free-form surfaces. Due to its real-time processing, the system allows its users to manipulate 
the shape of texture-mapped surfaces in an interactive manner and various application software has been 
developed taking advantage of this ability. In the following section, the texture-mapping algorithm based 
on a locally linear approximation of mapping functions and the method for anti-aliasing are presented. 
In Section 3, how they have been integrated into a flexible system is explained. In Section 4, two applications 
of this system are introduced. In Sec- tion 5, some possible improvements are discussed.  2. Locally 
Linear Approximation Texture mapping transforms a texture plane, {(u,v)}, onto a 3D surface, {(x',y',z')}, 
and then projects it into the output screen, !(x,y)}. Let f be the transformation from {(u,v)) to {(x 
,y ,z )} and p the projection from {(x',y',z')} to {(x,y)}. Then, 8(u,v)=p(f(u,v)) is a mapping function 
from the texture plane into the output screen (see Fig.2.1). f ~ 7 ~ Permission to copy without fee 
all or part of this material is granted provided that the copies are not made or distributed for direct 
commercial advantage, the ACM copyright notice and the ti0e of the ......... ~.7:: publication and its 
date appear, and notice is given that copying is by permission of the Asscciation for Computing Machinery, 
To copy ."" otherwise, or to republish, requires a fee and/or specific permission. texture plane output 
screen &#38;#169; 1987 ACM-0-89791-227-6/87/007/'0181 $00.75 Fig.2.1 Functions in Texture Mapping  ~ 
SIGGRAPH '87, Anaheim, July 27-31, 1987 Note that the inverse of g, namely h, is not defined for all 
(x,y) on the output screen. Moreover, even for (x,y) such that (x,y)=g(u,v) for some (u,v), h(x,y) is 
not uniquely defined. Given (x,y), it is hidden-surface removal that assigns (u,v)-value such that f(u,v) 
has the maximum z-value (the closest to the viewing point) among the candidates. Once h has been explicitly 
given, texture mapping is almost trivial, but it is difficult to com- pute h in general. So here, instead 
of calculating h, we approxi- mate g using a locally linear function, nam~y ~, and calculate the inverse 
of ~, namely/~. Suppose g is in C . (2.1)  i] l'"u v'l = g(,,,v) = tg~(,,,,,)r We first divide the 
(u,v)-plane into a 2D array of small square regions with edges of length d. We refer to each of these 
regions as a "block" in this paper. Let B be one of such blocks and (uo,v0) its center. Taking Taylor's 
expansion of g about (uo,vo) , we have gl(uo+d,va ) = i 1 s (%,%) + a-g =(Uo,~ o) + d'g 1n(Uo,Vo)+ O(ad) 
(2.2) g (%,Vo) 1 gl(uo_d,%) = ~ -d-s .(~o,~o) 1 + d'g ..(ua,vo) + O(da). (2.3) We define 1 1 g (uo+d,vo)-g 
(uo-d,v o) 2d  = g .(Uo,Vo)+ o(a ~1 (2.4) Similarly, 1 1  s (%,vo+a)-g (-o,vo-d) 2d  = g' (%,v0)+O(d 
~) (2.5) 2 2  g (uo+a,vo)-g (uo-d,vo) a2l 2d = g~(%,~o)+O(a ~) (2.6) 2 2 g (uo,vo+d)-g (uo,vo--d) 
a22 2d  = g'd%,~o)+O(Z). (2.7) Then ~, a linear approximation of g on B, is given as follows: ~(u,v) 
= t Z(u,v) J 1  = g (u0,v0)] + (2.8)  [ a 21[:: } Lg2(Uo,Vo) 1 21 a22 ' where ht=U--u 0 , h2=v-v o. 
 By this linear transformation, a block is transformed onto a parallelogram (see Fig.2.2). Note that 
the approximation was applied directly to g, a mapping into the output screen, but not to f, a mapping 
onto the surface. d..-k I.A ~ II II i I 1-'¢ ff"~ f IIII IIII IIit III 1 I [ I texture plane output 
screen Fig.2.2 Locally Linear Approximation Now, let's estimate the error caused by this approximation 
scheme. Since 8 can be expressed by s(u,v) 1 tg~(uo,vo)J g .(-0,%) g ~(Uo,Vo) 0 c3 2 t [(ht--+h2~) 8 
(uo+O~'hv%+e~'h2) ] (2.9) 2 |(hl~+h2~).d(.0÷ e~-h,,~0÷ 0~A)] Ou Ov for some o-<e.,e.-<l, taking (2.3) 
through (2.6) and Ihll,lh21<--d , &#38; z into consideration, we have ~(.,v)-g(u,v) 0 0 2 1 [(hl--+h:--) 
8 (uo+Ol'hl,vo+Ol"h2)" 1 I 0u dv Y'1 I + Lo(d)J21 a o22 t(hl--+h2--) 8 (%+e2"hl,vo+Oz'h2) au av (2.10) 
 to(d)J That is, if we measure the approximation error in terms of length, it is proportional to the 
square of the length of the edge of a block. This rapid convergence of the error is well illustrated 
in Fig.2.3, where the finely divided quadrilaterals look almost like parallelograms. ~ Computer Graphics, 
Volume 21, Number 4, July 1987 Fig.2.3 Effect of Fine Division Given a mapping function, although we 
can reduce the approxi- mation error by increasing the fineness of division, there will always remain 
some error. This may cause a crack between two adjacent parallelograms, resulting in a serious degradation 
of the image quality. Fortunately, these cracks can be avoided by set- ling some common area between 
two adjacent blocks (see Fig.2.4).  i(iJ-1):: ...i ........... i...  Fig.2.4 Transformation of Blocks 
with Common Area Some pixels on the output screen will be accessed more than once, but if the blocks 
are sufficiently small, the approximation becomes sufficiently accurate and we do not care which access 
resulted in the final image. As is shown in (2.10), the approxi- mation error is dominated by the second 
partial derivatives of g. Unfortunately, the values of these derivatives depend on many factors, such 
as the curvature of the surface and the location of the viewing point, so it is impossible to determine 
the appropri- ate block size in terms of surface parameters. It has been shown by experiment that division 
of a 512x 512-pixel texture plane into 8xS-pixel blocks with 0.5-pixel-wide common areas works in most 
practical applications. AS a general aid to understanding, in this paper we refer to mapping functions 
with reasonably small second partial derivatives as "smooth" mapping functions and surfaces which lead 
to smooth mapping functions as "smooth sur- faces". The employment of the locally linear approximation 
described above makes the algorithm for texture mapping vet 3, simple First of all, the inverse of a 
linear function ~, namely h, is also a linear function and is obtained by simply calculating the inverse 
matrix of A, namely B(bq), as follows: 1 D ~-all.a22 -a12"a21 r :--- D btl = r.a22 b12 =-r.a12 (2.11) 
b2t = -r.azt b22 = r.axl. This requires only 1 division, 6 multiplications, 1 subtraction and 1 change 
of sign. Moreover, since h is also a linear function, its own calculations are quite simple. Let po=(xo,yo) 
be the center of an output pixel within the parallelogram and q0 the image of P0 by h Let p n be the 
output pixel which lies m-pixels to the " ni . ^ right of and n-plxels above P0, and q~, the tmage of 
P,, by h. Then, m-btt + n'btx ] (2.12) q=. = qo + tm.b2z + n.b22J" (2.12) can be used to calculate/~ 
in an incremental manner. To calculate/~(P2,2,), for example, we repeat (2.12) twice. Alterna-tively, 
(2.12~ can be used to calculate /~ for various m and n directly. A combination of these two methods leads 
to the effi- cient algorithm shown in Fig.2.5. segment --I ! r jr pixel  I/ f ,r, 1 Fig .2.5 Calculation 
of Inverse Linear Transformation  The output screen is divided into rectangular segments. /~ is cal- 
culated by the former method for one pixel in each of the seg- ments which intersect the parallelogram. 
To the rest of the pix- els in each segment, the latter method is applied. Notice that the calculations 
within a segment can be processed in parallel. Also notice that the second term of the right hand side 
of (2.12) is a constant for fixed values of m and n. By synthesizing all the transformed blocks based 
on their z-coordinate, transformation of the whole texture image is completed. As is well known, assigning 
to a given pixel on the output screen the intensity value of the texture point which corresponds to the 
center of the pixel causes serious aliasing problems. A popular method which produces results which are 
visually accept- able is to assign to the pixel the average intensity value over the texture area that 
corresponds to the output pixel square (see, for example, [5]). Another method, which was employed by 
Willi- ams [6] and Crow [4] , is to assign to the pixet the average value of the texture in the minimal 
rectangle (or square) which covers the area that corresponds to the output pixel. Although this may cause 
an over-blurred image due to the extraneous areas con-sidered for the average, it simplifies the calculation 
greatly. Since an output pixel corresponds to a l~arallelogram defined by the two vectors, (b ,b ,) and 
(b,,,b,,) in our algorithm, the . . . I 2 .... rmmmal rectangle is ~ounded by e~ges of length lb.. 1+ 
Ib..] and Ib-.l+ Ib--I (see Fig.2.6 ). Assuming that the center b'f the~aral -leI~grard'coincides with 
the center of a pixel, pre-filtering of the texture image, whose coefficient values vary from one block 
to another, is possible. Pixels lying near boundary or silhouette edges of the transformed image may 
partially cover the back- ground and the texture pattern in a remote location. Anti-aliasing along these 
edges is computationally much more expen-sive and is not considered in this paper. Ib=ll+ Ib=21 Iblll+lb~21 
Fig.2.6 Texture Area Corresponding to One Output Pixel  SIGGRAPH '87, Anaheim, July 27-31, 1987 I~~1 
There are several ways to define the shape of a surface, for example by equations and by interpolation 
of two given surfaces. 3. Real-Time Texture-Mapping System The methods described in the previous section 
were In any case, the system has to cope with changes in the shape of integrated to construct a texture-mapping 
system. In order to surfaces. Among the processing steps in Fig.3.1, (1) and (2) allow easy manipulation 
of free-form surfaces, the system was require this flexibility and hence, should be controlled by designed 
so that: software. For (2), our algorithm calculates the transformation of the central point of each 
block. Although the number of blocks [1] Transformation into any smooth surface is possible. is much 
smaller than that of pixels, it is still several thousands, so the processing for (2) has to be much 
faster than that for (1), [2] Transformation of texture image is done in real time. which only has to 
be done once for a frame. In the constructed [3] Response to changes in transformation data is made in 
real system, (1) is implemented by a versatile micro-processor and (2) time. is implemented by parallel 
micro-coded processors. On the other hand, the processings for (3) and (4) are only linear transforma- 
 Although our algorithm runs fast, it is impossible for any tions which are substantially the same for 
any curved surface. current single processor to satisfy, these requirements. For-These calculations are 
simple but as they must be done for each tunately, processing of texture mapping can be done as shown 
in pixel, the system implements them by hardware. Fig.3.1: L Figure 3.2 shows the actual composition 
of the system. It has two major data channels, one for transformation data, the other for image data. 
Host Computer (HC) conducts user inter- face. It accepts transformation data from input devices and transfers 
programs and data to Micro-Coded Processors (MP) every frame according to the kind of curved surface. 
MP first calculates the 3D location of the central point of each block, applies 3D affine transformations 
to it and projects it onto the screen. Then it generates locally linear approximation data based (1) 
User Interface (2) Calculation of  on (2.4) through (2.7) and (2.11) in the previous section. It also 
Mapping Function controls hidden-surface removal by sorting the blocks according to the z-coordinate 
of their central points. This sorting is done by a bucket-sort and a linear list of these blocks is constructed. 
The data calculated by NIP are stored in Block Data Memory 1 (3) Address Matching (BDM) and transferred 
to Address Controller (AC) by double- of Image Memories buffering. AC calculates the inverse linear transformation 
using the algorithm described in the previous section and gives the read address to Input Image Memory 
(IIM) and write address to Out- put Image Memory (OIM). AC processes the blocks in the order of the linear 
list, from the furthest to the nearest. Thus the (4) Calculation of hidden-surface removal is automatically 
carried out. Pixel Pro- Intensity of Each Pixel cessor (PP) interpolates the texture data of the nearest 
4 pixels in IIM and writes it to OIM. Texture image is filtered for anti-aliasing before it is stored 
in IIM. Double buffering is also Fig.3. i applied to IIM and OIM and one frame of transformed image is 
Processing of Texture Mapping output every 33msee. 4. Applications A notable characteristics of this 
proo~ss is that calculations done Various application software which makes use of the real- at an early 
step are unaffected by subsequent calculations. Mak-time processing of this system has been developed. 
In this sec-ing use of this characteristics, we constructed a hierarchical sys- tion, two of them are 
introduced. tem which consists of software-driven processors and special hardware and implements pipeline 
processing. Mouse, Track-Ball Host Lever, Keyboard Computer Micro-Coded Processors b, Block Data Memory 
¢ read address Address Controller [ write address of Image Memories] 1 ¢ Pre-Filter I I _1 rl Input.Image 
Memory _l -1 Pixel r o ssors I I -I -I Output-Image Memory ¢ texture image output image Fig.3.2 System 
Composition  ~ Computer Graphics, Volume 21, Number 4, July 1987 4,1. Free-Farm Surface Design This 
application is to design and manipulate free form sur- faces such as human faces in an interactive way 
by locally deforming a displayed curved surface by trial and error and step by step. A non-deformed plane 
is taken as the initial shape of the surface and deformations are repeatedly added to it. Let p be a 
point on the texture plane. At the i-th deformation, p is transformed to a point in a 3D space, namely 
Pr Pt is calculated as PJ = Pi-t + Vt'F(p,cj,ai), (4.1) where V~ is a deformation 3D vector at the i-th 
step and F is a scalar valued function which regulates the deformation area F is controlled by two kinds 
of parameters, c. and a v c~ is the central point of the deformation and a~ is a 2/) vector which gives 
its extent To restrict the deformation within the neighborhood of c., F should have an essentially finite 
support. For example, the I . . . . . . . following Gausstan Dtstrthutmn Functton, whose value ~s nearly 
0 outside a certain limit, can be used as F: e(p,c,,a,) = Piu --exp(-((--) Cl= 2 + ( P~v --ely 2 ) )) 
(4.2) Ct iu air Each point on the surface is moved by the action of V .F(p,c ,a ), t . l l and the surface 
ts locally deformed near c.. Deformalaons are repeatedly added to the surface untal a sansfactory shape 
is obtained. Figure 4.1 shows the surface obtained by adding a deforma- tion to the initial plane. The 
"+" cursor indicates the central point of deformation and the oval shows its extent. Figure 4.2 is a 
schematic block diagram of the apparatus of this free-form sur- face design system. The trackball is 
used to control the viewing point and the lever and the mouse are used to control the above V,, c. and 
a,. Figure 4.3 is a flowchart of this free-form surface d[sig'n. In t~ae Loop-l, a deformation which 
corresponds to (4,1) is implemented. Thanks to the real-time processing, the user can control the deformation 
interactively and check it from various viewing points quite easily. In the Loop-2, deformations are 
repeatedly added and the surface data are renewed At the same time, deformation parameters such as V, 
c and a are added to a I. I. i data list. Since the shape of a surface is independent from the order 
of the deformations and each deformation is reversible, it is easy to edit this list to modify the shape 
of the surface. Figure 4.4 is a relief generated from a picture of a face using the above- mentioned 
method. Fifty deformations were added to generate this surface. Figure 4.5 shows other examples which 
were gen-erated from the same picture as Fig.4.4, where S. was created first and then some modifications 
were added to it t°o generate S t through S 9. 4.2. Multiple 3D Inbetweenlng and Real-Time Animation 
3D inbetweening, a popular technique in 3D computer arti- marion, interpolates two surfaces to define 
new surfaces. It is not necessary to restrict the number of surfaces to be interpolated to two if some 
means of controlling the interpolation is provided. Increasing the number of the surfaces gives more 
potential variety to the shape of the interpolated surface. So, we extend 3D inbetweening to a multiple 
3D inbetweening and apply it to a real-time animation. In a multiple 3D inbetweening, a weighted sum 
of several surfaces is calculated as T = "~,IFS~, (4.3) l-O (Cursor) f t Real-Time Texture-Mapping System 
(Mouse) (Tr ackball) ~ [~](Lev e ~ s)~-~ Fig.4.2 Apparatus for Free Form Surface Design I Set Plane as 
Initial Shape of Surface Loop 2 ;1 Loop 1 Vt ~c i ~ at i i I Cheek the Deformation 1 from Various Viewing 
Points l l Add V~,c,a t to Data ~ist Ii I [ ,=,÷1 I  where S:'s are the given surfaces, l.'s the coefficients 
and T the interpolated surface. The sum of thh coefficient values, l.'s, is 1, but each of them is not 
necessarily restricted to between 6 and 1, Fig.4.3Coefficient values which do not lie between 0 and 1 
extrapolate Flowchart of Free Form Surfaee Design the given surfaces instead of interpolating them. 
 SIGGRAPH '87, Anaheim, July 27-31, 1987 I~~1 It is easy to generate smooth movement of a free-form sur- 
face using a multiple 3D.inbetweening. A key-frame animation is produced with this system in the following 
manner. First, the animator selects several surfaces and stores them in the internal memories of NIPs. 
Then, key frames are designated and the coefficients of the multiple 3D inbetweening are given at each 
of the key frames in an interactive way. Finally, the system inter- polates the parameters along the 
time axis and an animated tex- ture mapping is realized. Animation of facial expressions proved to be 
an interesting application of this method and will be quite useful when com- bined with speech recognition 
and synthesis. It is possible to synthesize a variety of facial expressions with fewer surfaces if they 
have been chosen in an efficient way. Fox this purpose, deformations of different parts of a face should 
be put into separate surfaces. Reduction of the number of surfaces helps the control of animation as 
well as saving storage space. The facial expressions in Fig.4.6 were synthesized from the surfaces in 
Fig.4.5 using the coefficient values shown in the table. Notice that T^ in Fig.4.6 was generated by extrapolating 
the original facial r~clief, So, and the one with a closed mouth, S s. 5. Some Possible Improvements 
 Although in the interest of simplicity we did not integrate them into our first system, improvements 
on hidden-surface removal and shading are possible at a rather small expense. As stated in S¢.ction 
3, hidden-surface removal was realized by sort- ing the blocks according to the z-coordinate of their 
central points and processing them from the furthest to the nearest. So, if two blocks intersect with 
each other or two non-adjacent blocks arc positioned too close, this hidden-surface removal does not 
work correctly. This is avoided by calculating the z-coordlnate of each pixel and implementing a z-buffer 
algorithm. Locally linear approximation in z-direction will be useful for calculating the z- coordinate 
of each pixel. Gouraud and Phone-type shadings are also possible by linearly approximating the intensity 
or the nor- real direction in each block. 6. Conclusions A real-time texture mapping system was constructed. 
The system works in real time in the sense that it reacts to changes in parameter values of the surfaces 
and the viewing point which axe interactively given by its operator 30 times per second. The sys- tem 
makes use of a newly proposed algorithm based on a locally linear approximation of mapping functions. 
The algorithm is simple, runs fast and can be applied to any smooth surface. A practical anti-aliasing 
method was also proposed and integrated into the system. Real-time texture mapping proved to be very 
useful for human-machine interface and several applications were introduced.  Acknowledgements The 
authors would like to express their appreciation to Mr. Y. Kodera, Mr. H. Yoshida and Mr. M. Morizono 
of Sony Cor- poration, for giving them the opportunity to study this subject and the permission to publish 
this paper. They also wish to thank Mr. H. Kanemaki, Mr. N. Asarnizuya and many other col- leagues in 
Sony Corporation who have contributed to the work described in this paper.  References 1. Blinn, James 
F., Newell, Martin E. Texture and Reflection in Computer Generated Images. Communic~itions of the ACM, 
19,10 (October 1976), 542-547. 2. Catmull, Edwin. Computer Display of Curved Surfaces. P~oceedings of 
IEEE Conference on Computer Graphics, Pattern RecognitiOn, and Data Structures (Los Angeles, California, 
May 1975), 11-17. 3. Catmull, Edwin., Smith, Alvy R. 3-D Transformation of Images in Scanline Order. 
Proceedings of SIGGRA.PH'80. In Computer Graphics 14,3 (July 1980), 279-285. 4. Crow, Franklin C. Summed-Area 
Tables for Texture Map- ping. Proceedings of SIGGRAPI-P84 (Minneapolis, Min- nesota, July 23-27). In 
Computer Graphics 18,3 (July 1984), 207-212 5. Glassner, Andrew. Adaptive Precision in Texture Map- 
ping. Proceedings of SIGGRAPH'86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics 20,4 (August 
1986), 297-306. 6. Williams, Lance. Pyramidal Parametrics. Proceedings of SIGGRAPH'83 (Detroit, Michigan, 
July 25-29, 1983). In Computer Graphics 17,3 (luly 1983), 1-11.      
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37425</article_id>
		<sort_key>189</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[Shading bicubic patches]]></title>
		<page_from>189</page_from>
		<page_to>196</page_to>
		<doi_number>10.1145/37401.37425</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37425</url>
		<abstract>
			<par><![CDATA[We present several techniques for implementing Phong shading in hardware for bicubic patches. Patches are shaded, not by subdividing into polygons, but by drawing many curves close together leaving no pixel gaps. Each curve is drawn using an adaptive forward difference algorithm which generates the coordinates as well as the shading parameters as cubic functions incrementally evaluated along the curve. The forward difference step size is adaptively adjusted so that it generates approximately one pixel along the curve per forward difference step. The hardware implements Phong shading directly with a surprisingly simple configuration built from general purpose compute units and look-up tables. Two new methods are presented for deriving bicubic approximations to the shading parameters over a bicubic patch. One method uses two Coons patches to approximate the unnormalized <i>N&amp;middot;L</i>, and <i>N&amp;middot;H</i>, and a third Coons patch for <i>N&amp;middot;N</i>, where <i>N</i> is the surface normal, <i>L</i> is the light direction, and <i>H</i> is the direction of maximum highlight. In this case the hardware performs the normalization per pixel. The second method uses two Coons patches to approximate the normalized dot products <i>N&amp;middot;L</i>, and <i>N&amp;middot;H.</i> The method is suitable for both hardware and software implementations.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>B.7.1</cat_node>
				<descriptor>VLSI (very large scale integration)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010633</concept_id>
				<concept_desc>CCS->Hardware->Very large scale integration design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31093889</person_id>
				<author_profile_id><![CDATA[81332526795]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shantz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sun Microsystems, Inc., Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P263510</person_id>
				<author_profile_id><![CDATA[81332512187]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sheue-Ling]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lien]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sun Microsystems, Inc., Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>15897</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Gary Bishop and David M. Weimer, "Fast Phong Shading," Computer Graphics, vol. 20, no. 4, pp. 103 - 106, August 1986.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Edwin Catmull, A Subdivision Algorithm f o r Computer Display o f Curved Surfaces, Computer Science, University of Utah, UTEC-CSc-74-133, December 1974.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>889976</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Steven A. Coons, Surfaces f o r Computer-Aided Design o f Space Forms, Project MAC, Massachusetts Institute of Technology, MAC-TR-41, June 1967.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807455</ref_obj_id>
				<ref_obj_pid>965103</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Tom Duff, "Smoothly Shaded Renderings of Polyhedral Objects on Raster Displays," Computer Graphics, vol. 13, no. 2, August 1979.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358815</ref_obj_id>
				<ref_obj_pid>358808</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Jeffrey Lane, Loren Carpenter, Turner Whitted, and James Blinn, "Scan Line Methods for Displaying Parametrically Defined Surfaces," CACM, vol. 23, no. 1, January 1980.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37416</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Sheue-Ling Lien, Michael Shantz, and Vaughan Pratt, "Adaptive Forward Differencing for Rendering Curves and Surfaces," Computer Graphics, vol. 21, no. 4, July 1987.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Bui Tuong Phong, Illumination f o r Computer- Generated Images, UTEC-CSc-73-129, July 1973.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~ '~' Computer Graphics, Volume 21, Number 4, July 1987 Shading Bicubic Patches Michael Shantz and 
Sheue-Ling Lien Sun Microsystems, Inc. 2500 Garcia Avenue Mountain View, CA 94043 Abstract We present 
several techniques for implementing Phong shading in hardware for bicubic patches. Patches are shaded, 
not by subdividing into polygons, but by drawing many curves close together leaving no pixel gaps. Each 
curve is drawn using an adaptive forward difference algorithm which generates the coordinates as well 
as the shading parameters as cubic functions incrementally evaluated along the curve. The forward difference 
step size is adaptively adjusted so that it generates approximately one pixel along the curve per forward 
difference step. The hardware implements Phong shading directly with a surprisingly simple configuration 
built from general purpose compute units and look-up tables. Two new methods are presented for deriving 
bicubic approx- imations to the shading parameters over a bicubic patch. One method uses two Coons patches 
to approximate the un- normalized N.L, and N'H, and a third Coons patch for N.N, where N is the surface 
normal, L is the light direction, and H is the direction of maximum highlight. In this case the hardware 
performs the normalization per pixel. The second method uses two Coons patches to approximate the normal- 
ized dot products N.L, and N'H. The method is suitable for both hardware and software implementations. 
CR Categories and Subject Descriptors: 1.3.3 [Computer Graphics]: Picture/Image Generation -Display algorithms; 
1.3.7 [Computer Graphics]: Three-dimensional Graphics and Realism - Color, shading, shadowing, and texture. 
Additional Key Words and Phrases: image synthesis, shad- ing, adaptive forward differencing, graphics 
VLSI, parametric surfaces. Permission to copy without fee all or part of this material is granted provided 
that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice 
and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. &#38;#169; 1987 ACM-0-89791-227-6/87/007/0189 $00.75 Introduction Phong[7] shading 
is a well known technique for generating- smoothly shaded images of surfaces approximated by patches 
or polygons. This shading technique is attractive because it gives a fairly realistic rendering with 
a modest computational cost. Most 3D MCAD applications give highest priority to interactive performance 
and are satisfied with the realism afforded by Phong shading. Indeed, linear interpolation of color over 
the individual polygons is often acceptable for interactive design. Polygonal approximations for curved 
surfaces are used for performance reasons, since most high speed graphics hardware is built for fast 
rendering of polygons. A typical bicubic patch may require 25 or more polygons to give a usably accurate 
approximation. Many design applications would be facilitated if smooth, high speed, curved surface rendering 
were available. Existing scanline algorithms for rendering curved surfaces[5] are too complex for hardware 
implementation. In this paper we describe a method for smoothly shading bicubic patches which is suitable 
for hardware implementa- tion. Hardware adaptive forward difference units are used to evaluate bicubic 
functions which approximate the shading parameters over a patch. Patches are rendered by drawing many 
cubic curves spaced closely together. Each curve is shaded with the cubic approximations to the shading 
param- eters. The result is high speed rendering of bicubic patches. The hardware referred to in this 
paper has not been built. All images were generated by software simulations of the algo- rithms. 1" 
 Background We use the following Phong approximation to compute the color at a point on a surface illuminated 
by a single light source at infinity. color = (A + D (N'L ))objectcolor +S (N.H)~ lightcolor Where A, 
D and S are the ambient light intensity, the diffuse coefficient, and the specular coefficient, respectively, 
m is t Sun Microsystems, Inc. is pursuing patent protection in the United States and abroad on the technology 
described in this paper. ~ SIGGRAPH '87, Anaheim July 27-31, 1987  p X AFDU }"----'~ Pixel address 
AFDU control Image Memory ~t ~t Pixel color AU 1 AU2 I Q ul -I I R AFFDU Figure 1. Simplified block 
diagram of the shading hardware. The AFDUs (Adaptive Forward Difference Units) are cubic function generators 
and the AUs (Arithmetic Unit) perform ~A +(1-~)B, ff.A +B, or A*B. the specular power, L is a unit vector 
toward the light source, and H is a unit vector in the direction of maximum highlight (ie. the vector 
in the direction halfway between the viewer and the light source). The surface normal unit vector N varies 
across the surface. Dufff4] derived a difference equation for efficiently interpo- lating N.L or N'H 
between two points A and B on a polygon with normalization at each intermediate point. This expres- sion 
requires 3 additions, a divide, and a square root per pixel. ~(Nb'L )+(I-a)(Na'L ) N.L = "ql-2a(1-ct)(1-Na 
"Nb) Bishop and Weimer[1] further reduced the computation per pixel by approximating DufFs expression 
with a quadratic. The difference equation for this quadratic requires only 2 additions per pixel but 
the setup per polygon to obtain the quadratic expression is significant. They quoted the over- head as 
equivalent to computing Duff's expression directly for 10 pixels, including the square root. If the pixel 
loop additions were performed in fast hardware, the setup over- head would likely be the performance 
bottleneck. The qua- dratic approximation produces visible artifacts if the angle between N, and Nb is 
greater than 60 degrees. The robust- ness of this method would be improved if cubic interpolation were 
used for N.N and the normalization was done per pixel in hardware. Bishop and Weimer correctly point 
out that Phong's propo- sal for hardware implementation is somewhat complicated since he suggests a circuit 
for actually computing the square root. However, current hardware technology provides some very simple 
ways to compute Duff's expression directly and at the same time reduce the polygon overhead. Our approach 
for high performance bicubic patches computes cubic approximations and normalization directly in hardware. 
The new method we propose has the following advantages. 1) Fast rendering of bicubic patches using adaptive 
for- ward differencing 2) Simple hardware implementation with pixel rates at frame buffer memory speeds. 
The circuit uses general purpose units which may be implemented in VLSI and used for other geometry and 
shading tasks. 3) Allows for up to cubic approximation of N-L and N'N. The Shading Hardware Patches 
are shaded by drawing many curves spaced closely together so that no pixel gaps remain between the adjacent 
curves. Each curve is a univariate cubic obtained by setting one of the bicubic parameters to a constant. 
The hardware uses adaptive forward difference units to compute the cubic equations for x,y,z,w and for 
the shading parameters such as N'L along the curve. Polygons are shaded by drawing hor- izontal line 
segments with the shading parameters along the segment computed by adaptive forward difference units. 
The details of the adaptive forward differencing technique are presented in another paper.[6] This paper 
will concen- trate on the shading computations along the cubic curves across a bicubic patch. Figure 
1 shows the cubic adaptive forward difference units which together with the arithmetic units compute 
the Phong shading along a scanline or along a cubic curve. Polygon shading doesn't require cubics but 
they are used as basic building blocks for many graphics hardware tasks, and are used to shade bicubic 
patches. The arithmetic unit consists of three subunits, one for red, green, and blue. Each computes 
one of the following expressions on the A, B, and a components of their input. The output may be clamped 
to a maximum value. out = CtA+(1-a)B out = ot.A +B (~) ~ Computer Graphics, Volume 21, Number 4, July 
1987 alpha Br AU red ~ R Bg AU green ~ G Bb ~, AU blue ~ B Figure 2. Detailed block diagram of an arithmetic 
unit. out = A*B Here, A and B are RGB colors or other shading parameters, and ct is a shading parameter 
or coefficient used for blending A and B. The inputs A, B, and ct may be selected from vari- ous sources 
depending on the function being performed. These functions include shading, depth cueing, image map- 
ping, and antialiasing. The AFD units are third order digital differential analyzers which implement 
an adaptive forward difference solution to a parametric cubic function of v. The parameter v varies from 
0 to 1 along the curve. The dv step size for v is adap- tively adjusted so that the curve steps along 
in approximately one pixel steps. The same dv is used for the AFDUs involved in the shading calculations 
so that the shading is mapped correctly along the curve. We use the forward difference basis functions: 
B3 - v(v-l)(v-2) 6 v(v-1) B2= 2 Bl=v B0=l A parametric cubic function f(v) is represented in this basis 
as f = aB 3(v )+bB 2(v )+cB l(v )+dB o(v) A cubic curve is defined by four cubic functions x(v), y(v), 
z(v), and w(v), each implemented by a separate AFD unit. x (v) = a~B 3+bxB 2+cz B l+d~B o y (v ) = ayB 
3+byB T~+cyB l+d.yB o z (v) = a, B3+bzB2+czB l+d, B0 w (v) = awB3+bwB 2+cwB l+d~B o The coefficients 
a, b, c, and d are loaded into the 4 coefficient registers of each AFD unit. At each clock event the 
parameter v increases by dv and the four AFD units gen- erate the coordinates of one pixel. The P, Q, 
and R AFDUs are used as function generators in Phong shading. The R AFDU computes N.N along a scanline 
or a curve. The Q and P AFDUs compute cubic approximations (linear for polygon scanlines) for the dot 
products between light and normal N'L, and between highlight and normal N.H. The AU 1 A input is <N .L 
,N .H ,0>. A look-up table is used to obtain the reciprocal square root of N.N. AU1 multiplies 1 N'L 
and N'H by ~ and adds the ambient light constant, CO, to the N.L term. The output from AU1 is AUI(R)] 
r d/if] [a nt] 1 rN.L] AUI'G'I= = ~ie + --~- LN0~ The specular coefficient from AUI(G) is raised to 
a power by the x" look-up table. This look-up table generates 24bit specular color values from one of 
4 look-up tables, one table for white light, and three others for other light source colors. This allows 
a limited selection of light source colors. The AU2 operation aA+B multiplies the diffuse coefficient 
~ times the object color A, and adds this to the specular coefficient B times the light color. The object 
color can either be the constant Color C2, or a mapped sample from image memory. The resulting pixel 
color is pixel_color = [ ambient +~.LN l object_color +f N HI" N~'N J light_color The design allows 
high speed diffuse and specular shading and image mapping on curved surfaces, at frame buffer memory 
speeds. Shading Bicubic Patches We develop two methods for fast shading of ordinary bicu- bic patches. 
The first is to approximate the un-normalized N'L, the un-normalized N.H, and N.N over a bicubic patch 
using three bicubic functions F(u,v). The second method is to approximate the normalized functions N-L 
and N.H over a bicubic patch using two bicubic functions. The shading hardware described above then generates 
the Phong shading values of each pixel along the curve F(u=u,v). A 8u is adap- tively calculated so that 
adjacent curves have no unshaded pixel gaps between them [6]. Coons patches are used because they give 
tangent continuity across patch boun- daries. 1. Un.normalized Coons Patch The components of the normal 
vector to a bicubic Patch are fifth order polynomials in u and v. Catmull[2] gives a method for approximating 
these biquintic functions with bicubic functions, using Coons[3] matrix C C = -3 3 -2 0 0 1 1 0 0 For 
a bicubic patch defined as x(u,v)=U x v r y(u,v)=U Y V r z(u,v)=U Z V r [~ SIGGRAPH '87, Anaheim, July 
27-31, 1987 the normal vector is 0x ~ 0z 0x 0z N = <~u' Ou ' ~u > x<~v'=~v ' ~> = ~/1 x )?/y )n z where 
n~ (u ,v ) = y. z,-y. z. ny (u ,v ) =z,,x.-z~x. n, (u ,v ) = x.y.-xv y. Each component of the normal 
vector <nx,ny,nz> can be approximated by a Coon's patch nAu,v)= UCPxCTV r, where matrix 0/I x 0n x " 
n. (0,0) n~ (0,l) -~-(0,0) -~-(0,1) On~ On~ n~, (l,O) nj, (I,1) ---~-v (1,0) ---~-v(1,1) Px = On x On 
x 02nz 02nx -~-(0,0) -~-(0,1) O~v(0,0) ~-~(0,1) Onx Onx c)2nx oznz -~-(l,O) -~-(I,l) O~v(l,O) O---~-v(1,l) 
 and similarly for % and n,. (The derivation of the derivatives of the vector functions is in Appendix 
A.) These functions approximate unnormalized normal vector functions, there- fore, at each pixel the 
shading function is calculated with an inner product, a "one over square root" look up, and a multi- 
ply: n~L~ + nyLy +n,L, N'L- where L=<Lx,LyL,> is the light source direction. Figure 4 shows the Utah 
teapot rendered with a software simulation of this shading method and using the adaptive forward difference 
technique [6]. 2. N.N Coons Patch Our first approach is to apply Catmull's technique to the un- normalized 
normal function N.L as in Catmull's thesis, and to use another Coons patch to approximate N.N. The Coons 
patches are converted to the forward difference basis [6] for hardware evaluation. Three AFD units are 
used to calculate these cubic functions N.L, N'H, and N.N. This approach eliminates the calculation of 
N.N per pixel, but still needs the "one over square root" look up and a multiply. The un-normalized N'L 
is interpolated by a matrix M=PxLx +PyL, +P,L, and the bicubic patch is N.L (u,v) = UCi~CrV r. The inner 
product N.N = nx 2 + ny 2 + nz 2. We approximate this function by a bicubic function f (u,v) N.N = f 
(u,v)= UCFCrV r where C is the Coons matrix and F is the Coons data matrix. We derive F below. The lighting 
function N.L is given by N.L(u,v) (~](N.L(u,v)) N.L= ~ = It remains to obtain the elements of the matrix 
F for the N-N Coons patch. We:e'ed f(?) f(O,1) -~-(0,0) -~-(0,1) f (l,0) f (l,1) ~v (l,0) -~-(l,l) F= 
-~-(0,0) ~u (0,l) ~v (0,0) ~u~v (0,l ~u(l,O) ~u(l,l) OOu~v(l,O) o~ofv(l,l} These elements are given 
by 0: f ~n z 0n On,1 7v vc+-j 02f Ou Ov =2L~--~-+-~--~-+ o. Ovj i" 02,~ 02ny 02nl 1 and for example 
f (0,0) = n~ 2(O,O)+ny 2(O,O)+nz 2(0,0) We now have a bicubic function for the un-normalized N.L and 
for N-N. Figure 5 shows the teapot rendered using this N.N approximation with the reciprocal square root 
lookup table and normalization performed at each pixel. This approximation for N.H starts to exhibit 
some visual artifacts in the specular regions on less smooth patches. The Coons patch can overshoot in 
the center of the patch to produce N.H values greater than 1. When these values are raised to a high 
power, some specular "blooming" occurs, as can be seen under the knob on the teapot lid. 3. Normalized 
Coons Patch An alternative method is to apply Catmull's technique to the normalized functions. The normal 
vector for a patch is given by the cross product of the patch tangent vectors N = <n~ ,ny ,n, > Normalizing 
the normal vector functions gives n z &#38;(u,v) = -- G . % n, (u,v) = -~- n z a, (u,v ) = -U-  where 
G is the length of the normal vector a(u,,)=4n)+n]+n? (~) ~  We then use a Coons patch to approximate 
the normalized normal vector function by ~(u,v ) = UCI~Cr V r fly (u,v) = UCI~ CT V r ~, (u,v ) = UCfi, 
cr v r where ~ = Ce~,:y,/~, > is the Coons patch data matrix. The x component f~ is dx (0,0) d~ (O,l) 
--~.~-(0,0) --~-(O,l) rf~ (l,O) dz(l,l) -~--(1,0) --~-(1,1) ~= -.~-(0,0) --~-(O,l) -~-~(0,0) -~-(0,1) 
-~-(1,0) ~u (1,1) ~(I,O) ~(1,1) At first glance this matrix is somewhat terrifying, however, the calculations 
involve many common subexpressions so that the computational cost is reasonable. Appendix A shows how 
to calculate the elements of the/~x,/~y, and fi, matrices. We now have a Coons patch which approximates 
the normalized normal vectors over the patch. Clearly, if the light source is transformed into world 
coordinates and the Coons patch is derived in world coordinates, the resulting bicubic function for N.L 
can be used for ordinary bicubic patches which undergo perspective transformations. It remains only to 
transform the Coons patch into the forward difference basis so that the parameters of the cubic N.L curves 
at u =u~ can be loaded directly into the hardware. Fig- ure 6 shows the teapot rendered as bicubic patches 
using adaptive forward differencing and shaded with the above approximations to the normalized N.L and 
NH. With this approximation method, only two Coons patches are required and no normalization per pixel 
is required. 4. Surface Rendering Shading and image mapping onto rational bicubie or rational biquadratic 
patches is performed by drawing many cubic or rational cubic curves very close to each other. Each curve 
is a cubic in v formed by setting u=u~. We therefore need to find the maximum 8u between curves such 
that no gaps exist between the pixels of the curve g(u~v) and the curve g ( ul +Su ,v). TO obtain this 
8u we use the adaptive forward difference hardware. The first partial derivative of a rational bicubic 
at u = u~ is a 6th order rational equation. We cannot solve this directly, however, we can use the AFD 
units to find the max- imum 6u for which no gaps will exist between the curves. We first draw a series 
of test curves at constant v and moni- tor the adjustments that are made to 8u along these curves. The 
AFDUs automatically adjust 8u along the curve so as to generate one pixel steps. We need to find the 
smallest 8u used by the hardware anywhere along these test curves. A register is maintained in the hardware 
which accumulates the maximum net up-down adjustments made by the AFDUs. Computer Graphics, Volume 21, 
Number 4, July 1987 The estimated minimum value for 8u over the entire patch is obtained by looking at 
the number of adjusts done on these test curves by the hardware. The patch is then rendered by drawing 
the curves corresponding to u = nSu, for 0_< n < _L For each curve we load the hardware with six sets 
of cubic coefficients, four for the geometry, one for the normalized N'L, and one for the normalized 
N.H. The AFDUs for x,y control the 8v for all the AFDUs. The color values over a single curve of the 
patch are thus generated in lock step with the geometry. Conclusions We have described a method for shading 
bicubic patches suitable for hardware implementation. We presented two new methods for approximating 
the shading parameters over a bicubic patch. These methods both produce higher quality images than polygonal 
renderings. The advantages of rendering bicubic patches directly, instead of breaking them down into 
polygons for rendering, can be seen by comparing figures 3 and 4. The 4000 polygon teapot of figure 3 
is still noticeably faceted whereas the 80 patch teapot shown in figure 4 is quite smooth. No antialiasing 
has been performed and the hidden surface elimination is via Z-buffer. Further work is necessary to better 
understand how to approximate N.H with no overshoot (never greater than 1). The specular areas tend to 
"bloom" if the approximation exceeds 1.0 in the interior of the Coons patch. Figure 7 shows a sequence 
of increasingly subdivided patches using the normalized Coons method. The four examples represent 1, 
4, 16, and 64 patches, respectively, used on the visible side of the teapot spout. With finer subdivision 
of the patches, the shading approximations improve as the patches become smoother. We use Coons patches 
because of their tangent continuity properties, but other approximations such as Bezier patches should 
be investigated. Shading approximations for curved surfaces that are rational cubics or rational quadratics 
in world coordinates is an area that also needs further investigation. We are currently applying the 
techniques in this paper to the rational quadratic case. Acknowledgements Sue Carrie and David Elrod 
contributed to the architecture of the shading section by improving its Phong shading capabili- ties. 
Jerry Evans, Nola Donato, Bob Rocchetti, and Jim Van Loo gave many helpful suggestions on various aspects 
of this project. Appendix A A bicubic patch is defined by x (u ,v) = UXV y (u,v ) = UYV z (u,v ) = UZV 
where U =[u3u~u 1], V=lv3v2v II r, U' = [3u22u 10l, V'=[3v22vlO] r, U'=[6u200], and v"=[6v200] r. The 
 ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 normal vector to this patch is given by the following cross 
product. 3x .~_ 3~ 3x _~_ 3z N = <~-. 3u ' --3U > ×<~v' 3v ' ~v > = <n x ,ny ,n z > where nz=U'YVUZV'-UYWU'ZV 
ny =U'ZVUXW - UZV'U'XV n, =U'XVUYV" -uXV'U'YV The derivatives of the normal vector function are given 
by 3nx 3--~-= u"YVUZV" + u'YVU'ZV U'YV'U'ZV UYV'U"ZV 3n z -- =U'YV'UZW + U'YVUZV" 3v -UYV'U'ZV - UYVU'ZV 
~2B x = U"YWUZV" + U"YVUZV" 3u 3v + U'YV'U'ZW + U'YVU'ZV" -U'YV'U'ZV U'YVU'ZV" -UYV"U"ZV UYVU"ZV' The 
normalized normal vector function or unit normal func- tion is tl x ~z(u,v) = +.~ + n 21 6(u,v) ny q.L 
+.2, + .2 11 z a,(u,v) = q.L +.2, +.2 To interpolate the unit normal vector function by a bicubic function, 
we need 3,&#38; Oe. ,¢.(0,0) ,&#38;(0,t) -~-(0,0) -~-(0,t) 3,~. a&#38; fief1,0) Ex(l,l) -~-(l,0) -~-(1,1) 
-~-(0,0) -~-(0,1) ~v(O,O) ~v(O,l) -~-(I,0) -~-(1,1) ~v(1,0) ~v(l,1) Let a (u,v) = (. ~ + n~ + n2 )-la 
so that, for example dx (0,0)=nx (0,0)G (0,0) The derivatives in the u derivatives are given by. 3d.(u,v) 
3u 3d~(u,v) 3v and v directions, and the cross 3n. 3G 3u G +-~-n~ 3~ 3G 3v G+-~ -nz 32dx 32nz 3nx 3G 
o~2G 3G 3nz 3.3v ~a + -~--N- + ~2gf "~ + 3u &#38;, The only terms remaining to compute are those involving 
G ~G_ . 2 2 2.-3/2. 3n+ 3% 3%. 3--~---tn ~+n y+n ,) tn~ 3--~-+% 3"--~-+n, 3"~-.J . 3nx 3n~ 3% =-c ° 
(,.~-+,,-~- +.,-~) 3G ..... 3n~ 3n. 3n. 3-V +"5 +"" ) .... W ) and 32G 3 r G] 3u3v l- j Cl3~ j r3,. 
3.. 3°, 3,, 3.. 3,.1 References 1. Gary Bishop and David M. Weimer, "Fast Phong Shading," Computer Graphics, 
vol. 20, no. 4, pp. 103 - 106, August 1986. 2. Edwin Catmull, A Subdivision Algorithm for Computer Display 
of Curved Surfaces, Computer Science, University of Utah, UTEC-CSc-74-133, December 1974. 3. Steven 
A. Coons, Surfaces for Computer-Aided Design of Space Forms, Project MAC, Massachusetts Institute of 
Technology, MAC-TR-41, June 1967. 4. Tom Duff, "Smoothly Shaded Renderings of Polyhedral Objects on 
Raster Displays," Computer Graphics, vol. 13, no. 2, August 1979. 5. Jeffrey Lane, Loren Carpenter, 
Turner Whitted, and James Blinn, "Scan Line Methods for Displaying Parametrically Defined Surfaces," 
CACM, vol. 23, no. 1, January 1980. 6. Sheue-Ling Lien, Michael Shantz, and Vaughan Pratt, "Adaptive 
Forward Differencing for Rendering Curves and Surfaces," Computer Graphics, vol. 21, no. 4, July 1987. 
 7. Bui Tuong Phong, Illumination for Computer-Generated Images, UTEC-CSc-73-129, July 1973.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37426</article_id>
		<sort_key>197</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[A parallel processor architecture for graphics arithmetic operations]]></title>
		<page_from>197</page_from>
		<page_to>204</page_to>
		<doi_number>10.1145/37401.37426</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37426</url>
		<abstract>
			<par><![CDATA[Interactive 3D graphics applications require significant arithmetic processing to handle complex models, particularly if realistic rendering techniques are used. Current semiconductor technology cannot provide the necessary performance without some form of multi-processing.This paper describes a graphics processor architecture which can be configured with an arbitrary number of identical processors operating in parallel. Each of the parallel processors can be programmed identically as if it were a single processor system, substantially simplifying software development and allowing complex rendering functions to take advantage of the multiple processors. The architecture described is able to achieve extremely high performance while allowing the price/performance of the system to be optimized for a given application.Techniques are described for handling graphics command distribution, sequencing of commands which must be processed in order, parallel processing of graphics primitive picking, and handling inquiry (read-back) commands.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>B.2.1</cat_node>
				<descriptor>Parallel</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>C.1.2</cat_node>
				<descriptor>Parallel processors**</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010528</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Parallel architectures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010600.10010615</concept_id>
				<concept_desc>CCS->Hardware->Integrated circuits->Logic circuits</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Measurement</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P146285</person_id>
				<author_profile_id><![CDATA[81100089135]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Torborg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Raster Technologies, Inc., Westford, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>801272</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Clark, J.H., "The Geometry Engine, a VLSI Geometry System for Graphics", Computer Graphics (ACM) 16,3 (1982), 127.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H. and Poulton, J., "Pixel-Planes: A VLS1-Oriented Design for a Raster Graphics Engine," VLSI Design, No. 3 (1981), 20.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15898</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H., Goldfeather, J., Hultquist,, J. "Fast Constructive Solid Geometry Display in the Pixel-Powers Graphics System," Computer Graphics (ACM) 20,4 (1986), 107.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808580</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Niimi, H., Imai, Y., Murakami, M., Tomita, S., and Hagiwara, H., "A Parallel Processor System for Three-Dimensional Color Graphics," Computer Graphics (ACM) 18,3 (1984), 67.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Torborg, John G., "Computer Graphics System Having Arbitrary Number of Parallel Arithmetic Processors," US Patent Application, (1987).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[van Dam. A., et. al., "PHIGS+ Functional Description Rev. 2," Jointly developed PHIGS+ specification. (1987) Contact Andries van Dam - Committee Chairman, Stellar Computer Inc., 100 Wells Ave., Newton, MA, 02159. (1987).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A Parallel Processor Architecture for Graphics Arithmetic Operations John G. Torborg Raster Technologies, 
Inc. Two Robbins Road Westford, Mass. 01886 ABSTRACT Interactive 3D graphics applications require significant 
arithmetic processing to handle complex models, par-ticularly if realistic rendering techniques are used. 
Current semiconductor technology cannot provide the necessary performance without some form of multi-processing. 
This paper describes a graphics processor architecture which can be configured with an arbitrary number 
of identical processors operating in parallel. Each of the parallel processors can be programmed identically 
as if it were a single processor system, substantially simpli- fying software development and allowing 
complex ren- dering functions to take advantage of the multiple proc- essors. The architecture described 
is able to achieve extremely high performance while allowing the price/performance of the system to be 
optimized for a given application. Techniques are described for handling graphics com-mand distribution, 
sequencing of commands which must be processed in order, parallel processing of graphics primitive picking, 
and handling inquiry (read- back) commands. CR Categories and Subject Descriptors: B.2.1 [Arith-metic 
and Logic Structures]: Design Styles -Parallel; C.1.2 [Processor Architectures]: Multiprocessors -Par-allel 
processors; 1.3.5 [Computer Graphics]: Computa- tional Geometry and Object Modeling -Geometric al- gorithms, 
languages, and systems. Additional Key Words and Phrases: parallel process-ing, arithmetic processing, 
graphics command process- ing. Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. &#38;#169; 1987 ACM-0-89791-22%6/87/007/0197 $0O.75 INTRODUCTION Multiprocessor 
architectures have been used for sev-eral years to meet the demanding computational re-quirements of 
interactive 3D graphics. Simple graph- ics operations such as 3D wireframe manipulation can easily be 
divided into a sequence of pipelined opera-tions. If independent processors are used to handle these 
operations, very high performance can be at-tained [Clark 1982]. However, more complex opera-tions such 
as surface tesselation and lighting calcula- tions can not easily be handled by a highly pipelined architecture 
because of the difficulty in reconfiguring the pipeline to execute a wide variety of different graphics 
operations efficiently. Although parallel processing architectures have been explored by many researchers 
for performing drawing operations [Fuchs 1981, Niimi 1984, Fuchs 1986], rela- tively little work has 
been done to take advantage of parallel processing for front end geometric and arith- metic operations. 
A graphics processor architecture is presented which employs an arbitrary number of iden- tical graphics 
arithmetic processors. This architecture is currently being implemented in a high performance graphics 
system which can be configured with one to eight processors. The graphics system has been designed to 
run an ex-tended version of the ANSI proposed Programmer's Hi- erarchical Interactive Graphics Standard 
called PHIGS+. PHIGS+ has been jointly developed by sev-eral industrial and university contributors to 
provide a standard for high performance 3D graphics systems. Extensions to the ANSI proposed PH/GS are 
provided for shading and hidden surface removal, lighting mod- els, arbitrary clipping planes, 3D curves 
and surfaces, depth cueing, segment extents, and several other exten- sions. Many of these capabilities 
have been available on a smattering of high performance graphics systems although no attempt has been 
made to standardize them. [van Dam, et. al. 1987]. While some of the specifics of the graphics processor 
implementation are unique to PHIGS+, most of the concepts can be easily applied to other graphics com-mand 
sets. A parallel processing architecture for graphics must provide two basic attributes to be effective. 
First, graphics commands must be adequately distributed be- tween the processors for efficient processor 
utilization. And second, the multiple processors must produce the same apparent results as a single processor 
performing ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 the same operations. In other words, as additional 
processors are added, the user should notice no differ- ences in the operation of the system other than 
an al-most linear improvement in graphics performance. ORDER INDEPENDENCE OF GRAPHICS COM- MANDS An order-independent 
series of graphics commands is defined as a list of graphics primitives (polylines, poly- gons, etc.) 
in which the order in which the primitives are drawn has no effect on the display. For example, consider 
a series of vectors which define an arbitrary wireframe object. As long as all of these vectors are drawn 
into the frame buffer with the same pixel value (color), the order in which they are actually drawn has 
no effect on the resultant image. Analysis of a shaded surface representation of the same object indicates 
that if depth buffering is used to perform hidden surface removal, the resultant image will be determined 
by the depth priority of each pixel on each patch and is again independent of the order in which the 
primitives (patches in this case) are drawn. The order-independent nature of the most frequently encountered 
graphics primitives allows a parallel proc- essing architecture to be used very efficiently. There are, 
however, some graphics primitives and other op- erators which may be encountered in a display list which 
are not order-independent. The parallel process- ing architecture should also handle these operations 
with minimal degradation to the overall system per-formance. Sequential Commands A sequential graphics 
command is defined to be one which must be processed (written into the frame buffer if it is a drawing 
primitive) after all preceding graphics commands, and must be processed before any succeed- ing graphics 
commands. An example of a sequential command is one which changes the pixel value with which succeeding 
drawing primitives will be written. A simple approach to handling sequential commands would be towait 
until all graphics processors are idle, process the command by a single processor, then con-tinue the 
distribution of order-independent commands to the parallelprocessors. This approach dramatically reduces 
system performance if the command stream contains a significant percentage of sequential com-mands dispersed 
throughout. The inefficiencies which result from this situation can be greatly minimized by providing 
a mechanism which can reorder the sequential commands as they are drawn into the frame buffer. There 
will still be a de- gree of inefficiency due to the forced delay of the proc- essors which are processing 
other commands (to wait for the sequential command to be transferred), but this will be shown to be minimal. 
GRAPHICS SYSTEM ARCHITECTURE AND DATA FLOW The overall architecture of the graphics display system is 
split into three main sections as shown in Figure 1. The display list manager contains a dual-ported 
mem- ory system and memory management processor. Graphics commands are stored in this memory system as 
a hierarchical structure of linked blocks. The mem- ory management processor reads graphics commands 
from a particular structure (as specified by the applica- tions processor) and sends each command to 
a graph- ics arithmetic processor as shown in Figure 2. The graphics arithmetic processors handle all 
of the complex computational functions such as transforma-tions, clipping, tesselation, lighting models, 
picking, and general command processing. After processing, the graphics arithmetic processors transfer 
low-level drawing primitives (points, vectors, triangles, etc.) to the image memory units (as shown in 
Figure 2). The uniqueness of this architecture is in determining the order in which these low-level drawing 
primitives are transferred. The image memory units contain a frame buffer and video output section, as 
well as a VLSI drawing proces- sor which directly handles vectors, triangles, rectan-gles, and bitblts. 
By offloading the low-level drawing operations to the image memory units, the processing time for each 
graphics command (by the graphics arithmetic processors) is independent of the number of pixels that 
are modified, thereby increasing the uni-formity of command processing time and improving the efficiency 
of parallel processing of order dependent commands. The VLSI drawing processor has been designed to al- 
low very fast update of image memory. A master con- troller IC and four scan line processor ICs make 
up the drawing processor. The master control parses the low-level drawing command stream and performs 
setup calculations for the various operations. Each scan-line processors each control one quarter of 
the scan-lines using a four-way interleaved organization. The image memory is five-way interleaved to 
each scan-line processor allowing the entire system to ac-cess twenty pixels every memory cycle. This 
allows a peak drawing performance of over 60 million pixels per second including full intensity interpolation 
and depth buffering. The master controller IC directly controls vector and triangle operations and performs 
the necessary setup calculations. The setup calculation.~, as well as the pix- el drawing performance, 
can limit the primitive draw- ing rate. The vector setup time is 1 microsecond allow- ing 1 million short 
vectors/second to be rendered. The triat)gle setup time is 3 microseconds allowing 330,000 small triangles/second 
to be rendered (including inter- polated shading and depth buffering). Substantial floating point arithmetic 
power is necessary to fully utilize the drawing performance of this processor. COMMAND DISTRIBUTION The 
display list manager interfaces with the graphics arithmetic processors over a unidirectional 32-bit 
syn- chronous bus (called the CMD Bus). Data will be transferred to the arithmetic processors whenever 
data is available and the appropriate arithmetic processor is ready. Graphics commands are distributed 
to arithme- tic processors in one of four ways as determined by information in the first word of each 
command. | || | i , i GRAPHICS SYSTEM IMU BUS I I APPLJCACATIONS PROCESSOR AND PERIPHERALS ;4 CMD BUS 
DISPLAY LIST MANAGER ' GRAPHICS ARITHMETIC PROCESSOR 4 ,I GRAPHICS ARITHMETID PROCESSOR (OP~ONAL} f 1 
IMAGE MEMORY UNIT I I I I I L I ! I J VME BUS VIDEO OUTPUT FIGURE 1 GRAPHICS SYSTEM ARCHITECTURE GRAPHICS 
ARITHMETIC PROCESSOR DISPLAY LIST MANAGER -i -I GRAPHICS ARITHMETIC PROCESSOR GRAPHICS ARITHMETIC PROCESSOR 
IMAGE MEMORY UNIT H, oTI LEVEL GRAPHICS COMMANDS GRAPHICS ARITHMETIC PROCESSOR LEVEL DRAWING COMMANDS 
FIGURE 2 GRAPHICS COMMAND PROCESSING DATA FLOW 1) The command is not sent to any arithmetic proces- 
sor. This command type is used to insert labels and other non-graphics information into the dis-play 
list. 2) The command is sent to all arithmetic processors. This is used for commands that affect state 
on the arithmetic processors, such as the transformation matrix, the clipping planes, or the light sources. 
 3) The command is sent to the arithmetic processor which is most ready to accept the command. This is 
determined by a command arbitration mecha-nism described later. This command type is used for all graphics 
drawing primitives and all other graphics commands which only affect the image memory units. 4) The command 
is sent to a specific arithmetic proc- essor. In this case, the first word in the command specifies a 
particular processor number. This mode is currently not used but could allow special- ized processors 
to be incorporated into the archi- tecture for certain command types in the future. ~~ SIGGRAPH '87, 
Anaheim, July 27-31 1987 Command Format The first word of each command is called the com-mand header 
and is used to indicate how the command should be distributed between the parallel processors. An eight 
bit field in the header indicates the command type. The remainder of the header bits provide com-mand 
dependent information to the arithmetic proces- sors. The command type field in the header is defined 
as follows: Mode Dependence Command 3 bits 3 bits i bit 1 bit The distribution mode field is used by 
the display list manager and graphics arithmetic processors to deter-mine how the command should be distributed. 
The or-der dependence field is used by the arithmetic proces- sor in determining whether the command 
must be proc- essed sequentially. The hidden command bit and pick mode bits are used for graphics primitive 
picking and are described later. Order Dependence Classification Parallel command processing falls into 
two categories -order-independent and sequential. The order depend- ence field in the command header 
is used to determine how the command will be processed by the arithmetic processors. All commands fall 
into one of six classifi- cations as described below. 1) Non-shaded Drawing Primitive Command. This classification 
includes all drawing primitives which use preset value registers (registers on the image memory unit 
which have been loaded by a previ-ous command) to determine the pixel value in which the primitive will 
be drawn. Examples of these commands are vectors (other than depth-queued vectors), circles, arcs, and 
poly-gons. This command type is order-independent and therefore can always be processed in parallel and 
transferred to the image memory unit in any order. 2) Shaded Drawing Primitive Command. All drawing primitives 
where the value of the pixel data is computed using tight source calculations or where the value is included 
in the command (other than image transfers) fall into this category. Examples of these commands are shaded 
patches, 3D sur-faces, and depth-queued lines. This type of com- mand is order-independent if depth buffering 
is used to determine depth priority. If depth buffer- ing is not enabled, this command is sequential 
and must be transferred to the image memory unit in the same order as the command appeared in the original 
command stream. 3) Sequential Image Memory Unit Command. All commands of this type must be transferred 
from the arithmetic processor(s) to the image memory unit in the same order in which it occurred in the 
original command stream. Examples of these commands are set value register, set area pattern, and set 
vector pattern. 4) Inquire Image Memory Unit Commands. All in- quire commands are sequential commands 
to in-sure that the application will receive the inquire responses in order and to insure that the data 
is current. This command category is used for in-quire commands which read data from the image memory 
units. Inquiries to the image memory unit will occur in the same order as the command appeared in the 
original command stream. Like-wise, data transfers back to the application proces- sor must occur in 
order. Examples of these com-mands are inquire value register, inquire pixel data, and inquire look-up 
table entry. 5) Inquire Arithmetic Processor State. This classifi- cation is used for inquire commands 
which re-spond with state contained on the arithmetic proc- essors. As described above, all inquire commands 
are sequential commands requiring response data to be transferred to the application processor in order. 
Examples of this command category are in-quire transformation matrix, inquire clipping plane, and inquire 
light source. 6) Order-Independent Image Memory Unit Com-mand. This command type is used to specify a 
command which accesses the image memory unit and is order independent. This command type is not currently 
used. Command Arbitration Command arbitration is used to determine which arith- metic processor should 
receive the command if it can be processed in parallel. This arbitration mechanism attempts to fairly 
distribute commands between proces- sors and gives priority to processors which are most ready to accept 
the command. Each processor has a command input FIFO which is used to buffer commands from the display 
list man-ager. This FIFO is 512 long-words deep so that it can contain several commands simultaneously. 
The proc-essor will request commands on two priority levels based on the amount of data in its input 
FIFO. If the FIFO is empty, it will request a command using the high priority request. If the FIFO is 
not empty but is less than half full, the lower priority request will be used. No request will be made 
if the input FIFO is more than half full. This insures that the processor will not re-quest a command 
if it cannot buffer the entire com-mand in the remaining space in the FIFO (at least for the vast majority 
of commands). This prevents one processor from tying up the bus when another proces-sor may be idle. 
A fair arbitration mechanism is used to insure that all processors requesting a command on a given arbitra- 
tion level will be serviced before any other processor can request. If all commands took the same amount 
of processing time, this would result in a round-robin command distribution. However, since command proc- 
essing time is usually not evenly distributed, distribu-tion priority is given to the processors executing 
the commands which take the least amount of time to proc- ess. GRAPHICS ARITHMETIC PROCESSOR ARCHI-TECTURE 
A simplified block diagram of the graphics arithmetic processor is shown in Figure 3. This diagram shows 
the basic blocks that are necessary for graphics draw- ing operations. The programmable element of the 
graphics arithmetic processor is designated the proces- sor core. This is implemented using a horizontally 
microcoded 32 bit processor running at 12.5 Mhz pro- viding a peak performance of 12.5 MIPs and 25 MFLOPs 
(using independent multiply and ALU pipe-lines). Graphics Command Input Controller The graphics command 
input controller includes the CMD Bus interface and the command input FIFO. This controller determines 
which commands and which command headers need to be clocked into the input FIFO, based on the result 
of the command arbitration and the information in the command header. All com- mands (including headers) 
to be executed by the proc- essor core are clocked into the FIFO. In addition, com-mand headers are clocked 
into the FIFO for commands which are sequential or potentially sequential (for ex-ample, shaded drawing 
primitives are sequential if depth buffering is disabled, but are otherwise order-in- dependent). During 
pick mode (described later), all command headers are clocked into the FIFO. In addition to the data, 
two control bits are clocked into the FIFO. These two bits indicate whether the data is a header and 
whether the header is part of a command to be executed by this particular arithmetic processor. The processor 
core only executes commands which are so indicated. Graphics Command Tag FIFO As each command header 
is fetched from the com-mand input FIFO, an entry is loaded into another small tag FIFO (64 x 2). This 
FIFO is used to keep track of the ordering of all sequential commands being proc-essed by all arithmetic 
processors and all commands being processed by this processor. The two bit entry in the tag FIFO indicates 
whether the command is being processed by this arithmetic processor and whether the command is a sequential 
command. The appropriate mode bits are checked to determine if a potentially se- quential command is 
actually sequential before loading the tag FIFO. (A potentially sequential command which is determined 
to be order-independent and is not being processed by this arithmetic processor will Computer Graphics, 
Volume 21, Number 4, July 1987 This tag FIFO is the key to providing optimum per-formance for parallel 
commands and insuring sequen- tial processing of order dependent commands. The output of this FIFO is 
used to control the order in which image memory unit commands are transferred over the image memory unit 
bus (IMU Bus). Drawing Command Output Controller This controller is used to transfer data from the proces- 
sor core to the image memory units over a 32-bit mul- timaster synchronous data bus (IMU Bus). Included 
in this logic is a 512 x 36 output FIFO and the mecha-nism used to maintain proper ordering of sequential 
commands. The processor core writes image memory unit com-mands into the output FIFO as required. The 
first 32-bit word of each command is a command header which indicates the destination of the command 
as well as certain command specific information. In addition to the data word, the FIFO contains several 
control bits which indicate the first word (header) and last word of each image memory unit command. 
If the entry is the last word, control bits indicate whether the command is the last of a sequence of 
indivisible commands, and whether it is the last of a group of commands spawned by a single high-level 
graphics input command. The control information allows multiple image memory unit commands to be associated 
with a single high-level graphics input command. These commands may be divisible in which case the output 
controller will release the IMU Bus between commands (assum-ing that the graphics input command was not 
sequen-tial), or may be indivisible in which case all the image memory commands will be sent as a group 
before re-leasing the bus. The output of the tag FIFO is used to control arbitra- tion for the IMU Bus. 
If the two control bits indicate that the command is not sequential, then the output controller Will 
request the IMU Bus as soon as a com- plete _command block is available. In this case, the order in which 
commands are transferred to the image memory unit will depend on the processor load and command distribution 
of all processors. The tag FIFO output will be clocked after each command group asso- ciated with a single 
graphics input command is trans- ferred over the IMU Bus. If the tag FIFO indicates a sequential command, 
the output controller will wait until all other arithmetic processor output controllers have reached 
the same point in the original command stream. Since every processor places an entry into its tag FIFO 
for every not cause an entry to be loaded into the tag FIFO). IMU BUS   cMus .RocEsso DRAWING GRAPHIO8 
COMMAND COMMAND CORE OUTPUT INPUT CONTROLLER CONTROLLER I ,71 TAG FIFO FIGURE 3 GRAPHICS ARITHMETIC 
PROCESSOR SIMPLIFIED BLOCK DIAGRAM ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 sequential command (even 
if the command is not exe- cuted on that processor), all processors' tag FIFOs will indicate a sequential 
command but only one will indi- cate that the command was processed by that proces- sor. The processor 
which has processed the sequential command will then request the bus and send the group of commands associated 
with the graphics input com-mand. Once this command transfer has completed, the tag FIFO output on all 
arithmetic processors will be clocked. Since the processor core can still continue to transfer commands 
into the output FIFO, processor perform- ance is usually not affected when the 1MU interface is held 
up to maintain sequentiality. GRAPHICS COMMAND PREFETCHER The command headers of all potentially sequential 
commands are transferred to all arithmetic processors. If a significant number of potentially sequential 
com-mands (such as 3D patches) are being processed in a large configuration (several processors), each 
proces- sor will receive many more command headers than commands. A command prefetcher is added to elimi- 
nate the overhead associated with these extra com-mand headers. This prefetcher will fetch data out of 
the FIFO before it is required by the processor core. If the data is a header which is not to be processed 
by the processor core, it is handled directly by the prefetcher. The tag FIFO is also controlled by the 
prefetcher, al-lowing the processor core to completely ignore the par- allel processing aspects of the 
architecture. SEQUENCING OF RESPONSE DATA Response data is sent to the application processor over the 
VME bus. This allows inquiry commands to be processed without interrupting the command pipeline from 
the display list manager. All response data is written back to the application processor in the same 
order as the high-level graphics commands occurred in the command stream. As with the IMU Bus, some mechanism 
must be pro- vided to insure that response data transfers are per-formed sequentially. The mechanism 
provided for the VME Bus is the same as the IMU Bus with two excep- tions. First, the response commands 
are always se-quential so no distinction is made between sequential and order-independent commands. Second, 
some commands do not always have response data to send (such as drawing primitives in pick mode) so a 
mecha- nism must be provided to allow processing to continue without requesting the VME Bus. The VME 
Bus interface incorporates a small (64 x 1) tag FIFO to keep track of sequential inquiry com-mands. This 
FIFO is clocked whenever a command header is fetched from the command input FIFO which potentially has 
response data to transfer back to the application processor. The FIFO input bit is set if the command 
will be processed by the processor core and is cleared if the command will be processed by a dif- ferent 
arithmetic processor. The output of the tag FIFO is used to control arbitra- tion for the VME Bus. If 
the FIFO is not empty, a VME response transfer is pending from some proces-sor. A mechanism is provided 
to suspend VME arbitra- tion until all processor VME bus controllers have reached the same point in the 
command stream (indi-cated by a tag FIFO not-empty condition). If the proc- essor executing the command 
has response data to send to the application processor, it can then request the VME Bus and transfer 
the data. After the proces- sor has transferred all its response data, or if no data is to be sent, all 
processor VME bus controllers will clock their tag FIFO outputs. Two enhancements are added to this basic 
mechanism to improve parallel processing performance. The VME Bus controller will assume that the processor 
core did not require the VME Bus if another command is fetched from the input FIFO. This eliminates the 
need for the processor to inform the bus controller. Further, the VME Bus controller incorporates a counter 
which keeps track of the number of potential response com-mands which did not require VME Bus access. 
This counter allows the processor core to continue process- ing potential response commands without waiting 
for the VME Bus sequential transfer mechanism to catch up. Only when the processor actually needs to 
transfer data over the VME Bus wilt it wait for the other arith- metic processors (which are performing 
response trans- fers from commands earlier in the command stream). These enhancements are particularly 
important when the system is operating in pick mode (described below) because all primitive drawing commands 
are poten-tially response commands although only a small per- centage of commands actually transfer data 
over the VME Bus. GRAPHICS PRIMITIVE PICKING Primitive picking performance is as important as dis-play 
performance in an interactive system. The arith- metic processors operate in a special mode for primi- 
tive picking operations. This pick mode is controlled by the display list manager and causes drawing 
primi- tives to be handled differently. As the display list is traversed, all geometry is transformed 
and clipped nor. really, and is also clipped to the pick aperture. The pick aperture is a small 2D window 
(or 3D cube) which surrounds the pick point (normally the pointing device position). Primitives which 
intersect the pick aperture cause a pick hit. When this occurs, the arithmetic processor will inform 
the application processor with in- formation identifying the picked primitive. All drawing primitives 
are potentially response com-mands when the system is in pick mode. This requires that all command headers 
for pickable commands be loaded into the input FIFO of all arithmetic processors. (Note that all command 
headers must be clocked in to support the primitive counting mechanism described below). Only those primitives 
which are picked will actually generate a response to the application proces- sor. Some commands, such 
as segment ID, are only needed by the arithmetic processors when in pick mode. The command header contains 
a bit, called the Pick Mode bit, which is set for commands required only during pick mode. These commands 
are not transferred to the arithmetic processors unless the system is in pick mode, thus reducing processor 
overhead when the sys- tem is not in pick mode. PRIMITIVE COUNTING MECHANISM When a pick hit is detected 
by the arithmetic processor, information is returned to the application processor identifying the location 
in the structure of the primitive. The PHIGS graphics standard includes a primitive count as part of 
this information. The primitive count specifies the number of the primitive within the struc-ture. A 
24-bit counter is provided on each arithmetic proces- sor. This counter is incremented for each command 
header as it is fetched from the command input FIFO except for those headers with the hidden bit set. 
The hidden bit allows non-PHIGS commands (such as dis-play list labels) to be inserted in the command 
stream transparently to the primitive count and the application program. Since all headers are clocked 
into the input FIFO of all arithmetic processors when the system is in pick mode, each arithmetic processor 
can maintain a count of the PHIGS primitive which is being processed. The primitive count is pushed onto 
a stack and the counter is reset when a segment reference is encoun-tered. The primitive count is restored 
when the seg-ment ends. A latch is loaded with the primitive count when a head- er is fetched from the 
input FIFO which is to be exe-cuted by the processor core. This allows the command prefetcher to continue 
prefetching headers from the in- put FIFO while the processor core is testing the primi- tive against 
the pick aperture. If the processor core determines that the primitive is a valid pick hit, it can then 
write the primitive count and appropriate tree (structure) information to the application processor. 
PERFORMANCE At the time that this paper was written, the system was in debug and was unavailable for 
system benchmark- ing. The image memory unit and VLS[ drawing proc- essor has been fabricated and the 
performance of this part of the system has been validated. Detailed simu- lation software has been developed 
to allow accurate system analysis. A wireframe and shaded patch repre- sentation of an automobile (shown 
in Figure 4 and 5) have been run through this simulator to show the per- formance of the parallel processing 
architecture. The expected performance is shown below. Wire Frame Database of Chrysler Laser courtesy 
of Chrysler Corporation Number of Vectors: 99,236 Average Vector Length: 4.8 pixels Shaded Patch Database 
of Chrysler Laser courtesy of Chrysler Corporation Number of Time to Process Processor Processors Image 
Efficiency 1 690 ms 100% 2 345 ms 100% 3 230 ms 100% 4 176 ms 98% 5 143 ms 96% 6 124 ms 93% 7 109 ms 
90% 8 104 ms 84% Number of Triangles: 64,696 Average Triangle Size: 19 pixels Number of Time to Process 
Processor Processors Image Efficiency 1 5.7 see 100% 2 2.9 sec 100% 3 1.9 sec 100% 4 1.4 see 100% 
 5 1.1 ms 100% 6 950 ms 100% 7 820 ms 100% 8 720 ms 100%  Perspective transformations were applied to 
both the wireframe and surface models. Approximately half of the triangles were culled because the normal 
vectors were facing away from the viewer. Diffuse, ambient, and specular terms were calculated at each 
vertex of the remaining triangles to determine the colors to be interpolated. The efficiency of this 
architecture when processing a large number of the same command is extremely high (until other system 
constraints are reached). This makes the system well suited for interactive manipula- tion of complex 
models. Processor efficiency degrades as the processing time for each command becomes less uniform and 
as the percentage of sequential commands increases. Our simulations have shown that this be- comes a 
factor only when the total drawing command output rate (from all graphics arithmetic processors) starts 
to exceed 50% of the drawing processor bandwidth. Below this level, the output FIFOs of the graphics 
arithmetic processors are never filled so the processor core never has to wait. On the current im-plementation, 
the maximum vector drawing perform- ance of 104 ms (for the given example) is reached with just over 
seven processors. The maximum shaded patch rendering performance of 150 ms is not reached with the maximum 
complement of processors. SUMMARY A parallel processing architecture has been presented which allows 
an arbitrary number of identical proces- sors to be applied to graphics arithmetic calculations. This 
system provides the necessary floating point com- putational power to handle sophisticated tesselation 
and lighting models, while still operating very effi-ciently and cost effectively for simple operations 
such as transformations and clipping. The processors are each programmed identically and each processor 
is programmed as if it were a uniprocessor system, thus substantially simplifying software development. 
The number of processors can be optimized for the computational requirements of the problem, allowing 
a cost effective system to be imple- mented for a wide range of applications. Also, since all processors 
are identical, systems in the field can be upgraded to higher performance by simply plugging in additional 
processor boards.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37427</article_id>
		<sort_key>205</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[Elastically deformable models]]></title>
		<page_from>205</page_from>
		<page_to>214</page_to>
		<doi_number>10.1145/37401.37427</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37427</url>
		<abstract>
			<par><![CDATA[The theory of elasticity describes deformable materials such as rubber, cloth, paper, and flexible metals. We employ elasticity theory to construct differential equations that model the behavior of non-rigid curves, surfaces, and solids as a function of time. Elastically deformable models are active: they respond in a natural way to applied forces, constraints, ambient media, and impenetrable obstacles. The models are fundamentally dynamic and realistic animation is created by numerically solving their underlying differential equations. Thus, the description of shape and the description of motion are unified.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.1.8</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003727.10003729</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Differential equations->Partial differential equations</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14109166</person_id>
				<author_profile_id><![CDATA[81100294834]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Demetri]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Terzopoulos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Schlumberger Palo Alto Research, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31092696</person_id>
				<author_profile_id><![CDATA[81100090687]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Platt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology, Pasadena]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P12238</person_id>
				<author_profile_id><![CDATA[81100070192]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Alan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Barr]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology, Pasadena]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39071844</person_id>
				<author_profile_id><![CDATA[81332499016]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Kurt]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fleischer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Schlumberger Palo Alto Research, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Armstrong, W.W., and Green, M., "The dynamics of articulated rigid bodies for purposes of animation," Proc. Graphics Interface '85, Montreal, Canada, 1985, 407-415.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barr, A.H., Geometric Modeling and Fluid Dynamic Analysis of Swimming Spermatozoa, PhD thesis, Department of Mathematical Sciences, Rensselaer Polytechnic Institute, Troy, NY, 1983.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808573</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Barr, A.H., "Global and local deformations of solid primitives," Computer Graphics, 18, 3, 1984, (Proc. SIC- GRAPH) 21-29.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Barzel, l:t.~ Dynamic Constraints, MSc thesis, Department of Computer Science, California Institute of Technology, Pasadena, CA, 1987.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Courant, R., and Hilbert, D., Methods of Mathematical Physics, Vol. I, Interscienee, London, 1953.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>940481</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Dahlquist, G., and Bjorek, A., Numerical Methods, Prentice-HM1, Englewood Cliffs, N J, 1974.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[de Boor, C., A Practical Guide to Splines, Springer- Vedag, New York, NY, 1978.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[do Carmo, M.P., Differential Geometry of Curves and Surfaces, Prentice-Hall, Englewood Cliffs, N J, 1974.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>578513</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Faux, ,I.D., and Pratt~ M.J., Computational Geometry for Design and Manufacture, Halstead Press, Horwood, NY, 1981.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Feynman, C.R., Modeling the Appearance of Cloth, MSc thesis, Department of Electrical Engineering and Computer Science, MIT, Cambridge, MA, 1986.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15894</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Fournier, A , and Reeves, W.T., "A simple model for ocean waves," Computer Graphics, 20, 4, 1986, (Proc. SIGGRAPH), 75-84.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Fung, Y.C., Foundations of Solid Mechanics, Prentice- Hall, Englewood Cliffs, N J, 1965.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Gelfand~ I.M.~ and Fomin, S.V., Calculus of Variations, Prentice-Hall, Englewood Cliffs, N J, 1963.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Goldsteln~ H., ClassicalMechanics, Addison-Wesley, Reading, MA, 1950.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Immel, D.S., Cohen, M.F, and Greenberg, D .P , "A radiosity method for non-diffuse environments," Computer Graphics, 20, 4, 1986, (Proc. SIGGRAPH), 133-142.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Kajiya~ J.T., "The rendering equation," Computer Graphics, 20, 4, 1986, (Proe. SIGGRAPI-I), 143-150.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808594</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J.T., and yon Herzen, B.~ "Ray tracing volume densities," Computer Graphics, 18, 3, 1984, (Proc. SIGGRAPH), 165-174.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Landau, L.D., and Lifshitz, E.M., Theory of Elasticity, Pergamon Press, London, UK, 1959.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Lapidus, L., and Pinder, G.F., Numerical Solution of Partial Differential Equations in Science and Engineering, Wiley, New York, NY, 1982.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15893</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Peachey, D.R., "Modeling waves and surf," Computer Graphics, 20, 4, 1986, (Proc. SIGGRAPH), 65- 74.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Sederberg, T.W., and Parry, S.R., "Free-form deformation of solid geometric models," Computer Graph. ics, 20, 4, 1986, (Proc. SIGGRAPH), 151-160.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Stoker, J .J ., Nonlinear Elasticity, New York, NY, 1968.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., "Multilevel computational processes for visual surface reconstruction," Computer Vision, Graphics, and Image Processing, 24, 1983, 52-96.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5994</ref_obj_id>
				<ref_obj_pid>5979</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., "Regularization of inverse visual problems involving discontinuities," IEEE Trans. Pattern Analysis and Machine Intelligence, PAMI-g, 1986, 413-424.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D.~ "On matching deformable models to images: Direct and iterative solutions," Topical Meeting on Machine Vision, Technical Digest Series, Vol. 1~., Optical Society of America, Washington, DC, 1987, 160-167.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15891</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Well, J., "The synthesis of cloth objects," Computer Graphics, 20, 4, 1986, (Proc. SIGGRAPH), 49-54.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_obj_id>20331</ref_obj_id>
				<ref_obj_pid>20313</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Wilhelms, J , and Barsky, B.A., "Using dynamic analysis to animate articulated bodies such as humans and robots," Proe. Graphics Interface '85, Montreal, Canada, 1985, 97-104.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15895</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Yaeger, L., Upson, C., and Myers, It., "Combining physical and visual simulation -- creation of the planet Jupiter for the film "2010"," Computer Graphics, 20, 4, 1986, (Proe. SIGGRAPH), 85-94.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Zienkiewicz, O.C., The Finite Element Method; Third edition, McGraw-Hill, London, 1977.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~) ~ Computer Graphics, Volume 21, Number 4, July 1987 Elastically Deformable Models Demetri Terzopoulost 
John Platt$ Alan Barr$ Kurt Fleischert tSchlumberger Palo Alto Research, 3340 Hillview Avenue~ Palo 
Alto, CA 94304 California Institute of Technology, Pasadena, CA 91125 Abstract: The theory of elasticity 
describes deformable ma- terials such as rubber, cloth, paper, and flexible metals. We employ elasticity 
theory to construct differential equations that model the behavior of non-rigid curves, surfaces, and 
solids as a function of time. Elastically deformable models are active: they respond in a natural way 
to applied forces, constraints, ambient media, and impenetrable obstacles. The models are fundamen- tally 
dynamic and realistic animation is created by numerically solving their underlying differential equations. 
Thus, the de- scription of shape and the description of motion are unified. Keywords: Modeling, Deformation, 
Elasticity, Dynamics, An- imation, Simulation CR categories: G.1.8--Partial Differential Equations; 1.3.5-- 
Computational Geometry and Object Modeling (Curve, Sur- face, Solid, and Object Representations); 1.3.7--Three-Dimen- 
sional Graphics and Realism 1. Introduction Methods to formulate and represent instantaneous shapes of 
objects are centralto computer graphics modeling. These methods have been particularly successful for 
modeling rigid objects whose shapes do not change over time. This paper develops an approach to modeling 
which incorpo- rates the physically-based dynamics of flexible materials into the purely geometric models 
which have been used traditionally. We propose models based on elasticity the- ory which conveniently 
represent the shape and motion of deformable materials, especially when these materials in- teract with 
other physically-based computer graphics ob- jects. 1.1. Physical Models versus Kinematic Models Most 
traditional methods for computer graphics modeling are kinematic; that is, the shapes are compositions 
of ge- ometrically or algebraically defined primitives. Kinematic models are passive because they do 
not interact with each other or with external forces. The models are either sta- tionary or are subjected 
to motion according to prescribed Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. &#38;#169; 1987 ACM-0-89791-227-6/87/007/0205 $00.75 trajectories. Expertise is 
required to create natural and pleasing dynamics with passive models. As an alternative, we advocate 
the use of active mod- els in computer graphics. Active models are based on prin- ciples of mathematical 
physics [5]. They react to applied forces (such as gravity), to constraints (such as linkages), to ambient 
media (such as viscous fluids), or to impene- trable obstacles (such as supporting surfaces) as one would 
expect real, physical objects to react. This paper develops models of deformable curves, sur- faces, 
and solids which are based on simplifications of elas- ticity theory. By simulating physical properties 
such as tension and rigidity, we can model static shapes exhibited by a wide range of deformable objects, 
including string, rubber, cloth, paper, and flexible metals. Furthermore, by including physical properties 
such as mass and damping, we can simulate the dynamics of these objects. The simu- lation involves numericaily 
solving the partial differential equations that govern the evolving shape of the deformable object and 
its motion through space. The dynamic behavior inherent to our deformable mod- els significantly simplifies 
the animation of complex ob- jects. Consider the graphical representation of a coiled telephone cord. 
The traditional approach has been to rep- resent the instantaneous shape of the cord as a mesh as- sembly 
of bicubic spline patches or polygons. Making the cord move plausibly is a nontrivial task. In contrast, 
our deformable models can provide a physical representation of the cord which exhibits natural dynamics 
as it is subjected to external forces and constraints. 1.2. Outline The remainder of the paper develops 
as follows: Section 2 discusses the connections of our work to other physical models in computer graphics. 
Section 3 gives differential equations of motion describing the dynamic behavior of deformable models 
under the influence of external forces. Section 4 contains an analysis of deformation and defines deformation 
energies for curve, surface, and solid models. Section 5 lists various external forces that can be applied 
to deformable models to produce animation. Section 6 de- scribes our implementation of deformable models. 
Section 7 presents simulations illustrating the application of de- formable models. Section 8 discusses 
our work in progress.  ~t~ SIGGRAPH '87, Anaheim, July 27-31, 1987 2. Related Graphics Models Interestingly, 
the classical spline representations of shape have characterizations based in elasticity theory [7]. 
How- ever, in adopting splines as a representation of curve and surface shape, the graphics literature 
has deemphaslzed the physical basis of splines. The cubic interpolating spline, for instance, is an abstraction 
of the shape exhibited by a thin elastic beam (the elastica used in boat construction) whose minimal 
bending energy configuration may be character- ized by a fourth-order differential equation. The elasticity 
theory perspective leads to generalized spline representa- tions of curves, surfaces, and solids. Our 
work in this paper can be viewed as an extension, including physically-based dynamics, of the mixed-order 
generalized splines employed in computer vision by Terzopoulos [24]. Special purpose physical models 
have begun to cap- ture the attention of the computer graphics community. Fluid mechanics was used by 
Peachey [20] and Fournier and Reeves [11] to model water waves, as well as Kajiya and yon Herzen [17] 
and Yaeger et aL [28] for cloud sim- ulation. Also, the physics of imaging has been applied to rendering 
[16, 15]. Well [26] used catenaries to approxi- mate cloth, while Feynman [10] used a more sophisticated 
thin plate flexure model for the same purpose. Terzopoulos [23] employed deformable models based on variational 
principles to reconstruct surfaces from scat- tered visual constraints. To create deformable models, 
Barr [3] subjected solid primitives to prescribed deforma- tions using Jaeobian matrices. Sederberg and 
Parry [21] imposed similar deformations to solids modeled as free- form surfaces. We extend these approaches 
by adding equations governing the eycolution of deformations. Our models are compatible with and complementary 
to the constraint-based modeling approach for rigid prim- itives proposed by Barzel and Barr [4], as 
well as with the dynamics-based approaches of Wilhelms and Barsky [27] and Armstrong and Green [1] to 
animating articulated rigid bodies. Finally, since computer vision is the inverse problem of computer 
graphics, the models presented in this paper are of value for reconstructing mathematical repre- sentations 
of non-rigid objects from their images [25]. 3. Dynamics of Deformable Models We begin the mathematical 
development by giving the equations of motion governing the dynamics of our de-formable models under 
the influence of applied forces. The equations of motion are obtained from Newtonian mechan- ics and 
balance the externally applied forces with the forces due to the deformable model. Let a be the intrinsic 
or material coordinates of a point in a body ~. For a solid body, a has three com-ponents: [az, a2, as]. 
Similarly, for a surface a = [az, a2], and a curve a = [az]. The Euclidean 3-space positions of points 
in the body are given by a time-varying vec-tor valued function of the material coordinates r(a, t) = 
[rz (a, t), r2(a, t), r3(a, t)]. The body in its natural rest state 7,0 a ,I "0 a ,r 0 a (see Figure 
1) is specified by r°(a) = [ 1( ) 2( ) s( )1. deforming body undeform~body ^ Figure 1. Coordinate systems. 
The equations governing a deiormable model's motion can be written in Lagrange's form [14] as follows: 
0 (Or) Or ~E(r) =f(r,t) ' (1) where r(a,t) is the position of the particle a at time t, kt(a) is the 
mass density of the body at a, "7(a) is the damping density, and f(r, t) represents the net externally 
applied forces, g(r) is a functional which measures the net instantaneous potential energy of the elastic 
deformation of the body. The external forces are balanced against the force terms on the left hand side 
of (1) due to the deformable model. The first term is the inertial force due to the model's distributed 
mass. The second term is the damping force due to dissipation. The third term is the elastic force due 
to the deformation of the model away from its natural shape. The elastic force is conveniently expressed 
as gE(r)/6r, a variational derivative of the potential energy of deforma- tion £(r) (as approximated 
in equation 14). More informa- tion on variational derivatives can be found in textbooks on the calculus 
of variations [5, 13]. 4. Energies of Deformation This section develops potential energies of deformation 
£(r) associated with the elastically deformable models. These energies are employed to define the internal 
elastic forces of the models (see Section 6). ¢  4.1. Analysis of Deformation Elasticity theory involves 
the analysis of deformation [18, 12]. We will define measures of deformation using con- cepts from the 
differential geometry of curves, surfaces, and solids [8]. One requirement of our present approach is 
that the measures should be insensitive to rigid body motion since it imparts no deformation. The shape 
of a body is determined by the Euclidean distances between nearby points. As the body deforms, these 
distances change. Let a and a + da be the material coordinates of two nearby points in the body. The 
distance between these points in the deformed body in Euclidean 3-space is given by dl = E Gijdaidaj, 
(2) i,j where the symmetric matrix Or Or Gij (r(a))= Oa"-~'Oaj (3) is known as the metric tensor or 
first fundamental form [9] (the dot indicates the scalar product of two vectors). Two 3-dimensional solids 
have the same shape (differ only by a rigid body motion) if their 3 x 3 metric tensors are identical 
functions of a = lax, a2, a3]. However, this no longer need be true when the body becomes infinitesimally 
thin in one or more of its dimensions. Thus, the lengths between nearby points do not deter- mine the 
shape of a surface, since curvature can be altered without affecting lengths. The fundamental theorem 
of surfaces [8] states that two surfaces have the same shape if their metric tensors G as well as their 
curvature tensors B are identical functions of a = [aa,a2]. The 2 x 2 matrices G and B are the first 
and second fundamental forms of the surface [9]. The components of the curvature tensor are 02r Bij (r(a)) 
= n. OaiOaj ' (4) where n = [nz, n2,n3] is the unit surface normal. For the case of space curves, the 
metric and curvature tensors are scalars called the arc length s (r(a)) and the curvature ~ (r(a)). Again, 
arc length and curvature do not entirely determine the shape of a space curve; the curve can twist. Thus, 
the fundamental theorem of curves [8] states that two curves have the same shape if their arc length, 
curvature, and torsion r(r) are identical functions of a = a [9]. 4.2. Energies for Curves, Surfaces, 
and Solids Using the above differential quantities, we now define po- tential energies of deformation 
for elastic curves~ surfaces, and solids. These energies restore deformed bodies to their natural shapes, 
while being neutral with respect to rigid body motion (see Figure 2). Thus, the potential energy should 
be zero when the model is in its natural state, and the energy should grow larger as the model gets increas- 
ingiy deformed away from its natural state. Computer Graphics, Volume 21, Number 4, July 1987 natural 
shape rigid body motion zero energy small deformation large deformation low energy high energy Figure 
2. Energy of deformation. A reasonable strain energy for elastic bodies is a norm of the difference between 
the fundamental forms of the de- formed body and the fundamental forms of the natural, undeformed body. 
This norm measures the amount of de- formation away from the natural state. In the rest of the paper, 
the fundamental forms asso- ciated with the natural shapes of deformable bodies will be denoted by the 
superscript O. For example, G,°j = Or ° Oa i Or 0 --Oh j" (5) Thus, for a curve, we use the strain energy 
E(r) = f. ~(s -,°)~ + ~(~ -~0)~ +.r(,. -r°) ~da (6) where a,/3, and 7 are the amount of resistance of 
the curve to stretching, bending, and twisting, respectively. An anal- ogous strain energy for a deformable 
surface in space is E(r) = fn IIG - G°ll~ + lIB - solID daida2, (7) where I1" I1,~ and I1" 118 are weighted 
matrix norms. Similarly, a strain energy for a deformable solid is E(r) -- fo IIG - G°ll~ daldazda3. 
(8) The deformation energies (6), (7), and (8) are zero for rigid motions, and they include the fewest 
partial deriva- tives necessary to restore the natural shapes of non-rigid curves, surfaces, and solids, 
respectively. However, higher- order derivatives can be included to further constrain the smoothness 
of'the admissible deformations of these bodies [24]. 5. Applied Forces Applying external forces to elastic 
models yields realis- tic dynamics. This section lists representative examples  ~ SIGGRAPH '87, Anaheim, 
July 27-31, 1987 of external forces, including the effects of gravity, fluids, and collisions with impenetrable 
objects. The net exter- nal force f(r, t) in (1) is the sum of the individual external forces. Various 
types of external forces, each a vector func- tion of r, are presented below. A gravitational force acting 
on the deformable body is given by fgravity = #(a)g, (9) where #(a) is the mass density and g is the 
gravitational field. A force that connects a material point a0 to a point in world coordinates r0 --[x0, 
Y0, z0] by an ideal Hookean spring is f.prlng = k(r0 -r(a0)), (10) where k is the spring constant. The 
force on the surface of a body due to a viscous fluid is f~i ..... = c(n. v)n, (11) where c is the strength 
of the fluid force, n(a) is the unit normal on the surface, and ar(a,t) (12) v(a, t) = u -Ot is the 
velocity of the surface relative to some constant stream velocity u. The force is a flow field projected 
onto the normal of the surface, is linear in the velocity, and models a viscous medium [2]. We simulate 
collision dynamics between elastic models and immobile impenetrable objects by creating a potential energy 
cexp(-f(r)/e) around each object, where f is the object's inside/outside function. The constants c and 
e determine the shape of the potential and are chosen such that the energy becomes prohibitive if the 
model attempts to penetrate the object. The resulting force of collision is fcollision =- (Vf(r)exp (--'~-----~)" 
n)n, (13) where n(a) is the unit normal vector of the deformable body's surface. This force ignores frictional 
effects at con- tact points, but it is a straightforward matter to define friction forces which impede 
sliding motions along the ob- ject's surface. Elastic bodies should not self-intersect as they deform. 
Self-intersection can be avoided by surrounding the surface of the object with a self-repulsive collision 
force. The re- pulsive force requires an implicit description of the surface of the object, which is 
only available locally in our mod- els. Thus, each object decomposes into many small patches and the 
repulsive force computation can become expensive. However, greater efficiency may be obtained by placing 
the patches into hierarchical bounding boxes. 6. Implementation of Deformable Models To create animation 
with deformable models, the differ- ential equations of motion are simulated numerically. We concentrate 
on the case of surfaces in order to illustrate the implementation of deformable models. Curves (solids) 
represent a straightforward restriction (extension) of the discrete two-parameter equations developed 
in this sec-tion. Discrete equations of motion are sought that are tractable and stable. We first propose 
a simplification of the elastic forces ~E(r)/~r. The partial differential equa- tion (1) is then discretized 
in space. Finally, the resulting system of coupled ordinary differential equations is inte- grated through 
time using standard techniques. 6.1. A Simplified Elastic Force We will use a weighted matrix norm in 
(7) to obtain the following simplified deformation energy for a surface: 2 g(r) = ~ ~ (7/ij(Gij -Oi°j) 
2 + (ij(Bij -B~j) 2) dalda2, i,j=l  (14) where ~/ij(a) and (i/(a) are weighting functions. The first 
variational derivative 6E(r)/6r of (14) can be approximated by the vector expression: 0 ( Or) 0 2 (~ 
0~r \ 2 aiJ~aJ e(r)= ~-Pal + ~,/JiJ0a~') ' i,j=l (15) where aij(a, r) and f~ij(a, r) are constitutive 
functions de- scribing the elastic properties of the material. Now, aij(a, r) = ~/ij(a) (Gij --Gi°j). 
(16) When aij is positive the surface wants to shrink in extent, and when aij is negative, it wants to 
grow. Thus, the alj are controlling surface tensions which minimize the devia- tion of the surface's 
actual metric from its natural metric Gi°j. As rlij(a0 ) is increased, the material's resistance to such 
deformation increases at material point a0. yll and ~2~ determine the resistance to length deformation 
along the coordinate directions, while UI~ = r/21 determine the resistance to shear deformation. Unfortunately, 
the calculus of variations applied to the second term in (14) yields unwieldy expressions. One alternative 
which follows by analogy to (16) is to use ~,j(,, r) = ~,~(~) (B,j -B~j). (17) When flij is positive, 
the surface wants to be flatter, and when flij is negative, the surface wants to be n~ore curved. Thus, 
/3ij are controlling surface rigidities which act to minimize the deviation of the surface's actual curvature 
from it's natural curvature Bi°j. As ~ij(a0) is increased, the material becomes more resistant to such 
deformation at material point a0. ~al and ~22 determine the resistance to bending deformation along the 
coordinate directions, while ~a2 = ~21 determines the resistance to twist deformation. To simulate a 
stretchy rubber sheet, for example, we make yij relatively small and set ~ij = 0. To simulate rel- atively 
stretch resistant cloth, we increase the value of T/ij. To simulate paper, we make Yij relatively large 
and we in- troduce a modest value for ~ij. Springy metal is simulated by increasing the value of ~ij. 
The ability to set y and independently at each material point a allows the intro- ~ Computer Graphics, 
Volume 21, Number 4, July 1987 duction of local singularities such as fractures and creases [24]. Note 
that for the special case where cq2 = a21 = 0 and where an, a22, and the ~ij are linearized so as to 
be independent of r, we obtain the "thin plate surface under tension" [24]. The thin plate surface under 
tension further reduces to the traditional "spline under tension" in the case of curves. 6.2. Discretization 
Expression (15) for the elastic force is continuous in the material coordinates of the deformable surface. 
For simu- lating the dynamics of the model, (15) can be discretized by applying finite element or finite 
difference approxima- tion methods [19]. Discretization transforms the partial differential equation 
of motion (1) into a system of linked ordinary differential equations. We illustrate the discretiza- 
tion step using standard finite difference approximations. The discrete representation of the unit square 
domain 0 < al,az < 1 on which the surface is defined is a regular M x N discrete mesh of nodes with horizontal 
and vertical inter-node spacings hi and h2. The nodes are indexed by integers [m,n] where 1 <_ m <_ M 
and 1 <_ n <_ N. We approximate an arbitrary continuous vector function u(al,a2) by the grid function 
u[m,n] = u(mhl,nh2) of nodal variables. The elastic force requires approximations to the first and second 
derivatives of the nodal variables. Given a grid function u[m, n], we first define the forward first 
difference operators D+(u)[m, n] =(u[m + 1, n] u[m,n])/hl -  (18) D + (t0[m , n] =(u[rn, n + 11 -u[m, 
n])/h2 and the backward first difference operators D~-(u)[m, n] =(u[m, n] - u[m -1, n])/hl (19)D; (u)[.~, 
~] =(u[.~,~] -ui.~,n -~])/h~. Using (18) and (19), we can define the forward and back- ward cross difference 
operators D+(u) [m, n] =D+l(u)[m, n] = D+(D+(u))[m,n],  (20) DS(u)[m,n ] =D;x(u)[m,n] = D;(D;(u))[m,n], 
and the central second difference operators Dn(u)[m,n] =D~(D+(u))[m,n], (21) D22( u)[m,n] =D2 ( D+ ( 
u) )[m,n]. Using the above difference operators, we can discretize the constitutive functions (16) and 
(17) as follows:  aijtm, n] =r/ij [m,n](D+(r)[m, n]. D+(r)[m, n] -- G,°.j [m, n]), fllj [m, n] = ~ij 
[m, n]( n [m, n]. D~ +) (r)[m, n] - B°j [m, n] ),  (22) where n[m, n] is the surface normal grid function 
and the (+) superscript indicates that the forward cross difference operator is used when i # j. The 
elastic force (15) can then be approximated by 2 e[m,n] = ~ -D:(p)[rn,nl + D~f)(q)[m,n], (23) i,j=l where 
p = ,~,j Ira, nlD+(r)[~, =1 and q = ~,~ Ira, nlD~ +~(r)@, %  (24) 3ump discontinuities will generally 
occur in the sur-face: for example, at its external boundaries. However, a free (natural) boundary condition 
can be simulated by setting to zero the value of any difference operator D + or D (+) in (24) involving 
r[m,n] on ij opposite sides of a boundary. If the nodal variables comprising the grid functions r[m, 
n] and e[m, n] are collected into the MN dimensional vectors g and e, (23) may be written in the vector 
form ~ = g(~)~ (25), where K(E) is an MN x MN matrix known as the stiffness matriz. Due to the local 
nature of the finite difference dis- cretization, K has the desirable computational properties of sparseness 
and bandedness. Consider, for simplicity, the case of time invariant mass density/1(a, t) = kt[a~,a2 
] and damping density 7(a, t) = 3'[al, a2] in (1). The resulting discrete densities are g[m, n] and 7[m,n]. 
Let M be the mass matriz, a diagonal MN x MN matrix with the #[m, n] variables as diagonal compo- nents, 
and let C be the damping matriz constructed slm- ilarly from 7[m, hi. The discrete form of the equations 
of motion (1) can be expressed in grid vector form using (25) by the following coupled system of second-order 
ordinary differential equations: 0Zr__ ~r M~-/-~ + C~ + K(r_)r__ = _fi (26) where f is the grid vector 
representing the discrete net external force. 6.3. Numerical Integration Through Time To simulate the 
dynamics of an elastic model, the system of ordinary differential equations (26) is integrated through 
time. We integrate these equations using a numerical step- by-step procedure, which converts the system 
of nonlinear ordinary differential equations into a sequence of linear al- gebraic systems. A time interval 
from t = 0 to t = T is subdivided into equal time steps At, and the integration procedure computes a 
sequence of approximate solutions at times At, 2At,..., t, t + At,..., T. Evaluating e at t + At and 
f at t, and substituting the (second-order accurate) discrete time approximations 02£ 0t z =(rt+a, -2r__t 
+ r__t_t,,)/At z   (27) br     ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 References 1. Armstrong, 
W.W., and Green, M., "The dynam- ics of articulated rigid bodies for purposes of anima- tion," Proc. 
Graphics Interface '85, Montreal, Canada, 1985, 407-415. 2. Barr, A.H., Geometric Modeling and Fluid 
Dynamic Analysis of Swimming Spermatozoa, PhD thesis, De- partment of Mathematical Sciences, Rensselaer 
Poly- technic Institute, Troy, NY, 1983.  3. Barr, A.H., "Global and local deformations of solid primitives," 
Computer Graphics, 18, 3, 1984, (Proc. SIC- GRAPH) 21-29. 4. Barzel, l:t.~ Dynamic Constraints, MSc 
thesis, De- partment of Computer Science, California Institute of Technology, Pasadena, CA, 1987. 5. 
Courant, R., and Hilbert, D., Methods of Mathe- matical Physics, Vol. I, Interscienee, London, 1953. 
 6. Dahlquist, G., and Bjorek, A., Numerical Meth- ods, Prentice-HM1, Englewood Cliffs, N J, 1974. 7. 
de Boor, C., A Practical Guide to Splines, Springer-Vedag, New York, NY, 1978. 8. do Carmo, M.P., Differential 
Geometry of Curves and Surfaces, Prentice-Hall, Englewood Cliffs, N J, 1974. 9. Faux, ,I.D., and Pratt~ 
M.J., Computational Ge- ometry for Design and Manufacture, Halstead Press, Horwood, NY, 1981. 10. Feynman, 
C.R., Modeling the Appearance of Cloth, MSc thesis, Department of Electrical Engineering and Computer 
Science, MIT, Cambridge, MA, 1986. 11. Fournier, A, and Reeves, W.T., "A simple model for ocean waves," 
Computer Graphics, 20, 4, 1986, (Proc. SIGGRAPH), 75-84.  12. Fung, Y.C., Foundations of Solid Mechanics, 
Prentice-Hall, Englewood Cliffs, N J, 1965. 13. Gelfand~ I.M.~ and Fomin, S.V., Calculus of Vari- ations, 
Prentice-Hall, Englewood Cliffs, N J, 1963. 14. Goldsteln~ H., ClassicalMechanics, Addison-Wesley, Reading, 
MA, 1950. 15. Immel, D.S., Cohen, M.F, and Greenberg, D.P, "A radiosity method for non-diffuse environments," 
Computer Graphics, 20, 4, 1986, (Proc. SIGGRAPH), 133-142. 16. Kajiya~ J.T., "The rendering equation," 
Computer Graphics, 20, 4, 1986, (Proe. SIGGRAPI-I), 143-150.  17. Kajiya, J.T., and yon Herzen, B.~ 
"Ray tracing volume densities," Computer Graphics, 18, 3, 1984, (Proc. SIGGRAPH), 165-174.  18. Landau, 
L.D., and Lifshitz, E.M., Theory of Elas- ticity, Pergamon Press, London, UK, 1959.  19. Lapidus, L., 
and Pinder, G.F., Numerical Solu- tion of Partial Differential Equations in Science and Engineering, 
Wiley, New York, NY, 1982.   20. Peachey, D.R., "Modeling waves and surf," Com-puter Graphics, 20, 
4, 1986, (Proc. SIGGRAPH), 65- 74. 21. Sederberg, T.W., and Parry, S.R., "Free-form deformation of solid 
geometric models," Computer Graph. ics, 20, 4, 1986, (Proc. SIGGRAPH), 151-160. 22. Stoker, J.J., Nonlinear 
Elasticity, New York, NY, 1968.  23. Terzopoulos, D., "Multilevel computational processes for visual 
surface reconstruction," Computer Vision, Graphics, and Image Processing, 24, 1983, 52-96. 24. Terzopoulos, 
D., "Regularization of inverse visual problems involving discontinuities," IEEE Trans. Pat- tern Analysis 
and Machine Intelligence, PAMI-g, 1986, 413-424. 25. Terzopoulos, D.~ "On matching deformable mod- els 
to images: Direct and iterative solutions," Topical Meeting on Machine Vision, Technical Digest Series, 
 Vol. 1~., Optical Society of America, Washington, DC, 1987, 160-167. 26. Well, J., "The synthesis of 
cloth objects," Computer Graphics, 20, 4, 1986, (Proc. SIGGRAPH), 49-54. 27. Wilhelms, J, and Barsky, 
B.A., "Using dynamic analysis to animate articulated bodies such as humans and robots," Proe. Graphics 
Interface '85, Montreal, Canada, 1985, 97-104. 28. Yaeger, L., Upson, C., and Myers, It., "Combin- ing 
physical and visual simulation --creation of the planet Jupiter for the film "2010"," Computer Graph- 
ics, 20, 4, 1986, (Proe. SIGGRAPH), 85-94. 29. Zienkiewicz, O.C., The Finite Element Method; Third edition, 
McGraw-Hill, London, 1977.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37428</article_id>
		<sort_key>215</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[Controlling dynamic simulation with kinematic constraints]]></title>
		<page_from>215</page_from>
		<page_to>224</page_to>
		<doi_number>10.1145/37401.37428</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37428</url>
		<abstract>
			<par><![CDATA[Theoretical and numerical aspects of the implementation of a DYNAmic MOtion system, dubbed DYNAMO, for the dynamic simulation of linked figures is presented. The system introduces three means for achieving, control of the resulting motion which have not been present in previous dynamic simulation systems for computer animation. (1) "Kinematic constraints" permit traditional keyframe animation systems to be embedded within a dynamic analysis. Joint limit constraints are also handled correctly through kinematic constraints. (2) "Behavior functions" relate the momentary state of the dynamic system to desired forces and accelerations within the figure. (3) "Inverse dynamics" provides a means of determining the forces required to perform a specified motion.The combination of kinematic and dynamic specifications allows the animator to think about each part of the animation in the way that is most suitable for the task. Successful experimental results are presented which demonstate the ability to provide control without disrupting the dynamic integrity of the resulting motion.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Measurement</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P221554</person_id>
				<author_profile_id><![CDATA[81414617707]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Isaacs]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell Univ., Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77037488</person_id>
				<author_profile_id><![CDATA[81406592138]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Cohen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell Univ., Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Armstrong, William W., and Green, Mark W., "The Dynamics of Articulated Rigid Bodies for Purposes of Animation," The Visual Computer, Vol. I, 4, Springer Verlag, December 1985, pp.231-240]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>319132</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Badler, Norman I., et el., "Multi-Dimensional Input Techniques and Articulated Figure Positionaing By Multiple Constraints," 1986 Workshop on Interactive 3D Graphics, Chapel Hill, North Carolina, October 1986~]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>578374</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Conte, Samuel D., and de Boor, Carl, Elementary Numerical Analysis, An Algorithmic Approach, (Third Edition), Mcgraw-Hill Book Company, New York, N.Y., 1980, pp.379-389.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Featherstone, R., "The Calculation of Robot Dynamics Using Articulated-Body Inertias," The International Journal of Robotics Research, Vol. 2, No. 1, Spring 1983, pp.13-30.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325244</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Girard, Michael, and Maciejewski, A. A., "Computational Modelling for the Computer Animation of Legged Figures," ACM COMPUTER GRAPHICS (Siggraph Proc. '85), July 1985, pp.263-270.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>319131</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Girard, Michael, "Interactive Design of 3-D Computer-Animated Legged Animal Motion," Ig86 Workshop on Interactive 3D Graphics, Chapel Hill, North Carolina, October 1986.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Hornbeck, Robert W., Numerical Methods, Quantum P u b l i s h e r s , New York, NY, 1 9 7 4 , pp.199-202.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Korein, James U., and Badler, Norman I., "Techniques for Generating the Goal-Directed Motion of Articulated Structures," IEEE Computer Graphics Applications, November 1982, pp.71-81.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Luh, J., Walker M., Paul R., "On-line Computational Scheme for Mechanical Manipulators," in Robot Motion, Planning and Control, edited by Brady et. el., M.I.T. Press, pp.89-i06.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806799</ref_obj_id>
				<ref_obj_pid>800224</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[O'Donaell, T.J., and Olson, Arthur J. "GRAMPS - A Graphics Language Interpreter for Real-Time, Interactive, Three-Dimensional Picture Editing and Animation," ACM COMPUTER GRAPHICS (Siggraph Proc. '81), August 1981, pp. 133-142.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Raibert, Marc H., et. al., "Experiments in Balance with a 3D One-Legged Hopping Machine," The International Journal of Robotics Research, Vol. 3, No. 2, Summer 1984, pp.75-92.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Stern, Garland, "Bbop A Program for 3-Dimensional Animation," Nico~raph '83 Proceedings, December 1983, pp.403-404.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>20331</ref_obj_id>
				<ref_obj_pid>20313</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Wilhelms, Jane, and Barsky, Brian. "Using Dynamic Analysis to Animate Articulated Bodies Such as Humans and Robots," Proceedings, Graphics Interface '85, May 1985, pp,97-I04.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Williams, R.J., and Seireg, A., "Interactive Modeling and Analysis of Open or Closed Loop Dynamic Systems with Redundant Actuators," Journal of Mechanical Design (Transactions of the ASME), Vol. I01, July 1979, pp.407-416]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Wittenberg, Jens, Dynamics of Systems of Rigid Bodies, B.G. Teubner, Stuttgart, Germany, 1977.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 CONTROLLING DYNAMIC SIMULATION WITH KINEMATIC 
CONSTRAINTS, BEHAVIOR FUNCTIONS AND INVERSE DYNAMICS Paul M, Isaacs and Michael F, Cohen Program of 
Computer Graphics, Cornell University Ithaca, New York, 14853 ABSTRACT Theoretical and numerical aspects 
of the implementation of a DYNAmic MOtion system, dubbed DYNAMO, for the dynamic simulation of linked 
figures is presented. The system introduces three means for achievin~ control of the resulting motion 
which have not been present in previous dynamic simulation systems for computer animation. (I) "Kinematic 
constraints" permit traditional keyframe animation systems to be embedded within a dynamic analysis. 
Joint limit constraints are also handled correctly through kinematic constraints. (2) "Behavior functions" 
relate the momentary state of the dynamic system to desired forces and accelerations within the figure. 
(3) "Inverse dynamics" provides a means of determining the forces required to perform a specified motion. 
 The combination of kinematic and dynamic specifications allows the animator to think about each part 
of the animation in the way that is most suitable for the task. Successful experimental results are presented 
which demonstrate the ability to provide control without disrupting the dynamic integrity of the resulting 
motion. I.0 INTRODUCTION The specification of motion for computer graphic sequences has traditionally 
been controlled explicitly by an animator. Motion occurs in the physical world, however, due to forces 
acting on objects which have shape and mass. The explicit control of traditional animation methods might 
be compared to utilizing a paint program for image creation, as opposed to simulating light propagation 
in an environment. To achieve the degree of .realism found in other areas of computer graphics, the motion 
of objects must be simulated by the physical principles of dynamics governing the motion. Permission 
to copy without fee all or part of this material is granted provided that the copies are not made or 
distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or SlXmific permission.  &#38;#169; 
1987 ACM-0-89791-227-6/87/007/0215 $00.75 There are good reasons that this has not yet occurred. The 
mathematical principles governing the motion of objects are both complex and computatlonally time consuming. 
Perhaps even more difficult is establishing some intuitive link between the parameters of a dynamic 
simulation and the resulting motion. For example, it is clear that to pick up an object we must move 
our hand from its current position to the object. It is much more difficult to describe the same motion 
through dynamics, i.e., as a series of forces and torques on joints of a skeletal structure. It is at 
this level, however, that the simulation must have its roots. The term "simulation", itself, rather 
t'han "animation", denotes a shift in control from the animator to the underlying physics of the environment. 
One would like a system for specifying motion which combines the realism of dynamic simulation without 
removing control from the animator. A DYNAmic MOtion system, dubbed DYNAMO, has been implemented to 
perform dynamic simulation on linked figures. In addition to performing dynamic simulation, the system 
contains three means for achieving control which have not been present in previous dynamic simulation 
systems for computer animation. (i) The imposition of "kinematic constraints" permits traditional animation 
systems to be embedded within a dynamic analysis. Motion of portions of the figure can be explicitly 
specified while allowing the remaining sections of the body to react to the dynamic forces created by 
this motion. Joint limits are also handled in a coherent means through kinematic constraints.  (2) The 
ability to define "behavior functions" allows the figure to react to its surroundings. Behavior functions 
relate the momentary state of the dynamic system to desired forces and accelerations within the figure. 
 (3) A process of "inverse dynamics" provides a means of determining the forces required to perform 
a specified motion. Thus, a previously specified action can be transformed into equivalent forces for 
development of behavior functions or evaluation of stresses within the linkage. The above mechanisms 
provide control without disrupting the dynamic integrity of the resulting motion.  After a short look 
at previous work in the field, % .  ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 theoretical and numerical 
aspects of the DYNAMO system are described. Simulations which have been run to date have provided some 
exciting results. These are briefly described following the system's description. After a concluding 
discussion, a derivation of the equations of motion is provided in the appendix. 2.0 FROM ANIMATION 
TO SIMULATION Computer animation methodologies can be characterized as belonging to one of three categories: 
Keyframe Animation, Procedural Animation, and Dynamic Simulation. 2.1 Keyframe Animation Keyframe animation 
is derived directly from traditional animation techniques in which the animator specifies what is to 
appear in each frame and thus explicitly specifies the "kinematics" or motion of the system. The computer 
adds efficiency by interpolating "in-between" frames from user supplied "keyframes" [I0|,[12]. Although 
this type of system gives almost complete control to the animator, it lacks the tools for creating dynamically 
correct sequences.  2.2 Procedural Animation Procedural methods rely on the computer's ability to determine 
the kinematics based on implicit instructions rather than explicit positions. One class of procedural 
methods is "inverse kinematics," where the motion of end links in a chain is specified by the animator, 
but the motion of interior links is determined algorithmicly [2],[5],[6],[8]. In Girard's work, some 
dynamic principals are invoked to enable the figure to interact with the ground plane in realistic ways. 
Although procedural methods have produced some of the best animation to date, they often lack dynamic 
integrity. 2.3 Dynamic Simulation General systems for dynamic simulation of linked figures have been 
described in recent literature relating to robotics and biomechanics as yell as computer graphics. Wilhelms 
and Barsky [13] describe a system for dynamic simulation similar to the one presented here, but without 
the incorporation of kinematic constraints and the associated control mechanisms. Armstrong and Green 
 [I] have also taken steps towards describing figure animation based on an alternative dynamic formulation. 
Williams and Seireg [141 have developed a system for simulating dynamic systems in order to study optimizing 
strategies for actuator forces. Development of robot machines through simulation relies heavily on similar 
principles. Experiments reported by Raibert [ii] of hopping and running machines reinforce the need for 
dynamic simulation methods. While based on a dynamic formulation, the methods presented in this paper 
provide a means to incorporate the three types of animation techniques within a single coherent system. 
Among the numerous texts on dynamics of jointed figures, Wittenberg [15] has been found to be of the 
most use for developing the DYNAMO system and many of the mathematical formulations in this paper are 
derived from it.  3.0 THE DYNAMO SYSTEM 3.1 Overview The dynamic simulation for this work was done 
using the DYNAMO system written in the C programming language at the Cornell University Program of Computer 
Graphics. The flow of control of the system is illustrated in figure I. positions, velocities, LiM I 
I]positions, ve]ocities, tlw I~r/~CJLL MODm. ~q31,YIB~IlY.AVIOB -GEOI4ETRY state-dependent accelerations 
-MASS state-dependent forces -CON~ECTtVITY -JOINT DOF -SP~IH6S. DAMPERS -JOINT CONSTRAINTS O1 MOTION 
BIBAgIORS -KEYFRANE~]TION -AL6ORITHI4~CMOTION  ii ~Lv, L -APPLIEDFORCES -ALGf]~ITHMICFORCES 'J P°sitiD°ns' 
velCfW°cities IllU ' L USER R~PUT ~, acceleraSP~tions~ y Large ~t=--'~'-~l = TOO Slal~ Figure 1 THE DYNAMO 
SYSTEM: FLOW OF CONTROL DYNAMO requires as input the physical and behavioral characteristics of a linked 
figure placed in an initial state. The physical model includes descriptions of all links and joints, 
as well as their connectivity. The initial state of the system contains the starting position and velocity 
of the links and an initial time. Behavior functions relate the current state of the system to external 
forces or to specified motion. The dynamic simulation is treated as an explicit time series analysis. 
A simultaneous solution is performed at each time increment for the accelerations of each degree of freedom 
of the system. These accelerations are integrated with the current state to determine a new set of positions 
and velocities. The solution is checked to see if any constraints have been exceeded and to see if the 
accuracy is within a tolerable range. If these tests are passed, the new state becomes the current state 
and the process is repeated for the following time increment. Time increments corresponding to frame 
times are recorded for display and playback.  (~) ~ Computer Graphics, Volume 21, Number 4, July 1987 
3.2 Links, Joints and Forces Each link has size, shape and mass and, thus, a center of gravity (COG) 
and a moment of inertia. The linkage for each figure forms a tree structure. Each link possesses one 
joint at which it is attached to its parent link and may possess one or more joints at which child links 
are attached. Links move relative to each other via one to six translational or rotational degrees of 
freedom, (DOF), associated with each joint. (figures 2,3) I DOF 2 DOF 3 DOF Pin Joint UmlverBal Jotnt 
B011 on¢~ Socket Joint @ Slidt n ~; Joint Cyllnd rlcdal Joint P[onQr Tro nllo%ion wlth One Rototlon 4. 
DOF 5 DOF 6 DOF Cylinci@r on o PIQn~ Flying OtpjeCt Figure 2: Types Of Joints DO\F 3 DOF I DO~ r \', 
~/1 I / ~ , \v,,'  °Do. .-. _//>" .a ~. Upp/er_Body Right_Leg ~ Lef t_Leg \ I I Head Left Arm RightArm 
Lower_Leg Lover_Leg Lower Arm Lower_Arm Left_Foot Right_Foot I I Left_Hand Right_Hand Figure 3 The 
Human Figure As A Linkage  Each joint may have associated springs and/or dampers which act to exert 
internal forces or torques within that joint. Joints may also have associated limits which act to keep 
the DOFs from moving beyond some point, e.g., the lower arm can bend only within a defined arc about 
the elbow. (figure 4) // TRANSLATIONAL LIMIT ROTATIONAL LIMIT Figure 4: Joint Limits  In addition, 
the linkage responds to externally applied forces . External forces can be specified as applied torques, 
point vector forces, or force fields. Most animate figures are actually driven by tensile forces caused 
by contraction of a muscle attached to the skeletal frame. Muscles can be modeled as physical entities 
attached to the links (figure 5). Muscle contractions apply equal but opposite tensile forces between 
adjacent attachment points. All forces are resolved into force/torque pairs acting at the link center 
of gravity. Orlglnal Mugcle Equivalent Force| Force/Torque Pal'rs Figure 5: Representation Of A Muscle 
 The links, joints, forces, and position and velocity of the DOFs form a complete description of the 
state of the dynamic system at any given time.   3.3 Dynamic Simulation The dynamic simulation for 
each time increment can be broken down into four phases. These are: ]) execution of the behaviors, 2) 
calculation of joint forces 3) formation of the equations of motion, and 4) matrix solution and evaluation 
of results.  3.31 Execution of Behavior Functions Behavior functions determine, at each moment, forces 
acting on a linkage and/or specific motion which is to occur. The forces or specified motion can be determined 
through any algorithm of the user's choosing, based on any currently available information about the 
state of the system (e.g. time, geometry, etc.) Examples of useful input and associated output for behaviors 
are illustrated in figure 6.  A behavior function's output can specify a single force or a force field 
such as gravity. Gravity's simple behavior function always exerts a downward force equal to the mass 
times the acceleration of gravity with its point of action at the center of gravity of each link. Contributions 
from a]] external forces are summed for each link into an aggregate force and torque vector expressed 
in the global or "inertial" spatial frame. Motion may also be output from a behavior function using 
time or other input parameters. The specified motion can be defined by keyframed paths which depend only 
on time, or by procedural means which may depend on other criteria. The user-designed behavior algorithms 
can make decisions in virtually any way, ranging from "begin  ~ SIGGRAPH '87, Anaheim, July 27-31, 
1987 c Behawlor. Dclrnplng gehuvlor: RaaGh]ng Hand BahavfoM Ke~rfr~med Puth Input: angular vuloulty. 
Inpuh poaltlane and Input: Path and time. Output: deaalarating veloolflul of X.O.O.D Output; Torquee 
at A,B,C Output: Auoe|,rQ~lon. ~orque. to reaah O x I c~r x =, alrff I : = X Behavior:. Gravity Input: 
Cllff edge, oor Iooatlon, oar veloolty. Input; Muse. Output: Braking forae. Oufp~4h. Downward forao. 
 Figure 6: Some Sample Behaviors  the keyframed motion of the car when the starting gun sounds" to "apply 
torques to all motors that will lift the right leg." In addition, these algorithms may be nested; thus 
one behavior function may invoke others, allowing for higher level behaviors such as walking. The mixture 
of specified forces and specified motion expressed through the behavior functions provides the combination 
of kinematic control and dynamic integrity.  3.32 Calculation of Joint Forces Given the current positions 
of the degrees of freedom, internal spring and damper forces are calculated through the equations: F(spring) 
= spring_k * offset_from_center position (Eq. I) F(damper) = damper_k * velocity of DOF (Eq. 2) where 
spring_k and damper_k are the spring and damper constants for that DOF. These equations are used for 
both translational and rotational DOFs. The resulting forces are summed into internal force and torque 
vectors for each joint.  3.33 Building the Equations of Motion. At this stage all the physical parameters 
have been determined. Thus, each creature may be regarded as a passive linkage moving in response to 
applied loads. The links and joints of a creature have a given position and velocity, and they are subjected 
to internal and external forces. The primary unknowns are the momentary accelerations of the DOF's (q") 
 A linear equation can be derived for each DOF relating the current state of the creature and the accelerations 
it undergoes to the forces which are acting on it. (Equations relating to DOFs with accelerations pre-specified 
by the behavior functions are eliminated. See section 3.4) The simplest view of this relationship is 
Newton's 2nd law, that force equals mass times acceleration. The series of equations can be written: 
 [A] h"J = ~J (Sq. 3) where: [A] is a generalized mass matrix. ~"] is a vector of the accelerations 
of each of the DOF's. ~J is a vector of force terms. The [A] matrix coefficients dependent only on the 
geometry and mass of the system. This includes the current configuration of all joints and links as well 
as the mass and moments of inertia of the links. The ~J vector includes terms for all applied forces 
as they relate to each DOF. A brief derivation for the equations of motion appears in the appendix. 
More details can be found in ~ittenberg [15].  3.34 The Equation Solution The set of simultaneous equations 
must be formed and solved for each time increment. A simple Gaussian elimination scheme works well. 
More efficient recursive schemes have been devised to replace the simultaneous equation solution outlined 
here. The recursive solutions have been shown efficient for the determination of motion from specified 
forces [4] or for finding actuator forces required to execute specified motion [9]. Unfortunately, they 
do not allow the combination of partial force and partial motion specification within the same linkage. 
This combination permits the control that is central to the DYNAMO system.  The solution provides the 
accelerations of the DOFs for the current time increment. From these accelerations and the current position 
and velocity of each DOF, new positions and velocities are calculated for the following time step. If 
constraints are exceeded during the time increment, their constraining accelerations are determined and 
explicitly specified, the constrained DOF's are removed from the system, and the time increment is repeated. 
 The size of the time increment is crucial to the accuracy and stability of the simulation since the 
geometric terms are assumed to remain constant throughout a time increment. If the geometry is changing 
rapidly, this assumption can quickly lead to inaccurate solutions. To overcome this problem without overburdening 
the machine by enforcing very small time increments, an adaptive time step sequence has been implemented 
(figure 1). A variation on a predictor correcter method [7],[3] allows the time step to vary based on 
momentary conditions of the stability of the equations. A starting sequence is achieved by more expensive 
Runge-Kutta methods for the initial three time increments to provide a history for following time steps. 
After the initial time increments, predictions for the positions and velocities of the DOFs are made 
for the following time step based on recent past history through a polynomia] extrapolation. The equations 
of motion are then formed from these "predicted" results and solved to find new accelerations for the 
same time step. The new accelerations are interpolated with past accelerations and integrated to find 
"corrected" results for the positions and velocities.  (~ ~ Computer Graphics, Volume 21, Number 4, 
July 1987 If the predicted positions agree sufficiently with the corrected results, then the time step 
is held constant. If they do not coincide, then the results are thrown out and the time increment is 
halved and repeated. If the agreement is very good, the result is kept and the increment is doubled for 
subsequent time steps. In this way the size of the time increment adapts to changing conditions throughout 
the simulation. At no time is the time increment allowed to exceed a frame time, i.e., 1/24th of a second. 
Results from time increments representing frames are recorded for later playback. 3.4 Kinematic Constraints 
and Inverse Dynamics If solving an equation for accelerations when the forces are given is called Forward 
Dynamics, then solving for forces when the accelerations are given can be called Inverse Dynamics. Since 
it is often difficult to think of motion in terms of the given forces, a system capable of performing 
both forward and inverse dynamics is desirable. Equation i, simply stated, is a relationship between 
geometry, acceleration, and forces. If all the values of matrix [A] are known, then there are really 
two ways to view the situation. Specify the force vector, B, and solve for the resultant accelerations: 
 q" = [A] -I B (Eq. 4: Forward Dynamics) or in the simpler case: specify the acceleration vector, (i.e., 
the kinematic constraints), solving for the forces that would cause such an acceleration: B = [A]q" (Eq. 
5: Inverse Dynamics) In mechanical engineering terms, one can specify a set of Force Boundary Conditions 
(the first case), or a set of Displacement Boundary Conditions (the second case). In addition, the whole 
problem does not have to be specified in only one way. Each degree of freedom can be given either a Force 
Boundary Condition or a Displacement Boundary Condition (a kinematic constraint), but not both. 3.41 
Kinematic Constraints A kinematic constraint consists of an explicit specification for the acceleration 
of some DOF during the current time increment, thus removing an unknown degree of freedom from the system. 
Kinematic constraints may arise in three ways: they may be prespecified by an animator as part of a prescribed 
sequence; they may come into effect only when some inequality is satisfied, such as when the maximum 
rotation of an elbow joint constraint is exceeded; or they may be invoked by a behavior based on current 
criteria in the system, (e.g., a ball stays in the hand after being caught until thrown). Vithin the 
context of the mathematical formulation, a kinematic constraint consists of removing a row and column 
from the system of equations. As an example, in a system with four DOF's, if the first and third are 
prescribed through kinematic constraints: A~ i A22 A2 3 A24 . A.. A.. A. 4 ~.J I A42 A43 A44 = B2 4 (X's 
(Eq. are unkno 6:) wn) The unknown DOF's, q~ and q~ can be solved for using the following general method: 
 A-- For each i where q[ is given, move all terms involving q~ to the right side by subtracting from 
the load vector the product of q~ and the i th column of the [A] matrix.  A22 0 A24 B2 ~21 ~23 -q:-q; 
 [i Elx A42 0 A44 4 ~'41 ~43 B-- Remove the rows and columns for each equation, i, for which an acceleration, 
q[ is prescribed. ['~t: 22 A¢aJ A24] ~ ] = qlq:]-[AA23*--43*] = LB [~: ]-FAA21*~-*II* qi 4~znew]new.,I 
C-- Solve the reduced s~stem for the unknown acc- elerations, q2 and q4" [qqi ] [~22 A21]-1 rl~-2newl 
= ~'42 A44 LD4newJ It is important to note that the new accelerations found by this method are, in a 
sense, a response to the given ones. This is because in step A, for each DOF with a prescribed force, 
a reactant force to the given accelerations is added to the original load. Hence, the solved motion is 
reactant to the prescribed motion. The specification of some portion of a figure's motion leaves the 
remaining DOF's free to respond to the constrained motion under the control of the dynamic simulation. 
The ability to prespeclfy some motion within a dynamically based model provides the animator with the 
power of dynamic simulation while maintaining the control found in traditional animation methods. Thus, 
keyframe techniques can be embedded within a dynamic simulation system. If all parts of the body are 
constrained then there are no unknowns and the system reverts completely to a traditional animation 
system. 3.42 Inverse Dynamics Continuing with the above example, once the unknown D0F accelerations 
have been found, the unknown forces can be found from the newly computed accelerations through inverse 
dynamics. A-- Substitute the new-found accelerations (q2 and q4) into the original equation (Eq. 6). 
 B-- For each DOF, i, with q~ originally given, mul- o tiply row i of [A] by the acceleratlon vector 
to find Binew, the unknown force. A specific desired motion can thus be converted to the equivalent 
set of forces. The reader may recall that in the original formulation of equation 12, values were found 
for B i of all degrees of freedom. These original B contained all known internally and externally ~ applied, 
centripital,  SIGGRAPH '87, Anaheim, July 27-31, 1987 I~~1 coriolis, and coupling forces. We can use 
this knowledge to our advantage, if we say that: Binew -B i = Factuator (Eq. 7)  for the DOFs with 
prescribed motion. Factuato[ is then the additional force that a motor or muscle would have to exert 
on that degree of freedom to bring about the prescribed q[. This permits the determination of robot actuator 
forces needed to perform a specified task or the forces within the joints of a hiomechanical system such 
as strain in a knee joint due to a given movement. The ability to mix forward and inverse Dynamics has 
two direct implications for animation purposes. First, a keyframing animation system may be directly 
embedded within a Dynamic system. The key visual elements of a sequence can be programmed by keyframing 
them while allowing the other elements to react to them. Secondly, knowledge of the actuator forces can 
greatly increase the ability to develop behavior functions. 4.0 RESULTS A series of short simulations 
has been performed to test the abilities of the DYNAMO system. The selected models were chosen in order 
to isolate various features which are of particular interest to the research effort being reported. Five 
experiments were conducted: a series of hanging chains, a tree blown by wind, a whip, a person on a swing, 
and an arm catching and throwing a ball. The computation for the following simulations was run on a 
DEC VAX 8700. The display was performed on an Evans and Sutherland Picture System 2. The computation 
time is inversely dependent on the time step needed to maintain accuracy within the solution and exponentially 
dependent on the number of DOFs.  # of DOFs CPU Minutes/Simulation Seconds CHAIN 6 0.35 TREE 39 14.00 
WHIP 9 0.77 SWINGER 4 0.21 CATCHER 6 1.43 KICKER 39 30.00 4.1A Series of Hanging Chains A series of 
hanging chains ranging from a simple suspended weight to a branching tree of chains were constructed 
(figure 7). A simple behavior function exerted a force field due to gravity. Each chain was given an 
initial configuration and allowed to swing unconstrained. The resulting motion was complex, as primary 
and secondary waves passed through the chains, illustrating the dynamic coupled force interactions between 
links. The effects of damping within the DOFs produces expected settling of the motion over time. 4.2 
A Tree Being Blown by a Time Varying Wind A tree was constructed as a branching set of links and joints 
(figure 8). Each joint had three rotational DOFs and associated springs and dampers. The tree was given 
a density, thus, the mass of each link was a function of its volume. The spring  and damper constants 
associated with each joint were described as a function of the cross-sectional area of the branch. A 
behavior for the wind exerted a time varying horizontal force on each branch as a function of the branch 
size. The simulation resulted in a very complex swaying motion portraying the various natural frequencies 
of each of the branches of the tree. The tree and branches swayed in response to the wind, to coupled 
reactions between parent and child branches and to their individual resonances. Thus, a very simple set 
of instructions based on natural parameters to both construct and act on the tree resulted in a complex 
motion sequence. 4.3 A Whip Driven by a Kinematically Controlled Arm A linear formation of links connected 
by one rotational degree of freedom formed an arm holding a whip (figure 9). The first two links represented 
the upper and lower arm, while the remaining links represented the whip. As in the tree example above, 
the diminishing size, mass and spring/dampers of each link and joint of the whip were parametrically 
determined from natural criteria. The motion of the two arm rotations were prespecified as kinematic 
constraints through standard keyframing techniques. The remaining links, the whip, were unconstrained 
and therefore reacted to the motion of the hand by whipping out and snapping. This example illustrates 
the combination of constrained and unconstrained motion and the complexity achieved by a relatively simple 
set of inputs. 4.4 A Swing A swing illustrates a familiar dynamics problem; how does one get a swing 
to go by kicking out and contracting one's legs and body? The problem was simulated using a simplified 
model of a body on a swing. (figure I0) A person on a swing gains height by rapidly rotating the body 
and lower legs about the seat at appropriate times, thus adding rotational energy to the system . A functional 
description of the rotation of the upper body and lower legs, in terms of the natural period of the swing, 
specified the kinematic constraints on the fly. After starting from an initial height, because of the 
body's pumping action, the swing did in fact gain height after each swing. This example illustrates how 
a simple behavior can be created without exact knowledge of the underlying physics to achieve a resulting 
motion with dynamic integrity. 4.5 An Arm Catching and Throwing a Ball This example consisted of a 
ball and a three link arm: upper arm, lower arm, and hand (figure II). The three arm joints had one rotational 
degree of freedom and the shoulder and elbow had associated springs and dampers. Each joint possessed 
different types of constraints, The elbow was constrained not to bend  (~ ~ Computer Graphics, Volume 
21, Number 4, July 1987 % 7 \  ~7 ~7 J 7 J f Figure 7: A Hanging Chain Figure 8: A Tree Swavin~ 
In The Uind I I % % J J %  Figure 9: A Whip Driven By A Kinematically Controlled Arm / / / J 1 Figure 
i0: A Swing \  Figure II: An Arm Catching And Throwing A Ball backwards. The hand was always constrained 
to move in the plane of the arm and was constrained to remain horizontal, thus the wrist had a positional 
move with the hand while in contact with it. constraint based on the unknown position of the shoulder 
and elbow. An actuator force (programmed to mimic a strong spring) was added to the shoulder from the 
time A hall completed the system. The ball was free to that arm became fully cocked until the ball was 
 ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 released. This additional force threw the ball back into 
the air. This same actuator exerted a damping force after the release of the ball to bring the arm smoothly 
back to rest in its original position. The results produced a very natural action arising from the variety 
of constraint types and a simple set of behaviors. The values of the wrist actuator torques were found 
by employing Inverse Dynamics. The required accelerations of the wrist to maintain the horizontality 
of the hand were determined during the dynamic simulation. After solving for all other accelerations, 
the actual torque on the wrist was calculated. Subtracting all other known torques on the wrist, the 
necessary actuator torque was found. Figure 12 shows a graph of the wrist actuator torques with time, 
as well as the shoulder spring and motor torques, which were given by forward dynamics. 7~.~ I I * I 
I * I i I i [ i i t , i I f i i ~ * I i i i i * [ i I i i WRIST I ~° Z " Arm is F",Jlly" Cocked. ACTUATOR 
TORQUE AcUvated as S~>r{ng B011 iS Releo~ed, 80{I is Caught \ /~. ^\ V I s.o~,a.. Moto, I-,~0 \ / \, 
/\ / / % Activated aS Damper 0.0 12,0 24,0 34~0 48,0 oo.o 72.0 i i i i , [ i i i , i I ' i i i , [ i 
~ , , , I ' i , , i [ , , , ~ iJ I z SHOULDER 30~O.0  ~o Boll is (Daught .f'" o ~0 coo .o, s" /"F"< 
- -Is0o.o Boll S Releosed ~ - "Motor Act|voted "as ~~ -~'~" MOTORTORQUE i f i , , I , ~ i J , I , , 
b , , i , i q i i [ i i ~ , , I i , i , , -I -4SO0.O 0.0 12.0 24.0 38.0 4[8.0 ~,0 7~0 FRAM[S (seconds/24) 
Figure 12: Torques In The Catcher Arm  4.6 A Man Kicking on Two Types of Floors This last example illustrates 
how inverse dynamics can be used to create behaviors which produce different sequences under different 
conditions. A man executing a kick was first animated with a keyframing system (figure 13a). Through 
inverse dynamics, DYNAMO found the actuator forces and torques needed to produce the same motion. Two 
subsequent runs of DYNAMO were then executed. In the first, these actuator force and torque values were 
used to drive the figure. As expected, the resulting motion was nearly identical to the original keyframed 
sequence. In the second (figure 13b), the horizontal forces between the foot and floor were removed, 
producing the conditions of a frictionless surface. The figure exerted the same pattern of forces on 
itself, but in a different environment. Since the horizontal support was gone and the figure was not 
perfectly balanced, the leg Figure 13a: A Man Executing A Kick Figure 13b: The Same Kick On A Frtctionless 
Floor slid out from under the hip as the figure executed the motion. 5.0 CONCLUSION A system for performing 
dynamic simulation of linked figures has been presented. The definition of the figures includes behavioral 
as well as physical characteristics. The behaviors cause the figures to react to their momentary state 
through the imposition of external or internal forces or through explicit specification of motion. The 
formulation of the equations of motion permits the imposition of kinematic and limiting constraints on 
the unknown degrees of freedom associated with each joint. An inverse dynamics procedure evaluates the 
equivalent force(s) which would be required to create the same motion as that specified by kinematic 
constraints. The dynamic simulation is run as an explicit time series analysis with predictor corrector 
methods maintaining accuracy and efficiency in the solution. A series of experimental runs of the DYNAMO 
system illustrating  the methods outlined in the paper have produced some exciting results and are reported 
in the previous section. The catcher-arm example illustrates one of the prime advantages of mixing kinematic 
and dynamic specifications through the behavior functions. It allows the user to think of each part of 
the animation in the way that is most suitable for the job: The motion of the hand is controlled visually 
--it is simply kept level. The ball and lower arm are passive links, each with simple constraints on 
their motions. Lastly, the torque in the shoulder is controlled through forward dynamics, by specifying 
the torque in the motor based on information about the state of the system. The behaviors, kinematic 
constraints, and inverse dynamics which were introduced in this paper provide control mechanisms to achieve 
a desired motion while maintaining dynamic integrity throughout the simulation. There remains a large 
body of related research to be done. The system was written in C, which requires that behaviors be compiled 
and linked with the simulation code. Higher level interpreted languages would be a natural choice to 
enhance the process of developing behavior functions. Additional desirable features which have not been 
(~ ~ Computer Graphics, Volume 2!, Number 4, July 1987 implemented to date include: the implementation 
of closed kinematic chains, behaviors that learn, collision detection between links, a more flexible 
user interface for defining linkages and behaviors, and the ability for figures to interact in parallel 
 through message passing, i.e. messages passed from behavior to behavior. The use of a muscle based model 
may aid modeling techniques by relating muscle tension and contraction to shape and size. The methods 
outlined in the paper should provide a base for further research for both the animator creating a particular 
motion sequence and the scientist simulating physical phenomena. 6.0 APPENDIX DERIVING THE EQUATIONS 
OF MOTION - The equations of motion are derived from D'Alembert's principle of virtual work [15], which 
states that if a system is in dynamic equilibrium and the bodies are allowed to move a small amount (called 
a virtual displacement) then the sum of the work of applied forces, the work of applied torques, and 
the work of internal forces will be equal and opposite to the work of changes in momentum. This is equivalent 
to saying that all work done in the system is accounted for. For a system of n links, D'alembert's equation 
is: (Eq. AI) ~i=~ ldr(Fili -mini )i + IdOiCMi- L~,~ +idWi] I =i0 _I I I I I Work of applied Work of 
applied Work of None forces minus torques minus internal left work of changes work of changes forces, 
over. in linear in angular momentum, momentum. where: dr i = virtual linear displacement of llnk number 
i (3d coordinate) F i = the total applied force through the COG of link i (coord) m i = the mass of 
link i (scalar) ri, r~, r~ = the linear position, velocity and acceleration of link i (coord) dO i = 
virtual angular displacement of link number i (coord) M = total applied torque on link i (coord) L) 
i = the change in angular momentum of link number i (coord), where: L~ = Ji" 81' + O~x Ji' O~ Ji = moment 
of~inertia tensor of link i (3x3 matrix) Oi, O~, 0[' = the angular position velocity and acceleration 
of of link i (coord) dW i = virtual work done by internal forces on link i (coord) (i.e., the work done 
by springs and dampers in joint i) D'Alembertrs equation is written in terms of variables for position 
(r) and orientation (e). If we treat this sum as a system of n independent linear equations, then each 
equation will have six unknowns: the linear acceleration in the x, y and z directions (r" , r" , r" ) 
and the angular acceleratlon about the th[-ee x y axes (e , e , e ). All other variables are calculated 
as ~nown quantities from the current state of the system,  except for the virtual displacements, which 
are later eliminated from the equations. This gives a total of (6 * n) unknowns If, instead, DrAlembert's 
principle is expressed in terms of the system's degrees of freedom, the total number of unknowns is reduced 
to total number of degrees of freedom, nDOF, vhich is typically much less than (6 * n), because most 
links have parent joints with fewer than six degrees of freedom. If the number of unknowns is not reduced 
in this way, then (6 -nDom) additional constraint equations would have to he written, one for each disallowed 
direction of motion. Thus, by formulating the equations in terms of the DOFs, the number of unknowns 
are reduced and the simulation runs more efficiently. In addition, the resulting motion is expressed 
in terms of the joint DOFs as they were constructed. To express the motion of the system in terms of 
the DOFs, four generalized coordinate vectors are used. Each vector has one entry for each DOF: q a 
vector of positions (either r or 8) q' a vector of velocities q" a vector of accelerations (unknowns) 
 and dq, a vector of virtual displacements Matrix equations describing each of the vector quantities 
dO, dr, 0", r", and dW in terms of generalized coordinates and other known quantities are derived: dO 
= _T T pT dq (Eq. A2) dr = [p x T(C + Z)T -kT] T dq (Eq. A3) 0" = _T T (pT q,, + f) + O0 (Eq. A4) 
r" = [p x T(C + Z)T -kT] T q" + U (Eq. A5) dW = -dq T (k.X + p.Y) (Eq. A6) and the following new (known) 
terms are introduced: T = matrix expressing connectivity of the system p = matrix of the unit axes 
of rotation of all rotational DOFs of the system. (zero for translational DOFs) C = matrix of distances 
from the joints to the COGs of the links which they connect Z = matrix of current displacement vectors 
along translational axes of freedom. (zero for ro- tational DOFs) k = matrix of partial derivatives 
of relative translation vectors with respect to each translational DOF. f = matrix of values relating 
angular velocity of one rotational DOF to a resulting angular acceleration of another DOF. O~ = vector 
of coordinates each equal to angular acceleration of inertial frame of reference. U = array of values, 
one per link, which relate its linear acceleration to known quantities in the system. X = vector of 
internal applied forces, one-per DOF. Y = vector of internal applied torques, one per DOF. [details 
can be found in Wittenberg, pages 147-163]  ~/~ StGGRAPH '87, Anaheim, July 27-31, 1987 All of these 
new terms above are calculated based on the pre-defined model of the system, the known values for q and 
q', and the current internally applied forces and torques. The derivation continues by substituting 
equations A2 through A6 into equation A1 to yield: dqT{ [p x T(C + Z)T -kT] {F - m|p x T(C + Z)T -kT] 
v q" - mU} -pT'{M - J'[-T v (pV q,, + f) + O,o] _ 8'x J'8'} -k'X -p'Y } = 0 (Eq. AT)  Isolating the 
terms involving q", we have: dq T (-A q" + B) = 0 (Eq. A8) where A = [p x T(C + Z)T -kT] m[P x T(C 
+ Z)T -kT] T + (pT)'J'(pT) T (Eq. A9) B = [p x T(C + Z)T -kT] (F -mU) -pT [M + J (T T f -O;) -O'xJ-e'l 
-k-X -p-Y (Eq. AIO)  Since the motion of all generalized coordinates is independent, the dq term from 
equation A8 can be removed, yielding the original equation 3: [A1 I_q"J = ~J Although the final form 
of the equations for A and B appear complicated, it should be stressed that all of the quantities are 
based on a relatively small set of very natural parameters (mass, size, type of joint, etc.). The only 
unknowns are q", and the only required user inputs are F and M, the applied forces and torques. A note 
on the coordinate systems used: When forming the A matrix and B vector, it does not matter which coordinate 
system is used to represent vectors in 3-space, so long as they are consistent. In DYNAMO, the final 
equation is calculated in the inertial (world) reference frame. In many cases, as with axes of a joint 
and moment of inertia tensors, it is convenient to store the variables in local coordinates and convert 
them into inertial coordinates as they enter the equations. 7.0 ACKNOWleDGEMENTS This paper would not 
have been possible without the input and support of our colleagues at the Cornell Program of Computer 
Graphics. Special thanks go to Donald Greenberg, for providing unlimited freedom and constant enthusiasm, 
to Stewart Feldman, for helping with the diagrams, to Dave Salmon and Jerome Hajjar, for their depth 
of knowledge and generosity with their time, and to Susan Morgenstein, for her inspiration. This research 
was conducted under grant No. DCR-8203979 from the National Science Foundation and was supported by generous 
equipment grants from the Digital Equipment Corporation and Hewlett-Packard. 8.0 REFERENCES  [i] Armstrong, 
William W., and Green, Mark W., "The Dynamics of Articulated Rigid Bodies for Purposes of Animation," 
The Visual Computer, Vol. I, 4, Springer Verlag, December 1985, pp.231-240 [2] Badler, Norman I., et 
el., "Multi-Dimensional Input Techniques and Articulated Figure Positionaing By Multiple Constraints," 
1986 Workshop on Interactive 3D Graphics, Chapel Hill, North Carolina, October 1986 [3] Conte, Samuel 
D., and de Boor, Carl, Elementary Numerical Analysis, An Algorithmic Approach, (Third Edition), Mcgraw-Hill 
Book Company, New York, N.Y., 1980, pp.379-389. [4] Featherstone, R., "The Calculation of Robot Dynamics 
Using Articulated-Body Inertias," The International Journal of Robotics Research, Vol. 2, No. 1, Spring 
1983, pp.13-30. |5] Girard, Michael, and Maciejewski, A. A., "Computational Modelling for the Computer 
Animation of Legged Figures," ACM COMPUTER GRAPHICS (Siggraph Proc. '85), July 1985, pp.263-270. [6] 
Girard, Michael, "Interactive Design of 3-D Computer-Animated Legged Animal Motion," Ig86 Workshop on 
Interactive 3D Graphics, Chapel Hill, North Carolina, October 1986. [7] Hornbeck, Robert W., Numerical 
Methods, Quantum Publishers, New York, NY, 1974, pp.199-202. [8] Korein, James U., and Badler, Norman 
I., "Techniques for Generating the Goal-Directed Motion of Articulated Structures," IEEE Computer Graphics 
Applications, November 1982, pp.71-81. [9] Luh, J., Walker M., Paul R., "On-line Computational Scheme 
for Mechanical Manipulators," in Robot Motion, Planning and Control, edited by Brady et. el., M.I.T. 
Press, pp.89-i06. [lO]O'Donaell, T.J., and Olson, Arthur J. "GRAMPS -A Graphics Language Interpreter 
for Real-Time, Interactive, Three-Dimensional Picture Editing and Animation," ACM COMPUTER GRAPHICS (Siggraph 
Proc. '81), August 1981, pp. 133-142.  [ll]Raibert, Marc H., et. al., "Experiments in Balance with a 
3D One-Legged Hopping Machine," The International Journal of Robotics Research, Vol. 3, No. 2, Summer 
1984, pp.75-92. |12]Stern, Garland, "Bbop A Program for 3-Dimensional Animation," Nico~raph '83 Proceedings, 
December 1983, pp.403-404. [13]Wilhelms, Jane, and Barsky, Brian. "Using Dynamic Analysis to Animate 
Articulated Bodies Such as Humans and Robots," Proceedings, Graphics Interface '85, May 1985, pp,97-I04. 
 |14|Williams, R.J., and Seireg, A., "Interactive Modeling and Analysis of Open or Closed Loop Dynamic 
Systems with Redundant Actuators," Journal of Mechanical Design (Transactions of the ASME), Vol. I01, 
July 1979, pp.407-416 [15]Wittenberg, Jens, Dynamics of Systems of Rigid Bodies, B.G. Teubner, Stuttgart, 
Germany, 1977.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37429</article_id>
		<sort_key>225</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[Energy constraints on parameterized models]]></title>
		<page_from>225</page_from>
		<page_to>232</page_to>
		<doi_number>10.1145/37401.37429</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37429</url>
		<abstract>
			<par><![CDATA[A simple but general approach to imposing and solving geometric constraints on parameterized models is introduced, applicable to animation as well as model construction. Constraints are expressed as energy functions, and the energy gradient followed through the model's parameter space. Intuitively, energy constraints behave like forces that pull and parametrically deform the parts of the model into place. A wide variety of geometric constraints are amenable to this formulation, and may be used to influence arbitrary model parameters. A catalogue of basic constraints is presented, and results are shown.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P18516</person_id>
				<author_profile_id><![CDATA[81100295587]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Witkin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Schlumberger Palo Alto Research, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39071844</person_id>
				<author_profile_id><![CDATA[81332499016]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kurt]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fleischer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Schlumberger Palo Alto Research, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P12238</person_id>
				<author_profile_id><![CDATA[81100070192]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Alan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Barr]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology, Pasadena]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[William W. Armstrong and Mark W. Green, The dynamics of articulated rigid bodies .for purposes of animation, in Visual Computer, Springer-Verlag, 1985, pp. 231-240.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808573</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Alan H. Barr, Global and Local Deformations of Solid Primitives, Proe. SIGGRAPH, 1984, pp. 21-29,]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Ronen Barzel and Alan It. Barr, Dynamic Constraints, to appear.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Kurt Fleischer and Andrew Witkin, The SPAR modeling testbed, to appear.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>540426</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[William C. Gear, Numerical Initial Value Problems in Ordinary Differential Equations, Prentice-ttall, Englewood Cliffs, N J, 1971]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Michael Girard and Anthony a Maciejewski, Cornputataional Modeling for the Computer Animation of Legged Figures, Proc. SIGGRAPH, 1985, pp. 263 270]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Michael Kass, Andrew Witkin, and Demetri Terzopoulos, Snakes: Active Contour Models, Proc. International Conference on Computer Vision, 1987.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806803</ref_obj_id>
				<ref_obj_pid>800224</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[V. C. Lin, D. C. Gossard, and R. A. Light, Variational Geometry in Computer-Aided Design, Proc. S{GGRAPH, 1981, pp. 171-178]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325241</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Greg Nelson, Juno, a constrait~t-based graphics ~y~tent Computer Graplffcs, Vol. 19 No. 3, July 1985, pp. 235- 243.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Thomas W. Sederberg and Scott R. Parry, Free-Form Deformation of Solid Geometric Models, Proc. SIG- GRAPH, 1986, pp. 151-160.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Scott N. Steketee and Norman I. Badler, Parametric Keyfvame Interpolation Incorporating Kinetic Adjustment and Phrasing Control, Proc. SIGGRAPII, 1985, pp. 255-262.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Demetri Terzopoulos, John P l a t t , Alan Barr, and Kurt Fleischer, Elastically Deformable Models, Proc. SICGRAPH, 1987.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Jane Wilhehns and Brian Barsky, Using Dynamic Analysis To Animate Articulated Bodies Such As Humans and Robots, Graphics Interface, 1985.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 21, Number 4, July 1987 ] Energy Constraints On Parameterized Models Andrew 
Witkin~ Kurt Fleischer~ Alan Barr~ t ~Schlumberger Palo Alto Research, 3340 Hillview Avenue, Palo Alto, 
CA 94304 :~California Institute of Technology, Pasadena, CA 91125 Abstract A simple but general approach 
to imposing and solving geometric constraints on parameterized models is intro- duced, applicable to 
animation as well as model construc- tion. Constraints are expressed as energy functions, and the energy 
gradient followed through the model's parame- ter space. Intuitively, energy constraints behave like 
forces that pull and parametrically deform the parts of the model into place. A wide variety of geonmtric 
constraints are amenable to this formulation, and may be used to influ- ence arbitrary model parameters. 
A catalogue of basic constraints is presented, and results are shown. Keywords --Constraints, Modeling, 
Animation I. Introduction A widely-used approach to modeling is to combine geo-metric primitives--such 
as cylinders, blocks, and bicubic patches--with a variety of operators--such as translations, rotations, 
booleans, and deformatlons--to form a model hierarchy. The task of constructing a model within this framework 
has two parts: building the hierarchy, and set-ting the internal parameters of the prinfitives and opera- 
tors. Experience tells us that the second task is usually by far the more diflqcult and time-consuming, 
particularly when complex operators such as deformations are used. As the complexity of the model increases, 
the number of pa- rameters becomes large, and they tend to interact in ways that make the model difficult 
to control. The user knows at the outset what the objects be-ing modeled are supposed to look like--how 
the pieces are supposed to fit together and move. The difficulty lies in finding settings of the parameters 
that achieve the desired effect. The utihty of hierarchic modefing systems would be greatly enhanced 
if this tedious process could be per- formed automatically, permitting the user to state in terms Permission 
to copy without fee all or part of this material is granted provided that the copies are not made or 
distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. of constraints 
the properties the model is supposed to have, without the need to manually adjust parameters to give 
it those properties. In this paper we present a simple but general ap-proach to expressing and solving 
constraints on param-eterized model hierarchies. We formulate constraints as "energy" functions on the 
model's parameter space, non-negative functions with zeroes at points satisfying the con- straints. We 
then sum the constraints' energy functions to create a single scalar function of the parameters, and 
move through parameter space to minimize the energy. We refer to the constraint functions as energy func-tions 
not because they always model the energy of ac-tual physical systems, but because they play a role similar 
to that of physical energy fimctions during the constraint solving process. For example, an energy constraint 
attach- ing points on the surfaces of two objects acts much like a spring that pulls the objects together. 
However, in addi- tion to translating and rotating, the objects are free to vary their internal parameters, 
so, for example, a cylinder may vary its length or radius to meet the constraint. Although no fanfiliar 
physical material deforms in this stylized way in response to applied forces, it is easy enough to imag-ine 
an unphysic&#38;l material that does. Since we are using the energy analogy as a mechanism for building 
models, rather than for sinm|ating physical phenomena, this kind of non-physical behavior poses no problem. 
Our approach provides: Self.assembling models, whose parts move and deform parametrically from an ilfitial 
configuration to one that satisfies the specified constraints.  Animated models that, once assembled, 
may move in response to time-varying constraints while continuing to satisfy static ones.  Oenerality 
and modularity: we can formulate a wide range of constraints as energy functions, and use them to influence 
arbitrary model parameters. To imple- ment a new constraint we need not know the details of other constraints, 
nor of the primitives and operators to wtfich they will be applied. Sinfilarly, new parame- terized prinfitives 
and operators may be implemented without modifying existing constraints.  Additivity: Energy fimctions 
compose by addition. The solution to a system of constraints is the so-  &#38;#169; 1987 ACM-O-89791-227-6/87 
/O07 /0225 $00.75 ~'~~ SIGGRAPH '87, Anaheim, July 27-31, 1987 lution to a single equation, the sum of 
the energy terms. This property is particularly valuable in deal- ing with overdetermined systems. While 
conventional algebraic methods return no solution to an overdeter- nfined system, the energy minimum 
is a "compronaise" that is sometimes acceptable, nearly always informa- tive, and often easily repaired. 
Interactive control: since we satisfy constraints by moving ttlrough a curve in parameter space, the 
initial constraint solving process can itself be animated, per- nfitting the user to assist the solver 
in escaping local energy minima, resolving ambiguities, etc. A significant body of work in constraint-based 
and dy- uanlics modeling for colnputer graphics is concerned with the the specialized problem of animating 
articulated bod- ies, particularly hmnan and animal forms. These include Armstrong and Green, [1], Girard 
and Maciejewski, [6], and Wilhehns and Barksy [13]. Nelson's Juno editor em-ploys non-linear geometric 
constraints in the context of a 2-D image editor. Dynanffc models of elastic bodies for computer graphics 
are treated by Terzopoulos et al. in [12]. Closest to ours in approach are Barzel and Barr's dy- nauric 
constraints [3], although their current work focuses on constraining ttle motion of rigid bodies.  II. 
Energy constraints A model hierarchy is a tree that defines the model's geom- etry through a collection 
of mathematical functions, three of wlffch will concern us here. These are a parametric posi- tion function, 
la(u, v) that returns a 3-space point for each (u,v) pair, a surface normalfunction, N(u,v), that returns 
a surface normal vector, and an irttplicit or inside-outside function, I(X), that returns a scalar given 
a 3-space point, such that I = 0 for points on the object's surface, I < 0 for points inside the object, 
and 1 > 0 for points outside the object. One such collection of functions is defined for each leaf iu 
the tree, and represents tile combined effects of the prinfitive at the leaf and of all the operators 
on the path from that leaf to the root. Defiuitions of these functions are given in Appendix A. In generM, 
each primitive or operator possesses some real-valued paraineters, for instance the radius of a sphere, 
a translation vector, or the bend angle of a parameterized deformation. The position, normal and implicit 
functions each depend on these parameters: when they change, ob- jects' surfaces move. We refer to the 
union of all these parameters as ~I'. Once the hierarchic structure is fixed, the state of the model 
is completely determined by the v.-fiue of ~I'. The notion of parameter spaces, and of mo- tion along 
curves through parameter space, is fanffliar in computer graphics in the context of keyframe interpolation 
(see, e.g. [111.) We will express geometric constraints in terms of the functions P, N, and I. For instance, 
if we wish to attach two surface points P~(ui,v~) and P2(u2,v2), at least one condition we must satisfy 
is Pl = P2-A solution is a value of ~ such that all the imposed conditions are met. Rather than solving 
the constraint equations alge-braically, we formulate constraints as energy fimctions, and move through 
parameter space according to the energy gradient. In general, to formulate an energy constraint, we must 
construct a non-negative smooth function E('I') such that E((P) = 0 at all and olrly values of 'I' for 
which the constraint is satisfied. The solutions to a set of n con-straints are values of such that 
it E(~) y~ E,(~) o, i so to combine constraints, the corresponding energy terms are simply summed. We 
are free to express E in terms of position, normal, or implicit functions, or any other quan- tities 
that may be extracted from the model tree. Intuitively, energy constraints may be viewed as "forces" 
ttlat pull the parts of the model into the desired configuration and hold them there, although they are 
not necessarily intended to be physically realistic forces. For instance, a simple attachment constraint 
nffght be imple- mented as a spring connecting the points, in which case we have E.,,,.;,~,, = ,~ IP~(u~,v~) 
-~(~2,w_)l-", where ~ is a spring constant, and the "force" vector in parameter space is ~TE.p,.i,,j. 
From an initial condition @0, the energy E is mini- mized by numerically solving the differential equation 
dF(t)/dt-rE, F(0) = ~0, for a fixed point of the parameter-space curve F(t), i.e. a point at wtffch VE 
= 0. The solution is a local mini- mum, Mthough it is not guaranteed to be a zero. Tiffs is a steepest 
descent method for solving ~TE -0. A variety of standard numerical methods may be used to solve the energy 
equation. The simplest of these, Euler's method, has F(~;~I) -F(t) + h~TE, with h the step size. More 
sophisticated methods, such as Gear's method [5] should be used to obtain accurate, reliable results. 
Any solution method requires evaluation of ~TE. To do so, the suunned energy must be differenti- ated 
with respect to each model parameter, which may be done numerically by varying each parameter in turn, 
re-evaluating E, and taking differences. The structure of the tree may be used to avoid the needless 
expense of differen- tiating energy terms with respect to parameters on which they do not depend. A limitation 
of the method is that it may be trapped at spurious (i.e. non-zero) local minima of E. Our solution to 
this problem is user interaction. Such minima are usu-ally easy to interpret geometrically, e.g. a single 
part has become stuck or been turned backwards. Presented with a bad answer, the user can often correct 
the situation by  (~ ~)' Computer Graphics, Volume 21, Number 4, July 1987 manually repositioning a 
part. In fact, with fast enough rendering to view the evolving solution dynamically, the user can literally 
push or pull on parts of the model with a pointing device, introducing a time-varying energy term, E~ 
.... into the equation, to bump it out of local minima. This style of user interaction has been used 
to good effect in interactive image interpretation [7]. A different form of user control is obtained 
by selectively freezing and un-freezing model parameters, to decompose a larg~ problem into a sequence 
of smaller ones. III. A catalogue of useful constraints A wide range of geometric constraints may be 
cast in the form of energy functions. Here we list a few basic con-straints, most of which are used in 
the examples to follow. Many are subject to alternative formulations. Each energy function is multiplied 
by a weighting factor; these factors are not shown below. Attachment to a fixed point in space: The energy 
term E = IP"(u~,v,~) - ql 2 attaches a specific point on the surface of object a, defined by parameter 
point (u,, v,~), to a specific point in space, Q. Surface-to-surface attachment: Place specified points 
on two surfaces in contact. To acheive contact, the points must coincide. In addition, their tangent 
planes at those points must coincide, and the surfaces should not (locally) interpenetrate. These conditions 
can be encoded by E = IP"(u,~,v,,)-Pb(u~,v~)[ 2 + N"(u~,v,). Nb(ub,vb) + 1, where pa and pb are the positions 
at the two attach- ment points, and N" and N b are the unit surface nor- reals at those points. This 
function is zero when the points coincide and the dot product of the normals is --]., Floating attachment: 
Attach a specified point on an object to some point on a second object, allow- ing the point of contact 
to slide freely on the second object. Our implementation of this constraint is sim- ilar to that for 
simple surface-to-surface attachment, but uses the second object's implicit function instead of its parametric 
position function: E = Ib(P"(u,,,v,,)) ~" + VI ~ N"(u,,,v,,). lWib I + 1, noting that KrIt'/]VII is a 
unit normal to surface b where I b = 0. A useful variation is double floating attachment, in which both 
points float on their re-spective surfaces. Slider constraint: Constrain a specified point on an object 
to a line in space: E = PLD(Pa(u,,,v,,),P1,P.,) 2, where PLD is the polnt-to-llne distance function, 
and P1 and P2 are points on the line. Useful variations constrain the point to a line segment, or constrain 
two line segments to be colinear and to overlap (like seg- ments of a telescope.) Collision using the 
implicit function: For ob- jects possessing inside-outside functions, interference or collision constraints 
may be imposed without cal- culating surface intersections. The implicit function is zero everywhere 
on the object's surface, and, by our convention, negative inside and positive outside the object. To 
impose an anti-interference constraint, we transform the implicit function into a thin repulsive "force 
field" surrounding the object. At a single point, P'~(u,,,v,,) on object a, a suitable energy function 
is .~ = c--~ib(P'(u.,va)) where ~ is a positive scale factor. This makes the energy high inside object 
b, tending to zero far from object b. Thus a point inside the object is repelled, the repulsion approaching 
zero off the object's surface. To implement a general interference constraint, this function must be 
integrated over u and v. An efficient implementation must make use of intelligent sampling, hierarchic 
bounding boxes, etc., which are beyond the scope of this paper. Direct constraints on parameters: It 
is some- times useful to impose constraints directly on model parameters, for instance to establish default 
values, or to constrain relations among parameters. If a is some model parameter, then a defaulting constraint 
m~ty be written as E = (or -a0) 2, where a0 is the' default value. If a and/3 are two model parameters, 
then a linear relational constraint may be written as E = (a -kl/3 - k,_) 2, which says that the linear 
rela- tion a = klfl + k2 should hold between a and/3. For instance, if we want one rod to be twice as 
long as another, we have E = (l] -212) ~', where 11 and 12 are the lengths of the rods.  IV. Examples 
This section presents three examples of the use of energy constraints to build and animate models. The 
first, a rela- tively simple one, is described in detail as a concrete illus- tration of the method. 
The second and third are described more briefly. Pipefitting: A simple example illustrating self- assembly 
and adjustment of a variety of model parameters ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 la~®~e~l is 
shown in figure 1. A cylindrical pipe, subjected to a translation, a rotation, and a parameterized bend 
is to be fitted to other pipes at either end. All other parts of the model have already been assembled, 
and their parameters frozen. The model hierarchy for the adjustable tube is de- scribed schematically 
by Trans(Rot(Bend(Tube))): A tube is a primitive, whose axis is coincides with the x-axis in model space, 
and whose dimensions are controlled by three parameters --length, radius, and thickness.  A bend (after 
[2]) is a parameterized deformation that maps the ~-axis into a circular arc in the x, z plane. Its effect 
on shape is controlled by three parameters-- start, stop, and amount. Start and stop determine the "tightness" 
of the bend, and amount is the angle between the ends of the curved axis.  A quaternion rotation is 
specified by a 4-vector. Al-though any rotation may be specified by three Euler angles, we use quaternions 
to avoid gimb~ lock.  A translation is specified by a 3-vector of x, y, and z displacements.  The 
union of these parameters, ~, is a 13-dimensional vector. Motion along a curve through q'-space corresponds 
to some combination of bending, translating, rotating, and changing the tube's dimensions. Despite the 
simplicity of the example, this means that we have to come up with 13 independent numbers to pin down 
the model in the desired configuration. Doing this manually, or writing a special purpose program to 
do it, would have been unpleasant. For our purposes, two pipes are attached if their axes join smoothly 
and they have the same radius and thickness. An "attach-pipes" (AP) energy constraint may be built by 
combining a surface-to-surface attachment constraint, as defined in the previous section, with relational 
constraints that make the radii and thicknesses agree. Let P1 and Pz be the endpoints of the two pipes' 
axes, i.e. the points to be joined, and let Nt and N_~ be two unit vectors extending outward from the 
axis endpoints in a direction tangent to the axes. Then we want P1 = P~_ and N, .N~ = 0. Additionally, 
we want el = v2 and tl -t2 for the radii and thicknesses. In energy form, this gives us EAp = ]Pl --P.~l 
"~ + Na Nz + 1 + (r~ -re) 2 + (ta -1_,) -9. To attach both ends of the moving pipe, we have as the total 
energy the sum of two terms of this form. Prior to bending, rotation, and translation, the end- points 
of the moving tube's axis are situated at the points Pa = (length/2,0,O), and P9 = (-length/2,0, O), 
with unit normals N~ = (1,0,0) and N2 = (-1,0,0) point-ing outward from the ends. The two fixed pipes 
to which the moving one is to be attached each have a sinfi- larly defined endpoint and normal, which 
are constants. The transformed endpoints are Trans(Rot(Bend(P,))) and TTans(Rot(Bcnd(P2))), respectively, 
so their posi-tions in model space depend on all the model parame-ters except radius and thickness. Using 
the fact that sur-face normals transform under deformations by multiplica- tion with the inverse transpose 
of the deformation's ja-cobian ([2]), the transformed normals are Rot(J[~,tN, ) and ttot(j~!TtN,),,.,, 
where d -tTn,.~,,,,l is the inverse transpose . of the bend operator's jacobian, evaluated at P1 and 
P~. respectively (see [2] for the formula.) To solve the constraints, we solve the equation ,~@(t) = 
VE from a starting point @(t0), until we reach a point at which VE < ~, where e is a small tolerance 
value. At any point in parameter space, we can evaluate P1, Pz, N1, and N2, and hence the energy function 
defined in terms of them. To compute VE munerically, we first evaluate E at the current ~, then add a 
small A to each parameter (i.e. each component of ~) in turn, re-evaluate E and subtract the central 
value of E, obtaining the cor-responding component of VE. Using Euler's method the new value of ~ is 
given by ~'t+a = q2, + hVE, where h is a step size. Figure 1 shows the model at the initial condition, 
at several steps toward the solution, and at the solution. Fi-nally, we show a new solution obtained 
when one of the fixed pipes is moved. Oldham linkage: An oldham finkage is used to trans- fer rotation 
between shafts that are offset in a plane per- pendicular to their axes, by means of a system of tongues 
and grooves. Figure 2 shows several frames from the self-assembly sequence for an oldham linkage, and 
several frames from an animation sequence. The specification of this mechanism involved a variety of 
constraints, including sliders, surface-to-surface contact, and position and ori-entation constraints. 
This example illustrates the use of energy constraints both for assembly and for animation of the assembled 
model. Cam and rocker arm: This example (figure 3) shows an already-assembled cam and rocker arm at several 
points in its cycle. This is a working model: the pressure of the spring on the valve head pushes the 
follower against the cam via the fulcrum. The follower "feels" the cam using an implicit-function interference 
constraint, so that if the cam were reshaped, the motion of the arm would change accordingly. V. Conclusion 
 Energy constraints were shown to provide an effective means of building and controlling parameterized 
models. A principle advantage of the energy method is its gener- ality: it does not depend on the details 
of the constraints used or the models to which they are applied. It is tolerant of over- and under-determined 
systems, and amenable to user interaction. Among its disadvantages, it can be nu-merically intensive--particularly 
when the equations be-come stiff--and it can be trapped in local minima. The  (~ ~ Computer Graphics, 
Volume 21, Number 4, July 1987 second difficulty is largely overcome by effective user in-teraction. 
Appendix A In this appendix we define the position, normal and im- plicit fnnctions in terms of the structure 
of the model tree. Our definition describes the SPAR modeling testbed [4], but is typical of hierarchic 
modelers in most relevant re-spects. Each leaf in the tree represents a primitive. The root is a camera, 
and the intermediate nodes represent op- erators. We denote the leaves by L i, and the n nodes on the 
ascending path from leaf L i to the camera as 0 Lj, where 0 i'l is L i, 0 i'~- is the first operator 
above L i, and Oi,n is the camera. (When we refer to the objects comprising the tree without regard to 
the paths they lie on, we index them as 0;.) For the purpose of sampling and rendering, each such path 
defines a distinct object, characterized by a coordinated bundle of mathematical functions. These include: 
A parametric position fnnction, P;(u,v), ~-~ ~ ~3 defined recursively by Pi(tL, v) = pi"'(u,v), Pi'J(u,v) 
= Ti'J(Pi'J-a(u,v)),j # l, pi'l(u,v) = pL'(u,v), where T i'5, ~.3 ~ ~3 is associated with operator 0 
i'j, defining the transformation it performs, and pL' is the prinfitive position function associated 
with L ~. By convention, the domain of P is the unit square 0 < u < 1, 0 < v < 1. In words, the primitive 
L* generates 3- space positions on the object's surface as a function of u and v, and each operator transforms 
those positions. A parametric normal function, Ni(u,v), similar to the position function but generating 
surface normals. Tiffs is defined by N'(~,v) = N~"~(~,v), Ni'J(u,v) = Ni'J-I(u,v)J-1T(Ti'j),j # 1, oPLI(u,v) 
oPL'(u,v) NZA(U,V) --× Ou Ov ' where 3 -IT is the inverse transpose of the Jacobian nmtrix [2]. An implicit 
(inside-outside) function, I~(X), ~3 ~, such that the solution to Is(X) = 0 is the same surface defined 
by pi. The implicit function is defined recursively by ~(x) = I~"(x), Ii'/(X) = I i'j 1((Ti'J)-I(X),j 
# 1, /i'l(x ) ~-/'L' (X), where T -1 is the inverse of T, and I/; is the pritfiitive implicit function 
associated with L i. References [1] William W. Armstrong and Mark W. Green, The dy- namics of articulated 
rigid bodies .for purposes of an- imation, in Visual Computer, Springer-Verlag, 1985, pp. 231-240. [2] 
Alan H. Barr, Global and Local Deformations of Solid Primitives, Proe. SIGGRAPH, 1984, pp. 21-29, [3] 
Ronen Barzel and Alan It. Barr, Dynamic Con-straints, to appear. [4] Kurt Fleischer and Andrew Witkin, 
The SPAR mod- eling testbed, to appear. [5] William C. Gear, Numerical Initial Value Problems in Ordinary 
Differential Equations, Prentice-ttall, En- glewood Cliffs, N J, 1971 [6] Michael Girard and Anthony 
a Maciejewski, Corn-putataional Modeling for the Computer Animation of Legged Figures, Proc. SIGGRAPH, 
1985, pp. 263 270 [7] Michael Kass, Andrew Witkin, and Demetri Ter-zopoulos, Snakes: Active Contour Models, 
Proc. In-ternational Conference on Computer Vision, 1987. [8] V. C. Lin, D. C. Gossard, and R. A. Light, 
Vari-ational Geometry in Computer-Aided Design, Proc. S[GGRAPH, 1981, pp. 171-178 [9] Greg Nelson, Juno, 
a constrait~t-based graphics ~y~tent Computer Graplffcs, Vol. 19 No. 3, July 1985, pp. 235- 243. [10] 
Thomas W. Sederberg and Scott R. Parry, Free-Form Deformation of Solid Geometric Models, Proc. SIG-GRAPH, 
1986, pp. 151-160. [11] Scott N. Steketee and Norman I. Badler, Parametric Keyfvame Interpolation Incorporating 
Kinetic Adjust- ment and Phrasing Control, Proc. SIGGRAPII, 1985, pp. 255-262. [12] Demetri Terzopoulos, 
John Platt, Alan Barr, and Kurt Fleischer, Elastically Deformable Models, Proc. SICGRAPH, 1987. [131 
Jane Wilhehns and Brian Barsky, Using Dynamic Analysis To Animate Articulated Bodies Such As Hu- mans 
and Robots, Graphics Interface, 1985. Acknowledgements All images were rendered by Kurt Fleischer using 
his modeling testbed system (M-BLORB) on a Symbolics LISP Machine. Michael Kass helped design some of 
the constraints, and provided helpful comments on early veri- ons of tiffs paper. We thank Demetri Terzopoulos, 
Jotm Platt, and Michael Kass for valuable discussions and goop.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37430</article_id>
		<sort_key>233</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[Rectangular convolution for fast filtering of characters]]></title>
		<page_from>233</page_from>
		<page_to>242</page_to>
		<doi_number>10.1145/37401.37430</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37430</url>
		<abstract>
			<par><![CDATA[While the race towards higher-resolution bitmap displays is still on, many grayscale displays have appeared on the scene. To fully utilize their capabilities, grayscale fonts are needed, and these can be produced by filtering bi-level masters. Most of the efficient filtering techniques cannot directly be applied. For example, prefiltering is impractical, due to the number of character masters and the requirement of sub-pixel positioning. Furthermore, we would like to impose as few restrictions as possible on the characteristics of the filter, in order to facilitate exploration into the quality of various filters.We describe a fast filtering technique especially adapted to this task. The characters are decomposed into rectangles, and a summed-area representation of the filter is efficiently convolved with each individual rectangle to construct the grayscale character. For a given filter, the number of operations is <i>O (linear size of the grayscale character)</i>, which is optimal.We give an analysis of the efficiency of this technique, and examples of its implementation applied to various families of fonts and point sizes. The performance of the implementation is such that filtering characters for grayscale displays is feasible in realtime on personal workstations.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.4.3</cat_node>
				<descriptor>Filtering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.3</cat_node>
				<descriptor>Smoothing</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Measurement</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P23126</person_id>
				<author_profile_id><![CDATA[81100030602]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Avi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Naiman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Univ. of Toronto, Toronto, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42051322</person_id>
				<author_profile_id><![CDATA[81100345881]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alain]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fournier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Univ. of Toronto, Toronto, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bigelow, C. and D. Day, "Digital Typography," Scientific American, Volume 249, Number 2, August 1983, pp. 106-119.]]></ref_text>
				<ref_id>Bige83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Blackwell, H. R., "Contrast Thresholds of the Human Eye," Journal of the Optical Society of America, Volume 36, 1946, pp. 642-643.]]></ref_text>
				<ref_id>Blac46</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bruckstein, A. M., "On Optimal Image Digitization," Electrical Engineering Publication Number 577, Faculty of Electrical Engineering, Technion Israel Institute of Technology, Haifa, Israel, February 1986.]]></ref_text>
				<ref_id>Bruc86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cornsweet, T. N., Visual Perception, Academic Press, New York, 1970.]]></ref_text>
				<ref_id>Corn70</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807417</ref_obj_id>
				<ref_obj_pid>800249</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Catmull, E., "A Tutorial on Compensation Tables," Computer Graphics, Volume 13, Number 2, August 1979, pp. 1-7. SIGGRAPH 1979 Proceedings.]]></ref_text>
				<ref_id>Catm79</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807359</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Crow, F. C., "The Use of Grayscale for Improved Raster Display of Vectors and Characters," Computer Graphics, Volume 12, Number 3, August 1978, pp. 1-6. SIGGRAPH 1978 Proceedings.]]></ref_text>
				<ref_id>Crow78</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808600</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Crow, F. C., "Summed-Area Tables for Texture Mapping," Computer Graphics, Volume 18, Number 3, July 1984, pp. 207-212. SIGGRAPH 1984 Proceedings.]]></ref_text>
				<ref_id>Crow84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Ferrari, L. A. and J. Sklansky, "A Fast Recursive Algorithm for Binary-Valued Two-Dimensional Filters," Computer Vision, Graphics, and Image Processing, Volume 26, 1984, pp. 292-302.]]></ref_text>
				<ref_id>Ferr84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Fuchs, D. R. and D. E. Knuth, "Optimal Font Caching," STAN-CS-82-901, Department of Computer Science, Stanford University, Stanford, California, March 1982.]]></ref_text>
				<ref_id>Fuch82</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Gould, J. D. and N. Grischkowsky, "Doing the Same Work with Hard Copy and with Cathode-Ray Tube (CRT) Computer Terminals," Human Factors, Volume 26, Number 3, June 1984, pp. 323- 337.]]></ref_text>
				<ref_id>Goui84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357308</ref_obj_id>
				<ref_obj_pid>357306</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Guibas, L. J. and J. Stolfi, "A Language for Bitmap Manipulation", ACM Transaction on Graphics, Volume 1, Number 3, July 1982, pp. 191-214.]]></ref_text>
				<ref_id>Guib82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15921</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Heckbert, P. S., "Filtering by Repeated Integration," Computer Graphics, Volume 20, Number 4, August 1986, pp. 315-321. SIGGRAPH 1986 Proceedings.]]></ref_text>
				<ref_id>Heck86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806784</ref_obj_id>
				<ref_obj_pid>800224</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J. and M. Ullner, "Filtering High Quality Text for Display on Raster Scan Devices," Computer Graphics, Volume 15, Number 3 August 1981, pp. 7-15. SIGGRAPH 1981 Proceedings.]]></ref_text>
				<ref_id>Kaji81</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Kobayashi, S. C., "Optimization Algorithms for Grayscale Fonts," B. Sc. Thesis, Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, Massachusetts, June 1980.]]></ref_text>
				<ref_id>Koba80</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Kou, L., G. Markowski and L. Berman, "A Fast Algorithm for Steiner Trees," Acta lnformatica, Volume 15, 1981.]]></ref_text>
				<ref_id>Kou81</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807509</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Leler, W. J., "Human Vision, Anti-Aliasing, and the Cheap 4000 Line Display," Computer Graphics, Volume 14, Number 3, July 1980, pp. 308-313. SIGGRAPH 1980 Proceedings.]]></ref_text>
				<ref_id>Lele80</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Lingas, A., R. Pinter, R. Rivest, and A. Shamir, "Minimum Edge Length Decompositions of Rectilinear Figures," Proceedings of the 12th Annual Allerton Conference on Communication, Control, and Computing, Illinois, 1982.]]></ref_text>
				<ref_id>Ling82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>720199</ref_obj_id>
				<ref_obj_pid>647211</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Lingas, A., "Heuristics for Minimum Edge Length Rectangular Partitions of Rectilinear Figures," in Theoretical Computer Science, Edited by A. B. Cremers and H. P. Kriegel, Springer-Verlag, Berlin, January 1983, pp. 199-219.]]></ref_text>
				<ref_id>Ling83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Naiman, A. C., "High-Quality Text for Raster Displays," M. Sc. Thesis, Department of Computer Science, University of Toronto, Toronto, Ontario, 1985.]]></ref_text>
				<ref_id>Naim85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Negroponte, N., "Soft Fonts," Proceedings, Society for Information Display, 1980.]]></ref_text>
				<ref_id>Negr80</ref_id>
			</ref>
			<ref>
				<ref_obj_id>108781</ref_obj_id>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Pratt, W. K., Digital Image Processing, John Wiley and Sons, New York, 1978.]]></ref_text>
				<ref_id>Prat78</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Schmandt, C., "Fuzzy Fonts," Proceedings of the National Computer Graphics Association, 1983.]]></ref_text>
				<ref_id>Schm83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Seitz, C., et al., "Digital Video Display System with a Plurality of Gray-Scale Levels," United States Patent Number 4,158,200.]]></ref_text>
				<ref_id>Seit79</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Sholtz, P. N., "Making High-Quality Colored Images on Raster Displays," Computer Science Research Report RC9632 (#42528), IBM T. J. Watson Research Center, Yorktown Heights, NY 10598, October 1982.]]></ref_text>
				<ref_id>Shol82</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Shurtleff, D. A., How to Make Displays Legible, Human Interface Design, La Mirada, California, 1980.]]></ref_text>
				<ref_id>Shur80</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807508</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Warnock, J. E., "The display of Characters Using Gray Level Sample Arrays," Computer Graphics, Volume 14, Number 3, July 1980, pp. 302-307. SIGGRAPH 1980 Proceedings.]]></ref_text>
				<ref_id>Warn80</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801126</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Williams, L., "Pyramidal Parametrics," Computer Graphics, Volume 17, Number 3, July 1983, pp. 1- 11. SIGGRAPH t983 Proceedings.]]></ref_text>
				<ref_id>Will83</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 O ~ Computer Graphics, Volume 21, Number 4, July 1987 Rectangular Convolution for Fast Filtering of 
Characters A vi Naiman Alain Fournier Computer Systems Research Institute Department of Computer Science 
University of Toronto Toronto, Ontario M5S 1A4 { avilalain } @ csri.toronto.edu Abstract While the race 
towards higher-resolution bitmap displays is still on, many grayscale displays have appeared on the scene. 
To fully utilize their capabilities, grayscale fonts are needed, and these can be produced by filtering 
bi-level masters. Most of the efficient filtering techniques cannot directly be applied. For example, 
prefiltering is impractical, due to the number of character masters and the requirement of sub-pixel 
positioning. Furthermore, we would like to impose as few restrictions as possible on the characteristics 
of the filter, in order to facilitate exploration into the quality of various filters. We describe a 
fast filtering technique especially adapted to this task. The characters are decomposed into rectangles, 
and a summed-area representation of the filter is efficiently convolved with each individual rectangle 
to construct the grayscale character. For a given filter, the number of opera- tions is O(linear size 
of the grayscale character), which is optimal. We give an analysis of the efficiency of this technique, 
and examples of its implementation applied to various fami- lies of fonts and point sizes. The performance 
of the imple- mentation is such that filtering characters for grayscale displays is feasible in realtime 
on personal workstations. CR Categories: 1.3.3 [Computer Graphics]: Picture/Image Generation -- display 
algorithms; 1.4.3 [Image Processing]: Enhancement --filtering, smoothing. General Terms: digital typography, 
algorithms. Additional Keywords and Phrases: grayscale fonts, summed- area filters, rectangular decomposition. 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169; 
1987 ACM-0-89791-227-6/87/007/0233 $00.75 Introduction Until recently, most text on raster displays 
used charac- ters represented as binary matrices, the ones and zeros corresponding to the black and white 
dots to be displayed. Typically, only one set of'characters was provided, simple and tuned to the characteristics 
of the display. While bi-levei matrix representations of characters work quite well when high-resolution 
characters and display dev- ices are available, at low resolutions -- such as on terminals and low-end 
laser printers --the one-bit characters do not resemble their analog predecessors accurately enough [Bige83]. 
With the availability of grayscale devices, we can increase our effective resolution by using gray pixels 
in the representation of a character, as well as black and white ones (figure 1).  RQENbaegnv RQENbaegnv 
 Figure 1. Sampled and filtered versions of several characters from Latin 725 Medium. The success of 
grayscale fonts is based on the principle that, as objects become too small to resolve spatially, size 
and intensity become interchangeable [Corn70]. One of the prin- ciple functions carded out by the human 
visual system is to find edges in the scene being viewed [Blac46]. When objects are too small to resolve 
spatially --such as a pixel from a sufficient viewing distance -- the gray intensity of that object may 
be 'misinterpreted' as spatial components of light and dark; i.e., an 'edge' will be inferred where there 
really is an area of uniform illumination. It is this perceptual effect which is exploited in the use 
of grayscale. Note that the grayscale pixel provides no information about the orientation of the inferred 
edge; that information is deduced by the visual system based on the intensities of the surrounding pixels. 
For example, assuming for the moment that only the immediately adjacent pixels will influence the ~ 
SIGGRAPH '87, Anaheim, July 27-31, 1987 perception of the grayscale pixel, if the pixels to the left 
are black, the pixels to the right are white, and those above and below are the same gray as the center 
pixel, a vertical edge will be perceived in the center column, whose sub-pixel posi- tion depends on 
the intensity of the gray pixels. On the other hand, if the pixels above are white, the pixels below 
are black, and the pixels to the left and right are gray, a horizon- tal edge will be perceived in the 
center row, whose sub-pixel position again depends on the intensity of the gray pixels. Notice, therefore, 
that the same value of (for example) 25% gray in the center pixel will at one time be interpreted as 
resolution in the horizontal direction and at another time in the vertical direction (or even some other 
orientation, depend- ing on the surrounding pixels). In other words, once orienta- tion information of 
the perceived edge is resolved with respect to the surrounding pixels, the grayscale is utilized as resolution 
information. Therefore, to a first approximation, the added number of grayscale levels (not the added 
number of bits) is advantageously exploited regardless of the orienta- tion of the edge; it merely serves 
to position the edge more precisely. For many applications (such as text entry), it will be sufficient 
to provide a single version of a grayscale font for each size and style which is needed on a particular 
display device. However, since grayscale can be used to achieve sub-pixei positioning of edges, one could 
generate many grayscale versions of the same font at a particular size and for a specific device, each 
differing only slightly from the next in terms of the sub-pixel position of the character's edges. By 
using the particular grayscale version which best approxi- mates the sub-pixel position of the edge, 
one could reduce the spacing error that would otherwise result from positioning characters on whole pixel 
boundaries. Prior Work Although grayscale text has gotten some limited com- mercial exposure lately 
(e.g., IBM's Yoda terminal [Sho182] and Bitstream Inc.'s grayscale fonts), two factors have com- bined 
to restrict its usage mainly to specialized environments such as paint programs and slide preparation 
packages, where the grayscale value is used as a weight for interpolating between the text color and 
a variegated background. First, the techniques previously discussed in the litera- ture are computationally 
expensive, and second, there has been little quality control over the resultant fonts. Since the generation 
of gray pixels depends on the characteristics of the display device (pixel size, shape (point spread 
function), and overlap; intensity gamma; spatial inhomogeneities), a model of each device must be incorporated 
into the font generation system [Kaji81]. Otherwise, good-looking fonts produced for one monitor may 
not perform well on another. One can envision a font-production tool which allows parametrization of 
a display device's characteristics, and pro- duces device-dependent grayscale fonts from a master font 
library. For the benefit of researchers exploring models of display devices and the appropriateness of 
particular grays- caling algorithms, it is important to increase the efficiency of robust, filter- and 
display-independent techniques for generat- ing grayscale fonts. Once appropriate filters and models 
have been developed, we will be faced not only with producing numerous fonts at numerous sizes, but also 
for various dev- ices, and perhaps with more than one filter. In order for this task to be feasible, 
fonts must be producible at rates far greater than have heretofore been reported. We will demon- strate 
how, by meeting a few reasonable assumptions, we can drastically reduce the computational expense of 
generating grayscale fonts, in particular for experimentation purposes, but more generally for font production. 
 Filtering The common method for generating a grayscale charac- ter is filtering, whereby a high-resolution 
raster-encoded mas- ter character is convolved with a filter. The filters can be defined in various ways, 
very often analytically [Prat78]. For the rest of the paper, we will assume that values of the filter 
are needed only at the locations of the master and therefore, without loss of generality (though perhaps 
some loss of preci- sion), we can represent a filter with a digitized array of values at the resolution 
of the master. In the process described below, we will assume that all two-dimensional arrays are square 
and we will adopt the following notation (this development is along the lines of [Warn80] -- see figure 
2): we have an m×m binary-valued pixel array, M, representing a high-resolution master character  we 
want a gxg multi-valued pixel array, G, representing a low-resolution grayscale (filtered) character 
 for a given filter type and filter overlap, o, we compute an fxf multi-valued weighted pixel array, 
F,ere~resent-  J J ing a filter kernel, where f=o×m/g, and ~, ~,Fxy is y=lx=l normalized to 1.0 M is 
overlaid with S, an sxs sampling grid where s = g, with a spacing interval of i = m/g (the ratio between 
the master and grayscale sizes) between samples; note that there are i×i different phases at which S 
can be overlaid onto M -- ifp×p different phases (i.e., grayscale character ver- sions) are needed, then 
s = pg with i = m/pg spacing intervals -- if all of the possible phases are needed, then s = m and i=1 
F is centered at each of the sampling points Sxy and con- voived with M, producing up to pxp different 
g×g grays-cale characters In our work, then, we assume an appropriate filter (or filters) is available 
for convolution with the character master, which sufficiently models the display device so that we can 
regard it as a linear device in both intensity [Catm79] and space. This allows us to concentrate our 
efforts on generating accurately-spaced grayscale characters in a minimum amount of time, independent 
of the other important issues affecting the success of grayscale fonts, namely the appropriateness of 
particular filters [Warn80], reconstruction of the character's signal (master) with the displayed samples 
(grayscale) [Kaji81], modeling of the characteristics of display devices [Shur80], the number of grayscale 
bits necessary [Lele80, Bruc86], and possible fatigue of the visual system [Gou184].     ~ SIGGRAPH 
'87, Anaheim, July 27-31, 1987 times (i.e., the number of times the pixel is covered by a rec- tangle). 
Therefore, we will consider only non-overlapping rectangles. Unfortunately, like many similar optimization 
algo-rithms, the general problem of decomposing a rectilinear polygon into rectangles such that the total 
perimeter is minimal is NP-hard /Ling82]. If a polygon is without holes, the problem is solvable in polynomial 
time (0(//4) for n corners /Ling82]), but, of course, many characters do have holes. Lingas presents 
various heuristics for finding a rec-tangular decomposition within some constant factor of the minimum 
edge length when there are holes /Ling83]. They are all theoretically interesting, but, for the relatively 
small number of holes involved in our application, the best approach seems to be to eliminate the holes 
by adding approximately minimum-length edges from the holes to the boundaries. This can be done in O(n 
2) time and gives a solution within a factor of 2 of the minimum length for this step [Kou81]. Once the 
holes have been eliminated, the aforementioned algorithm for rectilinear polygons with no holes can be 
run. t It should be stressed that all of this has only to be done once per master, and the cost of this 
prepro- cessing is therefore not an issue, as long as it is polynomial. Implementation In order to explore 
the quality of various filters in gen- erating grayscale characters, we have implemented a subset of 
the rectangular convolution technique on a Motorola 68020 class machine (HP 9000-320). As our goal is 
to explore the problems inherent to this process, we did not want to take any short cuts which a production 
environment might use for wholesale font production. In particular, we did not use the optimizations 
discussed above concerning the reduced intersection calculations for the various regions of interest 
of a rectangle. We used 32-bit fixed-point integer representations of the filter entries, where the sum 
of all the filter entries is normal- ized to 1.0, and the grayscale pixels are computed in the range 
of [0..256). Each addition, then, is a 32-bit add opera- tion, As mentioned above, the rectangular decomposition 
we used is the repeating-RLE described in [Naim85] (at a master size of 256×256), which does not generate 
optimal rectangles for the rectangular convolution process, but does a fairly good job on the Swiss 721 
Bold seen in many of the figures. Therefore, the timings listed in tables 3, 4, 5, and 6 should be considered 
for the relative improvement of rec-tangular convolution over direct convolution rather than as absolute 
benchmarks for generating grayscale fonts. We foresee another order of magnitude speedup for production 
software over the 2 orders of magnitude we have already achieved. Conservatively, this would result in 
a production rate on the order of 100-1000 characters per second for the , An alternative way to deal 
with holes would be to decompose them into negative contribution rectangles, that is, their gray value 
is subtracted from -- rather than added to -- the intermediate results. Although this will produce equivalent 
results, it must allow for intermediate values which could either overflow the maximum (1.0) or underftow 
the minimum (0.0), which may be impractical. filter/character size combinations listed in the tables. 
 The timings reported are the average of 52 convolution operations (once for each of the upper and lower 
case charac- ters), do not include rectangular decomposition or display time, and were obtained with 
the UNIX TM profiling utility profat a 20 millisecond resolution. Grayscale Filter Convolution Time Size 
Overlap Size Rectangular Direct 16 1.0 16 46 930 32 1.0 8 69 1010 64 1.0 4 139 1340 16 1.25 20 49 
1310 32 1.25 10 78 1520 64 1.25 5 153 1860 16 1.5 24 55 2040 32 1.5 12 87 2120 64 1.5 6 168 2510 
 Table 3. Swiss 721 Bold, single phase timings (in milliseconds). GS Filter Total Time Per-Phase Time 
Size Overlap Size Rect. Direct Rect. Di~ct ....... 16 1.0 16 4605 232690 18 909 32 1.0 8 2559 64210 40 
1003 64 1.0 4 1673 21240 105 1328 16 1.25 20 5594 323840 22 1265 32 1.25 10 3060 96170 48 1503 64 1.25 
5 1887 29260 118 1829 16 1.5 24 7147 526650 28 2057 32 1.5 12 3497 138220 55 2160 64 1.5 6 2073 41700 
130 2606 Table 4. Swiss 721 Bold, all phases timings (in milliseconds). Grayscale Filter Convolution 
Time Size Overlap Size Rectangular Direct 16 1.0 16 58 910 32 1.0 8 79 1000 64 1.0 4 139 1330 16 !.25 
20 62 1270 32 1.25 10 87 1530 64 1.25 5 152 1870 16 1.5 24 69 2070 32 1.5 12 102 2160 64 1.5 6 169 
2450  Table 5, Latin 725 Medium, single phase timings (in milliseconds).  Conclusions The timings 
reported have demonstrated that the rec-tangular convolution technique is effective, leading to a con- 
siderable speedup in the computation of grayscale fonts, without compromising the characteristics of 
the kernels that can be used. This technique can be employed for realtime display of grayscale characters 
on systems with the comput- ~' UNIX is a registered trademark of AT&#38;T Bell Laboratories.  ~ Computer 
Graphics, Volume 21, Number 4, July 1987 GS Filter ~ Total Time Per-PhaseTime Size Overlap Size | Rect. 
Direct RecL Direct 16 1.0 16 4844 235440' 19 920 32 1.0 8 2477 64380 39 1006 64 1.0 4 1562 21340 98 
1334 16 1.25 20 5820 320610 23 1252 32 1.25 10 2955 94900 46 1483 64 1.25 5 1753 29150 110 1822 16 
1.5 24 7723 502240 30 1962 32 1.5 12 3616 133060 57 2079 64 1.5 6 1983 38940 124 2434  Table 6. Latin 
725 Medium, all phases timings (in milliseconds). ing power of a personal workstation. Several improvements 
described in this paper, but not included in the implementa- tion used to generate the timings -- such 
as optimal rectangu- lar decomposition and the use of four summed-area filters -- would further reduce 
the cost of filtering. Note that filtering inherently takes care of mismatched aspect ratios, whether 
they arise from the master character, grayscate character, or display device pixel. Furthermore, as in 
previous methods, the grayscale pixel value can be used as a weight for interpolating between colored 
text and a variegated background. Another aspect of the algorithm is that the rectangles in the decomposition 
do not have to be stored in any particular data structure and can be processed independently of each 
other and in any order. This suggests a straightforward imple- mentation on multiprocessor systems, whether 
general-purpose or specialized for this particular task. The ability to generate grayscale fonts very 
quickly changes the parameters of the 'font caching equation'. As mentioned earlier, precomputing all 
of the phases of all the characters needed is quite out of the question. With the tech- nique described 
here, many applications will be able to justify the cost of dynamically computing grayscale characters, 
and not have to rely on a small selection of poor-quality fonts. Extensions and Applications One additional 
improvement in speed can easily be achieved by determining, for a given filter support, the pixels that 
will always be black, and separating them from the rest of the character, so that they are not included 
in the process- ing of the rectangles. Since these pixels are already processed very efficiently, this 
would result in only a modest improve- ment. In many applications there is a demand for rotated text. 
Bitmaps can of course be rotated, and there are clever algo- rithms to do so [Guib82]. Our technique 
is not well adapted to this, however, since the rectangular decomposition would have to be recomputed 
for every new rotated master. The best way to apply our technique to generate rotated text is to rotate 
the sampling grid and apply it to the unrotated master. This rotation has to be done only for one point; 
the other grid points can be computed by incremental techniques. While the rectangular decomposition 
of the master is still valid, the filter and its summed-area representation would have to be rotated 
as well, but this has to be done only once per rotation angle. In fact, for radially-symmetric filters 
this does not even have to be done. The main loss in efficiency is in the compu- tation of the intersection 
between the filter and the rectangles. For each rectangle, one has to find the sample point closest to 
one of its comers and then move along the grid points using some form of incremental technique. Each 
move would, in general, be in both the X and Y directions, and therefore also a little more costly than 
in the original case. Lastly, one can also put to good use the flexibility of the choice of the filter, 
it has been advocated to use different filters for different parts of a character (for example, to emphasize 
the serifs, or treat leading and trailing edges dif- ferently). To this end, we can mark the rectangles 
of the decomposition based on the parts of the character to which they belong (e.g., vertical stem, diagonal 
hairline) and use a filter appropriate to that type of shape when displayed on a particular device. These 
techniques were developed precisely to facilitate such investigations. Acknowledgements This work has 
been partially funded by the Natural Sci- ences and Engineering Research Council of Canada. The authors 
are grateful to Bitstream Inc. for providing high- quality fonts for this research project, and to the 
Hewlett Packard Co. (John Wilkes in particular) for the use of their facilities in producing the timings 
and preparing this manuscript. The second author also thanks the Imaging group at Xerox PARC for providing 
a very congenial environment while this paper was written. Lastly, the party of the first part would 
like to thank the party of the second part for encouraging him to become a party of the first part in 
the first place.  ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 References Koba80 Kobayashi, S. C., "Optimization 
Algorithms for Bige83 Bigelow, C. and D. Day, "Digital Typography," Scientific American, Volume 249, 
Number 2, August 1983, pp. 106-119. Blac46 Blackwell, H. R., "Contrast Thresholds of the Human Eye," 
Journal of the Optical Society of America, Volume 36, 1946, pp. 642-643. Bruc86 Bruckstein, A. M., "On 
Optimal Image Digitiza- tion," Electrical Engineering Publication Number 577, Faculty of Electrical Engineering, 
Technion Israel Institute of Technology, Haifa, Israel, Febru- ary 1986. Corn70 Cornsweet, T. N., Visual 
Perception, Academic Press, New York, 1970. Catm79 Catmull, E., "A Tutorial on Compensation Tables," 
Computer Graphics, Volume 13, Number 2, August 1979, pp. 1-7. SIGGRAPH 1979 Proceedings. Crow78 Crow, 
F. C., "The Use of Grayscale for Improved Raster Display of Vectors and Characters," Com- puter Graphics, 
Volume 12, Number 3, August 1978, pp. 1-6. SIGGRAPH 1978 Proceedings. Crow84 Crow, F. C., "Summed-Area 
Tables for Texture Mapping," Computer Graphics, Volume 18, Number 3, July 1984, pp. 207-212. SIGGRAPH 
1984 Proceedings. Ferr84 Ferrari, L. A. and J. Sklansky, "A Fast Recursive Algorithm for Binary-Valued 
Two-Dimensional Filters," Computer Vision, Graphics, and Image Processing, Volume 26, 1984, pp. 292-302. 
Fuch82 Fuchs, D. R. and D. E. Knuth, "Optimal Font Caching," STAN-CS-82-901, Department of Com- puter 
Science, Stanford University, Stanford, Cali- fornia, March 1982. Goui84 Gould, J. D. and N. Grischkowsky, 
"Doing the Same Work with Hard Copy and with Cathode-Ray Tube (CRT) Computer Terminals," Human Fac- tors, 
Volume 26, Number 3, June 1984, pp. 323- 337. Guib82 Guibas, L. J. and J. Stolfi, "A Language for Bitmap 
Manipulation", ACM Transaction on Graphics, Volume 1, Number 3, July 1982, pp. 191-214. Heck86 Heckbert, 
P. S., "Filtering by Repeated Integra- tion," Computer Graphics, Volume 20, Number 4, August 1986, pp. 
315-321. SIGGRAPH 1986 Proceedings. Kaji81 Kajiya, J. and M. Ullner, "Filtering High Quality Text for 
Display on Raster Scan Devices," Com- puter Graphics, Volume 15, Number 3 August 1981, pp. 7-15. SIGGRAPH 
1981 Proceedings. Kou81 Lele80 Ling82 Ling83 Naim85 Negr80 Prat78 Schm83 Seit79 Sho182 Shur80 Warn80 
Wi1183 Grayscale Fonts," B. Sc. Thesis, Department of Electrical Engineering and Computer Science, Mas- 
sachusetts Institute of Technology, Cambridge, Massachusetts, June 1980. Kou, L., G. Markowski and L. 
Berman, "A Fast Algorithm for Steiner Trees," Acta lnformatica, Volume 15, 1981. Leler, W. J., "Human 
Vision, Anti-Aliasing, and the Cheap 4000 Line Display," Computer Graph- ics, Volume 14, Number 3, July 
1980, pp. 308-313. SIGGRAPH 1980 Proceedings. Lingas, A., R. Pinter, R. Rivest, and A. Shamir, "Minimum 
Edge Length Decompositions of Rectil- inear Figures," Proceedings of the 12th Annual All- erton Conference 
on Communication, Control, and Computing, Illinois, 1982. Lingas, A., "Heuristics for Minimum Edge Length 
Rectangular Partitions of Rectilinear Figures," in Theoretical Computer Science, Edited by A. B. Cremers 
and H. P. Kriegel, Springer-Verlag, Berlin, January 1983, pp. 199-219. Naiman, A. C., "High-Quality Text 
for Raster Displays," M. Sc. Thesis, Department of Computer Science, University of Toronto, Toronto, 
Ontario, 1985. Negroponte, N., "Soft Fonts," Proceedings, Society for Information Display, 1980. Pratt, 
W. K., Digital Image Processing, John Wiley and Sons, New York, 1978. Schmandt, C., "Fuzzy Fonts," Proceedings 
of the National Computer Graphics Association, 1983. Seitz, C., et al., "Digital Video Display System 
with a Plurality of Gray-Scale Levels," United States Patent Number 4,158,200. Sholtz, P. N., "Making 
High-Quality Colored Images on Raster Displays," Computer Science Research Report RC9632 (#42528), IBM 
T. J. Wat- son Research Center, Yorktown Heights, NY 10598, October 1982. Shurtleff, D. A., How to Make 
Displays Legible, Human Interface Design, La Mirada, California, 1980. Warnock, J. E., "The display of 
Characters Using Gray Level Sample Arrays," Computer Graphics, Volume 14, Number 3, July 1980, pp. 302-307. 
SIGGRAPH 1980 Proceedings. Williams, L., "Pyramidal Parametrics," Computer Graphics, Volume 17, Number 
3, July 1983, pp. 1- 11. SIGGRAPH t983 Proceedings.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37431</article_id>
		<sort_key>243</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[Character generation under grid constraints]]></title>
		<page_from>243</page_from>
		<page_to>252</page_to>
		<doi_number>10.1145/37401.37431</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37431</url>
		<abstract>
			<par><![CDATA[An original and fast filling algorithm based on vertical scan line sweep and contour tracking of a presorted shape description allows filling of character shapes with real subpixel resolution. Identical parts of a character lying at a different phase in respect to the grid will have a dissimilar discrete look. Grid constraints are applied in order to force given parts of a character (stems, serifs) to attain identical phasing. So that several contraints may be applied, degrees of freedom are provided in the form of stretchable null-segments inserted at particular locations in the character outline description. Grid constraints are also applied to avoid discrete arcs with an isolated pixel or a long horizontal or vertical run. The type of constraints applied to parts of a character consists only of horizontal or vertical subpixel translations. The resulting character description therefore remains nearly identical to the original description. The processing time used to apply grid constraints is negligible, compared with the time needed for character scan-conversion and filling. Hence, this method is very well adapted for direct character generation on non-impact printers. It is also suitable for character rasterization in typographic computer-aided design systems.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Digitizing and scanning</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.m</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010432.10010439</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010506</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Document scanning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15020442</person_id>
				<author_profile_id><![CDATA[81100044881]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Roger]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Hersch]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Swiss Federal Institute of Technology, Lausanne]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Coueignoux, P.,"Character Generation by Computer," Computer Graphics and Image Processing, Vot 16, pp 240-269, 1981]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>102723</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Adobe Systems Inc, Postscript Language Reference Manual, Addison-Wesley, 1985]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Karow, P., "Elektronische Modifikation grafischer und verbalgrafischer Zeichen," Deutscher Drucker, Nr. 25, pp.4-8, August 1979]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Knuth, D., Tex and Metafont, American Mathematical Society, Digital Press, 1979]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Hersch, R.D., "Descriptive Contour Fill of Partly Degenerated Shapes," IEEE Computer Graphics and Applications, Vol 6, No 7, July 1986.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>30314</ref_obj_id>
				<ref_obj_pid>30300</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hersch, R.D., "Real Scan-Conversion of Shape Contours, " Proceedings Computer Graphics International 87, Karuizawa, Japan, Ed. T.L Kunii, Springer Verlag, 1987]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Bresenham, J.E.,"Algorithm for computer control of a digital plotter," IBM Systems Journal, Vol 4, No 1, 1965, pp 25-30]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359432</ref_obj_id>
				<ref_obj_pid>359423</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Bresenham, J.E., "A Linear Algorithm for Incremental Digital Display of Circular Arcs," Communications of the ACM, Vol 20, No 2, Febrary 1977]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>246</ref_obj_id>
				<ref_obj_pid>245</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Mcllroy, M.D., "Best Approximate CirOes on Integer Grids," ACM Transactions on Graphics, Vol. 2, No 4, pp 237-263, Oct 83.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6684</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Foley, J.D., Van Dam, A., Fundamentals of Interactive Computer Graphics, Addison-Wesley, 1982]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Ackland, B.D., Weste, NH., "The Edge Flag Algorithm - A Fill Method for Raster Scan Displays," IEEE Trans. on Computers, Vol 30, No 1, January 1981, pp. 41-48]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Newman, W.M., Sproull, R.F., Principles of Interactive Computer Graphics, McGraw-Hill, 1979]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325225</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Pratt, v., "Techniques for Conic Splines," Proceedings of SIGGRAPH'85, (San Francisco, July 22-26,1985). In ACM Computer Graphics, Vol 19, No 3, (July 1985), pp t51-159]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Pitteway, M., "Algorithm for Drawing Ellipses or Hyperbolae with digital plotters," Computer Journal, Vol 10, No 3, pp 282-289, Nov. 1967]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>2213</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Rogers, D.F., Mathematical Elements for Computer Graphics, McGraw-Hill, New-York, 1976]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Hourdequin, M., Coueignoux, P., "Specifying arbitrary planar smooth curves for fast drawing", Proceedings Eurographics Conference, Bologna 1979, pp 193-211]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 II CHARACTER GENERATION UNDER GRID CONSTRAINTS 
 Roger D. HERSCH Swiss Federal Institute of Technology, Lausanne Abstract An originat and fast fitling 
algorithm based on verticat scan line sweep and contour tracking of a presorted shape description allows 
filling of character shapes with real subpixel resolution. Identical parts of a character lying at a 
different phase in respect to the grid will have a dissimilar discrete look. Grid constraints are applied 
in order to force given parts of a character (stems, serifs) to attain identical phasing. So that several 
contraints may be applied, degrees of freedom are provided in the form of stretchable null-segments inserted 
at particular locations in the character outline description. Grid constraints are also applied to avoid 
discrete arcs with an isolated pixel or a long horizontal or vertical run. The type of constraints applied 
to parts of a character consists only of horizontal or vertical subpixel translations. The resulting 
character description therefore remains nearly identical to the original description. The processing 
time used to apply grid constraints is negligible, compared with the time needed for character scan-conversion 
and filling. Hence, this method is very well adapted for direct character generation on non-impact printers. 
It is also suitable for character rasterization in typographic computer-aided design systems. Keywords 
raster graphics, digital typography, outline fonts, analytical character generation, constraints application, 
shape filling, real scan-conversion  1. Introduction For many years, digital character generation has 
been dedicated to hlgh-resolution photocomposing devices [1"1. In the seventies, fidelity of character 
generation was less important than minimization of computer power and memory requirements. The new laser 
printer technology developed in the eighties led to a first generation of raster image Permission to 
copy without fee all or part of this material is granted provided that the copies are not made or distributed 
for direct commercial advantage, the ACM copyright notice and the title of the publication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery. 
To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169; 1987 ACM-0-89791-227-6/87/007/0243 
$00.75 processors using bitmap characters. A second generation of imaging devices capable of representing 
and printing pages independently of the target's printer output resolution arose as a result of proprietary 
research [2]. For today's manufacturers of laser printer and plotting devices, the ability to interpret 
resolution-independent page description languages is becoming a crucial issue. The main problem of device-independent 
raster imaging is character generation from a resolution-independent character description. Traditional 
typography has evolved into digital typography. Font designers use CAD systems for assistance and to 
generate output fonts compatible with the needs of today's photocomposers and laser printers. A major 
step, which may be very work-intensive, concerns the rasterization of character fonts. Commonly used 
systems [3] generate raster characters which generally entail interactive modification of their discrete 
representation by skilled typographers. The techniques described in this paper can be used in order to 
automatically generate raster characters of improved quality. The main problem of typographic character 
generation on a discrete grid is the preservation of important geometrical properties by the scan-conversion 
process. For example, parts of a character which have an identical outline description like stems or 
serifs must remain identical after scan-conversion. Replication of identical parts should lead to identical 
configurations of darkened pixels. Simple scan-conversion of shapes outlines does not respect exactly 
implicit properties such as stem width or serif outlook (figure 1 ). In order to improve character rendering, 
selected segments of shapes are considered to be locally elastic. Important geometrical properties are 
described by constraints and applied to the character shape outline. The resultant character description 
allows the subsequent scan-conversion process to respect the given constraints. A second key point concerns 
the generation of attractively curved character parts. As it has already been pointed out [4], strange 
rasterization effects may appear depending on the relative position of a curved character part in respect 
to the grid. In order to obtain acceptable discrete characters, it is imperative to allow only attractively 
discrete curves to be generated. This can be done by applying constraints specifying the domain through 
which the curvilinear outline must pass.  "~ SIGGRAPH '87, Anaheim, July 27-31, 1987 Shape of original 
character: printed at 150 dots/inch (physical height: 174 pixels) ITI scan-converted character without 
constraint application ITI physical height: 23 pixels scan-converted character with constraint application 
(physical height: 23 pixels) ITI Fig. f Identical stems before and after scan -con version Furthermore, 
the graphic filling algorithm used for analytical character generation should be able to fill degenerate 
shapes (figure 2). Filling speed becomes an essential factor for characters directly generated on a target 
printer. physical g g height (pixels) : 120 18 10 enlargment : 2 8 8  41: r height: 8 5 3 enlargment 
: t 6 16 16 Fig. 2 Example of degenerating character shape: vanishing white interior shape part The 
filling algorithm developed for character generation [5"1 is based on vertical scan-line sweep and contour 
tracking of a presorted shape description. By working on presorted shapes, character generation time 
can be greatly reduced. Presorted shapes can only be filled if their topology remains unmodified by the 
scan-conversion process. Rounding operations may modify the shape's topology. To avoid this, the traditional 
incremental straight line and circular arc scan-conversion algorithms are extended to work with real 
segment departure and arrival points, as well as with real parameters like slope or radius E6]. 2. Elements 
of real scan-conversion Traditional scan-conversion algorithms [7], [8] for straight line and circular 
arc segments are defined for integer coordinates of departure and arrival points Traditional scan-conversion 
and shape filling implies preliminary rounding of shape vertices Real number scan-conversion is introduced 
to avoid rounding operations and to provide higher precision for the selection of discrete pixels Furthermore, 
real scan-conversion allows the generation of many slightly different discrete shapes based on the same 
contour description, by applying to it horizontal or vertical subpixel displacements. Real fixed-point 
scan-conversion of straight line segments is a simple extension of integer scan-conversion. Let us consider 
a line segment with real extremities lying on its support line. Real scan-conversion applied to the considered 
segment should generate exactly the same discrete pixels as those which would have been generated by 
scan conversion of the support line (figure 3). discrete arrival pixel ,.° ..'~,--- support line \ =..1.,~ 
'PA (xA ,YA ) .i.. ~ ---~ considered segment '(~-~t~ discrete departure pixel ... ""i(Fbx.~.v.] Po (Xo,Yo) 
oO x = roundup(x o ) Fig 3 Support line, real segment and associated pixels After scan conversion, a 
real straight line segment Po(Xo,YD)PA(XA,YA) lying in the first octant will have one pixel on each integer 
abcissa intersecting it. The discrete departure pixel Po(xo,Yo) is the closest grid pixel to the intersection 
point Pi(xi,YL) of the real segment with the integer abcissa on the right of departure point PD" Coordinates 
of intersection point Pi(xl, yi): x i = roundup (x D) Yi = Yo + YA-YP_ (x i-xD) X A X D Discrete departure 
pixel Po(xo,Yo) : X 0 = X i YO = round (yi) where xD,Y o, x A, YA ' Yi: real numbers in fixed point representation 
Xo' Yo, x i : integer numbers In order to run the extended Bresenham algorithm, the initial error C o 
= Yi- Yo is used for the computation of error e~ which helps to select next grid pixel PI The following 
recurrence formula is used to get pixel PK÷I from pixel PK and error coefficient £:~:. eK+l = E: K + 
YA- YD X A ~ X D XK+ 1 --X K -F 1 YK*I = YK + round(eK, 1)  ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 
Outlines of characters are generally described by cubic splines. Scan-conversion can proceed directly 
from the cubic spline equation, for example by forward differentiation [12]. If characters are described 
by conics [13], their outline can be scan -converted by fast incremental Bresenham-like algorithms [14]. 
For fast incremental scan-conversion, the original cubic spline description can be approximated by straight 
line, conic or circular arc segments. In order to attain fastest possible scan-conversion and to be able 
to handle degeneration cases easily, we segment the original character description given in natural and 
closed splines [15] into circular arc segments. A sufficiently flat spline segment given by two interpolation 
points and their respective tangents can be approximated by two circular arcs having first derivative 
continuity at their meeting point [16]. A character shape approximated by circular arcs can be scaled 
down without loss of quality. When enlarged, the quality of its contour approximation will decrease. 
Therefore, spline to circular arc conversion should be accomplished on the full-scaled character outline 
description. In order to ease character filling, we ensure that local minima and maxima lie on circular 
arc vertices and that each arc is located within one octant. The approximated contour described by a 
list of subsequent circular arcs and straight line segments must be sorted and converted to a description 
suitable for direct shape filling. Such a description (figure 6), which includes information about the 
order of occurrence of intersections between scan lines and contour parts, contains the following elements 
: 1) An ordered list of birth points 2) An ordered list of death points 3) An ordered list of polysegments 
associated with each birth point. This list contains the order in which polysegments are intersected 
by a horizontal scan line just above the corresponding birth point. 4) A description of each polysegment 
containing all circular arc and straight fine segments from a local minimum (birth point) to a local 
maximum (death point). Such a presorted character description can be referenced whenever a new raster 
character with horizontal or vertical orientation is generated. For characters rotated by any angle, 
circular arc extraction and presorting is applied again on the original spline outline description. The 
character filling algorithm, working on a presorted description, can be described in the following way 
for non-degenerated shapes: Initialize current scan line to the closest integer ordinate inferior to 
the first birthpoint FOR first birthpoint TO last birthpeint DO fetch list of ordered polysegments belonging 
to current birthpoint WHILE current scan line inferior to the next birthpoint DO with real scan-conversion, 
intersect each polysegment of the ordered polysegment list with the current scan line and fill the horizontal 
run between each pair of scan-converted pixels Increment the current scan line ordinate END (,.while*) 
END (*for*) death point I 13~ 13 legend: -~ spline interpolation point% actually arc vertices arc vertices 
at junction between 2 ares 11 ~-straight Hne segment vertices 10 ~ birthpoint [local minimum] deathpoint 
[local maximum] poly- segment 3 each vertex within a potysegment has a vertex number polysegrnents, 
birthpoints and de~thpoir~t~ ~,re numberedbirth point 1 poly-/ segment O 8 ( polysegment 2 !7 I/ d.ath 
 4 ~-poly- birth ~ ~"-2 4 ~ segment t point O 2 1 0 2 3  Description of character t: birthpoinf /is~: 
birthpoint 0 (polysegment 0, vertex 0) birthpoint 1 (polysegment 2, vertex 0) deathpoint list: deathpoint 
0 (polysegrnent 2, vertex 4) deathpoint 1 (polysegment 0, vertex 13) ordered lists of polysegments: ordered 
list at birthpoint O: polysegment O, polysegment 1 ordered list at birthpoint 1: polysegment O, polysegment 
3, polysegment 2, po~ysegment 1 polysegment description: polysegment 0: departure vertex (p0x0,p0y0), 
arc vertex (p0xl,p0yl), .. arc vertex (p0xd,p0y8), segment vertex ('p0x9,p0y9), .. , segment vertex (p0x13,p0y13) 
polysegment 1: departure vertex (plx0,ply0), arc vertex {plxl,plyl), .., arc vertex (plx5,plyS), segment 
vertex (plx6,ply6) polysegment 2: departure vertex (p2x0,p2y0), arc vertex (p2xl,p2yl) .... arc vertex 
(p2x4,p2y4) polysegment 3: departure vertex (p3x0,p3y0), are vertex (p3xl,p3yl), .. ,arc vertex (p3xd,p3y8), 
segment vertex Ip3xg,p3yg), .. segment vertex (p3xl 4,p3y14) Fig. 6 Example of a presorted character 
description suitable for subsequent filling This filling algorithm is restricted to shapes without self-intersections. 
Characters with self-intersections are segmented into one or more distinct shapes which are filled separately. 
For handling degeneration effects the reader should refer to a previous paper describing filling of degenerate 
shapes [5]. Characters generated by simple descriptive contour fill may lose some geometrical properties. 
For example, the first two stems of character m (figure 1), which have an identical description, appear 
in their rasterized unconstrained form as two different elements. Scan-converted originally identical 
stems appear differently because they are drawn at a different phase relative to the grid. Applying constraints 
to the character description can cause identical parts to be drawn at the same subpixel displacement 
relative to the grid. (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 4. Grid constraints applied 
to the character The filling algorithm based on real scan-conversion allows the production of many slightly 
different discrete shapes at various subpixel displacements based on one original contour description 
(figure 7).  g g g phase difference (0, 0) (0, 1/2) (0, 3/4) (Ax, Ay) Fig. 7 Typographic character 
generated at different vertical subpixel displacements The freedom to apply to a character horizontal 
or vertical displacements relative to the grid can be used to keep some geometrical relationships ( ;~, 
=, < ) between discrete character parts. A simple analysis of phasing artifacts on a vertical bar shows 
that phasing may generate the same discrete bar for two real bars having, at worst, a width difference 
of 1 pixel on each side. By centering the real bar outline relative to the grid, the same discrete bar 
is generated for two real bars having a maximal width difference of half a pixel on each side (figure 
8). The centering operation ensures that a maximum number of discrete pixel centers come to lie within 
the real shape border. Therefore geometrical relations (;), =, ~ ) between real centered bars can be 
kept on the generated discrete bars {figure 9). Original scaled character {0, 22.8]" * [2.e, 22.e} poly-poly-segment 
1 ~egnnent 0 [2.e, 2.3} . {11.9,2.3} (o,o) {11.9,o} original coordinates after scaling: polysegment 0: 
departure point (0,0) segment arrival point (0, 22.8) polysegment I: departure point (0,0) segment arrival 
point (11.9, 0) segment arrival point (11,9, 2.3) segment arrival point (2.8, 2.3) segment arrival point 
(2.8, 22.8) segment arrival point (0.0, 22.8) I ...........i × !:; '!:!:i~!~!~!~!:!:!' x FI!iscrete::;' 
"::~ x ';:;::~1:;:;~;:;:: i~ width 4~ //smallest / I largest assc iated J| largest associated ~1 real 
width i I.real width ---)l maximal difference: " ~p- maximal difference e = 1 pixel e= 0.5 uncentered 
vertical bar centered vertical bar Fig. 8 Real and discrete vertical bars Consider character L with vertical 
stroke width slightly larger than horizontal stroke width. By specifying that horizontal and vertical 
strokes of the scaled character must be drawn centered relative to the grid, we ensure that the discrete 
width of the vertical stroke remains larger or becomes equal to the discrete width of the horizontal 
stroke (figure 10). For more complex characters, like character I:, freedom of horizontal and vertical 
character displacement is not enough. More freedom may be given to a character scaled and centered character 
centering operation: translation by vector (0.6, 0.65) (0.6, 23.65) ~ ~ (3.4, 23.65) 5 5 N . , center 
of pixel [] boundary between pixels ¥ -~-~ 3.4 3.15) 12.5 3.15) i i3ilil lilil5 51 (O.6, 0.85) : =-r-,~:~-:~--~'_l) 
I"," 1;"~"]]:~ (12.5, 0.85) original coordinates after scaling and centering: polysegment 0: departure 
point (0.6. 0.85) segment arrival point (0.6, 23.65) polysegment 1: departure point (0.6, 0.85) segment 
arrival point (12.5, 0.85) segment arrival point (12.5, 3.15) segment arrival point (3.4, 3.15) segment 
arrival point (3.4, 23.65) segment arrival point (0.6, 23.65) Fig. 10 Centering the horizontal and vertical 
bars of character L ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 description by considering some particular 
straight line A B C' segments to be elastic (figure 11). As an example, we consider some segments of 
the original character description of letter E to be stretchable in the vertical direction. Thus, it 
becomes easy to center every horizontal bar in respect to the pixel grid. Elasticity is applied only 
at specific locations in order to leave the general shape description unchanged. Therefore, the segment 
which becomes elastic must be chosen carefully. In order to simplify the application of constraints, 
only straight line segments may acquire a stretchable end. Such segments are not always available, so 
that generally an additional stretchable segment called null-segment is inserted in the character description. 
By adding a horizontal or vertical displacement to parts of a character, this additional segment may 
acquire a positive fractional length. A constraint description specifies the actions that must be taken 
in order to modify the coordinates of the character outline. Such a description contains a constraint 
qualifier specifying how to compute the horizontal or vertical displacement parameter. The constraint 
application part contains commands which specify on which parts of a character the current subpixel displacement 
must be appNed (figure 12). Before filling a character, the presorted character description is modified 
by a constraint interpretation routine. This routine computes horizontal or vertical displacements i11 
27 26 25 at high resolution: width(A) > width(B) width(B) > width(C)  IIi iii at low resolution at 
low resolution without centering with centering width(A) > width(B) width(A) > width(B) width(B) < width(C) 
width(B) = width(B) Fig. 9 Continuous and discrete relationships between shape parts using the constraint 
qualifier information. These subpixel displacements are applied to the parts of the character specified 
by the constraint application description. The constraint interpreter can be compared to a linker : just 
before filling, it adjusts the coordinate values of the character description parameters. Original scaled 
character description C0, 22.e) t / ~'" {1 z 2z.8) vertically stretchable vertically stretchabte segment 
segment 1,¢Cz.8, 12.8} ~_[1 t.7,12.8} -}.,r~--- Ioo lysegmen t 1 |~. A= C'I 1.7, 10.5} I (2.e, ~o.5) 
~B poly-~_ vertically stretchable segment .~egment 0 D-~  i 1([z.2,2.31 CO,O] A~ i[12 2 0} Outline 
coordinates before Constraints: constraint application A. constraint qualifier: centering lower horizontal 
segment in vertical direction B. constraint qualifier: centering middle horizontal segment in vertical 
direction C. constraint qualifier: centering upper horizontal segment in vertical direction D. constraint 
qualifier: centering of vertical bar to the right character with modified description having vertical 
and horizontal bars centered on the grid [0.6, 24.6] {12.6, 24.15} , ff Y £ " " {3.4. 14.1S] ~(12.3 
14.15) 4 -_, lX, lqTT-l.l.I;I4'~4i.l.l  :_ ",[12.3,11.85} stretched = w w segment <-~ stretched segment 
.~.j [3.4, 3.15) .(12.8, 3.15) {o6, o 85T'"- i~lJ~ ;T" F'~'~[lz.e,o.e51 Outline coordinates after constraint 
application resulting cothstraint application: vertical translation of whole character by 0.85 resulting 
constraint application: translation of middle and upper character part by 0.5 resulting constraint application: 
vertical translation of upper character part by 0.0 resulting constraint application: horizontal translation 
of whole character by 0.6 Fig. I I Example of simple character outline with stretchable segments before 
and after centering vertical and horizontal bars ~ 5. Generation of discrete curvilinear contour pieces 
by application of grid constraints The problem of generating attractive curvilinear discrete contour 
pieces can be solved by specification of adequate grid constraints. Let us look at the same arc portion, 
at different subpixel displacements (figure 13) : exterior arc portion exterior arc portion exterior 
arc portion with isolated pixel with long with very long at tangential point vertical run vertical run 
Fig. 13 Discrete curved shape at different subpixel displacements  Discrete curvilinear shapes look 
ugly when they contain, at their vertical or horizontal tangential points, an isolated pixel or a long 
run. Real scan-conversion generates an isolated pixel or a long run if the horizontal or vertical tangential 
point of a curve segment lies approximately halfway between two pi×els (figure 14). 7""  ":" ], jr ' 
'~-- constraint 2 I poly- ~ ! constraint 1 ~ / |,ll segrnent 4 poly- "--.gm.nt 3 poly-/ segment 0 " 
" 6 14 5 (b'?.~--- null-segment ' 5 ~-3 =4.~ 5 --inserted here  ~'~3 ~4~2 stretchab,e ~-~2 P~t 3/" r/ 
--segment poly-~ \ segmer~t 1 ~ polysegment Z constraint descriptions 1. constraint qualifier: center 
horizontally between polysegment 0, vertex 6 and polysegment 5, vertex 4 constraint application: horizontal 
displacement applied to the whole character  2. constaint qualifier: center horizontally between polysegment 
4, vertex 6 and polysegment 3, vertex 2 constraint application: apply horizontal displacement to: polysegment 
3: whole polysegment polysegment 4: vertex 7, vertex 8 polysegment 2: vertex 0, vertex 1 Fig. 12 Example 
of constraint descriptions with qualifier and application parts Computer Graphics, Volume 21, Number 
4, July 1987 pixel at long vertical run al point x ~!i at tangential poir~t x ~ \ Fig. 14 Ugly discrete 
arcs produced by scan-converted real arc passing halfway between pixel centers By allowing tangential 
points of arcs to pass only within a certain distance range from pixel centers, neither isolated pixels 
nor long vertical runs will be generated (figure 15). Definition of allowed range for right-oriented 
vertical ares (.for other arcs: same _± ¢ definition applied symmetrically) / tangential point external 
arc external arc external arc passing at -1/8 passing at +1/8 passing at +3/8 from pixe[ center from 
pixel center from pixel center (largest vertical run) (smallest vertical run} Fig. 15 Allowed placement 
of tangential points and corresponding results These curve generation constraints can be added to the 
other character generation constraints. They may require stretchable segments at strategic places. In 
most cases however, it is enough to apply a horizontal or vertical displacement to the whole character 
in order to obtain attractive curvilinear contour parts. For character u (figure 16), a vertical displacement 
is calculated so that the inner and outer tangential points lie within the allowed range. t~ SIGGRAPH 
'87, Anaheim, July 27-31, 1987 7 L6' -s ~'u'~2 / | / I<-~ segment 3 | additional | poty-| constraint 
| segment O ~4 I 5~,'7~1 nutl-~egment ~. ~_3 I ~a~#~ 5~--i .... ted here 4 "~Z~,~"44~2 I stretchable 
u ~. "~"~_ 3J ~segment poly- polysegment 2 segment 1 additional constraint to obtain attractive discrete 
arcs: constraint qualifier: horizontal positive arc -horizontal positive arc between polysegment 0, vertex 
0 and polysegment 5, vertex 0 constraint application: vertical displacement applied to the whole character 
Fig. 16 Application of a vertical constraint to get a nicely curvilinear character shape The visual 
impact of exterior arcs is more important than the impact of interior arcs. Experience has shown that 
arc constraints should be applied to exterior arcs. Interior arcs can be left without constraints. An 
isolated "background pixel" on an interior arc does not disturb the overall visual impression too much. 
6. Definition and application of grid constraints Constraints should be defined in such a way that constraint 
application will not modify important topological attributes of the original shape. The ordered birthpoint 
and deathpoint lists as well as the ordered polysegment lists should remain valid for the shape undergoing 
constraint application. Cases of constraint applications arise in which subpixel translations of shape 
parts completely modify the original shape topology (figure 17). They may occur when selected stretchable 
segments are smaller than one pixel. A simple solution to this problem consists in defining conditional 
constraints, which are applied only if a vertical or horizontal distance between two shape support points 
is bigger than a specified value. By applying grid constraints to a character shape, we ensure that identical 
character parts (serifs, stems) remain identical on the discrete shape, We also ensure that relationships 
( ~<, =, t> ) between real shape parts are maintained on the generated discrete parts. Grid constraint 
application essentially implies local modifications at specific shape locations. Stretchable segments 
become longer or shorter by a fractional value. Null-segments acquire a positive length. Are these local 
shape modifications noticeable on the generated discrete shapes? Null-segments are generally inserted 
at corner points between distinct shape parts. The local discrete shape modification produced by null-segments 
acquiring a fractional length is hardly noticeable. Fractional modification of a stretchable segment 
length may result in a local difference of one or two pixels. constraint definition: center vertically 
to have character centered on base line constraint application:vertical positive displacement applied 
to the whole character streto.ab,o constraint definition: topology change: arc constraint te ebtain the 
local maximum attractive exterior arcs vanished constraint application: vertical negative displacement 
 applied to lower-right part of the character shape [fat) before constraint application: after constraint 
application original character shape resulting shape with 2 vertical constraints with modified topology 
Fig. 17 Topological modifications by constraint application The concept of constraints presented in this 
paper provides the framework within which further research is needed for defining optimal constraints, 
both from a topological and from an esthetical point of view. At present, constrai~ts are added individually 
to each shape description. They should be extracted and formalized by partly automatic, partly interactive 
means. 7. Conclusion An attempt to solve the problem presented by generation of typographic characters 
for middle resolution raster devices becomes possible with a fast shape-filling algorithm working on 
real shape coordinates and capable of filling degenerated shapes. The fundamental problem of producing 
attractive and regular characters on middle resolution devices {200..600 dots/inch) is essentially a 
phasing problem. By providing a means to apply subpixel dephasing to critical parts of a character, identical 
parts of a character like stems or serifs may remain identical throughout scan-conversion. The proposed 
solution consists in appending to the character description a constraint description part. Each constraint 
descriptor contains a qualifier specifying how to compute horizontal or vertical subpixel displacements. 
The constraint application part belonging to a constraint descriptor specifies to which parts of the 
character the computed subpixel displacement should be applied. Between the part of a character where 
a constraint is applied and the part where it is not applied, stretchable null-segments are inserted. 
They wil~ acquire a positive fractional length after constraint application. Similar constraints can 
be defined and applied in .order to obtain attractively discrete curvilinear contour pieces at character 
generation time.  (~) ~ Computer Graphics, Volume 21, Number 4, July 1987 These constraint application 
techniques distinguish themselves from previous attempts to adapt character shapes to the grid [3] by 
the fact that the character description is modified only at very specific places. The inserted stretchable 
null-segments define separations between character parts. Character parts are translated by the constraint 
application process. Their outline description therefore remains nearly identical to the original one. 
The presented techniques allow the drawing of sharp character edges. This approach contrasts with other 
character generation algorithms which generate half-tone rasters on character edges in order to compensate 
for phasing errors. Sharp edges produce the desirable crisp typographic effect on middle resolution printing 
devices. Due to their simplicity, grid constraints can be applied satisfactorily to characters generated 
directly on non-impact printers. Compared to the time needed for character generation and filling, constraint 
application time is negligible. The character designer should be aware that similar looking pieces of 
a character must have a strictly identical outline description. Furthermore, the computer aided character 
design system should allow the typographer to specify in a transparent way which are the constraints 
and where they must be applied. Constraint descriptions should be considered as an integral part of character 
outline descriptions. They provide the means to generate typographical characters of acceptable quality 
on middle resolution output devices. 8. Acknowledgments This research was partly accomplished during 
a four months leave at Vrije Universiteit Brussel. I wish to thank Prof. T. d'Hondt (VUB) and E. Kohen 
(ETH) for the stimulating discussions. Also many thanks to Prof. Nicoud and to my colleagues at Laboratoire 
de Microinformatique for having developed powerful programming and document production environments. 
 9. References : [1] Coueignoux, P.,"Character Generation by Computer," Computer Graphics and Image Processing, 
Vot 16, pp 240-269, 1981 [2] Adobe Systems Inc, Postscript Language Reference Manual, Addison-Wesley, 
1985 [3] Karow, P., "Elektronische Modifikation grafischer und verbalgrafischer Zeichen," Deutscher Drucker, 
Nr. 25, pp.4-8, August 1979 [4] Knuth, D., Tex and Metafont, American Mathematical Society, Digital Press, 
1979 [5] Hersch, R.D., "Descriptive Contour Fill of Partly Degenerated Shapes," IEEE Computer Graphics 
and Applications, Vol 6, No 7, July 1986. [6] Hersch, R.D., "Real Scan-Conversion of Shape Contours, 
" Proceedings Computer Graphics International 87, Karuizawa, Japan, Ed. T.L Kunii, Springer Verlag, 1987 
[7] Bresenham, J.E.,"Algorithm for computer control a digital plotter," IBM Systems Journal, Vol No 1, 
1965, pp 25-30 of 4, [8] Bresenham, J.E., Incremental Digital Communications of Febrary 1977 "A Linear 
Algorithm for Display of Circular Arcs," the ACM, Vol 20, No 2, [9] Mcllroy, M.D., "Best Approximate 
CirOes on Integer Grids," ACM Transactions on Graphics, Vol. 2, No 4, pp 237-263, Oct 83. [lO] Foley, 
J.D., Van Dam, A., Fundamentals of Interactive Computer Graphics, Addison-Wesley, 1982 [11] Ackland, 
B.D., Weste, NH., "The Edge Flag Algorithm -A Fill Method for Raster Scan Displays," IEEE Trans. on Computers, 
Vol 30, No 1, January 1981, pp. 41-48 [12] Newman, Interactive W.M., Sproull, R.F., Principles of Computer 
Graphics, McGraw-Hill, 1979 El 3] Pratt, v., "Techniques for Conic Splines," Proceedings of SIGGRAPH'85, 
(San Francisco, July 22-26,1985). In ACM Computer Graphics, Vol 19, No 3, (July 1985), pp t51-159 [14] 
Pitteway, M., "Algorithm for Drawing Ellipses or Hyperbolae with digital plotters," Computer Journal, 
Vol 10, No 3, pp 282-289, Nov. 1967 r15] Rogers, D.F., Mathematical Elements for Graphics, McGraw-Hill, 
New-York, 1976 Computer [ 16 ] Hourdequin, M., Coueignoux, P., "Specifying arbitrary planar smooth curves 
for fast drawing", Proceedings Eurographics Conference, Bologna 1979, pp 193-211  ~ SIGGRAPH '87, Anaheim, 
July 27-31, 1987  Appendix Typographic characters generated under grid constraints at several sizes: 
  G G G original character reduced character physical height: physical height: at 150 dots/inch physical 
height: 27 pixels 23 pixels physical height: 32 pixels 243 pixels G G o G physical height: physical 
height: physical height: physical height: 19 pixels 14 pixels 10 pixels 5 pixels  ITlmm scan-converted 
character physical height: physical height: physical height: at 150 dots/inch 31 pixels 27 pixets 23 
pixels physical height: 243 pixels 1TI m m m physical height: physical height: physical height: physical 
height: 18 pixels t4 pixels 10 pixels 5 pixels U U u scan-converted character physical height: physical 
height: physical height: at 150 dots/inch 32 pixels 27 pixels 23 pixels physical height: 243 pixels 
U U U u physical height; physical height: physical height: physical height: 19 pixels 14 pixels 10 pixels 
5 pixels  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37432</article_id>
		<sort_key>253</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[An efficient new algorithm for 2-D line clipping: Its development and analysis]]></title>
		<page_from>253</page_from>
		<page_to>262</page_to>
		<doi_number>10.1145/37401.37432</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37432</url>
		<abstract>
			<par><![CDATA[This paper describes a new alorithm for clipping a line in two dimensions against a rectangular window. This algorithm avoids computation of intersection points which are not endpoints of the output line segment. The performance of this algorithm is shown to be consistently better than existing algorithms, including the Cohen-Sutherland and Liang-Barsky algorithms. This performance comparison is machine-independent, based on an analysis of the number of arithmetic operations and comparisons required by the different algorithms. We first present the algorithm using procedures which perform geometric transformations to exploit symmetry properties and then show how program transformation techniques may be used to eliminate the extra statements involved in performing geometric transformations.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Hierarchy and geometric transformations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.2.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011074.10011075.10011079.10011080</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management->Designing software->Software implementation planning->Software design techniques</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010240.10010244</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision representations->Hierarchical representations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011074.10011081</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management->Software development process management</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Measurement</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P282920</person_id>
				<author_profile_id><![CDATA[81100641860]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tina]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Nicholl]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Univ. of Western Ontario, London, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39074880</person_id>
				<author_profile_id><![CDATA[81100397910]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Northwestern Univ., Evanston, IL]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39081208</person_id>
				<author_profile_id><![CDATA[81100641873]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Robin]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Nicholl]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Univ. of Western Ontario, London, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M. and R. F. Sproull. Principles of Interactive Computer Graphics, 2nd ed., McGraw-Hill, New York, 1979.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Sproull, R. F. and I. E. Sutherland. A Clipping Divider, FICC 1968, Thompson Books, Washington, D.C., pp. 765-775.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cyrus, M. and I. Beck. Generalised Two- and Three- Dimensional Clipping, Computers and Graphics, Vol. 3, No. 1, 1978, pp. 23-28.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357333</ref_obj_id>
				<ref_obj_pid>357332</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Liang, Y.-D. and B. A. Barsky. A New Concept and Method for Line Clipping, ACM Transactions on Graphies, Vol. 3, No. 1, 1984, pp. 1-22.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Sobkow, M. S., Pospisil, P. and Y.-II. Yang. A Fast Two- Dimensional Line Clipping Algorithm, University of Saskatchewan Technical Report, 86-2.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hoare, C. A. R. et al. Laws of Programming: a tutorial paper, Oxford University Programming Research Group PRG-45, 1985.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359057</ref_obj_id>
				<ref_obj_pid>359046</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Arsac, J. I. Syntactic Source to Source Transforms and Program Manipulation, Communications of the ACM, Vol. 22, No. 1, 1979, pp. 43-54.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~ ~' Computer Graphics, Volume 21, Number 4, July 1987 AN EFFICIENT NEW ALGORITHM FOR 2-D LINE CLIPPING: 
ITS DEVELOPMENT AND ANALYSIS . -t-, Tma M. Nteholl , D. T. Lee and Robin A. Nieholl *Department of Computer 
Science, +Department of Electrical Engineering and Computer Science, The University of Western Ontario, 
and London, CANADA N6A 5B7 ABSTRACT This paper describes a new algorithm for clipping a line in two 
dimensions against a rectangular window. "Dais algorithm avoids computation of intersection points which 
are not end- points of the output line segment. The performance of this algorithm is shown to be consistently 
better than existing algo- rithrns, including the Cohen-Suthedand and Liang-Barsky algorithms. This performance 
comparison is machine-independent, based on an analysis of the number of arithmetic operations and comparisons 
required by the different algo- rithrns. We first present the algorithm using procedures which perform 
geometric transformations to exploit symmetry pro- perties and then show how program transformation techniques 
may be used to eliminate the extra statements involved in per- forming geometric transformations, Categories 
and Subject Descriptors: D.2.2 [Software Engineering]: Tools and Techniques; F.2.2 [Analysis of Algo- 
rithms and Problem Complexity]: Normumerieal Algorithms and Problems -geometrical problems and computations; 
1.3.3 [Computer Graphics] Picture/Image Generation -display algorithms; 1.3.5 [Computer Graphics] Computational 
Geometry and Object Modeling -geometric algorithms, languages and systems; hierarchy and geometric transforma- 
tions General Terms: Algorithms, design, measurement, perfor- mance Addltlonal Key Words and Phrases: 
Clipping, line clipping, program transformation Permission to copy without fee all or part of this material 
is granted provided that the copies are not made or distributed for direct commercial advantage, the 
ACM copyright notice and the title of the publication and its date appear, and notice is given that copying 
is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires 
a fee and/or specific permission. 1987 ACM-0-89791-227-6/87/007/0253 $00.75 Northwestern University, 
Evanston, Illinois 60201, U.S.A. I. INTRODUCTION In the most general sense, clipping is the evaluation 
of the intersection between two geometrical entities. These geometr- ical entities may be points, llne 
segments, rectangles, polygons, polyhedrons, curves, surfaces and so on, or assem- blies of these. In 
this paper we will restrict ourselves to com- puting the intersection between a line segment and a rectilinear 
rectangle (which we call a window) in two dimensions. Assume that we have a line segment with endpoints 
(xl,yl) and (x2,y2), and a window represented by four real numbers xleft, ytop, xright and ybottom. The 
window is defined as the set of all points (x,y) such that :,deft < x < xright and ybottom < y < ytop. 
The intersection (if not empty) is a continuous portion of the line segment, and so can be represented 
by two endpoints. Thus we must determine i~f the intersection is empty, and if not, compute the coordinates 
of its endpoints. II. BACKGROUND The Cohen-Sutherland (CS) algorithm [1] appears, until recently, to 
be the only line-clipping algorithm known to the graphics community. (SprouU and Sutherland's midpoint 
sub- division algorithm [2] is designed for machines with no hardware support for multiplication and 
division.) The CS algorithm uses an encoding scheme to indicate the positions of the eudpoints of line 
segments. The Cyrus-Beck (CB) algorithm [3], though published in 1978, is not very well known to most 
of the graphics commun- ity. This algorithm is based on a parametric representation of the line segments 
The theoretical model of this algorithm is very general. However, it is rather inefficient. To clip a 
line segment which is neither vertical nor horizontal and lies entirely within the window it will perform 
12 additions, 16 subtractions, 20 multiplications and 4 divisions. The CS algo- rithm performs no arithmetic 
operations for the same line seg- ment. ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 The Liang-Barsky (LB) 
algorithm [4], published in 1984, may be the first attempt to improve on the performance of the CS algorithm. 
The algorithm is a lot more efficient than the C13 algorithm, even though the two use the same theoretical 
model. Experimental analysis was used to show that this algo- rithm is faster than the CS algorithm. 
However the approach of running the algorithms many times, with random line seg- ments and windows, is 
inadequate. The results of the experi- ments are dependent on characteristics of the machine used, for 
example, whether or not a floating point accelerator is used. A very recent technical report by Sobkow, 
Pospisil and Yang [5] describes an algorithm (the SPY algorithm) which also uses an encoding scheme 
for line segments. They also used experimental analysis to show that their algorithm is faster than both 
of the CS and the LB algorithms. In the experiment they showed that the LB algorithm is slower than the 
CS algo- rithm when the windows used are large. This inconsistency demonstrates further the weakness 
of experimental analysis. Experimental analysis suffers from other problems too. The probabilistic model 
used to generate random input data may not be realistic. Even when it is realistic, the experiment pro- 
vides little insight into why one algorithm is faster than another. A common weakness of all the previous 
algorithms is the need to evaluate intersection points which are not part of the result. For example, 
given the line and window shown in Figure 1 both the CS and SPY algorithms will compute the intersection 
point I L before rejecting the entire line segment (i.e. eonclud-hag that the intersection is empty), 
whereas the LB algorithm will compute parametric values of all the intersection points IL, IR, I B and 
I T before rejecting the line segment. There are many trivial cases in two-dimensional line clipping, 
and they should be handled with as lltde computation as possi- ble. For example, when both endpoints 
lie within the boun- daries of the window the LB algorithm computes parametric values of the intersection 
points with all four window boun- daries before deciding that the line needs no clipping. In fact, the 
LB algorithm always computes these four parametric values when the intersection is non-empty. This explains 
why the LB algorithm is slower than the CS algorithm when the window is large and there are more line 
segments with non- empty intersection with the window. Both the CS and SPY algorithms use an encoding 
system. This approach divides the problem into a manageable number of eases and thus probably leads to 
a shorter program. How-ever an encoding system can be the cause of inefficiency. To encode the location 
of a line segment some comparisons must be performed. Further comparisons on the encoding are then needed 
before the appropriate calculation of an intersection is done. If we can manage all possible eases without 
going through an encoding scheme then the appropriate calculations can be done immediately after the 
initial comparisons. III. MACHINE-INDEPENDENT EVALUATION OF EFFICIENCY  To evaluate the efficiency 
of a clipping algorithm, we count up the number of times particular operations are executed in all possible 
cases. This is possible because clipping is a particu- larly simple and symmetrical problem. The operations 
to be counted should be generally recognised as most time-consuming and should also be indispensible 
in a clipping algo- rithm. What these operations should be depends on the level of abstraction we think 
about the algorithm and the assump- tions we make of the computing environment. The operations we have 
chosen are comparisons and the four arithmetic operations: addition, subtraction, multiplication and 
division. Ilowever, a clipping algorithm which relies heavily on operations other than these will be 
compared rather unjustly favourably in our evaluation. For example, the CS algorithm relies heavily on 
set operations on codes which are absent in the LB algorithm. This is indeed the most difficult hurdle 
in designing a machine-independent evaluation, namely, all operations are different and we are not comparing 
like with like. To be able to progress from an evaluation scheme to the design of an efficient clipping 
algorithm, we also need to make some assumptions on the relative speeds (or costs) of these operations 
to be counted. The assumptions should be tree in most computing environments, We have assumed that the 
operations "comparison, addition, subtraction, multiplication and division are decreasing in speed in 
that order. This is tree in most computing environments without a floating point accelerator. With a 
floating point accelerator, addition and subtraction are about the same speed with the latter slightly 
slower, multiplication and division are about the same speed with the latter slightly slower, and addition 
and subtraction are slower than multiplication and division. So, the most general assumption that applies 
to both kinds of environments is that subtraction is slower than addition and division is slower than 
multiplication. Even though we designed our algorithm with the initial assumption in mind, our algorithm 
is shown to be faster than the LB algorithm in all cases with the most general assumption, and faster 
than the CS algorithm in all cases aver- aged over symmetry with the most general assumption if the difference 
in speed between division and multiplication is greater than the difference between subtraction and addition. 
  (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 IV. DEFINITIONS The lines x = xleft, x = xrlght, 
y = ybottom and y = ytop are called the left, right, bottom and top boundaries of the window respectively. 
A point, a line segment or a portion of a line seg- ment which lies entirely inside the window is visible. 
A point, a line segment or a portion of a line segment which lles entirely outside the window is invisible. 
A line segment which lies partly inside the window and partly outside is partially visible. If a line 
segment is invisible then no part of the line segment appears in the output, and the line segment is 
said to be rejected by the clipping algorithm. The boundaries of the window divide the 2-dimensional 
Cartesian plane into 9 regions. We call regions which are bounded by only 2 boun- daries the corner regions, 
and the regions which are bounded by 3 boundaries, the edge regions. (See Figure 2) V, A HIERARCHICAL 
ANALYSIS OF THE PROBLEM Given a line segment with endpoints Pl=(xl,yl) and P2=(x2,y2), P1 is located 
in the window, an edge region or a comer region. In each of these cases, P2 may be at any point on the 
2-dimensional Cartesian plane. We can divide all pos- sible positions of P2 (i.e. the whole plane) into 
regions each of which corresponds to intersection points at the same boun- daries (or none) to be output. 
Figures 3 to 5 show the subdivi- sions. In those figures, if P2 lies in a region filled with charac- 
ter L, R, B or T, the line PIP2 will intersect the left, right, bot- tom or top boundary respectively. 
Combinations of two char- acters indicate the need for two intersection points. Unfilled regions require 
calculation of no intersection points. These three figures are sufficient to represent all cases, because 
all other cases are the same as one of them up to a rotation of a multiple of 90 ° about the origin or 
a reflection about the line x = -y, or a combination of the two. This analysis leads naturally to an 
algorithm. Given the input P1 and P2, characterize the location of Pl among the 9 regions. According 
to that, characterize the location of P2 among the appropriate subdivisions. Then, calculate the inter- 
section points according to the characterization. In this way, only the intersebtion points required 
for output are calculated. VI. DESIGN OF THE ALGORITHM 1, Characterization of the endp0ints Characterization 
of P1 is straightforward, Characterization of P2 could involve a lot of arithmetic operations, because 
not all boundaries of the subdivision are vertical or horizontal. Observe that all oblique parts of the 
subdivision boundaries are formed by a line joining PI to a comer of the window. For example, consider 
the line joining Pl to the left-top corner in Figure 4. P2 is above this line if and only if (ytop-yl) 
* (x2-xl) < (xleft-xl) * (y2-yl). Note that the arithmetic operations involved in making this comparison 
must be performed if intersection points at the top and left boundaries are to be calculated, so the 
effort involved in this comparison can be useful. 2. Geometric Transformations Since PI may be in any 
one of the 9 regions, each of which corresponds to a different subdivision, a different procedure can 
be written to handle each case. However, this can be very error-prone because the programmer will be 
writing similar but not identical code many times. A more satisfactory way is to exploit the symmetry 
of the problem as much as possible so that all cases symmetrical to each other are transformed geometrically 
to the same case and are handled by only one piece of code. This approach raises the fear that geometric 
transformations may involve a lot of arithmetic operations. Ilowever, a closer examination of the required 
geometric transformations revealed that the only operations involved are unary minus and assignment. 
A complete list of the required geometric transformations and their Pascal implementations are as follows: 
Rotation of 90 ° clockwise about the origin: procedure rotate90c (vat x,y : real); vat t: real; begin 
t ;= x; x "= y ; y ;= -t er~d; Rotation of 180 ° clockwise about the origin: procedure rotatelS0c (var 
x,y : real); begin x := -x; y := -y end; Rotation of 270 ° clockwise about the origin: procedure rotate270c 
(var x,y : real); vat t: real; begin t := x; x := -y; y := t end; Reflection about the line x = -y : 
procedure reflectxmlnusy (var x,y : real); vat t: real; begin t := x; x :=-y; y :=-t end; Reflection 
about the x-axis: procedure reflectxaxis (var x,y: real); begin y := -y end; By employing these simple 
transformations, the number of different cases becomes manageable and we can optimize each of them with 
confidence. However, we are not limiting our-selves from bringing the algorithm to its most efficient 
form - a form that is free from these geometrical transformations and procedure calls. As will be explained 
in a later section, a mechanical software transformation can be applied to the code to bring it to such 
a form.  ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 VII. DETAILS OF THE ALGORITHM PI can be beyond the 
left boundary, beyond the right boundary or between the two boundaries. The first two cases are sym- 
metrical up to a rotation of 180 ° about the origin, and can be handled together. A Pascal implementation 
of the main pro- cedure is: procedure clip (xleft, ytop, xright, ybottom, xl,yl,x2,y2: real); var display 
: boolean; begin ifxl < xleft then leftcolurrm (xleft, ytop, xright, ybottom, xl, yl, x2, y2, display) 
else if xl > xright then begin rotatel80e (xl, yl); rotate180e (x2, y2); leftcolumn (-xright, -ybottom, 
-xleft, -ytop, xl, yl, x2, y2, display); rotatel80c (xl, yl); rotatel80c (x2, y2); end else centrecolumn 
(xleft, ytop, xright, ybottom, x 1, y 1, x2, y2, display); if display then {display the visible part 
of the line segment, which is now between the current values of (xl ,yl) and (x2,y2) } end{ clip}; Now 
we need consider only the cases where P1 is beyond the left boundary or between the left and right boundaries. 
1. P1 is beyond the left boundary Now, it is pointless to further characterize Pl, if P2 is also beyond 
the left boundary. So, we should check that before proceeding on. P1 can be beyond the top boundary, 
beyond the bottom boundary or between the two boundaries. Again, the first two cases are symmetrical 
up to a certain transforma- tion, and can be handled together. The transformation should not only map 
the left-bottom comer region to the left-top comer region, but should also preserve the fact that P2 
is not beyond the left boundary. A reflection about the x-axis satisfies the criteria. A Pascal implementation 
of the pro- cedure is: procedure leftcolumn (xleft, ytop, xright, ybottom: real; var xl ,y 1 ,x2,y2: 
real; var display: boolean); begin if x2 < xleft then display := false else ifyl > ytop then toplefleomer 
(xleft, ytop, xright, ybottom, xl, yl, x2, y2, display) else if yl < ybottom then begin refleetxaxis 
(xl, yl); reflectxaxis (x2, y2); topleftcomcr (xleft, -ybottom, xright, -ytop, xl, yl, x2, y2, display); 
refiectxaxis (xl, yl); reflect~axis (x2, y2) end else leftedge (xleft, ytop, xrlght, ybottom, x 1, yl, 
x2, y2, display) end { leftcolumn } ; 1.1. PI is In the left-top corner region and P2 is not beyond 
the left boundary Now, it is pointless to proceed if P2 is beyond the top boun- ttaty. We check that 
first, and then start to chanlcteriz~ lY2 among the subdivisions in Figure 5. To reduce the number of 
different cases by haft (approximately), we compare P2 against the line joining P1 and the left-top comer. 
The case ha which P2 is on one side of this line is symmetrical to the case in which it is on the other 
side. So, we only need to handle one of the two cases. Notice that up to this point, we still do not 
know whether the subdivisions are as in Figure 5 or its reflection about the line x = -y. If the line 
segment P1P2 is partially visible then this comparison is unavoidable. A Pascal implementation of the 
procedure is: procedure topleftcomer (xleft, ytop, xright, ybottom: real; var xl ,y 1 ,x2,y2: real; var 
display: boolean); vat relx2, rely2, topproduct, leftproduct: real; begin if y2 > ytop then display 
:= false else begin relx2 := x2 - xl ; rely2 := y2 - yl; topproduct := (ytop -yl)* relx2 ; leftproduct 
:= (xleft - xl) * rely2; if topproduct > lefiproduct then leftbottomregion (xleft, ytop, xright, ybottom, 
xl, yl, x2, y2, display, relx2, rely2, leftproduct)  else begin reflectxminusy (xl, yl); refl ectxm 
inu s y (x2, y2); leftbottomregion (-ytop, -xleft, -ybottom, -xright, xl, yl, x2, y2, display, -rely2, 
-rel.x2, topproduct);  reflectxminusy (xl, yl); reflectxminusy (x2, y2) end end end { topleftcomer } 
; 1.I.1. PI is Ifi the left-top corner, P2 Is not beyond the left boundary, and P2 is to the right of 
the vector from P1 to the Icl't-top corner (~ ~)' Computer Graphics, Volume 21, Number 4, July 1987 
If P2. is above the bottom boundary, then no more oblique boundaries need to be compared. The intersection 
polnt(s) that should be calculated are as shown in Figure 5. If P2 is below the bottom boundary, then 
there are 3 possibilities. The boundary formed by the line joining P1 to the left-bottom comer has to 
be compared 'no matter which side of the right boundary P2 happens to be on. So, we do this comparison 
first. Now, if P2 is to the left of the right boundary, we have no more oblique boundaries to be compared. 
Otherwise, one more comparison with an oblique boundary will decide which subdivision P2 is in. A Pascal 
implementation is as follows: procedure leftbottomreg[on (xleft, ytop, xright, ybouom: real; var xl,yl 
,x2,y2: real; var display: boolean; relx2, rely2, leftproduct : real); var bottomproduct, rightproduct 
: real; begin if y2 >= ybottom then begin if xg. > xright then begin y2 := yl + (aright - xl) * rely2/relx2; 
x2 := xrlght end; yl := yl + leftproduct/relx2; xl := alert; display := true end else begin bottomproduct 
:= (ybottom -y l) * relx2; if bottomproduct > leftproduct then display := false else begin if x2 > 
xrlght then begin rightproduct := Cxright - xl ) * rely2; if bottomproduct > rightproduct then begin 
x2 := xl + bottomproduct/rely2; y2 := ybottom; end else begin y2 := yl + rightproduct/relx2; x2 := xright; 
end; end else begin x2 := xl + bottornproduct/rely2; y2 ;= ybottom; end; yl :=yl + leftproduct/relx2; 
xl := xleft; display := true end end end { leftbottomregion } ; 1.2. P1 is in the left edge region 
 If P2 is beyond the left boundary, then the line segment should be rejected. Otherwise, P2 can be above 
the top boundary, below the bottom boundary, or between the two boundaries. The first two cases are symmetrical 
to each other and should be handled together. The last case is quite obvious from Figure 4. A Pascal 
implementation is as follows: procedure leftedge (alert, ytop, xright, ybottom : real; var xl,yt ,x2,y2: 
real; var display: boolean); vat reLx2, rely2: real; begin if x2 < xleft then display := false else 
if y2 ,¢ ybottom then p2bottom (xleft, ytop, xright, ybottom, xl, yl, x2, y2, display) else if y2 > 
ytop then begin rcflectxaxis (xl, yl); reflectxaxis (x2, y2); p2bottom (xleft, -ybottom, xright, -ytop, 
 xl, yl, x2, y2, display); reflectxaxis (xl, yl); reflectxaxis (x2, y2) end else begin relx2 := x2 - 
xl; rely2 := y2 - yl; if x2 > xright then begin y2 := y l + rely2 * (xright -xl)/relx2; x2 := xright 
end; yl := yl + rely2 * (xleft - xl)/relx2 ; x 1 := xleft; display := true end end { ]cftedge } ;  
1.2.1. PI is in tile left edge region, P2 is not beyond the left boundary and P2 Is beyond the bottom 
boundary Comparing with the boundary joining P1 to the left-bottom comer cannot be avoided by comparing 
with any vertical or horizontal boundaries first. We, therefore, perform the com- parison first before 
comparing with the right boundary which may save us from further comparisons. A Pascal implementa- tion 
is as follows: procedure p2bottom (xleft, ytop, xright, ybottom :real; var x I ,y I ,x2,y2: real; vat 
display: boolean); var leftproduct, bottomproduct, rightproduct, relx2, rely2: real; begin relx2 := 
x2 - xl ; rely2 := y2 - yl; leftproduct := (xleft -x 1) * rely2; bottomproduct := (ybottom - yl) * relx2; 
ff bottomprcxtuct > leftproduct then display := false else begin if x2 <= aright then begin x2 := x 
1 + bottomproduct/rely2; y2 := ybottom; end else begin righlproduct := (aright - xl) * rely2; if bottomproduct 
> rightproduct then begin  ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 x2 := xl + bottomproduetlrely2; 
y2 := ybottom; end else begin y2 := yl + rightproduct/relx2; x2 := xright; end; end; yl := yl + leftproduct/relx2; 
xl := xleft; display := tree end end { p2bottom } ; 2. P1 is between the left and right boundaries If 
P1 is above the top boundary or below the bottom boundary, the case is symmetrical to that if P1 is in 
the left edge region, and we will use the same procedure. A Pascal implementation is as follows: procedure 
centreeolumn (xleft, ytop, xright, ybottom: real; var x 1 ,y 1 ,x2,y2: real; var display: boolean); begin 
ifyl > ytop then begin rotate270c (xl, yl); rotate270c (x2, y2); leftedge (-ytop, xright, -ybottom, xleft, 
xl. yl, x2, y2, display); rotate90c (xl. yl); rotate90c (x2, y2) end else if y 1 < ybottom then begin 
rotate90c (xl, yt); rotate90c (x2, y2); leftedge (ybottom, -xleft, ytop, -xright, xl, yl, x2, )'2, display); 
rotate270e (x I, yl); rotate270e (x2, y2) end else inside (xleft, ytop, xright, ybottom, xl, yl, x2, 
5,2, display) end { centrecolumrt } ; 2.1. P1 is In the window If I"2 is in an edge region then the 
intersection point to be cal- culated is obvious from Figure 3. If 1"2 is in a comer region then comparison 
with one oblique boundary is necessary before the appropriate intersection points are calculated. Again, 
symmetry is used to reduce the number of different eases. A Pascal implementation is as follows: procedure 
inside (xleft. ytop, xright, ybottom: real; var x 1 ,y 1,x2,y2: real; var display: boolean); procedure 
p21eft (xleft, ytop, xright, ybottom: real; var xl.yl ,x2,y2: real); procedure p21efttop (xleft, ytop, 
xrlght, ybottom: real; varxl ,yl ,x2,y2: real); ~ar relx2, rely2, leftproduct, topproduct: real; begin 
relx2 := x2 - x I ; rely2 := y2 -y I; leftproduct := rely2 * (xleft - x 1); topproduct := relx2 * (ytop 
- yl); if topproduct > leftproduet then begin x2 := xl + topproduct / rely2; y2 := ytop end else begin 
y2 := yl + leftproduct / relx2; x2 := xleft end end { p21efttop } ; begin if y2 > ytop then p21efttop 
(xleft, ytop, xright, ybottom, xl, yl, x2, y2) else if y2 < ybottom then begin rotate90c (x 1, y l); 
rotate90c (x2,y2); p21efttop @bottom, -xleft, ytop, -xright, xl, yl, x2, y2); rotate270c (x 1, y 1); 
rotate270c (x2,y2) end else begin y2 := yl + (y2-yl) * (xleft-xl)/(x2oxl); x2 := xleft end end { p21eft 
} ; beg in display := true; if x2 < xleft then p21eft (xleft, ytop, xright, ybottom, xl,yl,x2, y2) 
 else if x2 > xrlght then begin rotatelS0c (xl, yl); rotate180c (x2, y2); p21eft (-xright, -ybottom, 
-xleft, -3'top, xl. yl, x2, y2); rotatelg0c (xl, yl); rotate180c (x2, y2) end else if y2 > ytop then 
begin x2 := xl + (x2 -xl) * (ytop - yl)l(y2 - yl); y2 := ytop end else if y2 < ybottom then begin x2 
:= xl + (x2-xl) * (ybottom-yl)/(y2-yl); y2 := ybottom end {else P2 is inside, just display, no need 
to clip} end [ inside } ; Now, we have handled all possible cases. VIII. ANALYSIS OF THE ALGORITHM To 
analyse the eflicienc T of the algorithm, we insert extra vari- ables in our Pascal implementation to 
count up the number of comparisons, additions, subtractions, multiplications and divi- sions in all the 
different cases. For the sake of comparison, we do Ihc salne to the CS algorithm and the l.ll algorithm. 
To ~)' Computer Graphics, Volume 21, Number 4, July 1987 normalize the effect of the different order 
in which the window boundaries are considered in the algorithms, we average the result over symmetry. 
For the eases in which P1 is in the win- dow or in an edge region, we average over the 4 rotations of 
a multiple of 90 °. For the case in which PI is in a comer region, we average over the 4 rotations of 
a multiple of 90 ° and their reflections about the line x = -y. The results are displayed in Figures 
6 to 8. From the analysis, we can draw the following conclusions (and these conclusions are machine independent) 
: 1. Our algorithm has the fewest number of divisions, equal to the number of intersection points for 
output. 2. Our algorithm has fewest comparisons, in most cases about 1/3 of the CS algorithm and about 
1i2 of the LB algorithm. 3. ~ we assume only that (i) subtraction is slower than addi- tion, (ii) division 
is slower than multiplication and (iii) the difference in speed between subtraction and addition is smaller 
than that between division and multiplication, then our algorithm is the most efficient. 4. The LB algorithm 
requires the largest number of multiplica- tions + divisions in all eases, and the largest number of 
arithmetic operations in most cases. 5. The CS algorithm requires the largest number of comparis- ons 
in most cases. (To allow for possible short-circuit evaluation we treat the while condition as 2 comparisons 
instead of 3.) 6. The LB algorithm is the slowest in most trivial reject cases. 7. When the window 
is large, the dominating case is when P2 is in the window in Figure 6. In this case, the CS algorithm 
does very few set operations, and so the LB algorithm is the slowest. 8. When the window is small, the 
dominating cases are the four comer regions of Figure 8. If PI and P2 are in comer regions at opposite 
ends of a diagonal of the window, then the CS algorithm may require twice as many comparisons as the 
LB algorithm. In this ease the CS algorithm performs many set operations, so it may be slower than the 
LB algo- rithm. A. floating point accelerator makes tb.is more likely, because the CS algorithm has more 
additions and subtrac- tions than the LB algorithm in this case.  The LB algorithm clips vertical and 
horizontal line segments faster than oblique line segments, hence a detailed analysis of the LB algorithm 
has been performed. This detailed analysis does not alter the conclusions. IX. TRANSFORMATION OF THE 
ALGORITHM The algorithm presented above uses explicit geometric transformations (rotations and reflections) 
to exploit the sym- metries present in the problem. Thus sections of the algorithm have the form: 1) 
transform the positions of the line and the window ; 2) clip the line to that window ; 3) transform the 
clipped line to its original position ; illustrated by the following statements from the main pro- cedure 
"clip": rotate180c (xl, yl) ; rotatel80e (x2, y2) ; leftcolumu (-xright, -ybottom, -xleft, -ytop, xl, 
yl, x2, y2, display) ; rotate180c (x I, y 1) ; rotate 180c (x2, y2) ; In addition to the arithmetic operations 
and comparisons of procedure leftcolumn, we have additional assignments and negations in precedure rotatel80c, 
as well as the negations (and passing) of parameters to procedure leftoolumn. We will now explain how 
correcmess-preserving program transforma- tions are used to eliminate these extra operations. In this 
way we can construct a highly efficient algorithm from a form in which it is less efficient, but easier 
to follow. 1. Basle transformations Let x and y be lists of variable names, with no names in com- mon. 
Let E be a llst of expressions, of the same length as x. Let F(x) be a list of expressions, of the same 
length as x and possibly involving some of the names in x. Then: (a) (x,y := E,y) = (x := E) For example, 
(x l,yl ,x2,y2 := -xl,-yl ,x2,y2) = (xl ,yl := -xl,-yl)  (b) (x := E ; x := F(x)) = (x := F(E)) For 
example, (xl,yl :=-xl,-yl;xl,yl :=xl,-yl) = (xl,yl := -xl,-(-yl)) = (xl,yl := -xl ,yl)  (e) (x := E 
; if p(x) then Sl else $2) =  (if p(E) then begin x := E ; S1 end else begin x := E ; $2 end) For example, 
(x2,y2 := -x2,-y2; if x2 < xl then S1 else $2) = (if -x2 < xl then begin x2,y2 := -x2,-y2; SI end else 
begin x2,y2 := -x2,-y2; $2 end) (d) (x := x) = 0 -the empty statement (e) (if b then S 1 else $2 ; x 
:= E) = (if b then begin SI ; x := E end  else begin $2 ; x := E end) For example,  I~®®~=1 SIGGRAPH 
'87, Anaheim, July 27-31, 1987 (if tp > lp then S1 else $2 ; xl,yl := -yl,xl) = (if tp > lp then begirt 
S 1 ; x 1 ,y 1 := -y 1,xl end else begin $2 ; xl,yl := -yl,xl end) These transformations (identified 
by Hoare et al. in [6]) may be used to eliminate many assignments by modifying state- ments following 
the assignments, as seen particularly in transformations Col and (c). We illustrate this process by transforming 
the text of the procedure p21eft. 2. Example: Transformation of p21eft p21eft has the form: if y2 > ytop 
then p21efttop ... else if y2 < ybottom then (rotate90e ... ; p21efttop ... ; rotate270c ...) else (3,2 
: .... ; x2 := ...) The section of text to be transformed is rotate90e ... ; p21efttop ... ; rotate270c 
... which may be written as x 1 ,y 1 ,x2,y2 := y 1 ,-x 1 ,y2,-x2 ; p21efttop ... ; xl,yl,x2,y2 := -yl~l,-y2,x2 
; which is, expanding the parameter substitution involved in the call to p21efttop, xl,yl,x2,y2 := yl,-xl,y2,-x2 
; xleft,ytop,xright,ybottorn := ybottorn,-xleft,ytop,-xright ; ... body of procedure p21efttop ... ; 
xl ,yl ,x2,y2 := -y I ,xl,-y2,x2 ; Using transformation rules (a) and (b) and simplifying arith- metic 
expressions, the first four assignments of p21efttop, which read relx2 :=x2 -xl ; rely2 :=y2 -yl ; leftproduct 
:= rely2 * (xleft - xl) ; topproduet := relx2 * (ytop - yl) ; will become simply relx2 := y2 - yl ; 
rely2 := xl - x2 ; leftproduct := rely2 * (ybottom - yl) ; topproduct := relx2 * (xl - xleft) ; Similarly 
transformation rules (c) and (e) allow us to rewrite the ff statement of p21efttop as if topproduct > 
leftproduct then begin xl,yl,x2,y2 := yl,-xl,y22,-x2 ; xleft,ytop,xright,ybott om := ybottom,-xleft 
,ytop,-xright ; x2 := xl + topproduct / rely2 ; y2 := ytop ; xl,yl,x2,y2 := -yl,xl,-y2,x2 end else begin 
xl,yl,x2,y2 := yl,-xl,y2,-x2 ; xleft,ytop,xright,ybottom := ybottom,-xleft,ytop,-xright ; y2 := yl + 
leftproduct / relx2 ; x2 := xleft ; xl ,yl ,x2,y2 := -yl ,x 1 ,-y2,x2 end which can be further transformed 
by rules (a) and Co) and then simplified to if topproduct > leftproduct then begin x2 := xleft ; y2 := 
yl + topproduct / rely2 end else begin x2 := xl - leftproduct / relx2 ; y2 := ybottom end ; Thus after 
transformation, including removal of procedure calls, the text of p21eft appears as: procedure p21eft 
(xleft, ytop, xfight, ybottom: real ; var xl, yl, x2, y2: real) ; var relx2, rely2, leftproduct, topproduct: 
real ; begin if y2 > ytop then begin ... text of p21efttop ... end else if y2 < ybottom then begin relx2 
:= y2 - yl ; rely2 := xl - x2 ; lefiproduct := rely2 * (ybottom - yl) ; topproduct := relx2 * (xl - xleft) 
; if topproduct > leftproduct then begirt x2 := xleft ; y2 := yl + topproduct / rely2 end else begin 
x2 := xl - leftproduct / relx2 ; y2 := ybottom end end else begin y2 := yl + (y2-yl) * (xleft-xl) / 
(x2-xl) ; x2 := xleft end end { p21eft } ; 3. Observations on the transformations Performing the above 
transformations reduces the number of assignments and negations executed in clipping a line. How- ever 
the size of the program text increases considerably, so that it is not practical to provide the complete 
text here. Furth- ermore, since considerable effort is required to apply the transformations throughout 
the program, the transformations should be applied by a program (and not manually). Program transformation 
systems do exist (for example [7]), but we have not used such software to support development of this 
algo- rithm.  (~) ~ Computer Graphics, Volume 21, Number 4, July 1987 X. CONCLUSIONS AND FUTURE WORK 
We have developed a new 2-dimensional line clipping algo- rithm. Using a machine-independent analysis, 
we have shown that this algorithm is faster than both the Cohen-Sutherland algorithm and the Liang-Barsky 
algorithm. Using program transformation techniques we showed how geometric transfor- mations on the line 
to be clipped could be performed by modified program text without the overhead of actually exe- cuting 
statements to perform the transformation. Currently, we are investigating the possibility of extending 
it to polygons and to the 3-dimensional case. Acknowledgements The authors would like to acknowledge 
the useful discussions with colleagues and students at the University of Western Ontario, especially 
Ti m Walsh. We are very grateful for the reviewers' suggestions, which we have incorporated, within the 
space allowed. Financial upport for this research was provided by the National Science and Engineering 
Research Council (NSERC) of Canada. REFERENCES [I] Newman, W. M. and R. F. Sproull. Principles of Interac- 
tive Computer Graphics, 2nd ed., McGraw-Hill, New York, 1979. [2] Sproull, R. F. and I. E. Sutherland. 
A Clipping Divider, FICC 1968, Thompson Books, Washington, D.C., pp. 765-775. [3] Cyrus, M. and I. Beck. 
Generalised Two- and Three- Dimensional Clipping, Computers and Graphics, Vol. 3, No. 1, 1978, pp. 23-28. 
[4] Liang, Y.-D. and B. A. Barsky. A New Concept and Method for Line Clipping, ACM Transactions on Graph- 
ies, Vol. 3, No. 1, 1984, pp. 1-22. [5] Sobkow, M. S., Pospisil, P. and Y.-II. Yang. A Fast Two- Dimensional 
Line Clipping Algorithm, University of Saskatchewan Technical Report, 86-2. [6] Hoare, C. A. R. et al. 
Laws of Programming: a tutorial paper, Oxford University Programming Research Group PRG-45, 1985. [7] 
Arsac, J. I. Syntactic Source to Source Transforms and Program Manipulation, Communications of the ACM, 
Vol. 22, No. 1, 1979, pp. 43-54. I R ....-+ iT ~" Fig. I Intersection points computed b5 previous al,3orithms 
top le?t top top right corner edge cornet- region resion region le?t risht edge window edse resion resion 
 bottom le?t bottom bottom right edge corner region resion region c orner Fi 9. 2 Subdivision o? the 
plane into regions -l~-l~r]q i i | i i i 1 t 11 ITi ~ | I I I I I | I I I I I I I I I 1 1~ I 1 1 l-r~ 
l 1111111 ~ 71~Iq I I I I I I I I I I I I-1"I~ I I l i i i I I I i | I I l'l']'~Tl~lq I [ I I i I I J~'~R~ 
[~|'I IIIII tlll III I I~ tl II lllllll I III I I I I I~ I I III III I I I k~RRR~ ['FI~[TIq I I I L I 
I I I I FIt I I I I I I II II II Ill I II I |I I I I I I I I I I I~RRRRR~ ~i i ii ii i ii i i iI II 
I~ II II |i III II III II Ill I~I II I I | ~(RRRRRR -1~12'12~.L 1 ........... ~ ........ 1 ........ l 
t ,~ I t ,~RRRRRRRRRR~ ~LLLLLL[LE%.LI L £ t I t t~ I I I I I t L L t I L Z t t t A I I t I~ £ ~RRRRRRRRRRRRR~ 
~LLLLLLLLLLLI~[~L~6.t L[i t I t t t L t t I t i t I i t t t ]71-I I~.RRRRRRRRRRRRRR| [LLLLLLLLLLLLLLLLL~ 
............ .." I~F.RRRRRRRRRRRRRR| iLLLLLLLLLLLLLLLLL .........-'"... rA ." RRRRRRRRRRRRRRRR| iLLLLLLLLLLLLLLLLL 
.....":~" RRRRRRRRRRRRRRRR 'LLLLLLLLLLLLLLLL~ ........ \ RRRRRRRRRRRRRRRR I ~LLLLLLLLLLLLLLLLLI] ""'" 
\ RR.RRRRRRR RRRRRRR! ILLLLLLLLLLLLLLLLL d ........ \ RRRRRRRRRRRRRRRRI iLLLLLLLLLLLLLLLLL ...."'" ~ 
RRRRRRRRRRRRRRRR i[lTl ............ i~ .... RRRRRRRRRRRRRRRR] LLLLLLLLLLLLLLi~i,:.~BBBBB B BB B B BB 
BB BBf~ RR.R RRRRRRRRRRRR! iLLLLLLLLLLLI~3~ B B~ B B B B B B B B B BBB BB BBB B pI~RRRRRR RRRR RRRR[ 
iLLLLLLLLL[.a:,'I~ BBB B B~BBB BB B BB BBBB BBBBB B ~ BI~RRRRRRRRRRRRR] ~LLLLLL~..~'I~'BBBB B B B B~BB 
B BB BBB BBB B B BBBB B ~ B B ~RR RRRRRRRRRR .ILLLi,~'BBBBBBBBBBB~BBBBBBBBBBBBBBBBBB~BBB~RRRRRRRRRRRR! 
-I~£~B BBBBBBBBBBBB~BBBBBBBBBBBBBBBBBB~BBBB~RRKRRRRRRRI LiBBBBBBBBBBBBBBBB~BBBBBBBBBBBBBBBBBB 3BBBBB~RRRRRRRRRR 
 iBBBBBBBBBBBBBBBB~BBBBBBBBBBBBBBBBBB 3BBBBBB~RRRRRRRRR LBBBB.BBBBBBBBBBBBJ~BBBBBBBBBBBp_BBBBBB ~BBBBBBBRRRRRRRRR| 
 Fig. 3 Subdivision of the plane when Pl is in the window  ~,~ SIGGRAPH '87, Anaheim, July 27-31, 1987 
[ ..................................... ~TLII'n_;IIXLTLTL'n..TL'rLTL'n..T~ i /ll.TLTLTL1LTLTL'n.TLTUT.TLTLTi 
CS LB NLN F CS~ .75LB" NLN~. 5 21 i~.75 ~.5 0 14.75  i ,mTLTLTL~TLTLTLTLTL~TL~T I 1 1 0  i ZL'n'~TLTLTL'n:n'~'n"m'n'~TLTI 
3 I/3 55  i .ZTLTL'II.TLTLTLI~TLTLTLTLTLTLIlTLTI i Z~LTLYLTLTLTLTLTLIITLTLTLrLrLTLYL~ CS LB NLN i/ 
 i /~LTL'IIILTLTLTLTLI~TLIITLll;It 9.5 10.5 3.5 1 0 12-'~.9.~R] 3.5 i . ~TLT~TLT~rcTLTL~TLTL~.~,rS.LRLRLR~ 
0 0 0 I...................... :LTLTLTLTLTLTLTLTLTbllL.t~ .£~RLRLRLRL R L~ 0 4 0 i :." LLLLLLUJ/..LLI.J/ 
-RLELRLRLRLRLRLI~i.i~ 0 0 0 CS LB NLN  0 2.5 0 ! / LLLLE~I,~f~iLLLLLLLLI~ RLRLRLRLRLPJ-RLPJ- ~ 3b.5 
20 g.5 / ..~-~-~u~u-uu~u-u~u~W~u~u~R u~-~ 2.5 4 2 i P 1 -'-":-.........~LilJ ! r ! ! 7 ! ! LLLLLLLLI.IRLRLRLRLRLRLRLPd..RI 
7.5 6 5 i "~::7---.__ LU t t t t t u..LLLLL RLRLRLRLRI.Pd..RLRLpj 2.5 4 3 2.5 4 2 CS LB NLN COMPARISONS 
32 /20 8.5 ~LB LB LBLB L B LBL B LB L~ L~ E~L~.L~LRL RL~ + 2/ 4 2 l "~BLBLBLBLBLBLBflBLBLB LBLBLB~ 
6 6 4  j "m~SLBLBLBLBLB~BLBLBLBLBLB LBLBLB] /~ 4 2  I | "%~BLBLBLBII~LBLB LBLBLBLBLBLHI / 4 2",d~LBLB[~BLBLBLBLBLBLBLBLB| 
; "~Bb~LBLBLBLBLB LBLB LB  ! I "N~BLBLBLBLBLBLBLBLB I ! [ "~'B'-LB LB L B LB LB L B LBI / L .................... 
......................... BLBLBLBLBLB~ / _/ Lm.__~__L. / CS LB / NLN LB CS LB NLN CS NLN Fi$. 4 Subdivision 
oF the plane when  i0 10.5 3.5 21 20 8 32 20 8  Pl is in an edse region 0 01 0 1 2 1 2 4 2  0 4 
0 3 6 3 6 6 4  0 ,0 0 1 2 1 2 4 2 0 /2.5 0 1 4 l 2 4 2  / / /_ -n , i  i , ' , i  i ' I L I I 
l i i Pl ! i i ! ::-. I ............. I i  I "..----.--| - FIG.7 Analysis of the three algorithms 
when i ................. ~......---"---. ................. --.I [ ~ $~J..l I I 1 I 1111 I 1 I I I I 
I 1 ~TI'rT~.. .... I P1 is in an edge region i ~ [u.~;~.~ ........... hTRTRTRTRTR'm~ ! ~ LLLLLLU[~AI* 
lltt i~TRTRTR'i~TR'I~TRT~ "Further subdivision is needed. i 5. I.LLLLD.U.J.I~[ i i ,.j., ~t ,~RTRTRTRTRTRIRYRT~ 
Average shown is for the largest unbounded subregion." ! :[LLLLLLLLLLLLLt L l *, i%1 i~ I'RTRTRTRTR~__~I" 
~ [................... ~LBLBLSLBLBLSLSm~IR~~ i | t B LB LB i B LB LB L B LB L~I~BTB'YCRTRTRTRTRTRT~ 
i ! ~B LB LB L B LB LB LB LB L B I~W~TB TB?r/~TRTRTRTRT~ CS LB NLN ! I ~LBLBLBLBLBLBLB LBL~L~TBTB~RTRTRTRT~ 
9 6 2.5 I : ~LBLBLBLBLBLBLBLBL~LB~';BTBTB~TRTRTII 0 0 0 i ! 'tBLBLBLBLBLBLBLBL~LBLBh~BTBTBT~RTt 0 2.5 
0 i i ~BLBLBLBLBLBLBLBLt~LBLBLI~EP~TBTBT~p~ 0 0 0 [ i ~LBLBLBLBLBLBLBL~LBLBLBLB~TBTBT~ 0 1.5 0 L..................... 
i__ %--.~--B--L.B. B--L.B-Ir-B.L LB 5 BLB LB L 6~BTBTI~ L--B.L-B--~.~  [ CS LB NLN CS LB NLN 9.5 10.5 
3.75 9 10.5 3.75 1 FiS. 5 Subdivision oF the plane when  ~ 0 0 0 0 P! is in a corner resion    
'-" -°°- \ oo ! I o o o,o I \ ~o o \ \ 2.5 . 0 2.5 0 , ~s ~ ~ c~ \ 25.5 20 1 .75 I CS LB NLN \ 1.5\ 
2 1  i iTM CS LB NLN I 1.5 2 1 1.5 2\ 2 1-5 25.5 20 8 \ 4.5 "6 4 4.5 05.5 21 20 7.5 ~ 4.5 6 4 1 2 
1 1.5 4 \ 1 1.5 3.5 ~0 3 6 3  l 1.5 2 2 1.5 4 1 1 2 1 1 4 1 CS LB NLN ~ CS LB NLN COMPARISONS 36.5 
20 36.5 20 8 + 2.5 4 2.5 4 2 CS LB NLN P1 7.5 6 7.5 6 5 COMPARISONS * 2.5 4 2.5 4 3 i0 20 8  + 0 
0 0 / 2.5\4 2.5 4 2 0 6 0 0 0 0  CS LB NLN / 41 20 i0 0 4 0 3 4 2 9 6 6 3 4 4 3 4 2  CS LB NLN 25 
14.5 8 1.5 0 0 4.5 5.5 5 J 1.5 0 3 1.5 3.5 0 FIG.6 Analysis of the three algorithms when P1 is in 
the window FIG.8 Analysis of the three algorithms when P1 is in a corner region  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37433</article_id>
		<sort_key>263</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[Planar 2-pass texture mapping and warping]]></title>
		<page_from>263</page_from>
		<page_to>272</page_to>
		<doi_number>10.1145/37401.37433</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37433</url>
		<abstract>
			<par><![CDATA[The 2-pass tranformation replaces a 2-D (2-dimensional) transformation with a sequence of orthogonal, simpler 1-D transformation. It may be used for the closely related processes of texture mapping and warping in computer graphics and image processing. First, texture maps onto planar quadric and superquadric surfaces and, second, planar bicubic and biquadratic warps of images are shown to be 2-pass transformable. A distinction between serial and parallel warps is introduced to solve a confusion in terms between computer graphics and image processing. It is shown that an <i>n</i>-th order serial polynomial warp is equivalent to an (<i>n</i><sup>2</sup>+<i>n</i>)-th order parallel polynomial warp. It is also shown that the serial equivalent to a parallel polynomial warp is generally not a polynomial warp, being more complicated than a polynomial. The unusual problem of bottlenecking and the usual one of antialiasing are discussed in the 2-pass context.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Hierarchy and geometric transformations</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010240.10010244</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision representations->Hierarchical representations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010240.10010244</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision representations->Hierarchical representations</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P15765</person_id>
				<author_profile_id><![CDATA[81100078209]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alvy]]></first_name>
				<middle_name><![CDATA[Ray]]></middle_name>
				<last_name><![CDATA[Smith]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pixar]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Barr, Alan H. Superquadrics and Angle-Preserving Transformations, IEEE Computer Graphics and Applications, January, 1981, pp. 11-23.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bennett, Philip P., and Steven A. Gabriel, System for Spatially Transforming Images, United States Patent 4,472,732, September 18, 1984. (Assigned to Ampex Corporation. This is one of the patents for the very successful ADO (Ampex Digital Optics) product. See also U. S. Patents 4,463,372 and 4,468,688.)]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807505</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Catmull, Edwin, and Alvy Ray Smith. 3-D Transformations of lmages in Scanline Order, Computer Graphics, Vol. 14, No. 3, pp. 279-285, July, 1980. (SIGGRAPH 80 Conference Proceedings).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13056</ref_obj_id>
				<ref_obj_pid>13050</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Fant, Karl M. A Nonaliasing, Real-Time Spatial Transform Technique, IEEE Computer Graphics and Applications, January, 1986, pp. 71-80. (See also the Letters to the Editor section of IEEE Computer Graphics and Applications, March, 1986, pp. 66-67, and July, 1986, pp. 3 and 8.)]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Fraser, Donald, Robert A. Schowengerdt, and Ian Briggs. Rectification of Multichannel Images in Mass Storage Using Image Transposition, Computer Vision, Graphics, and Image Processing, Volume 29, Number 1, January, 1985, pp. 23-36. (See also Corrigendum, Volume 31, Number 3, September, 1985, p. 395.)]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>16579</ref_obj_id>
				<ref_obj_pid>16564</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Paeth, Alan. A Fast Algorithm for General Raster Rotation, Graphics Interface '86 Proceedings, May, 1986, pp. 77-81.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Smith, Alvy Ray. Projected Superquadrics are 2-Pass Transformable, Technical Memo 54, Computer Graphics Department, Computer Division, Lueasfilm Ltd., August, 1982 (now Technical Memo 54, Pixar).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Smith, Alvy Ray. A 2-Pass Solution to the Planar Biquadratic Patch, Technical Memo 128, Computer Graphics Department, Computer Division, Lucasfilm Ltd., May, 1985 (now Technical Memo 128, Pixar).]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Smith, Alvy Ray. A 2-Pass Solution to the Planar Bicubic Patch, Technical Memo 132, Computer Graphics Department, Computer Division, Lucasfilm Ltd., June, 1985 (now Technical Memo 132, Pixar).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Smith, Alvy Ray. Serial vs Parallel Warps, Technical Memo 134, Computer Graphics Department, Computer Division, Lucasfilm Ltd., June, 1985 (now Technical Memo 134, Pixar).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Smith, Alvy Ray. Digital Filtering Tutorial for Computer Graphics Technical Memo 27, Computer Graphics Department, Computer Division, Lucasfilm Ltd., March, 1983 (now Technical Memo 27, Pixar). Also in Tutorial Notes for Siggraph 1983 and Siggraph 1984.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Smith, Airy Ray. Digital Filtering Tutorial, Part H Technical Memo 44, Computer Graphics Department, Computer Division, Lucasfilm Ltd., May, 1983 (now Technical Memo 44, Pixar). Also in Tutorial Notes for Siggraph 1983 and Siggraph 1984.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~) ~ Computer Graphics, Volume 21, Number 4, July 1987 PLANAR 2-PASS TEXTURE MAPPING AND WARPING Alvy 
Ray Smith Pixar ABSTRACT The 2-pass transformation replaces a 2-D (2-dimensional) transformation with 
a sequence of orthogonal, simpler 1-D transformations. It may be used for the closely related processes 
of texture mapping and warping in com-puter graphics and image processing. First, texture maps onto planar 
quadric and superquadric surfaces and, second, planar bicubic and biquadratic warps of images are shown 
to be 2-pass transformable. A distinction between serial and parallel warps is introduced to solve a 
confusion in terms between computer graphics and image processing. It is shown that an n-th order serial 
polynomial warp is equivalent to an (n2+n)-th order parallel polynomial warp. It is also shown that the 
serial equivalent to a parallel polynomial warp is generally not a polynomial warp, being more complicated 
than a polynomial. The unusual problem of bottlenecking and the usual one of antialiasing are discussed 
in the 2-pass context. KEY WORDS AND PHRASES 2-pass, texture mapping, warping, serial warp, parallel 
warp, quadrics, superquadrics, bicubic warp, biquadratic warp, bottleneck, antialiasing CR CATEGORY INTRODUCTION 
The term warping is often used in image processing to mean a 2-D resampling of an image. For example, 
when a photo of the Earth's surface is transmitted from a satellite to ground, it is typically warped 
to correct the surface patch for surface curvature, an oblique viewing angle, or lens aberra- tions. 
In general, warping is a continuous mapping of a 2-D planar region into another 2-D planar region. In 
image pro- cessing, it is the digital approximation of such a mapping which is of interest. Pelion to 
copy without fee all or part of this material is granted provided that the copies are not made or distributed 
for direct commercial advantage, the ACM copyright notice and the title of the publication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery. 
To copy otherwise, or to republish, requires a fee and/or speofic permission. &#38;#169; 1987 ACM-0-89791-227-6/87/007/0263 
$00.75 The term texture mapping is used in computer graphics to also mean 2-D resampling of an image, 
particularly when the target is the 2-D projection of a 3-D surface, viewed through a viewing transformation 
with perspective. It is the digital approximation of a presumably continuous mapping that is of interest 
in computer graphics also. A useful distinction may be made between the use of warping in image processing 
and texture mapping in com-puter graphics. Image processing uses the mapping to correct or rectify images 
-to map a nonrectangular patch onto a rec- tangular one -while computer graphics proceeds the other direction 
to map a rectangular patch onto a nonrectangular one. Another distinction -a confusion really -between 
the two historically separate disciplines is not helpful. The terms biquadratic and bicubic are used 
differently by the two groups. The terms serial map (warp) and parallel map (warp) are introduced to 
clarify this situation. Examples from each of computer graphics and image processing are examined here 
and shown to be effectively simplified using the 2-pass technique [3]. First, the 2-pass texture mapping 
of a texture onto a planar superquadric sur- face is derived. For example, a rectangular framebuffer 
pic- ture may be mapped onto a disk by the technique. Then the 2-pass warping of an image onto a planar 
bicubic or biqua- dratic patch is derived. The case where the edge of an image remains a rectangle but 
the interior points are warped -which is called a frozen-edge warp -is particulary suitable for image 
processing. Then the mathematical relationship between serial and parallel warps is derived using some 
of these results as examples. Finally, two generic problems with the 2-pass technique are emphasized. 
The mathematical problem of bottlenecking is reexamined, and since it is the digital approximation of 
the 2-pass technique which is of primary interest, the important subject of antialiasing is investigated. 
The work here builds on the original paper [3] and con- tains results derived in a series of internal 
technical memos [7-10]. 2-PASS NOTATION AND REVIEW If u s and v s are the coordinates of a source picture 
and u t and v t those of a target, then a general parallel 2-D coor-dinate mapping -or parallel map for 
short -may be defined by any two functions x and y such that  ~ SIGGRAPH '87, Anaheim, July 27-31, 
1987 (U t ,V t) = ( X (U s ,V s ), y (u s ,v s) ) . In this paper, u and v are understood to be parameterizations 
of the horizontal and vertical coordinates of a picture. Parameters u and v with no subscript are assumed 
to be u s and v s . A picture of course is a mapping of each point of uv parameter space to a set of 
colors -e.g., the grays. The term image will be used here to mean picture -as in "image com- puting" 
or "image processing" -as well as for its usual mathematical meaning, with the context distinguishing 
which use is intended. The term image computing will be used to mean all of traditional computer graphics 
plus all of tradi- tional image processing. This paper is an image computing paper because parallel maps 
include the texture maps of com- puter graphics and the warps of image processing. Thus parallel maps 
will also be called parallel warps. The objects on which digital image computing focuses are digitized 
pictures -sampled versions of continuous images, where each sample is of course a pixel. Although we 
will talk of mappings of the set of continuous pictures to itself, it is really the sampled source and 
target pictures which are of ultimate interest. Sampling and filtering theory is now a well-understood 
discipline for correctly representing continuous pictures by arrays of pixels, but it is computationally 
expensive. The 2- pass technique is interesting because it suggests a cheaper solution for parallel maps 
on sampled pictures although it is a technique described in terms of continuous functions and pic- tures. 
Perhaps the most general presentation of the 2-pass technique appears in [3], but approximately simultaneous 
work was occurring in industry [2] and in image processing [5]. All of these in turn refer to earlier 
works on the special case of image rotation in the plane. The basic idea is to replace a parallel map 
with a sequence, or composition, of parallel maps, where each map- ping in the sequence is computationally 
more interesting (e.g., cheaper) than the original map. The 2-pass technique replaces a given parallel 
map with a sequence of two parallel maps, where the first applied is called the first pass, or hor- izontal 
pass, and takes the form (ui ,vi ) = (fv, (u,),v,) where u i and v i are the coordinates of the intermediate 
image. The second pass, or vertical pass takes the form (ut ,vt ) = (u i ,gui (Vi )) . The decomposition 
of a parallel map into a sequence of map- pings results in an overall mapping from source to target called 
a serial 2-D coordinate mapping or a serial map (serial warp) for short. (It has been shown that three 
map- pings in the sequence is of interest in the case of rotation in the plane [6].) It is sometimes 
important to reverse the order of the decomposition, with the vertical pass first, the horizontal pass 
second. The functional expressions are generally different for the two orderings. When a distinction 
between the two orderings is required, "horizontal pass first" or the "vertical pass first" will be used. 
The horizontal pass first is assumed unless otherwise stated. See Figure 1. Each of the two mappings, 
the first and second passes, is considered simpler than the given parallel map because fv, applies across 
a line of constant v s and g,, down a line of constant u i. In the digital approximation, lines of constant 
v s are the horizontal scanlines and those of constant u i are verti- cal scanlines. Resampling along 
a scanline is a 1-D problem. Thus, in a sense, the 2-pass technique is the replacement of a 2-D resampling 
problem with a sequence of two 1-D resam- plings. A more careful analysis shows that a true 1-D resam- 
piing is sometimes inadequate, but a simplified 2-D resam-pling may suffice. This will be explored further 
below. The 2-Pass Technique The problem of replacing a given parallel map with a serial equivalent was 
solved in [3]. It is restated and solved again here to show the use of the current notation. Given parallel 
map (x (u s ,v s), y (u s ,v s )) = (u t ,v t ), it is desired to decompose it into two sequential mappings 
(X "(U s ,V s ), V s ) = (U i ,V i ) (ui, Y "(ui ,v i )) = (u t ,vt) . The problem is to express x" 
and y ', the two sequential scan-line functions, as functions of the given mappings x and y and the source 
coordinates u s and v s for x" or the intermedi- ate coordinates u i and v i for y'. The horizontal-pass 
scanline function is obvious: x'(u s ,v s ) ~ f v, (us) = x (u s ,v s ) . We shall call this the first 
step of the 2-pass technique. For the vertical-pass scanline function, note that u i = x(us,vs) and v 
s = v i. Let hue be the solution of u i = x (u s,v s) for u s. This solution is the second step. So hut 
is a function of v s = v i and Y "(ui ,vi ) "~ gu, (vi) = Y (hu, (vi),vi ) for the third step. Vertical-pass-first 
scanline functions are derived in an analogous manner. A difficulty with the 2-pass technique is obtaining 
a closed form for the second-pass scanline function. Some-times this is not possible and numerical techniques 
must be used. In other cases, such as when there are multiple solu- tions hut , numerical techniques 
are preferred. The bicubic and biquadratic warping techniques in this paper are of this variety [8, 9]. 
Another difficulty is the so-called bottleneck problem. There are cases [3] where the two scanline functions 
exist in closed form but are useless. If the source picture is mapped to a point or to a line segment 
by the first pass, then it hardly matters that a mapping exists which takes this intermediate image to 
the desired target picture. Although the shape would be correct, the color information would have been 
lost in the vanishing area bottleneck of the intermediate image. Although experience has shown that a 
bottleneck can always be avoided -e.g., by reversing the order of horizontal and vertical passes -this 
has not yet been proved to be the case. A final difficulty appears only in the digital approxima- tion 
of the 2-pass technique. This is the antialiasing problem alluded to earlier. If only 1-D sampling and 
filtering is used  (~ '~' Computer Graphics, Volume 21, Number 4, July 1987 along scanlines, then serious 
aliasing can occur. In many interesting cases studied in [2, 3, 5], this is not a problem, but in others 
-such as in this paper (and in [7]) -it is. Again, experience has shown that aliasing artifacts can always 
be avoided -e.g., by reversing the order of horizontal and vertical passes -but this has not yet been 
proved to be the case. SUPERQUADRIC TEXTURE MAPPING Following A1 Barr [1], given a "horizontal" plane 
curve h and a "vertical" modulating plane curve m h(v) = [hl(V ) h2(v)], Vo_<V<_Vl, m(u) = [ml(u ) m2(u)] 
, Uo_<U.~.Ul, a spherical product surface is defined to be S(u,v)=[ml(U)hl(V) ml(U)h2(v ) m2(u)] where 
Uo<_U _<u 1, Vo-<V-<V 1. We have reversed the orientation of h and m from [1], so h is actually vertical 
here -i.e., it is a function of the vertical parameter v -and m is horizontal. A projected spherical 
product surface has m2(u ) = 0 -i.e., is the orthographic projection of a spherical product surface into 
the xy-plane. Barr [1] has shown how the (super)quadrics (super)ellipsoids, (super)hyperboloids of one 
and two sheets, and (super)toroids -can be represented as rescaled spherical product surfaces. A (super)toroid 
may be thought of as an extended (super)ellipsoid; it has the same form except the modulating function 
is offset by a constant a and u varies over 2g radians. Table 1 gives the details of the defining functions 
for the superquadric family. An n-hyperboloid is an hyperboloid with n sheets. In all cases, the superquadrics 
give the quadrics if the two squareness parameters e and e' are set to 1. It will be shown below (see 
also [7]) that the projected (super)quadrics, under "standard computer graphics transfor- mations", are 
2-pass transformable. A parallel map is 2-pass transformable if it can be converted into an equivalent 
serial map by the 2-pass technique described above. The standard computer graphics transformations are 
the following: In computer graphics, objects are flown through 3-space and projected into 2-space with 
a perspective projec- tion using a 4x4 matrix multiplication followed with division by the homogeneous 
coordinate. These classic transforma- tions shall be called CG transforms. The 4x4 matrix will be represented 
here by fj n T= m1 gk o " h I p The transformation of a point [X(u,v) Y(u,v) Z(u,v) 1] by a CG transform 
is accomplished by [X'Y'Z'W']=[X Y Z liT. The homogeneous divide by W" after this transform gives X" 
aX +bY+cZ +d x(u,v)= W---7= mX +nY +oZ +p Y' eX +fY+gZ +h y (u ,v ) = = W" mX +nY +oZ +p" For example, 
if X (u,v) = u, Y (u ,v) = v, and Z (u,v) = 0 and we apply the 2-pass technique, the simple rectangle 
under CG transform result of [2, 3] is obtained. The 2-D Superquadric 2-Pass Functions The 2-D superquadrics 
are just the projected 3-D super- quadrics -i.e., with m2(u) = 0. The horizontal and vertical scanline 
functions for the 2-D superquadrics under CG transforms are derived to show a typical application of 
the 2-pass technique. The general class of 2-D superquadrics under 3-D CG transforms is given by [ml(U)hl(V 
) ml(U)h2(v ) 0 1] a b c e f g i j k m] n 0 " d h I p Scaling factors for the two axes of the projected 
superquadric have been subsumed into the diagonal elements of the CG transform matrix. Thus aml(U)hl(V) 
+ bml(U)h2(v) + d x (u ,v ) = mml(U)hl(V) + nml(u)h2(v) + p eml(U)hl(V) + fml(U)h2(v) + h y (u ,v ) = 
mml(U)hl(V) + nml(u)h2(v) + p" Application of the first step of the 2-pass technique immediately yields, 
as the horizontal scanline function for scanline v s : A(vs)ml(u ) + d fv,(u) = M(vs)ml(u) + p where 
A(v) = ahl(V) + bh2(v ) M(v ) = mh i(V ) -t- nh2(v) . The second step is to solve A(V)ml(u) + d u i = 
M(V)ml(u ) + p for u = hu,(v) for vertical scanline u i. Expanding and rear- ranging gives d -pu i ml(u 
) = M(v)ui -A(v )' As will be seen immediately, it is unnecessary to complete the solution of this equation 
for u. The third step yields the vertical scanline function by substituting the expression just obtained 
for mr(u) into the expression above for y (u ,v ): (d -PUi)(ehl(V) + fh2(v)) + h(M(v)u i -A(v)) gut(V) 
= (d -PUi)(mhl(V) + nh2(v)) + p(M(v)u i -A(v)) Since v i = Vs, we will drop the subscript from v i also. 
The scanline function may be rearranged to give E(u i)h l(v ) + F(u i )h 2(v ) gut(V) = Ghl(v) + Hh2(v) 
E(u), F(u), G, and H are defined in Table 3, which, with SIGGRAPH '87, Anaheim, July 27-31, 1987 | Table 
2, summarizes the application of the formulas just derived to the superquadric family. All quantities 
are as defined above if not otherwise specified. The vertical-pass-first scanline functions may be derived 
similarly by exchanging x and y and also u and v in the expression for the parallel mapping and then 
applying the 2- pass technique. To get an analytic solution, e" = 1 must be assumed. This will be called 
a semi-superquadric case. Suppose it is desired to map the contents of a framebuffer onto a disk with 
T the identity transformation. The parameterization used thus far is awkward for this case since it generates 
a polar view. A more natural mapping is that used for Figure 2. It corresponds to an ellipsoid expressed 
as the spherical product surface S(u,v) = [ m2(U)hl(V ) h2(v) ml(U)hl(V ) ] with mr(u), m2(u), hl(V), 
h2(v) as before but with 7U -~ < u < 7r, --~- < v < ~-. This is nothing more than a per- mutation of 
the 3-D coordinates used before and a swapping of the parameter space axes. For the example of mapping 
a framebuffer to a disk, the horizontal-pass-first formulas hold for the superquadric case in the alternative 
parameterization, just as before, and the vertical-pass-first functions are simi-larly good only up to 
the semi-superquadrics. Figure 2 also illustrates exercise of the two squareness parameters. BICUBIC 
AND BIQUADRATIC WARPING A bicubic patch may be described parametrically by two parameters u and v, each 
varying over the interval [0.,1.], and the two equations below: [ a°ala2a3 a4 a5 a6 a7 [i 3 v 2 _ uAvT 
x(u,v)=[u 3 u 2u 1 ] as a9 al0 all a12 a13 a14 a15 bo bl b2 b3 v 3 b4 b5 b6 b7 v2 _= iiBv T y(u,v) = 
[ u 3 u 2 u 1 ] b8 b9 bl 0 bl 1 b12 b13 b14 b15 The addition of a third equation of similar form, z(u,v) 
= uCv T, defines a full 3-D bicubic patch, and a fourth, w (u ,v) = uDv T , may be added for the homogeneous 
coordinate convenient for perspective transformations. How-ever, attention shall be restricted here to 
the planar case. Moreover, it will be computationally advantageous to con-sider only those planar patches 
which are nonfolded, or sin-gle valued. That is, no point (x,y) is the image of more than one point (u 
,v). The equations for x and y expand into X(U ,v) = aott3vS+alu3vZ+a2u3v+a3u3+a4u2v3+asl~2v2+a6u2v+aTl,~2+ 
a suv3+a 9uv2+a lOUV q-a 11 u +a 12v3+a 13v2+a 14 v 4-a 15 y(u ,v) = bou3v3+btu3v2+b2u3v+b3u3+b4u2v3+bsu2v2+b6u%+b-tu:2+ 
b suv3 +b 9UV 2+b loUV +b 11 u +b 12v3+b tav2+b 14v +b is which may be cast into expressions of the 
known coordinates x i and Yi by solving for the boundary conditions. For exam- pie, v = 0 corresponds 
to one edge of the bicubic patch and v = 1 to the opposite edge, and similarly for u = 0 and u = 1. Define 
matrix X to be the following array of sixteen specific x coordinates (see Figure 3): Ix(0.0) x(uo,O) 
x(u~,O) x(l,0) [x0 xt xz x3 "/x(0.v0) x(uo,vo) x(u~,vo) x(1,v0) [x4 xs x6 x7 X= [x(0.vl) X(Uo,Vl) x(ux,vl) 
x(1,vl) ---xs x9 xt0 xn Lx(O,1) x(u0,1) x(ul,1) x(1.1) xt2 x13 x14 x15 Then it can be shown that the 
x i are related to the a i by a compact matrix equation: X = VA TU T where 0 0 0 1 .g u0 1 U= [13 u2 
Ul 1 11 1 and V is defined similarly in terms of v 0 and v 1. This equation can be solved for the a 
i in terms of the xi: A = U-1XrV -r where V -T represents the inverse of the transpose of V. Similarly, 
the b i in terms of the Yi are given by B = U-tyTv -T where Y is defined similarly to X, but for specific 
y coordi-nates. It can be shown that U -1 may be represented as follows, where for notational convenience, 
we let ~-0 = l-u0, Et = l-u1, u o = l+u0, u I = l+Ul, Uto = ut-uo, Uot = Uo+Ul, u01 = Uo+Ul+l, and ~-Ol 
= uoul+uo+ul, and similarly for v 0 and v I : 1 0 0 0 UOUl -1 l -1 1 0 1 o o U -1 = U01 --U 1 L --UoI 
U 1 //0 --UO --U01 U0U l 0 /A 0/~0U 10 0 1 0 UoU 1 0 0 0 U IU-lU 10 0 0 0 1 UOUl and similarly for V 
-1 in terms of the v i . A special case is the cubic patch, a bicubic patch with terms which have exponents 
summing to three or less. This is equivalent to matrices A and B being all zeros above the bend-sinister 
diagonal. Several other special cases of interest are discussed below. A Special Case: The Bicubic Frozen 
Edge A simple special case (Figure 4) requires that the boun- dary of the bicubic patch be a rectangle. 
If the uv parameter space is thought of as a rectangular source picture and its image under x (u ,v ) 
and y (u ,v ) as a bicubic patch target pic- ture, then the special case requires that the rectangle 
around the rectangular patch map to itself -hence the Frozen Edge. Only the four internal control points 
(xs,Ys), (x6,Y6), (x9,Y9), and (xlo,Ylo) move from source to target. Thus ~ Computer Graphics, Volume 
21, Number 4, July 1987 X 5 X 6 1 i u° ul 1 X 9 Xl0 1 , u o u 1 1 0 0 0 0 v0 Y5 Y6 v0 Is Vl Y9 Yl0 Vl 
1 1 1 1 And these collapse the expressions for A to ao -(ao+a2) a 2 0 -(ao+ag) ao+a2+as+a 10 -(a2+a 
10) 0 A s -__. U-1xTv-T a8 -(as+a 10) al0 1 0 0 0 0 and similarly for B, beth of which become particularly 
sim- ple for the special case of the cubic frozen edge.  A Special Case: The Biquadratic Patch By a 
derivation analogous to that for the bicubic patch above and using the notation of Figure 5, A2 = u~x~v~ 
r where the subscript 2 denotes the biquadratic case (3><3 matrices) and __!_1 0 0 Ul 1 -1 1 1 U~ 1 
= -u I 1 -u t 0 0 u 1~-1 u 1 0 0 0 0 1 Ul and similarly for V~ -1 and also B 2. Common examples of biquadratic 
warps are the pin-cushion and barrel distortions of video -see Figure 7. So biquadratic warps may be 
used to correct for these distor- tions. Analogous to the cubic patch, a quadratic patch (or quadric 
patch) is defined to have only those terms with exponents summing to two or less, so all elements above 
the bend-sinister diagonals of the corresponding 3x3 A 2 and B 2 matrices are zeros. A Special Case: 
The Biquadratic Frozen Edge There is a Frozen Edge special case of the general biquadratic patch analogous 
to that for the bicubic patch dis- cussed above. See Figure 6. Using the techniques above, it can be 
readily shown that 0 1 = U~IxTv~ T a0-a 0 A2s = -a 0 a 0 0 0 0 0 bo~ -b° 0 = ufly vf r g2s = -b 0 1 
0 where X4--U [ ao = UlUlVlVl y4--Vl b 0 = UlUlVlVl and point ( x 4, Y4) is the only control point 
that moves. The quadratic frozen edge is a particularly simple spe- cial case of the biquadratic frozen 
edge. The bilinear patch was fully treated in [3]. The Horizontal Function fv,(u) For subsequent convenience, 
let the rows of A be denoted by a o, a t, a 2, and a 3. Also let f(v)=Av T =[f0(v) fl(v) f2(v) f3(v) 
IT = [ a0vT alvT a2vT a3vT ]T Direct application of the 2-pass technique first step yields f~,(u)= uAv[ 
= uf(vD for horizontal scanline v s and Vs T=[vs 3 v: v s 1]. The biquadratic case may also be represented 
in an analogous fashion. The Auxiliary Function h,~(v) The 2-pass technique second step requires that 
X (U ,V )--U i =0 be solved for u = h (v). (The subscript ui is dropped from h and g for convenience 
in this and the following section.) In words, the set of u's is desired which map into ui under the horizontal 
scanline functions. Since x (u ,v ) = uf(v) is cubic in u, the equation may be written as a general cubic 
equa- tion, the auxiliary cubic equation, au3+f~u2-~,u+~ = 0 where the coefficients are the following 
functions of v : tx = f 0(v) = a0 vr [~= f t(v ) = alvT ~/=/2(v) = a2v r = f 3(v)-u i = a3 vT-u i . 
 In general, the auxiliary cubic has three (non-polynomial) solutions, ho(v), hl(v),~and h2(v), which 
may be obtained using classic cubic equatio n solution techniques. It is difficult to determine which 
of-the three are the valid solu- tions, and two of them may be complex. The solution method suggested 
below capitalizes on the restriction to planar nonfolded patches to avoid these difficulties.  A Special 
Case: The Planar Nonfolded Bicubic Patch Nonfolded patches can have only one valid solution; only one 
u on each horizontal scanline can map to the current vertical scanline ul. This set of u's is a smooth 
function of v, u = h(v). Hence, if we find a solution u = h (0) for the first horizontal scanline, it 
can be assumed to be in the vicinity of the solution for the next adjacent ~ SIGGRAPH '87, Anaheim, 
July 27o31, 1987 scanline and hence be used as a first approximation in a Newton iteration to the solution 
for the second scanline. Then this solution can be used as a starting value for an iteration to a solution 
for the next scanline, and so forth, exploiting the coherence. So the problem of solving for h reduces 
to that of finding good starting values for the Newton iteration. A crude value would be u i itself. 
A more refined value comes from the fact that the horizontal scanline functions have already been derived 
in the first pass. For a given v, the scanline function fv (u) can be computed for a small number, say 
n, of values of u equally spaced along [0, 1] to find two images which bracket ui. Either of the corresponding 
values of u could be used as a starting value for the iteration or a linear interpolation between them. 
A set of starting values could be generated for all vertical scanlines by such a pro-cedure applied along 
just one horizontal scanline between passes. Figure 1 illustrates the use of Newton iteration to solve 
a planar nonfolded bicubic patch with the 2-pass tech- nique. The Vertical Function gu, (v) Direct application 
of the 2-pass technique third step yields three functions gi, depending on which of the three auxiliary 
functions hi, is used. Assuming only the planar nonfolded case, this reduces to one function g (v). Thus, 
for vertical scanline ui, g (v) = UhBV T where u h=[h3(v) h2(v) h(v) 1 ] . In general, this vector changes 
from (vertical) scanline to scanline u i . The biquadratic case is analogously handled. A nonfolded patch 
would have g (v) one-to-one on the domain [0, 1] for those points which are images of [0, 11 under some 
horizontal scanline function. The fourth, or alpha, channel of a framebuffer could be used to determine 
if a point fit this condition; its alpha channel would be empty if it were the image of a point outside 
[0, 1]. So nonfolded means that all scanline functions, horizontal and vertical, are one-to-one mappings 
on the domain [0, 1], subject to this condition. This can be shown to be equivalent to the definition 
of nonfolded given in the Bicubic and Biquadratie Warping section. Ordinary B-spline or Bezier patch 
tech-niques may be used to ensure a patch is nonfolded. SERIAL VS PARALLEL WARPS Summarizing, polynomial 
warps may defined by x (u s ,v s ) = u s AVs T y (us ,vs) = us Bv r where A and B are matrices of polynomial 
coefficients and u s and v s axe vectors of powers of u s and v s. A third-order parallel polynomial 
warp would have A and B be 4×4 matrices of constants and us =[ u3us2Us 1] v s =[v?v2vs 1] Since x and 
y axe third-order polynomials in two variables, the resulting warp is called a bicubic warp. The biquadratic 
warp is defined similarly but for A and B both 3×3 matrices and u~ =[u) us 1] vs =[v) v s 1] A second- 
or third-order serial polynomial warp would have f u, (Us) = X(Us,Vs) = usAv T gu,(Vi) = y (ui,vi) = 
uiBv T which is quite similar in form to the parallel polynomial warp described above. The parallel equivalent 
of this serial poly- nomial warp is derived below where it is seen to be a higher-order polynomial mapping 
and hence quite different in form from the parallel polynomial warp. The Parallel Equivalent of a Serial 
Warp Given a general serial warp (X (U s ,V s ),V s ) = (U i ,V i ) (ui ,y (ul ,vi)) = (ut ,vt ) the 
problem is to find x'(us,vs) = u t and y'(us,vs) = v t in terms of u s, vs, x, and y. The solution is 
straightforward using the notation: u t = u i =x(u s,v s) is already the desired solution for x'. That 
is, x '(us ,vs) = x (us ,v, ). Since v i = v s and u i = x (u s,v s), y "(u s ,v s) = y (u i ,v i) = 
y (x (us ,vs),vs) Example The parallel equivalent of a serial biquadratic polyno- mial warp is given 
immediately by x'(us ,vs) = us Av~ y'(us,v s) = [ (usAvsr) 2 usAv ~ 1 ]Bvs T . Thus the parallel equivalent 
of a second-order serial polyno- mial warp is fourth order in u s and sixth order in v s. Simi-larly, 
a third-order serial polynomial warp is equivalent to a parallel polynomial warp which is ninth order 
in us and twelfth order in v s . In general, the parallel equivalent of an n-th order serial polynomial 
warp is n2-th order in us and (n2+n)-th order in v s . In particular, for the biquadratic Frozen Edge 
case dis-cussed above and implemented serially by Thomas Porter as part of the Pixar Image Computer demonstration 
at the National Computer Graphics Association (NCGA) convention in Dallas, April, 1985, x(us,vs) = aous(1-us)vs(1-vs)+u 
s -aoUsUsVsVs+Us Y (ul ,vi) = bou i (1-u i )v i (1-v i )+v i --- bou i uivi ~.i+ui ~ Computer Graphics, 
Volume 21, Number 4, July 1987 The parallel equivalent of this is easily shown to be X "(U s ,V s ) = 
a OUs u s v s v s +u s y "(u s ,v s ) = a 0 b OUs ~ vs2V2( 1-u s us vs Vs )+Vs which is a sixth-order 
parallel polynomial warp. Clearly, it is important to know if a "biquadratic" warp is serial or paral- 
lel. Similarly the "bicubic" warp of the scarab beetle in [5] is a serial third-order warp equivalent 
to a twelfth-order parallel polynomial warp. The mappings in [5] are in reverse order to those given 
here with u s = uiAvf and v i = utBvT, but the argument still holds, in the reverse direction. The problem 
of converting between the order presented here and the reverse order is another whole problem not considered 
further here. The Serial Equivalent of a Parallel Warp The problem here is to find a serial decomposition 
of a parallel mapping. But, of course, this is exactly the 2-pass problem. In particular, it is shown 
above that parallel poly- nomial warps are equivalent to serial warps with x'(u~,v~) = u~ Av r and y'(u 
i,vi) = [ h 3 h 2 h 1 ]Bvf for the bicubic case and similarly( for the biquadratic case, where h is 
the solution of u s Av]-u i = 0 for u s. There are three solutions h for the bicubic case and two for 
the biqua- dratic case. The solutions are not polynomials, which proves that, in general, the serial 
equivalent of a parallel polynomial warp is not a serial polynomial warp. SHADING, DEPTH, MATTING, AND 
NORMALS Normals and z information at each point may be carried along through the 2-pass technique just 
as are colors (where alpha, or opacity, is assumed to be a fourth component of each color). Then shading 
information is computed from the normal information and color information, and depth from the z information, 
as traditionally done. The alpha channel is correctly transformed by the 2-pass technique. Therefore 
it serves as a matte channel so that a 2-pass transformed object may be correctly composited with other 
images. BOTTLENECK PROBLEM The area of the intermediate picture can be much less than that of either 
the source or the target pictures. This is called [3] the bottleneck problem. In fact, the intermediate 
area can be zero. This happens, for example, for a rotate about the picture plane normal by 90 degrees. 
In general there are several paths from source to target using the 2-pass technique. First, there is 
the horizontal pass followed by the vertical pass - the method usually assumed in this paper. Second, 
there is the vertical pass followed by the horizontal pass. Then there are variations on these two which 
incorporate a "preprocessing" step for which there is subsequent compensation. For example, in the case 
of rota- tion by almost 90 degrees -say 87 degrees -the bottleneck can be avoided by doing a simple transpose 
of rows and columns to effect a 90-degree rotation then a normal 2-pass transformation to get the remaining 
-3 degrees. The method which has been used successfully for CG transforms of a simple rectangle is to 
compute the intermedi- ate areas which would obtain via a set of four paths and select the path with 
the largest intermediate area. The four paths are (1) horizontal pass first, (2) vertical pass first, 
(3) transpose rows and columns then horizontal pass first, and (4) transpose then vertical pass first. 
The intermediate areas can be readily computed -the formulas are given in [3]. As mentioned in The 2-Pass 
Technique section, this has always worked but has not been proved to do so. The bottlenecking solution 
for the projected superqua- drics used here is simply that above. The justification is that a CG transform 
of a projected superquadric is the same as a mapping onto a projected superquadric in canonical position 
followed by a CG transform of the resulting 2-D image. The first step is non-degenerate -see Figure 2. 
Since this image falls within a rectangle, the second step is exactly that solved with the technique 
above. The bottlenecking problem for the bicubic and biqua-dratic warps is ignored here because warping 
is generally not used for large geometric distortions -such as scalings and rotations -but rather for 
relocation of points within the vicin- ity of the original positions -i.e., for scale factors of about 
1. and rotations of about 0. ANTIALIASING Most of this paper may be read independently of a digi- tal 
realization of the technique presented. In this section we address those artifacts which arise strictly 
because digital approximations of the scanline functions are implemented. The 2-pass technique is attractive 
because it promises to cheapen the antialiasing computations required by the equivalent serial mapping. 
How true is it that the 2-pass technique replaces a full 2-D antialiasing problem with a sequence of 
two simpler 1-D antialiasing problems -in the case of 2-D quadrics under CG transform? Suppose the 2-D 
antialiasing method we would have chosen in a full 2-D antialiasing application would integrate all the 
pixels in neighborhood N fp ) of source pixel p to obtain the target pixel p'. Presumably N(p) would 
be the pixel support of some antialiasing filter. Then a necessary condition that a serial map perform 
the same filtering would be that all these same pixels be used in the computation of p ". This implies 
that all pixels in N (p) map into the same vertical scanline during the first pass, so that the vertical 
pass can then map all of them -their intermediate images actually -into p'. This condition is rarely 
met, so it is surprising how often the use of two serial 1-D filtering steps actually works. Intuitively, 
it works whenever the horizontal pass does not skew neighboring horizontal scanlines in N(p ) very far 
with respect to one another. Another way to say this is that the 1-D filtering trick works whenever there 
is not a high fre- quency change, in the vertical direction, of the object being transformed. "High frequency" 
in this case means near or greater than the spatial frequency of the horizontal scanlines. Figure 8 illustrates 
the point, and also the fact that changing the order sometimes corrects the problem. As pointed out earlier, 
there is no proof that this is always the case. ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 It should be 
no surprise that 1-D filtering in the discrete 2-pass should occasionally result in aliasing artifacts 
-one whole dimension cannot be thrown away without seeing some effect. The continuous 2-pass technique, 
of course, isn't plagued by this problem. A higher-ordcr antialiasing technique to use when the 1-D filtering 
trick fails is easily described. Consider a horizontal scanline of pixels, modeled as a row of abutting 
squares. The input domain image of an output pixel which intersects this seanline is an area bounded 
above and below by parallel line segments and left and right by curves (straight lines for several interesting 
transformations). The average intensity over this area is a more accurate average than the swicfly 1-D 
average over say the midline of this area. Notice that this "scanline area" technique takes the 1-D passes 
back into 2-D computa- tions. It is essentially a box filtering technique. Higher order filters would 
give better results as usual. All 1-D sampling and filtering used for the figures in this paper is derived 
from the standard theories as described, for exarnple, in [11, 12]. ACKNOWLEDGEMENTS Colleagues Ed Catmull, 
Charlie Gunn, Pat Hanrahan, and Tom Porter have all provided important ideas for this 2-pass work. Ed 
and I worked on the original idea together. Charlie championed Newton iteration. Tom implemented the 
serial biquadratic frozen-edge and Pat the full planar serial biqua- dratic on the Pixar Image Computer. 
Tom's implementation - and subsequent arguments about what a biquadratic warp really is -inspired the 
resolution, presented herein, of the long-standing confusion between serial and parallel maps. REFERENCES 
[1] Barr, Alan H. Superquadrics and Angle-Preserving Transformations, IEEE Computer Graphics and Appli- 
cations, January, 1981, pp. 11-23. [2] Bennett, Philip P., and Steven A. Gabriel, System for Spa- tially 
Transforming Images, United States Patent 4,472,732, September 18, 1984. (Assigned to Ampex Corporation. 
This is one of the patents for the very suc- cessful ADO (Ampex Digital Optics) product. See also U. 
S. Patents 4,463,372 and 4,468,688.) [3] Catmull, Edwin, and Alvy Ray Smith. 3-D Transforma- tions of 
lmages in Scanline Order, Computer Graphics, Vol. 14, No. 3, pp. 279-285, July, 1980. (SIGGRAPH 80 Conference 
Proceedings). [4] Fant, Karl M. A Nonaliasing, Real-Time Spatial Transform Technique, IEEE Computer Graphics 
and Applications, January, 1986, pp. 71-80. (See also the Letters to the Editor section of IEEE Computer 
Graph- ics and Applications, March, 1986, pp. 66-67, and July, 1986, pp. 3 and 8.) [5] Fraser, Donald, 
Robert A. Schowengerdt, and Ian Briggs. Rectification of Multichannel Images in Mass Storage Using Image 
Transposition, Computer Vision, Graph- ics, and Image Processing, Volume 29, Number 1, Janu- ary, 1985, 
pp. 23-36. (See also Corrigendum, Volume 31, Number 3, September, 1985, p. 395.) [6] Paeth, Alan. A 
Fast Algorithm for General Raster Rota- tion, Graphics Interface '86 Proceedings, May, 1986, pp. 77-81. 
[7] Smith, Alvy Ray. Projected Superquadrics are 2-Pass Transformable, Technical Memo 54, Computer Graphics 
Department, Computer Division, Lueasfilm Ltd., August, 1982 (now Technical Memo 54, Pixar). [8] Smith, 
Alvy Ray. A 2-Pass Solution to the Planar Biqua- dratic Patch, Technical Memo 128, Computer Graphics 
Department, Computer Division, Lucasfilm Ltd., May, 1985 (now Technical Memo 128, Pixar). [9] Smith, 
Alvy Ray. A 2-Pass Solution to the Planar Bicu- bic Patch, Technical Memo 132, Computer Graphics Department, 
Computer Division, Lucasfilm Ltd., June, 1985 (now Technical Memo 132, Pixar). [10] Smith, Alvy Ray. 
Serial vs Parallel Warps, Technical Memo 134, Computer Graphics Department, Computer Division, Lucasfilm 
Ltd., June, 1985 (now Technical Memo 134, Pixar). [11] Smith, Alvy Ray. Digital Filtering Tutorial for 
Computer Graphics Technical Memo 27, Computer Graphics Department, Computer Division, Lucasfilm Ltd., 
March, 1983 (now Technical Memo 27, Pixar). Also in Tutorial Notes for Siggraph 1983 and Siggraph 1984. 
[12] Smith, Airy Ray. Digital Filtering Tutorial, Part H Technical Memo 44, Computer Graphics Department, 
Computer Division, Lucasfilm Ltd., May, 1983 (now Technical Memo 44, Pixar). Also in Tutorial Notes for 
Siggraph 1983 and Siggraph 1984. (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 x]Yx x2Y 2 x3Y3 
 (Figures 1, 2, 7, and 8 axe on next page.) 0 > ~ x?y7 Vo Vl x4Y41~x,tY H 1 uo ul xtsY15  Table 1. 
Superquadric Defining Functions xl2Yt2 x14Y]4 Type m~(u) m2(u) udomain h,(v) h2(v) v domain Ellipsoid 
cos"u sin'u -~"~u < ~- lOSer sill~'v --~ < v < 7~ Figure 3. Bicubic patch transformation. l-Hyperboloid 
secCu tantu --~ < u < COS~'V sin~v ~ ~v < 2-Hyperboloid see% tan% -~ < u < se~¢v tane'v 2 2 Woroid a+coseu 
sintu --x < u < g 3g T <,~ <-~-*. * For the first theet. ** For the ~e~ond the.et. 0 XoYo xlYl x2Y2 x3Y3 
 ~o x4Y4 ~ X7Y7 Vl xsY8 ~ XllYll 1 0 Uo u I 1 x]2Yt2 xI3YI3 XI4.Y 14 XI~Y 15 Table 2. 2-D Superquadric 
2-Pass Horizontal Scanline Functions Type /.,(u) A(v) M(v ) Figure 4. Bieublc frozen edge. A(v, )cos% 
+cl Ellipsoid aco~v+ bsin% mcose'v + nsin~'~, M(~:#)coseu +p A(v, )sectu + d 1-Hypcrboloid aco~'v + 
bsinev tacos% + nsin% M(v,)seceu + p A(v, )scceu +d  2-Hyperboloid asec['~ + btantev Ill~'p + ntan['v 
M(v,)see~u + P A(v. )(a + cos~u) + d  Toroid acosev + bsinev mcos% + nslnev M(~, )(a + co/~ ) ÷ p xtYt 
x2y2 xsY5 v 0 I u0 1 xsY6 xsy 8 Table 3. 2-D Superquadric 2-Pass Vertical Scanline Functions Type 
g.d~) E(u), F(u), G, H Figure $. Biquadrafic patch transformation. E(u~)eo~¢v + F(ul)sinevEHipsoid GcesC'v 
+ Hsint/v E(u)= 7 ph u-a:e E(u~)cmev + F(u~ )sinev  1-Hyperboloid Glory + Hsinev E(~0secev + F(uDtan~v 
2-Hyperboloid GS~¢t"v + Htantev = mp G ad ]~u~-)c~ev + F(ul)sJne'v xoYo xtYt x2Y2 I  Toroid C, cm% 
+ Hsin% Vo ~. x 3Y3~ x~y5 Uo 1 x6y 6 xTy v xsy s Figure 6. Biquadratic frozen edge.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37434</article_id>
		<sort_key>273</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[Bidirectional reflection functions from surface bump maps]]></title>
		<page_from>273</page_from>
		<page_to>281</page_to>
		<doi_number>10.1145/37401.37434</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37434</url>
		<abstract>
			<par><![CDATA[The Torrance-Sparrow model for calculating bidirectional reflection functions contains a geometrical attenuation factor to account for shadowing and occlusions in a hypothetical distribution of grooves on a rough surface. Using an efficient table-based method for determining the shadows and occlusions, we calculate the geometric attenuation factor for surfaces defined by a specific table of bump heights.Diffuse and glossy specular reflection of the environment can be handled in a unified manner by using an integral of the bidirectional reflection function times the environmental illumination, over the hemisphere of solid angle above a surface. We present a method of estimating the integral, by expanding the bidirectional reflection coefficient in spherical harmonics, and show how the coefficients in this expansion can be determined efficiently by reorganizing our geometric attenuation calculation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P32489</person_id>
				<author_profile_id><![CDATA[81100575702]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Brian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cabral]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Univ. of California at Davis, Davis]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39044822</person_id>
				<author_profile_id><![CDATA[81100480335]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nelson]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Max]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Univ. of California at Davis, Davis]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P240225</person_id>
				<author_profile_id><![CDATA[81100549848]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Rebecca]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Springmeyer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Univ. of California at Davis, Davis]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Blinn, James. Models of Light Reflection for Computer Synthesized Pictures. Proceedings of SIGGRAPH '77 (San Jose, California, July 20-22, 1977). In Computer Graphics 11, 2, (July 1977), 192-198.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Blinn, James. Simulation of Wrinkled Surfaces. Proceedings of SIG- GRAPH '78 (Atlanta, Georgia, August 23-25, 1978). In Computer Graphics 12, 3, (August 1978), 286-292.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360353</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bllnn~ James, and NeweU, Martin. Tezture and Reflection in Computer Synthesized Pictures. Comm. ACM. Vol. 19, No. 10, pp. 542-547. 1976.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Born, Max, and Wolf, Emil. Principles of Optics. Pergamon Press. Oxford 1980]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bresenham, 3. E. Algorithm for computer control of a digital plotter. IBM Systems Journal. Vol 4. pp. 25-30. 1965.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Catmull, Edwin~ and Rom, Raphael. A Class of Interpolating Splines, in Computer Aided Geometric Design. Barnhill and Pdesenfeld, Eds. Academic Press, pp. 31%326. New York.1974.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert, Porter, Thomas, and Carpenter, Loren. Distributed Ray Tracing. Proceedings of SIGGRAPH '84 (Minneapolis, Minnesota, July 23-27, 1984). In Computer Graphics 18, 3, (July 1984)~ 137-145.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806819</ref_obj_id>
				<ref_obj_pid>800224</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert and Torrance, Kenneth. A Reflectance Model for Computer Graphics. Proceedings of SIGGRAPH '81 (Dallas, Texas, August 3-7, 1981). In Computer Graphics 15, 3, (August 1981), 307-316.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Courant, R., and Hilbert, D. Methods of Mathematical Physics. Interscieuce Publishers, Inc., p. 513. New York. 1953.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808600</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Crow, Franklin. Summed-Area Tables for Teztuve Mapping. Proeeedings of SIGGRAPH '84 (Minneapolis, Minnesota, July 23-27, 1984). In Computer Graphics 18, 3, (July 1984), 207-212.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325174</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Duff, Tom. Compositing $-D Rendered Images. Proceedings of SIGGRAPH '85 (San Francisco, California, July 22-26, 1985). In Computer Graphics 19j 3, (July 1985), 41-44.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15919</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Glassner, Andrew. Adaptive Precision in Tezture Mapping. Proceedings of SIGGRAPH '86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics 20, 4, (August 1986), 297-306.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13023</ref_obj_id>
				<ref_obj_pid>13021</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Greene, Ned. Applications of World Projections. IEEE CG&amp;A. Vol. 6, No. 11. pp. 21-29.1986.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6023</ref_obj_id>
				<ref_obj_pid>6020</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Greene, Ned, and Heckbert, Paul. Creating Raster Omnimaz 1mages from Multiple Perspective Views using the Elliptical Weighted Average Filter. IEEE CG&amp;A. Vol. 6, No. 6, pp. 21-27. 1986.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Hall, Roy, and Greenberg~ Donald. A Testbed for Realistic Image Synthesis IEEE Computer Graphics and Applications Volume 3, No. 8, pp. 10-20 1984]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15921</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Heckbert, Paul. Filtering by Repeated Integration Proceedings of SIGGRAPH '86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics 20, 4, (August 1986), 315-321.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Helmholtz, H.v. Helmoltz's Treatise on Physiological Optics. Optical Society Of America. Washington, D.C. 1924.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Immel, David, Cohen, Michael, and Greenberg, Donald. A Radiosity Method for Non-Diffuse Environments. Proceedings of SIG- GRAPH '86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics 20, 4, (August 1986), 133-142.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Kajiya, James. The Rendering Equation. Proceedings of SIG- GRAPH '86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics 20, 4, (August 1086), 143-150.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808594</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Kajiya, James, and Von Herren, Brian. Ra~l Tracing Volume Densit/es. Proceedings of SIGGRAPH '84 (Minneapolis, Minnesota, July 23-27, 1984). In Computer Graphics 18, 3, (July 1984), 165-174.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>23954</ref_obj_id>
				<ref_obj_pid>23944</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Max, Nelson. Shadows for Bump Mapped Surfaces. Advanced Computer Graphics, T. L. Kunii, Ed. Springer Verlag, Tokyo. pp. 145-156. 1986.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Miller, Gene, and Hoffman, Robert. Illumination and Reflection Maps: Simulated Objects in Simulated and Real Environments. Advanced Image Synthesis Course Notes. Siggraph Conference. 1984.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Ohira, Tomohiro. A Shading Model for Anisotropic Reflection. Technical Report of The Institute of Electronics and Communication Engineers of Japan, in Japanese. Vol. 82, No. 235, pp. 47-54. 1983.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Perlin~ Kenneth. Course Notes. Siggraph Conference. 1984.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Perlin, Kenneth. Course Notes. SIGGRAPH '85 State of the Art in Image Synthesis Seminar Notes. submitted to IEEE CG&amp;A, and personal communication. 1986.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Phong, Bui-Tuong. Illumination for Computer Generated Images. Comm. ACM. Vol. 18, No. 6, pp. 311-17. 1975.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Reuse, W. A. Polarization Studies of Light Diffusely Reflected from Ground and Etched Glass Surfaces. J. Opt. Soc. Am. Vol 40, No. 1. pp. 55-59. 1950.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[" Snell, Jay. Radiometery and Photometery. Handbook of Optics. Driseoll, W. G. and Vaughen. W., Eds. McGraw-Hill. 1978.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Spangenberg, D. B., Strung, A. G., and Chamberlin, J. L. Surface Tezture Measumnents of Metal Surfaces National Bureau Standards, Special Publication 300 Vol 7. Washington, D.C. 1971.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Takagi, 3., Yokoi, S., and Tsurwoka, S. Comment on the Anisotropie Reflection Model. Bulletin of SIG. Graphics and CAD, Information Processing Society of Japan, in Japanese. Vol. 11. No. 1 pp. 2-9. 1983.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Tinkham, M. Group Theory and Quantum Mechanics. McGraw Hill pp.101-115. New York. 1964.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Torrance, Kenneth, and Sparrow, Ephraim. Theory for Off- Specular Reflection .from Roughened Surface. Journal of the Optical Society of America. Volume 57 No. 9 1967.]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[USA Standard Nomenclature and Definitions for Illuminating Engineering. USAS Z7.1-1967. 1967.]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Whitted, Turner. An Improved Illumination Model for Shaded Display. Comm. ACM.'Vol. 23, No. 6, pp. 343-349. 1980.]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Whltted, Turner, and Cook, Robert. A Comprehensive Shading Model. Image Rendering Tricks Course Notes. Siggraph Conference. 1985.]]></ref_text>
				<ref_id>35</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801126</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Williams, Lance. Pyramidal Parametries. Proceedings of SIG- GRAPH '83 (Detroit, Michigan, July 25-29~ 1983). In Computer Graphics 17, 3, (July 1983), 1-11.]]></ref_text>
				<ref_id>36</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 21, Number 4, July 1987 Bidirectional Reflection Functions from Surface 
Bump Maps BRIAN CABRAL, NELSON MAX, and REBECCA SPRINGMEYER UC Davis/Lawrence Livermore National Laboratory 
 The Torrance-Sparrow model for calculating bidirectional reflection functions contains a geometrical 
attenuation factor to account for shadowing and oc- clusions in a hypothetical distribution of grooves 
on a rough surface. Using an efficient table-based method for determining the shadows and occlusions, 
we calculate the geometric attenuation factor for surfaces defined by a specific table of bump heights. 
Diffuse and glossy specular reflection of the environment can be handled in a unified manner by using 
an integral of the bidirectional reflection func- tion times the environmental illumination, over the 
hemisphere of solid angle above a surface. We present a method of estimating the integrM, by ex- panding 
the bidirectional reflection coefficient in spherical harmonics, and show how the coefficients in this 
expansion can be determined efficiently hy reorganizing our geometric attenuation calculation. Categories 
and Subject Descriptors: 1.3.7 [Computer Graphics]: Thzee- Dimensio~al G~phlcs mxd Realism -- Color, 
shading, sh~dowlng, and tex- ture General Terms: Computer graphics, image synthesis, reflectance, shading 
Additional Key Words and Phrases: Bidizectional reflection function, lighting model, horizon mapping, 
spherical harmonics, environmental illumination Introduction It is possible to model the reflection properties 
of a rough surface with geometric optics, by assuming that at a small scale, which is still large with 
respect to the wavelength of light, the surface is actually continu- ous, smooth, and shiny, and reflects 
like a curved mirror, according to Fresnel's law. The shape of a patch of such a surface can be specified 
as a height function of two continuous parameters. If a two parame- ter family of parallel rays meets 
such a surface, they will be reflected with a certain density per solid angle, called the bidirectional 
reflection density function, or bidirectional reflection function for short. This function could "be 
estimated stochastically, by tracing many parallel, randomly positioned rays. Authors's address: LLlqL, 
P.O. Box 808, Livermore, CA 94550 (415) 423-0201 cabral@lll-crg.AgPA Permission to copy without fee all 
or part of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM copyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, 
or to republish, requires a fee and/or specific permission. &#38;#169; 1987 ACM-0-89791-22%6/871007/0273 
$00.75 In this paper, we approximate the bumpy surface by a collection of triangular facets, interpolating 
between the bump heights at a discrete array of points. The rays which hit a facet without being shadowed 
on the way in, and leave the surface directly without hitting another facet on the way out, define a 
parallel beam emerging from the non-obscured part of the facet. This reflected beam contributes a "delta 
function ~ peak to the bidirectional reflection, weighted by its cross-sectional area. The bidirectional 
reflection function for the faceted approximation is the sum of these weighted delta functions, and is 
thus not continuous. We present two methods for capturing the information in the reflected beams. The 
first method divides the hemisphere of reflected directions into a number of bins, and assigns each reflected 
beam to one of the bins. This leads to a tabulated version of the bidirectional reflection function. 
The second method uses spherical harmonics to approximate the density per solid angle of the weighted 
delta functions. The result is a series of coefficients defining a continuous bidirectional reflection 
function as a linear combination of basis functions, effectively condens- ing the table into less data, 
and also smoothing it. Section 1 gives several definitions f~om radiometry, leading up to a physical 
definition of the bidirectional reflection function. Section 2 summarizes previous models for rough surfaces 
and methods for find- ing their reflection properties. Section 3 summarizes previous work on using bidirection 
reflection functions to calculate the effects of environ- mental illumination. Section 4 describes horizon 
mapping, an efficient way for finding the non-obscured part of each facet. Section 5 shows how to assign 
the beams into bins corresponding to a collection of tab- ulated reflection directions, and section 6 
argues that a bidirectional reflection function tabulated in this way should approximately satisfy Helmholtz's 
Law of Reciprocity. Section 7 shows how a spherical har- monic expansion of the bidirectional reflection 
function can be used to efficiently compute the effects of environmental illumination, and section 8 
shows how to determine the coefficients in this expansion from the collection of beams reflected by the 
facets. Finally, section 9 explains the construction of the bump tables, and presents images rendered 
with the resulting reflection functions. Our methods generate anisotropic reflection functions. However 
the anisotropy can be averaged out if desired for isotropic surfaces. For simplicity we consider only 
isotropic reflection functions in sections 7 and 8. 1. Radiometry There are two methods of quantifying 
light measurements: 1) by ra- diant energy, which measures physical quantities, and 2) by luminous energy, 
which measures the response of the eye. In this paper we dis- cuss only radiant energy, integrated over 
all wavelengths. However, the quantities defined below can also be considered as spectral quantitie% 
which vary with wavelength. They can then be converted to luminous quantities by multiplying by the CIE 
luminous efficiency function and integrating over all wavelengths. They can similarly be multiplied by 
 ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 Table of Notation 0 polar angle in spherical coordinates 
¢ azimuthal angle in spherical coordinates radiant flux D radiant flux density Din radiant flux density 
of incident beam L radiance Li,~ incident radiance l-.,.e[ reflected radiance f, bidirectional reflection 
function Q unit sphere H unit hemisphere of directions above a surface N global normal to a surface N' 
local normal to bumps on a surface W incident direction (Oi,-,,¢~.) V reflection and viewing direction 
(0.~i, dp.,l ) M mirror reflection (Omi.... emi..~r) of V P off specular peak direction (Oveak , dpz,,atc) 
/3 angle from surface normal to horizon Si the i th facet B i the non-obscured area of facet S i Ni the 
normal to facet Si R~ direction of the beam reflected from Si Gi "fraction" of incident flux reflected 
from Si F Fr esnel's law 6 Kronecker delta function Vk direction for bin h ~k flux in bin k l~n real 
spherical harmonics basis function Pz. associated Legendre function lift,, normalization factor c~'~ 
maz(eosO, O) D~,. matrix element for rotating spherical harmonic basis functions g~ coefficients in Fourier 
series for L.~j the CIE color matching functions, and integrated to get CIB z, Y, and z color coordinates, 
which can be converted to the appropriate output colors for a specific device (See Hall [15] and Cook 
and Torrance [8].) To measure solid angle, we use a spherical coordinate system with the Z axis at the 
surface normal N. A direction V has coordinates (0, ~b) where 0 measures the polar angle of V from the 
Z axis, and ¢ measures the azimuthal angle between the X axis and the projection of V in the XY plane. 
The element of solid angle is then dw = sin0d0dqL We now state several definitions taken from ANSI Z7.1-1967 
[33]. The radiant flus, ~, is the time rate of flow of energy traveling through a surface in the form 
of electromagnetic waves. It is usually measured in watts. The radiant fluz density, D = d~/dA, at an 
element of a surface is the ratio of the radiant flux through that surface element, to the area of the 
element. It cast be measured in watts per square meter. When referring to radiant flux incident on a 
surface, the density is celled irradiance. The radiance, L = d2~/(dw cos 0dA), in a direction (0,~,), 
at a point of a surface is the following ratio. The numerator is the radiant flux leav- ing, passing 
through, or arriving at an element of the surface surround- ing the point, and propagated in directions 
within a cone containing the given direction. The denominator is the product of the solid angle of the 
cone and the area of the orthogonal projection of the dement of the surface on a plane perpendicular 
to the given direction. Radiance can be measured in watts per square meter per steradian. Consider a 
beam of incident light, with radiance Li,,, coming from a solid angle dwin about an incident direction 
(Oil, ¢~) and reflecting from a surface. Let dL.~! be the radiance reflected in the direction (O,~l, 
¢~e! ). Then the bidirectional reflection function f~ is the ratio: dL,~! fl(0~., ~i,~; e.,y, ¢.,j,) 
-L,, cos O~,,d~,, (See SneLl [28].) In the limit when dw~, approaches zero and the incident beam becomes 
parallel, the denominator becomes the irradiance onto the surface from the single direction (0i~,¢,~). 
Since f, is a radiance divided by a radiant flux density, the units of f, are inverse steradians. For 
a radiance function Lin(Oi~,~bi~) which varies continuously with the incident direction, we can get the 
total reflected radiance in the direction (0,,1,~,,1) by integrating dL,,! over the hemisphere H of possible 
incident directions above a surface. Thus L..,: f, f.(Oi,~,¢i,~;O..l,¢..l)Li.,cosOi,Jxvi,,. (1} 2. Bidirectional 
Reflection Models Torrance and Sparrow [32] developed a geometric lighting model for specular reflection, 
which was applied to computer graphics by Blinn [1], and modified by Cook and Torrance [8], to take ketter 
account of colored light. It has been used to create spectacularly realistic shaded renderings of surfaces 
such as brushed metal. The Torrance-Sparrow model a.~sumes that an infinitely long, symmet- rical, wedge-shaped 
groove has been cut into the surface. The normal N' to one of the two flat sides of this groove is used, 
together with the lighting direction and the viewing direction, to compute the frac- tion of the incoming 
fight which is neither shadowed on the way in nor obscured on the way out by the opposite side of the 
groove. Random grooves, with some specific distribution of normMs N' about the surface normal N, generate 
a distribution of reflected rays from each incoming direction. One can thus compute a bidirectional reflection 
coefficient. However on any real surface the grooves will interfere with each other, so they cannot be 
both randomly oriented and infinitely long. A real surface can be more explicitly modeled by a bump table, 
which gives the surface height at a two dimensional array of sample points. Blinn [2] has shown how to 
perturb the surface normal for use in a fighting model which takes account of the bumps. The method has 
become known as "bump mapping." It gives realistic light reflections for a level of detail at which the 
bumps axe visible, but need not be modeled in full 3-D perspective. Max [21] has shown how to account 
for the shadows from the humps, by using a table of horizon angles. This might appropriately be called 
"horizon mapping." In the present paper, we divide the surface defined by the bump table into triangular 
facets. For each facet and each tabulated fighting direction, we compute the reflection direction and 
use the horizon table to find the reflected beam, that is, the portion of the beam potentially intercepted 
by the facet, which is neither shadowed on the way in nor obscured on the way out. We accumulate this 
refected flux into a tabulated bidirectional reflec- tion function, using the tabulated reflection direction 
closest to the actual reflected beam. Because it is derived from the bump table, the resulting lighting 
model will be consistent with the area average of the fight from an image rendered with bump mapping 
and horizon map- ping. This should permit smooth transitions of detail between these two methods of representing 
surface roughness. This is the chief jus- tification of our method: consistency with explicitly modeled 
surface structure, including nnisotropie reflections. Kajiya [20] has proposed smooth transitions between 
three roughness representations: fighting models, bump mapping, and full 3-D visible-surface calculations 
which include the bumps in the data base. However his method uses the wave theory of light, and is not 
computationally practical. If bump mapped surfaces axe rendered with horizon mapping, they should in 
addition allow smooth transitions to full 3-D renderings including cast shadows. Perfin [24] has also 
proposed a smooth transition of surface roughness components, between lighting models and normal perturbations. 
How- ever his normal perturbations do not come from an explicitly specified bump table, and therefore 
do not permit horizon mapping, or full 3-D modeling. (~ '~ Computer Graphics, Volume 21, Number 4, July 
1987 Ohira [23], Takagi [30], and Kajiya [20] have discussed bidirectional reflection functions which 
are anisotropic. These depend on all four parameters needed to define the lighting and viewing directions, 
with respect to a frame specifying the orientation of two surface tangents and the surface normal. Our 
calculations initially generate anisotropic reflections, since the two tangent vectors are needed to 
orient the bump tables on the surface. If isotropic reflection functions are desired, the anisotropic 
tables can be averaged over the possible orientations of the bump table on the surface, so that they 
depend on only three parameters. This will make more reflected rays contribute to each table entry, and 
improve the sampling statistics. 3. Environmental illumination Early illumination models handled only 
point light sources, but there have been many attempts to include the light coming from the whole environment, 
based on equation (I) above. Whitted and Cook [35] an- alyze various specific fighting models in terms 
of restrictions on the full generality of equation (1). For example, Blinn and Newel! [3] created mirror 
reflections of a room in a teapot by assuming that it,, is inde- pendent of position, and that fl is 
a delta function. If Li,, instead is a delta function, we have the case of a point light source. Lambcrt's 
law for diffuse reflection results when ]r is constant. Phong [26]~ Blina [1], and Cook and Torrance 
[8] have generated glossy highlights from point sources by using more general specular reflection functions 
]~, concentrated near the mirror direction. Cook, Carpenter, and Porter [7] have used distributed ray 
tracing to model glossy reflections, with such a concentrated .fr and an arbitrary Lin. Because the integral 
is estimated by tracing sample rays near the mirror reflection, L~n can vary with position and multiple 
reflections can bc rendered. Kajiya [19] has demonstrated that by long calculation and a tittle prun- 
ing of the ray tree, it is possible to include diffuse as well as specular reflections in this scheme, 
allowing a completely general f~. Irnmel, Cohen, and Greenberg [18] have also solved the same intcrreflcetion 
problem for general jr,, by dividing the surface into polygons, and solv- ing a huge system of linear 
equations. In this paper we apply our bidirectional reflection distribution function to the case that 
Lin is independent of position, as if the environment were painted on a sphere at infinity. In this case 
Li,~(Oin, ¢i~) can be sampled into a texture table. Greene [13] has called techniques based on such a 
table ~environment mapping", and surveyed methods for obtaining the integral for if el efficiently from 
the table. For example, if f, is constant (diffuse reflection) ire/ depends only on the normal N, and 
Miller and Hoffman [22] suggest that it be precomputed and tabulated. In the Phong reflection model [26], 
fl depends only on the mirror reflection M = (8,~i,,o,, qb,~i,,o,) of the viewing direction V : (O,~!,~b,e!), 
so L,e! can again be precomputed and tabulated as a function of (On, .... ~b,,,,,o~) (See [22].) Consider 
a somewhat more general f,, which, as a function of (8~n, qbin) for fixed V and fixed normal N, has ellipticul 
symmetry about some ~off specular" peak direction P -(0p,~h,¢p,ah) near M. (See [1] or [32].) That is, 
contours of constant .f,. correspond to small concentric ellipses about P on the sphere of (8~,¢~) directions. 
(See figure 1.) The shape of fT is determined by the eccentricity, which is the same for all these ellipse.s, 
and by a curve on a cross section plane through N and P, specifying f, as a function of the ellipse size. 
The shape off, usually varies with 9, ~1, and the orientation of the ellipses varies with N, so the integrals 
cannot be precomputed as a function of {Opea~, ¢pesk) alone. The elliptical weighted average filter of 
Greene and Heckbert [14] can take advantage of the elliptical symmetry of ], to estimate the integral 
for L,.,! from the tabulated values of L,,,(8~,,, ¢,~). Its computation time is proportional to the number 
of entries in the table which con- tribute to the integral, so this method is most efficient for shiny 
surfaces, with narrow specular peaks. Greene [13] has suggested using Williams' pyramidal patamettics 
[36] together with elliptical weighted averages, so that the number of entries in the selected table 
is bounded, inde- pendent of the width of specular peak. Glassner [12] has shown how to use summed area 
tables (See Crow [10]) to approximate the integral of L,,, over larger ellipses. But his method requires 
that at, be constant P Figure 1. inside the ellipse, and zero outside. Perlin [25} has generalized 
summed area tables to higher order, and shown how to approximate an elliptical ganssian by piccewise 
quadratic polynomials, whose convolutions with L,~ can be obtained using the second order tables, in 
time independent of the width of the gaussinn. (See Heckbert [16] for a more detailed explanation.) The 
ellipses must be oriented with their major and minor axes horizontal or vertical in the texture table. 
This can be arranged in the following case. Suppose the clew of the reflecting object is from far away, 
so that the viewing direction V can be assumed to be constant, and that Li,,is tabulated in spherical 
coordinates, with V as the north pole. An isotropic bidi- rectional function will have mirror symmetry 
with respect to a plane through V and N, so its contour ellipses must also. This guarantees the required 
orientation, since a plane through the pole is a line of constant azimuthal angle in the texture table. 
Greene [14] also considers the problem of antialiasing reflections in a curved, perfectly shiny mirror, 
to account for the fact that the ray from the eye reflects in directions which vary over the area of 
the pixel. He proposes elliptical weighted average filtering, using values of L,,, tab- ulated on the 
six faces of an environment cube. A ganssian weighting about the pixel center, for slowly curving mirrors, 
will transform to an approximate elliptical gaussian in the environment map, in spherical coordinates 
as well as on an environment cube. To generalize this to the case of a glossy curved ndrror, the appropriate 
filter is the convolu- tion of the weighting function with the specular bidirectional reflection function 
f,. If fr can be approximated by an elliptical gaussian, the convolution of these two functions is again 
an elliptical gaussian, which may no longer be oriented consistently with the spherical axes. The method 
of Per]in [24] no longer applies, but the method of Greene and Heckbert [13,14] can still be used. Miller 
and Hoffman [22] also include antialiasing in their technique. Of course, in distributed ray tracing 
[2,7], the rays can be distributed simultaneously over both the subpixel positions and the glossy reflection 
directions. The method of integration we propose in section 7 below works under restricting assumptions 
similar to those above: a) L~,, is independent of position, b) V is constant, and c) .f, is isotropic. 
However, we can handle arbitrarily shaped fi, which can combine specular and diffuse reflection. We expand 
both cos 8inf,. and Lin in spherical harmonics~ with V as the north pole. The-integral for L~! can then 
be computed efficiently as the dot product of the coefficient vectors for cos 8,~f, and L~,~. Because 
the computation time is proportional to the number of coefficients, our method works best for rougher 
surfaces, where .f, is  ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 wide and can be approximated by fewer 
terms. (This is in contrast to the methods of Greene and Heckbert [14] and Immel, Cohen, and Greenberg 
[18], which work better for narrow f,.) 4. Horizon Mapping Horizon tables were originally developed to 
create shadows on bump- mapped surfaces [21]. Imagine a bump height function, tabulated on an m x rn 
grid, representing the altitude of a mountainous terrain, with :: = east, y ---- north, and z --up. Suppose 
the sun sets to the west in a vertical plane, as it would at the equator on an equinox. Then a point 
on the terrain is in shadow whenever the sun is below the horizon, that is, whenever the angle $ from 
the Z axis to the sun is greater than the angle /3 from the Z axis to the western horizon. The angle 
to the western horizon can be computed at each tabulated position, by looking at the slopes of lines 
from that position to other tabulated positions to its west, and finding the maximum slope. The bump 
map is doubly periodic in z and y, so that the slope can be determined by the m- 1 points to the west, 
even for a starting point near the western edge of the bump map. The angle of the horizon can be determined 
similarly for any sunset direction, that is, for any half plane through the Z axis. Max [21] proposed 
using only the eight principal compass directions, for which the slope to the horizon can be easily determined 
from the bump table. This resulted in a horizon table of size m x m x 8, and the horizon ang, le at other 
compass directions was determined by interpolation. Mountains which are missed by the sampled compass 
directions from a data point will fail to cast shadows on the point, so more compass directions will 
give more accurate results. In this work, wc have used 24 directions. Let PQ represent a ray from the 
data point P in one of these directions, shown intersecting the triangles in Figure 2. The bump heights 
at an intersection point with a triangle side are determined by interpolation from the tabulated vertices 
at endpoints of the side. Note that the interpolation factors, and the positions of the two endpoints 
relative to the start of the ray, depend only on the ray's direction. To speed up the calculation of 
the horizon table, this information is computed ahead of time for each ray direction [5]. Max [21] shows 
how to use the horizon table computed for a flat surface, to find the bump shadows when the flat surface 
is parametrized onto a curved surface patch. Here we will use it to estimate energy reflected from the 
bumpy surface. \ /\/ >(\/ /\ \ \ \/( /\/  \/\ /\/\/\ Figure 2. Ray PQ intersecting grid tessellations. 
5. Reflection From Facets Consider a collimated parallel beam of light coming to the surface S from the 
direction Win : (0o,, @i,,), with radiant flux density D~,, mea- sured per unit area normal to W~. This 
is the limit for a source of radiance Li,~ and solid angle d~,n , as the Source moves away to infinity, 
and d~in approaches zero, while the radiance increases to keep Lo, d~i,, equal to Din. Since W/n is tilted 
away from the normal N by an angle Om, the irrrarliance incident on S is Di,, cos 0i,~ = D~(Wi,,. N). 
We divide S into 2m 2 triangular facets, as shown projected in figure 2. if Ui and V~ represent the vectors 
along the edges of facet Si, which project to the horizontal and vertical edges in figure 2, then the 
area A~ of S~ is [Ui x V/I/2, and the normal N~ to Si is (Ui x Vi)/tU~ x g~[. Given N¢ and Wi, we can 
compute the reflected direction Ri = 2(Wi,~. Ni)Ni -W,~ (See Whitted [34]). The obscuring effects of 
other facets can be estimated from the horizon table. We can determine from the entries for the compass 
direction Oi,,, the three horizon angles/3~,32, and/3s for the three vertices of Si. If the samples for 
0i~ for the tabulated bidirectional reflection function correspond to those in the horizon table, no 
interpolation is required. When/31,f/a , and/3 s are all greater than 0i,,, the facet S i is completely 
lit, and when all are less than 8in, the whale facet is in shadow. When some are greater and some are 
less, the partial shadowing is determined as follows. Along the two sides where f/j -ai~ changes sign, 
we interpo- late to estimate two points where 13 = 8in. The line joining these two points separates the 
triangle into a quadrilateral and a smaller triangle, one of which is illuminated and the other, shadowed. 
Shadowed light contributes its ~tux instead to the speculax reflection from the facet which intercepted 
it. But, as in the Torrance-Sparrow model, reflected light which is obscured on the way out is lost from 
the specular energy computation, and assumed to contribute instead to diffuse reflection or absorption. 
The illuminated portion of the facet sends out a reflected beam in the direction Ri = (0rcI,~re/). The 
portion of this beam which is not obscured can be found similarly, using the convention of Duff [11], 
Figure 1, to treat the ease where/3 -0,,j changes sign along all four sides of a quadrilateral. Since 
~,'eI can be an arbitrary azimuthal angle, interpolation in the horizon table is now required, which 
introduces another approximation in oat calculations. Let Bi be the area of the facet S~ which reflects 
the non-obscured, non-shadowed portion of the beam. This area projects to an area Bi(N'i, vI.ri**) normal 
to the incident beam, and therefore intercepts a flux of Dir, Bi(N~,Win ). We assume the facet is perfectly 
smooth, so that the reflected flux is this incident flux multiplied by the Frcsncl factor ~'(N~, W~). 
(See Born and Wolf [4].) Now take a collection {Vklk = 1, n} of sampled reflection directions, and let 
Nearest(V) be the index k of the Vs, nearest to the unit vec-tor V. (Choose the lower index in case of 
a tic.) Then C~ = {V E DlNearest(V) = k} represents the bin on the hemisphere H assigned to V~. Let dw~ 
be the solid angle measure of C/~. To accumulate the reflected flux into the appropriate bins, we assign 
the flux from facet Si to bin k : Nearest(Ri). When all 2m a facets have been considered the total flux 
~,(01,,, ~bi,~) in bin k is 2m ~k(Oi., eki.) = y]~ 6(k -- NearestCR.))F(N~, W~.)DI.Bi(Wi. . Ni) (2), 
/=1 We find the reflected radiance L~el,~ in the direction V~, for bin k, by dividing the flux i~ by 
the area dB of S normal to the outgoin 8 direction VA, and by the solid angle d~h of the bin. The area 
dA of S is taken as the area of the fiat lattice, shown in figure 2, on which the bumps axe based. Then 
dB = dA(Vt N). Thus '~ Computer Graphics, Volume 21, Number 4, July 1987 (ei., ¢i~) L" I J' --d~ l~ 
d A ( Vi, N) By definition, the bidirectional reflection function f, is this reflected radiance, divided 
by the incoming irradiance. Since the incoming beam has a radiant flux density Di,, measured normal to 
its direction Wi,,, its irradiance on the surface S is Din cos Oin = Din(Win " N), so Lrel,k f, (oi., 
~i.,; o..:, ¢.q ) - D~. (Win" N) Putting the above three equations together, we get h (oi,,, ¢.,; e.q, 
4'..t) = (3) Di,,(Wi,," N)d~dA(V~,. N) Note that Di,~ can be cancelled from both the numerator and 
denom- inator, so that Gi = F(Ni, Wir.)Bi(Win" Ni)/(Wi.," N)dA represents the fraction of the incoming 
flux reflected by facet St, and 2~ 3 ~i=~ $(k -Nearest(R~))Gi  h(o,., 4,i,,; o.q, ¢..t) = ~(v~ N) (4) 
If this computation is repeated for each of a finite collection of inci- dent directions Wi~, we can 
build up a bidirectional reflection table  f.(o~.,~i.;o..~,¢..~) = f.(w~, v~). Torrance and Sparrow 
[32] consider a continuous distribution of hypo- thetical facets, all of the same projected area, with 
a density ~(N ~) per steradian having facet normal N'. They apply the formula ~,e! ---- 4(W-N')t:~o .... 
fxom Reuse [271, where ~ .... is a small solid angle fox normals about N', ~d d~rtl is the solid aaglc 
of corresponding reflected directions for the incident ray from W. Because we are using an explicit collection 
of polygonal facets instead of a distribution, and accumulating the flux of the reflected beams into 
a predeflned collection of bins, we do not need to include this solid angle spreading factor. 6. Reciprocity 
 Torrance and Sparrow also refer to the reciprocity law fl(V,W) = f,(W, V) in Helmholts [17], obtained 
by reversing the roles of the inci- dent and reflected dlxections. Our calculated fr should approximately 
satisfy this reciprocity law by the following reasoning. Take the same cofiection of samples on the hemisphere 
H for both the viewing, V, and incident, W, direction indices in the tabulated bidirectional reflection. 
Assume that C~ = {VlNearest(V ) = k} : (VlAngle(V, ~) < "r} for some smaLl.constant 7, so that G~, is 
a circular region on H, of radius % (This can never be exactly true, but is approximately true for a 
"hexagonally close packed" collection of directions based on icosahedral symmetry. The corresponding 
C/,'s consist of 12 regular pentagonal regions and 301~ -10 regular or not-quite-regular hexagonal regions 
on the unit sphere. For exarnple, a soccer ball is sewn from 12 black pentagonal and 20 white hexagonal 
pieces of leather, the case 1 : 1.) Now consider a facet St of non-obscured area Bi, for incoming light 
direction Wj, and reflected beam direction Ri. Let Nearest(R.~) : k, so that Angle(P~, V#,) < ~. Then 
the same facet will reflect Vk back to a ray within 7 of W i. The non-obscured area in the reverse situation 
will be close to Bi if 3, is smallj since all angles have changed by less than T. Also, the angle between 
Ri and Vk is less than 7, so in equation (2) for incoming direction W#, W i Ni = Ri Ni ,.~ V~ Ni, 
and the Fresnel factors F(NI, W~) and F(NI, V~) are also close, since F(N, W) depends only on the dot 
product of N and W. Thus the contributions of facet Si to the sum ~k(Wj) in equation (2), and to the 
corresponding ray reversed sum ~#(V~), are approximately equal. In the denominator of equation (3), we 
have assumed the solid angles dw~ are all equal, and V~ N and Wj N both appear, so f,.(W.i,Vk ) and 
f,.(VJ.,Wj) are approximately equal also. We can thus decrease the size of the bidirectional reflection 
table by about half, and improve the sampling statistics, by setting both f, (Wi , Vk) and fr (Vh, Wj) 
to their average value, enforcing reciprocity. Under the additional condition that the reflection is 
isotropic, f, (Oin, ¢in; O,'el, eve/) depends only on 0i,,, Ore t, and [~bi,~ -¢,el [. Thus, the data 
for all bins with the same I¢in -¢,ef[ can be averaged, re-ducing the table size and improving the statistics 
still further. In the following two sections, we assume f, is isotropic. 7. Spherical Harmonics in Environment 
Mapping The bidirectional reflection function can be used as a part of any shad- ing algorithm. In this 
section, we discuss the use of spherical harmon- ics in shading computations based on environmental illumination. 
The spherical harmonic method can be used with any bidirectional reflection function. In section 8, however, 
we give a particularly efficient method of determining the spherical harmonic coefficients from the reflected 
beams. For representing functions defined on the unit sphere, spherical har- monics functions arc the 
analogues of the fourier series terms used on the unit circle. They are the products of associated Legendre 
functions with simple periodic functions in ¢. When used to represent wave functions in physics, they 
are usually complex valued, but to represent images, we need real functions. The real spherical harmonics 
may be expressed in terms of cos nff and sin he: M~. i% (cos O) cos n~ n>0; Yzn(0,¢) Ms. P'l-t(eos 0)sin 
I~1¢ n<0; where (21+r)(t-.I)~ n ~ 0;M~, = V ~" (t+l~)!' {.] V ' 4~ " n=0; and Pzn(cos 0) is the associated 
Legendre function. (See Courant and Hilbert [9].) The spherical harmonics form an orthonormal basis for 
the Hilbert space of functions on the unit sphere. Thus any real function h(8, ~,) has an expansion h(O,¢) 
= fi ~ a,~Y~(O,~k). I=O ¢r=--I We can speed up the calculation of the integral in equation (1) by ap- 
proximating the factor cos Oi.f. (IV, V) with spherical harmonics. We reorganize the spherical coordinates 
so that the pole is in the viewing direction V. The isotropic bidirectional reflection function fr(W, 
V) really depends on the three vectors W,V, and N. (For non-isotropie reflection functions, tangent vectors 
are also required.) In the previous section, N was assumed fixed, but now V is fixed. So we change nota- 
tion, and let fr~ (0, ¢) denote the bidirectional reflection function of the illumination direction W 
= (0, ¢), for V permanently fixed, and N tem- porarily fixed and indicated in the subscript. We have 
taken V along the Z axis, and will at first assume that N lies in the XZ plane, with spherical coordinates 
(a, 0). Since f, is isotropic; f, ~, (O, ¢) is symmetric with respect to the XZ plane, and f,,~($,-~b) 
= f,~(0,¢). As a result, cos Oi=f~t¢(O, ~) can be expanded in spherical harmonics with terms in cos n¢ 
but none in sin he, that is, there are no at,, terms for n < 0. This expansion is defined over the whole 
unit sphere Q, instead of just the hemisphere H, so we will replace cos0i= by 6"0~0i, = muz(cos0in,0). 
Thus the expansion of 6~01,~fr,(0,¢) is: co ! ~o,.s..(o,¢) = ~ ~ ~,.(~)Y,,*(0, ¢). |=o n=o  ~ SIGGRAPH 
'87, Anaheim, July 27-31, 1987 The expansion is an infinite series, but if we replace the infinite upper 
bound in the first summation by a finite upper bound M, we get an approximation to ff'~sOinf,.~(O,c~).We 
will calculate the coefficients atn(ai ) for a finite sample {hr~[j : 1, J} of normals in the XZ plane, 
with spherical coordinates (a1,0), and find atn(a) for other normals N = (a, 0) by interpolation. Now 
let N be an unrestricted normal, with spherical coordinates (a,/~). A rotation of -fl about the Z axis 
takes (c~,fl) to No = (a, 0), and W = (0, ¢) to W0 = (O, ¢--/~). Since the reflection function is isotropic, 
and only depends on the relative angles between V, N, and W, f,t,(O,¢) = l-no (8, ¢ -/~). Also, ~-o's01,~depends 
only on the angle between W and N. Therefore M !  ~...f.,,,(~, +)~ ~ ~ ,,,..(~)M,.,P,. (cos 0) cos(,,(¢-z)). 
l=0 n=O But  cos n(+ - ~) = cos(,.¢ - ,,p) = cos n~b cos ~tfl + sin n¢ sin nil. Therefore M , / cos 
~z¢, n>O; ~0,j,,,(0,¢) ~ ~ ~ a,,M,,~P,i,q(cosO ) Lsin [nit ' n< O; I:0 n=--I where _ f ~.(~)cos~. ~ 
>_ o; We now have terms in sinzt¢, so there axe ~#~ for n < 0. The compu- tation of the a~(a) is explained 
in section 4. The radiance of the environment, Lin(8, c~), may also be expanded in real spherical harmonics: 
 I=0 n=--I Since the Y~ axe an orthonormal basis, the coefficients bt~ are com-puted by integrating 
the product of the illumination function and the spherical harmonics over the unit sphere:   (s). Having 
expanded both the reflection function and the environmental radiance function in spherical harmonics, 
we can now estimate the in- tegral of equation (1): L,.I= fH cos o~/,(v, w)L~(o, ¢)d~ = fee d"~sOi, 
f,(V,W)Li~,(O,4~)d.w q Q I=0 n=--I It=OnS=-U 1=0 ~:--1 P=O ~=--P M ! co I t  = ~ ~ ~ ~ a,..b,,.., ~(l,~')~(~,~') 
M I 1=0 ~=-1 Thus L~ey becomes the inner product of these two coefficient vectors. If Li~ has high spatial 
frequencies, but y, does not, then y, acts like a filter in the integral for L,~/, averaging out the 
high frequencies in Li~. Thus when the terms up to I = M are sufficient to represent ~'sOi,~f¢N (~, ¢), 
the higher terms in Lin axe eliminated from the integral by the orthogonMity of the l~. For a curved 
or bump-mapped surface, the bidirectional reflection func- tion should be further widened and frequency 
limited, to account for the variation of surface normals within a pixel, as mentioned in the introduction 
above. An inexpensive way to do this is to limit the range of l indices in the expansion for ~'~8f,~ 
to some maximum M l less than M. The values of ai,~ can be gradually decreased for large I, so that the 
expansion varies smoothly with the range of normals within a pixel. Decxeasing the weight for terms with 
large l also helps diminate the "ringing", or Gibbs phenomenon, at sharp edges or in Li~(0, ¢). The M-term 
approximation for ~'~sOinfr~(~, ¢) cannot be exactly zero in the hemisphere Q -H behind the surface, 
where 6"~sOin is zero. This can cause slight reflections of objects behind the surface, but such artifacts 
do not appear disturbing in the images shown here. If Li,(0,¢) is represented as a cube whose six faces 
are texture maps, as in Greene [13], the integral in equation (5) can be estimated by summation over 
the texture pixels. This integral must be computed only once, for the first viewing direction g. For 
each new viewing direction the set of coefficients bt,~ may be transformed by taking a linear combination 
of the original coefficients: b~,D~,~(a, ~, 7) nt=--| where the matrices D~,~ describe how the spherical 
harmonics trans- form under rotation through the Eulerian angles c~,~, and % (See Tinkham [31].) Note 
that each D matrix will be of size 2l % 1, with the largest matrix requiring (2M + 1) x (2M + 1) elements. 
The use of these rotation matrices is clearly more efficient than recomputing the coefficients for each 
new viewing direction. The expansion 1=0n=--I has (M + 1) 2 terms, each each requiring interpolation 
and rotation, and it must be computed once per pixel. This is better than doing an integral per pixel, 
but it can bc simplified still further by precomputing some of the interpolation, as follows. Once per 
surface texture, for j = 1,...,J, for l = 0,...,M, and for n = 0, ...,1, compute  a,..(,~,) = f~ ~o,.j..,j 
(o. +)~..(o. ¢) si~ edOd¢ (7) for Nj = (c~j,0). Once per viewing direction/surface-texture combina- tion, 
and for 2" = 1, ...Y, compute M g~(~J) = S~ a,,~(~Ab,,.. (s) t=[,~[ There may be only one constant viewing 
direction, in the approxima- tion of distant viewing discussed above. But suppose the scene contains 
several objects, each subtending a small angle of view, even if the whole image covers a large angle. 
Then there may be a separate viewing di- section for each object. There may even be a separate environment 
for each object, if the hidden surface computation for the environment texture cube is recomputed from 
the point of view of each object. This allows one level of glossy intcrreflection between objects to 
be approx- imated. There may also be different dewing directions for different frames of an animation. 
   ~ Computer Graphics, Volume 21, Number 4, July 1987 8. Cook, Robert and Torrance, Kenneth. A Reflectance 
Model for Computer Graphics. Proceedings of SIGGRAPH '81 (Dallas, Texas, August 3-7, 1981). In Computer 
Graphics 15, 3, (August 1981), 307-316. 9. Courant, R., and Hilbert, D. Methods of Mathematical Physics. 
Interscieuce Publishers, Inc., p. 513. New York. 1953. 10. Crow, Franklin. Summed-Area Tables for Teztuve 
Mapping. Pro-eeedings of SIGGRAPH '84 (Minneapolis, Minnesota, July 23-27, 1984). In Computer Graphics 
18, 3, (July 1984), 207-212. 11. Duff, Tom. Compositing $-D Rendered Images. Proceedings of SIGGRAPH 
'85 (San Francisco, California, July 22-26, 1985). In Computer Graphics 19j 3, (July 1985), 41-44.  
12. Glassner, Andrew. Adaptive Precision in Tezture Mapping. Pro- ceedings of SIGGRAPH '86 (Dallas, Texas, 
August 18-22, 1986). In Computer Graphics 20, 4, (August 1986), 297-306. 13. Greene, Ned. Applications 
of World Projections. IEEE CG&#38;A. Vol. 6, No. 11. pp. 21-29.1986. 14. Greene, Ned, and Heckbert, Paul. 
Creating Raster Omnimaz 1m- ages from Multiple Perspective Views using the Elliptical Weighted Average 
Filter. IEEE CG&#38;A. Vol. 6, No. 6, pp. 21-27. 1986. 15. Hall, Roy, and Greenberg~ Donald. A Testbed 
for Realistic Image Synthesis IEEE Computer Graphics and Applications Volume 3, No. 8, pp. 10-20 1984 
 16. Heckbert, Paul. Filtering by Repeated Integration Proceedings of SIGGRAPH '86 (Dallas, Texas, August 
18-22, 1986). In Computer Graphics 20, 4, (August 1986), 315-321. 17. Helmholtz, H.v. Helmoltz's Treatise 
on Physiological Optics. Op- tical Society Of America. Washington, D.C. 1924. 18. Immel, David, Cohen, 
Michael, and Greenberg, Donald. A Ra- diosity Method for Non-Diffuse Environments. Proceedings of SIG- 
GRAPH '86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics 20, 4, (August 1986), 133-142. 19. 
Kajiya, James. The Rendering Equation. Proceedings of SIG- GRAPH '86 (Dallas, Texas, August 18-22, 1986). 
In Computer Graphics 20, 4, (August 1086), 143-150. 20. Kajiya, James, and Von Herren, Brian. Ra~l Tracing 
Volume Densi- t/es. Proceedings of SIGGRAPH '84 (Minneapolis, Minnesota, July 23-27, 1984). In Computer 
Graphics 18, 3, (July 1984), 165-174. 21. Max, Nelson. Shadows for Bump Mapped Surfaces. Advanced Computer 
Graphics, T. L. Kunii, Ed. Springer Verlag, Tokyo. pp. 145-156. 1986. 22. Miller, Gene, and Hoffman, 
Robert. Illumination and Reflection Maps: Simulated Objects in Simulated and Real Environments. Ad-vanced 
Image Synthesis Course Notes. Siggraph Conference. 1984. 23. Ohira, Tomohiro. A Shading Model for Anisotropic 
Reflection. Technical Report of The Institute of Electronics and Communication Engineers of Japan, in 
Japanese. Vol. 82, No. 235, pp. 47-54. 1983. 24. Perlin~ Kenneth. Course Notes. Siggraph Conference. 
1984.  25. Perlin, Kenneth. Course Notes. SIGGRAPH '85 State of the Art in Image Synthesis Seminar Notes. 
submitted to IEEE CG&#38;A, and personal communication. 1986. 26. Phong, Bui-Tuong. Illumination for 
Computer Generated Images. Comm. ACM. Vol. 18, No. 6, pp. 311-17. 1975.  27. Reuse, W. A. Polarization 
Studies of Light Diffusely Reflected from Ground and Etched Glass Surfaces. J. Opt. Soc. Am. Vol 40, 
No. 1. pp. 55-59. 1950. 2'8." Snell, Jay. Radiometery and Photometery. Handbook of Optics. Driseoll, 
W. G. and Vaughen. W., Eds. McGraw-Hill. 1978. 29. Spangenberg, D. B., Strung, A. G., and Chamberlin, 
J. L. Surface Tezture Measumnents of Metal Surfaces National Bureau Standards, Special Publication 300 
Vol 7. Washington, D.C. 1971. 30. Takagi, 3., Yokoi, S., and Tsurwoka, S. Comment on the Anisotropie 
Reflection Model. Bulletin of SIG. Graphics and CAD, Information Processing Society of Japan, in Japanese. 
Vol. 11. No. 1 pp. 2-9. 1983. 31. Tinkham, M. Group Theory and Quantum Mechanics. McGraw Hill pp.101-115. 
New York. 1964. 32. Torrance, Kenneth, and Sparrow, Ephraim. Theory for Off-Specular Reflection .from 
Roughened Surface. Journal of the Optical Society of America. Volume 57 No. 9 1967.  33. USA Standard 
Nomenclature and Definitions for Illuminating Engineering. USAS Z7.1-1967. 1967. 34. Whitted, Turner. 
An Improved Illumination Model for Shaded Display. Comm. ACM.'Vol. 23, No. 6, pp. 343-349. 1980. 35. 
Whltted, Turner, and Cook, Robert. A Comprehensive Shading Model. Image Rendering Tricks Course Notes. 
Siggraph Conference. 1985. 36. Williams, Lance. Pyramidal Parametries. Proceedings of SIG- GRAPH '83 
(Detroit, Michigan, July 25-29~ 1983). In Computer Graphics 17, 3, (July 1983), 1-11.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37435</article_id>
		<sort_key>283</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>33</seq_no>
		<title><![CDATA[Rendering antialiased shadows with depth maps]]></title>
		<page_from>283</page_from>
		<page_to>291</page_to>
		<doi_number>10.1145/37401.37435</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37435</url>
		<abstract>
			<par><![CDATA[We present a solution to the aliasing problem for shadow algorithms that use depth maps. The solution is based on a new filtering technique called percentage closer filtering. In addition to antialiasing, the improved algorithm provides soft shadow boundaries that resemble penumbrae. We describe the new algorithm in detail, demonstrate the effects of its parameters, and analyze its performance.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.3</cat_node>
				<descriptor>Filtering</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Measurement</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P299831</person_id>
				<author_profile_id><![CDATA[81100228626]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[Reeves]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pixar, San Rafael, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P63622</person_id>
				<author_profile_id><![CDATA[81100188207]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Salesin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pixar, San Rafael, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35024317</person_id>
				<author_profile_id><![CDATA[81100111623]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Cook]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pixar, San Rafael, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>808589</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Amanatides, Ray Tracing with Cones, Computer Graphics (SIGGRAPH '84 Proceedings) 18, 3 (July 1984), 129-145.]]></ref_text>
				<ref_id>ama84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807403</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[P. R. Atherton, K. Weiler and D. P. Oreenb~rg, Polygon Shadow Generation, Computer Graphics (SIGGRAPH "78 Proceedings) 12, 3 (August 1978), 275-281.]]></ref_text>
				<ref_id>AWG78</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13029</ref_obj_id>
				<ref_obj_pid>13028</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. Bergeron, A General Version of Crow's Shadow Volumes, IEEE Computer Graphics and Applications 6, 9 (Sept. 1986), 17-28.]]></ref_text>
				<ref_id>Ber86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. F. Blinn, Simulation of Wrinkled Surfaces, Computer Graphics (SIGGRAPH '78 Proceedings) 12, 3 (August 1978), 286-292.]]></ref_text>
				<ref_id>Bli78</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Bouknight and K. Kelley, An Algorithm for Producing Halftone Computer Graphics Presentations with Shadows and Moving Light Sources, SJCC, AFIPS 36 (1970), 1-10.]]></ref_text>
				<ref_id>BoK70</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[L. S. Brotman and N. I. Badler, Generating Soft Shadows with a Depth Buffer Algorithm, 1EEE CG&amp;A, October 1984.]]></ref_text>
				<ref_id>BrB84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[R. L. Cook, T. Porter and L. Carpenter, Distributed Ray Tracing, Computer Graphics (SIGGRAPH '84 Proceedings) 18, 3 (July 1984), 137-145.]]></ref_text>
				<ref_id>CPC84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808602</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. L. Cook, Shade Trees, Computer Graphics (SIGGRAPH '84 Proceedings) 18, 3 (July 1984), 223-231.]]></ref_text>
				<ref_id>Coo84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[R. L. Cook, Stochastic Sampling in Computer Graphics, ACM Transactions on Graphics 5, 1 (January 1986), 51-72.]]></ref_text>
				<ref_id>Coo86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[R. L. Cook, L. Carpenter and E. Catmull, An Algorithm for Rendering Complex Scenes, submitted to SIGGRAPH '87.]]></ref_text>
				<ref_id>CCC</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563901</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[F. C. Crow, Shadow Algorithms for Computer Graphics, Comp,ter Graphics (SIGGRAPH "77 Proceedings) 11, 2 (1977).]]></ref_text>
				<ref_id>Cro77</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808600</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[F. C. Crow, Summed-Area Tables for Textm-e Mapping, Computer Graphics (SIGGRAPH '84 Proceedings) 18, 3 0uly 1984), 207-212.]]></ref_text>
				<ref_id>Cro84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>16584</ref_obj_id>
				<ref_obj_pid>16564</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[N. Greene, Applications of World Projections, Graphics Interface '86, May 1986, 108-114.]]></ref_text>
				<ref_id>Gre86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[E. A. Haines and D. P. Greenberg, The Light Buffer: A Ray Tracer Shadow Testing Accelerator, 1EEE CG&amp;A 6, 9 (September 1986), 6-15.]]></ref_text>
				<ref_id>HAG86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808588</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[P. S. Heckbert and P. Hanrahan, Beam Tracing Polygonal Objects, Computer Graphics (SIGGRAPH '84 Proceedings) 18, 3 0uly 1984), 119-127.]]></ref_text>
				<ref_id>I-IeH84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[J. C. Hourcade and A. Nicolas, Algorithms for Andaliased Cast Shadows, Computers &amp; Graphics 9, 3 (1985), 259-265.]]></ref_text>
				<ref_id>HoNg5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[D. S. Kay, A Transparency Refraction and Ray Tracing for Computer Synthesized Images, master's thesis, Comell University, Ithaca, New York, 1979.]]></ref_text>
				<ref_id>Kay79</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15916</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[T. L. Kay and J. T. Kajiya, Ray Tracing Complex Scenes, Computer Graphics (SIGGRAPH '86 Proceedings) 20, 4 (Aug. 1986), 269-278.]]></ref_text>
				<ref_id>KaK86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15899</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[N. L. Max, Atmospheric Illuminadon and Shadows, Computer Graphics (SIGGRAPH "86 Proceedings) 20, 4 (August 1986), 117-124.]]></ref_text>
				<ref_id>Max86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>282938</ref_obj_id>
				<ref_obj_pid>282918</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[T. Nishita, L Okamura and E. Nakamae, Shading Mtxlels for Point and Linear Sources, ACM Trans. on Graphics 4, 2 (April 1985), 124-146.]]></ref_text>
				<ref_id>NON85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Pixar, Luxo Jr., July 1986.]]></ref_text>
				<ref_id>Pix86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Pixar, Red's Dream, July 1987.]]></ref_text>
				<ref_id>Pix87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325250</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[W. T. Reeves mad R. Biau, Approximate and Probabilisdc Algorithms for Shading and Rendering Structured Particle Systems, Computer Graphics (SIGGRAPH '85 Proceedings) 19, 3 Ouly 1985), 313-322.]]></ref_text>
				<ref_id>ReB85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807479</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[S. M. Rubin and T. Whitted, A 3-Dimensional Representation for Fast Rendering of Complex Scenes, Computer Graphics (SIGGRAPH '80 Proceedings) 14, 3 (July 1980), 110-116.]]></ref_text>
				<ref_id>RuW80</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[T. Whirred, An Improved Illumination Model for Shaded Display, Communications of the ACM 23 (1980), 343-349.]]></ref_text>
				<ref_id>Whi80</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807402</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[L. Williams, Casting Curved Shadows on Curved Surfaces, Computer Graphics 12, 3 (August 1978), 270-274.]]></ref_text>
				<ref_id>wn783</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801126</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[L. Williams, Pyramidal Parametrics, Computer Graphics 17, 3 (July 1983), 1-11.]]></ref_text>
				<ref_id>Wi183</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 21, Number 4, July 1987 III III Rendering Antialiased Shadows with Depth 
Maps William T. Reeves David 1-1. Salesin~- Robert L. Cook Pixar San Rafael, CA ABSTRACT We present 
a solution to the aliasing problem for shadow algorithms that use depth maps. The solution is based on 
a new filtering tech- nique called percentage closer filtering. In addition to antialiasing, the improved 
algorithm provides soft shadow boundaries that resem- ble penumbrae. We describe the new algorithm in 
detail, demon- strate the effects of its parameters, and analyze its performance. CR Categories and Subject 
Descriptors: 1.3.3 [Computer Graph- ics]: Picture/Image Generation -Display algorithms; 1.3.7 [Com-puter 
Graphics]: Three-Dimensional Graphics and Realism - Color, shading, shadowing, and texture General Terms: 
Algorithms, Performance Analysis Key Words: shadows, depth maps, antialiasing, percentage closer filtering 
1. Introduction Shadows enhance the images synthesized by computers. Although many algorithms for rendering 
shadows have been pub- lished, most have been either restricted to a limited crass of modeling primitives 
or are computationally expensive. Max [Max86] has classified these shadow rendering techniques as ray 
tracing, prepro- cessing, shadow volumes, area subdivision, and z -buffer algorithms. Ray tracing algorithms 
[Whi80] [Kay79] [CPC84] [HAG86] produce excellent shadows and are easy to implement, but they are expensive. 
In order to make ray tracing more tractable, many techniques have been developed for quickly determining 
which object a secondary ray hits lama84] [HeH84] [RuW80] [KaK86]. However, this does not completely 
solve the problem, since once the object is deter- mined it must still be accessed from the database. 
As models become more complex, the need to access any part of the model at any stage becomes more expensive; 
model and texture paging can dominate the rendering time. I" Current address: Computer Science DepL, 
Stanford University, Stanford, CA Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notioe and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. Non ray tracing algorithms produce shadows without tracing secon- dary rays. Because 
objects can be sorted into buckets or scan lines according to the part of the screen they affect, the 
model can be accessed efficiently. But these algorithms also have serious limita- tions. Shadow ot maps 
[ReB85] [Coo84] provide only a 2½-D solu- tion, not a general 3-D solution. Preproeessing algorithms 
[BoKT0] are suitable mostly for static environments. Shadow volumes [Cro77] [Ber86] [Max86] [NON85] [BrB841 
and area subdivision algorithms [AWG78] are restricted to polygonal data and are inefficient for complex 
environments. The z -buffer shadow algorithm developed by Williams [Wi178] does not have these problems. 
It can support all types of primitives; it is not excessively expensive, even for complex environments; 
and it is easy to implement. Its most serious drawback is a severe aliasing problem; it also requires 
additional memory for the z -buffer. The z-buffer algorithm's singular versatility, efficiency, and simpli- 
city make it tempting to look for ways to overcome its drawbacks, particularly the more serious aliasing 
problem. Storing floating point values in the depth buffer instead of 16-bit integers (as Williams did) 
reduces but does not solve this problem. An approach proposed by Hourcade and Nicolas [HEN85] stores 
object tags instead of depth values, but a limitation is that surfaces may not cast shadows on themselves. 
In this paper, we introduce percentage closer filtering, a new sam-pling technique that can be used to 
eliminate the aliasing problem in Williams's z-buffer shadow algorithm. In addition to providing antialiased 
shadows, our new technique can be used to render soft shadow edges that resemble penumbrae. 2. Percentage 
Closer Filtering The z-buffer algorithm presented in [Wi178] operates in two passes, as illustrated for 
a simple scene in Figure 1. In the first pass, a view of the scene is computed from the light source's 
point of view, and the z values for objects nearest the light are stored in a z - buffer (also known 
as a depth map). In the second pass, the scene is rendered from the camera's position. At each pixel, 
a point on the surface is transformed to tight source space, and its transformed z is compared against 
the z of the object nearest the light, as recorded in the depth map. If the transformed z is behind the 
stored z, the point is considered to be in shadow. This algorithm has two aliasing problems: one in creating 
the depth maps, and the other in sampling them. The first aliasing problem can be solved by creating 
the depth maps with stochastic sampling [Coo86]. We solve the second problem by introducing a new tech- 
nique called percentage closer filtering. &#38;#169; 1987 ACM-0-89791-227-6/87/007/0283 $00.75   ~ 
SIGGRAPH '87, Anaheim, July 27-31, 1987 Light source ]~"~-~-- Camera (a) View from high above the scene. 
(b) View from the light source. (c) View from the camera. Figure 1. Points of view for a simple scene. 
 Ordinarily, texture maps are accessed by filtering the texture values over some region of the texture 
map. However, depth maps for sha- dow calculations cannot be accessed in this manner. The main prob- 
lem is that the filtered depth value would be compared to the depth of the surface being rendered to 
determine whether or not the surface is in shadow at that point. The result of this comparison would 
be binary, making soft antialiased edges impossible. Another problem is that filtered depth values along 
the edges of objects would bear no relation to the geometry of the scene. Our solution reverses the order 
of the filtering and comparison steps. The z values of the depth map across the entire region are first 
com- pared against the depth of the surface being rendered. This sample transformationconverts the depth 
map under the region into a binary image, which is then filtered to give the proportion of the region 
in shadow. The resulting shadows have soft, antialiased edges. The difference between ordinary texture 
map filtering and percentage closer filtering is shown schematically in Figure 2. In this example, the 
distance from the light source to the surface to be shadowed is z = 49.8. The region in the depth map 
that it maps onto (shown on the left in the figures) is a square measuring 3 pixels by 3 pixels.* Ordinary 
filtering would filter the depth map values to get 22.9 and then compare that to 49.8 to end up with 
a value of 1 meaning that 100% of the surface was in shadow. Percentage closer filtering com- pares each 
depth map value to 49.8 and then filters the array of binary values to arrive at a value of .55 meaning 
that 55% of the sur- face is in shadow. A square region and box filtering are used to simplify this example. 
The real algorithm, as described in subsequent sections, uses more sophisticated techniques. Surface 
at z = 49.8 ) 50.2 50.0 50.0 J , x -4-----,---"- 50.1 1.2 1.1 22.9 ~ 1 1.3 1.4 t.2 a) Ordinary texture 
map filtering. Does not work for depth maps. Surface at z = 49.8 /  50.2 50.0 50.0 J 0 0 0 50.1 1.2 
1.1 .55 ~ 1.3 1.4 1.2 1 1 1 Sample Transform Step b) Percentage closer filtering. Figure 2. Ordinary 
filtering versus percentage closer filtering.  ~ Computer Graphics, Volume 21, Number 4, July 1987 In 
ordinary texture map applications, the cost of examining every pixel in a region can be avoided by saving 
the texture in some prefiltered format such as resolution pyramids [Wi183] or summed- area tables [Cro84]. 
Because our sample transformation depends on the unfiltered depth values, we cannot apply any such prefiltering 
technique here. But we can limit the number of texture pixel accesses in another way. By employing Monte 
Carlo techniques [Coo861, we can use a small, constant number of samples to approxi- mate the result 
of transforming every sample in the region. This can be done in one of several ways (Figure 3): (a) choose 
samples randomly from a bounding box for the region; (b) choose samples under some distribution, such 
as a Gaus- sian, from the same bounding box; (c) partition the bounding box into subregions and sample 
each one with jitter; (d) sample only positions inside the geometric boundary of the region.  Method 
(c), jitter sampling, approximates a Poisson disk distribution to produce shadows that are less noisy 
than those produced with either (a) or (b). All figures in this paper use (c), though (a) was used successfully 
in Luxo Jr. [Pix86]. Images made with (b) did not appear substantially different from those made with 
(a). We have not implemented (d), which is potentially more accurate, but also more complex and expensive. 
Increasing the size of the sample region diffuses a shadow's edge over a larger area, resulting in a 
soft shadow edge resembling a penumbra. Although the shadow edges produced am not true penumbrae (in 
that their sizes do not depend on the relative distances between objects and light source), we have nevertheless 
found them convincing enough for many applications, 3. Implementation of the Algorithm We now describe 
in detail how percentage closer filtering can be used with a depth buffer to create shadows. As in Williams's 
origi- nal z-buffer algorithm, we use two passes: one to create the depth map for each light source; 
and one to render the scene, using the depth maps to determine portions of objects in shadow. 3.1 First 
Pass: Creating the Depth Maps The depth map for each light source is created by computing the depth values 
for all objects in the image from the light source's point of view. In the screen space of the light, 
the x- and y-coordinates correspond to pixel locations in the depth map, and the z -coordinate (in floating 
point) is the distance from the light in world space. We use the term light space to refer to these x, 
y, and z values. .............................. t a Bounding box sampled with uniform distribution. 
c Bounding box sampled with jitter. In practice, we use regular sampling instead of stochastic sampling 
when creating the depth maps. This is because with one sample per pixel and low depth map resolutions, 
the slight aliasing of depth values with regular sampling is sometimes less objectionable than noise 
with stochastic sampling. We use a relatively course resolu- tion for our depth maps in order to minimize 
the memory require- ments. The first pass can be implemented very easily. In our rendering sys- tem, 
we only needed to make one change: instead of computing and storing integer color values in a picture 
file, the closest z values (which are already being computed for l~dden surface calculations) must be 
stored in floating point in a texture file.* This change amounted to about 40 lines of code out of over 
30,000 for the render- ing system as a whole. A depth map can be computed faster than a shaded image 
for several reasons. First, none of the shading, texturing, and lighting calcula- tions are needed. Second, 
objects (such as the ground plane) that never cast shadows on any other object can be ignored. Finally, 
depth maps require only one sample per pixel. 3.2 Second Pass: Rendering the Scene In the second pass, 
the scene is rendered from the camera's point of view. Each shading calculation represents some region 
on a sur- face. Depending on the rendering system, these regions might represent anything from polygons 
coveting large areas of pixels (e.g., for a painter's algorithm) to exact pixel regions (e.g., for scan- 
line methods) to tiny subpixel regions-(e.g., for micropolygons [CCC]). The shadow algorithm presented 
here is independent of the type of region used. Each region to he shaded is first mapped into light space, 
giving a region in the depth map. Percentage closer filtering is used to deter- mine the proportion of 
z values in the region of the depth map that are closer to the light than the surface. This gives the 
proportion of the surface in shadow over the region. This proportion is then used to attenuate the intensity 
of the light. If several lights in a scene cast shadows, this process is repeated for every light. The 
attenuated intensities are then used in the shading calculations. One problem arises if the transformed 
region lies outside the extent of the depth map. Generally, we use the convention that regions out- side 
the light source's field of view are not considered to be in sha- dow. For directed lights the distinction 
is not important, since objects outside a light's field of view are not illuminated by that light anyway. 
For lights that cast shadows in all directions, a more com- plex mapping scheme, such as spherical or 
cubical environment maps, should be used [Gre86]. * For pixels containing no visible surface, a very 
large constant is stored to denote an infinite depth. b Bounding box sampled with gaussian distribution. 
.. :".., x. ..... '.. ...... -.-" "... :'-...._......x .... d Geometric boundary sampled with jitter. 
 Figure 3. Different methods for choosing samples. ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 Our implementation 
of the second pass is simplified by the use of light trees [Coo84]. Light trees are essentially small 
programs that describe the illumination calculations for individual light sources. They allow us to describe 
lights with different characteristics. For example, we earl control the softness of shadow edges or distinguish 
lights that east shadows from lights that do not. As each region is shaded, the light trees are called 
to determine the proportion of the region illuminated. Each light tree calls the percentage closer filter- 
ing routine, passing a pointer to the depth map and the region to be filtered, and uses the result (in 
conjunction, perhaps, with other parameters controlling the spatial distribution of the ligh0 in com- 
puting its contribution to the illumination of the surface. In our implementation, the second pass required 
about 370 lines of code. Most of this code served merely to integrate the heart of the percentage closer 
filtering algorithm, shown in Figure 4, with the rest of our renderer. The code in Figure d provides 
a number of parameters that we can adjust in computing our shadows. The NumSamples parameter Controls 
the number of sample points used per region. The Res-Factor parameter artificially enlarges the size 
of the sampling region, allowing lights that cast softer shadows. The Bias parame-ter is used to offset 
the surface slightly when comparisons to the z values in the depth buffer are made. This prevents a surface 
from incorrectly shadowing itself if a z value for a point on the surface is compared to the depth map 
z from a nearby but different position on the same surface.* This incorrect self-shadowing can create 
Moir4 patterns. The effects of these and other parameters are discussed later. 3.3 Storage Issues Depth 
maps tend to be large. We store along with each depth map a bounding box of all pixels with finite depths, 
and pixeis out- side this box are not actually stored with the depth map. We have not found the working 
storage requirements of our algorithm to be too great. For a scanline rendering algorithm, locality in 
the screen space of the camera is correlated with locality in the screen space of the light source. Thus, 
a simple paging scheme works well for this application. Still more memory could potentially be saved 
by dividing the depth map into rectangular tiles, which could be cached to take better advantage of the 
algorithm's two-dimensional locality. In addition, a tile scheme would allow us to store a maximum z 
value with each tile, thereby avoiding sampling the depth map altogether if a region were further away 
from the light than any object in the tile. 4. Examples 4.1 Effect of Stochastic Percentage Closer Filtering 
Our first example, Figure 5, shows a simple scene. A light source off-screen to the left shines on a 
red sphere, which casts a sha- dow onto an uptight green plane. Figure 6 is the result when the dif- 
fuse and specular shading components are removed, revealing only the shadow component of the shading. 
The image in Figure 6a was rendered with our algorithm but with its parameters set to simulate an ordinary 
z-buffer algorithm (i.e., the depth map is point sampled without jitter). The image in Figure 6b uses 
the same depth map as the other, but is rendered using our new technique of percentage closer filtering. 
This image has antialiased shadow edges. We actually specify a minimum and a maximum bias, and at every 
sample the actual bias is chosen stochastically from that range. This allows a surface to curve over 
to legitimately shadow itself without allasing. /* parameters setable in other, parts of renderer * / 
 float ResFactor = 3, MinSize -0, Bias0 -.3, Biasl -.4; int NumSamples -16, MinSamples -i; #define MAPRES 
1024 /* sizeof depthmap */ float DepthMap[MAPRES] [MAPRES] ; /* actual depth map */ #define CLAMP(a, 
min, max) (a<min?min: (a>max?max:a)) float Rand ( ) ; /* returns random numbers in range [0.,1.) * / 
float cei 1 ( ) ; /* returns smallesl integer no less than argument * / float floor () ; /* returns largesI 
integer no greater than argument */ typedef struct { int r umin, r_umax; /* rain andmaxpixels in u dimension 
* / int r_vmin, r_vmax ; /* rain and max pixels in v dimen,~ion * / } TextureRect ; float SampleShadow(s, 
t, z, sres, tres, bbox) float s, t; /* depthmap indices, range [0.,1.) */ float z ; /~ light space depth 
* / float sres, tres; /* size of sampling rectangle, range [0..I.) * / TextureRect *bbox; /* bounding 
box on depth map in pixels */ { int i, j, inshadow, iu, iv, as, nt, lu, hu, iv, hg; float bias, smin, 
tmin, ds, dr, js, jr; / * ffpoint is behind light source, call it not in shadow * / if (Z < 0.) return 
(0 . ) ; / * convert to coordinates of depth map * / sres = MAPRES * sres * ResFactor; tres -MAPRES 
* tres * ResFactor; if(sres < MinSize) sres --MinSize; if(tres < MinSize) tres -MinSize; s = s * MAPRES; 
t = t * MAPRES; /* cull if outside bounding box */ lu -floor(s -sres); hu = eeil(s + sres); iv -floor(t 
-tres) ; hv -ceil (t +tres) ; if (lu>bbox->r_umax II hu<bbox->r_umin II iv>bbox->r_vmax II hv<bbox->r_vmin) 
return (0.) ; / * calculate number of samples * / if(sres*tres*4. < Nu~Samples) { ns z sres*2.+.5; ns 
= CLAMP(ns, MinSamples, NumSamples); nt = tres*2.+.5; nt = CLAMP(nt, MinSamples, MumSamples); } else 
{ nt = sqrt (tres*NumSamples/sres) +. 5; ns = CLAMP (ns, MinSamples, NumSamples) ; ns = ( (float)NumSamples}/nt+.5; 
ntz CLAMP (nt, MinSamples, NumSamples) ; ) / * setup jitter variables * / ds = 2*sres/ns; dt ~ 2*tres/nt; 
js = ds*.5; jt = dr*.5; stain = s -sres + js; tmin = t -tres + jt; / * test the samples * / inshadow 
= 0; for (i = 0, s ~ stain; i < ns; i = i+l, s = s+ds) { for (j = 0, t = tmin; j < nt; j = j+l, t = t+dt) 
{ /* jitter s and t * / iu = s + Rand() * js; iv = t + Rand() * jr; / * pick a random bias * / bias 
= Rand () * (Biasl-Bias0) +Bias0; / * clip to bbox * / if (iu>=bbox->r umin &#38;&#38; iu<=bbox->r_umax 
&#38;&#38; iv>=bbox->r vmin ~ iv<=bbox->r vmax) { /* compare z value to z from depth map ~us bias * / 
if(z > DepthMap[iu] [iv] + bias) inshadow -inshadow+i; } ) } return ( ((float) inshadow) / ~ns*nt) ) 
; Figure 4. Percentage Closer Filtering Algorithm.   SIGGRAPH '87, Anaheim, July 27-31 1987 I~~] 
Computation Time (in minutes) image Without Shadows Number of Lights First pass Second pass Sphere and 
plane 42.0 1 9.7 48.0 Colored lights 64.4 3 14.2 80.8 Luxo Jr. 58.8 3 14.6 74.2 Red' s Dream 261.3 2 
55.3 332.1 Total With Shadows % Increase 57.7 95.0 88.8 387.4 37.3 47.6 50.9 48.4  TABLE 1. Shadow 
Algorithm Performance Depth Map Storage (in megabytes) ResolutionsImage Sphere and plane 1 at 10242 Colored 
lights 3 at 10242 Luxo Jr. 1 at 20482, 2 at 10242 Bike Store 2 at 10242 Raw Depth Bounding Box Tile 
Maps Scheme Scheme 4.0 .4 .4 12.0 2.6 2.9 24.0 13.0 3.7 8.0 5.6 4.2 TABLE 2. Depth Map Storage A breakdown 
of the extra time spent in computing our sample frame from Luxo Jr. gives an idea of where that extra 
time is spent. The first pass (creating the three depth maps) accounts for 50% of the extra time. Of 
the remaining half, the percentage closer filtering accounts for 28%, and the transformation of regions' 
coordinates into light space accounts for the remaining 22% of the extra time. This last transformation 
is performed by the light tree, which is implemented with an interpreted language. It could be sped up 
con- siderably if we wrote the transformation code in C. Depth map storage statistics for the examples 
are shown in Table 2. The "Resolution" column lists the size of the depth maps used. The "Raw Depth Maps" 
column gives the total size of the depth maps if no storage compaction scheme is used. The "Bounding 
Box Scheme" column gives the size when only the parts of the depth map containing non-infinite depths 
are stored. The "Tile Scheme" column gives the size when 32×32-pixel tiles are used. While the algorithm 
uses a lot of storage when the raw depth maps are stored, our bounding box scheme can give significant 
improve- ments. In some very complex images, such as Red's Dream, the bounding box scheme may not save 
much storage because objects that can potentially east shadows are everywhere in the scene. In such images, 
a tile scheme may give better results. 6. Limitations and Future Work Although the shadow algorithm described 
here provides an improvement to Williarns's original depth buffer algorithm, it still has many/imitations. 
The algorithm does not handle motion blur nor compute exact penumbrae. We are currently investigating 
extensions of the algo- rithm that we believe will address these limitations. However, it is worth noting 
that for many situations the algorithm presented here is adequate. For instance, the shadows in Luxo 
Jr. did not have correct penumbrae, and while the lamps themselves were rendered with motion blur, the 
shadows were not. The algorithm presented here also does not address transparent or translucent objects 
that cast sha- dows. Although the use of bounding boxes reduces the algorithm's storage requirements 
considerably, we would like to develop more sophisti- cated schemes for reducing this storage requirement 
further. The tile-based scheme outlined in this paper would be one approach. An adaptive scheme, where 
higher or lower resolution areas were used depending on the relative complexities of various regions 
of the scene, might also be appropriate. We would like to develop better tools for automating the process 
of creating the depth maps and generating the light trees. We would also like to build a system that 
used more intuitive parameters that corresponded more closely with aspects of the appearance of sha- 
dows in the scene. This might obviate much of the trial-and-error we have relied upon in choosing parameter 
values for our scenes. Finally, we hope to be able to generalize and formalize the sample transformation 
step in percentage closer filtering. We believe that this technique may have important implications to 
the use of texture maps for other purposes. For example, in bump mapping [B1i78], specular reflections 
could be computed before filtering, and the results could be filtered and sampled as ordinary textures. 
In this way, specular highlights from the mierofacets of a bumpy surface would be maintained even as 
the surface were translated back into the far distance. 7. Conclusions We have presented a solution to 
the aliasing problem for the depth buffer shadow algorithm. This solution is based on a new technique 
for using texture maps called percentage closer filtering. Other improvements to the algorithm include 
using floating point values in the depth map and including the shadow information as part of the shading 
calculations instead of as a postprocess. The new technique also provides a penumbra-like effect by providing 
control over the softness of shadow edges. Our method is more expensive than the original, both in terms 
of time and space. Percentage closer filtering takes more time than evaluating a single sample, and floating 
point numbers typically con- sume more space than integers. However, because percentage closer filtering 
requires only a constant number of samples per region, the extra cost is bounded by a constant factor, 
and in practice this factor is small. We feel that the extra time and space are justified by the improved 
image quality. This improved image quality has proven robust in an animated sequence. 8. Acknowledgements 
Eben Ostby, Loren Carpenter and Paul Heckbert provided many significant insights while the algorithm 
was being developed. Eben also found several bugs and optimized parts of the code. Eben and John Lasseter 
helped test the algorithm by designing animated sequences that depended on the shadows to work. Ricki 
Blau pro- vided photographic assistance. ~ Computer Graphics, Volume 21, Number 4, July 1987 9. Bibliography 
lPix86] Pixar, Luxo Jr., July 1986. [Pix87] Pixar, Red's Dream, July 1987. [ReB85] W. T. Reeves mad R. 
Biau, Approximate and Probabilisdc Algorithms for Shading and Rendering Structured Particle Systems, 
Computer Graphics (SIGGRAPH '85 Proceedings) 19, 3 Ouly 1985), 313-322. [RuW80] S. M. Rubin and T. Whitted, 
A 3-Dimensional Representation for Fast Rendering of Complex Scenes, Computer Graphics (SIGGRAPH '80 
Proceedings) 14, 3 (July 1980), 110-116. [Whi80] T. Whirred, An Improved Illumination Model for Shaded 
Display, Communications of the ACM 23 (1980), 343-349. [wn783 L. Williams, Casting Curved Shadows on 
Curved Surfaces, Computer Graphics 12, 3 (August 1978), 270-274. [Wi183] L. Williams, Pyramidal Parametrics, 
Computer Graphics 17, 3 (July 1983), 1-11. lama841 IAWG781 [Ber86] [Bli78] [BoK70] [BrB84] [CPC841 [Coo84] 
[Coo86] [CCC] [Cro77] [Cro84] [Gre86] [HAG86] [I-IeH84] [HoNg5] [Kay79] [KaK86] [Max86] [NON85] J. Amanatides, 
Ray Tracing with Cones, Computer Graphics (SIGGRAPH '84 Proceedings) 18, 3 (July 1984), 129-145. P. R. 
Atherton, K. Weiler and D. P. Oreenb~rg, Polygon Sha- dow Generation, Computer Graphics (SIGGRAPH "78 
Proceedings) 12, 3 (August 1978), 275-281. P. Bergeron, A General Version of Crow's Shadow Volumes, IEEE 
Computer Graphics and Applications 6, 9 (Sept. 1986), 17-28. J. F. Blinn, Simulation of Wrinkled Surfaces, 
Computer Graphics (SIGGRAPH '78 Proceedings) 12, 3 (August 1978), 286-292. ft. Bouknight and K. Kelley, 
An Algorithm for Producing Halftone Computer Graphics Presentations with Shadows and Moving Light Sources, 
SJCC, AFIPS 36 (1970), 1-10. L. S. Brotman and N. I. Badler, Generating Soft Shadows with a Depth Buffer 
Algorithm, 1EEE CG&#38;A, October 1984. R. L. Cook, T. Porter and L. Carpenter, Distributed Ray Tracing, 
Computer Graphics (SIGGRAPH '84 Proceedings) 18, 3 (July 1984), 137-145. R. L. Cook, Shade Trees, Computer 
Graphics (SIGGRAPH '84 Proceedings) 18, 3 (July 1984), 223-231. R. L. Cook, Stochastic Sampling in Computer 
Graphics, ACM Transactions on Graphics 5, 1 (January 1986), 51-72. R. L. Cook, L. Carpenter and E. Catmull, 
An Algorithm for Rendering Complex Scenes, submitted to SIGGRAPH '87. F. C. Crow, Shadow Algorithms for 
Computer Graphics, Comp,ter Graphics (SIGGRAPH "77 Proceedings) 11, 2 (1977). F. C. Crow, Summed-Area 
Tables for Textm-e Mapping, Computer Graphics (SIGGRAPH '84 Proceedings) 18, 3 0uly 1984), 207-212. N. 
Greene, Applications of World Projections, Graphics Interface '86, May 1986, 108-114. E. A. Haines and 
D. P. Greenberg, The Light Buffer: A Ray Tracer Shadow Testing Accelerator, 1EEE CG&#38;A 6, 9 (September 
1986), 6-15. P. S. Heckbert and P. Hanrahan, Beam Tracing Polygonal Objects, Computer Graphics (SIGGRAPH 
'84 Proceedings) 18, 3 0uly 1984), 119-127. J. C. Hourcade and A. Nicolas, Algorithms for Andaliased 
Cast Shadows, Computers &#38; Graphics 9, 3 (1985), 259-265. D. S. Kay, A Transparency Refraction and 
Ray Tracing for Computer Synthesized Images, master's thesis, Comell University, Ithaca, New York, 1979. 
T. L. Kay and J. T. Kajiya, Ray Tracing Complex Scenes, Computer Graphics (SIGGRAPH '86 Proceedings) 
20, 4 (Aug. 1986), 269-278. N. L. Max, Atmospheric Illuminadon and Shadows, Computer Graphics (SIGGRAPH 
"86 Proceedings) 20, 4 (August 1986), 117-124. T. Nishita, L Okamura and E. Nakamae, Shading Mtxlels 
for Point and Linear Sources, ACM Trans. on Graphics 4, 2 (April 1985), 124-146.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37436</article_id>
		<sort_key>293</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>34</seq_no>
		<title><![CDATA[The zonal method for calculating light intensities in the presence of a participating medium]]></title>
		<page_from>293</page_from>
		<page_to>302</page_to>
		<doi_number>10.1145/37401.37436</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37436</url>
		<abstract>
			<par><![CDATA[The zonal method for calculating radiative transfer in the presence of a participating medium is applied to the generation of realistic synthetic images. The method generalizes the radiosity method and allows for emission, scattering, and absorption by a participating medium. The zonal method accounts for volume/surface interactions which have not been previously included, as well as volume/volume and surface/surface interactions. In addition, new algorithms, based on the hemi-cube formulation, are introduced for calculating the geometric factors required by the zonal method.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Viewing algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.3</cat_node>
				<descriptor>Filtering</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P111526</person_id>
				<author_profile_id><![CDATA[81100255828]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Holly]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Rushmeier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell Univ., Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31097274</person_id>
				<author_profile_id><![CDATA[81332531868]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kenneth]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Torrance]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell Univ., Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>801255</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Blinn, James F. Light Reflection Functions for Simulation of Clouds and Dusty Surfaces. Proceedings of SIGGRAPH '82 (Boston, Massachusetts, July 26-30,1982). In Computer Graphics 16, 3 (July 1982), 21-29.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F. and Donald P. Greenberg. The Hemi-Cube: Radiosity Solution for Complex Environments. Proceedings of SIGGRAPH '85 (San Francisco, California, July 22-26, 1985). In Computer Graphics 19, 3 (July 1985), 31-40.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Glassner, Andrew S. Space Subdivision for Fast Ray Tracing. IEEE Computer Graphics and Applications 4, I0 (October 1984), 15-22.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Goral, Cindy M., Kenneth E. Torrance, Donald P. Greenberg, and Bennett Battaile. Modeling the Interaction of Light Between Diffuse Surfaces. Proceedings of SIGGRAPH '84 (Minneapolis, Minnesota, July 23-27, 1984). In Computer Graphics 18, 3 (July 1984), 213-222.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Hottel, Hoyt C., and Adel F. Saroflm, Radiative Transfer. McGraw-Hill, New York, New York, 1967.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Immel, David S., Michael F. Cohen and Donald P. Greenberg. A Radiosity Method for Non-Diffuse Environments. Proceedings of SIGGRAPH '86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics 20, 4 (August 1986), 133-142.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808594</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Kajiya, James T. and Brian P. Von Herzen. Ray Tracing Volume Densities. Proceedings of SIGGRAPH '84 (Minneapolis, Minnesota, July 23-27, 1984). In Computer Graphics 18, 3 (July 1984), 165-174.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5515</ref_obj_id>
				<ref_obj_pid>5513</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Max, Nelson L. Light Diffusion through Clouds and Haze. Computer Vision, Graphics, __and Image Processing 33, 3 (March 1986), 280-292.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15899</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Max, Nelson L. Atmospheric Illumination and Shadows. Proceedings of SIGGRAPH '86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics 20, 4 (August 1986), 117-124.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>7920</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Meyer, Gary W., Holly E. Rushmeier, Michael F. Cohen, Donald P. Greenberg and Kenneth E. Torrance. An Experimental Evaluation of Computer Graphics Imagery. ACM Transactions on Graphics 5, 1 (January 1986) 30-50.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Rushmeler, Holly E. Extending the Radiosity Method to Transmitting and Specularly Reflecting Surfaces. Masters Thesis, Cornell University, 1986.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13045</ref_obj_id>
				<ref_obj_pid>13043</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Wyvill, Geoff, Tosiyasu L. Kunii and Yasuto Shirai. Space Subdivision for Ray Tracing in CSG. IEEE Computer Graphics and Applications 6, 4 (April 1986) 28-34.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
  SIGGRAPH '87, Anaheim, July 27-31, 1987 l~~I participating medium is calculated by using the scattering 
equation of transfer. Direct input from a light source and from inter-volume scatter are included. In 
a second step, the intensity due to surface reflections is combined with the intensity of the participating 
medium by ray tracing. The method does not account for surface/volume interactions, nor for diffuse surface/surface 
reflections. In this paper a general method is introduced which allows for all volume/volume, volume/surface, 
and surface/surface interactions. The method assumes isotropic, volumetric emission, absorption, and 
scattering by the participating medium, and ideal diffuse reflection from opaque surfaces. Directional 
(non-diffuse) lighting is allowed. The method is based on, and extends, the radiosity method. The method 
was developed for radiant heat transfer analysis by Hottel and Sarofim [5] and is known as the zonal 
method. The participating medium is discretized into small volumes (or zones), each with a uniform volume 
radiosity. Complex geometries with arbitrary reflecting surfaces are readily included. In the following 
sections, the zonal method is described, extended, and applied to the calculation of light intensities 
in a scene. 2. BASIC CONCEPTS In the zonal method, all surfaces are assumed to be opaque, ideal-diffuse 
emitters and/or reflectors of light. Scattering and emission within the participating medium is assumed 
to be isotropic (i.e. independent of direction). In this paper, it is further assumed that light absorbed 
in one wavelength band is not re-emitted in another. This leads to independent sets of equations for 
the light intensities within discrete wavelength bands. 2.1 Absorption -The intensity of light is defined 
as the radiant energy crossing an area per unit time, per unit area (projected on a plane perpendicular 
to the direction of travel), and per unit solid angle. When light travels through an absorbing medium, 
however, the intensity of light decreases along the path. Consider a pencil of light of intensi~y I incident 
on a small volume of matter, dr, as in Fig. 2a. The energy absorbed by the volume per unit time is: 
I -intensity of incident pencil incident beamd2Vk ~°flight light dw e of dV ~-\----~k \ d3Pab s = K 
a I dm dA cos8 dx = Ka I d~ d2V (1) where K a is the absorption coefficient (the fraction by which the 
intensity of the light is reduced by absorption as it passes through a unit distance in the volume), 
d~ is the solid angle of the pencil of light, dA cos8 is the illuminated surface area, 8 is the angle 
between the pencil of light and the normal to dA, and dx is the distance traveled through the volume. 
On the right side of Eq. (1), d2V denotes the differential volume through which the light passes. Next, 
consider a larger beam of light of uniform intensity I which has the same directional orientation as 
the original pencil but fully illuminates the volume dV, as shown in Fig. 2b. The energy absorbed per 
unit time is found by integrating Eq. (i) : d2Pabs = K a I d~ dV (2) Finally, consider light of constant 
intensity I arriving uniformly from all directions, as shown in Fig. 2c. The energy absorbed per unit 
time is found by integrating Eq. (2) over 4K steradians to obtain: dPab s = 4RK a IdV (3) In this integration, 
all surfaces are presumed to be uniformly illuminated by light of intensity I. Equation (3) can also 
be written in terms of a directionally-uniform incident flux density H, which is equal to nl (or to RI 
if the intensity ave is not directionally uniform) as dPab s = 4 Ka H dV (4) The units of H are energy 
per unit time per unit area. 2.2 Emission -Emitted energy leaving a surface is expressed by the energy 
flux density, E, in energy per unit time per unit area. The energy per unit time, Pem' emitted by a surface 
of area A is EA (watts). The analogous derivation of P for a em volume with energy flux density E requires 
care, and the interested readerls referred to the first chapter of [5] for details. Basically, from the 
laws of thermodynamics it can be shown that the energy emitted per unit time, dPem , from a volume  
d ¢~ ~.~ ~ r / k -- -- -v (a) (b) (c) (d)  beam of light encompassing a volume; (c) Uniform Figure 
2 -Geometry of light absorption: (a) A irradiation on a volume. (d) Geometry of lightsmall pencil of 
light intersecting a volume; (b) A emission/scattering by a volume.  ~ Computer Graphics, Volume 21, 
Number 4, July 1987 dV with emisslve flux density E is: dP = 4 K E dV (5) em a where m is the absorption 
coefficient. Since K is a a the fraction by which intensity is reduced by absorption per unit length, 
the product KaE has units of energy per unit time per unit volume. For isotropic emission, K and E are 
independent of a direction. Thus, the emitted light goes out uniformly in all directions, as sketched 
in Fig. 2d. 2.3 Scattering -Scattering redirects energy within a volume. Similar to the definition for 
absorption, let K be the fraction by which the s intensity of a pencil of light in a particular direction 
is reduced by scattering as it travels a unit distance. The total energy scattered per unit time, dPsc, 
is: dP = 4 K H dV (6) sc s For isotropic scattering, the intensity of scattered light is uniform in 
all directions as sketched in Fig. 2d. 2.4 Volume Transmittance -The transmittance, , of a volume is 
a directional quantity which describes how much of the light on a given path will pass through the volume 
without being absorbed or scattered. For a pencil of light traveling a differential distance in a particular 
direction, the intensity is reduced by absorption and scattering by: dl = -Ktl dx, or, dl/dx =-Ktl (7a) 
 where K t m K a + K s (7b) Integration of Eq. (7) yields the intensity I(x) at a distance x into the 
medium: I(x) = I ° exp[- fO x K t dx*] (8a) where I is the initial intensity, and * denotes a o dummy 
variable. Thus, the transmittance is given by: (x) = exp[-fO x K t dx*] (8b) 2.5 Volume Radiosity -The 
flux density leaving a volume element due to emission and scattering is defined as the volume radiosity 
B, given by: 4 KtB = 4 KaE + 4 KsH (9) The radiosity of a volume includes onl 7 the energy which has 
been emitted or scattered by the volume. Energy that is transmitted directly through the volume is not 
included. By introducing the isotropic scattering albedo, defined as ~ m Ks/Kt, Eq. (9) can be written 
in the alternate form: B = (1 -9)E + 9.H (10) Equation (10) is similar to the defining equation for 
the radiosity of a surface. The isotropic scattering albedo ~ appears in place of the diffuse reflectance 
p of the surface. 2.6 Variation of Intensity along a Light Path -The intensity of light reaching the 
eye depends on the attenuation of intensity along the light path due to absorption and scattering, and 
on the enhancement due to emission and in-scattering. In-scattering refers to the scattering of incident 
light into the direction of interest. Equation (7) describes attenuation along a path. Similarly, the 
enhancement can be described by: dl/dx = KtJ(x) (II) where J(x) is the scattered and emitted intensity 
originating from an infinitesimal volume of thickness dx at x. For isotropic emission and scattering 
J(x) is related to the volume radiosity by J(x) = B(x)/E. Defining t = fO x Kt(x*)dx*, and summing 
Eqs. (7) and (II), the following relation between the local intensity and the scattered/emitted intensity 
results: dl/dt = -I(t) + J(t) (12) Integration of Eq. (12) yields: I(t)= exp(-t)[ I ° + fO t J(t*)exp(t*) 
dr*} (13) 3. GEOMETRIC FACTORS In the radiosity method [4], linear algebraic equations for the surface 
radiosities are constructed by using form factors which depend on geometry alone. In the zonal method 
the concept of form factors is extended to include volumes. 3.1 Surface to Surface (SiSj) Factors -The 
geometry of two surfaces interchanging energy is shown in Fig. 3a. In the absence of a participating 
medium, the fraction of energy leaving a differential element dA. and reaching a differential element 
dA i is: I FdAidAj = coseicosOjdAj/(~slj 2) (14) An absorbing/scattering medium will reduce the amount 
of energy traveling directly from dA. to i dAj, and a transmittance T (as given in Eq. (8b)) must be 
included: FdAidA j = ~(si j)cos@icos@jdAj/(~sij2) (15) The fraction of energy leaving a finite surface 
A. 1 of uniform radiosity B i that arrives at a second finite surface A. is found by integrating over 
the 3 two surfaces: Fij = (1/Ai) fAi fAj ~(sij)c°seic°sejdAjdAi/(nsij z) (16) This differs from a 
conventional form factor by the inclusion of the transmittance inside the   ~Z SIGGRAPH '87, Anaheim, 
July 27-31, 1987 r / / /I / S HA/ (a) Figure 3 -Geometry of Between two surfaces ; (b) / J dV 
k ~-~ f I_ ff -~'/ I I I I I I/. i L ~. light interchange, (a) Between a volume and a integral. In 
the zonal method it ~s more convenient to use a factor SiSj given by AiFij, or: SiSj = --IAi IAj ~(sij)c°s®ic°s%dAjdAi/(~sij 
2) (17) SiSj can be interpreted as the total energy reaching surface j from surface i, divided by the 
radiosity of surface i. Note that SiSj is equal to S~Si; this is consistent with the reciprocity requirements. 
 3.2 Volume to Surface (VkSj) Factors -The geometry of a volume exchanging energy with a surface is shown 
in Fig. 3b. The total energy scattered from and emitted by a volume is found by summing Eq. (5) and (6) 
and applying the definition given in Eq. (9). The fraction of energy emitted from or scattered by volume 
dV k and reaching a surface dAj, in the absence of any intervening medium, is the solid angle subtended 
by dA. 3 divided by 4~. The total energy d2Pkj emitted or scattered by volume dV k reaching dAj is: 
 d2Pkj = 4KtBkdVkCOSSjdAj/(4~Skj 2) (18) An intervening medium reduces the amount of energy reaching 
dAj, and introduces the transmittance ~: d2Pkj = ~(Sjk)KtBkdVkCOSSjdAj/(~Skj 2) (19) The total energy 
emitted from or scattered by a finite volume V k and arriving at a finite surface A. is found by integrating 
Eq. (19) over the entire 3 volume and the entire receiving surface. If the radiosity of the volume is 
taken as spatially uniform, a purely geometric factor arises. Analogous to the factor SiSj, the factor 
VkSj is defined as the total energy emitted from or scattered by V k that arrives at Aj, divided by the 
 radiosity of volume Vk, or: VkSJ = IVk;Aj ~(Sjk)KtdVkCOS%dAj/(~Skj2 ) (20)  / 0Aj / , ,;;, I g' 
I #-r~. ~1 / //Vm  ,._ _/St;, ) I / ~ ~ i. I e -" k L .~;J I Irk I I IVk ,... ,J I I i -j I / (b) 
u L / (c) surface; and (c) Between two volumes. A factor SjVk can be defined which is the total energy 
leaving surface j (of uniform radiosity Bj), which is either scattered or absorbed by volume k, divided 
by the radiosity 'of surface J. The reciprocity relationship SjVk = VkSj holds. 3.3 Volume Volume (VkVm) 
Factors -The geometry of two volumes exchanging energy is shown in Fig. 3c. The energy d2Pkm emitted 
from or scattered by volume dVk, and incident on volume dVm, after attenuation by an intervening medium, 
is: d2Pkm =T(Skm)Kt, k B k dV k cosO m dAm/(~Skm 2) (21) The fraction of this energy absorbed or scattered 
by dV m is Kt, m dx m. The energy scattered or emitted by dVk, which is absorbed or scattered by dVm, 
is given by: d2Pkm = ~(Skm)Kt,kBkdVkCOSG m dAmKt,mdXm/(KSkm 2) = ~(Skm)Kt,mKt,kBkdVkdV m /(mSkm 2) 
(22) The product cOS@mdAmdX m for the parallelepiped shown in Fig. 3c is equal to dV m. Any arbitrary 
 volume can be approximated by a set of such parallelepipeds. Thus, the amount of scattered or absorbed 
energy depends only on the volume of dVm, and not on its orientation. The total energy scattered by 
or emitted from a finite volume V k of uniform volume radiosity Bk, which is absorbed or scattered by 
a finite volume Vm, is found by integrating over the two volumes. Similar to the factors SiSj and VkSj, 
a factor VkVj appears which represents the total scattered and emitted energy leaving V k which is absorbed 
or scattered by volume Vj, divided by the radiosity Bk, or: VkVm = ~Vk~Vm ~(Skm)Kt,mKt,kdVkdVm/(nSkm 
2) (23)  (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 4. RADIOSITY EQUATIONS A set of simultaneous 
linear algebraic equations for the zonal method is derived in this section. This set couples the radiosities 
of surfaces and volumes, and can be formed by expressing the energy scattered or absorbed by each surface 
and volume in terms of the radiosities of the other surfaces and volumes in the environment. The total 
energy leaving a surface i is given by the product BiAi, where B i is the radiosity of the surface. 
B. consists of emitted and reflected I energy. The energy emitted by the area is EiA i. Energy incident 
on the surface comes partially from other surfaces and partially from other volumes in the environment. 
The energy incident on surface i from surface j is BjSjSi. The energy incident on surface i from volume 
k is BkVkS !. Therefore, a complete equation for the radiosity B. of a surface is: i BiA i = EiA i 
+ mi(E BjSjSi + E BkVkSi ) (24) where the first term represents the emitted energy, the remaining terms 
represent reflected energy, and ~i is the surface reflectance. The complete equation for the radiosity 
B k of a volume is: 4mtBkV k =4KaEkV k + Qk{E BjS~Vk + E BmVmVk } (25) On the left is the total energy 
emitted or scattered from a volume. The term 4KaEkV k is the emitted energy. The term QkBjSjVk is the 
energy leaving a surface A. which is scattered by the 3 volume V k. The energy emitted by or scattered 
from another volume m which is scattered by volume k is ~kBmVmVk. For a system of s surfaces and v 
volumes, equations of the form (24) for surfaces and (25) for volumes result in s+v simultaneous equations 
for the s+v radiosities in the environment. Both volume and surface radiosities appear. In general the 
equations are strongly coupled. The s+v equations represent an energy-conserving model of a lighting 
environment, and can be applied monochromatically or to discrete wavelength bands. 5. COMPUTATIONAL 
CONSIDERATIONS 5.1 Input Data - The geometry and properties of surfaces can be specified in the zonal 
method in the same way they are for the basic radiosity method. New data structures are required to store 
the attributes of volumes of participating media. A simple method is to define each volume containing 
a participating medium as a rectangular prism. Octree data structures used for accelerated ray tracing 
[3, 12] could also be used. For each volume of participating medium, E, Kt, and ~ must be specified. 
 5.2 Finding Factors - The zonal method can be implemented by calculating the factors SiS___~j, VkSj 
and VkVm using variations of the hemi-cube algorithm [2]. The algorithm calculates form factors by using 
a depth buffer to project surfaces onto a half cube. In the zonal method, reciprocity relations are used 
to reduce calculations. Surface to Surface Form Factors - The factor SiS i is given by Eq. (27). This 
is approximated by: SiSj = A i ~Aj r(sij)c°sOic°s@jdAj/(asij 2) (26) where it is assumed that the surfaces 
are sufficiently finely divided so that the integral is nearly constant over the surface A i. Equation 
(26) is further approximated by : SiS~ = AiZ p x(sij(p))cosOicOsOpdAp/(aSip2) (27) where the sum is 
over all of the hemi-cube grid cells p through which area A. is visible, as shown 2 in Fig. 4, and sij(P 
) is the distance from surface A i to the point on Aj which is visible through grid cell p. The terms 
in this summation, with the exception of the factor ~, are the same as for the basic hemi-cube algorithm. 
The value of needs to be approximated for each grid cell. For a medium completely filling the region 
between A i and Aj, as shown in Fig. 4a, with spatially uniform properties, x is given by: x(sij(P) 
) = exp{_K t /(x 2 + y2 + z2)} (28) where x, y, and z are the coordinates of a point on surface Aj as 
seen through grid cell p in a rectangular, undistorted, coordinate system based on surface A.. A transformation 
is made to a 1 perspective coordinate system in which: x' = x/z , y'= y/z , z' = = + 8/z (29) where 
~ and 8 are arbitrary constants. Equation (28) can be rewritten: x(sij(P))= exp{-(Kt(B/(z'-~))/(x'2+y'2+l)} 
(30) Let dp = /(x '2 + y,2 + 1). Thus, Eq. (27) becomes: SiSj = A i Ep exp(-(KtS/(z'-~))dp} [cosOicOSOpdAp/(~Sip2)] 
(31) In Eq. (31) the quantity dp and the quantity in square brackets are calculated once for each grid 
cell. As the factors for a particular surface A. are calculated, the depth buffer is consulted to determine 
z' for A. for each grid cell so that 3 can be calculated. Pseudo-code for calculating factors after 
the depth buffer is filled is: FOR each grid cell bt,(ffer [ocation p BEGIN IF object[p] ! = null BEGIN 
z = ~/(depth_bt(fferlPl-~); "r = e.xpl-Kt * z * dlp]);  (~) ~ Computer Graphics, Volume 21, Number 
4, July 1987 A1 lt Grid Cell v,, ,T" EPI($ Gell thrcuoh Nhlch Flct~t.~ous I .~f_ _ $ - - ~ Vlllhll to 
v k (a) (b) Figure 5 -Form factor determination (a) Volume to surface. (b) Volume to volume. the volume 
center to the value stored in the depth buffer. Once visibility is determined, the distance between the 
centers is calculated, both for use in the denominator in (33) and for calculating ~. (If many media 
are present the front buffer / back buffer method is repeatedly used to determine T.) 5.3 Calculatin 
G Radiosities After the geometric factors for an environment have been found, a system of equations for 
the radiosities of surfaces and volumes is formed using Eqs. (24) and (25). The equations are diagonally 
dominant, and the Gauss-Seidel iterative solution method can be used. 5.4 Rendering -The determination 
of the intensity of an individual pixel on the screen is diagrammed in Fig. 6. The intensity along the 
ray shown is determined by accounting for the attenuation, in-scattering and emission. It is assumed 
that there is no interference between light rays, The viewing intensity of each surface and volume along 
the path is determined separately and the results summed. In an environment composed of opaque surfaces, 
there is only one visible surface along each ray. The visible surfaces are determined using the depth 
buffer algorithm. The intensity contribution of the visible surface is its intensity (equal to its radiosity 
divided by n) attenuated by the value of along the ray from the surface to the eye. The value of x along 
the path is determined by the same front buffer/ back buffer method used to find "[ in the determination 
of geometric factors. ~ light 1,1If lec%~.nl liar f icl r "1 ---/ ~lntlnllty  "r /ooo.,.o, °"""""'°" 
' .o,. ~., / , o::t..°... I-I / I light Ply LrI~TL-IlCrlln iit¥ ¢onltlnt PiXel 1 eye ~ Figure 6 - Pixel 
intensity calculation. For the intensity contributions of volumes, it is necessary only to find the 
intensity leaving the front face of the volume when the volume is isolated, and then attenuate that intensity 
by the appropriate value of x. Consider a hypothetical light path through such an isolated volume V k 
of radiosity Bu, for a particular screen pixel, as shown in Fi~. 7. The points on the surface of the 
volume pierced by the rays passing through the centers of the pixels can be determined by finding the 
depths of the surfaces bounding the volume and storing the results in a front buffer and a back buffer. 
back pterco point front plorco point Figure 7 -Intensity calculation for an isolated volume. Once the 
path through the volume has been found using the front buffer/back buffer, the intensity Ik(X) is calculated 
using Eq. (13). For an isolated volume, I 0 is zero, J(t) is the radiosity B k divided by m, and t varies 
from O to Ktx. Equation (13) yields: Ik(X ) = exp(-Ktx) ~0 Kx (Bk(t)/n)exp(t) dt (34) B k is assumed 
to vary linearly along the path through the volume, and varies from some value Bkb at t = 0 to Bkf at 
t = Ktx. The values at the front and back of the volume are found by bilinear interpolation between discrete 
points on the surface of V k. The radiosities at the discrete points are found by averaging the radiosities 
of the surrounding volumes. The foregoing procedure reduces the visibility of spatial discretization 
of the participating medium. 6. ILLUSTRATIVE EXAMPLES Several images will be presented to illustrate 
the zonal method. The images in Figs. I, 8, 9, I0 and II were calculated using a Digital Equipment Corporation 
VAX 11/780, at a resolution of 400 x 400. Individual and composite images were displayed using 24 bit, 
1280 x 1024 resolution frame buffers-- a Raster Technologies Model One/380 and a Hewlett Packard 98720A. 
 The images shown in Fig. 12 were calculated at a resolution of 1000 x 1000 using a VAX 8700 and were 
displayed using the HP 9872OA frame buf[er. The environment displayed in Fig. 12 was discretized into 
1146 surfaces and 2744 volumes. Calculating geometric factors and solving for radiositles required approximately 
3 epu hours. Rendering each image required approximately 3 additional cpu hours.  ~ SIGGRAPH '87, Anaheim, 
July 27-31, 1987 6.1 Volume Interactions -Four images of a black-walled cubical enclosure are displayed 
in Fig. 8. The enclosure is filled with an absorbing/isotropically-scattering participating medium which 
is illuminated by a planar rectangular ideal diffuse white light source on the ceiling. A constant value 
of K t = (l/L) was used, where L is the length of one side of the enclosure. The upper and lower rows 
of images were computed using scattering albedoes of Q = 0.8 and ~ = 0.3 respectively. The zonal method 
was used to calculate the images on the left, and a single scatter approximation was used to obtain the 
images on the right. For a high scattering albedo, top row, volume/volume interactions are absent in 
the image on the right. Either the zonal method or Kajiya and Von Herzen's method can be used to obtain 
the correct image of the high albedo medium in the upper left. For the lower row of images for a low 
scattering albedo, volume/volume interactions can be ignored without affecting the final image. The zonal 
method and single scatter models are in close agreement. Either Kajiya and von Herzen's method or Max's 
version of Blinn's single scatter model can be used for correct images. 6.2 Surface/Volume Interactions 
- The presence of opaque surfaces in a participating medium may either increase the illumination of the 
medium when light is reflected from a surface into the medium, or it may decrease the illumination of 
the medium when the opaque surface lies between the medium and light sources. In addition, a dense participating 
medium can cast shadows, and alter the illumination of opaque surfaces. The effect of light reflected 
from an opaque surface is illustrated in Fig. 9, which shows the same enclosure displayed in Fig. 8, 
but with one of the walls given a non-zero reflectance. Values of K t = (I/L) and Q = 0.8 were used for 
all four images. The upper and lower rows of images correspond to enclosures with a red and a cyan wall, 
respectively. In the left column of images, the colored wall is to the left. In the right column, the 
view is through the colored wall. Clearly the presence of the reflecting wall affects the illumination 
of the participating medium, and the wall color bleeds into the medium. The shadowing effect of opaque 
objects in a participating medium is shown in Fig, I0. Two red blocks have been placed in the black walled 
enclosure. Values of .K t = (l/L) and Q = 0.7 were used. The blocks cast shadows on the medium. The 
shadowing effect of a medium on an opaque object is shown in Fig. II. A white planar rectangular light 
source illuminates a small dense cloud with high scattering albedo which casts a shadow (with penumbra) 
on an opaque green surface. The cloud was modeled by assigning values of of K t to each sub-volume. 
The K t values varied from (IO/L) at the center of the cloud to zero at the outer edge, where L represents 
the length of one edge of the green surface. A uniform value of Q = 0.8 was used. 6.3 Combined Interactions 
-Figures 1 and 12 display images in which surface/surface, surface/volume, and volume/volume interactions 
are all present. Constant values of K t = .7/L and Q =  0.95 were used to define the participating 
medium. The light source outside the windows simulate outdoor lighting, with a small intense distant 
light source and a distributed, weaker, hemispherical source. Figures 12a and 12b show the same environment 
(with the same illumination) from different viewing positions. Figure 12c shows the environment with 
the color and position of the source illumination changed. Figure 12d shows the environment with the 
light source embedded within the participating medium. Clearly the zonal method allows the subtle interactions 
between surfaces and volumes to be included, without restrictions on view point or the location of the 
light source. 7. CONCLUSIONS The zonal method for radiant transfer in participating media 15] has been 
applied to the generation of synthetic computer images. The method allows all volume/volume, volume/surface, 
and surface/surface interactions to be included for the case of isotropic participating media and diffuse 
reflecting surfaces. The method requires extensions of the hemi-cube algorithm to calculate form factors. 
 The zonal method is the first method to correctly render images of participating media for all possible 
values of the scattering albedo. Surface/volume interactions such as color bleeding and shadowing are 
included. The method is more complicated than the basic radiosity method, but generalizes that method. 
The zonal method is both view independent and view dependent. The view independence arises because for 
isotropic scattering radiosities can be calculated once. The view dependence arises because the total 
intensity leaving any point in the medium varies with direction. The total intensity must be calculated 
by path integration after the viewpoint is specified. The zonal method is a potentially very powerful 
method which warrants further development. Possible extensions of the present study include adaptive 
subdivision and substructuring of volumes, direetional volume and surface scattering, and the use of 
a hardware depth buffer. 8. ACKNOWLEDGMENTS This study is part of a continuing effort in the Program 
of Computer Graphics at Cornell University to develop physically-based lighting models. We are grateful 
to Prof. Donald Greenberg, Prof. Michael Cohen, Gary Meyer and John Wallace for helpful discussions and 
encouragement during this study. We acknowledge the support of the National Science Foundation under 
Grants DCR 8203979 and MEA 8401489, and support from the Digital Equipment Corporation via a research 
grant in computer graphics. The raster images were photographed by Emil Ghinger.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37437</article_id>
		<sort_key>303</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>35</seq_no>
		<title><![CDATA[A shading model for atmospheric scattering considering luminous intensity distribution of light sources]]></title>
		<page_from>303</page_from>
		<page_to>310</page_to>
		<doi_number>10.1145/37401.37437</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37437</url>
		<abstract>
			<par><![CDATA[Studio spotlights produce dazzling shafts of light, while light scattered from fog illuminated by automobile headlights renders driving difficult. This is because the particles in the illuminated volume become visible by scattering light. A shading model for scattering and absorption of light caused by particles in the atmosphere is proposed in this paper. The method takes into account luminous intensity distribution of light sources, shadows due to obstacles, and density of particles. The intensity at a viewpoint is calculated by integration of light scattered by particles between the viewpoint and a given point on an object. The regions to be treated in this manner are localized by considering illumination volumes and shadow volumes caused by obstacles in the illumination volumes.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP36042206</person_id>
				<author_profile_id><![CDATA[81100539710]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tomoyuki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nishita]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Fukuyama Univ., Hiroshima, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P304953</person_id>
				<author_profile_id><![CDATA[81100656738]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yasuhiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Miyawaki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hiroshima Univ., Hiroshima, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P75905</person_id>
				<author_profile_id><![CDATA[81100145250]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Eihachiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nakamae]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hiroshima Univ., Hiroshima, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>801127</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Warn, D.J.: Lighting Controls for Synthetic Images, Computer Graphics, Voi. 17, No.3 (1983) pp.13-21.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>282938</ref_obj_id>
				<ref_obj_pid>282918</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Nishita, T., Okamura,I. and Nakamae,E.: Shading Models for Point and Linear Sources, ACM Trans. on Graphics, Vol.4, No.2 (1986) pp.124-146]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Nishita, T. and Hakamae, E.: Half-Tone Representation of 3-D Objects Illuminated by Area Sources or Polyhedron Sources, IEEE, Proc. of COMPSAC (1983) pp.237-241.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325169</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Nishita, T. and Nakamae, E. : Continuous Tone Representation of Three-Dimensional Objects Illuminated by Sky Light, Computer Graphics, Voi,19, No. 3 (1986) pp.23-30.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801255</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F.: Light Reflection Functions for Simulation of Clouds and Dusty Surfaces, Computer Graphics, Voi. 16, No.3 (1982) pp.21- 29.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808594</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[KaJiya, J.T. and Von Herzen, B.P.: Ray Tracing Volume Densities, Computer Graphicsj Voi.18, No.S (1984) pp.165-174.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15899</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Max, ~, L.: Atmospherical Illumination and Shadows, Computer Graphics, Vol.20, No.4 (1986) pp.117-124.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[IES : IES Lighting Handbook Reference Volume, (1981) p.6-6.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Gibbons,M.G.: Radiation Received by Uncollimated Receiver from a 4~ Source, J. Opt. Soe. of America, Vol.~8, No.8 (1958) pp.550-555.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15909</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Nakamae, E., Harada,K,, Ishizaki,T, Nishita,T.: A Montage; The Overlaying of the Computer Generated Images onto a Background Photograph, Computer Graphics, Vol.20, No.3 (1986) pp.207- 214.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563901</ref_obj_id>
				<ref_obj_pid>965141</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Crow, F. : Shadow Algorithms for Computer Graphics, Computer Graphics, Voi.11, No.3 (1977) pp.242-248.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Nakamae, E. and Nishita, T. : An Hidden Line Elimination of Polyhedra, Information Processing in Japan, Voi~12 (1972) pp.134- 141.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325248</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Gardner, Y.G. : Visual Simulation of Clouds, Computer Graphics, Voi.19, No.3 (1985) pp.297-303.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 A SHADING MODEL FOR ATMOSPHERIC SCATTERING CONSIDERING 
LUMINOUS INTENSITY DISTRIBUTION OF LIGHT SOURCES Tomoyuki Nishita Fukuyama University Higashimura,Fukuyama 
Hiroshima 729-02, Japan Yasuhiro Miyawaki and Eihachiro Nakamae Hiroshima University Saijo, Higashi-Hiroshima 
Hiroshima 724, Japan Abstract Studio spotlights produce dazzling shafts of light, while light scattered 
from fog illuminated by automobile headlights renders driving difficult. This is because the particles 
in the illuminated volume become visible by scattering light. A shading model for scattering and absorption 
of light caused by particles in the atmosphere is proposed in this paper. The method takes into account 
luminous intensity distribution of light sources, shadows due to obstacles, and density of particles. 
The intensity at a viewpoint is calculated by integration of light scattered by particles between the 
viewpoint and a given point on an object. The regions to be treated in this manner are localized by considering 
illumination volumes and shadow volumes caused by obstacles in the illumination volumes. CR Categories 
and Subject Descriptions: 1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism: 1.3.3 [Computer 
Graphics]: Picture/Image Generation General Terms:Algorithm Additional Key Words and Phrases: shading, 
atmospheric scattering, luminous intensity characteristic, shadow volumes I. INTRODUCTION Many papers 
have been published which enhance the realism of calculated images by considering properties of objects, 
such as reflection, refraction, and transparency, and properties of light sources such as point sources, 
linear sources, area sources, polyhedron sources [I-3], and sky light [4]. In order to produce realistic 
images, the phenomena in the space between light sources and objects must also be considered; that Permi~ion 
~ copy without fee aU or part of th~ martial ~ granted prodded that the ~pi~ are n~ made or dmtdbuted 
~r d~e~ commercial advantage, the ACM copyright noti~ and the tkle of the pubfi~tion and ~ da~ appea~ 
and notice is Oven that ~pying ~ by permi~ion of the Associ~ion ~r Computing Machme~. To copy ~herwise, 
or ~ ~publish, requi~s a fee and/or specific perm~sion. 1987 ACM-0-89791-227-6/g7/007/0303 $00.75 is, 
the effect of atmospheric particles along the path of the light. Light scattered from particles such 
as water and dust in the air causes illuminated volumes to glow. In particular, understanding this effect 
makes it possible to simulate such real-world phenomena as: I) shafts of light caused by headlights of 
automobiles, street lamps, beacons, or searchlights at night (these effects are important for drivers), 
2) light beams caused by spotlights in studios and on stages, 3) shafts of light pouring through windows, 
and 4) visibility reduction of traffic signals or traffic signs in fog or haze. Representative of methods 
considering particles in the air is the fog effect in day time, commonly used in flight simulators. This 
method simply calculates attenuation as a function of depth from the viewpoint. Some light scattering 
models have been developed: Blinn first developed a method adapted to displaying Saturn's rings or cloud 
layers [5], but this method is limited to thin layers. Kajiya developed a method taking account of densities 
of particles [6]. Recently b~x made it possible to display light beams passing through gaps of clouds 
or trees [7]. In all these methods, however, light sources are limited to a simple, single parallel or 
isotropic source, ignoring the distribution of luminous intensity of the light source. In order to display 
illumination effects in fog, we must take into account the luminous intensity characteristics of actual 
light sources, in particular spotlights and headlights, and also must consider effects due to multiple 
light sources. This paper presents a method considering these factors. In this paper we use the following 
assumptions: I) light sources treated here are point sources with variable angular intensity distributions, 
and a parallel source. 2) the light from multiple scattering and the illumination onto objects due to 
scattering can be neglected. 3) objects treated here are composed of convex polyhedra. 2. CALCULATION 
FOR LIGHT SCATTERING Illuminated volumes in the air glow by light scattered from particles in the space, 
while light traversing the space is attenuated by absorption. These effects are modelled as follows: 
for scattering, particles are considered to be an infinite number of point sources; for attenuation, 
the atmosphere is supposed to be a semi-transparent  ~ SIGGRAPH '87, Anaheim, July 27-31, 1987 object. 
First, we discuss the effects of light scattering due to a point source whose angular range of illumination 
is limited (e.g. a spotlight). As shown in Fig. 1, the intensity of light reaching a viewpoint Pv from 
a point Pi on an object can be obtained by summing the reflected intensity, attenuated by traversing 
PiPv through the absorbing medium, with the intensity scattered in the direction of the viewpoint from 
each point along PiPv. The attenuation varies exponentially with distance (e.g., from a point on PiPv 
to Pv), as described by Bouguer's law (e.g., [8]). The total contribution from scattering is obtained 
by integrating over all points along PiPv . For example, at any point P on PiP v at distance s from Pv, 
the intensity scattered in the direction of the viewpoint is Ip(s), and will be attenuated by traversing 
distance s to the viewpoint. Thus, the intensity of light at the viewpoint is given by I = Iie-~(L)+ 
Ip(S)e-r(S)~d s (1) 0 where T(S) = odt (2) f 0 o is the extinction coefficient per unit length and 
depends on particle density (a function of positionl, ~(s) expresses the optical depth of PPv, and T(L) 
that of PiP v. Consider the direct illumination due to a point light source with luminous intensity 
I(0,~) (0 is the angle from illumination axis; ~ is the revolution angle; see Appendix), and uniform 
ambient light Ia, which is due to interreflection of light from objects' surfaces and to multiple scattering. 
The intensity of light reaching the point P from the light source is also attenuated due to absorption 
by particles and subject to the inverse square law of distance, Then Ip is given by the following equation. 
Ip(s) = ~1(0'$) w F(a) e "T(r)+ I a (3)r 2 Here w is the reflectance, r is the distance between the light 
source Q and the point P, ~(r) is the optical depth of PQ (see equation (2)), F(a) is the scattering 
phase function, and ~ is the angle between the forward scattering direction and the scattered ray (see 
Fig. l). The phase function is a function of particle radius, index of refraction, and wave length. The 
simplest example of the phase function is that for isotropic scattering, F(a) = constant. For extremely 
small particles such as molecules of the air~ Rayleigh scattering theory is used; F(~) : K(I+cosLa) (K 
is a constant). For relatively small particles such as fog, Mie scattering theory is used. Mie theory 
is very complicated, so this paper uses the following experimental approximation [9] for foggy atmosphere, 
 ~K(I+ 9coalS(a~2)) :hazy atmosphere F(a ): (4) K(1+50cosd*(a/2)) :murky atmosphere where K is a constant. 
 light source r ~ . PVpoin t Fig. I Intensity of light reaching a viewpoint from a point Pi on an object. 
 In equation (1), I i is the intensity of light arriving at point Pi on an object, and is also subject 
to attenuation due to the distance from the light source just as in equation (3) (i.e., I i depends on 
exp(-T(r))/r2). Calculation of illuminance due to point sources with variable angular intensity distributions 
is performed by the method given in Reference [2]. If the density of particles is uniform, equation (I) 
can be expressed as follows I=Iie-°L+Ia (1-e -aL) +jLwI (6,¢) e -°(r+s) F(~)/r2ods ~ -0 (51 In applying 
this equation, the following properties should be noted: a) The third term refers to the shaft of light. 
Thus, if the light ray doesn't pass through an illuminated volume, the intensity is given by the first 
two terms. b) Even for uniform density, we may consider many types of luminous intensity distributions, 
therefore numerical integration is useful because of the difficulty of obtaining an analytical solution. 
 c) Outdoors, during the day, I a corresponds to the intensity of the atmosphere at infinite distance, 
that is, the first two terms of equation (51 arc equivalent to the equation for fog effect [10]. d) 
For multiple light sources, the total intensity is obtained by summing up the intensities yielded by 
equation (5) for each light source. e) In the case of a parallel source, ~ of equation (3) becomes: 
 Ip(s) = wroF(a) e-~(r)+ ia (61 where ~ is the intensity of light and r(r) the optical depth from the 
reference plane (e.g., a   (~ ~' Computer Graphics, Volume 21, Number 4, July 1987 Q light source 
~./il  lumination ~. ~ Pvs ;hadow v o i ume Fig. 2 Calculation of scattered light using illumination 
and shadow volumes. window plane for a shaft of light pouring through a window). 3- ILLUMINATION VOLUMES 
AND INTEGRATION SEGMENTS Light sources treated here are point sources with variable angular intensity 
distributions, and parallel sources. In order to minimize the application of equation (I) (requiring 
a lengthy calculation), illumination volumes are localized by the following principles: (I) For point 
sources, directions of radiation are limited by reflectors and lenses. (2) For axisymmetric luminous 
distributions, the illumination volume is defined as a circular cone whose vertex is the light center, 
and whose central axis coincides with the illumination axis (see Fig.2). (3) For non- axisymmetrie luminous 
intensity distributions such as headlights, the illumination volume is an elliptical cone. (4) For a 
parallel light source entering through a window, the illumination volume is a prism of which the base 
is the window and the base is swept in the direction of light (see Fig. 3). Shadows on particles in 
the atmosphere are as important as those on the surfaces of objects; when there are objects in an illumination 
volume, non-illuminated parts arise within it. In order to detect shadows on objects, we use shadow 
volumes [11] defined by the light source and the contour lines of each polyhedron as viewed from the 
light source [2]. These shadow volumes are also used for detecting shadows in the atmosphere. The shadows 
on each particle along the llne between the viewpoint and a point on an object (hereafter called the 
ray) can be obtained by using the ray tracing algorithm (in this case, the ray tracing algorithm is applied 
for each sampling point on the ray). However, this is very time-consuming and gives rise to sampling 
errors. The following method is more efficient and accurate. The shadow segments on the ray are obtained 
by using intersection points between the wi ndo w # /I Fig. 3 Illumination volume for a parallel 
source. ray and both illumination volumes and shadow volumes, which are pre-oalculated before intensity 
calculation at each pixel. No allasing problems caused by shadow calculation arise because shadow regions 
are accurately calculated. The segments in which scattered light must be calculated (e.g., SlS 2 and 
sBs 4 in Fig.2) are extracted by the following processes. The following preproeessing is executed: i) 
Extract illumination volumes for each light source. ii) Extract polyhedra intersecting illumination volumes. 
iii) Extract shadow volumes formed by the light sources and those polyhedra. Then the following steps 
are executed for each pixel on every scan line. iv) Extract illumination volumes intersecting the ray, 
and calculate the intersection points. If there is no intersection, no calculation is required for scattered 
light. v) Calculate the intersections between the ray and all shadow volumes within each illumination 
volume. vi) Extract illuminated segments on the ray. (These segments are visible from the light source.) 
 vii) Integrate intensities of the scattered light on the illuminated segments of the ray. In step ii), 
all polyhedra are given a spherical bounding volume, and the polyhedra intersecting illumination volumes 
are extracted using these bounding spheres. Steps i), ii) and iii) need not be recalculated if the viewpoint 
is changed, as they are independent of the viewpoint. They are also used for detection of shadows on 
faces. For steps iv) and v), in order to calculate intersections between the ray and illumination and 
shadow volumes efficiently, the regions visible ~ SIGGRAPH'87,Anaheim,July 27-31, 1987 I~®~1 Q light 
source i~-~'. illumination~ vo,ume shado~., I:.':'::<'\  /.:;:!~ shado~., I:.':'::<' ~"~ SCreeil Fig. 
4 Pre-caleulation of intersections between the ray and shadow and illumination volumes on the screen. 
 from the screen are pre-calculated; the contour lines of shadow and illumination volumes viewed from 
the viewpoint are projected onto the screen as shown in Fig. 4. Since the projected contour lines are 
convex polygons, they can be extracted by means of polygon scan conversion. Then the illumination and 
shadow volumes intersecting with the ray are easily obtained. In this way, the regions in which scattered 
light is calculated are localized (see dotted parts in Fig. 4). When the light source is a point source, 
the illumination volume projects onto the screen as a triangle whose vertex is the projected light center. 
The projected shadow volume is a polygon (see shaded area in Fig. 4) bounded by a triangle with vertex 
at the projected light center. The shadow volumes intersecting the ray can be extracted efficiently by 
means of these bounding triangles. When an illumination volume includes the viewpoint, the illumination 
volume can't be projected onto the screen, and the intersection test must be executed in 3-D space, even 
though computation time increases. The extraction of integration segments (i.e., the visible parts when 
viewed from a light source) in step vi) is perfomed by using the notion of $1 quantitative invisibility, 
as in hidden line elimination [12]. For example, in Fig. 5, as we traverse the ray from Pu to Pi, the 
quantitative invisibility is incremented each time the ray enters a shadow volume (Sz, s3, and se in 
Fig.5), and decremented when it leaves (s4 and s5). Segments for which quantitative invisibility is zero 
are visible (sis2 and SsS6 in Fig.5). 4. DENSITY DISTRIBUTION OF PARTICLES In many cases, the effect 
of spotlights in studio or stage lighting is intensified by using dry Ace. Dry ice, smoke, dust, and 
fog or haze exhibit non-uniform particle densities. We discuss calculation of scattered light under such 
conditions. In a dense volume, the extinction of light increases due to the increased optical depths 
both from the light source to a particle and from the particle to the viewpoint. On the other hand, because 
the intensity of scattered light also increases, dense volumes in most cases are bright. In order to 
calculate the intensity at the viewpoint Pu due to scattered light from a point P on the ray, we must 
know the luminous intensity of light source Q in the direction of P, the particle density at P, and the 
optical depths of QP and PPu. Therefore, to take into account the distribution of density, we establish 
a model for density distribution and a method for calculating optical depths: I) Modelling of density 
distribution In this paper, we do not consider arbitrary density distributions over the whole space, 
but rather the simpler case in which certain regions of the atmosphere are occupied by smoke or fog of 
uniform density. One researcher has represented volume density using a 3-D grid, with numerical densities 
for each element [6], but this method requires a great deal of memory. We use a model in which the boundaries 
of layers of different densities are represented by curved surfaces. For a foggy medium due to dry ice, 
the difference of densities between the fog and the atmosphere is large, and because the fog is heavy, 
 light source source llumination viewpoint J ] ation (, -~ / volume Fig. 5 Extraction of integration 
segments for Fig. 6 Calculation of optical depths from the light scattered light. source to a particle 
and from the particle (a view from the light source) to the viewpoint.    O ~ Computer Graphics, 
Volume 21, Number 4, July 1987 obtained efficiently by using their projected contour lines. The shadow 
segments on the ray are extracted using the hidden line technique, with the ray viewed from the light 
source. Acknowledgements The authors wish to thank Bonnie Sullivan for carefully reading and commenting 
on this paper.  REFERENCES 1) Warn, D.J.: Lighting Controls for Synthetic Images, Computer Graphics, 
Voi. 17, No.3 (1983) pp.13-21. 2) Nishita, T., Okamura,I. and Nakamae,E.: Shading Models for Point and 
Linear Sources, ACM Trans. on Graphics, Vol.4, No.2 (1986) pp.124-146 3) Nishita, T. and Hakamae, E.: 
Half-Tone Representation of 3-D Objects Illuminated by Area Sources or Polyhedron Sources, IEEE, Proc. 
of COMPSAC (1983) pp.237-241. 4) Nishita, T. and Nakamae, E. : Continuous Tone Representation of Three-Dimensional 
Objects Illuminated by Sky Light, Computer Graphics, Voi,19, No. 3 (1986) pp.23-30. 5) Blinn, J. F.: 
Light Reflection Functions for Simulation of Clouds and Dusty Surfaces, Computer Graphics, Voi. 16, 
No.3 (1982) pp.21- 29. 6) KaJiya, J.T. and Von Herzen, B.P.: Ray Tracing Volume Densities, Computer 
Graphicsj Voi.18, No.S (1984) pp.165-174. 7) Max, ~, L.: Atmospherical Illumination and Shadows, Computer 
Graphics, Vol.20, No.4 (1986) pp.117-124. 8) IES : IES Lighting Handbook Reference Volume, (1981) p.6-6. 
 9) Gibbons,M.G.: Radiation Received by Uncollimated Receiver from a 4~ Source, J. Opt. Soe. of America, 
Vol.~8, No.8 (1958) pp.550-555. 10) Nakamae, E., Harada,K,, Ishizaki,T, Nishita,T.: A Montage; The Overlaying 
of the Computer Generated Images onto a Background Photograph, Computer Graphics, Vol.20, No.3 (1986) 
pp.207- 214. 11) Crow, F. : Shadow Algorithms for Computer Graphics, Computer Graphics, Voi.11, No.3 
(1977) pp.242-248. 12) Nakamae, E. and Nishita, T. : An Hidden Line Elimination of Polyhedra, Information 
Processing in Japan, Voi°12 (1972) pp.134- 141. 13) Gardner, Y.G. : Visual Simulation of Clouds, Computer 
Graphics, Voi.19, No.3 (1985) pp.297-303.  Fig. 8 Illustration of angles for non-axisymmetric luminous 
intensity. APPENDIX Calculation of Luminous Intensity Characteristics I) Axisymmetric distribution 
of luminous intensity In this case the intensity can be expressed by a function of angle 0 from the 
illumination axis (see Fig. 8). In most cases the distribution curves of the intensity can be expressed 
as a polynominal of cose. Here we consider the sharpness of the illuminated edge. In order to control 
the illumination range, the expression l(e)= Io(cose) c has been proposed [1] (For this expression, the 
illumination range decreases as c increases). However, because sharp edges cannot be produced, and because 
of the computational expense of the exponent in the cosine term, this function is not well suited to 
modelling spotlights. Therefore we propose the following function for spotlights: I(e) : I0{ (1-q)(cose-cosy)/(1-cos¥) 
+ q }, (7)  where I0 is the luminous intensity at e=0, ~ is the beam spread, and q is a parameter which 
controls the sharpness of the edge (q=1: very sharp, q=0: very soft) (see Fig. 2 for 7). 2) Non-axisymmetric 
distribution of luminous intensity In this case the luminous intensity is expressed by I(~,~), where 
¢ is the revolution angle from the reference plane which includes the illumination axis (refer to Fig. 
8). In the figure the light center is Qe, the reference point is Q0, Qc is a point on the illumination 
axis, and P is an arbitrary point. Then cos~ can be obtained by the inner product of the normal vectors 
of triangles, QeQcQ0 and QeP Qc. First we discuss luminous intensity expressed by functions. For example, 
luminous intensities for the daisy shape and for polka dots like those produced by a mirror ball in a 
disco are calculated as follows. In these sources, the intensity I(e,$) ~ SIGGRAPH '87, Anaheim, July 
27-31, 1987 can be expressed as the product of I(e) of equation (7) and the following function k(¢). 
 k(@) = max{ p+(1-p)[2mod(@,A¢)-n¢)]/~¢, 0 } (8) where the symbol "mod" means modulo, A@ and p (p<1) 
are the period of luminous intensity and the ratio of the minimum intensity to the maximum intensity, 
respectively: When p is small (including negative), the radius of the polka-dots becomes small. For the 
daisy shape, the distribution of luminous intensity is given by I(e,~) = Z(e)k(~,) . (9) 2 ~ 0 . 2' 
4 , 6 0 8 o .......... .~. .,.~ o o , ,~ u For the polka-dot pattern, the luminous intensity can be 
obtained by adding the variation in the ~ direction to equation (9). That is, I(e,¢) = "r(e3k(¢3k(e)v 
, (103 where v=mod([@/A~]+[e/A0],2) (i.e., v=O or v=l): v is used to decrease the number of polka dots. 
For arbitrary distributions, numerical luminous intensity data should be used, for example, every 5 degrees 
on e and ¢. Intervening luminous intensities are calculated by linear interpolation. For headlights, 
however, more detailed data, for example every 2 degrees, are necessary because of the radical change 
of intensities (see Fig. 93. z '4-b-~-.!.U" 12 ~ 14 ° 16 °I,8 ° 20 ° 22 ° FAg. 9 Distribution curve 
of luminous intensity for a headlight.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>37438</article_id>
		<sort_key>311</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1987</article_publication_date>
		<seq_no>36</seq_no>
		<title><![CDATA[A two-pass solution to the rendering equation: A synthesis of ray tracing and radiosity methods]]></title>
		<page_from>311</page_from>
		<page_to>320</page_to>
		<doi_number>10.1145/37401.37438</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=37438</url>
		<abstract>
			<par><![CDATA[View-independent and view-dependent image synthesis techniques, represented by radiosity and ray tracing, respectively, are discussed. View-dependent techniques are found to have advantages for calculating the specular component of illumination and view-independent techniques for the diffuse component. Based on these observations a methodology is presented for simulating global illumination within complex environments using a two-pass approach. The first pass is view-independent and is based on the hemi-cube radiosity algorithm, with extensions to include the effects of diffuse transmission, and specular to diffuse reflection and transmission. The second pass is view-dependent and is based on an alternative to distributed ray tracing in which a z-buffer algorithm is used to sample the intensities contributing to the specularly reflected or transmitted intensity.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P146446</person_id>
				<author_profile_id><![CDATA[81414601063]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Wallace]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell Univ., Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77026366</person_id>
				<author_profile_id><![CDATA[81406592138]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Cohen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell Univ., Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P68459</person_id>
				<author_profile_id><![CDATA[81100196982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Greenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell Univ., Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>808589</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Amanatides, John, "Ray Tracing with Cones," Proceedings of SIGGRAPH'84, In ComPuter Graphics, Vol. 18, No. 3, July 1984, pp. 129-136.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Arvo, James, "Backward Ray Tracing," Developments in Ray Tracing, SIGGRAPH Course Notes, Vol. 12, 1986.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15889</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bergmann, Larry, Henry Fuchs, Eric Grant, Susan Spach, "Image Rendering by Adaptive Refinement," Proceedings of SIGGRAPB'86, In Computer Graphics, Vol. 20, No, 4, Aug. 1986, pp. 29-38.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Blinn, James F.,"Models of Light Reflection for Computer Synthesized pictures," Proceedings of SIGGRAPH'77, In Computer Graphics, Vol. ll, No. 2, 1977, pp. 192-198.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F. and Donald P. Greenherg, "A Radiosity Solution for Complex Environments," Proceedings of SIGGRAPH'85, In Computer Graphics, Vol. 19, No. 3, July 1985, pp. 31-40.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., Donald P. Greenberg, David S. Immel, Philip J. Brock, "An Efficient Radiosity Approach for Realistic Image Synthesis," IEEE Computer Graphics and Applications, Vol. 6, No. 2, March 1986, pp. 26-35.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357293</ref_obj_id>
				<ref_obj_pid>357290</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., and Kenneth E. Torrance, "A Reflection Model for Computer Graphics," ACM Transactions on Graphics, Vol. I, No. i, January 1982, pp. 7-24.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., Thomas Porter and Loren Carpenter, "Distributed Ray Tracing," Proceedings of SIGGRAPH'84, In Computer Graphics, Vol. 18, No. 3, July 1984, pp.137-145.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., "Stochastic Sampling in Computer Graphics," ACM Transactions on Graphics, Vol. 5, No. I, January 1986, pp 51-72.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325182</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Dippe, Mark A. Z., Erling Henry Wold, "Antialiasing Through Stochastic Sampling," Proceedings of SIGGRAPH'85, In Computer Graphics, Vol 19, No. 3, July 1985, pp. 69-78.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Dunkle, R. V., "Radiant interchange in an enclosure with specular surfaces and enclosures with window or diathermanous walls.", in Heat Transfer, Thermodynamics and Education, edited by H.A. Johnson, Boelter Anniversary Volume, New York: McGraw-Hill, 1964.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Eckert, E. R. G., and Sparrow, E. M., "Radiative Heat Exchange Between Surfaces with Specular Reflection," International Journal of Hea___{t and Mass Transfer, Vol. 3, pp. 42-54, 1961.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Goral, Cindy M., Kenneth E. Torrance, Donald P. Greenburg, Bennet Battaile, "Modeling the Interaction of Light Between Diffuse Surfaces," Proceedings of SIGGRAPH'84, In Computer Graphics, Vol. 18, No. 3, July 1984, pp. 213-222.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Gouraud, H., "Continuous Shading of Curved Surfaces," IEEE Transactions on Computers, Vol. 20, No. 6, June 1971, pp. 623-628.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Hall, Roy A. and Donald P. Greenberg, "A Testbed for Realistic Image Synthesis," IEEE Computer Graphics and Applications, Vol. 3, No. I0, Nov. 1983, pp. 10-20.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808588</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Heckbert, Paul S. and Pat Hanrahan, "Beam Tracing Polygonal Objects," Proceedings of SIGGRAPH'84, In Computer Graphics, Vol. 18, No. 3, July 1984, pp. 119-128.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Immel, David S., Michael F. Cohen, Donald P. Greenberg, "A Radiosity Method for Non-Diffuse Environments," Proceedings of SIGGRAPH'86, In Computer Graphics, Vol. 20, No. 4, Aug. 1986, pp. 133-142.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Kajiya, James T., "The Rendering Equation," Proceedings of SIGGRAPH'86, In Computer Graphics, Vol. 20, No. 4, Aug. 1986, pp. 143-150.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325169</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Nishita, Tomoyuki and Eihachiro Nakamae, "Continuous Tone Representation of Three-Dimensional Objects Taking Account of Shadows and Interreflection," Proceedings of SIGGRAPH'85, In Computer Graphics, Vol. 19, No.3, July 1985, pp. 22-30.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Yhong, Bui Tuong, "Illumination for Computer Generated Pictures," Communications of the ACM, Vol. 18, No. 6, June 1975, pp. 311-317.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Rushmeier, Holly E., "Extending the Radiosity Method to Transmitting and Specularly Reflecting Surfaces," Master's thesis, Cornell Univ., Ithaca, 1986.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Siegel, Robert and John R. Howell, Thermal Radiation Heat Transfer, Hemisphere Publishing Corp., Washington DC., 1981.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15896</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Swanson, Roger W. and Larry J. Thayer, "A Fast Shaded-Polygon Renderer," Proceedings of SIGGRAPH'86, In Computer Graphics, Vol. 20, No. 4, Aug. 1986, pp. 95-102.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Whitted, Turner, "An Improved Illumination Model for Shaded Display," Communications of the ACM, Vol. 23, No. 6, June 1980, pp. 343-349.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 (~ ~ Computer Graphics, Volume 21, Number 4, July 1987 A TWO-PASS SOLUTION TO THE RENDERING EQUATION: 
A SYNTHESIS OF RAY TRACING AND RADIOSITY METHODS John R. Wallace, Michael F. Cohen, Donald P. Greenberg 
Cornell University Ithaca, N. Y. 14853 AB S~,AC'I' View-independent and view-dependent image synthesis 
techniques, represented by radiosity and ray tracing, respectively, are discussed. 7Jew-dependent techniques 
are found to have advantages for calculating the specular component of illumination and view-independent 
techniques for the diffuse component. Based on these observations a methodology is presented for simulating 
global illumination within complex environments using a two-pass approach. The first pass is view-independent 
and is based on the hemi-cube radiosity algorithm, with extensions to include the effects of diffuse 
transmission, and specular to diffuse reflection and transmission. The second pass is view-dependent 
and is based on an alternative to distributed ray tracing in which a z-buffer algorithm is used to sample 
the intensities contributing to the specularly reflected or transmitted intensity. CR Categories and 
Subject Descriptors: 1.3.3 [Computer Graphics]: Picture/Image Generation; 1.3.7 [Computer graphics]: 
Three-Dimensional Graphics and Realism General Terms: Algorithms Additional Key Words and Phrases: radiosity, 
distributed ray tracing, z-buffer, global illumination, view-dependence, vlew-independence. 1.0 INTRODUCTION 
 The creation of realistic images for a raster display requires the calculation of the intensity of light 
leaving visible surfaces in the direction of the observer through each pixel of the image plane. Early 
methods for calculating this intensity accounted only for the direct illumination of surfaces by light 
sources [14][20]. The subsequent evolution of illumination models has Permission to copy without fee 
all or part of this material is granted provided that the copies are not made or distributed for direct 
commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. &#38;#169; 1987 ACM-0-89791-227-6/87/007/0311 
$00.75 provided increasingly sophisticated methods of accounting for global illumination, which includes 
the effect of all objects in the environment. Algorithms to compute global illumination may be characterized 
by their approach to selecting the sample points within the environment and the directions for which 
the final intensity is calculated. For view-dependent algorithms these sample points and directions are 
determined by the view position and by the discretization of the image plane. View-independent algorithms, 
on the other hand, calculate the illumination of all surfaces for a set of discrete environment locations 
and directions determined by criteria that are independent of view. A two-pass method is presented in 
this paper that overcomes disadvantages o£ previous methods by computing the global diffuse component 
of illumination during a vlew-independent preprocess and the global specular component during a view-dependent 
postprocess. Recently, in separate papers, Kajiya [18] and Immel et al [17] presented essentially the 
same equation to completely describe the intensity of light leaving a surface in a given direction in 
terms of the global illumination within an environment. However, each paper described radically different 
approaches to the equation's solution. Kajiya extended view-dependent ray tracing [24][8] to include 
global diffuse illumination, which ray tracing had previously not accounted for correctly. Immel extended 
the view-independent approach taken by the radiosity method [13][5][19] to include directional reflection, 
eliminating the restriction of purely diffuse environments. Although both approaches ultimately converge 
to the same solution, they illustrate the complementary advantages and disadvantages of solving the problem 
entirely on a view-dependent or view-independent basis. Kajiya and Immel each described a complete illumination 
equation based on earlier work in radiative heat-transfer [22]: Iout(eou t) = E(0ou t ) + [ P"(8out,Gin) 
Iin(Oin) cos(0) dm (i) J~ where lou t = the outgoing intensity for the surface 3ll  ~ SIGGRAPH '87, 
Anaheim, July 27-31, 1987 Iin = an intensity arriving at the surface from the rest of the environment 
E = outgoing intensity due to emission by the surface 8ou t = the outgoing direction ®in = the incoming 
direction Q = the sphere of incoming directions O = the angle between the incoming direction Oin and 
the surface normal d~ = the differential solid angle through which the incoming intensity arrives p" 
= the bidirectional reflectance/transmittance of the surface The outgoing intensity, I ut' leaving a 
dlfferentlal area of a surface in a given direction Oou t is the sum of the light emitted by the surface 
in that direction, E(Oout), plus any light arriving at the surface which is then reflected or transmitted 
in that direction The reflected intensity depends on light arriving at the surface from all directions 
above the surface and the transmitted intensity depends on light arriving from all directions below the 
surface. Hence the integration is over the entire sphere of incoming directions. The bidirectional reflectance 
-transmittance p"(O ,0 ) represents the physical rl ou~ ~n reriectlon propertles of the surface and 
is expressed as the ratio of the reflected or transmitted intensity in the outgoing direction ®out to 
energy arriving from the incoming direction Oin. All quantities are also dependent on wavelength; assuming 
no energy exchange between wavelength bands, independent equations of the same form can be written for 
each wavelength band. 2.0 DIFFUSE RAY TRACING AND SPECULAR RADIOSITY Kajiya describes an algorithm 
that solves equation (i) using an efficient approach to stochastic ray tracing [8] in which many rays 
are shot per pixel with each ray generating only one path through the environment. Since light sources 
seen by a surface typically make a very large contribution to the reflected intensity, one ray is also 
sent towards a light source for every ray shot stochastically at the rest of the environment. These modifications, 
along with other variance reduction techniques described in the same paper, allow sufficient incoming 
directions to be sampled by ray tracing to evaluate the outgoing intensity for diffuse reflection, thus 
successfully reproducing phenomena previously only modeled by radiosity methods. Like its ray tracing 
antecedents, Kajiya's method is view-dependent, being restricted to those rays that ultimately reach 
the eye. This is enforced by tracing rays backwards from the eye, through the pixels of the image plane 
and into the environment. Thus, for a given point on a surface visible to the viewer, the intensity need 
only be determined for one outgoing direction. The directional nature of the bidirectional reflectivity 
function then provides an efficient basis for selecting the important directions in which to sample the 
incoming intensities. In other words, the incoming intensities may be sampled at a higher frequency in 
the direction of the specular peak (Fig. la). For ideal diffuse reflection, however, the bidirectional 
reflectivity is independent of the outgoing direction; thus the view direction does not provide a basis 
for "importance sampling". To reduce the amount of sampling required, techniques may be used that take 
advantage of knowledge gained as sampling progresses. However a large number of directions may still 
have to be sampled, particularly when the assumption that lights are the most significant sources of 
illumination does not hold. Such cases may occur, for example, when a diffuse surface is entirely in 
shadow or when light reflected from a specular surface contributes significantly to the illumination 
of a diffuse surface (Fig. ib). In addition, the pixel by pixel determination of intensity imposed by 
ray tracing from the eye may result in the performance of more work than necessary since the illumination 
of a diffuse surface as perceived by the viewer typically changes relatively slowly from one pixel to 
the next. By contrast, in the radiosity approach all calculations are view-independent. The standard 
radiosity method treats only diffuse surfaces. The set of sample points for which the intensities are 
calculated depends on the discretization of the environment surfaces rather than the viewpoint and image 
resolution (Fig. Id). This greatly reduces the number of sample points compared to the number of pixels 
in the final image. For surfaces with high intensity gradients, which occur at shadow boundaries, for 
example, a uniform surface discretization does not sufffce. However, the distribution of these sample 
points for a given surface may be adaptively determined by the gradient of intensity over the surface 
[6]. Immel expanded the view-independent radiosity approach to include specular reflection. The relationship 
between a surface patch and all the other patches in the environment becomes, in Immel's approach, a 
relationship between a given outgoing reflection direction for a patch and all outgoing directions for 
all other patches. A simultaneous solution of the resulting system of equations gives an intensity in 
each direction for each patch. Unfortunately, for specular surfaces the intensity as seen by the viewer 
typically changes very quickly from pixel to pixel. Therefore a view-independent solution may require 
that specular surfaces be subdivided to the point where each patch covers approximately one pixel in 
the final view. Although Immel's approach would eventually converge to an accurate solution as the discretization 
of the environment increased, the computation and space required to solve the resulting system of simultaneous 
equations precludes subdivision to the required level. As a result, artifacts appear when specular surfaces 
are rendered, since the correct intensity is known only at relatively widely spaced sample points (Fig. 
ic). 2.1 A TWO COMPONENT MODEL OF THE TRANSFER OF LIGHT ENERGY A reasonable approach to solving the 
global illumination problem is to divide it in a manner that allows the solution to take advantage of 
the strengths of both view-dependent and view-independent sampling.   (~) ~ Computer Graphics, Volume 
21, Number 4, July 1987 > eve eyt-   \//o.o .,-o ege plurle  /" / / \C',', \,. ",\ salnp le points 
 Figure la. View dependent calculation of specular component: The intensity calculation is limited to 
the outgoing directions that reach the eye. Incoming intensities may then be sampled at a higher frequency 
in the direction of the specular peak. The outgoing intensity on the floor will be calculated at points 
corresponding to each pixel, thus capturing the reflection of the table's edge to the accuracy required 
by the view. eye ~ light sample points Figure lb. View dependent caleulation of diffuse component: 
For diffuse reflection the contribution of incoming intensities to the outgoing intensity is independent 
of the outgoing direction. If the light source is not visible to the sample point, many incoming directions 
may have to be sampled, since the significant sources of illumination may be difficult to find. This 
will be repeated for each pixel in which the floor is visible. Local light reflection models for computer 
graphics traditionally separate the scattering o£ light from a surface into two components, a non-directional 
or diffuse term and a directional or specular term [20][4][7]. This corresponds to approximating the 
bidirectional reflectance function in equation (1) as the sum of a diffuse portion, Pc' which is independent 
of viewpoint, and a specular portion, Ps, which depends on the view direction. Thus, p,,(eout,el, ) = 
ks%(eout,ein) + kap a where k = fraction of reflectance that is specular S k d = fraction of reflectance 
that is diffuse k s + k d = 1 Equation (i) can then be rewritten as Iout(eout) = E(eo.t) + Id,ou t 
+ I .... t(eout ) (2a) widely spaced sample points Figure lc. View independent calculation of specular 
component: All outgoing directions must be accounted for, hence there is no preferred incoming direction. 
The outgoing intensity used when rendering from a specific view is the result of weighting the equally 
spaced incoming samples. The intensity at point A will be determined by interpolating from the widely 
spaced sample points. Thus the reflection of the edge of the table will not be accurately captured. 
~. eye ------T-----~ '', / ~, light "mage plane ," ", "', 21 % po.nuNSra / / closely spaced sample 
po±nts sample points Figure id. View independent calculation of diffuse component: Many incoming directions 
are sampled for each sample point with their contributions weighted according to Lambert's cosine law. 
The sample points are spaced according to the gradient of illumination. The intensity at point A will 
be determined by interpolating from the surrounding sample points. where Id,ou t = kd0df lin(Oin ) COS(0) 
dm (2b) I .... t (®out) = k~ %(eo.t,ein) Iin<ein) cos(e) d~ (2c) The outgoing diffuse and specular 
terms each depend on all incoming intensities I, . Since these zn incoming intensities are, in fact, 
just outgoing intensities from other surfaces, they in turn contain both diffuse and specular components 
Thus, it is not theoretically correct to solve for the diffuse and specular components independently, 
precluding a simple superposition of ray tracing and standard radiosity solutions, (although such an 
approach may be acceptable in many cases). Since the standard radiosity solution considers only diffuse 
inter-reflection, the illumination of a diffuse surface by light reflected specularly from another surface 
will not be accounted for and the subsequent effect of this light on the global illumination will be 
lost. The superposition of ray tracing will not recover it, since ray tracing  t~ SIGGRAPH '87, Anaheim, 
July 27-31, 1987   + % + + \ % (a) (b) (c) (d) Figure 2. The four "mechanisms" of light transport: 
(a) diffuse to diffuse, (b) specular to diffuse, (c) diffuse to specular and (d) specular to specular. 
 does not consider the illumination of diffuse surfaces by other surfaces at all. Given the separation 
of P" into Pd and 9 , the transfer of light from one surface to another can be thought of as occurring 
by way of four "mechanisms". These are illustrated in Figure 2. Light reflected diffusely by one surface 
may have arrived at that surface via diffuse reflection (Fig. 2a) or specular reflection (Fig. 2b) from 
another surface. Similarly, light reflected specularly may also have arrived via diffuse reflection (Fig. 
2c) or specular reflection (Fig. 2d) from the other surface. The first two mechanisms are expressed by 
equation (2b) and the latter two by equation (2c). The diffuse to diffuse transfer is handled by the 
standard radiosity algorithms. Specular to specular and diffuse to specular transfer are handled by standard 
ray tracing algorithms, although the diffuse component is not correctly modeled. Neither approach in 
its conventional form has handled the specular to diffuse transfer, although other approaches, such as 
backwards ray tracing [2], beam tracing [16] and the methods of Kajiya and Immel described above, have 
been presented to account for this transfer mechanism. The backwards ray tracing method described by 
Afro, in particular, anticipates the two-pass nature of the approach described below. 3.0 TI/0-PASS 
IMAGE SYNTHESIS The two-pass approach for computing global illumination described in the following sections 
accounts for all four mechanisms of light transfer. In a view-independent stage of the algorithm, called 
the preprocess, the complete global propagation of light is approximated in order to determine the diffuse 
component of intensity for all surfaces (Eq. 2b). All four transfer mechanisms are included in the preprocesm. 
Thus specular reflection must be accounted for, but only to the extent necessary to accurately calculate 
the diffuse component. A view-dependent stage of the algorithm, called the postprocess, then uses the 
results of the preprocess as the basis for calculating the specular component (Eq. 2c) to the accuracy 
required by the view. The postprocess accounts for the specular to specular and diffuse to specular transfer 
mechanisms, in the latter case using the diffuse component calculated during the preprocess as the source. 
For each pixel in the final image, the resulting specular component is added to the diffuse component, 
interpolated from the preprocess sample points, providing a complete solution to equation (2a).  3.1 
THE PREPROCESS The standard radiosity solution using the hemi-cube algorithm provides the basis for the 
preprocess [5]. (Details of the radiosity method are not included here. The hemi-cube algorithm is a 
geometrically based numerical integration technique for calculating form-factors, which are purely geometric 
terms describing the transfer of energy from one surface to another.) Since the standard radiosity method 
accounts only for diffuse reflection, extensions to the hemi-cube algorithm must be made to add diffuse 
transmission and to approximate specular reflection and specular transmission in so far as it effects 
the diffuse component for all surfaces. 3.11 Translucency Ideal diffuse transmission (translucency) 
is readily included by placing a hemi-cube on the back, as well as the front, of the transmitting surface 
and calculating backward in addition to the usual forward form-factors [11][21]. The backward form-factors 
represent the effect that light from surfaces seen by the back of the translucent surface has on the 
intensity of the front of the translucent surface.  3.12 Specular to Diffuse Transport Specular reflection 
or transmission may also be accounted for in the standard radiosity solution by performing additional 
work during the calculation of form-factors [12]. The form-factor, it will be recalled, represents the 
fraction of the total energy leaving a given diffuse surface patch that arrives at a second diffuse surface 
patch. Specular surfaces are treated as additional routes by which light energy may reach one diffuse 
surface from others (Fig. 3). Thus, two diffuse surfaces that "see" each other via specular reflection 
or transmission by intermediate surfaces have an extra form-factor representing the additional fraction 
of energy that will be transfered over this route. The additional form-factors may be calculated by any 
method that can determine the path of specular reflection or transmission. The radiosity solution proceeds 
as before by solving the system of equations describing the interrelationships between  ~ Computer 
Graphics, Volume 21, Number 4, July 1987 / L  virtual world real world Figure 3. Calculation of extra 
form-factors to account for mirror reflection. Patch A receives light directly from patch B and indirectly 
through reflection by the mirror. The mirror is treated as a window into a virtual "mirror world." Projecting 
patch B' onto the hemicuhe is then equivalent to following the actual path of reflection back to patch 
B. diffuse surfaces, with specular reflection included implicitly to the extent that it affects these 
interrelationsh ips. This accounts for the intensity of the diffuse component due to the diffuse to 
specular, specular to specular, and specular to diffuse transfer mechanisms without explicitly calculating 
the specular component for any surface. In the current implementation, this technique is restricted 
to perfect, planar mirrors or filters. This allows the additional form-factors to be calculated with 
the current z-buffer hemi-cube algorithm by creating a "virtual world" which is seen through the mirror 
or filter [21] (Fig. 3). The approach may be generalized to handle curved surfaces and refraction by 
using ray tracing to determine the form-factors. 3.13 Result of the Preprocess The final result of the 
preprocess is an accurate determination of the diffuse intensity at selected sample points (the element 
vertices) within the environment. Although some of these sample points may end up being hidden from a 
particular viewpoint, the number of sample points required is typically much less than the number that 
would have been imposed by a pixel to pixel calculation (although this would not necessarily be the case 
for environments with a very large number of surfaces). The hemi-cube algorithm, in effect, determines 
the incoming intensities at each sample point for a number of directions determined by the hemi-cube 
resolution. The effective number of directions is in the tens of thousands for typical hemi-eube resolutions. 
In a sense, the effort that would have been required to determine the diffuse component at every plxel 
in a view-dependent approach is applied instead to more accurately determining the illumination at a 
smaller number of points. 3.2 THE POSTPROCESS The postprocess takes the results of the preprocess and, 
for a given view, completes the solution of the illumination equation for the surface visible at each 
pixel. The view-dependence of the postprocess permits the efficient calculation of the specular component 
I (®o -) (Eq 2b) by S,OUE ~ " limiting the direction for whic~ it must be calculated to the view direction. 
As in previous radiosity methods, the diffuse component I; .. is calculated by interpolation from the 
elemen~°~rtex intensities determined during the preprocess. The sum Id,ou t ~ I s out(~ ut) completes 
the solution to the integral " ' v xn equatlon (I) and, with the addition of intensity due to emission, 
provides the final intensity at each pixel. The specular component I -(® .) depends on the ..... S 
ou~ u~  lntensltles arrlvlng at t~e surface from the entire hemisphere of directions, weighted by the 
specular bidirectional reflectance ps(Oin,O ut). Distrib-uted ray tracing [8] and "cone tracing" [I] 
were the first algorithms for sampling these incoming intensities. The method presented in this section 
is based on the observation that in most specular reflection, the bidirectional reflectance is such that 
only a fraction of the incoming intensities over the hemisphere make a significant contribution to the 
outgoing intensity in a particular direction. Thus, with little loss of accuracy, the limits of integration 
may be reduced from the entire hemisphere to the smaller solid angle over which the weighted intensity 
is significant. The determination of the incoming intensities requires that the visible surfaces and 
intensities be found over the solid angle of interest~ a problem that is precisely equivalent to that 
of computing an image from the surface intersection point with a view in the mirror direction.  "t"x\l~//3 
SIGGRAPH '87, Anaheim, July 27-31 1987 region included by frustum  outgoing reflection direction frustum 
 0 K ~~ ,12 (a) (b)  Figure 4. (a) A specular bidirectional reflectivity function for a particular 
outgoing direction showing the reflection frustum and the solid angle through which incoming intensities 
will be sampled. (b) A two-dimensional slice through the reflectivity function of figure 4a plotted 
in rectangular coordinates with incoming angle on the axis and reflectlvity on the y axis. The weight 
that will he given to incoming intensities is proportional to the value of this function at the incoming 
angle. 3.21 The Reflection Frustum A view frustum encompassing this solid angle is constructed (Fig. 
4). The visible surfaces for this reflection frustum are determined using a standard low resolution z-buflfer 
algorithm (typically on the order of I0 by i0 "pixels"). The incoming intensity "seen" through each "pixel" 
of this frustum is simply the intensity of the surface visible at that pixel (Fig. 5). This intensity 
may contain both diffuse an~ specular components. The incoming diffuse component at each reflection frustum 
pixel is determined during the z-buffer operation by Gouraud shading from the element vertex intensities 
calculated during the preprocess. Vhere a surface visible in a reflection frustum pixel has a specular 
component, its intensity is calculated by applying the entire postprocess algorithm recursively, analogously 
to the similar case in traditional ray-tracing. The work required for this recursive step may be reduced 
by adaptively limiting the depth of reeursion [15] and by reducing the resolution of the frustum for 
successive bounces. Once the incoming intensities have been determined, the integral in equation (2c) 
can be numerically evaluated. The subdivision of the reflection frustum into pixels acts as a dlscretization 
of the domain of integration. The integral thus becomes the summation: I .... e ks ~ ~w~,j Iin(Si, j) 
cos(el, j) 6~oi, i i=oj=o  where the bidirectional reflectance function is represented by W i' an array 
of weights, and n is the resolution of~'fhe reflection frustum. Each weight in the array corresponds 
to the incoming direction Oi, j determined by the "pixel" (i,j) of / / / z / /, ./ / , application 
of algorithm outgoing directioo reflection point  Figure 5. Sampling of the intensities arriving through 
the reflection frustum using the z-buffer algorithm. The incoming diffuse component due to element B 
at each "pixel" is obtained by inter- polating from the diffuse intensities at the element vertices. 
The incoming specular component is obtained recursively. the reflection frustum and is proportional 
to the bidirectional reflectance for the view direction and the incoming direction determined by that 
"pixel". The array of weights can be pre-computed as a look-up table for a simple Phong-like reflectance 
function at a given reflection frustum resolution, making the approximation that the variation of cos(O)A~ 
over the frustum is small and can be ignored. Various surface finishes can be simulated by simply varying 
the size of the frustum; the smaller the frustum, the more mirror-like the reflection. More complex 
physically based reflection models may require more elaborate look-up tables or require the weights to 
be computed on the fly based on reflection angle, frustum size and resolution. 3.22 Transparency Specular 
transmission, including refraction, is accounted for analogously to reflection by defining a bidirectional 
transmittance and constructing a transmission frustum in the transmitted direction. 3.23 Antialiasing 
 Inevitably, a uniform point sampling method will produce aliasing in one form or another. Figur e 6a 
provides an example of aliasing produced by the regular point sampling of the incoming intensities through 
the reflection frustum. The uniform sampling produces a striped or plaid effect due to an alignment of 
the sampling pattern with the projection of object edges in the environment. A small shift in the reflection 
frustum may result in a sudden jump in the number of reflection frustum "plxels" covered by the object. 
Selecting sample points stochastically rather than uniformly, as imposed by the regular grid of "pixels", 
may eliminate aliasing by converting it to noise [9][10]. However, this also eliminates the speed  ~ 
SIGGRAPH '87, Anaheim, July 27-31, 1987 Figures 10a, b and c show an environment for which the illumination 
of diffuse surfaces by specular reflection (via the specular to diffuse transfer mechanism) is significant. 
Several versions of the image have been calculated to emphasize the effects of various levels of sophistication 
provided by the preprocess. Overall illumination of the room is provided by a dim area source on the 
ceiling. The reflection in the mirror in each case was calculated during the postprocess. In Figure IOa 
only the direct illumination of surfaces by the light sources is accounted for, hence surfaces facing 
away from lights or in shadow are black. In Figure lOb the full radiosity solution has been applied but 
the effect of the specular reflection from the mirror on the illumination of diffuse surfaces has been 
ignored. In Figure foe this specular to diffuse transfer has been accounted for using the mirror form-factor 
technique. The illumination of the top of the vanity along with the objects on it results primarily from 
light emitted by the lamp on the vanity and subsequently reflected by the mirror. The environment is 
subdivided into 4224 elements, providing only 5379 sample points for which the diffuse component was 
calculated. This is a significantly smaller number than the number of pixels at which an entirely view-dependent 
calculation would have calculated the diffuse component. The hemi-eube resolution during the preprocess 
was 150 by 150. The specular component of the mirror was calculated with a frustum of 0.032 radians. 
Figure ii shows an environment inspired by a well-known painting, "Lady and Gentleman at the Virginals", 
by the 17th century Dutch painter Jan Vermeer. Vermeer is particularly known for his use of light to 
define space, based, at least in part, on a sensitivity to the effects of what we would now call "global 
illumination", effects such as penumbra and "color bleeding", for example. For the image in Figure lla 
the floor was treated as an ideal diffuse reflector. As far as is known, the floor of his studio never 
attained the high sheen demonstrated in Figure 11b. The hemi-cube resolution for the preprocess was 50 
by 50 for both images. The resolution of the reflection frustum was 10 by I0 for the floor in Figure 
llb, with a reflection frustum size of 0.079 radians. All images were calculated on DEC VAX 11/750, 
11/780, 8300 or 8700 computers and displayed using 1280 by 1024 24-bit frame buffers from Raster Technologies 
or Hewlett-Packard. 5.0 CONCLUSION AND FUTURE DIRECTIONS A hybrid, two-pass methodology for simulating 
global illumination within general complex environments has been presented. The approach takes advantage 
of the complementary strengths of view-dependent and view-independent methods. The view independent preproeess, 
based on the radiosity method, provides an efficient computation of the diffuse component. The view-dependent 
postprocess, based on ray tracing, efficiently calculates the specular component. By taking advantage 
of the best features of each a complete simulation is achieved. The standard radlosity algorithms are 
also extended to handle curved surfaces and diffuse transmission and to account for the contribution 
of specular reflection to the illumination of diffuse surfaces. An alternative to distributed ray tracing 
is described in which the specular component is determined by a regular sampling of intensities contributing 
to the reflected intensity using a z-buffer algorithm. Both the preprocess and the postprocess require 
the performance of a very large number of independent visible surface calculations. These are necessary 
during the preprocess to calculate the form-factors and during the postprocess to determine incoming 
intensities contributing to the specular component. In fact, the total computation time in both processes 
is overwhelmingly dominated by these calculations. The choice of the standard z-buffer algorithm was 
motivated in part by recent advances in the implementation of such algorithms in special-purpose hardware 
[23]. The use of such hardware to perform the z-buffer portions of the hemi-cube algorithm and the distributed 
ray tracing algorithm described above promises dramatic increases in the speed of both the preprocess 
and the postprocess. In addition, with increased processing speed, aliasing problems may be reduced by 
increasing the resolution of the reflection frusta. Future implementations should increase the generality 
of the preprocess by including ray tracing to calculate reflected and refracted form-factors where necessary. 
Future implementations should also provide for cases where the gradient of the diffuse intensity is extremely 
high, such as along sharp shadow boundaries. Just as with the specular component, the attempt to solve 
for these cases in an entirely view independent manner is inefficient. Regions of high diffuse gradient 
may instead be merely identified in the preprocess and solved for in the postprocess on a pixel by pixel 
basis. The two-pass approach presented here is more general than the particular implementation described. 
Many alternative pre and post processes may be imagined. Conventional distributed ray tracing, for example, 
could be substituted for the z-buffer algorithm in the postprocess. Path tracing, as Kajiya named his 
approach, might use the approximate description of the propagation of light gained during the preprocess 
as a basis for importance sampling. The two-pass approach also provides a framework for the progressive 
refinement of images, in the spirit of the approach described by Bergman, et al [3]. Using currently 
available hardware the pre-computed diffuse component provided by the preprocess may be rendered at interactive 
rates, enabling "walk-throughs" of static environments. ~hen the viewer lingers at a certain view, refinement 
of the shading of visible surfaces by the postprocess may commence.  ~ SIGGRAPH '87, Anaheim, July 
27-31, 1987 ACKNOWLEDGMENTS The z-buffer distributed ray tracing algorithm is based on ideas developed 
by Michael Cohen and Lisa Maynes. Particular thanks go to Holly Rushmeier for many valuable discussions, 
to Stewart Feldman and Wayne Lytle for the diagrams, to Emil Ghinger for photography, and to the reviewers 
for their helpful comments, This research was conducted under grant No. DCR-8203979 from the National 
 Science Foundation and was supported by generous equipment grants from the Digital Equipment Corporation 
and Hewlett-Packard. REFERENCES I. Amanatides, John, "Ray Tracing with Cones," Proceedings of SIGGRAPH'84, 
In ComPuter Graphics, Vol. 18, No. 3, July 1984, pp. 129-136. 2. Arvo, James, "Backward Ray Tracing," 
Developments in Ray Tracing, SIGGRAPH Course Notes, Vol. 12, 1986.  3. Bergmann, Larry, Henry Fuchs, 
Eric Grant, Susan Spach, "Image Rendering by Adaptive Refinement," Proceedings of SIGGRAPB'86, In Computer 
Graphics, Vol. 20, No, 4, Aug. 1986, pp. 29-38.  4. Blinn, James F.,"Models of Light Reflection for 
Computer Synthesized pictures," Proceedings of SIGGRAPH'77, In Computer Graphics, Vol. ll, No. 2, 1977, 
pp. 192-198.  5. Cohen, Michael F. and Donald P. Greenherg, "A Radiosity Solution for Complex Environments," 
Proceedings of SIGGRAPH'85, In Computer Graphics, Vol. 19, No. 3, July 1985, pp. 31-40.  6. Cohen, Michael 
F., Donald P. Greenberg, David S. Immel, Philip J. Brock, "An Efficient Radiosity Approach for Realistic 
Image Synthesis," IEEE Computer Graphics and Applications, Vol. 6, No. 2, March 1986, pp. 26-35.  7. 
Cook, Robert L., and Kenneth E. Torrance, "A Reflection Model for Computer Graphics," ACM Transactions 
on Graphics, Vol. I, No. i, January 1982, pp. 7-24.  8. Cook, Robert L., Thomas Porter and Loren Carpenter, 
"Distributed Ray Tracing," Proceedings of SIGGRAPH'84, In Computer Graphics, Vol. 18, No. 3, July 1984, 
pp.137-145.  9. Cook, Robert L., "Stochastic Sampling in Computer Graphics," ACM Transactions on Graphics, 
Vol. 5, No. I, January 1986, pp 51-72.  I0. Dippe, Mark A. Z., Erling Henry Wold, "Antialiasing Through 
Stochastic Sampling," Proceedings of SIGGRAPH'85, In Computer Graphics, Vol 19, No. 3, July 1985, pp. 
69-78. 11. Dunkle, R. V., "Radiant interchange in an enclosure with specular surfaces and enclosures 
with window or diathermanous walls.", in Heat Transfer, Thermodynamics and Education, edited by H.A. 
Johnson, Boelter Anniversary Volume, New York: McGraw-Hill, 1964. 12. Eckert, E. R. G., and Sparrow, 
E. M., "Radiative Heat Exchange Between Surfaces with Specular Reflection," International Journal of 
Hea___[t and Mass Transfer, Vol. 3, pp. 42-54, 1961.  13. Goral, Cindy M., Kenneth E. Torrance, Donald 
P. Greenburg, Bennet Battaile, "Modeling the Interaction of Light Between Diffuse Surfaces," Proceedings 
of SIGGRAPH'84, In Computer Graphics, Vol. 18, No. 3, July 1984, pp. 213-222.  14. Gouraud, H., "Continuous 
Shading of Curved Surfaces," IEEE Transactions on Computers, Vol. 20, No. 6, June 1971, pp. 623-628. 
 15. Hall, Roy A. and Donald P. Greenberg, "A Testbed for Realistic Image Synthesis," IEEE Computer 
Graphics and Applications, Vol. 3, No. I0, Nov. 1983, pp. 10-20.  16. Heckbert, Paul S. and Pat Hanrahan, 
"Beam  Tracing Polygonal Objects," Proceedings of SIGGRAPH'84, In Computer Graphics, Vol. 18, No. 3, 
July 1984, pp. 119-128. 17. Immel, David S., Michael F. Cohen, Donald P. Greenberg, "A Radiosity Method 
for Non-Diffuse Environments," Proceedings of SIGGRAPH'86, In Computer Graphics, Vol. 20, No. 4, Aug. 
1986, pp. 133-142. 18. Kajiya, James T., "The Rendering Equation," Proceedings of SIGGRAPH'86, In Computer 
Graphics, Vol. 20, No. 4, Aug. 1986, pp. 143-150.  19. Nishita, Tomoyuki and Eihachiro Nakamae, "Continuous 
Tone Representation of Three-Dimensional Objects Taking Account of Shadows and Interreflection," Proceedings 
of SIGGRAPH'85, In Computer Graphics, Vol. 19, No.3, July 1985, pp. 22-30.  20. Yhong, Bui Tuong, "Illumination 
for Computer Generated Pictures," Communications of the ACM, Vol. 18, No. 6, June 1975, pp. 311-317. 
 21. Rushmeier, Holly E., "Extending the Radiosity Method to Transmitting and Specularly Reflecting 
Surfaces," Master's thesis, Cornell Univ., Ithaca, 1986.  22. Siegel, Robert and John R. Howell, Thermal 
Radiation Heat Transfer, Hemisphere Publishing Corp., Washington DC., 1981.  23. Swanson, Roger W. and 
Larry J. Thayer, "A Fast Shaded-Polygon Renderer," Proceedings of SIGGRAPH'86, In Computer Graphics, 
Vol. 20, No. 4, Aug. 1986, pp. 95-102.  24. Whitted, Turner, "An Improved Illumination Model for Shaded 
Display," Communications of the ACM, Vol. 23, No. 6, June 1980, pp. 343-349.     
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1987</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
</content>
</proceeding>

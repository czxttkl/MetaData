<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>07/31/2005</start_date>
		<end_date>08/04/2005</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[Los Angeles]]></city>
		<state>California</state>
		<country></country>
	</conference_loc>
	<conference_url></conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES382</series_id>
		<series_title><![CDATA[International Conference on Computer Graphics and Interactive Techniques]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>1198555</proc_id>
	<acronym>SIGGRAPH '05</acronym>
	<proc_desc>ACM SIGGRAPH 2005 Courses</proc_desc>
	<conference_number>2005</conference_number>
	<proc_class>conference</proc_class>
	<proc_title></proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>2005</copyright_year>
	<publication_date>07-31-2005</publication_date>
	<pages>7157</pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<abstract>
		<par><![CDATA[Learn how to master the latest digital theories and expert practices in the art and science of computer graphics. In quick tutorials, half-day sessions, and full-day courses, academic and industry specialists teach topics that deepen understanding, encourage exploration, and immediately enhance real-world skills.]]></par>
	</abstract>
	<publisher>
		<publisher_id>PUB27</publisher_id>
		<publisher_code>ACMNY</publisher_code>
		<publisher_name>ACM</publisher_name>
		<publisher_address>2 Penn Plaza, Suite 701</publisher_address>
		<publisher_city>New York</publisher_city>
		<publisher_state>NY</publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>10121-0701</publisher_zip_code>
		<publisher_contact>Bernard Rous</publisher_contact>
		<publisher_phone>212 869-7440</publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url>www.acm.org/publications</publisher_url>
	</publisher>
	<sponsor_rec>
		<sponsor>
			<sponsor_id>SP932</sponsor_id>
			<sponsor_name>ACM Special Interest Group on Computer Graphics and Interactive Techniques</sponsor_name>
			<sponsor_abbr>SIGGRAPH</sponsor_abbr>
		</sponsor>
	</sponsor_rec>
	<categories>
		<primary_category>
			<cat_node/>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
	<chair_editor>
		<ch_ed>
			<person_id>PP39094176</person_id>
			<author_profile_id><![CDATA[81339499981]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>1</seq_no>
			<first_name><![CDATA[John]]></first_name>
			<middle_name><![CDATA[]]></middle_name>
			<last_name><![CDATA[Fujii]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[Hewlett-Packard Company]]></affiliation>
			<role><![CDATA[Editor]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
	</chair_editor>
</proceeding_rec>
<content>
	<section>
		<section_id>1198556</section_id>
		<sort_key>1</sort_key>
		<section_seq_no>1</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Anyone can make quality animated films! (the eight basic steps to success)]]></section_title>
		<section_page_from>1</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>P837802</person_id>
				<author_profile_id><![CDATA[81322508457]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Eric]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Van Hamersveld]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>PP36033847</person_id>
				<author_profile_id><![CDATA[81322495133]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bob]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hanon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198557</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Anyone can make quality animated films!]]></title>
		<subtitle><![CDATA[the 8 basic steps to success]]></subtitle>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198557</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198557</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P837803</person_id>
				<author_profile_id><![CDATA[81322508457]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Eric]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[van Hamersveld]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Art Institute of California-San Diego]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36034289</person_id>
				<author_profile_id><![CDATA[81322495133]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bob]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hanon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Art Institute of California-San Diego]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36034512</person_id>
				<author_profile_id><![CDATA[81322501532]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Debra]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Miller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Art Institute of California-San Diego]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA["Producing Animation" by Catherine Winder & Zahra Dowlatabadi]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA["Producing Independent 2D Character Animation" by Mark Simon]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA["3D Short Film Production" by Jeremy Cantor & Pepe Valencia]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA["Story" by Robert McKee]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA["The Writer's Journey" by Christopher Vogler]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA["Screenwriting" by Ray Frensham]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA["Making a Good Script Great" by Linda Seger]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA["The Tools of Screenwriting" by David Howard and Edward Mabley]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA["How to Sell Your Screenplay" by Lydia Wilen and Joan Wilen]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA["Aristotle's Poetic's for Screenwriters" by Michael Tierno]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA["The Perfect Pitch" by Ken Rotcop]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA["The Art of Voice Acting" by James Alburger]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA["Animation Writing and Development" by Jean Wright]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA["The Art of Storyboard" by Don Bluth]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA["Exploring Storyboarding" by Wendy Tumminello]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA["Acting in Animation" by Ed Hooks]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA["Disney Animation - The Illusion of Life" by Frank Thomas & Ollie Johnson]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA["The Animator's Survival Kit" by Richard Williams]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA["The Animator's Workbook" by Tony White]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA["The Complete Animation Course" by Chris Patmore]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA["Cartoon Animation" by Preston Blair]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA["How to Draw Animation" by Christopher Hart]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA["Creating 3D Animation" by Peter Lord & Brian Sibley]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA["The Animator's Reference Book" by Les Pardew & Ross Wolfley]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA["From Word to Image" by Marcie Begleiter]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA["Graphic Storytelling and Visual Narrative" by Will Eisner]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA["Figure Drawing for All It's Worth" by Andrew Loomis]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198558</section_id>
		<sort_key>2</sort_key>
		<section_seq_no>2</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Introduction to articulated rigid body dynamics]]></section_title>
		<section_page_from>2</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP35035662</person_id>
				<author_profile_id><![CDATA[81100421152]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sunil]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hadap]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>PP24044546</person_id>
				<author_profile_id><![CDATA[81322498148]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Vangelis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kokkevis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198559</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Introduction to articulated rigid body dynamics]]></title>
		<subtitle><![CDATA[Copyright restrictions prevent ACM from providing the full text for this work.]]></subtitle>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198559</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198559</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35035651</person_id>
				<author_profile_id><![CDATA[81100421152]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sunil]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hadap]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24033326</person_id>
				<author_profile_id><![CDATA[81322498148]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Vangelis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kokkevis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	</section>
	<section>
		<section_id>1198560</section_id>
		<sort_key>3</sort_key>
		<section_seq_no>3</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Computational photography]]></section_title>
		<section_page_from>3</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP40022814</person_id>
				<author_profile_id><![CDATA[81100022847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ramesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Raskar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>P130685</person_id>
				<author_profile_id><![CDATA[81100216430]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jack]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tumblin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198561</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Computational photography]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198561</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198561</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40022814</person_id>
				<author_profile_id><![CDATA[81100022847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ramesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Raskar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P130685</person_id>
				<author_profile_id><![CDATA[81100216430]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jack]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tumblin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Northwestern University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198562</article_id>
		<sort_key>2</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Non-photorealistic camera]]></title>
		<subtitle><![CDATA[depth edge detection and stylized rendering using multi-flash imaging]]></subtitle>
		<page_from>2</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198562</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198562</url>
		<abstract>
			<par><![CDATA[We present a non-photorealistic rendering approach to capture and convey shape features of real-world scenes. We use a camera with multiple flashes that are strategically positioned to cast shadows along depth discontinuities in the scene. The projective-geometric relationship of the camera-flash setup is then exploited to detect depth discontinuities and distinguish them from intensity edges due to material discontinuities.We introduce depiction methods that utilize the detected edge features to generate stylized static and animated images. We can highlight the detected features, suppress unnecessary details or combine features from multiple images. The resulting images more clearly convey the 3D structure of the imaged scenes.We take a very different approach to capturing geometric features of a scene than traditional approaches that require reconstructing a 3D model. This results in a method that is both surprisingly simple and computationally efficient. The entire hardware/software setup can conceivably be packaged into a self-contained device no larger than existing digital cameras.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[depth edges]]></kw>
			<kw><![CDATA[image enhancement]]></kw>
			<kw><![CDATA[non-photorealistic rendering]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40022814</person_id>
				<author_profile_id><![CDATA[81100022847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ramesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Raskar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs (MERL)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P404590</person_id>
				<author_profile_id><![CDATA[81100316291]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kar-Han]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs (MERL)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P641605</person_id>
				<author_profile_id><![CDATA[81100636887]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Rogerio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Feris]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[UC Santa Barbara]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P544093</person_id>
				<author_profile_id><![CDATA[81100472930]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jingyi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MIT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40027489</person_id>
				<author_profile_id><![CDATA[81100457810]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Matthew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Turk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[UC Santa Barbara]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1081490</ref_obj_id>
				<ref_obj_pid>1081432</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Akers, D., Losasso, F., Klingner, J., Agrawala, M., Rick, J., and Hanrahan, P. 2003. Conveying Shape and Features with Image-Based Relighting. In IEEE Visualization.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Avenue Amy, 2002. Curious Pictures.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>930983</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Birchfield, S. 1999. Depth and Motion Discontinuities. PhD thesis, Stanford University.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882298</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Chuang, Y.-Y., Goldman, D. B., Curless, B., Salesin, D. H., and Szeliski, R. 2003. Shadow matting and compositing. ACM Trans. Graph. 22, 3, 494--500.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cohen, M. F., Colburn, A., and Drucker, S. 2003. Image stacks. Tech. Rep. MSR-TR-2003-40, Microsoft Research.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>794713</ref_obj_id>
				<ref_obj_pid>794191</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Daum, M., and Dudek, G. 1998. On 3-D Surface Reconstruction using Shape from Shadows. In CVPR, 461--468.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566650</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[DeCarlo, D., and Santella, A. 2002. Stylization and Abstraction of Photographs. In Proc. Siggraph 02, ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882354</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[DeCarlo, D., Finkelstein, A., Rusinkiewicz, S., and Santella, A. 2003. Suggestive contours for conveying shape. ACM Trans. Graph. 22, 3, 848--855.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>508550</ref_obj_id>
				<ref_obj_pid>508530</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Durand, F. 2002. An Invitation to Discuss Computer Depiction. In Proceedings of NPAR 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>339094</ref_obj_id>
				<ref_obj_pid>339084</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Elder, J. 1999. Are Edges Incomplete?. International Journal of Computer Vision 34, 2/3, 97--122.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566573</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Fattal, R., Lischinski, D., and Werman, M. 2002. Gradient Domain High Dynamic Range Compression. In Proceedings of SIGGRAPH 2002, ACM SIGGRAPH, 249--256.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033045</ref_obj_id>
				<ref_obj_pid>1032641</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Feris, R., Turk, M., Raskar, R., Tan, K., and Ohashi, G. 2004. Exploiting Depth Discontinuities for Vision-based Fingerspelling Recognition. In IEEE Workshop on Real-time Vision for Human-Computer Interaction (in conjunction with CVPR'04).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>580035</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Forsyth, and Ponce. 2002. Computer Vision, A Modern Approach.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>648739</ref_obj_id>
				<ref_obj_pid>645305</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Geiger, D., Ladendorf, B., and Yuille, A. L. 1992. Occlusions and Binocular Stereo. In European Conference on Computer Vision, 425--433.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>558817</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Gooch, B., and Gooch, A. 2001. Non-Photorealistic Rendering. A K Peters, Ltd., Natick.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280951</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Hertzmann, A. 1998. Painterly Rendering with Curved Brush Strokes of Multiple Sizes. In ACM SIGGRAPH, 453--460.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>46073</ref_obj_id>
				<ref_obj_pid>46072</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Huertas, A., and Nevatia, R. 1988. Detecting buildings in aerial images. Computer Vision, Graphics and Image Processing 41, 2, 131--152.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Huggins, P., Chen, H., Belhumeur, P., and Zucker, S. 2001. Finding Folds: On the Appearance and Identification of Occlusion. In IEEE CVPR, vol. 2, 718--725.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Irvin, R., and McKeown, D. 1989. Methods for exploiting the relationship between buildings and their shadows in aerial imagery. IEEE Transactions on Systems, Man and Cybernetics 19, 6, 1564--1575.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>508538</ref_obj_id>
				<ref_obj_pid>508530</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Johnston, S. F. 2002. Lumo: Illumination for cel animation. In Proceedings of NPAR, ACM Press, 45--52.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Kang, S. B., Szeliski, R., and Chai, J. 2001. Handling occlusions in dense multi-view stereo. In IEEE CVPR, vol. 1, 102--110.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Kriegman, D., and Belhumeur, P. 2001. What Shadows Reveal About Object Structure. Journal of the Optical Society of America, 1804--1813.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Langer, M., Dudek, G., and Zucker, S. 1995. Space Occupancy using Multiple Shadow Images. International Conference on Intelligent Robots and Systems, 390--396.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>307299</ref_obj_id>
				<ref_obj_pid>307388</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Lin, C., and Nevatia, R. 1998. Building detection and description from a single intensity image. Computer Vision and Image Understanding: CVIU 72, 2, 101--121.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Papademetris, X., and Belhumeur, P. N. 1996. Estimation of motion boundary location and optical flow using dynamic programming. In Proc. Int. Conf. on Image Processing.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>148286</ref_obj_id>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Press, W. H., Teukolsky, S., Vetterling, W. T., and Flannery, B. P. 1992. Numerical Recipes in C: The Art of Scientific Computing. Pearson Education.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>987671</ref_obj_id>
				<ref_obj_pid>987657</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., Ilie, A., and Yu, J. 2004. Image Fusion for Context Enhancement and Video Surrealism. In Proceedings of NPAR.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Raviv, D., Pao, Y., and Loparo, K. A. 1989. Reconstruction of Three-dimensional Surfaces from Two-dimensional Binary Images. In IEEE Transactions on Robotics and Automation, vol. 5(5), 701--710.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97901</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Saito, T., and Takahashi, T. 1990. Comprehensible Rendering of 3-D Shapes. In ACM SIGGRAPH, 197--206.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Sato, I., Sato, Y., and Ikeuchi, K. 2001. Stability issues in recovering illumination distribution from brightness in shadows. IEEE Conf. on CVPR, 400--407.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Savarese, S., Rushmeier, H., Bernardini, F., and Perona, P. 2001. Shadow Carving. In ICCV.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>598475</ref_obj_id>
				<ref_obj_pid>598429</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Scharstein, D., and Szeliski, R. 2002. A taxonomy and evaluation of dense two-frame stereo correspondence algorithms. In International Journal of Computer Vision, vol. 47(1), 7--42.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Shirai, Y., and Tsuji, S. 1972. Extraction of the Line Drawing of 3-Dimensional Objects by Sequential Illumination from Several Directions. Pattern Recognition 4, 4, 345--351.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>544522</ref_obj_id>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Strothotte, T., and Schlechtweg, S. 2002. NonPhotorealistic Computer Graphics: Modeling, Rendering and Animation. Morgan Kaufmann, San Francisco.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>946654</ref_obj_id>
				<ref_obj_pid>946247</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Tan, P., Lin, S., Quan, L., and Shum, H.-Y. 2003. Highlight Removal by Illumination-Constrained Inpainting. In Ninth IEEE International Conference on Computer Vision.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Tan, K., Kobler, J., Dietz, P., Feris, R., and Raskar, R. 2004. Shape-Enhanced Surgical Visualizations and Medical Illustrations with Multi-Flash Imaging. In MERL TR/38.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Toyama, K., Krumm, J., Brumitt, B., and Meyers, B. 1999. Wallflower: Principles and Practice of Background Maintenance. In ICCV, 255--261.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Waking Life, 2001. Waking Life, the movie.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Weiss, Y. 2001. Deriving intrinsic images from image sequences. In Proceedings of ICCV, vol. 2, 68--75.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>923318</ref_obj_id>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Yang, D. K.-M. 1996. Shape from Darkness Under Error. PhD thesis, Columbia University.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198563</article_id>
		<sort_key>3</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Assorted pixels]]></title>
		<subtitle><![CDATA[multi-sampled imaging with structural models]]></subtitle>
		<page_from>3</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198563</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198563</url>
		<abstract>
			<par><![CDATA[Multi-sampled imaging is a general framework for using pixels on an image detector to simultaneously sample multiple dimensions of imaging (space, time, spectrum, brightness, polarization, etc.). The mosaic of red, green and blue spectral filters found in most solid-state color cameras is one example of multi-sampled imaging. We briefly describe how multi-sampling can be used to explore other dimensions of imaging. Once such an image is captured, smooth reconstructions along the individual dimensions can be obtained using standard interpolation algorithms. Typically, this results in a substantial reduction of resolution (and hence image quality). One can extract significantly greater resolution in each dimension by noting that the light fields associated with real scenes have enormous redundancies within them, causing different dimensions to be highly correlated. Hence, multi-sampled images can be better interpolated using local structural models that are learned offline from a diverse set of training images. The specific type of structural models we use are based on polynomial functions of measured image intensities. They are very effective as well as computationally efficient. We demonstrate the benefits of structural interpolation using three specific applications. These are (a) traditional color imaging with a mosaic of color filters, (b) high dynamic range monochrome imaging using a mosaic of exposure filters, and (c) high dynamic range color imaging using a mosaic of overlapping color and exposure filters.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P264533</person_id>
				<author_profile_id><![CDATA[81100052215]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shree]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Nayar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Columbia University, New York, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P410377</person_id>
				<author_profile_id><![CDATA[81100599730]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Srinivasa]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Narasimhan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Columbia University, New York, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{Aut01} Authors. Resolution Enhancement Along Multiple Imaging Dimensions Using Structural Models. Technical Report, Authors' Institution, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{Bay76} B. E. Bayer. Color imaging array. U.S. Patent 3,971,065, July 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{BE00} M. Ben-Ezra. Segmentation with Invisible Keying Signal. In CVPR, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{BK00} S. Baker and T. Kanade. Limits on Super-Resolution and How to Break Them. In Proc. of CVPR, pages II:372--379, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{Bra65} R. N. Bracewell. The Fourier Transform and Its Applications. McGraw Hill, 1965.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{Bra94} D. Brainard. Bayesian method for reconstructing color images from trichromatic samples. In Proc. of IS&T 47th Annual Meeting, pages 375--380, Rochester, New York, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{Dil77} P. L. P. Dillon. Color imaging array. U.S. Patent 4,047203, September 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{Dil78} P. L. P Dillon. Fabrication and performance of color filter arrays for solid-state imagers. In IEEE Trans. on Electron Devices, volume ED-25, pages 97--101, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258884</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{DM97} P. Debevec and J. Malik. Recovering High Dynamic Range Radiance Maps from Photographs. Proc. of ACM SIGGRAPH 1997, pages 369--378, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>851588</ref_obj_id>
				<ref_obj_pid>850924</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{FP99} W. Freeman and E. Pasztor. Learning Low-Level Vision. In Proc. of ICCV, pages 1182--1189, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{GHZ92} R. Ginosar, O. Hilsenrath, and Y. Zeevi. Wide dynamic range camera. U.S. Patent 5,144,442, September 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{KM85} K. Knop and R. Morf. A new class of mosaic color encoding patterns for single-chip cameras. In IEEE Trans. on Electron Devices, volume ED-32, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{MN99} T. Mitsunaga and S. K. Nayar. Radiometric Self Calibration. In Proc. of CVPR, pages I:374--380, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{MOS83} D. Manabe, T. Ohta, and Y. Shimidzu. Color filter array for IC image sensor. In Proc. of IEEE Custom Integrated Circuits Conference, pages 451--455, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{MP95} S. Mann and R. Picard. Being 'Undigital' with Digital Cameras: Extending Dynamic Range by Combining Differently Exposed Pictures. Proc. of IST's 48th Annual Conf., pages 442--448, May 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{NM00} S. K. Nayar and T. Mitsunaga. High Dynamic Range Imaging: Spatially Varying Pixel Exposures. In Proc. of CVPR, pages I:472--479, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[{Par85} K. A. Parulski. Color filters and processing alternatives for one-chip cameras. In IEEE Trans. on Electron Devices, volume ED-32, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[{SN01} Y. Y. Schechner and S. K. Nayar. Generalized mosaicing. In ICCV, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[{WS95} M. A. Wober and R. Soini. Method and apparatus for recovering image data through the use of a color test pattern. U.S. Patent 5,475,769, Dec. 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198564</article_id>
		<sort_key>4</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Image fusion for context enhancement and video surrealism]]></title>
		<page_from>4</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198564</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198564</url>
		<abstract>
			<par><![CDATA[We present a class of image fusion techniques to automatically combine images of a scene captured under different illumination. Beyond providing digital tools for artists for creating surrealist images and videos, the methods can also be used for practical applications. For example, the non-realistic appearance can be used to enhance the context of nighttime traffic videos so that they are easier to understand. The context is automatically captured from a fixed camera and inserted from a day-time image (of the same scene). Our approach is based on a gradient domain technique that preserves important local perceptual cues while avoiding traditional problems such as aliasing, ghosting and haloing. We presents several results in generating surrealistic videos and in increasing the information density of low quality nighttime videos.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[gradient domain approach]]></kw>
			<kw><![CDATA[image fusion]]></kw>
			<kw><![CDATA[surrealism]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40022814</person_id>
				<author_profile_id><![CDATA[81100022847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ramesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Raskar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs (MERL), Cambridge]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24043805</person_id>
				<author_profile_id><![CDATA[81100546195]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Adrian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ilie]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[UNC Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P544093</person_id>
				<author_profile_id><![CDATA[81100472930]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jingyi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MIT, Cambridge]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[BostonWebcams, 2003. (Observe the cameras at night). http://www.boston.com/traffic/cameras/artery.htm.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Braun, M. 1992. Picturing Time. University of Chicago.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Chuang, Y., Curless, B., Salesin, D., and R., S. 2001. A Bayesian Approach to Digital Matting. In Proceedings of CVPR, vol. 2, 264--271.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cohen, M., 2003. Image Stacks. Presentation at MIT, Cambridge, USA, October 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566650</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[DeCarlo, D., and Santella, A. 2002. Stylization and Abstraction of Photographs. In Proc. Siggraph 02, ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[DiCarlo, J., and Wandell, B. 2000. Rendering High Dynamic Range Images. In Proceedings of SPIE: Image Sensors, vol. 3965, 392--401.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566574</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Durand, F., and Dorsey, J. 2002. Fast Bilateral Filtering for High-Dynamic-Range Images. In Proceedings of SIGGRAPH 2002, ACM SIGGRAPH, 257--266.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Essa, I., 2002. Graphical Display of Motion-Capture System using a Shape-time Style Rendering.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566573</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Fattal, R., Lischinski, D., and Werman, M. 2002. Gradient Domain High Dynamic Range Compression. In Proceedings of SIGGRAPH 2002, ACM SIGGRAPH, 249--256.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>331789</ref_obj_id>
				<ref_obj_pid>331770</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Fels, S., and Mase, K. 1999. Interactive video cubism. In Workshop on New Paradigms in Information Visualization and Manipulation, ACM Press, 78--82.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>649239</ref_obj_id>
				<ref_obj_pid>645318</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Finlayson, G., Hordley, S., and Drew, M. 2002. Removing Shadows from Images. In Proceedings of ECCV, vol. 4, 823--836.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Freeman, B., and Zhang, H. 2003. Shapetime photography. In Proceedings of CVPR, vol. 2, 264--271.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569007</ref_obj_id>
				<ref_obj_pid>569005</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Gleicher, M., Heck, R., and Wallick, M. 2002. A framework for virtual videography. In Smart Graphics.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Haeberli, P., 1994. A Multifocus Method for Controlling Depth of Field. Availavle at: http://www.sgi.com/grafica/depth/index.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>340917</ref_obj_id>
				<ref_obj_pid>340916</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Hertzmann, A., and Perlin, K. 2000. Painterly Rendering for Video and Interaction. In Proceedings of NPAR 2000, Symposium on Non-Photorealistic Animation and Rendering (Annecy, France, June 2000), ACM, 7--12.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>508534</ref_obj_id>
				<ref_obj_pid>508530</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Klein, A. W., Grant, T., Finkelstein, A., and Cohen, M. F. 2002. Video Mosaics. In Proceedings of NPAR 2002, International Symposium on Non Photorealistic Animation and Rendering (Annecy, France, June 2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>545264</ref_obj_id>
				<ref_obj_pid>545261</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Klein, A. W., Sloan, P.-P. J., Finkelstein, A., and Cohen, M. F. 2002. Stylized Video Cubes. In ACM SIGGRAPH Symposium on Computer Animation, 15--22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258893</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Litwinowicz, P. 1997. Processing Images and Video for an Impressionist Effect. In Proceedings of SIGGRAPH'97 (Los Angeles, Aug. 1997), T. Whitted, Ed., Computer Graphics Proceedings, Annual Conference Series, ACM SIGGRAPH, 407--414.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237288</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Meier, B. J. 1996. Painterly Rendering for Animation. In Proceedings of SIGGRAPH'96 (New Orleans, Aug. 1996), H. Rushmeier, Ed., Computer Graphics Proceedings, Annual Conference Series, ACM SIGGRAPH, 477--484.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Merriam-Webster. 2001. Collegiate Dictionary.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Muybridge, E. 1985. Horses and other animals in motion. Dover.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882269</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[P&#232;rez, P., Gangnet, M., and Blake, A. 2003. Poisson image editing. In Proceedings of SIGGRAPH 2003, 313--318.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>148286</ref_obj_id>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Press, W. H., Teukolsky, S., Vetterling, W. T., and Flannery, B. P. 1992. Numerical Recipes in C: The Art of Scientific Computing. Pearson Education.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280871</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Rademacher, P., and Bishop, G. 1998. Multiple-Center-of-Projection Images. In Proceedings of SIGGRAPH 98 (Orlando, July 1998), M. Cohen, Ed., Annual Conference Series, ACM SIGGRAPH, 199--206.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., Yu, J., and Ilie, A., 2003. Stylized Images using Variable Illumination. Unpublished, January 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., Yu, J., and Ilie, A., 2003. Video Surveillance with NPR Image Fusion. http://www.merl.com/projects/NPRfusion/, March 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566575</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Reinhard, E., Stark, M., Shirley, P., and Ferwerda, J. 2002. Photographic Tone Reproduction for Images. In Proceedings of SIGGRAPH 2002, ACM SIGGRAPH, 267--276.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258056</ref_obj_id>
				<ref_obj_pid>258049</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Smith, S., and Brady, J. 1997. SUSAN - a new approach to low level image processing. Int. Journal of Computer Vision 23, 1, 45--78.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Socolinsky, D., and Wolff, L. 1999. A New Visualization Paradigm for Multispectral Imagery and Data Fusion. In Proceedings of IEEE CVPR, 319--324.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Toyama, K., Krumm, J., Brumitt, B., and Meyers, B. 1999. Wallflower: Principles and Practice of Background Maintenance. In ICCV, 255--261.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Weiss, Y. 2001. Deriving Intrinsic Images From Image Sequences. In Proceedings of ICCV, vol. 2, 68--75.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198565</article_id>
		<sort_key>5</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[The trilateral filter for high contrast images and meshes]]></title>
		<page_from>5</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198565</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198565</url>
		<abstract>
			<par><![CDATA[We present a new, single-pass nonlinear filter for edge-preserving smoothing and visual detail removal for <i>N</i> dimensional signals in computer graphics, image processing and computer vision applications. Built from two modified forms of Tomasi and Manduchi's bilateral filter, the new "trilateral" filter smoothes signals towards a sharply-bounded, piecewise-linear approximation. Unlike bilateral filters or anisotropic diffusion methods that smooth towards piecewise constant solutions, the trilateral filter provides stronger noise reduction and better outlier rejection in high-gradient regions, and it mimics the edge-limited smoothing behavior of shock-forming PDEs by region finding with a fast min-max stack. Yet the trilateral filter requires only one user-set parameter, filters an input signal in a single pass, and does not use an iterative solver as required by most PDE methods. Like the bilateral filter, the trilateral filter easily extends to <i>N</i>-dimensional signals, yet it also offers better performance for many visual applications including appearance-preserving contrast reduction problems for digital photography and denoising polygonal meshes.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P590120</person_id>
				<author_profile_id><![CDATA[81100078032]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Prasun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Choudhury]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Northwestern University, Evanston, IL]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P130685</person_id>
				<author_profile_id><![CDATA[81100216430]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jack]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tumblin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Northwestern University, Evanston, IL]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>884142</ref_obj_id>
				<ref_obj_pid>882487</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M. Alexa, "Weiner filtering of meshes," in Proc. Shape Modeling International (SMI), pp. 51--57, 2002. 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>581916</ref_obj_id>
				<ref_obj_pid>581896</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M. Ashikhmin, "A tone mapping algorithm for high contrast images," in P. Debevec and S. Gibson Eds., Proc. 13th Eurographics Workshop on Rendering (EGRW), pp. 145--156, 2002. 1, 2, 6, 7]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>588276</ref_obj_id>
				<ref_obj_pid>588272</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C. Bajaj and G. Xu, "Anisotropic diffusion of surfaces and functions on surfaces," ACM Trans. Computer Graphics, vol. 22(1), pp. 4--32, 2003. 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>568224</ref_obj_id>
				<ref_obj_pid>568214</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. Barash, "A fundamental relationship between bilateral filtering, adaptive smoothing and nonlinear diffusion equation," IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 24(6), pp. 844--850, 2002. 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>238739</ref_obj_id>
				<ref_obj_pid>238728</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. Black, and A. Rangarajan, "On the unification of line processes, outlier rejection, and robust statistics with applications in early vision," International Journal of Computer Vision, vol. 19(1), pp. 57--92, 1996. 1, 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2319509</ref_obj_id>
				<ref_obj_pid>2318958</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. J. Black, G. Sapiro, D. Marimont, and D. Heeger, "Robust anisotropic diffusion," IEEE Transactions on Image Processing, vol. 7(3), pp. 421--432, 1998. 1, 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258884</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[P. Debevec, and J. Malik, "Recovering high dynamic range radiance maps from photographs," in Proc. SIGGRAPH 97, ACM SIGGRAPH / Addison Wesley Longman, Computer Graphics Proceedings, Annual Conference Series, pp. 369--378, 1997. 1]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[K. Delvin, A. Chalmers, A. Wilkie and W. Purgathofer, "Tone reproduction and physically based spectral rendering," EUROGRAPHICS 2002: State of the Art Report (STAR), 2002. 1, 2, 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311576</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[M. Desbrun, M. Meyer, P. Schroeder and A. H. Barr, "Implicit fairing of irregular meshes using diffusion and curvature flow," Proc. of ACM SIGGRAPH'99 Conference Proceedings, pp. 317--324, 1999. 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566574</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[F. Durand, and J. Dorsey, "Fast bilateral filtering for the display of high-dynamic range images," ACM Transactions on Graphics, special issue on Proc. of ACM SIGGRAPH 2002, San Antonio, Texas, vol. 21(3), pp. 249--256, 2002. 1, 2, 3, 6, 7, 8]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2320322</ref_obj_id>
				<ref_obj_pid>2319013</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Elad, "On the bilateral filter and ways to improve it," IEEE Transaction Image Processing, vol. 11(10), pp. 1141--1151, 2002. 1, 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566573</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[R. Fattal, D. Lischinski, and M. Werman, "Gradient domain high dynamic range compression," ACM Transactions on Graphics, special issue on Proc. of ACM SIGGRAPH 2002, San Antonio, Texas, vol. 21(3), pp. 257--266, 2002. 3, 6, 7, 8]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237266</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A. Finkelstein, C. E. Jacobs and D. H. Salesin, "Multiresolution video," Proc. of ACM SIGGRAPH 1996, ACM SIGGRAPH, Computer Graphics Proceedings, Annual Conference Series, pp. 281--290, 1996. 10]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882368</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[S. Fleishman, I. Drori and D. Cohen-Or, "Bilateral mesh denoising," ACM Transactions on Graphics, special issue on Proc. of ACM SIGGRAPH 2003, San Diego, California, 2003 (to appear). 3, 8, 9, 10]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311577</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[I. Guskov, W. Sweldens and P. Schroeder, "Multiresolution signal processing for meshes," in Proc. SIGGRAPH 99, ACM SIGGRAPH, Los Angeles, California, Computer Graphics Proceedings, Annual Conference Series, pp. 325--334, 1999. 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882367</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[T. R. Jones, F. Durand and M. Desbrun, "Non-iterative feature preserving mesh smoothing," ACM Transactions on Graphics, special issue on Proc. of ACM SIGGRAPH 2003, San Diego, California, 2003 (to appear). 3, 9, 10]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280831</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[L. Kobbelt, S. Campagna, J. Vorsatz and H. P. Siedel, "Interactive multi-resolution modeling on arbitrary meshes," in Proc. SIGGRAPH 98, ACM SIGGRAPH, Computer Graphics Proceedings, Annual Conference Series, pp. 105--114, 1998. 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[A. McNamara, "Visual perception in realistic image synthesis," EUROGRAPHICS 2000: State of the Art Report (STAR), Interlaken, Switzerland, 2000. 1, 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[S. K. Nayar and T. Mitsunaga, "High dynamic range imaging: spatially varying pixel exposures," in Proc. Computer Vision and Pattern Recognition (CVPR), pp. 473--479, 2000. 1]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383310</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[B. M. Oh, M. Chen, J. Dorsey and F. Durand, "Image based modeling and photo editing," in Proc. SIGGRAPH 2001, ACM SIGGRAPH, Los Angeles, California, Computer Graphics Proceedings, Annual Conference Series, pp. 433--442, 2001. 10]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>601686</ref_obj_id>
				<ref_obj_pid>601671</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[J. Peng, V. Strela, D. Zorin, "A simple algorithm for surface denoising," Proceedings of IEEE Visualization 2001. 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882269</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[P. Perez, M. Gangnet and A. Blake, "Poisson image editing," ACM Transactions on Graphics, special issue on Proc. of ACM SIGGRAPH 2003, San Diego, California, 2003 (to appear). 10]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>78304</ref_obj_id>
				<ref_obj_pid>78302</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[P. Perona, and J. Malik, "Scale space and edge detection using anisotropic diffusion," IEEE Transaction Pattern Analysis and Machine Intelligence, vol. 12(7), pp. 629--639, 1990. 1, 2, 3, 5]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566575</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Reinhard, E., Stark, M., Shirley, P. and Ferwada, J., "Photographic tone reproduction for digital images," ACM Transactions on Graphics, special issue on Proc. of ACM SIGGRAPH 2002, San Antonio, Texas, vol. 21 (3), pp. 267--276, 2002. 1, 2, 6, 7]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1204651</ref_obj_id>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[G. Sapiro, "Geometric partial differential equations and image analysis," Cambridge University Press, 2001. 1]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[C. Schlick, "Quantization techniques for visualization of high dynamic range pictures," in G. Sakas, et al. eds. Photorealistic Rendering Techniques, Proc. 5th Eurographics Rendering Workshop, pp. 7--20, 1995. 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218473</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[G. Taubin, "A signal processing approach to fair surface design," in Proc. SIGGRAPH 95, ACM SIGGRAPH, Computer Graphics Procedings, Annual Conference Series, pp. 351--358, 1995. 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[T. G. Stockham, "Image processing in the context of a visual model," Proceedings of the IEEE, vol. 60, no. 7, pp. 828--842, 1972. 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944024</ref_obj_id>
				<ref_obj_pid>944020</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[T. Tasdizen, R. Whitaker, P. Burchard and S. Osher, "Geometric surface processing via normal maps," ACM Trans. Computer Graphics, Sepetmber 2003 (to appear). 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[G. Taubin, "Geometric signal processing on polygonal meshes," EUROGRAPHICS 2000: State of the Art Report (STAR), Interlaken, Switzerland, 2000. 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>939190</ref_obj_id>
				<ref_obj_pid>938978</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[C. Tomasi, and R. Manduchi, "Bilateral filtering of gray and colored images," Proc. IEEE Intl. Conference on Computer Vision, pp. 836--846, 1998. 1, 3, 4, 5]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617873</ref_obj_id>
				<ref_obj_pid>616030</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[J. Tumblin, and H. Rushmeier, "Tone reproduction for realistic images," IEEE Computer Graphics and Applications, vol. 13(6), pp. 42--48, 1993. 1]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311544</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[J. Tumblin and G. Turk, "LCIS: A boundary hierarchy for detail-preserving contrast reduction," in Proc. SIGGRAPH 99, ACM SIGGRAPH, Los Angeles, California, Computer Graphics Proceedings, Annual Conference Series, pp. 83--90, 1999. 1, 2, 5, 6, 7]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>581906</ref_obj_id>
				<ref_obj_pid>581896</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[S. Vedula, S. Baker and T. Kanade, "Spatio-temporal view interpolation", Proc. 13th ACM Eurographics Workshop on Rendering, pp. 65--76, 2002. 10]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>167536</ref_obj_id>
				<ref_obj_pid>167526</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[R. Whittaker and S. Pizer, "A multi-scale approach to nonuniform diffusion," CVGIP: Image Understanding, vol. 57(1), pp. 99--110, 1993. 1, 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198566</section_id>
		<sort_key>4</sort_key>
		<section_seq_no>4</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[An interactive introduction to OpenGL programming]]></section_title>
		<section_page_from>4</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP39057358</person_id>
				<author_profile_id><![CDATA[81322506343]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dave]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shreiner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198567</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[An interactive introduction to OpenGL programming]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198567</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198567</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39057355</person_id>
				<author_profile_id><![CDATA[81322506343]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dave]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shreiner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35035674</person_id>
				<author_profile_id><![CDATA[81100366265]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ed]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Angel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P760266</person_id>
				<author_profile_id><![CDATA[81309506436]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Vicki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shreiner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198568</section_id>
		<sort_key>5</sort_key>
		<section_seq_no>5</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA["Madagascar:" bringing a new visual style to the screen]]></section_title>
		<section_page_from>5</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP35035875</person_id>
				<author_profile_id><![CDATA[81335490913]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Philippe]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gluckman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>PP24035134</person_id>
				<author_profile_id><![CDATA[81322501624]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Denise]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Minter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198569</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Madagascar: bringing a new visual style to the screen]]></title>
		<subtitle><![CDATA[Copyright restrictions prevent ACM from providing the full text for this work.]]></subtitle>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198569</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198569</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35035913</person_id>
				<author_profile_id><![CDATA[81335490913]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Philippe]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gluckman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24035004</person_id>
				<author_profile_id><![CDATA[81322501624]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Denise]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Minter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P837812</person_id>
				<author_profile_id><![CDATA[81322491260]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kendal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chronkhite]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31057694</person_id>
				<author_profile_id><![CDATA[81536811156]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Cassidy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Curtis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24043447</person_id>
				<author_profile_id><![CDATA[81322496178]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Milana]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P837819</person_id>
				<author_profile_id><![CDATA[81548023769]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Rob]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vogt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P837821</person_id>
				<author_profile_id><![CDATA[81322506258]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Scott]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Singer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	</section>
	<section>
		<section_id>1198570</section_id>
		<sort_key>6</sort_key>
		<section_seq_no>6</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Advanced topics on clothing simulation and animation]]></section_title>
		<section_page_from>6</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>P163975</person_id>
				<author_profile_id><![CDATA[81447598118]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kwang-Jin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Choi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>PP80029373</person_id>
				<author_profile_id><![CDATA[81423594747]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hyeong-Seok]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ko]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198571</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Stable but responsive cloth]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198571</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198571</url>
		<abstract>
			<par><![CDATA[We present a semi-implicit cloth simulation technique that is very stable yet also responsive. The stability of the technique allows the use of a large fixed time step when simulating all types of fabrics and character motions. The animations generated using this technique are strikingly realistic. Wrinkles form and disappear in a quite natural way, which is the feature that most distinguishes textile fabrics from other sheet materials. Significant improvements in both the stability and realism were made possible by overcoming the <i>post-buckling instability</i> as well as the numerical instability. The instability caused by buckling arises from a structural instability and therefore cannot be avoided by simply employing a semi-implicit method. Addition of a damping force may help to avoid instabilities; however, it can significantly degrade the realism of the cloth motion. The method presented here uses a particle-based physical model to handle the instability in the post-buckling response without introducing any fictitious damping.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[deformations]]></kw>
			<kw><![CDATA[numerical analysis]]></kw>
			<kw><![CDATA[physically based animation]]></kw>
			<kw><![CDATA[physically based modeling]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.7</cat_node>
				<descriptor>Convergence and stability</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.1.7</cat_node>
				<descriptor>Stiff equations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010342</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Model development and analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003727.10003728</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Differential equations->Ordinary differential equations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003727.10003728</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Differential equations->Ordinary differential equations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P163975</person_id>
				<author_profile_id><![CDATA[81447598118]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kwang-Jin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Choi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Seoul National University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P113193</person_id>
				<author_profile_id><![CDATA[81423594747]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hyeong-Seok]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ko]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Seoul National University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Amirbayat, J., and Hearle, J. 1989. The anatomy of buckling of textile fabrics: Drape and conformability. Journal of Textile Institute 80, 1, 51--70.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280821</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Baraff, D., and Witkin, A. 1998. Large steps in cloth simulation. In Proceedings of SIGGRAPH 98, ACM Press/ACM SIGGRAPH, Computer Graphics Proceedings, Annual Conference Series, ACM, 43--54.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bathe, K. J. 1996. Finte Element Procedures. Prentice-Hall.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192259</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Breen, D. E., House, D. H., and Wozny, M. J. 1994. Predicting the drape of woven cloth using interacting particles. In Proceedings of SIGGRAPH 94, ACM Press / ACM SIGGRAPH, Computer Graphics Proceedings, Annual Conference Series, ACM, 365--372.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134017</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Carignan, M., Yang, Y., Magnenat-Thalmann, N., and Thalmann, D. 1992. Dressing animated synthetic actors with complex deformable clothes. In Computer Graphics (Proceedings of ACM SIGGRAPH 92), ACM, 99--104.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218432</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Courshesnes, M., Volino, P., and Magnenat Thalmann, N. 1995. Versatile and efficient techniques for simulating cloth and other deformable objects. In Proceedings of SIGGRAPH 95, ACM Press / ACM SIGGRAPH, Computer Graphics Proceedings, Annual Conference Series, ACM, 137--144.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>351638</ref_obj_id>
				<ref_obj_pid>351631</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Desbrun, M., Schr&#246;der, P., and Barr, A. 1999. Interactive animation of structured deformable objects. In Graphics Interface, 1--8.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618378</ref_obj_id>
				<ref_obj_pid>616042</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Eberhardt, B., Weber, A., and Strasser, W. 1996. A fast, flexible, particle-system model for cloth draping. IEEE Computer Graphics and Applications 16, 5 (Sept.), 52--59.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618380</ref_obj_id>
				<ref_obj_pid>616042</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Eischen, J. W., Deng, S., and Clapp, T. G. 1996. Finite-element modeling and control of flexible fabric parts. IEEE Computer Graphics and Applications 16, 5 (Sept.), 71--80.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Gere, J. M. 2001. Mechanics of Materials. Brooks/Cole.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kang, T., Joo, K. and Lee, K. 2001. Analysis of fabric buckling based on nonlinear bending properties. (Submitted), http://textile.snu.ac.kr/upjuk/PDF/IJ_TRJ_2002_KHJOO.PDF.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Provot, X. 1995. Deformation constraints in a mass-spring model to describe rigid cloth behavior. In Graphics Interface '95, 147--154.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378522</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., and Fleischer, K. 1988. Modeling inelastic deformation: Viscoelasticity, plasticity, fracture. In Computer Graphics (Proceedings of ACM SIGGRAPH 88), ACM, 269--278.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>793086</ref_obj_id>
				<ref_obj_pid>792759</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Volino, P., and Magnenat-Thalmann, N. 2000. Implementing fast cloth simulation with collision response. In Proceedings of the Conference on Computer Graphics International (CGI-00), 257--268.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>735221</ref_obj_id>
				<ref_obj_pid>647781</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Volino, P., and Management-Thalmann, N. 2001. Comparing efficiency of integration methods for cloth animation. In Proceedings of the Conference on Computer Graphics International (CGI-01).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Yu, W., Kang, T., and Chung, K. 2000. Drape simulation of woven fabrics by using explicit dynamic analysis. Journal of Textile Institute 91 Part 1, 2, 285--301.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>826507</ref_obj_id>
				<ref_obj_pid>826029</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Zhang, D., and Yuen, M. 2000. Collision detection for clothed human animation. In Proceedings of the 8th Pacific Graphics Conference on Computer Graphics and Application (PACIFIC GRAPHICS-00), 328--337.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198572</article_id>
		<sort_key>2</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Robust treatment of collisions, contact and friction for cloth animation]]></title>
		<page_from>2</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198572</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198572</url>
		<abstract>
			<par><![CDATA[We present an algorithm to efficiently and robustly process collisions, contact and friction in cloth simulation. It works with any technique for simulating the internal dynamics of the cloth, and allows true modeling of cloth thickness. We also show how our simulation data can be post-processed with a collision-aware subdivision scheme to produce smooth and interference free data for rendering.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[cloth]]></kw>
			<kw><![CDATA[collision detection]]></kw>
			<kw><![CDATA[collision response]]></kw>
			<kw><![CDATA[contacts]]></kw>
			<kw><![CDATA[kinetic friction]]></kw>
			<kw><![CDATA[physically based animation]]></kw>
			<kw><![CDATA[static friction]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Physically based modeling</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352.10010379</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation->Physical simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003741.10003742.10003745</concept_id>
				<concept_desc>CCS->Mathematics of computing->Continuous mathematics->Topology->Geometric topology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP39034414</person_id>
				<author_profile_id><![CDATA[81100248660]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bridson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P337982</person_id>
				<author_profile_id><![CDATA[81100612327]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ronald]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fedkiw]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40031316</person_id>
				<author_profile_id><![CDATA[81314493471]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Anderson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Industrial Light & Magic]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>134084</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baraff, D., and Witkin, A. 1992. Dynamic simulation of non-penetrating flexible bodies. In Proc. of SIGGRAPH 1992, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc, 303--308.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Baraff, D., and Witkin, A. 1994. Global methods for simulating contacting flexible bodies. In Computer Animation Proc., Springer-Verlag, 1--12.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280821</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Baraff, D., and Witkin, A. 1998. Large steps in cloth simulation. In Proc. of SIGGRAPH 1998, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc., 1--12.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74356</ref_obj_id>
				<ref_obj_pid>74333</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Baraff, D. 1989. Analytical methods for dynamic simulation of non-penetrating rigid bodies. In Proc. of SIGGRAPH 1989, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97881</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Baraff, D. 1990. Curved surfaces and coherence for non-penetrating rigid body simulation. In Proc. of SIGGRAPH 1990, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122722</ref_obj_id>
				<ref_obj_pid>122718</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Baraff, D. 1991. Coping with friction for non-penetrating rigid body simulation. In Proc. of SIGGRAPH 1991, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc., 31--40.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Baraff, D. 1993. Issues in computing contact forces for non-penetrating rigid bodies. Algorithmica, 10, 292--352.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192168</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Baraff, D. 1994. Fast contact force computation for nonpenetrating rigid bodies. In Proc. of SIGGRAPH 1994, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Baraff, D. 2001. Collision and contact. In SIGGRAPH 2001 Course Notes, ACM.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Barequet, G., Chazelle, B., Guibas, L., Mitchell, J., and Tal, A. 1996. BOXTREE: A hierarchical representation for surfaces in 3D. Comp. Graphics Forum 15, 3, 387--396.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192259</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Breen, D. E., House, D. H., and Wozny, M. J. 1994. Predicting the drape of woven cloth using interacting particles. In Proc. of SIGGRAPH 1994, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc., 365--372.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>302658</ref_obj_id>
				<ref_obj_pid>302638</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Caramana, E., Burton, D., Shashkov, M., and Whalen, P. 1998. The construction of compatible hydrodynamics algorithms utilizing conservation of total energy. Journal of Computational Physics 146, 227--262.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134017</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Carignan, M., Yang, Y., Magnenat-Thalmann, N., and Thalmann, D. 1992. Dressing animated synthetic actors with complex deformable clothes. In Proc. SIGGRAPH 1992, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc., 99--104.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344882</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Chenney, S., and Forsyth, D. A. 2000. Sampling plausible solutions to multi-body constraint problems. In SIGGRAPH 2000, ACM Press / ACM SIGGRAPH, Comp. Graphics Proc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280826</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[DeRose, T., Kass, M., and Truong, T. 1998. Subdivision surfaces in character animation. In Proc. SIGGRAPH 1998, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc., 85--94.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Desbrun, M., and Gascuel, M.-P. 1994. Highly deformable material for animation and collision processing. In 5th Eurographics worshop on animation and simulation.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>351638</ref_obj_id>
				<ref_obj_pid>351631</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Desbrun, M., Schr&#246;der, P., and Barr, A. 1999. Interactive animation of structured deformable objects. In Graphics Interface, 1--8.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Doghri, I., Muller, A., and Taylor, R. L. 1998. A general three-dimensional contact procedure for finite element codes. Engineering Computations 15, 2, 233--259.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166157</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Gascuel, M.-P. 1993. An implicit formulation for precise contact modeling between flexible solids. In SIGGRAPH 1993, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc., 313--320.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237244</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Gottschalk, S., Lin, M. C., and Manocha, D. 1996. Obb-tree: a hierarchical structure for rapid interference detection. In Proc. of SIGGRAPH 1996, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc., 171--179.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74335</ref_obj_id>
				<ref_obj_pid>74333</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Gourret, J.-P., Magnenat-Thalmann, N., and Thalmann, D. 1989. Simulation of object and human skin deformations in a grasping task. In Proc. of SIGGRAPH 1989, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc., 21--30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>601723</ref_obj_id>
				<ref_obj_pid>601671</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Grinspun, E., and Schr&#246;der, P. 2001. Normal bounds for subdivision-surface interference detection. In Proc. of IEEE Scientific Visualization, IEEE.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378530</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Hahn, J. K. 1988. Realistic animation of rigid bodies. In Proc. of SIGGRAPH 1988, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97883</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Herzen, B. V., Barr, A. H., and Zatz, H. R. 1990. Geometric collisions for time-dependent parametric surfaces. In Proc. of SIGGRAPH 1990, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc., 39--48.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>350448</ref_obj_id>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[House, D. H., and Breen, D. E., Eds. 2000. Cloth modeling and animation. A. K. Peters.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Howlett, P., and Hewitt, W. T. 1998. Mass-spring simulation using adaptive non-active points. In Computer Graphics Forum, vol. 17, 345--354.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Hughes, T. J. R. 1987. The finite element method: linear static and dynamic finite element analysis. Prentice Hall.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Jimenez, S., and Luciani, A. 1993. Animation of interacting objects with collisions and prolonged contacts. In Modeling in computer graphics---methods and applications, Springer-Verlag, B. Falcidieno and T. L. Kunii, Eds., Proc. of the IFIP WG 5.10 Working Conference, 129--141.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Kane, C., Repetto, E., Ortiz, M., and Marsden, J. 1999. Finite element analysis of nonsmooth contact. Comput. Methods Appl. Mech. Eng. 180, 1--26.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Lafleur, B., Magnenat-Thalmann, N., and Thalmann, D. 1991. Cloth animation with self-collision detection. In Proc. of the Conf. on Modeling in Comp. Graphics, Springer, 179--187.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Lin, M., and Gottschalk, S. 1998. Collision detection between geometric models: A survey. In Proc. of IMA Conf. on Mathematics of Surfaces.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Loop, C. 2001. Triangle mesh subdivision with bounded curvature and the convex hull property. Tech. Rep. MSR-TR-2001-24, Microsoft Research.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Marhefka, D. W., and Orin, D. E. 1996. Simulation of contact using a nonlinear damping model. In Proc. of the 1996 IEEE Int'l Conf. on Robotics and Automation, IEEE, 1662--1668.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383263</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Milenkovic, V. J., and Schmidt, H. 2001. Optimization-based animation. In Proc. of SIGGRAPH 2001, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199436</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Mirtich, B., and Canny, J. 1995. Impulse-based simulation of rigid bodies. In Proc. of 1995 symposium on interactive 3d graphics, 181--188, 217.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344866</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Mirtich, B. 2000. Timewarp rigid body simulation. In Proc. of SIGGRAPH 2000, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc., 193--200.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378528</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Moore, M., and Wilhelms, J. 1988. Collision detection and response for computer animation. In SIGGRAPH 1988, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc., 289--298.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618376</ref_obj_id>
				<ref_obj_pid>616042</ref_obj_pid>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Ng, H. N., and Grimsdale, R. L. 1996. Computer graphics techniques for modeling cloth. IEEE Computer Graphics and Applications, 28--41.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311550</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[O'Brien, J. F., and Hodgins, J. K. 1999. Graphical modeling and animation of brittle fracture. In SIGGRAPH 1999, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc., 137--146.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134019</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Okabe, H., Imaoka, H., Tomiha, T., and Niwaya, H. 1992. Three dimensional apparel CAD system. In SIGGRAPH 1992, ACM Press/ACM SIGGRAPH, Comp. Graphics Proc., 105--110.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Pandolfi, A., Kane, C., Marsden, J., and Ortiz, M. 2002. Time-discretized variational formulation of non-smooth frictional contact. Int. J. Num. Methods in Eng. 53, 1801--1829.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Provot, X. 1995. Deformation constraints in a mass-spring model to describe rigid cloth behavior. In Graphics Interface, 147--154.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Provot, X. 1997. Collision and self-collision handling in cloth model dedicated to design garment. Graphics Interface, 177--89.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>829576</ref_obj_id>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Saad, Y. 1996. Iterative methods for sparse linear systems. PWS Publishing. New York, NY.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192167</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Sims, K. 1994. Evolving virtual creatures. In SIGGRAPH 1994, ACM Press / ACM SIGGRAPH, Comp. Graphics Proc., 15--22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., and Fleischer, K. 1988. Deformable models. The Visual Computer, 4, 306--331.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378522</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., and Fleischer, K. 1988. Modeling inelastic deformation: viscoelasticity, plasticity, fracture. In Proc. of SIGGRAPH 1988, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc., 269--278.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>102333</ref_obj_id>
				<ref_obj_pid>102313</ref_obj_pid>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., and Witkin, A. 1988. Physically based models with rigid and deformable components. In Graphics Interface, 146--154.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., Platt, J., Barr, A., and Fleischer, K. 1987. Elastically deformable models. In SIGGRAPH 1987, ACM Press/ACM SIGGRAPH, Comp. Graphics Proc., 205--214.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91430</ref_obj_id>
				<ref_obj_pid>91385</ref_obj_pid>
				<ref_seq_no>50</ref_seq_no>
				<ref_text><![CDATA[Thingvold, J. A., and Cohen, E. 1992. Physical modeling with B-spline surfaces for interactive design and animation. In Proc. of SIGGRAPH 1992, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc., 129--137.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>51</ref_seq_no>
				<ref_text><![CDATA[Volino, P., and Magnenat-Thalmann, N. 1994. Efficient self-collision detection on smoothly discretized surface animations using geometrical shape regularity. In Proc. of Eurographics, vol. 13 of Computer Graphics Forum, Eurographics Association, C-155-166.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>52</ref_seq_no>
				<ref_text><![CDATA[Volino, P., and Magnenat Thalmann, N. 1995. Collision and self-collision detection: Efficient and robust solutions for highly deformable surfaces. In Comp. Anim. and Simulation, Springer-Verlag, D. Terzopoulos and D. Thalmann, Eds., 55--65.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>836188</ref_obj_id>
				<ref_obj_pid>832294</ref_obj_pid>
				<ref_seq_no>53</ref_seq_no>
				<ref_text><![CDATA[Volino, P., and Magnenat-Thalmann, N. 1997. Developing simulation techniques for an interactive clothing system. In Proc. of the 1997 International Conf. on Virtual Systems and MultiMedia, IEEE, 109--118.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218432</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>54</ref_seq_no>
				<ref_text><![CDATA[Volino, P., Courchesne, M., and Magnenat-Thalmann, N. 1995. Versatile and efficient techniques for simulating cloth and other deformable objects. In Proc. of SIGGRAPH 1995, ACM Press / ACM SIGGRAPH, Comput. Graphics Proc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>55</ref_seq_no>
				<ref_text><![CDATA[Volino, P., Courchesne, M., and Magnenat-Thalmann, N. 2000. Accurate collision response on polygonal meshes. In Proc. of Computer Graphics, 179--188.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>135556</ref_obj_id>
				<ref_obj_pid>129873</ref_obj_pid>
				<ref_seq_no>56</ref_seq_no>
				<ref_text><![CDATA[Webb, R., and Gigante, M. 1992. Using dynamic bounding volume hierarchies to improve efficiency of rigid body simulations. In Comm. with Virtual Worlds, CGI Proc. 1992, 825--841.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198573</article_id>
		<sort_key>3</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Simulation of clothing with folds and wrinkles]]></title>
		<page_from>3</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198573</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198573</url>
		<abstract>
			<par><![CDATA[Clothing is a fundamental part of a character's persona, a key storytelling tool used to convey an intended impression to the audience. Draping, folding, wrinkling, stretching, etc. all convey meaning, and thus each is carefully controlled when filming live actors. When making films with computer simulated cloth, these subtle but important elements must be captured. In this paper we present several methods essential to matching the behavior and look of clothing worn by digital stand-ins to their real world counterparts. Novel contributions include a mixed explicit/implicit time integration scheme, a physically correct bending model with (potentially) nonzero rest angles for pre-shaping wrinkles, an interface forecasting technique that promotes the development of detail in contact regions, a post-processing method for treating cloth-character collisions that preserves folds and wrinkles, and a dynamic constraint mechanism that helps to control large scale folding. The common goal of all these techniques is to produce a cloth simulation with many folds and wrinkles improving the realism.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP39056457</person_id>
				<author_profile_id><![CDATA[81100248660]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bridson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24034796</person_id>
				<author_profile_id><![CDATA[81100602513]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[S.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Marino]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Industrial Light + Magic]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40031123</person_id>
				<author_profile_id><![CDATA[81100612327]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fedkiw]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>205143</ref_obj_id>
				<ref_obj_pid>205127</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[D. Adalsteinsson and J. Sethian. A fast level set method for propagating interfaces. J. Comput. Phys., (118):269--277, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>307368</ref_obj_id>
				<ref_obj_pid>307353</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Adalsteinsson and J. Sethian. The fast construction of extension velocities in level set methods. J. Comput. Phys., 148:2--22, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>90974</ref_obj_id>
				<ref_obj_pid>90967</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Aono. A wrinkle propagation model for cloth. In Proc. 8th International Conf. of the Computer Graphics Society on CG International '90, pages 95--115, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Aubel and D. Thalmann. Realistic deformation of human body shapes. In Proc. Computer Animation and Simulation, pages 125--135, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280821</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. Baraff and A. Witkin. Large steps in cloth simulation. Comput. Graph. (SIGGRAPH Proc.), pages 1--12, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882357</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Baraff, A. Witkin, and M. Kass. Untangling cloth. ACM Trans. Graph. (SIGGRAPH Proc.), 22, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>137963</ref_obj_id>
				<ref_obj_pid>137957</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Barraquand and J.-C. Latombe. Robot motion planning: a distributed representation approach. Int'l. J. Robotics Research, 10(6):628--649, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192259</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D. E. Breen, D. H. House, and M. J. Wozny. Predicting the drape of woven cloth using interacting particles. Comput. Graph. (SIGGRAPH Proc.), pages 365--372, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566623</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[R. Bridson, R. Fedkiw, and J. Anderson. Robust treatment of collisions, contact and friction for cloth animation. ACM Trans. Graph. (SIGGRAPH Proc.), 21:594--603, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>545273</ref_obj_id>
				<ref_obj_pid>545261</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. T. Chang, J. Jin, and Y. Yu. A practical model for hair mutual interactions. In Proc. ACM SIGGRAPH Symposium on Computer Animation, pages 77--80, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566624</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[K.-J. Choi and H.-S. Ko. Stable but responsive cloth. ACM Trans. Graph. (SIGGRAPH Proc.), 21:604--611, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237269</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[B. Curless and M. Levoy. A. volumetric method for building complex models from range images. Comput. Graph. (SIGGRAPH Proc.), pages 303--312, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566581</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[B. Cutler, J. Dorsey, L. McMillan, M. M&#252;ller, and R. Jagnow. A procedural approach to authoring solid models. ACM Trans. Graph. (SIGGRAPH Proc.), 21(3):302--311, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. Davis, S. R. Marschner, M. Garr, and M. Levoy. Filling holes in complex surfaces using volumetric diffusion. In Proc. First International Symposium on 3D Data Processing, Visualization, and Transmission, pages 428--438. IEEE, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218456</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[M. Desbrun and M.-P. Gascuel. Animating soft substances with implicit surfaces. In Proc. SIGGRAPH 95, pages 287--290, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>351638</ref_obj_id>
				<ref_obj_pid>351631</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[M. Desbrun, P. Schr&#246;der, and A. Barr. Interactive animation of structured deformable objects. In Graphics Interface, pages 1--8, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134027</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[T. Duff. Interval arithmetic and recursive subdivision for implicit functions and constructive solid geometry. Comput. Graph. (SIGGRAPH Proc.), pages 131--137, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[B. Eberhardt, O. Etzmu&#223;, and M. Hauth. Implicit-explicit schemes for fast animation with particle systems. In Proc. of Eurographics Workshop on Computer Animation and Simulation, pages 137--151, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566645</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[D. Enright, S. Marschner, and R. Fedkiw. Animation and rendering of complex water surfaces. ACM Trans. Graph. (SIGGRAPH Proc.), 21:736--744, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>776360</ref_obj_id>
				<ref_obj_pid>776350</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[S. Fisher and M. C. Lin. Deformed distance fields for simulation of non-penetrating flexible bodies. In Comput. Anim. and Sim. '01, Proc. Eurographics Workshop, pages 99--111, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344899</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[S. F. Frisken, R. N. Perry, A. P. Rockwood, and T. R. Jones. Adaptively sampled distance fields: a general representation of shape for computer graphics. In Proc. SIGGRAPH 2000, pages 249--254, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166157</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[M.-P. Gascuel. An implicit formulation for precise contact modeling between flexible solids. In Proc. SIGGRAPH 93, pages 313--320, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>288142</ref_obj_id>
				<ref_obj_pid>288126</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[S. F. F. Gibson. Using distance maps for accurate surface representation in sampled volumes. In Proc. of IEEE Symp. on Vol. Vis., pages 23--30, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>846284</ref_obj_id>
				<ref_obj_pid>846276</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[E. Grinspun, A. Hirani, M. Desbrun, and P. Schr&#246;der. Discrete shells. In ACM Symp. Comp. Anim., 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566578</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[E. Grinspun, P. Krysl, and P. Schr&#246;der. CHARMS: A simple framework for adaptive simulation. ACM Trans. Graph. (SIGGRAPH Proc.), 21:281--290, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[G. Hirota, S. Fisher, A. State, C. Lee, and H. Fuchs. An implicit finite element method for elastic solids in contact. In Comput. Anim., 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>350448</ref_obj_id>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[D. H. House and D. E. Breen, editors. Cloth modeling and animation. A. K. Peters, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[P. Howlett and W. T. Hewitt. Mass-spring simulation using adaptive non-active points. In Computer Graphics Forum, volume 17, pages 345--354, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[T. Hughes. The finite element method: linear static and dynamic finite element analysis. Prentice Hall, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[S. Huh, D. N. Metaxas, and N. I. Badler. Collision resolutions in cloth simulation. In Computer Animation. IEEE, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[S. Jimenez and A. Luciani. Animation of interacting objects with collisions and prolonged contacts. In B. Falcidieno and T. L. Kunii, editors, Modeling in computer graphics---methods and applications, Proc. of the IFIP WG 5.10 Working Conference, pages 129--141. Springer-Verlag, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Y.-M. Kang, J.-H. Choi, H.-G. Cho, and D.-H. Lee. An efficient animation of wrinkled cloth with approximate implicit integration. The Visual Computer, 17(3):147--157, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[O. Khatib and J. F. Le Maitre. Dynamic control of manipulators operating in a complex environment. In Proc. 3rd Int'l. CISM-IFToMM Symposium, pages 267--282, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566627</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[T.-Y. Kim and U. Neumann. Interactive multiresolution hair modeling and editing. ACM Trans. Graph. (SIGGRAPH Proc.), 21(3):620--629, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>90703</ref_obj_id>
				<ref_obj_pid>90692</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[T. L. Kunii and H. Gotoda. Modeling and animation of garment wrinkle formation processes. In Proc. Computer Animation, pages 131--147, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311600</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[W. A. McNeely, K. D. Puterbaugh, and J. J. Troy. Six degree-of-freedom haptic rendering using voxel samping. Comput. Graph. (SIGGRAPH Proc.), pages 401--408, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566585</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[K. Museth, D. Breen, R. Whitaker, and A. Barr. Level set surface editing operators. ACM Trans. Graph. (SIGGRAPH Proc.), 21(3):330--338, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>792939</ref_obj_id>
				<ref_obj_pid>792757</ref_obj_pid>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[L. P. Nedel and D. Thalmann. Real time muscle deformations using mass-spring systems. In Proc. Computer Graphics International, pages 156--165, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618376</ref_obj_id>
				<ref_obj_pid>616042</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[H. N. Ng and R. L. Grimsdale. Computer graphics techniques for modeling cloth. IEEE Computer Graphics and Applications, pages 28--41, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134019</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[H. Okabe, H. Imaoka, T. Tomiha, and H. Niwaya. Three dimensional apparel CAD system. Comput. Graph. (SIGGRAPH Proc.), pages 105--110, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[S. Osher and R. Fedkiw. Level Set Methods and Dynamic Implicit Surfaces. Springer-Verlag, 2002. New York, NY.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[D. Parks and D. Forsyth. Improved integration for cloth simulation. In Proc. of Eurographics, Computer Graphics Forum. Eurographics Assoc., 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>338913</ref_obj_id>
				<ref_obj_pid>338852</ref_obj_pid>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[D. Peng, B. Merriman, S. Osher, H. Zhao, and M. Kang. A PDE-based fast local level set method. J. Comput. Phys., (155):410--438, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74355</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[A. Pentland and J. Williams. Good vibrations: modal dynamics for graphics and animation. Comput. Graph. (Proc. SIGGRAPH 89), 23(3):215--222, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383264</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[R. N. Perry and S. F. Frisken. Kizamu: a system for sculpting digital characters. Comput. Graph. (SIGGRAPH Proc.), pages 47--56, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[X. Provot. Deformation constraints in a mass-spring model to describe rigid cloth behavior. In Graphics Interface, pages 147--154, May 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[X. Provot. Collision and self-collision handling in cloth model dedicated to design garment. Graphics Interface, pages 177--89, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[R. E. Rosenblum, W. E. Carlson, and E. Tripp III. Simulating the structure and dynamics of human hair: modelling, rendering and animation. Journal of Visualization and Computer Animation, 2(4):141--148, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[I. Rudomin and J. Castillo. Distance fields applied to character animation. In Proc. of Eurographics, volume 21 of Computer Graphics Forum. Eurographics Assoc., 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>951099</ref_obj_id>
				<ref_obj_pid>951087</ref_obj_pid>
				<ref_seq_no>50</ref_seq_no>
				<ref_text><![CDATA[W. J. Schroeder, W. E. Lorensen, and S. Linthicum. Implicit modeling of swept surfaces and volumes. In Proc. of Vis., pages 40--55. IEEE Computer Society Press, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122745</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>51</ref_seq_no>
				<ref_text><![CDATA[S. Sclaroff and A. Pentland. Generalized implicit functions for computer graphics. Comput. Graph. (Proc. SIGGRAPH 91), 25(4):247--250, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>52</ref_seq_no>
				<ref_text><![CDATA[J. Sethian. A fast marching level set method for monotonically advancing fronts. Proc. Natl. Acad. Sci., 93:1591--1595, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>329673</ref_obj_id>
				<ref_obj_pid>329646</ref_obj_pid>
				<ref_seq_no>53</ref_seq_no>
				<ref_text><![CDATA[J. Strain. Fast tree-based redistancing for level set computations. J. Comput. Phys., 152:664--686, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>326247</ref_obj_id>
				<ref_obj_pid>326237</ref_obj_pid>
				<ref_seq_no>54</ref_seq_no>
				<ref_text><![CDATA[J. Strain. Tree methods for moving interfaces. J. Comput. Phys., 151:616--648, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>55</ref_seq_no>
				<ref_text><![CDATA[D. Terzopoulos, J. Platt, A. Barr, and K. Fleischer. Elastically deformable models. Comput. Graph. (Proc. SIGGRAPH 87), 21(4):205--214, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91430</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>56</ref_seq_no>
				<ref_text><![CDATA[J. A. Thingvold and E. Cohen. Physical modeling with B-spline surfaces for interactive design and animation. Comput. Graph. (SIGGRAPH Proc.), pages 129--137, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>57</ref_seq_no>
				<ref_text><![CDATA[J. Tsitsiklis. Efficient algorithms for globally optimal trajectories. IEEE Trans, on Automatic Control, 40:1528--1538, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>58</ref_seq_no>
				<ref_text><![CDATA[Russel Turner and Enrico Gobbetti. Interactive construction and animation of layered elastically deformable characters. Computer Graphics Forum, 17(2):135--152, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>59</ref_seq_no>
				<ref_text><![CDATA[U.S. National Library of Medicine. The visible human project, 1994. http://www.nlm.nih.gov/research/visible/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218432</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>60</ref_seq_no>
				<ref_text><![CDATA[P. Volino, M. Courchesne, and N. Magnenat-Thalmann. Versatile and efficient techniques for simulating cloth and other deformable objects. Comput. Graph. (SIGGRAPH Proc.), pages 137--144, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>872899</ref_obj_id>
				<ref_obj_pid>872743</ref_obj_pid>
				<ref_seq_no>61</ref_seq_no>
				<ref_text><![CDATA[P. Volino and N. Magnenat-Thalmann. Accurate collision response on polygonal meshes. In Proc. of Computer Animation, pages 154--163, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>735221</ref_obj_id>
				<ref_obj_pid>647781</ref_obj_pid>
				<ref_seq_no>62</ref_seq_no>
				<ref_text><![CDATA[P. Volino and N. Magnenat-Thalmann. Comparing efficiency of integration methods for cloth simulation. In Proc. Computer Graphics International, pages 265--274, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15891</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>63</ref_seq_no>
				<ref_text><![CDATA[J. Weil. The synthesis of cloth objects. Comput. Graph. (SIGGRAPH Proc.), pages 49--54, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>64</ref_seq_no>
				<ref_text><![CDATA[R. Westermann, L. Kobbelt, and T. Ertl. Real-time exploration of regular volume data by adaptive reconstruction of isosurfaces. The Vis. Comput., 15(2):100--111, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299682</ref_obj_id>
				<ref_obj_pid>299660</ref_obj_pid>
				<ref_seq_no>65</ref_seq_no>
				<ref_text><![CDATA[R. T. Whitaker. A level-set approach to 3d reconstruction from range data. International Journal of Computer Vision, 29(3):203--231, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258833</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>66</ref_seq_no>
				<ref_text><![CDATA[J. Wilhelms and A. Van Gelder. Anatomically based modeling. Comput. Graph. (SIGGRAPH Proc.), pages 173--180, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198574</article_id>
		<sort_key>4</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[A virtual node algorithm for changing mesh topology during simulation]]></title>
		<page_from>4</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198574</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198574</url>
		<abstract>
			<par><![CDATA[We propose a virtual node algorithm that allows material to separate along arbitrary (possibly branched) piecewise linear paths through a mesh. The material within an element is fragmented by creating several replicas of the element and assigning a portion of real material to each replica. This results in elements that contain both real material and empty regions. The missing material is contained in another copy (or copies) of this element. Our new virtual node algorithm automatically determines the number of replicas and the assignment of material to each. Moreover, it provides the degrees of freedom required to simulate the partially or fully fragmented material in a fashion consistent with the embedded geometry. This approach enables efficient simulation of complex geometry with a simple mesh, i.e. the geometry need not align itself with element boundaries. It also alleviates many shortcomings of traditional La-grangian simulation techniques for meshes with changing topology. For example, slivers do not require small CFL time step restrictions since they are embedded in well shaped larger elements. To enable robust simulation of embedded geometry, we propose new algorithms for handling rigid body and self collisions. In addition, we present several mechanisms for influencing and controlling fracture with grain boundaries, prescoring, etc. We illustrate our method for both volumetric and thin-shell simulations.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[changing mesh topology]]></kw>
			<kw><![CDATA[finite elements]]></kw>
			<kw><![CDATA[fracture]]></kw>
			<kw><![CDATA[sculpting]]></kw>
			<kw><![CDATA[virtual surgery]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P686344</person_id>
				<author_profile_id><![CDATA[81100267288]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Neil]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Molino]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P686365</person_id>
				<author_profile_id><![CDATA[81100450933]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Zhaosheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14211107</person_id>
				<author_profile_id><![CDATA[81100612327]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ron]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fedkiw]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>346143</ref_obj_id>
				<ref_obj_pid>346131</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Aivazis, M., Goddard, W., Meiron, D., Ortiz, M., Pool, J., and Shepherd, J. 2000. A virtual test facility for simulating the dynamic response of materials. Comput. in Sci, and Eng. 2, 42--53.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Armero, F., and Love, E. 2003. An arbitrary lagrangian-eulerian finite element method for finite strain plasticity. Int. J. Num. Meth. Eng. 57, 471--508.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280821</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Baraff, D., and Witkin, A. 1998. Large steps in cloth simulation. In Proc. SIGGRAPH 98, 1--12.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882357</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Baraff, D., Witkin, A., and Kass, M. 2003. Untangling cloth. ACM Trans. Graph. (SIGGRAPH Proc.) 22, 862--870.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Belytschko, T., Chen, H., Xu, J., and Zi, G. 2003. Dynamic crack propagation based on loss of hyperbolicity and a new discontinuous enrichment. Int. J. Num. Meth. Eng. 58, 1873--1905.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Bessette, G., Becker, E., Taylor, L., and Littlefield, D. 2003. Modeling of impact problems using an h-adaptive, explicit lagrangian finite element method in three dimensions. Comput. Meth. in Appl. Mech. and Eng. 192, 1649--1679.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>826523</ref_obj_id>
				<ref_obj_pid>826029</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Bielser, D., and Gross, M. 2000. Interactive simulation of surgical cuts. In Pacific Graph., 116--125.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>946968</ref_obj_id>
				<ref_obj_pid>946250</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Bielser, D., Glardon, P., Teschner, M., and Gross, M. 2003. A state machine for real-time cutting of tetrahedral meshes. In Pacific Graph., 377--386.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Bouchard, P., Bay, F., and Chastel, Y. 2003. Numerical modelling of crack propagation: automatic remeshing and comparison of different criteria. Comput. Meth. in Appl. Mech. and Eng. 192, 3887--3908.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566623</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Bridson, R., Fedkiw, R., and Anderson, J. 2002. Robust treatment of collisions, contact and friction for cloth animation. ACM Trans. Graph. (SIGGRAPH Proc.) 21, 594--603.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>846281</ref_obj_id>
				<ref_obj_pid>846276</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Bridson, R., Marino, S., and Fedkiw, R. 2003. Simulation of clothing with folds and wrinkles. In Proc. of the 2003 ACM SIGGRAPH/Eurographics Symp. on Comput. Anim., 28--36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Camacho, G., and Ortiz, M. 1997. Adaptive Lagrangian modelling of ballistic penetration of metallic targets. Comput. Meth. in Appl. Mech. and Eng. 142, 269--301.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566622</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Capell, S., Green, S., Curless, B., Duchamp, T., and Popovi&#263;, Z. 2002. Interactive skeleton-driven dynamic deformations. ACM Trans. Graph. (SIGGRAPH Proc.) 21, 586--593.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>545268</ref_obj_id>
				<ref_obj_pid>545261</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Capell, S., Green, S., Curless, B., Duchamp, T., and Popovi&#263;, Z. 2002. A multiresolution framework for dynamic deformations. In ACM SIGGRAPH Symp. on Comput. Anim., ACM Press, 41--48.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134016</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Chen, D., and Zeltzer, D. 1992. Pump it up: Computer animation of a biomechanically based model of muscle using the finite element method. Comput. Graph. (SIGGRAPH Proc.), 89--98.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566624</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Choi, K.-J., and Ko, H.-S. 2002. Stable but responsive cloth. ACM Trans. Graph. (SIGGRAPH Proc.) 21, 604--611.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566581</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Cutler, B., Dorsey, J., McMillan, L., Muller, M., and Jagnow, R. 2002. A procedural approach to authoring solid models. ACM Trans. Graph. (SIGGRAPH Proc.) 21, 3, 302--311.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383262</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Debunne, G., Desbrun, M., Cani, M., and Barr, A. 2001. Dynamic real-time deformations using space & time adaptive sampling. In Proc. SIGGRAPH 2001, vol. 20, 31--36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>946946</ref_obj_id>
				<ref_obj_pid>946250</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Etzmuss, O., Keckeisen, M., and Strasser, W. 2003. A fast finite element solution for cloth modelling. In Pacific Graph., 244--251.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614374</ref_obj_id>
				<ref_obj_pid>614267</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Faloutsos, P., van de Panne, M., and Terzopoulos, D. 1997. Dynamic free-form deformations for animation synthesis. IEEE Trans. on Vis. and Comput. Graphics 3, 3, 201--214.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>329653</ref_obj_id>
				<ref_obj_pid>329646</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Fedkiw, R., Aslam, T., Merriman, B., and Osher, S. 1999. A non-oscillatory Eulerian approach to interfaces in multimaterial flows (the ghost fluid method). J. Comput. Phys. 152, 457--492.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>791587</ref_obj_id>
				<ref_obj_pid>791218</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Forest, C., Delingette, H., and Ayache, N. 2002. Removing tetrahedra from a manifold mesh. In Computer Animation, 225--229.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74335</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Gourret, J.-P., Magnenat-Thalmann, N., and Thalmann, D. 1989. Simulation of object and human skin deformations in a grasping task. Comput. Graph. (SIGGRAPH Proc.), 21--30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566578</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Grinspun, E., Krysl, P., and Schroder, P. 2002. CHARMS: A simple framework for adaptive simulation. ACM Trans. Graph. (SIGGRAPH Proc.) 21, 281--290.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>846284</ref_obj_id>
				<ref_obj_pid>846276</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Grinspun, E., Hirani, A., Desbrun, M., and Schroder, P. 2003. Discrete shells. In Proc. of the 2003 ACM SIGGRAPH/Eurographics Symp. on Comput. Anim., 62--67.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Hirota, K., Tanoue, Y., and Kaneko, T. 1998. Generation of crack patterns with a physical model. The Vis. Comput. 14, 126--187.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>260732</ref_obj_id>
				<ref_obj_pid>260709</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Hirt, C., Amsden, A., and Cook, J. 1974. An arbitrary Lagrangian-Eulerian computing method for all flow speeds. J. Comput. Phys. 135, 227--253.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1028541</ref_obj_id>
				<ref_obj_pid>1028523</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Irving, G., Teran, J., and Fedkiw, R. 2004. Invertible finite elements for robust simulation of large deformation. Submitted to the Symposium on Computer Animation (SCA).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882359</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[James, D., and Fatahalian, K. 2003. Precomputing interactive dynamic deformable scenes. ACM Trans. Graph. (SIGGRAPH Proc.) 22, 879--887.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566621</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[James, D., and Pai, D. 2002. DyRT: Dynamic response textures for real time deformation simulation with graphics hardware. ACM Trans. Graph. (SIGGRAPH Proc.) 21, 582--585.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Jirasek, M., and Zimmermann, T. 2001. Embedded crack model: II. combination with smeared cracks. Int. J. Num. Meth. Eng. 50, 1291--1305.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>351688</ref_obj_id>
				<ref_obj_pid>351631</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Mazarak, O., Martins, C., and Amanatides, J. 1999. Animating exploding objects. In Proc. of Graph. Interface 1999, 211--218.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Molino, N., Bridson, R., Teran, J., and Fedkiw, R. 2003. A crystalline, red green strategy for meshing highly deformable objects with tetrahedra. In 12th Int. Meshing Roundtable, 103--114.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>710372</ref_obj_id>
				<ref_obj_pid>646923</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Mor, A., and Kanade, T. 2000. Modifying soft tissue models: progressive cutting with minimal new element creation. In MICCAI, 598--607.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1006087</ref_obj_id>
				<ref_obj_pid>1006058</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Muller, M., and Gross, M. 2004. Interactive virtual materials. In Grap. Interface.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>776361</ref_obj_id>
				<ref_obj_pid>776350</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Muller, M., McMillan, L., Dorsey, J., and Jagnow, R. 2001. Real-time simulation of deformation and fracture of stiff materials. In Comput. Anim. and Sim. '01, Proc. Eurographics Workshop, Eurographics Assoc., 99--111.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>545269</ref_obj_id>
				<ref_obj_pid>545261</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Muller, M., Dorsey, J., McMillan, L., Jagnow, R., and Cutler, B. 2002. Stable real-time deformations. In ACM SIGGRAPH Symp. on Comput. Anim., 49--54.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1009573</ref_obj_id>
				<ref_obj_pid>1009379</ref_obj_pid>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Muller, M., Teschner, M., and Gross, M. 2004. Physically-based simulation of objects represented by surface meshes. In Proc. Comput. Graph. Int., 156--165.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566585</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Museth, K., Breen, D., Whitaker, R., and Barr, A. 2002. Level set surface editing operators. ACM Trans. Graph. (SIGGRAPH Proc.) 21, 3, 330--338.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>351686</ref_obj_id>
				<ref_obj_pid>351631</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Neff, M., and Fiume, E. 1999. A visual model for blast waves and fracture. In Proc. of Graph. Interface 1999, 193--202.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>115248</ref_obj_id>
				<ref_obj_pid>115244</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Norton, A., Turk, G., Bacon, B., Gerth, J., and Sweeney, P. 1991. Animation of fracture by physical modeling. Vis. Comput. 7, 4, 210--219.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311550</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[O'Brien, J., and Hodgins, J. 1999. Graphical modeling and animation of brittle fracture. In Proc. SIGGRAPH 99, vol. 18, 137--146.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566579</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[O'Brien, J., Bargteil, A., and Hodgins, J. 2002. Graphical modeling of ductile fracture. ACM Trans. Graph. (SIGGRAPH Proc.) 21, 291--294.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Ortiz, M., and Pandolfi, A. 1999. Finite-deformation irreversible cohesive elements for three-dimensional crack-propagation analysis. Int. J. Num. Meth. Eng. 44, 1267--1282.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383264</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Perry, R., and Frisken, S. 2001. Kizamu: a system for sculpting digital characters. In Proc. SIGGRAPH 2001, vol. 20, 47--56.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Rankine, W. 1872. Applied mechanics. Charles Griffen and Company, London.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Sederberg, T., and Parry, S. 1986. Free-form deformations of solid geometric models. Comput. Graph. (SIGGRAPH Proc.), 151--160.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[Smith, J., Witkin, A., and Baraff, D. 2001. Fast and controllable simulation of the shattering of brittle objects. In Comput. Graphics Forum, D. Duke and R. Scopigno, Eds., vol. 20(2). Blackwell Publishing, 81--91.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[Tabiei, A., and Wu, J. 2003. Development of the DYNA3D simulation code with automated fracture procedure for brick elements. Int. J. Num. Meth. Eng. 57, 1979--2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>846285</ref_obj_id>
				<ref_obj_pid>846276</ref_obj_pid>
				<ref_seq_no>50</ref_seq_no>
				<ref_text><![CDATA[Teran, J., Salinas-Blemker, S., Ng, V., and Fedkiw, R. 2003. Finite volume methods for the simulation of skeletal muscle. In Proc. of the 2003 ACM SIGGRAPH/Eurographics Symp. on Comput. Anim., 68--74.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>51</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., and Fleischer, K. 1988. Deformable models. The Visual Computer, 4, 306--331.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378522</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>52</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., and Fleischer, K. 1988. Modeling inelastic deformation: viscoelasticity, plasticity, fracture. Comput. Graph. (SIGGRAPH Proc.), 269--278.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>53</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., Platt, J., Barr, A., and Fleischer, K. 1987. Elastically deformable models. Comput. Graph. (Proc. SIGGRAPH 87) 21, 4, 205--214.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882337</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>54</ref_seq_no>
				<ref_text><![CDATA[Treuille, A., McNamara, A., Popovic, Z., and Stam, J. 2003. Keyframe control of smoke simulations. ACM Trans. Graph. (SIGGRAPH Proc.) 22, 716--723.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>55</ref_seq_no>
				<ref_text><![CDATA[Ventura, G., Budyn, E., and Belytschko, T. 2003. Vector level sets for desription of propagating cracks in finite elements. Int. J. Num. Meth. Eng. 58, 1571--1592.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>56</ref_seq_no>
				<ref_text><![CDATA[Wells, G., and Sluys, L. 2001. A new method for modelling cohesive cracks using finite elements. Int. J. Num. Meth. Eng. 50, 2667--2682.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344801</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>57</ref_seq_no>
				<ref_text><![CDATA[Yngve, G., O'Brien, J., and Hodgins, J. 2000. Animating explosions. In Proc. SIGGRAPH 2000, vol. 19, 29--36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198575</article_id>
		<sort_key>5</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Cloth design and application]]></title>
		<page_from>5</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198575</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198575</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39061875</person_id>
				<author_profile_id><![CDATA[81322511277]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dongliang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Digital Fashion Ltd]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198576</section_id>
		<sort_key>7</sort_key>
		<section_seq_no>7</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Line drawings from 3D models]]></section_title>
		<section_page_from>7</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP40031690</person_id>
				<author_profile_id><![CDATA[81100203803]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Szymon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rusinkiewicz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198577</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Line drawings from 3D models]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198577</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198577</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40024811</person_id>
				<author_profile_id><![CDATA[81100203803]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Szymon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rusinkiewicz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Princeton University, Princeton, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15034370</person_id>
				<author_profile_id><![CDATA[81100499844]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Doug]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[DeCarlo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rutgers University, Piscataway, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P10635</person_id>
				<author_profile_id><![CDATA[81100576882]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Adam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Finkelstein]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Princeton University, Princeton, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>383286</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Agrawala, M., and Stolte, C. 2001. Rendering Effective Route Maps: Improving Usability Through Generalization. In Proceedings of ACM SIGGRAPH 2001, Computer Graphics Proceedings, Annual Conference Series, 241--250.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>806007</ref_obj_id>
				<ref_obj_pid>800196</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Appel, A. 1967. The notion of quantitative invisibility and the machine rendering of solids. In Proceedings of the 1967 22nd national conference, ACM Press, New York, NY, USA, 387--393.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1006082</ref_obj_id>
				<ref_obj_pid>1006058</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Ashikhmin, M. 2004. Image-space silhouettes for unprocessed models. In GI '04: Proceedings of the 2004 conference on Graphics interface, Canadian Human-Computer Communications Society, School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada, 195--202.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304999</ref_obj_id>
				<ref_obj_pid>304893</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Barequet, G., Duncan, C. A., Goodrich, M. T., Kumar, S., and Pop, M. 1999. Efficient perspective-accurate silhouette computation. In SCG '99: Proceedings of the fifteenth annual symposium on Computational geometry, ACM Press, New York, NY, USA, 417--418.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Barrow, H., and Tenenbaum, J. 1981. Interpreting Line Drawings as Three-Dimensional Surfaces. Artificial Intelligence 17, 75--116.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335604</ref_obj_id>
				<ref_obj_pid>335600</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Belhumeur, P. N., Kriegman, D. J., and Yuille, A. L. 1999. The Bas-Relief Ambiguity. International Journal of Computer Vision 35, 1, 33--44.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>792865</ref_obj_id>
				<ref_obj_pid>792757</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Belyaev, A., Pasko, A., and Kunii, T. 1998. Ridges and ravines on implicit surfaces. In Computer Graphics International 98, 530--535.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>826471</ref_obj_id>
				<ref_obj_pid>826028</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Benichou, F., and Elber, G. 1999. Output Sensitive Extraction of Silhouettes from Polygonal Geometry. In PG '99: Proceedings of the 7th Pacific Conference on Computer Graphics and Applications, IEEE Computer Society, Washington, DC, USA, 60.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Bremer, D., and Hughes, J. 1998. Rapid approximate silhouette rendering of implicit surfaces. In Implicit Surfaces 98, 155--164.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1037235</ref_obj_id>
				<ref_obj_pid>1037210</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Brosz, J., Samavati, F., and Sousa, M. C. 2004. Silhouette rendering based on stability measurement. In SCCG '04: Proceedings of the 20th spring conference on Computer graphics, ACM Press, New York, NY, USA, 157--167.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073222</ref_obj_id>
				<ref_obj_pid>1186822</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Burns, M., Klawe, J., Rusinkiewicz, S., Finkelstein, A., and DeCarlo, D. 2005. Line Drawings from Volume Data. In SIGGRAPH '05: Proceedings of the 32nd annual conference on Computer graphics and interactive techniques, ACM Press, New York, NY, USA. To appear.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Cs&#233;bfalvi, B., Mroz, L., Hauser, H., K&#246;nig, A., and Gr&#246;ller, E. 2001. Fast Visualization of Object Contours by Non-Photorealistic Volume Rendering. In Eurographics 01.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566650</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[DeCarlo, D., and Santella, A. 2002. Stylization and Abstraction of Photographs. ACM Transactions on Graphics 21, 3 (July), 769--776.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882354</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[DeCarlo, D., Finkelstein, A., Rusinkiewicz, S., and Santella, A. 2003. Suggestive contours for conveying shape. ACM Trans. Graph. 22, 3, 848--855.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>987661</ref_obj_id>
				<ref_obj_pid>987657</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[DeCarlo, D., Finkelstein, A., and Rusinkiewicz, S. 2004. Interactive rendering of suggestive contours with temporal coherence. In NPAR '04: Proceedings of the 3rd international symposium on Non-photorealistic animation and rendering, ACM Press, New York, NY, USA, 15--145.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344792</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Deussen, O., and Strothotte, T. 2000. Computer-generated pen-and-ink illustration of trees. In SIGGRAPH '00: Proceedings of the 27th annual conference on Computer graphics and interactive techniques, ACM Press/Addison-Wesley Publishing Co., New York, NY, USA, 13--18.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>858657</ref_obj_id>
				<ref_obj_pid>858619</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Dong, F., Clapworthy, G. J., Lin, H., and Krokos, M. A. 2003. Nonphotorealistic Rendering of Medical Volume Data. IEEE Comput. Graph. Appl. 23, 4, 44--52.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91422</ref_obj_id>
				<ref_obj_pid>91385</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Dooley, D., and Cohen, M. F. 1990. Automatic illustration of 3D geometric models: lines. In SI3D '90: Proceedings of the 1990 symposium on Interactive 3D graphics, ACM Press, New York, NY, USA, 77--82.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732296</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Durand, F., Ostromoukhov, V., Miller, M., Duranleau, F., and Dorsey, J. 2001. Decoupling Strokes and High-Level Attributes for Interactive Traditional Drawing. In Rendering Techniques 2001: 12th Eurographics Workshop on Rendering, 71--82.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375241</ref_obj_id>
				<ref_obj_pid>375213</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Ebert, D., and Rheingans, P. 2000. Volume illustration: non-photorealistic rendering of volume models. In VIS '00: Proceedings of the conference on Visualization '00, IEEE Computer Society Press, Los Alamitos, CA, USA, 195--202.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97890</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Elber, G., and Cohen, E. 1990. Hidden curve removal for free form surfaces. In SIGGRAPH '90: Proceedings of the 17th annual conference on Computer graphics and interactive techniques, ACM Press, New York, NY, USA, 95--104.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614310</ref_obj_id>
				<ref_obj_pid>614259</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Elber, G. 1995. Line Art Rendering via a Coverage of Isoparametric Curves. IEEE Transactions on Visualization and Computer Graphics 1, 3, 231--239.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Elber, G. 1995. Line illustrations in computer graphics. The Visual Computer 11, 6, 290--296.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614393</ref_obj_id>
				<ref_obj_pid>614269</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Elber, G. 1998. Line Art Illustrations of Parametric and Implicit Forms. IEEE Transactions on Visualization and Computer Graphics 4, 1, 71--81.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Elber, G. 1999. Interactive Line Art Rendering of Freeform Surfaces. Computer Graphics Forum 18, 3, 1--1.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>340922</ref_obj_id>
				<ref_obj_pid>340916</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Girshick, A., Interrante, V., Haker, S., and Lemoine, T. 2000. Line direction matters: an argument for the use of principal directions in 3D line drawings. In NPAR '00: Proceedings of the 1st international symposium on Non-photorealistic animation and rendering, ACM Press, New York, NY, USA, 43--52.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280950</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Gooch, A., Gooch, B., Shirley, P., and Cohen, E. 1998. A nonphotorealistic lighting model for automatic technical illustration. In SIGGRAPH '98: Proceedings of the 25th annual conference on Computer graphics and interactive techniques, ACM Press, New York, NY, USA, 447--452.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300526</ref_obj_id>
				<ref_obj_pid>300523</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Gooch, B., Sloan, P.-P. J., Gooch, A., Shirley, P., and Riesenfeld, R. 1999. Interactive technical illustration. In SI3D '99: Proceedings of the 1999 symposium on Interactive 3D graphics, ACM Press, New York, NY, USA, 31--38.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>558817</ref_obj_id>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Gooch, B., and Gooch, A. 2001. Non-Photorealistic Rendering. A K Peters.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>966133</ref_obj_id>
				<ref_obj_pid>966131</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Gooch, B., Reinhard, E., and Gooch, A. 2004. Human facial illustrations: Creation and psychophysical evaluation. ACM Trans. Graph. 23, 1, 27--44.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383539</ref_obj_id>
				<ref_obj_pid>2383533</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Grabli, S., Turquin, E., Durand, F., and Sillion, F. 2004. Programmable Style for NPR Line Drawing. In Eurographics Symposium on Rendering '04.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1026054</ref_obj_id>
				<ref_obj_pid>1025128</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Grabli, S., Durand, F., and Sillion, F. 2004. Density Measure for Line-Drawing Simplification. In Proceedings of Pacific Graphics.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>856728</ref_obj_id>
				<ref_obj_pid>851039</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Hamel, J., Schlechtweg, S., and Strothotte, T. 1998. An Approach to Visualizing Transparency in Computer-Generated Line Drawings. In IV '98: Proceedings of the International Conference on Information Visualisation, IEEE Computer Society, Washington, DC, USA, 151.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>345074</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Hertzmann, A., and Zorin, D. 2000. Illustrating smooth surfaces. In SIGGRAPH '00: Proceedings of the 27th annual conference on Computer graphics and interactive techniques, ACM Press/Addison-Wesley Publishing Co., New York, NY, USA, 517--526.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>873338</ref_obj_id>
				<ref_obj_pid>872749</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Hertzmann, A. 2001. Paint by relaxation. In Computer Graphics International 2001, 47--54.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192186</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Hsu, S. C., and Lee, I. H. H. 1994. Drawing and animation using skeletal strokes. In SIGGRAPH '94: Proceedings of the 21st annual conference on Computer graphics and interactive techniques, ACM Press, New York, NY, USA, 109--118.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>833836</ref_obj_id>
				<ref_obj_pid>832271</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Interrante, V., Fuchs, H., and Pizer, S. 1995. Enhancing Transparent Skin Surfaces with Ridge and Valley Lines. In VIS '95: Proceedings of the 6th conference on Visualization '95, IEEE Computer Society, Washington, DC, USA, 52.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>245567</ref_obj_id>
				<ref_obj_pid>244979</ref_obj_pid>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Interrante, V., Fuchs, H., and Pizer, S. 1996. Illustrating transparent surfaces with curvature-directed strokes. In VIS '96: Proceedings of the 7th conference on Visualization '96, IEEE Computer Society Press, Los Alamitos, CA, USA, 211--ff.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Isenberg, T., Halper, N., and Strothotte, T. 2002. Stylizing Silhouettes at Interactive Rates: From Silhouette Edges to Silhouette Strokes. Computer Graphics Forum 21, 3, 249--249.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>858656</ref_obj_id>
				<ref_obj_pid>858619</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Isenberg, T., Freudenberg, B., Halper, N., Schlechtweg, S., and Strothotte, T. 2003. A Developer's Guide to Silhouette Algorithms for Polygonal Models. IEEE Comput. Graph. Appl. 23, 4, 28--37.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Itti, L., and Koch, C. 2000. A Saliency-based search mechanism for overt and covert shifts of visual attention. Vision Research 40, 1489--1506.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566648</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Kalnins, R. D., Markosian, L., Meier, B. J., Kowalski, M. A., Lee, J. C., Davidson, P. L., Webb, M., Hughes, J. F., and Finkelstein, A. 2002. WYSIWYG NPR: drawing strokes directly on 3D models. In SIGGRAPH '02: Proceedings of the 29th annual conference on Computer graphics and interactive techniques, ACM Press, New York, NY, USA, 755--762.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882355</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Kalnins, R. D., Davidson, P. L., Markosian, L., and Finkelstein, A. 2003. Coherent stylized silhouettes. ACM Trans. Graph. 22, 3, 856--861.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1023383</ref_obj_id>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Kalnins, R. D. 2004. WYSIWYG NPR: Interactive Stylization for Stroke-Based Rendering of 3D Animation. PhD thesis, Princeton University.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1081511</ref_obj_id>
				<ref_obj_pid>1081432</ref_obj_pid>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Kindlmann, G., Whitaker, R., Tasdizen, T., and Moller, T. 2003. Curvature-based transfer functions for direct volume rendering: methods and applications. In IEEE Visualization 2003, 513--520.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Knill, D. C. 1992. Perception of surface contours and surface shape: from computation to psychophysics. Journal of the Optical Society of America A 9, 9, 1449--1464.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Knill, D. C. 2001. Contour into texture: information content of surface contours and texture flow. Journal of the Optical Society of America A 18, 1, 12--35.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[Koenderink, J. J., and van Doorn, A. J. 1982. The Shape of Smooth Objects and the Way Contours End. Perception 11, 129--137.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[Koenderink, J. J. 1984. What does the occluding contour tell us about solid shape? Perception 13, 321--330.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>77527</ref_obj_id>
				<ref_seq_no>50</ref_seq_no>
				<ref_text><![CDATA[Koenderink, J. J. 1990. Solid Shape. MIT press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>51</ref_seq_no>
				<ref_text><![CDATA[Koenderink, J. J., van Doorn, A., Christou, C., and Lappin, J. 1996. Shape constancy in pictorial relief. Perception 25, 155--164.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>52</ref_seq_no>
				<ref_text><![CDATA[Koenderink, J. J., and van Doorn, A. 1998. The Structure of Relief. Advances in Imaging and Electron Physics 103, 65--150.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>53</ref_seq_no>
				<ref_text><![CDATA[Koenderink, J. J., van Doorn, A. J., Kappers, A. M., and Todd, J. T. 2001. Ambiguity and the 'mental eye' in pictorial relief. Perception 30, 431--448.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>602131</ref_obj_id>
				<ref_obj_pid>602099</ref_obj_pid>
				<ref_seq_no>54</ref_seq_no>
				<ref_text><![CDATA[Lu, A., Morris, C. J., Ebert, D. S., Rheingans, P., and Hansen, C. 2002. Non-photorealistic volume rendering using stippling techniques. In VIS '02: Proceedings of the conference on Visualization '02, IEEE Computer Society, Washington, DC, USA, 211--218.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>508542</ref_obj_id>
				<ref_obj_pid>508530</ref_obj_pid>
				<ref_seq_no>55</ref_seq_no>
				<ref_text><![CDATA[Lum, E. B., and Ma, K.-L. 2002. Hardware-accelerated parallel non-photorealistic volume rendering. In NPAR '02: Proceedings of the 2nd international symposium on Non-photorealistic animation and rendering, ACM Press, New York, NY, USA, 67--ff.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>267085</ref_obj_id>
				<ref_obj_pid>266989</ref_obj_pid>
				<ref_seq_no>56</ref_seq_no>
				<ref_text><![CDATA[Ma, K.-L., and Interrante, V. 1997. Extracting feature lines from 3D unstructured grids. In VIS '97: Proceedings of the 8th conference on Visualization '97, IEEE Computer Society Press, Los Alamitos, CA, USA, 285--ff.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>57</ref_seq_no>
				<ref_text><![CDATA[Malik, J. 1987. Interpreting Line Drawings of Curved Objects. International Journal of Computer Vision 1, 1, 73--103.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258894</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>58</ref_seq_no>
				<ref_text><![CDATA[Markosian, L., Kowalski, M. A., Goldstein, D., Trychin, S. J., Hughes, J. F., and Bourdev, L. D. 1997. Real-time nonphotorealistic rendering. In SIGGRAPH '97: Proceedings of the 24th annual conference on Computer graphics and interactive techniques, ACM Press/Addison-Wesley Publishing Co., New York, NY, USA, 415--420.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>59</ref_seq_no>
				<ref_text><![CDATA[Martin, D., Fekete, J., and Torres, J. C. 2002. Flattening 3D objects using silhouettes. Computer Graphics Forum 21, 3, 239--239.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>60</ref_seq_no>
				<ref_text><![CDATA[Masuch, M., Schlechtweg, S., and Schnwlder, B. 1997. dali! Drawing Animated Lines! In Simulation and Animation 97, 87--96.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>61</ref_seq_no>
				<ref_text><![CDATA[Masuch, M., Schuhmann, L., and Schlechtweg, S. 1998. Animating Frame-To-Frame-Coherent Line Drawings for Illustrated Purposes. In Simulation and Animation 98, 101--112.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>856773</ref_obj_id>
				<ref_obj_pid>851039</ref_obj_pid>
				<ref_seq_no>62</ref_seq_no>
				<ref_text><![CDATA[Masuch, M., and Strothotte, T. 1998. Visualising Ancient Architecture using Animating Line Drawings. In IV '98: Proceedings of the International Conference on Information Visualisation, IEEE Computer Society, Washington, DC, USA, 261.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>987663</ref_obj_id>
				<ref_obj_pid>987657</ref_obj_pid>
				<ref_seq_no>63</ref_seq_no>
				<ref_text><![CDATA[McGuire, M., and Hughes, J. F. 2004. Hardware-determined feature edges. In NPAR '04: Proceedings of the 3rd international symposium on Non-photorealistic animation and rendering, ACM Press, New York, NY, USA, 35--147.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>64</ref_seq_no>
				<ref_text><![CDATA[Nagy, Z., and Klein, R. 2004. High-Quality Silhouette Illustration for Texture-Based Volume Rendering. In WSCG '04.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>340920</ref_obj_id>
				<ref_obj_pid>340916</ref_obj_pid>
				<ref_seq_no>65</ref_seq_no>
				<ref_text><![CDATA[Northrup, J. D., and Markosian, L. 2000. Artistic silhouettes: a hybrid approach. In NPAR '00: Proceedings of the 1st international symposium on Non-photorealistic animation and rendering, ACM Press, New York, NY, USA, 31--37.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015768</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>66</ref_seq_no>
				<ref_text><![CDATA[Ohtake, Y., Belyaev, A., and Seidel, H.-P. 2004. Ridge-valley lines on meshes via implicit surface fitting. ACM Trans. Graph. 23, 3.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>67</ref_seq_no>
				<ref_text><![CDATA[Page, D. L., Koschan, A., Sun, Y., Paik, J., and Abidi, A. 2001. Robust Crease Detection and Curvature Estimation of Piecewise Smooth Surfaces from Triangle Mesh Approximations Using Normal Voting. In Proc. Conference on Computer Vision and Pattern Recognition.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>68</ref_seq_no>
				<ref_text><![CDATA[Pauly, M., Keiser, R., and Gross, M. 2003. Multi-Scale Feature Extraction on Point-Sampled Models. In Proc. Eurographics.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>69</ref_seq_no>
				<ref_text><![CDATA[Phillips, F., Todd, J. T., Koenderink, J. J., and Kappers, A. M. 2003. Perceptual representation of visible surfaces. Perception and Psychophysics 65, 5, 747--762.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383328</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>70</ref_seq_no>
				<ref_text><![CDATA[Praun, E., Hoppe, H., Webb, M., and Finkelstein, A. 2001. Realtime hatching. In SIGGRAPH '01: Proceedings of the 28th annual conference on Computer graphics and interactive techniques, ACM Press, New York, NY, USA, 581.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300539</ref_obj_id>
				<ref_obj_pid>300523</ref_obj_pid>
				<ref_seq_no>71</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., and Cohen, M. 1999. Image precision silhouette edges. In SI3D '99: Proceedings of the 1999 symposium on Interactive 3D graphics, ACM Press, New York, NY, USA, 135--140.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383525</ref_obj_id>
				<ref_obj_pid>383507</ref_obj_pid>
				<ref_seq_no>72</ref_seq_no>
				<ref_text><![CDATA[Raskar, R. 2001. Hardware Support for Non-photorealistic Rendering. In Proc. Graphics Hardware.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015779</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>73</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., han Tan, K., Feris, R., Yu, J., and Turk, M. 2004. Non-photorealistic Camera: Depth Edge Detection and Stylized Rendering using Multi-Flash Imaging. ACM Trans. Graph. 23, 3.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>74</ref_seq_no>
				<ref_text><![CDATA[Rossignac, J., and van Emmerik, M. 1992. Hidden Contours on a Framebuffer. Proc. of 7th Workshop on Computer Graphics Hardware.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>826529</ref_obj_id>
				<ref_obj_pid>826029</ref_obj_pid>
				<ref_seq_no>75</ref_seq_no>
				<ref_text><![CDATA[Rossl, C., and Kobbelt, L. 2000. Line-art rendering of 3D-models. In Pacific Graphics 00, 87--96.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97901</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>76</ref_seq_no>
				<ref_text><![CDATA[Saito, T., and Takahashi, T. 1990. Comprehensible rendering of 3D shapes. In SIGGRAPH '90: Proceedings of the 17th annual conference on Computer graphics and interactive techniques, ACM Press, New York, NY, USA, 197--206.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>197974</ref_obj_id>
				<ref_obj_pid>197938</ref_obj_pid>
				<ref_seq_no>77</ref_seq_no>
				<ref_text><![CDATA[Saito, T. 1994. Real-time previewing for volume visualization. In VVS '94: Proceedings of the 1994 symposium on Volume visualization, ACM Press, New York, NY, USA, 99--106.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192185</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>78</ref_seq_no>
				<ref_text><![CDATA[Salisbury, M. P., Anderson, S. E., Barzel, R., and Salesin, D. H. 1994. Interactive pen-and-ink illustration. In SIGGRAPH '94: Proceedings of the 21st annual conference on Computer graphics and interactive techniques, ACM Press, New York, NY, USA, 101--108.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237286</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>79</ref_seq_no>
				<ref_text><![CDATA[Salisbury, M., Anderson, C., Lischinski, D., and Salesin, D. H. 1996. Scale-dependent reproduction of pen-and-ink illustrations. In SIGGRAPH '96: Proceedings of the 23rd annual conference on Computer graphics and interactive techniques, ACM Press, New York, NY, USA, 461--468.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344935</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>80</ref_seq_no>
				<ref_text><![CDATA[Sander, P. V., Gu, X., Gortler, S. J., Hoppe, H., and Snyder, J. 2000. Silhouette clipping. In SIGGRAPH '00: Proceedings of the 27th annual conference on Computer graphics and interactive techniques, ACM Press/Addison-Wesley Publishing Co., New York, NY, USA, 327--334.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>987669</ref_obj_id>
				<ref_obj_pid>987657</ref_obj_pid>
				<ref_seq_no>81</ref_seq_no>
				<ref_text><![CDATA[Santella, A., and DeCarlo, D. 2004. Visual interest and NPR: an evaluation and manifesto. In NPAR 2004, 71--78.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1008967</ref_obj_id>
				<ref_obj_pid>1008963</ref_obj_pid>
				<ref_seq_no>82</ref_seq_no>
				<ref_text><![CDATA[Schein, S., and Elber, G. 2004. Adaptive extraction and visualization of silhouette curves from volumetric datasets. Vis. Comput. 20, 4, 243--252.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>83</ref_seq_no>
				<ref_text><![CDATA[Sousa, M. C., Foster, K., Wyvill, B., and Samavati, F. 2003. Precise Ink Drawing of 3D Models. Computer Graphics Forum 22, 3, 369--369.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>84</ref_seq_no>
				<ref_text><![CDATA[Sousa, M. C., and Prusinkiewicz, P. 2003. A Few Good Lines: Suggestive Drawing of 3D Models. Computer Graphics Forum 22, 3, 381--381.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>85</ref_seq_no>
				<ref_text><![CDATA[Stevens, K. A. 1981. The Visual Interpretation of Surface Contours. Artificial Intelligence 17, 47--73.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>544522</ref_obj_id>
				<ref_seq_no>86</ref_seq_no>
				<ref_text><![CDATA[Strothotte, T., and Schlechtweg, S. 2002. Non-Photorealistic Computer Graphics. Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>246268</ref_obj_id>
				<ref_obj_pid>246267</ref_obj_pid>
				<ref_seq_no>87</ref_seq_no>
				<ref_text><![CDATA[Thirion, J.-P., and Gourdon, A. 1996. The 3D Marching Lines Algorithm. Graphical Models and Image Processing 58, 6 (Nov.), 503--509.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375243</ref_obj_id>
				<ref_obj_pid>375213</ref_obj_pid>
				<ref_seq_no>88</ref_seq_no>
				<ref_text><![CDATA[Treavett, S. M. F., and Chen, M. 2000. Pen-and-Ink rendering in volume visualisation. In VIS '00: Proceedings of the conference on Visualization '00, IEEE Computer Society Press, Los Alamitos, CA, USA, 203--210.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>89</ref_seq_no>
				<ref_text><![CDATA[Waltz, D. L. 1975. Understanding Line Drawings of Scenes with Shadows. In The Psychology of Computer Vision, P. Winston, Ed. McGrawHill, 19--92.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>90</ref_seq_no>
				<ref_text><![CDATA[Watanabe, K., and Belyaev, A. G. 2001. Detection of Salient Curvature Features on Polygonal Surfaces. Computer Graphics Forum (Proc. Eurographics 2001) 20, 3.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>987674</ref_obj_id>
				<ref_obj_pid>987657</ref_obj_pid>
				<ref_seq_no>91</ref_seq_no>
				<ref_text><![CDATA[Wilson, B., and Ma, K.-L. 2004. Rendering complexity in computer-generated pen-and-ink illustrations. In NPAR '04: Proceedings of the 3rd international symposium on Non-photorealistic animation and rendering, ACM Press, New York, NY, USA, 129--137.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192184</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>92</ref_seq_no>
				<ref_text><![CDATA[Winkenbach, G., and Salesin, D. H. 1994. Computer-generated pen-and-ink illustration. In SIGGRAPH '94: Proceedings of the 21st annual conference on Computer graphics and interactive techniques, ACM Press, New York, NY, USA, 91--100.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237287</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>93</ref_seq_no>
				<ref_text><![CDATA[Winkenbach, G., and Salesin, D. H. 1996. Rendering parametric surfaces in pen and ink. In SIGGRAPH '96: Proceedings of the 23rd annual conference on Computer graphics and interactive techniques, ACM Press, New York, NY, USA, 469--476.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2386335</ref_obj_id>
				<ref_obj_pid>2386332</ref_obj_pid>
				<ref_seq_no>94</ref_seq_no>
				<ref_text><![CDATA[Xu, H., Nguen, M., Yuan, X., and Chen, B. 2004. Interactive Silhouette Rendering for Point-Based Models. In Proc. Eurographics Symposium on Point-Based Graphics.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>988876</ref_obj_id>
				<ref_obj_pid>988834</ref_obj_pid>
				<ref_seq_no>95</ref_seq_no>
				<ref_text><![CDATA[Zakaria, N., and Seidel, H.-P. 2004. Interactive stylized silhouette for point-sampled geometry. In GRAPHITE '04: Proceedings of the 2nd international conference on Computer graphics and interactive techniques in Australasia and Southe East Asia, ACM Press, New York, NY, USA, 242--249.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>96</ref_seq_no>
				<ref_text><![CDATA[Zander, J., Isenberg, T., Schlechtweg, S., and Strothotte, T. 2004. High Quality Hatching. Computer Graphics Forum 23, 3, 421--421.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198578</section_id>
		<sort_key>8</sort_key>
		<section_seq_no>8</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[The web as a procedural sketchbook]]></section_title>
		<section_page_from>8</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP31058609</person_id>
				<author_profile_id><![CDATA[81100250413]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ken]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Perlin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198579</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[The web as a procedural sketchbook]]></title>
		<subtitle><![CDATA[Copyright restrictions prevent ACM from providing the full text for this work.]]></subtitle>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198579</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198579</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP31058570</person_id>
				<author_profile_id><![CDATA[81100250413]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ken]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Perlin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	</section>
	<section>
		<section_id>1198580</section_id>
		<sort_key>9</sort_key>
		<section_seq_no>9</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Digital face cloning]]></section_title>
		<section_page_from>9</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP39023831</person_id>
				<author_profile_id><![CDATA[81100026067]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fred]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pighin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[USC Institute for Creative Technologies]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>PP37032274</person_id>
				<author_profile_id><![CDATA[81409595937]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Lewis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Graphics Primitives]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198581</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Introduction]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198581</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198581</url>
		<abstract>
			<par><![CDATA[By far the most challenging aspect of a photoreal actor is the creation of a digital face that can stand up to close scrutiny. The human face is an extremely complex biomechanical system that is very difficult to model. Human skin has unique reflectance properties that are challenging to simulate accurately. Moreover the face can convey subtle emotions through minute motions. We do not know the control mechanism of these motions. All these issues combine to make the human face one of the most challenging object to model using computer graphics.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39023808</person_id>
				<author_profile_id><![CDATA[81100026067]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fr&#233;d&#233;ric]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pighin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP37031227</person_id>
				<author_profile_id><![CDATA[81409595942]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Lewis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[V. Blanz, C. Basso, T. Poggio, and T. Vetter. Reanimating faces in images and video. In Proc. of Eurographics, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>965470</ref_obj_id>
				<ref_obj_pid>965400</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[George Borshukov and J. P. Lewis. Realistic human face rendering for "the matrix reloaded". In Proceedings of SIGGRAPH conference Sketches & applications. ACM Press, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>965469</ref_obj_id>
				<ref_obj_pid>965400</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[George Borshukov, Dan Piponi, Oystein Larsen, J. P. Lewis, and Christina Tempelaar-Lietz. Universal capture: image-based facial animation for "the matrix reloaded". In Proceedings of SIGGRAPH conference on Sketches & applications. ACM Press, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344855</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Paul Debevec, Tim Hawkins, Chris Tchou, Haarm-Pieter Duiker, Westley Sarokin, and Mark Sagar. Acquiring the reflectance field of a human face. In SIGGRAPH 2000 Conference Proceedings, pages 35--42. ACM SIGGRAPH, July 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[P. Ekman and W. V. Friesen. Unmasking the face. A guide to recognizing emotions from facial clues. Prentice-Hall, Inc., Englewood Cliffs, New Jersey, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280822</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[B. Guenter, C. Grimm, D. Wood, H. Malvar, and F. Pighin. Making faces. In SIGGRAPH 98 Conference Proceedings, pages 55--66. ACM SIGGRAPH, July 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Haber, K. Khler, I. Albrecht, H. Yamauchi, and H.-P. Seidel. Face to face: From real humans to realistic facial animation. In Proceedings Israel-Korea Binational Conference on Geometrical Modeling and Computer Graphics, pages 37--46, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383575</ref_obj_id>
				<ref_obj_pid>2383533</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Tim Hawkins, Andreas Wenger, Chris Tchou, Andrew Gardner, Fredrik G&#246;ransson, and Paul Debevec. Animatable facial reflectance fields. In Rendering Techniques 2004: 15th Eurographics Workshop on Rendering, pages 309--320, June 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1198584</ref_obj_id>
				<ref_obj_pid>1198555</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Christophe Hery. Implementing a skin bssrdf (or several). SIGGRAPH course notes: Renderman, Theory and Practice, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218407</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Y. Lee, D. Terzopoulos, and K. Waters. Realistic modeling for facial animation. In SIGGRAPH 95 Conference Proceedings, pages 55--62. ACM SIGGRAPH, August 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Y. C. Lee, D. Terzopoulos, and K. Waters. Constructing physics-based facial models of individuals. In Proceedings of Graphics Interface 93, pages 1--8, May 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732140</ref_obj_id>
				<ref_obj_pid>647652</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Stephen Marschner, Brian Guenter, and Sashi Raghupathy. Modeling and rendering for realistic facial animation. In Rendering Techniques 2000: 11th Eurographics Workshop on Rendering, pages 231--242, June 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383829</ref_obj_id>
				<ref_obj_pid>2383815</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Stephen R. Marschner, Stephen H. Westin, Eric P. F. Lafortune, Kenneth E. Torrance, and Donald P. Greenberg. Image-based brdf measurement including human skin. In Eurographics Rendering Workshop 1999, June 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569955</ref_obj_id>
				<ref_obj_pid>800193</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[F. I. Parke. Computer generated animation of faces. Proceedings ACM annual conference., August 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>907312</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[F. I. Parke. A parametric model for human faces. PhD thesis, University of Utah, Salt Lake City, Utah, December 1974. UTEC-CSc-75-047.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280825</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[F. Pighin, J. Hecker, D. Lischinski, R. Szeliski, and D. H. Salesin. Synthesizing realistic facial expressions from photographs. In SIGGRAPH 98 Conference Proceedings, pages 75--84. ACM SIGGRAPH, July 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[F. Pighin, R. Szeliski, and D. H. Salesin. Resynthesizing facial animation through 3d model-based tracking. In Proceedings, International Conference on Computer Vision, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[B. Raitt. The making of Gollum. Presentation at U. Southern California Institute for Creative Technologies's Frontiers of Facial Animation Workshop, August 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1186371</ref_obj_id>
				<ref_obj_pid>1186223</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Mark Sagar. Reflectance field rendering of human faces for "spider-man 2". In Proceedings of SIGGRAPH conference Sketches & applications. ACM Press, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[D. Terzopoulos and K. Waters. Techniques for realistic facial modeling and animation. In Nadia Magnenat Thalmann and Daniel Thalmann, editors, Computer Animation 91, pages 59--74. Springer-Verlag, Tokyo, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073209</ref_obj_id>
				<ref_obj_pid>1186822</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[D. Vlasic, M. Brand, H. Pfister, and J. Popovic. Face transfer with multilinear models. In Proceedings of ACM SIGGRAPH 2005. ACM Press/Addison-Wesley Publishing Co., 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37405</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[K. Waters. A muscle model for animating three-dimensional facial expression. In SIGGRAPH 87 Conference Proceedings), volume 21, pages 17--24. ACM SIGGRAPH, July 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97906</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[L. Williams. Performance-driven facial animation. In SIGGRAPH 90 Conference Proceedings, volume 24, pages 235--242, August 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015759</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Li Zhang, Noah Snavely, Brian Curless, and Steven M. Seitz. Spacetime faces: high resolution capture for modeling and animation. ACM Trans. Graph., 23(3):548--558, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198582</article_id>
		<sort_key>2</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Modeling and digitizing human facial reflectance]]></title>
		<page_from>2</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198582</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198582</url>
		<abstract>
			<par><![CDATA[This section of the course describes techniques for modeling and digitizing the reflectance properties of faces and using these properties to create realistic renderings of faces under new lighting conditions, from new viewing angles, and with different expressions and motion.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P221188</person_id>
				<author_profile_id><![CDATA[81100086933]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Debevec]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[USC Institute for Creative Technologies]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>2383829</ref_obj_id>
				<ref_obj_pid>2383815</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Image-based BRDF Measurement Including Human Skin. Stephen R. Marschner, Stephen H. Westin, Eric P. F. Lafortune, Kenneth E. Torrance, Donald P. Greenberg. Eurographics Rendering Workshop 1999. 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344855</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Acquiring the Reflectance Field of a Human Face. Paul Debevec, Tim Hawkins, Chris Tchou, Haarm-Pieter Duiker, Westley Sarokin, Mark Sagar. Proceedings of ACM SIGGRAPH 2000. pp. 145--156, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383575</ref_obj_id>
				<ref_obj_pid>2383533</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Animatable Facial Reflectance Fields. Tim Hawkins, Andreas Wenger, Chris Tchou, Andrew Gardner, Fredrik Goransson, Paul Debevec. 2004 Eurographics Symposium on Rendering. 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166139</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Reflection from Layered Surfaces Due to Subsurface Scattering Pat Hanrahan, Wolfgang Krueger. Proceedings of SIGGRAPH 93. pp. 165--174, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383319</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A Practical Model for Subsurface Light Transport. Henrik Wann Jensen, Stephen R. Marschner, Marc Levoy, Pat Hanrahan. Proceedings of ACM SIGGRAPH 2001. pp. 511--518, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882345</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Light Scattering From Human Hair Fibers. Stephen R. Marschner, Henrik Wann Jensen, Mike Cammarano, Steve Worley, Pat Hanrahan. ACM Transactions on Graphics. 22(3), pp. 780--791, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073258</ref_obj_id>
				<ref_obj_pid>1186822</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Andreas Wenger, Andrew Gardner, Chris Tchou, Jonas Unger, Tim Hawkins, and Paul Debevec. Performance Relighting and Reflectance Transformation with Time-Multiplexed Illumination. Proc. SIGGRAPH 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198583</article_id>
		<sort_key>3</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Cross-mapping]]></title>
		<page_from>3</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198583</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198583</url>
		<abstract>
			<par><![CDATA[When done correctly, a digitally recorded facial performance is an accurate measurement of the performer's motions. As such it reflects all the idiosyncrasies of the performer. However, often the digital character that needs to be animated is not a digital replica of the performer. In this case, the decision to use performance capture might be motivated by cost issues, the desire to use a favorite actor regardless of the intended character, or the desire to portray an older, younger, or otherwise altered version of the actor. The many incarnations of Tom Hanks in <i>Polar Express</i> illustrate several of these scenarios.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP37031227</person_id>
				<author_profile_id><![CDATA[81409595942]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Lewis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39023808</person_id>
				<author_profile_id><![CDATA[81100026067]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Fr&#233;d&#233;ric]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pighin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>340929</ref_obj_id>
				<ref_obj_pid>340916</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Ian Buck, Adam Finkelstein, Charles Jacobs, Allison Klein, David H. Salesin, Joshua Seims, Richard Szeliski, and Kentaro Toyama. Performance-driven hand-drawn animation. In NPAR 2000: First International Symposium on Non Photorealistic Animation and Rendering, pages 101--108, June 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>945834</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Martin D. Buhmann. Radial Basis Functions: Theory and Implementations. Cambridge University Press, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Byoungwon Choe, Hanook Lee, and Hyeong-Seok Ko. Performance-driven muscle-based facial animation. The Journal of Visualization and Computer Animation, 12(2):67--79, May 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[E. Chuang and C. Bregler. Performance driven facial animation using blendshape interpolation. CSTR-2002-02, Department of Computer Science, Stanford University, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>826611</ref_obj_id>
				<ref_obj_pid>826030</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[E. Chuang, H. Deshpande, and C. Bregler. Facial expression space learning. In Proceedings of Pacific Graphics, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Covell and C. Bregler. Eigen-points. In Proc. IEEE International Conference on Image Processing, pages vol 3 p 471--474, 1996. Lausanne, Switzerland, Sept 16--19 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882285</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Mira Dontcheva, Gary Yngve, and Zoran Popovi&#263;. Layered acting for character animation. ACM Transactions on Graphics, 22(3):409--416, July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383575</ref_obj_id>
				<ref_obj_pid>2383533</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Tim Hawkins, Andreas Wenger, Chris Tchou, Andrew Gardner, Fredrik G&#246;ransson, and Paul Debevec. Animatable facial reflectance fields. In Rendering Techniques 2004: 15th Eurographics Workshop on Rendering, pages 309--320, June 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502422</ref_obj_id>
				<ref_obj_pid>502390</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Noh, D. Fidaleo, and U. Neumann. Animated deformations with radial basis functions. In ACM Symposium on Virtual Realisty Software and Technology, pages 166--174, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280825</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[F. Pighin, J. Hecker, D. Lischinski, R. Szeliski, and D. H. Salesin. Synthesizing realistic facial expressions from photographs. In SIGGRAPH 98 Conference Proceedings, pages 75--84. ACM SIGGRAPH, July 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Y. Wang, X. Huang, C.-S. Lee, S. Zhang, D. Samaras, D. Metaxas, A. Elgammal, and P. Huang. High resolution acquisition, learning, and transfer of dynamic 3-d facial expressions. In Eurographics, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383290</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Jun yong Noh and Ulrich Neumann. Expression cloning. In Proceedings of ACM SIGGRAPH 2001, Computer Graphics Proceedings, Annual Conference Series, pages 277--288, August 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198584</article_id>
		<sort_key>4</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Implementing a skin BSSRDF]]></title>
		<subtitle><![CDATA[(or several...)]]></subtitle>
		<page_from>4</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198584</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198584</url>
		<abstract>
			<par><![CDATA[In the seminal paper from 2001: <i>A Practical Model for Subsurface Light Transport</i> ([Jensen '01]), Henrik Wann Jensen et al employed the concept of a BSSRDF (a bidirectional surface scattering distribution function) as a means to overcome the limitations of BRDFs.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40031480</person_id>
				<author_profile_id><![CDATA[81332504075]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Christophe]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hery]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Industrial Light + Magic]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198585</article_id>
		<sort_key>5</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Human face project]]></title>
		<page_from>5</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198585</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198585</url>
		<abstract>
			<par><![CDATA["The Human Face Project" is a short film documenting an effort at Walt Disney Feature Animation to track and animate human facial performance, which was shown in the SIGGRAPH 2001 Electronic Theater. This short paper outlines the techniques developed in this project, and demonstrated in that film.The face tracking system we developed is exemplary of model-based computer vision, and exploits the detailed degrees of freedom of a geometric face model to confine the space of solutions. Optical flow and successive rerendering of the model are employed in an optimization loop to converge on model parameter estimates. The structure of the model permits very principled mapping of estimated expressions to different targets.Of critical importance in media applications is the handling of details beyond the resolution or degrees of freedom of the tracking model. We describe behavioral modeling expedients for realizing these details in a plausible way in resynthesis.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[3D facial animation]]></kw>
			<kw><![CDATA[model-based coding]]></kw>
			<kw><![CDATA[optical flow]]></kw>
			<kw><![CDATA[optimization]]></kw>
			<kw><![CDATA[visual servo]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P837824</person_id>
				<author_profile_id><![CDATA[81322496959]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Walter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hyneman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sony Image Works]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P837806</person_id>
				<author_profile_id><![CDATA[81322496926]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hiroki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Itokazu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Walt Disney Feature Animation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31059151</person_id>
				<author_profile_id><![CDATA[81322509847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Lance]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Williams]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Applied Minds, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24039416</person_id>
				<author_profile_id><![CDATA[81322510980]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Xinmin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Walt Disney Feature Animation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{ATOS01} ATOS-II Advanced Topometric Scanner. 2001. http://www.gom-online.de/En/Products/atos2_vars_print.html, GOM mbH, Braunschweig, Germany.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>964604</ref_obj_id>
				<ref_obj_pid>964568</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{Baker04} Baker, S., and Matthews, I. 2004. Lucas-Kanade 20 Years On: A Unifying Framework. International Journal of Computer Vision, Vol. 56, No. 3, March, 2004, pp. 221--255.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{Baumgart75} Baumgart, B. 1975. A polyhedron representation for computer vision. In AFIPS National Conference Proceedings, volume 44, 589--596.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>229157</ref_obj_id>
				<ref_obj_pid>229144</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{Black96} Black, M. J., and Anandan, P. 1996. The robust estimation of multiple motions: parametric and piecewise-smooth flow fields. In Computer Vision and Image Understanding 63(1), 75--104.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566595</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{Bregler02} Bregler, C., Loeb, L., Chuang, E., and Deshpande, H. 2002. Turning to the masters: motion capturing cartoons. In Proceedings of SIGGRAPH 2002, ACM Press / ACM SIGGRAPH, J. Hughes, Ed., Computer Graphics Proceedings, Annual Conference Series, ACM, 399--407.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>210980</ref_obj_id>
				<ref_obj_pid>210879</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{Byrd95} Byrd, R. H., Lu, P., and Nocedal, J. 1995. A Limited Memory Algorithm for Bound Constrained Optimization. SIAM Journal on Scientific and Statistical Computing, 16, 5, pp. 1190--1208.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280864</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{Debevec98} Debevec, P. 1998. Rendering synthetic objects into real scenes: Bridging traditional and image-based graphics with global illumination and high dynamic range photography. In Proceedings of SIGGRAPH 98.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{Ekman98} Ekman, P., and Rosenberg, E. (editors). What the Face Reveals: Basic and Applied Studies of Spontaneous Expression Using the Facial Action Coding System (Facs). (Series in Affective Science) Oxford University Press (February 01 1998).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{Eisert97} Eisert, P., and Girod, B. 1997. Model-based facial expression parameters from image sequences. In Proceedings of the IEEE International Conference on Image Processing (ICIP-97), 418--421.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{Hutchinson96} Hutchinson, S., Hager, G., Corke, P. 1996. A tutorial on visual servo control. In IEEE Transactions on Robotics and Automation.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>116694</ref_obj_id>
				<ref_obj_pid>116690</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{Lowe80} Lowe, D. 1980. Fitting parametrized three-dimensional models to images. In IEEE Transactions on Pattern Analysis and Machine Intelligence 13, 5. 441--450.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{Lucas81} Lucas, B. D., and Kanade, T. 1981. An Iterative Image Registration Technique with an Application to Stereo Vision. Proceedings of the 1981 DARPA Image Understanding Workshop, April, 1981, pp. 121--130.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383829</ref_obj_id>
				<ref_obj_pid>2383815</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{Marschner99} Marschner, S., Westin, S., Lafortune, E., Torrance, K., and Greenberg, D. 1999. Image-based BRDF measurement including human skin. In 10th Eurographics Rendering Workshop.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{Pighin99} Pighin, F., Hecker, J., Lischinski, D., Szeliski, R., and Salesin, D. 1999. Resynthesizing facial animation through 3D model-based tracking. In Seventh IEEE International Conference on Computer Vision (ICCV '99), 143--150.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{Roberts63} Roberts, L. G. 1963. Machine perception of three-dimensional solids. Lincoln Laboratory Technical Report #315.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>279236</ref_obj_id>
				<ref_obj_pid>279232</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{Zhu97} Zhu, C., Byrd, R. H., and Nocedal, J. 1997. L-BFGS-B: Algorithm 778: L-BFGS-B, FORTRAN routines for large scale bound constrained optimization. ACM Transactions on Mathematical Software, Vol 23, Num. 4, pp. 550--560.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198586</article_id>
		<sort_key>6</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[The faces of "The Polar Express"]]></title>
		<page_from>6</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198586</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198586</url>
		<abstract>
			<par><![CDATA[This paper covers methods used by Imageworks artist and technologists on <i>The Polar Express</i> ("PEX") for the entire facial pipeline. It includes a wide range of information from the shoot through to the final facial animation seen on the screen.The main areas that will be covered:&lang; <b>Facial Performance Capture</b> - Defines performance capture and gives technical details about the shooting of the movie.&lang; <b>Facial Tracking</b> - Covers technical obstacles encountered with facial tracking and the solutions used to overcome these issues.&lang; <b>Facial Rigging</b> - Outlines how the rigs were designed to accommodate the motion capture and animation.&lang; <b>Facial Integration</b> - Covers the retargeting of the data to the character and other tools that were used to prepare the motion capture for the animation department.&lang; <b>Facial Animation</b> - Covers the tools and techniques that the animation department used to enhance the data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP27007252</person_id>
				<author_profile_id><![CDATA[81545415256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bennett]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sony Pictures Imageworks Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198587</article_id>
		<sort_key>7</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Audience perception of clone realism]]></title>
		<page_from>7</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198587</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198587</url>
		<abstract>
			<par><![CDATA[The digital clones that have appeared briefly in recent movies are remarkable examples of computer graphics. We cannot say "mission accomplished" yet however.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP311018500</person_id>
				<author_profile_id><![CDATA[81545855456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Lewis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>2199455</ref_obj_id>
				<ref_obj_pid>2197882</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[S. Lyu and H. Farid. How realistic is photorealistic? IEEE Trans. Signal Processing, 53(2):845--850, Feb. 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198588</article_id>
		<sort_key>8</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Learning controls for blend shape based realistic facial animation]]></title>
		<page_from>8</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198588</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198588</url>
		<abstract>
			<par><![CDATA[Blend shape animation is the method of choice for keyframe facial animation: a set of blend shapes (key facial expressions) are used to define a linear space of facial expressions. However, in order to capture a significant range of complexity of human expressions, blend shapes need to be segmented into smaller regions where key idiosyncracies of the face being animated are present. Performing this segmentation by hand requires skill and a lot of time. In this paper, we propose an automatic, physically-motivated segmentation that learns the controls and parameters directly from the set of blend shapes. We show the usefulness and efficiency of this technique for both, motion-capture animation and keyframing. We also provide a rendering algorithm to enhance the visual realism of a blend shape model.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP35035999</person_id>
				<author_profile_id><![CDATA[81100641728]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pushkar]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Joshi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern Califronia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P575203</person_id>
				<author_profile_id><![CDATA[81100654479]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wen]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Tien]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern Califronia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40023038</person_id>
				<author_profile_id><![CDATA[81100041821]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Mathieu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Desbrun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern Califronia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39061089</person_id>
				<author_profile_id><![CDATA[81100026067]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Fr&#233;d&#233;ric]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pighin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern Califronia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>311556</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[T. Blanz and T. Vetter. A morphable model for the synthesis of 3d faces. In SIGGRAPH 99 Conference Proceedings. ACM SIGGRAPH, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>247</ref_obj_id>
				<ref_obj_pid>245</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[P. J. Burt and E. H. Adelson. A multiresolution spline with application to image mosaics. ACM Transaction on Graphics, 2(4), October 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[B. Choe, H. Lee, and H. Ko. Performance-driven muscle-based facial animation. In Proceedings of Computer Animation, volume 12, pages 67--79, May 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>872921</ref_obj_id>
				<ref_obj_pid>872743</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[G. Debunne, M. Desbrun, M. Cani, and A. Barr. Adaptive simulation of soft bodies in real-time. In Proceedings of Computer Animation 2000, pages 15--20, May 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[P. Ekman and W. V. Friesen. Unmasking the face. A guide to recognizing emotions fron facial clues. Prentice-Hall, Inc., Englewood Cliffs, New Jersey, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Fordham. Middle earth strikes back. Cinefex, (92):71--142, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[R. M. Haralick. Image segmentation survey. Fundamentals in Computer Vision, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Kleiser. A fast, efficient, accurate way to represent the human face. In SIGGRAPH '89 Course Notes 22: State of the Art in Facial Animation, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311586</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A. Lee, D. Dobkin, W. Sweldens, and P. Schr&#246;der. Multiresolution mesh morphing. In Proceedings of SIGGRAPH 99, pages 343--350, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>160683</ref_obj_id>
				<ref_obj_pid>160673</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[G. M. Nielson. Scattered data modeling. IEEE Computer Graphics and Applications, 13(1):60--70, January 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Nocedal and S. J. Wright. Numerical Optimization. Springer, New York, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569955</ref_obj_id>
				<ref_obj_pid>800193</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[F. I. Parke. Computer generated animation of faces. Proceedings ACM annual conference., August 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>907312</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[F. I. Parke. A parametric model for human faces. PhD thesis, University of Utah, Salt Lake City, Utah, December 1974. UTEC-CSc-75-047.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280825</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[F. Pighin, J. Hecker, D. Lischinski, R. Szeliski, and D. H. Salesin. Synthesizing realistic facial expressions from photographs. In SIGGRAPH 98 Conference Proceedings, pages 75--84. ACM SIGGRAPH, July 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[F. Pighin, R. Szeliski, and D. H. Salesin. Resynthesizing facial animation through 3d model-based tracking. In Proceedings, International Conference on Computer Vision, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[D. Zorin, P. Schr&#246;der, A. DeRose, L. Kobbelt, A. Levin, and W. Sweldens. Subdivision for modeling and animation. In SIGGRAPH 2000 Course Notes. ACM SIGGRAPH, May 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198589</article_id>
		<sort_key>9</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Synthesizing realistic facial expressions from photographs]]></title>
		<page_from>9</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198589</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198589</url>
		<abstract>
			<par><![CDATA[We present new techniques for creating photorealistic textured 3D facial models from photographs of a human subject, and for creating smooth transitions between different facial expressions by morphing between these different models. Starting from several uncalibrated views of a human subject, we employ a user-assisted technique to recover the camera poses corresponding to the views as well as the 3D coordinates of a sparse set of chosen locations on the subject's face. A scattered data interpolation technique is then used to deform a generic face mesh to fit the particular geometry of the subject's face. Having recovered the camera poses and the facial geometry, we extract from the input images one or more texture maps for the model. This process is repeated for several facial expressions of a particular subject. To generate transitions between these facial expressions we use 3D shape morphing between the corresponding face models, while at the same time blending the corresponding textures. Using our technique, we have been able to generate highly realistic face models and natural looking animations.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[facial animation]]></kw>
			<kw><![CDATA[facial expression generation]]></kw>
			<kw><![CDATA[facial modeling]]></kw>
			<kw><![CDATA[morphing]]></kw>
			<kw><![CDATA[photogrammetry]]></kw>
			<kw><![CDATA[view-dependent texture-mapping]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.2.10</cat_node>
				<descriptor>Modeling and recovery of physical attributes</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245.10010254</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems->Reconstruction</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP39023808</person_id>
				<author_profile_id><![CDATA[81100026067]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fr&#233;d&#233;ric]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pighin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Washington]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31047734</person_id>
				<author_profile_id><![CDATA[81332503356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jamie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hecker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Washington]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P58448</person_id>
				<author_profile_id><![CDATA[81311486606]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Dani]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lischinski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Hebrew University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P243128</person_id>
				<author_profile_id><![CDATA[81100122769]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Szeliski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P63622</person_id>
				<author_profile_id><![CDATA[81100188207]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Salesin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Washington]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>617851</ref_obj_id>
				<ref_obj_pid>616029</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Takaaki Akimoto, Yasuhito Suenaga, and Richard S. Wallace. Automatic Creation of 3D Facial Models. IEEE Computer Graphics and Applications, 13(5):16--22, September 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Alias | Wavefront, Toronto, Ontario. Alias V7.0, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134003</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Thaddeus Beier and Shawn Neely. Feature-based Image Metamorphosis. In SIGGRAPH 92 Conference Proceedings, pages 35--42. ACM SIGGRAPH, July 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Philippe Bergeron and Pierre Lachapelle. Controlling Facial Expressions and Body Movements in the Computer-Generated Animated Short "Tony De Peltrie". In SIGGRAPH 85 Advanced Computer Animation seminar notes. July 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258880</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Christoph Bregler, Michele Covell, and Malcolm Slaney. Video Rewrite: Driving Visual Speech with Audio. In SIGGRAPH 97 Conference Proceedings, pages 353--360. ACM SIGGRAPH, August 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199411</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[David T. Chen, Andrei State, and David Banks. Interactive Shape Metamorphosis. In 1995 Symposium on Interactive 3D Graphics, pages 43--44. ACM SIGGRAPH, April 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Chang S. Choi, Kiyoharu, Hiroshi Harashima, and Tsuyoshi Takebe. Analysis and Synthesis of Facial Image Sequences in Model-Based Image Coding. In IEEE Transactions on Circuits and Systems for Video Technology, volume 4, pages 257--275. June 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cyberware Laboratory, Inc, Monterey, California. 4020/RGB 3D Scanner with Color Digitizer, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237191</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Paul E. Debevec, Camillo J. Taylor, and Jitendra Malik. Modeling and Rendering Architecture from Photographs: A Hybrid Geometry- and Image-Based Approach. In SIGGRAPH 96 Conference Proceedings, pages 11--20. ACM SIGGRAPH, August 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Eben Ostby, Pixar Animation Studios. Personal communication, January 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Paul Ekman and Wallace V. Friesen. Unmasking the Face. A guide to recognizing emotions fron facial clues. Prentice-Hall, Inc., Englewood Cliffs, New Jersey, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Paul Ekman and Wallace V. Friesen. Manual for the Facial Action Coding System. Consulting Psychologists Press, Inc., Palo Alto, California, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>791488</ref_obj_id>
				<ref_obj_pid>791215</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Man Essa, Sumit Basu, Trevor Darrell, and Alex Pentland. Modeling, Tracking and Interactive Animation of Faces and Heads Using Input from Video. In Computer Animation Conference, pages 68--79. June 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Gary Faigin. The Artist's Complete Guide to Facial Expression. Watson-Guptill Publications, New York, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>171658</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Olivier Faugeras. Three-Dimensional Computer Vision: A Geometric Viewpoint. MIT Press, Cambridge, Massachusetts, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>248979</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[G. Golub and C. F. Van Loan. Matrix Computation, third edition. The John Hopkins University Press, Baltimore and London, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280822</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Brian Guenter, Cindy Grimm, Daniel Wood, Henrique Malvar, and Fr&#233;d&#233;ric Pighin. Making Faces. In SIGGRAPH 98 Conference Proceedings. ACM SIGGRAPH, July 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166139</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Pat Hanrahan and Wolfgang Krueger. Reflection from Layered Surfaces Due to Subsurface Scattering. In SIGGRAPH 93 Conference Proceedings, volume 27, pages 165--174. ACM SIGGRAPH, August 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Bright Star Technologies Inc. Beginning Reading Software. Sierra On-Line, Inc., 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Horace H. S. Ip and Lijun Yin. Constructing a 3D Individualized Head Model from Two Orthogonal Views. The Visual Computer, 12:254--266, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378490</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Gregory Ward J., Francis M. Rubinstein, and Robert D. Clear. A Ray Tracing Solution for Diffuse Interreflection. In SIGGRAPH 88 Conference Proceedings, volume 22, pages 85--92. August 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134007</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[James R. Kent, Wayne E. Carlson, and Richard E. Parent. Shape Transformation for Polyhedral Objects. In SIGGRAPH 92 Proceedings Conference, volume 26, pages 47--54. ACM SIGGRAPH, July 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237281</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Rolf M. Koch, Markus H. Gross, Friedrich R. Carls, Daniel F. von B&#252;ren, George Fankhauser, and Yoav I. H. Parish, Simulating Facial Surgery Using Finite Element Methods. In SIGGRAPH 96 Conference Proceedings, pages 421--428. ACM SIGGRAPH, August 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Tsuneya Kurihara and Kiyoshi Arai. A Transformation Method for Modeling and Animation of the Human Face from Photographs. In Nadia Magnenat Thalmann and Daniel Thalmann, editors, Computer Animation 91, pages 45--58. Springer-Verlag, Tokyo, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>840054</ref_obj_id>
				<ref_obj_pid>839277</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[A. Lanitis, C. J. Taylor, and T. F. Cootes. A Unified Approach for Coding and Interpreting Face Images. In Fifth International Conference on Computer Vision (ICCV95), pages 368--373. Cambridge, Massachusetts, June 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[C. L. Lawson and R. J. Hansen. Solving Least Squares Problems. Prentice-Hall, Englewood Cliffs, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218501</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Seung-Yong Lee, Kyung-Yong Chwa, Sung Yong Shin, and George Wolberg. Image Metamorphosis Using Snakes and Free-Form Deformations. In SIGGRAPH 95 Conference Proceedings, pages 439--448. ACM SIGGRAPH, August 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614355</ref_obj_id>
				<ref_obj_pid>614264</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Seung-Yong Lee, George Wolberg, Kyung-Yong Chwa, and Sung Yong Shin. Image Metamorphosis with Scattered Feature Constraints. IEEE Transactions on Visualization and Computer Graphics, 2(4), December 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218407</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Yuencheng Lee, Demetri Terzopoulos, and Keith Waters. Realistic Modeling for Facial Animation. In SIGGRAPH 95 Conference Proceedings, pages 55--62. ACM SIGGRAPH, August 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Yuencheng C. Lee, Demetri Terzopoulos, and Keith Waters. Constructing Physics-Based Facial Models of Individuals. In Proceedings of Graphics Interface 93, pages 1--8. May 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Francis H. Moffitt and Edward M. Mikhail. Photogrammetry. Harper & Row, New York, 3 edition, 1980.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>117636</ref_obj_id>
				<ref_obj_pid>117635</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Shree K. Nayar, Katsushi Ikeuchi, and Takeo Kanade. Shape from Interreflections. International Journal of Computer Vision, 6:173--195, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>160683</ref_obj_id>
				<ref_obj_pid>160673</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Gregory M. Nielson. Scattered Data Modeling. IEEE Computer Graphics and Applications, 13(1):60--70, January 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569955</ref_obj_id>
				<ref_obj_pid>800193</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Frederic I. Parke. Computer Generated Animation of Faces. Proceedings ACM annual conference., August 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>907312</ref_obj_id>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Frederic I. Parke. A Parametric Model for Human Faces. PhD thesis, University of Utah, Salt Lake City, Utah, December 1974. UTEC-CSc-75-047.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>249651</ref_obj_id>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Frederic I. Parke and Keith Waters. Computer Facial Animation. A K Peters, Wellesley, Massachusetts, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>148286</ref_obj_id>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[W. H. Press, B. P. Flannery, S. A. Teukolsky, and W. T. Vetterling. Numerical Recipes in C: The Art of Scientific Computing. Cambridge University Press, Cambridge, England, second edition, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732115</ref_obj_id>
				<ref_obj_pid>647651</ref_obj_pid>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Kari Pulli, Michael Cohen, Tom Duchamp, Hugues Hoppe, Linda Shapiro, and Werner Stuetzle. View-based rendering: Visualizing real objects from scanned range and color data. In Proc. 8th Eurographics Workshop on Rendering. June 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237196</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Steven M. Seitz and Charles R. Dyer. View Morphing. In SIGGRAPH 96 Conference Proceedings, Annual Conference Series, pages 21--30. ACM SIGGRAPH, August 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Chester C. Slama, editor. Manual of Photogrammetry. American Society of Photogrammetry, Falls Church, Virginia, fourth edition, 1980.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Richard Szeliski and Sing Bing Kang. Recovering 3D Shape and Motion from Image Streams using Nonlinear Least Squares. Journal of Visual Communication and Image Representation, 5(1):10--28, March 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258861</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Richard Szeliski and Heung-Yeung Shum. Creating Full View Panoramic Image Mosaics and Texture-Mapped Models. In SIGGRAPH 97 Conference Proceedings, pages 251--258. ACM SIGGRAPH, August 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Demetri Terzopoulos and Keith Waters. Physically-based Facial Modeling, Analysis, and Animation. Journal of Visualization and Computer Animation, 1(4):73--80, March 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>267823</ref_obj_id>
				<ref_obj_pid>267658</ref_obj_pid>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Kristinn R. Th&#243;risson. Gandalf: An Embodied Humanoid Capable of Real-Time Multimodal Dialogue with People. In First ACM International Conference on Autonomous Agents. 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801157</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Michael W. Vannier, Jeffrey F. Marsh, and James O. Warren. Three-dimentional Computer Graphics for Craniofacial Surgical Planning and Evaluation. In SIGGRAPH 83 Conference Proceedings, volume 17, pages 263--273. ACM SIGGRAPH, August 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37405</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Keith Waters. A Muscle Model for Animating Three-Dimensional Facial Expression. In SIGGRAPH 87 Conference Proceedings), volume 21, pages 17--24. ACM SIGGRAPH, July 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97906</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Lance Williams. Performance-Driven Facial Animation. In SIGGRAPH 90 Conference Proceedings, volume 24, pages 235--242. August 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>939158</ref_obj_id>
				<ref_obj_pid>938978</ref_obj_pid>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[Z. Zhang, K. Isono, and S. Akamatsu. Euclidean Structure from Uncalibrated Images Using Fuzzy Domain Knowledge: Application to Facial Images Synthesis. In Proc. International Conference on Computer Vision (ICCV'98). January 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198590</article_id>
		<sort_key>10</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Making faces]]></title>
		<page_from>10</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198590</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198590</url>
		<abstract>
			<par><![CDATA[We have created a system for capturing both the three-dimensional geometry and color and shading information for human facial expressions. We use this data to reconstruct photorealistic, 3D animations of the captured expressions. The system uses a large set of sampling points on the face to accurately track the three dimensional deformations of the face. Simultaneously with the tracking of the geometric data, we capture multiple high resolution, registered video images of the face. These images are used to create a texture map sequence for a three dimensional polygonal face model which can then be rendered on standard 3D graphics hardware. The resulting facial animation is surprisingly life-like and looks very much like the original live performance. Separating the capture of the geometry from the texture images eliminates much of the variance in the image data due to motion, which increases compression ratios. Although the primary emphasis of our work is not compression we have investigated the use of a novel method to compress the geometric data based on principal components analysis. The texture sequence is compressed using an MPEG4 video codec. Animations reconstructed from 512x512 pixel textures look good at data rates as low as 240 Kbits per second.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P32646</person_id>
				<author_profile_id><![CDATA[81100130209]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Brian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Guenter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39048283</person_id>
				<author_profile_id><![CDATA[81100553787]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Cindy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Grimm]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P59537</person_id>
				<author_profile_id><![CDATA[81100377878]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wood]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Washington]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P109471</person_id>
				<author_profile_id><![CDATA[81100362010]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Henrique]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Malvar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P828550</person_id>
				<author_profile_id><![CDATA[81100026067]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Fredrick]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pighin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Washington]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>134003</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Beier, T., and Neely, S. Feature-based image metamorphosis. In Computer Graphics (SIGGRAPH '92 Proceedings) (July 1992), E. E. Catmull, Ed., vol. 26, pp. 35--42.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bregler, C., Covell, M., and Slaney, M. Video rewrite: Driving visual speech with audio. Computer Graphics 31, 2 (Aug. 1997), 353--361.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cassell, J., Pelachaud, C., Badler, N., Steedman, M., Achorn, B., Becket, T., Douville, B., Prevost, S., and Stone, M. Animated conversation: Rule-based generation of facial expression, gesture and spoken intonation for multiple conversational agents. Computer Graphics 28, 2 (Aug. 1994), 413--420.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>794617</ref_obj_id>
				<ref_obj_pid>794190</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[DeCarlo, D., and Metaxas, D. The integration of optical flow and deformable models with applications to human face shape and motion estimation. Proceedings CVPR (1996), 231--238.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>261522</ref_obj_id>
				<ref_obj_pid>261506</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Essa, I., and Pentland, A. Coding, analysis, interpretation and recognition of facial expressions. IEEE Transactions on Pattern Analysis and Machine Intelligence 19, 7 (1997), 757--763.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Faugeras, O. Three-dimensional computer vision. MIT Press, Cambridge, MA, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>358692</ref_obj_id>
				<ref_obj_pid>358669</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Fischler, M. A., and Booles, R. C. Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography. Communications of the ACM 24, 6 (Aug. 1981), 381--395.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237216</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hoppe, H. Progressive meshes. In SIGGRAPH 96 Conference Proceedings (Aug. 1996), H. Rushmeier, Ed., Annual Conference Series, ACM SIGGRAPH, Addison Wesley, pp. 99--108. held in New Orleans, Louisiana, 04--09 August 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Horn, B. K. P. Closed-form solution of absolute orientation using unit quaternions. Journal of the Optical Society of America 4, 4 (Apr. 1987).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Lee, Y., Terzopoulos, D., and Waters, K. Realistic modeling for facial animation. Computer Graphics 29, 2 (July 1995), 55--62.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Pighin, F., Auslander, J., Lishinski, D., Szeliski, R., and Salesin, D. Realistic facial animation using image based 3d morphing. Tech. Report TR-97-01-03, Department of Computer Science and Engineering, University of Washington, Seattle, Wa, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>235125</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Sch&#252;rmann, J. Pattern Classification: A Unified View of Statistical and Neural Approaches. John Wiley and Sons, Inc., New York, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Strang. Linear Algebra and its Application. HBJ, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37405</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Waters, K. A muscle model for animating three-dimensional facial expression. In Computer Graphics (SIGGRAPH '87 Proceedings) (July 1987), M. C. Stone, Ed., vol. 21, pp. 17--24.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97906</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Williams, L. Performance-driven facial animation. Computer Graphics 24, 2 (Aug. 1990), 235--242.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198591</article_id>
		<sort_key>11</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Digital face cloning]]></title>
		<page_from>11</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198591</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198591</url>
		<abstract>
			<par><![CDATA[This sketch describes the process and the technology used in the creation of a digital clone of a human face for a story in the November 2002 issue of National Geographic on skin[Swerdlow 2002].]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P109434</person_id>
				<author_profile_id><![CDATA[81100640205]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Henrik]]></first_name>
				<middle_name><![CDATA[Wann]]></middle_name>
				<last_name><![CDATA[Jensen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, San Diego]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>383319</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Jensen, H. W., Marschner, S., Levoy, M., and Hanrahan, P. 2001. A practical model for subsurface light transport. Proceedings of SIGGRAPH '2001, 511--518.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74361</ref_obj_id>
				<ref_obj_pid>74333</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J., and Kay, T. 1989. Rendering fur with three dimensional textures. Proceedings of SIGGRAPH 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Swerdlow, J. 2002. Unmasking skin. National Geographic, 36--63.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198592</article_id>
		<sort_key>12</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[A rapid hierarchical rendering technique for translucent materials]]></title>
		<page_from>12</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198592</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198592</url>
		<abstract>
			<par><![CDATA[This paper introduces an efficient two-pass rendering technique for translucent materials. We decouple the computation of irradiance at the surface from the evaluation of scattering inside the material. This is done by splitting the evaluation into two passes, where the first pass consists of computing the irradiance at selected points on the surface. The second pass uses a rapid hierarchical integration technique to evaluate a diffusion approximation based on the irradiance samples. This approach is substantially faster than previous methods for rendering translucent materials, and it has the advantage that it integrates seamlessly with both scanline rendering and global illumination methods. We show several images and animations from our implementation that demonstrate that the approach is both fast and robust, making it suitable for rendering translucent materials in production.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[BSSRDF]]></kw>
			<kw><![CDATA[diffusion theory]]></kw>
			<kw><![CDATA[global illumination]]></kw>
			<kw><![CDATA[light transport]]></kw>
			<kw><![CDATA[realistic image synthesis]]></kw>
			<kw><![CDATA[reflection models]]></kw>
			<kw><![CDATA[subsurface scattering]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P109434</person_id>
				<author_profile_id><![CDATA[81100640205]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Henrik]]></first_name>
				<middle_name><![CDATA[Wann]]></middle_name>
				<last_name><![CDATA[Jensen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39059997</person_id>
				<author_profile_id><![CDATA[81322489561]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Juan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Buhler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[PDI/DreamWorks]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Appel, A. 1985. An efficient program for many-body simulations. SIAM Journal of Scientific Statistical Computing 6, 85--103.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Chandrasekhar, S. 1960. Radiative Transfer. Oxford Univ. Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Debevec, P., 1999. St. Peter's Basilica (www.debevec.org/probes/).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311560</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Dorsey, J., Edelman, A., Jensen, H. W., Legakis, J., and Pedersen, H. K. 1999. Modeling and rendering of weathered stone. In Proceedings of SIGGRAPH'99, 225--234.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Furutso, K. 1980. Diffusion equation derived from space-time transport equation. J. Opt. Soc. Am 70, 360.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Gemert, M., Jacques, S., Sterenborg, H., and Star, W. 1989. Skin optics. IEEE Trans. on Biomedical Eng. 16, 1146--1156.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Groenhuis, R. A., Ferwerda, H. A., and Bosch, J. J. T. 1983. Scattering and absorption of turbid materials determined from reflection measurements. I: Theory. Applied Optics 22, 2456--2462.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166139</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hanrahan, P., and Krueger, W. 1993. Reflection from layered surfaces due to subsurface scattering. In Computer Graphics (SIGGRAPH'93 Proceedings), 165--174.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Henyey, L., and Greenstein, J. 1941. Diffuse radiation in the galaxy. Astrophysics Journal 93, 70--83.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Ishimaru, A. 1978. Wave Propagation and Scattering in Random Media, vol. 1. Academic Press, New York.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383319</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Jensen, H. W., Marschner, S. R., Levoy, M., and Hanrahan, P. 2001. A practical model for subsurface light transport. In Proceedings of SIGGRAPH 2001, 511--518.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>275461</ref_obj_id>
				<ref_obj_pid>275458</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Jensen, H. W. 1996. Global illumination using photon maps. In Rendering Techniques '96, Springer Wien, X. Pueyo and P. Schr&#246;der, Eds., 21--30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Koenderink, J., and Van Doorn, A. 2001. Shading in the case of translucent objects. In Proceedings of SPIE, vol. 4299, 312--320.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Nicodemus, F. E., Richmond, J. C., Hsia, J. J., Ginsberg, I. W., and Limperis, T. 1977. Geometric considerations and nomenclature for reflectance. Monograph 161, National Bureau of Standards (US), Oct.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344824</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Pharr, M., and Hanrahan, P. 2000. Monte carlo evaluation of non-linear scattering equations for subsurface reflection. In Proceedings of SIGGRAPH 2000, 75--84.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Stam, J. 1995. Multiple scattering as a diffusion process. In Eurographics Rendering Workshop 1995, Eurographics.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134008</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Turk, G. 1992. Re-tiling polygonal surfaces. In Computer Graphics (SIGGRAPH '92 Proceedings), vol. 26, 55--64.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378490</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Ward, G. J., Rubinstein, F. M., and Clear, R. D. 1988. A ray tracing solution for diffuse interreflection. In Computer Graphics (SIGGRAPH '88 Proceedings), vol. 22, 85--92.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>70464</ref_obj_id>
				<ref_obj_pid>70459</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Wyman, D. R., Patterson, M. S., and Wilson, B. C. 1980. Similarity relations for anisotropic scattering in monte carlo simulations of deeply penetrating neutral particles. J. Comp. Physics 81, 137--150.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198593</article_id>
		<sort_key>13</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[Realistic human face rendering for "The Matrix Reloaded"]]></title>
		<page_from>13</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198593</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198593</url>
		<abstract>
			<par><![CDATA[The ultimate challenge in photorealistic computer graphics is rendering believable human faces. We are trained to study the human face since birth, so our brains are intimately familiar with every nuance and detail of what human skin is supposed look like. The challenge of rendering human skin is further complicated by some technical issues such as the fact that skin is a highly detailed surface with noticeable features in the order of ~100 microns and the fact that skin is translucent. On <i>The Matrix Reloaded</i> we had to create completely photorealistic renderings for most of the principal actors including Keanu Reeves, Lawrence Fishborne, and Hugo Weaving.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35035442</person_id>
				<author_profile_id><![CDATA[81100409357]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Borshukov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ESC Entertainment]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP37032287</person_id>
				<author_profile_id><![CDATA[81409595942]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Lewis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ESC Entertainment]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198594</article_id>
		<sort_key>14</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Reflectance field rendering of human faces for "Spider-Man 2"]]></title>
		<page_from>14</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198594</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198594</url>
		<abstract>
			<par><![CDATA[The creation of convincing computer generated human faces which can withstand close-up scrutiny under arbitrary lighting has been notoriously difficult to achieve, especially for well known actors. For the film "Spider-Man 2" it was decided to try recent experimental computer graphics research that looked promising but that had never been production tested.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP24046415</person_id>
				<author_profile_id><![CDATA[81322505026]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sagar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sony Pictures Imageworks]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>344855</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Debevec, P., Hawkins, T., Tchou, C., Duiker, H. P., Sarokin, W. and Sagar, M. 2000. Acquiring the reflectance field of a human face. In SIGGRAPH 2000, Computer Graphics Proceedings, 145--156, ACM SIGGRAPH]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198595</article_id>
		<sort_key>15</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Analysis and synthesis of facial expressions with hand-generated muscle actuation basis]]></title>
		<page_from>15</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198595</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198595</url>
		<abstract>
			<par><![CDATA[We present a performance-driven facial animation system for analyzing captured expressions to find muscle actuation and synthesizing expressions with the actuation values. Significantly different approach of our work is that we let artists sculpt the initial draft of the actuation basis---the basic facial shapes corresponding to the isolated actuation of individual muscles, instead of calculating skin surface deformation entirely relying on the mathematical models such as finite element methods. We synthesize expressions by linear combinations of the basis elements, and analyze expressions by finding the weights for the combinations. Even though the hand-generated actuation basis represents the essence of the subject's characteristic expressions, it is not accurate enough to be used in the subsequent computational procedures. We also describe an iterative algorithm to increase the accuracy of the actuation basis. The experimental results suggest that our artist-in-the-loop method produces more predictable and controllable outcome than pure mathematical models, thus can be a quite useful tool in animation productions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P708728</person_id>
				<author_profile_id><![CDATA[81100276590]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Byoungwon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Choe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Seoul National University, Seoul, Korea]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P113193</person_id>
				<author_profile_id><![CDATA[81423594747]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hyeong-Seok]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ko]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Seoul National University, Seoul, Korea]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B. Choe, H. Lee, and H.-S. Ko. Performance-driven muscle-based facial animation. The Journal of Visualization and Computer Animation, 12(2):67--79, May 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. D. Clemente. Anatomy: A Regional Atlas of the Human Body, 2nd edition. Urban and Schwarzenberg, 1981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618564</ref_obj_id>
				<ref_obj_pid>616054</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. Eisert and B. Girod. Analyzing facial expression for virtual conferencing. IEEE Computer Graphics & Applications, 18(5):70--78, September - October 1998. ISSN 0272--1716.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[P. Ekman and W. V. Friesen. Facial Action Coding System. Consulting Psychologists Press, Inc., 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>791488</ref_obj_id>
				<ref_obj_pid>791215</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[I. Essa, S. Basu, T. Darrell, and A. Pentland. Modeling, tracking and interactive animation of faces and heads using input from video. In Proceedings of Computer Animation '96 Conference, June 1996. Geneva, Switzerland.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>261522</ref_obj_id>
				<ref_obj_pid>261506</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[I. A. Essa and A. P. Pentland. Coding, analysis, interpretation and recognition of facial expressions. IEEE Transactions on Pattern Analysis and Machine Intelligence, 19(7):757--763, July 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[G. Faigin. The Artist's Complete Guide to Facial Expression. Watson-Guptill Publications, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. K. Greenwald, E. W. C. III, and P. J. Lang. Affective judgment and psychophysiological response: dimensional covariation in the evaluation of pictorial stimuli. Journal of Pyschophysiology, 3:51--64, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280822</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[B. Guenter, C. Grimm, D. Wood, H. Malvar, and F. Pighin. Making faces. In SIGGRAPH 98 Conference Proceedings, Annual Conference Series, pages 55--66. ACM SIGGRAPH, Addison Wesley, July 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[R. M. Koch, M. H. Gross, and A. Bosshard. Emotion editing using finite elements. Computer Graphics Forum, 17(3):295--302, 1998. ISSN 1067--7055.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237281</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[R. M. Koch, M. H. Gross, F. R. Carls, D. F. von B&#252;ren, G. Fankhauser, and Y. Parish. Simulating facial surgery using finite element methods. In SIGGRAPH 96 Conference Proceedings, Annual Conference Series, pages 421--428. ACM SIGGRAPH, Addison Wesley, Aug. 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>791537</ref_obj_id>
				<ref_obj_pid>521641</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[C. Kouadio, P. Poulin, and P. Lachapelle. Real-time facial animation based upon a bank of 3D facial expressions. In Proceedings of Computer Animation '98 Conference. IEEE Computer Society Press, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218407</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Y. Lee, D. Terzopoulos, and K. Waters. Realistic face modeling for animation. In SIGGRAPH 95 Conference Proceedings, Annual Conference Series, pages 55--62. ACM SIGGRAPH, Addison Wesley, Aug. 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344862</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. P. Lewis, M. Cordner, and N. Fong. Pose space deformations: A unified approach to shape interpolation a nd skeleton-driven deformation. Proceedings of SIGGRAPH 2000, pages 165--172, July 2000. ISBN 1-58113-208-5.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[D. G. Luenberger. Linear and Nonlinear Programming. Addison-Wesley, 2nd edition, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>160683</ref_obj_id>
				<ref_obj_pid>160673</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[G. M. Nielson. Scattered data modeling. IEEE Computer Graphics and Applications, 13(1):60--70, Jan. 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>249651</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[F. I. Parke and K. Waters. Computer Facial Animation. A K Peters, 1996. ISBN 1-56881-014-8.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280825</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[F. Pighin, J. Hecker, D. Lischinski, R. Szeliski, and D. H. Salesin. Synthesizing realistic facial expressions from photographs. In SIGGRAPH 98 Conference Proceedings, Annual Conference Series, pages 75--84. ACM SIGGRAPH, Addison Wesley, July 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[F. Pighin, R. Szeliski, and D. H. Salesin. Resynthesizing facial animation through 3D model-based tracking. In Seventh International Conference on Computer Vision (ICCV '99) Conference Proceedings, pages 143--150, September 1999. Corfu, Greece.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[D. Terzopoulos and K. Waters. Physically-based facial modelling, analysis, and animation. The Journal of Visualization and Computer Animation, 1:73--80, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628482</ref_obj_id>
				<ref_obj_pid>628302</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[D. Terzopoulos and K. Waters. Analysis and synthesis of facial image sequences using physical and anatomical models. IEEE Transactions on Pattern Analysis and Machine Intelligence, 15(6):569--579, June 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37405</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[K. Waters. A muscle model for animating three-dimensional facial expression. Computer Graphics (Proceedings of SIGGRAPH 87), 21(4):17--24, July 1987. Held in Anaheim, California.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97906</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[L. Williams. Performance-driven facial animation. Computer Graphics (Proceedings of SIGGRAPH 90), 24(4):235--242, August 1990. ISBN 0-201-50933-4. Held in Dallas, Texas.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383290</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[J. yong Noh and U. Neumann. Expression cloning. Proceedings of SIGGRAPH 2001, pages 277--288, August 2001. ISBN 1-58113-292-1.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198596</article_id>
		<sort_key>16</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[Universal capture - image-based facial animation for "The Matrix Reloaded"]]></title>
		<page_from>16</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198596</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198596</url>
		<abstract>
			<par><![CDATA[The VFX R&D stage for <i>The Matrix Reloaded</i> was kicked off in January 2000 with the challenge to create realistic human faces. We believed that traditional facial animation approaches like muscle deformers or blend shapes would simply never work, both because of the richness of facial movement and because of the human viewer's extreme sensitivity to facial nuances. Our task was further complicated as we had to recreate familiar actors such as Keanu Reeves and Lawrence Fishburne. Our team had been very successful at applying image-based techniques for photorealistic film set/location rendering, so we decided to approach the problem from the image-based side again. We wanted to produce a 3-d recording of the real actor's performance and be able to play it back from different angles and under different lighting conditions. Just as we can extract geometry, texture, or light from images, we are now able to extract movement. Universal Capture combines two powerful computer vision techniques: optical flow and photogrammetry.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35035693</person_id>
				<author_profile_id><![CDATA[81100409357]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Borshukov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ESC Entertainment]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P58196</person_id>
				<author_profile_id><![CDATA[81100284377]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Piponi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ESC Entertainment]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31056082</person_id>
				<author_profile_id><![CDATA[81322498745]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Oystein]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Larsen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ESC Entertainment]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP37032279</person_id>
				<author_profile_id><![CDATA[81409595942]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Lewis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ESC Entertainment]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P653843</person_id>
				<author_profile_id><![CDATA[81100624763]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Christina]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tempelaar-Lietz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ESC Entertainment]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198597</article_id>
		<sort_key>17</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Generating realistic human hair for "The Matrix Reloaded"]]></title>
		<page_from>17</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198597</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198597</url>
		<abstract>
			<par><![CDATA[In recent years, there have been a few successful applications of realistic computer generated hair in the entertainment industry. For <i>The Matrix Reloaded</i> we had to face new challenges. First, we had to handle both close ups and scenes with hundreds of human characters with hair. The task was further complicated by the fact that the CG hair needed to exactly match the styling of familiar heroes from the film: Agent Smith and Neo. Also because of the rendering methods we chose for our virtual actors the hair solution needed to work in a ray tracing context with many lights. Our in-house hair styling tool together with some key rendering techniques made it all possible.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP24045535</person_id>
				<author_profile_id><![CDATA[81322501803]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tadao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mihashi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ESC Entertainment]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P653843</person_id>
				<author_profile_id><![CDATA[81100624763]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Christina]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tempelaar-Lietz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ESC Entertainment]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35035434</person_id>
				<author_profile_id><![CDATA[81100409357]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Borshukov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ESC Entertainment]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198598</article_id>
		<sort_key>18</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[Lighting reconstruction for "The Matrix Reloaded"]]></title>
		<subtitle><![CDATA[(sketches_0314)]]></subtitle>
		<page_from>18</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198598</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198598</url>
		<abstract>
			<par><![CDATA[The demands of photo-realism required of the effects for <i>The Matrix Reloaded and The Matrix Revolutions</i> led us to create a system for directly and accurately reconstructing real world lighting environments. The Lighting Reconstruction Toolkit builds on research in the area of Image-based Lighting and extends current techniques to enable the reconstruction of lighting that more closely matches the real world.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP31028947</person_id>
				<author_profile_id><![CDATA[81100137101]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Haarm-Pieter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Duiker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ESC Entertainment]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198599</article_id>
		<sort_key>19</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[Making of <i>The Superpunch</i>]]></title>
		<page_from>19</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198599</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198599</url>
		<abstract>
			<par><![CDATA[<i>The Superpunch</i> is the final punch Neo that delivers to Agent Smith in the final installment of <i>The Matrix</i> trilogy during the film's last face-off. It was the first shot that the directors Larry and Andy Wachowski and their conceptual designer storyboarded for the sequels. (The shot's storyboards were also the first storyboards to leak out on the Internet back in Spring 2000). <i>The Superpunch</i> was meant to show, in familiar Bullet Time, the event of Neo's super-powerful last punch that occurs over a fraction of a second and lands on Smith's face deforming it in a surreal, anime-like fashion. As a Bullet Time shot, it was to feature an impossible virtual camera yet it had to look real. The nature of the push-in camera move and the requirement of punching someone with an inhumanly strong force meant that the original multiple still camera rig approach could not be deployed. The shot went through many different stages of visualizations, breakdowns, and considerations. <i>The Superpunch</i> became even more challenging when we learned that it had to happen under heavy rain. We explored creating the shot based on live action elements and augmenting it with CG elements. Tests revealed that this approach would compromise the required fluid camera. The camera was meant to glide through space showing us an exciting event from previously unseen perspectives. Around the Spring of 2003 when we had gained confidence that our 3 year-long R&D effort in realistic human face rendering technology could pull off a full-frame, slow-motion close up of a familiar actor such as Hugo Weaving, we decided to create the shot entirely in the CG world.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35035436</person_id>
				<author_profile_id><![CDATA[81100409357]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Borshukov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ESC Entertainment]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198600</section_id>
		<sort_key>10</sort_key>
		<section_seq_no>10</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Realistic materials in computer graphics]]></section_title>
		<section_page_from>10</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>P433357</person_id>
				<author_profile_id><![CDATA[81100504611]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hendrik]]></first_name>
				<middle_name><![CDATA[P. A.]]></middle_name>
				<last_name><![CDATA[Lensch]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>PP31057870</person_id>
				<author_profile_id><![CDATA[81100051843]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Goesele]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198601</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Realistic materials in computer graphics]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198601</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198601</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P433357</person_id>
				<author_profile_id><![CDATA[81100504611]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hendrik]]></first_name>
				<middle_name><![CDATA[P. A.]]></middle_name>
				<last_name><![CDATA[Lensch]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31057919</person_id>
				<author_profile_id><![CDATA[81100051843]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Goesele]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MPI Informatik]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P308194</person_id>
				<author_profile_id><![CDATA[81350582710]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yung-Yu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chuang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Taiwan University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43117244</person_id>
				<author_profile_id><![CDATA[81100179328]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Tim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hawkins]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14092425</person_id>
				<author_profile_id><![CDATA[81100238316]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Steve]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Marschner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40031269</person_id>
				<author_profile_id><![CDATA[81100458116]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Wojciech]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Matusik]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratories (MERL)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P837805</person_id>
				<author_profile_id><![CDATA[81322501298]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Gero]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mueller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#228;t Bonn]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{Adelson01} E. H. Adelson. On Seeing Stuff: the Perception of Materials by Humans and Machines. In Bernice E. Rogowitz and Thrasyvoulos N. Pappas, editors, Proceedings of SPIE - Human Vision and Electronic Imaging IV, volume 4299, pages 1--12, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{Agarwal04} Sameer Agarwal, Satya P. Mallick, David J. Kriegman, and Serje J. Belongie. On Refractive Optical Flow. In Proceedings of 8th European Conference on Computer Vision, pages 483--494, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344814</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{Ashikhmin00} M. Ashikhmin, S. Premoze, and P. Shirley. A Microfacet-based BRDF Generator. In Proc. SIGGRAPH, pages 65--74, July 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192246</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{Banks94} D. Banks. Illumination in Diverse Codimensions. In Proc. SIGGRAPH, pages 327--334, July 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{Bayer76} Bryce E. Bayer. Color imaging array. US Patent 3,971,065, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{Beckmann63} P. Beckmann and A. Spizzichino. The Scattering of Electromagnetic Waves from Rough Surfaces. McMillan, 1963.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{Blasi93} Philippe Blasi, Bertrand Le Sa&#235;c, and Christophe Schlick. A Rendering Algorithm for Discrete Volume Density Objects. Computer Graphics Forum, 13(3):201--210, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360353</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{Blinn76} James F. Blinn and Martin E. Newell. Texture and Reflection in Computer Generated Images. Communications of the ACM, 19(10):542--546, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{Blinn77} J. Blinn. Models of Light Reflection For Computer Synthesized Pictures. In Proc. SIGGRAPH, pages 192--198, July 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383270</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{Boivin01} Samuel Boivin and Andr&#233; Gagalowicz. Image-Based Rendering of Diffuse, Specular and Glossy Surfaces From a Single Image. In Eugene Fiume, editor, Proceedings of SIGGRAPH 2001, Computer Graphics Proceedings, Annual Conference Series, pages 107--116. ACM Press / ACM SIGGRAPH, August 2001. ISBN 1-58113-292-1.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{Born93} Max Born and Emil Wolf. Principles of Optics. Pergamon Press, Oxford, 6 edition, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{Bouguet} Jean-Yves Bouguet. Camera Calibration Toolbox for Matlab. See http://www.vision.caltech.edu/bouguetj.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{Brand03} M. Brand. Charting a manifold. In Advances in Neural Information Processing Systems, volume 15, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>320164</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{Brinkman99} Ron Brinkman. The Art and Science of Digital Compositing. Morgan Kaufman, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{BTF Database Bonn} BTF Database Bonn. http://btf.cs.uni-bonn.de.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{Burns01} Peter D. Burns and Don Williams. Image Resolution and MTF for Digital Cameras and Scanners. In Tutorial Notes, IS&T PICS Conference 2001, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37434</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[{Cabral87} B. Cabral, N. Max, and R. Springmeyer. Bidirectional Reflection Functions From Surface Bump Maps. In Proceedings SIGGRAPH, pages 273--281, Anaheim, California, July 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311553</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[{Cabral99} B. Cabral, M. Olano, and P. Nemec. Reflection Space Image Based Rendering. In Proceedings SIGGRAPH, pages 165--170, aug 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[{Carceroni01} Rodrigo L. Carceroni and Kiriakos N. Kutulakos. Multi-View Scene Capture by Surfel Sampling: From Video Streams to Non-Rigid 3D Motion Shape & Reflectance. In ICCV, pages 60--67, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566628</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[{Chen02} Yanyun Chen, Yingqing Xu, Baining Guo, and Heung-Yeung Shum. Modeling and rendering of realistic feathers. In Proceedings of SIGGRAPH, pages 630--636. ACM Press, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344844</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[{Chuang00} Yung-Yu Chuang, Douglas E. Zongker, Joel Hindorff, Brian Curless, David H. Salesin, and Richard Szeliski. Environment Matting Extensions: Towards Higher Accuracy and Real-Time Capture. In Proceedings of ACM SIGGRAPH 2000, pages 121--130, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[{Cohen85} M. F. Cohen and D. P. Greenberg. The hemicube: A radiosity solution for complex environments. Symposium on Computational Geometry, 19(3):31--40, July 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>154731</ref_obj_id>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[{Cohen93} Michael F. Cohen and John R. Wallace. Radiosity and Realistic Image Synthesis. Academic Press, Boston, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[{Cook84} R. L. Cook, T. Porter, and L. Carpenter. Distributed Ray Tracing. In Proceedings SIGGRAPH, pages 137--145, July 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>794511</ref_obj_id>
				<ref_obj_pid>794189</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[{Dana97} Kristin J. Dana, Bram van Ginneken, Shree K. Nayar, and Jan J. Koenderink. Reflectance and texture of real-world surfaces. In IEEE Conference on Computer Vision and Pattern Recognition, pages 151--157, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300778</ref_obj_id>
				<ref_obj_pid>300776</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[{Dana99} K. Dana, B. van Ginneken, S. Nayar, and J. Koenderink. Reflectance and texture of real-world surfaces. ACM Transactions on Graphics, 18(1):1--34, January 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[{Dana04} Kristin J. Dana and Jing Wang. Device for convenient measurement of spatially varying bidirectional reflectance. Journal of the Optical Society of America, A:1--12, January 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732290</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[{Daubert01} Katja Daubert, Hendrik Lensch, Wolfgang Heidrich, and Hans-Peter Seidel. Efficient Cloth Modeling and Rendering. In Proceedings of EGRW '01, pages 63--70, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[{Daubert02} K. Daubert and H. Seidel. Hardware-Based Volumetric Knit-Wear. Computer Graphics Forum, 21(3):575--784, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258884</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[{Debevec97} P. Debevec and J. Malik. Recovering High Dynamic Range Radiance Maps from Photographs. In Proc. SIGGRAPH, pages 369--378, August 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344855</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[{Debevec00} P. Debevec, T. Hawkins, C. Tchou, H.-P. Duiker, W. Sarokin, and M. Sagar. Acquiring the Reflectance Field of a Human Face. In Proc. SIGGRAPH, pages 145--156, July 2000. ISBN 1-58113-208-5.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[{Debevec04} Paul Debevec, Chris Tchou, Andrew Gardner, Tim Hawkins, Charis Poullis, Jessi Stumpfel, Andrew Jones, Nathaniel Yun, Per Einarsson, Therese Lundgren, Marcos Fajardo, and Philippe Martinez. Estimating Surface Reflectance Properties of a Complex Scene under Captured Natural Illumination. Technical Report ICT-TR-06.2004, USC ICT, December 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>266783</ref_obj_id>
				<ref_obj_pid>266774</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[{DeYoung97} J. DeYoung and A. Fournier. Properties of Tabulated Bidirectional Reflectance Distribution Functions. In Graphics Interface, pages 47--55, May 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237278</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[{Dorsey96} Julie Dorsey and Patrick M. Hanrahan. Modeling and Rendering of Metallic Patinas. In Proceedings of SIGGRAPH 96, Computer Graphics Proceedings, Annual Conference Series, pages 387--396, August 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311560</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[{Dorsey99} Julie Dorsey, Alan Edelman, Henrik Wann Jensen, Justin Legakis, and Hans Kohling Pedersen. Modeling and Rendering of Weathered Stone. In SIGGRAPH 1999, pages 225--234, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1103905</ref_obj_id>
				<ref_obj_pid>1103900</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[{Dutre04} Philip Dutre, Henrik Wann Jensen, Jim Arvo, Kavita Bala, Philippe Bekaert, Steve Marschner, and Matt Pharr. State of the Art in Monte Carlo Global Illumination. In Siggraph Course 4, Los Angeles, August 2004. ACM SIGGRAPH.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[{Farell92} T. J. Farell, M. S. Patterson, and B. Wilson. A diffusion theory model of spatially resolved, steady-state diffuse reflectance for the non-invasive determination of tissue optical properties in vivo. Med. Phys., 19:879--888, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[{Feng93} Sheshao Feng, Fanan Zeng, and Britton Chance. Monte Carlo Simulations of Photon Migration Path Distributions in Multiple Scattering Media. In Photon Migration and Imaging in Random Media and Tissues, Proc. of SPIE Vol. 1888, pages 78--89, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>351322</ref_obj_id>
				<ref_obj_pid>350448</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[{Fournier00} A. Fournier and P. Lalonde. From Structure to Reflectance. In Cloth Modeling and Animation, pages 241--267, Natick, MA, 2000. A K Peters, Ltd.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882342</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[{Gardner03} A. Gardner, C. Tchou, T. Hawkins, and P. Debevec. Linear light source reflectometry. ACM Trans. Graphics., 22(3):749--758, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258849</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[{Garland97} M. Garland and P. Heckbert. Surface Simplification Using Quadric Error Metrics. In Proc. SIGGRAPH, pages 209--216, August 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882438</ref_obj_id>
				<ref_obj_pid>882404</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[{Georghiades03} Athinodoros S. Georghiades. Recovering 3-D Shape and Reflectance From a Small Number of Photographs. In Eurographics Symposium on Rendering: 14th Eurographics Workshop on Rendering, pages 230--240, June 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[{Gibson01} Simon Gibson, Toby Howard, and Roger Hubbold. Flexible Image-Based Photometric Reconstruction using Virtual Light Sources. Computer Graphics Forum, 20(3), 2001. ISSN 1067-7055.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>527570</ref_obj_id>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[{Glassner95} Andrew Glassner. Principles of Digital Image Synthesis. Morgan Kaufmann, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015807</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[{Goesele04} Michael Goesele, Hendrik P. A. Lensch, Jochen Lang, Christian Fuchs, and Hans-Peter Seidel. DISCO - Acquisition of Translucent Objects. ACM Transactions on Graphics (Proceedings of SIGGRAPH 2004), 23(3):835--844, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[{Goldman04} Dan B Goldman, Brian Curless, Aaron Hertzmann, and Steve Seitz. Shape and Spatially-Varying BRDFs From Photometric Stereo. Technical report, University of Washington, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237200</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[{Gortler96} S. Gortler, R. Grzeszczuk, R. Szeliski, and M. Cohen. The Lumigraph. Computer Graphics, 30(Annual Conference Series):43--54, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>13023</ref_obj_id>
				<ref_obj_pid>13021</ref_obj_pid>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[{Greene86} N. Greene. Environment Mapping and Other Applications of World Projections. IEEE Computer Graphics & Applications, 6(11):21--29, nov 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882341</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[{Han03} Jefferson Y. Han and Ken Perlin. Measuring bidirectional texture reflectance with a kaleidoscope. ACM Trans. Graph., 22(3):741--748, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>50</ref_seq_no>
				<ref_text><![CDATA[{Hanrahan89} P. Hanrahan and D. Salzmann. A rapid hierarchical radiosity algorithm for unoccluded environments. In Eurographics Workshop on Photosimulation, Realism and Physics in Computer Graphics, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166139</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>51</ref_seq_no>
				<ref_text><![CDATA[{Hanrahan93} P. Hanrahan and W. Krueger. Reflection from Layered Surfaces Due to Subsurface Scattering. In Proceedings of SIGGRAPH 93, Computer Graphics Proceedings, Annual Conference Series, pages 165--174, August 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>52</ref_seq_no>
				<ref_text><![CDATA[{Hauth02} Michael Hauth, Olaf Etzmuss, Bernd Eberhardt, Reinhard Klein, Ralf Sarlette, Mirko Sattler, Katja Daubert, and Jan Kautz. Cloth Animation and Rendering. In Eurographics 2002 Tutorials, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383575</ref_obj_id>
				<ref_obj_pid>2383533</ref_obj_pid>
				<ref_seq_no>53</ref_seq_no>
				<ref_text><![CDATA[{Hawkins04} Tim Hawkins, Andreas Wenger, Chris Tchou, Andrew Gardner, Fredrik G&#246;ransson, and Paul E. Debevec. Animatable Facial Reflectance Fields. In Proceedings of the 15th Eurographics Workshop on Rendering, pages 309--321, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122738</ref_obj_id>
				<ref_obj_pid>122718</ref_obj_pid>
				<ref_seq_no>54</ref_seq_no>
				<ref_text><![CDATA[{He91} X. He, K. Torrance, F. Sillion, and D. Greenberg. A Comprehensive Physical Model for Light Reflection. In Proc. SIGGRAPH, pages 175--186, July 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>55</ref_seq_no>
				<ref_text><![CDATA[{Heckbert92} Paul Heckbert. Discontinuity mesching for radiosity. In Proceedings of the Third Eurographics Workshop on Rendering (Bristol, UK), pages 203--226, May 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>285310</ref_obj_id>
				<ref_obj_pid>285305</ref_obj_pid>
				<ref_seq_no>56</ref_seq_no>
				<ref_text><![CDATA[{Heidrich98} Wolfgang Heidrich. View-Independent Environment Maps. In Proceedings of Eurographics/SIGGRAPH Workshop on Graphics Hardware '98, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311554</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>57</ref_seq_no>
				<ref_text><![CDATA[{Heidrich99a} W. Heidrich and H.-P. Seidel. Realistic, Hardware-accelerated Shading and Lighting. In Proceedings SIGGRAPH, pages 171--178, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>58</ref_seq_no>
				<ref_text><![CDATA[{Heidrich99b} Wolfgang Heidrich. High-quality Shading and Lighting for Hardware-accelerated Rendering. PhD thesis, University of Erlangen-Nuremberg, April 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344984</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>59</ref_seq_no>
				<ref_text><![CDATA[{Heidrich00} W. Heidrich, K. Daubert, J. Kautz, and H.-P. Seidel. Illuminating Micro Geometry Based on Precomputed Visibility. In Proc. SIGGRAPH, pages 455--464, July 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>794489</ref_obj_id>
				<ref_obj_pid>794189</ref_obj_pid>
				<ref_seq_no>60</ref_seq_no>
				<ref_text><![CDATA[{Heikkil&#228;97} Janne Heikkil&#228; and Olli Silv&#233;n. A Four-Step Camera Calibration Procedure With Implicit Image Correction. In CVPR97, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>61</ref_seq_no>
				<ref_text><![CDATA[{Horn86} B. Horn. Computer Vision. MIT Press, Cambridge, Mass., 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>62</ref_seq_no>
				<ref_text><![CDATA[{Hunter87} Richard S. Hunter and Richard W. Harold. The measurement of appearance. Wiley, 2. ed., 5. print. edition, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>63</ref_seq_no>
				<ref_text><![CDATA[{IEC99} Multimedia Systems and Equipment - Colour Measurement and Management - Part 2-1: Colour Management - Default RGB Colour Space - sRGB. Publication IEC 61966-2-1, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>64</ref_seq_no>
				<ref_text><![CDATA[{Immel86} David S. Immel, Michael F. Cohen, and Donald P. Greenberg. A Radiosity Method for Non-Diffuse Environments. In Computer Graphics (Proceedings of SIGGRAPH 86), pages 133--142, August 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>65</ref_seq_no>
				<ref_text><![CDATA[{Ishimaru78} Akira Ishimaru. Wave Propagation and Scattering in Random Media. Academic Press, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>66</ref_seq_no>
				<ref_text><![CDATA[{ISO99} ISO 14524:1999: Photography - Electronic Still-Picture Cameras - Methods for Measuring Opto-Electronic Conversion Functions (OECFs), 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>67</ref_seq_no>
				<ref_text><![CDATA[{Janesick01} James R. Janesick. Scientific Charge-Coupled Devices. SPIE, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>275461</ref_obj_id>
				<ref_obj_pid>275458</ref_obj_pid>
				<ref_seq_no>68</ref_seq_no>
				<ref_text><![CDATA[{Jensen96} H. W. Jensen. Global Illumination using Photon Maps. In 7th Eurographics Workshop on Rendering, pages 21--30, jun 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280925</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>69</ref_seq_no>
				<ref_text><![CDATA[{Jensen98} Henrik Wann Jensen and Per H. Christensen. Efficient Simulation of Light Transport in Scences with Participating Media using Photon Maps. In SIGGRAPH 1998, pages 311--320, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383840</ref_obj_id>
				<ref_obj_pid>2383815</ref_obj_pid>
				<ref_seq_no>70</ref_seq_no>
				<ref_text><![CDATA[{Jensen99} Henrik Wann Jensen, Justin Legakis, and Julie Dorsey. Rendering of Wet Materials. In Rendering Workshop 1999, pages 281--290, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383319</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>71</ref_seq_no>
				<ref_text><![CDATA[{Jensen01} Henrik Wann Jensen, Stephen R. Marschner, Marc Levoy, and Pat Hanrahan. A Practical Model for Subsurface Light Transport. In SIGGRAPH 2001, pages 511--518, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325167</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>72</ref_seq_no>
				<ref_text><![CDATA[{Kajiya85} J. T. Kajiya. Anisotropic reflection models. Computer Graphics, 19(Annual Conference Series):15--21, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>73</ref_seq_no>
				<ref_text><![CDATA[{Kajiya86} James T. Kajiya. The rendering equation. In Computer Graphics (SIGGRAPH '86 Proceedings), 20(4):143--150, August 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>263037</ref_obj_id>
				<ref_obj_pid>263023</ref_obj_pid>
				<ref_seq_no>74</ref_seq_no>
				<ref_text><![CDATA[{Kambhatla97} Nandakishore Kambhatla and Todd K. Leen. Dimension reduction by local principal component analysis. Neural Comput., 9(7): 1493--1516, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882270</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>75</ref_seq_no>
				<ref_text><![CDATA[{Kang03} Sing Bing Kang, Matthew Uyttendaele, Simon Winder, and Richard Szeliski. High Dynamic Range Video. ACM Transactions on Graphics, 22(3):319--325, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383838</ref_obj_id>
				<ref_obj_pid>2383815</ref_obj_pid>
				<ref_seq_no>76</ref_seq_no>
				<ref_text><![CDATA[{Kautz99} J. Kautz and M. McCool. Interactive Rendering with Arbitrary BRDFs using Separable Approximations. In Tenth Eurographics Workshop on Rendering, pages 281--292, June 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>77</ref_seq_no>
				<ref_text><![CDATA[{Kautz00a} J. Kautz and M. McCool. Approximation of Glossy Reflection with Prefiltered Environment Maps. In Proceedings Graphics Interface, pages 119--126, may 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732274</ref_obj_id>
				<ref_obj_pid>647652</ref_obj_pid>
				<ref_seq_no>78</ref_seq_no>
				<ref_text><![CDATA[{Kautz00b} Jan Kautz, Pere-Pau V&#225;zquez, Wolfgang Heidrich, and Hans-Peter Seidel. A Unified Approach to Prefiltered Environment Maps. In 11th Eurographics Workshop on Rendering, pages 185--196, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>581934</ref_obj_id>
				<ref_obj_pid>581896</ref_obj_pid>
				<ref_seq_no>79</ref_seq_no>
				<ref_text><![CDATA[{Kautz02} J. Kautz, P.-P. Sloan, and J. Snyder. Arbitrary BRDF Shading for Low-Frequency Lighting Using Spherical Harmonics. In 13th Eurographics Workshop on Rendering, pages 301--308, June 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166136</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>80</ref_seq_no>
				<ref_text><![CDATA[{Kawai93} John K. Kawai, James S. Painter, and Michael F. Cohen. Radioptimization - Goal Based Rendering. In Proceedings of SIGGRAPH 93, Computer Graphics Proceedings, Annual Conference Series, pages 147--154, August 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>552373</ref_obj_id>
				<ref_seq_no>81</ref_seq_no>
				<ref_text><![CDATA[{Klette98} Reinhard Klette, Karsten Schl&#252;ns, and Andreas Koschan. Computer Vision: Three-Dimensional Data from Images. Springer, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>82</ref_seq_no>
				<ref_text><![CDATA[{Kobbelt96} L. Kobbelt. Discrete fairing. In Proc. of the 7th IMA Conf. on the Mathematics of Surfaces, pages 101--131, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>83</ref_seq_no>
				<ref_text><![CDATA[{Kobbelt00} Leif P. Kobbelt, Stephan Bischoff, Mario Botsch, Kolja K&#228;hler, Christian R&#246;ssl, Robert Schneider, and Jens Vorsatz. Geometric Modeling Based on Polygonal Meshes. Technical Report MPI-I-2000-4-002, Max-Planck-Institut f&#252;r Informatik, July 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>84</ref_seq_no>
				<ref_text><![CDATA[{Koenderink96a} J. Koenderink and A. van Doorn. Illuminance texture due to surface mesostructure. Journal of the Optical Society of America, 13(3):452--463, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>649002</ref_obj_id>
				<ref_obj_pid>645310</ref_obj_pid>
				<ref_seq_no>85</ref_seq_no>
				<ref_text><![CDATA[{Koenderink96b} J. Koenderink, A. van Doorn, and M. Stavridi. Bidirectional Reflection Distribution Function expressed in terms of surface scattering modes. In Proc. 4th Europ. Conf. on Computer Vision, pages 28--39, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>86</ref_seq_no>
				<ref_text><![CDATA[{Koenderink01} J. Koenderink and A. van Doorn. Shading in the Case of Translucent Objects. In Proceedings of SPIE, volume 4299, pages 312--320, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>87</ref_seq_no>
				<ref_text><![CDATA[{Koudelka03} Mellisa L. Koudelka, Sebastian Magda, Peter N. Belhumeur, and David J. Kriegman. Acquisition, Compression and Synthesis of Bidirectional Texture Functions. In Texture 2003, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>88</ref_seq_no>
				<ref_text><![CDATA[{Krawczyk05} Grzegorz Krawczyk, Michael Goesele, and Hans-Peter Seidel. Photometric Calibration of High Dynamic Range Cameras. MPI Informatik Technical Report MPI-I-2005-4-005, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>89</ref_seq_no>
				<ref_text><![CDATA[{Lafortune93} E. Lafortune and Y. Willems. Bidirectional Path Tracing. In Computer-graphics, pages 95--104, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>90</ref_seq_no>
				<ref_text><![CDATA[{Lafortune94} Eric P. Lafortune and Yves D. Willems. A Theoretical Framework for Physically Based Rendering. Computer Graphics Forum, 13(2):97--107, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>275468</ref_obj_id>
				<ref_obj_pid>275458</ref_obj_pid>
				<ref_seq_no>91</ref_seq_no>
				<ref_text><![CDATA[{Lafortune96} Eric P. F. Lafortune and Yves D. Willems. Rendering Participating Media with Bidirectional Path Tracing. In Rendering Workshop 1996, pages 91--100, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258801</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>92</ref_seq_no>
				<ref_text><![CDATA[{Lafortune97} E. Lafortune, S. Foo, K. Torrance, and D. Greenberg. Non-Linear Approximation of Reflectance Functions. In Proc. SIGGRAPH, pages 117--126, August 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>93</ref_seq_no>
				<ref_text><![CDATA[{Lambert60} J. Lambert. Photometria Sive de Mensura et Gradibus Luminus, Colorum et Umbrae. Eberhard Klett, 1760.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566610</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>94</ref_seq_no>
				<ref_text><![CDATA[{Latta02} L. Latta and A. Kolb. Homomorphic Factorization of BRDF-based Lighting Computation. In Proceedings SIGGRAPH, pages 509--516, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>364407</ref_obj_id>
				<ref_obj_pid>364338</ref_obj_pid>
				<ref_seq_no>95</ref_seq_no>
				<ref_text><![CDATA[{Lengyel01} J. Lengyel, E. Praun, A. Finkelstein, and H. Hoppe. Real-Time Fur over Arbitrary Surfaces. In Symposium on Interactive 3D Graphics, pages 227--232, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>826556</ref_obj_id>
				<ref_obj_pid>826029</ref_obj_pid>
				<ref_seq_no>96</ref_seq_no>
				<ref_text><![CDATA[{Lensch00} H. Lensch, W. Heidrich, and H.-P. Seidel. Automated Texture Registration and Stitching for Real World Models. In Pacific Graphics '00, pages 317--326, October 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732303</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>97</ref_seq_no>
				<ref_text><![CDATA[{Lensch01} Hendrik P. A. Lensch, Jan Kautz, Michael Goesele, Wolfgang Heidrich, and Hans-Peter Seidel. Image-Based Reconstruction of Spatially Varying Materials. In Rendering Techniques 2001: 12th Eurographics Workshop on Rendering, pages 103--114. Eurographics, June 2001. ISBN 3-211-83709-4.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>98</ref_seq_no>
				<ref_text><![CDATA[{Lensch02a} Hendrik P. A. Lensch, Katja Daubert, and Hans-Peter Seidel. Interactive Semi-Transparent Volumetric Textures. In Guenther Greiner, Heindrich Niemann, Thomas Ertl, Bernd Girod, and Hans-Peter Seidel, editors, Proceedings of Vision, Modeling and Visualization, pages 505--512, Erlangen, Germany, 2002. unknown.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>826632</ref_obj_id>
				<ref_obj_pid>826030</ref_obj_pid>
				<ref_seq_no>99</ref_seq_no>
				<ref_text><![CDATA[{Lensch02b} Hendrik P. A. Lensch, Michael Goesele, Philippe Bekaert, Jan Kautz, Marcus A. Magnor, Jochen Lang, and Hans-Peter Seidel. Interactive Rendering of Translucent Objects. In Sabine Coquillart, Heung-Yeung Shum, and Shi-Min Hu, editors, Proceedings of Pacific Graphics 2002, pages 214--224, Beijing, China, 2002. IEEE Computer Society.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>636891</ref_obj_id>
				<ref_obj_pid>636886</ref_obj_pid>
				<ref_seq_no>100</ref_seq_no>
				<ref_text><![CDATA[{Lensch03} Hendrik P. A. Lensch, Jan Kautz, Michael Goesele, Wolfgang Heidrich, and Hans-Peter Seidel. Image-Based Reconstruction of Spatial Appearance and Geometric Detail. ACM Transactions on Graphics, 22(2):234--257, April 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>101</ref_seq_no>
				<ref_text><![CDATA[{Lewis93} R. Lewis. Making Shaders More Physically Plausible. In 4th Eurographics Workshop on Rendering, pages 47--62, June 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>826600</ref_obj_id>
				<ref_obj_pid>826030</ref_obj_pid>
				<ref_seq_no>102</ref_seq_no>
				<ref_text><![CDATA[{Li02} Yuazhen Li, Sthefen Lin, Sing Bing Kang, Hanquing Lu, and Heun-Yeung Shum. Single-Image Reflectance Estimation for Relighting by Iterative Soft Grouping. In Pacific Graphics '02, pages 483--485, October 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>851576</ref_obj_id>
				<ref_obj_pid>850924</ref_obj_pid>
				<ref_seq_no>103</ref_seq_no>
				<ref_text><![CDATA[{Lin99} S. Lin and S. Lee. Estimation of Diffuse and Specular Appearance. In International Conference on Computer Vision, pages 855--860, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>977353</ref_obj_id>
				<ref_obj_pid>977247</ref_obj_pid>
				<ref_seq_no>104</ref_seq_no>
				<ref_text><![CDATA[{Liu04} Xinguo Liu, Yaohua Hu, Jingdan Zhang, Xin Tong, Baining Guo, and Heung-Yeung Shum. Synthesis and Rendering of Bidirectional Texture Functions on Arbitrary Surfaces. IEEE Transactions on Visualization and Computer Graphics, 10(3):278--289, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>105</ref_seq_no>
				<ref_text><![CDATA[{Lu98} R. Lu, J. Koenderink, and A. Kappers. Optical Properties (bidirectional reflectance distribution functions) of velvet. Applied Optics, 37(25):5974--5984, September 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>106</ref_seq_no>
				<ref_text><![CDATA[{Lyon02} Richard F. Lyon and Paul M. Hubel. Eyeing the Camera: Into the Next Century. In Proceedings of the 10th Color Imaging Conference on Color Science and Engeneering Systems, Technologies and Applications (CIC-02), pages 349--355. IS&T, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383320</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>107</ref_seq_no>
				<ref_text><![CDATA[{Malzbender01} Tom Malzbender, Dan Gelb, and Hans Wolters. Polynomial texture maps. In Proceedings of SIGGRAPH, pages 519--528. ACM Press, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>108</ref_seq_no>
				<ref_text><![CDATA[{Marschner97} S. R. Marschner and D. P. Greenberg. Inverse Lighting for Photography. In Proceedings of IS&T/SID Fifth Color Imaging Conference, pages 262--265, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>927098</ref_obj_id>
				<ref_seq_no>109</ref_seq_no>
				<ref_text><![CDATA[{Marschner98} S. Marschner. Inverse rendering for computer graphics. PhD thesis, Cornell University, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383829</ref_obj_id>
				<ref_obj_pid>2383815</ref_obj_pid>
				<ref_seq_no>110</ref_seq_no>
				<ref_text><![CDATA[{Marschner99} S. Marschner, S. Westin, E. Lafortune, K. Torrance, and D. Greenberg. Image-based BRDF Measurement Including Human Skin. In 10th Eurographics Workshop on Rendering, pages 131--144, June 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732140</ref_obj_id>
				<ref_obj_pid>647652</ref_obj_pid>
				<ref_seq_no>111</ref_seq_no>
				<ref_text><![CDATA[{Marschner00a} S. Marschner, B. Guenter, and S. Raghupathy. Modeling and Rendering for Realistic Facial Animation. 11th Eurographics Workshop on Rendering, pages 231--242, June 2000. ISBN 3-211-83535-0.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>112</ref_seq_no>
				<ref_text><![CDATA[{Marschner00b} S. Marschner, S. Westin, E. Lafortune, and K. Torrance. Image-based Measurement of the Bidirectional Reflection Distribution Function. Applied Optics, 39(16):2592--2600, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882345</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>113</ref_seq_no>
				<ref_text><![CDATA[{Marschner03} Stephen R. Marschner, Henrik Wann Jensen, Mike Cammarano, Steve Worley, and Pat Hanrahan. Light Scattering From Human Hair Fibers. ACM Transactions on Graphics (Proc. SIGGRAPH), 22(3):780--791, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882315</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>114</ref_seq_no>
				<ref_text><![CDATA[{Masselus03} Vincent Masselus, Pieter Peers, Philip Dutr&#233;, and Yves D. Willems. Relighting With 4D Incident Light Fields. ACM Transactions on Graphics, 22(3):613--620, July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566599</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>115</ref_seq_no>
				<ref_text><![CDATA[{Matusik02a} Wojciech Matusik, Hanspeter Pfister, Addy Ngan, Paul Beardsley, Remo Ziegler, and Leonard McMillan. Image-based 3D photography using opacity hulls. In Proceedings of SIGGRAPH, pages 427--437. ACM Press, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566599</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>116</ref_seq_no>
				<ref_text><![CDATA[{Matusik02b} Wojciech Matusik, Hanspeter Pfister, Addy Ngan, Paul Beardsley, Remo Ziegler, and Leonard McMillan. Image-based 3D photography using opacity hulls. In Proceedings of ACM SIGGRAPH 2002, Computer Graphics Proceedings, Annual Conference Series, pages 427--437. ACM Press / ACM SIGGRAPH, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569057</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>117</ref_seq_no>
				<ref_text><![CDATA[{McAllister02} D. McAllister, A. Lastra, and W. Heidrich. Efficient Rendering of Spatial Bi-directional Reflectance Distribution Functions. Graphics Hardware 2002, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383276</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>118</ref_seq_no>
				<ref_text><![CDATA[{McCool01} M. McCool, J. Ang, and A. Ahmad. A Homomorphic Factorization of BRDFs for High-Performance Rendering. In Proceedings SIGGRAPH, pages 171--178, August 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>119</ref_seq_no>
				<ref_text><![CDATA[{Meseth04} Jan Meseth, Gero M&#252;ller, and Reinhard Klein. Reflectance Field based real-time, high-quality Rendering of Bidirectional Texture Functions. Computers and Graphics, 28(1):103--112, February 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>120</ref_seq_no>
				<ref_text><![CDATA[{Meyer98} A. Meyer and F. Neyret. Interactive Volumetric Textures. In Proc. of Eurographics Workshop on Rendering, pages 157--168, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>121</ref_seq_no>
				<ref_text><![CDATA[{Miller84} G. Miller and R. Hoffman. Illumination and Reflection Maps: simulated Objects in simulated and Real Environments. In SIGGRAPH '84 Course Notes - Advanced Computer Graphics Animation, July 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>122</ref_seq_no>
				<ref_text><![CDATA[{M&#252;ller03} Gero M&#252;ller, Jan Meseth, and Reinhard Klein. Compression and real-time Rendering of Measured BTFs using local PCA. In Vision, Modeling and Visualisation 2003, pages 271--280, November 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>123</ref_seq_no>
				<ref_text><![CDATA[{M&#252;ller04} Gero M&#252;ller, Jan Meseth, and Reinhard Klein. Fast Environmental Lighting for Local-PCA Encoded BTFs. In Computer Graphics International 2004 (CGI2004), June 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>124</ref_seq_no>
				<ref_text><![CDATA[{Nayar90} S. Nayar, K. Ikeuchi, and T. Kanade. Determining Shape and Reflectance of Hybrid Surfaces by Photometric Sampling. RA, 6(4):418--431, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882280</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>125</ref_seq_no>
				<ref_text><![CDATA[{Ng03} Ren Ng, Ravi Ramamoorthi, and Pat Hanrahan. All-Frequency Shadows using Non-Linear Wavelet Lighting Approximation. ACM Transactions on Graphics, 22(3):376--381, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>126</ref_seq_no>
				<ref_text><![CDATA[{Nicodemus77} Fred E. Nicodemus, Joseph C. Richmond, Jack J. Hsia, I. W. Ginsberg, and T. Limperis. Geometrical Considerations and Nomenclature for Reflectance. National Bureau of Standards, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>127</ref_seq_no>
				<ref_text><![CDATA[{Nishino99} K. Nishino, Yoichi Sato, and Katsushi Ikeuchi. Eigen-texture method: appearance compression based on 3D model. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR'99), volume 1, pages 618--624, June 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>128</ref_seq_no>
				<ref_text><![CDATA[{Nishino01} K. Nishino, Z. Zhang, and K. Ikeuchi. "Determining Reflectance Parameters and Illumination Distribution from a Sparse Set of Images for View-dependent Image Synthesis". In in Proc. of Eighth IEEE International Conference on Computer Vision ICCV '01, pages 599--606, july 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882427</ref_obj_id>
				<ref_obj_pid>882404</ref_obj_pid>
				<ref_seq_no>129</ref_seq_no>
				<ref_text><![CDATA[{Peers03} Pieter Peers and Philip Dutr&#233;. Wavelet Environment Matting. In Proceedings of the 14th Eurographics Symposium on Rendering, pages 157--166, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>78304</ref_obj_id>
				<ref_obj_pid>78302</ref_obj_pid>
				<ref_seq_no>130</ref_seq_no>
				<ref_text><![CDATA[{Perona90} P. Perona and J. Malik. Scale Space and Edge Detection using Anisotropic Diffusion. IEEE Trans. on Pattern Analysis and Machine Intelligence, 12(7):629--639, July 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344824</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>131</ref_seq_no>
				<ref_text><![CDATA[{Pharr00} Matt Pharr and Pat Hanrahan. Monte Carlo Evaluation of Non-linear Scattering Equations for Subsurface Reflection. In SIGGRAPH 2000, pages 75--84, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>132</ref_seq_no>
				<ref_text><![CDATA[{Phong75} B.-T. Phong. Illumination for Computer Generated Pictures. Communications of the ACM, 18(6):311--317, June 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97909</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>133</ref_seq_no>
				<ref_text><![CDATA[{Poulin90} P. Poulin and A. Fournier. A Model for Anisotropic Reflection. In Proceedings SIGGRAPH, pages 273--282, July 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>148286</ref_obj_id>
				<ref_seq_no>134</ref_seq_no>
				<ref_text><![CDATA[{Press92} W. Press, S. Teukolsky, W. Vetterling, and B. Flannery. Numerical recipes in C - The art of scientific computation. ISBN 0-521-43108-5. Cambridge University Press, 2nd edition, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>135</ref_seq_no>
				<ref_text><![CDATA[{Radloff04} Judith Radloff. Obtaining the Bidirectional Texture Reflectance of Real-World Surfaces by means of a Kaleidoscope. Technical report, Department of Computer Science, Rhodes University, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383317</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>136</ref_seq_no>
				<ref_text><![CDATA[{Ramamoorthi01a} R. Ramamoorthi and P. Hanrahan. An Efficient Representation for Irradiance Environment Maps. In Proceedings SIGGRAPH, pages 497--500, August 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383271</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>137</ref_seq_no>
				<ref_text><![CDATA[{Ramamoorthi01b} Ravi Ramamoorthi and Pat Hanrahan. A Signal-Processing Framework for Inverse Rendering. In Eugene Fiume, editor, Proceedings of SIGGRAPH 2001, Computer Graphics Proceedings, Annual Conference Series, pages 117--128. ACM Press / ACM SIGGRAPH, August 2001. ISBN 1-58113-292-1.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566611</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>138</ref_seq_no>
				<ref_text><![CDATA[{Ramamoorthi02a} R. Ramamoorthi and P. Hanrahan. Frequency Space environment Map Rendering. In Proceedings SIGGRAPH, pages 517--526, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628830</ref_obj_id>
				<ref_obj_pid>628331</ref_obj_pid>
				<ref_seq_no>139</ref_seq_no>
				<ref_text><![CDATA[{Ramamoorthi02b} Ravi Ramamoorthi. Analytic PCA construction for theoretical analysis of lighting variability in images of a Lambertian object. PAMI Oct 2002, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>140</ref_seq_no>
				<ref_text><![CDATA[{Reflectance} Columbia-Utrecht Reflectance and Texture Database. http://www1.cs.columbia.edu/CAVE/curet/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>141</ref_seq_no>
				<ref_text><![CDATA[{Robertson99} Mark A. Robertson, Sean Borman, and Robert L. Stevenson. Dynamic Range Improvement Through Multiple Exposures. In Proceedings of ICIP 1999, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>142</ref_seq_no>
				<ref_text><![CDATA[{Robertson03} Mark A. Robertson, Sean Borman, and Robert L. Stevenson. Estimation-Theoretic Approach to Dynamic Range Enhancement using Multiple Exposures. Journal of Electronic Imaging, 12(2):219--285, April 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>77636</ref_obj_id>
				<ref_obj_pid>77635</ref_obj_pid>
				<ref_seq_no>143</ref_seq_no>
				<ref_text><![CDATA[{Rushmeier90} Holly E. Rushmeier and Kenneth E. Torrance. Extending the Radiosity Method to Include Specularly Reflecting and Translucent Materials. ACM Trans. Graph., 9(1):1--27, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>144</ref_seq_no>
				<ref_text><![CDATA[{Rusinkiewicz98} S. Rusinkiewicz. A New Change of Variables for Efficient BRDF Representation. In Rendering Techniques '98, pages 11--22, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>145</ref_seq_no>
				<ref_text><![CDATA[{Rusinkiewicz00} S. Rusinkiewicz and S. Marschner. Measurement I - BRDFs. Script of Course CS448C: Topics in Computer Graphics, held at Stanford University, October 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258885</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>146</ref_seq_no>
				<ref_text><![CDATA[{Sato97} Y. Sato, M. Wheeler, and K. Ikeuchi. Object Shape and Reflectance Modeling from Observation. In Proc. SIGGRAPH, pages 379--388, August 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882429</ref_obj_id>
				<ref_obj_pid>882404</ref_obj_pid>
				<ref_seq_no>147</ref_seq_no>
				<ref_text><![CDATA[{Sattler03} M. Sattler, R. Sarlette, and R. Klein. Efficient and Realistic Visualization of Cloth. Proceedings of the Eurographics Symposium on Rendering 2003, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>148</ref_seq_no>
				<ref_text><![CDATA[{Schlick94} Christophe Schlick. An Inexpensive BRDF Model for Physically-based Rendering. Computer Graphics Forum, 13(3):233--246, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>149</ref_seq_no>
				<ref_text><![CDATA[{Schneider04} Martin Schneider. Real-Time BTF Rendering. In Proceedings of CESCG 2004, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166135</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>150</ref_seq_no>
				<ref_text><![CDATA[{Schoeneman93} Chris Schoeneman, Julie Dorsey, Brian Smits, James Arvo, and Donald Greenberg. Painting With Light. In Proceedings of SIGGRAPH 93, Computer Graphics Proceedings, Annual Conference Series, pages 143--146, August 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073257</ref_obj_id>
				<ref_obj_pid>1073204</ref_obj_pid>
				<ref_seq_no>151</ref_seq_no>
				<ref_text><![CDATA[{Sen05} Pradeep Sen, Billy Chen, Gaurav Garg, Steve Marschner, Mark Horowitz, Marc Levoy, and Hendrik P. A. Lensch. Dual Photography. ACM Transactions on Graphics, July 2005. (accepted for publication).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>152</ref_seq_no>
				<ref_text><![CDATA[{Shirley95} P. Shirley, B. Wade, P. Hubbard, D. Zareski, B. Walter, and D. Greenberg. Global Illumination via Density Estimation. In 6th Eurographics Workshop on Rendering, pages 219--231, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122739</ref_obj_id>
				<ref_obj_pid>122718</ref_obj_pid>
				<ref_seq_no>153</ref_seq_no>
				<ref_text><![CDATA[{Sillion91} F. Sillion, J. Arvo, S. Westin, and D. Greenberg. A Global Illumination Solution for General Reflectance Distributions. In Proceedings SIGGRAPH, pages 187-196, July 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>561383</ref_obj_id>
				<ref_seq_no>154</ref_seq_no>
				<ref_text><![CDATA[{Sillion94} Francois X. Sillion and Claude Puech. Radiosity and Global Illumination. Morgan Kaufmann Publishers, San Francisco, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614311</ref_obj_id>
				<ref_obj_pid>614259</ref_obj_pid>
				<ref_seq_no>155</ref_seq_no>
				<ref_text><![CDATA[{Sillion95} Francois X. Sillion. A Unified Hierarchical Algorithm for Global Illumination with Scattering Volumes and Object Clusters. IEEE Trans. Visualization and Computer Graphics, 1(3):240--254, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566612</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>156</ref_seq_no>
				<ref_text><![CDATA[{Sloan02} Peter-Pike Sloan, Jan Kautz, and John Snyder. Precomputed Radiance Transfer for Real-Time Rendering in Dynamic, Low-Frequency Lighting Environments. In Proceedings of SIGGRAPH, pages 527--536. ACM Press, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882281</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>157</ref_seq_no>
				<ref_text><![CDATA[{Sloan03a} Peter-Pike Sloan, Jesse Hall, John Hart, and John Snyder. Clustered Principal Components for Precomputed Radiance Transfer. ACM Transactions on Graphics, 22(3):382--391, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882279</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>158</ref_seq_no>
				<ref_text><![CDATA[{Sloan03b} Peter-Pike Sloan, Xinguo Liu, Heung-Yeung Shum, and John Snyder. Bi-Scale Radiance Transfer. ACM Transactions on Graphics, 22(3):370--375, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>159</ref_seq_no>
				<ref_text><![CDATA[{Stam95} Jos Stam. Multiple Scattering as a Diffusion Process. In Rendering Workshop 1995, pages 51--58, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732287</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>160</ref_seq_no>
				<ref_text><![CDATA[{Stam01} Jos Stam. An Illumination Model for a Skin Layer Bounded by Rough Surfaces. In Rendering Workshop 2001, pages 39--52, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>161</ref_seq_no>
				<ref_text><![CDATA[{Suykens03} Frank Suykens, Karl vom Berge, Ares Lagae, and Philip Dutr&#233;. Interactive Rendering of Bidirectional Texture Functions. In Eurographics 2003, pages 463--472, September 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>105532</ref_obj_id>
				<ref_obj_pid>105528</ref_obj_pid>
				<ref_seq_no>162</ref_seq_no>
				<ref_text><![CDATA[{Tagare91} H. Tagare and R. de Figueiredo. A Theory of photometric stereo for a class of diffuse non-lambertion surfaces. IEEE Trans. Pattern Anal. Mach. Intelligence, 13(2):133--152, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566634</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>163</ref_seq_no>
				<ref_text><![CDATA[{Tong02} Xin Tong, Jingdan Zhang, Ligang Liu, Xi Wang, Baining Guo, and Heung-Yeung Shum. Synthesis of bidirectional texture functions on arbitrary surfaces. In Proceedings of SIGGRAPH, pages 665--672. ACM Press, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>164</ref_seq_no>
				<ref_text><![CDATA[{Torrance67} K. Torrance and E. Sparrow. Theory for Off-Specular Reflection from Roughened Surfaces. Journal of Optical Society of America, 57(9), 1967.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>165</ref_seq_no>
				<ref_text><![CDATA[{Tsai87} Roger Y. Tsai. A Versatile Camera Calibration Technique for High-Accuracy 3D Machine Vision Metrology Using Off-the-Shelf TV Cameras and Lenses. RA, 3(4):323--344, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>166</ref_seq_no>
				<ref_text><![CDATA[{v. Helmholtz25} H. V. Helmholtz. Treatise on Physiological Optics. Dover, New York, 1925.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>965508</ref_obj_id>
				<ref_obj_pid>965400</ref_obj_pid>
				<ref_seq_no>167</ref_seq_no>
				<ref_text><![CDATA[{Vasilescu04} M. A. O. Vasilescu and Demetri Terzopoulos. TensorTextures: Multi-linear Image-Based Rendering. In Proceedings of SIGGRAPH, August 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>927297</ref_obj_id>
				<ref_seq_no>168</ref_seq_no>
				<ref_text><![CDATA[{Veach97} E. Veach. Robust Monte Carlo Methods for Light Transport Simulation. PhD thesis, Stanford University, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134078</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>169</ref_seq_no>
				<ref_text><![CDATA[{Ward Larson92} G. Ward Larson. Measuring and Modeling Anisotropic Reflection. In Proc. SIGGRAPH, pages 265--272, July 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>581932</ref_obj_id>
				<ref_obj_pid>581896</ref_obj_pid>
				<ref_seq_no>170</ref_seq_no>
				<ref_text><![CDATA[{Wexler02} Yonatan Wexler, Andrew W. Fitzgibbon, and Andrew Zisserman. Image-Based Environment Matting. In Proceedings of the 13th Eurographics workshop on Rendering, pages 279--290, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>171</ref_seq_no>
				<ref_text><![CDATA[{Williams99} Tom L. Williams. The Optical Transfer Function of Imaging Systems. Institute of Physics Publishing, London, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>528718</ref_obj_id>
				<ref_seq_no>172</ref_seq_no>
				<ref_text><![CDATA[{Wolberg90} G. Wolberg. Digital Image Warping. IEEE Computer Society Press, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>731971</ref_obj_id>
				<ref_obj_pid>647651</ref_obj_pid>
				<ref_seq_no>173</ref_seq_no>
				<ref_text><![CDATA[{Wong97} Tien-Tsin Wong, Pheng-Ann Heng, Siu-Hang Or, and Wai-Yin Ng. Image-based Rendering with Controllable Illumination. In Proceedings of EGRW '97, pages 13--22. Springer-Verlag, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>174</ref_seq_no>
				<ref_text><![CDATA[{Woodham81} R. Woodham. Analysing Smages of Curved Surfaces. Artificial Intelligence, 17:117--140, 1981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280874</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>175</ref_seq_no>
				<ref_text><![CDATA[{Yu98} Y. Yu and J. Malik. Recovering Photometric Properties of Architectural Scenes from Photographs. In Proc. SIGGRAPH, pages 207--218, July 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311559</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>176</ref_seq_no>
				<ref_text><![CDATA[{Yu99} Y. Yu, P. Debevec, J. Malik, and T. Hawkins. Inverse Global Illumination: Recovering Reflectance Models of Real Scenes From Photographs. In Proc. SIGGRAPH, pages 215--224, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>177</ref_seq_no>
				<ref_text><![CDATA[{Zhang98} Z. Zhang. A Flexible New Technique for Camera Calibration. Tr98-71, MSR Redmond, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>178</ref_seq_no>
				<ref_text><![CDATA[{Zhang99} Z. Zhang. Flexible Camera Calibration By Viewing a Plane From Unknown Orientations. In Int. Conf. on Computer Vision, pages 666--673, September 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357025</ref_obj_id>
				<ref_obj_pid>357014</ref_obj_pid>
				<ref_seq_no>179</ref_seq_no>
				<ref_text><![CDATA[{Zhang00} Zhengyou Zhang. A Flexible New Technique for Camera Calibration. IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(11):1330--1334, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1026063</ref_obj_id>
				<ref_obj_pid>1025128</ref_obj_pid>
				<ref_seq_no>180</ref_seq_no>
				<ref_text><![CDATA[{Zhu04} Jiayuan Zhu and Yee-Hong Yang. Frequency-Based Environment Matting. In Proceedings of 12th Pacific conference on Computer Graphics and Applications, pages 402--410, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311558</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>181</ref_seq_no>
				<ref_text><![CDATA[{Zongker99} Douglas E. Zongker, Dawn M. Werner, Brian Curless, and David H. Salesin. Environment Matting and Compositing. In Proceedings of ACM SIGGRAPH 1999, pages 205--214, 1999. General References]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>182</ref_seq_no>
				<ref_text><![CDATA[Richard S. Hunter and Richard W. Harold. The Measurement of Appearance. Wiley, 2. ed., 5. print. edition, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>183</ref_seq_no>
				<ref_text><![CDATA[Fred E. Nicodemus, Joseph C. Richmond, Jack J. Hsia, I. W. Ginsberg, and T. Limperis. Geometrical Considerations and Nomenclature for Reflectance. National Bureau of Standards, 1977. BRDFs]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>184</ref_seq_no>
				<ref_text><![CDATA[James F. Blinn. Models of Light Reflection for Computer Synthesized Pictures. In SIGGRAPH '77: Proceedings of the 4th annual conference on Computer graphics and interactive techniques, pages 192--198. ACM Press, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357293</ref_obj_id>
				<ref_obj_pid>357290</ref_obj_pid>
				<ref_seq_no>185</ref_seq_no>
				<ref_text><![CDATA[R. Cook and K. Torrance. A reflection model for computer graphics. ACM Transactions On Graphics, 1(1):7--24, 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122738</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>186</ref_seq_no>
				<ref_text><![CDATA[X. He, K. Torrance, F. Sillon, and D. Greenberg. A comprehensive physical model for light reflection. Computer Graphics, 25(Annual Conference Series):175--186, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258801</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>187</ref_seq_no>
				<ref_text><![CDATA[Eric P. F. Lafortune, Sing-Choong Foo, Kenneth E. Torrance, and Donald P. Greenberg. Non-linear Approximation of Reflectance Functions. In SIGGRAPH '97: Proceedings of the 24th annual conference on Computer graphics and interactive techniques, pages 117--126. ACM Press/Addison-Wesley Publishing Co., 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>188</ref_seq_no>
				<ref_text><![CDATA[S. Marschner, S. Westin, E. Lafortune, and K. Torrance. Image-based measurement of the Bidirectional Reflection Distribution Function. Applied Optics, 39(16):2592--2600, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>189</ref_seq_no>
				<ref_text><![CDATA[Bui Tuong Phong. Illumination for Computer Generated Pictures. Commun. ACM, 18(6):311--317, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134078</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>190</ref_seq_no>
				<ref_text><![CDATA[G. Ward. Measuring and modeling anisotropic reflection. Computer Graphics, 26(Annual Conference Series):265--273, 1992. Spatially Varying BRDFs]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383270</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>191</ref_seq_no>
				<ref_text><![CDATA[Samuel Boivin and Andr&#233; Gagalowicz. Image-based rendering of diffuse, specular and glossy surfaces from a single image. In Eugene Fiume, editor, Proceedings of SIGGRAPH 2001, Computer Graphics Proceedings, Annual Conference Series, pages 107--116. ACM Press / ACM SIGGRAPH, August 2001. ISBN 1-58113-292-1.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344855</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>192</ref_seq_no>
				<ref_text><![CDATA[P. Debevec, T. Hawkins, C. Tchou, H.-P. Duiker, W. Sarokin, and M. Sagar. Acquiring the Reflectance Field of a Human Face. In Proc. SIGGRAPH, pages 145--156, July 2000. ISBN 1-58113-208-5.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>193</ref_seq_no>
				<ref_text><![CDATA[Paul Debevec, Chris Tchou, Andrew Gardner, Tim Hawkins, Charis Poullis, Jessi Stumpfel, Andrew Jones, Nathaniel Yun, Per Einarsson, Therese Lundgren, Marcos Fajardo, and Philippe Martinez. Estimating Surface Reflectance Properties of a Complex Scene under Captured Natural Illumination. Technical Report ICT-TR-06.2004, USC ICT, December 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882342</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>194</ref_seq_no>
				<ref_text><![CDATA[A. Gardner, C. Tchou, T. Hawkins, and P. Debevec. Linear light source reflectometry. ACM Trans. Graphics., 22(3):749--758, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882438</ref_obj_id>
				<ref_obj_pid>882404</ref_obj_pid>
				<ref_seq_no>195</ref_seq_no>
				<ref_text><![CDATA[Athinodoros S. Georghiades. Recovering 3-d shape and reflectance from a small number of photographs. In Eurographics Symposium on Rendering: 14th Eurographics Workshop on Rendering, pages 230--240, June 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732303</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>196</ref_seq_no>
				<ref_text><![CDATA[Hendrik P. A. Lensch, Jan Kautz, Michael Goesele, Wolfgang Heidrich, and Hans-Peter Seidel. Image-based reconstruction of spatially varying materials. In Rendering Techniques 2001: 12th Eurographics Workshop on Rendering, pages 103--114. Eurographics, June 2001. ISBN 3-211-83709-4.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>636891</ref_obj_id>
				<ref_obj_pid>636886</ref_obj_pid>
				<ref_seq_no>197</ref_seq_no>
				<ref_text><![CDATA[Hendrik P. A. Lensch, Jan Kautz, Michael Goesele, Wolfgang Heidrich, and Hans-Peter Seidel. Image-Based Reconstruction of Spatial Appearance and Geometric Detail. ACM Transactions on Graphics, 22(2):234--257, April 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383829</ref_obj_id>
				<ref_obj_pid>2383815</ref_obj_pid>
				<ref_seq_no>198</ref_seq_no>
				<ref_text><![CDATA[S. Marschner, S. Westin, E. Lafortune, K. Torrance, and D. Greenberg. Image-based BRDF Measurement Including Human Skin. In 10th Eurographics Workshop on Rendering, pages 131--144, June 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569057</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>199</ref_seq_no>
				<ref_text><![CDATA[D. McAllister, A. Lastra, and W. Heidrich. Efficient rendering of spatial bi-directional reflectance distribution functions. Graphics Hardware 2002, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>200</ref_seq_no>
				<ref_text><![CDATA[K. Nishino, Z. Zhang, and K. Ikeuchi. "determining reflectance parameters and illumination distribution from a sparse set of images for view-dependent image synthesis". In in Proc. of Eighth IEEE International Conference on Computer Vision ICCV '01, pages 599--606, july 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383271</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>201</ref_seq_no>
				<ref_text><![CDATA[Ravi Ramamoorthi and Pat Hanrahan. A signal-processing framework for inverse rendering. In Eugene Fiume, editor, Proceedings of SIGGRAPH 2001, Computer Graphics Proceedings, Annual Conference Series, pages 117--128. ACM Press / ACM SIGGRAPH, August 2001. ISBN 1-58113-292-1.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258885</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>202</ref_seq_no>
				<ref_text><![CDATA[Y. Sato, M. Wheeler, and K. Ikeuchi. Object Shape and Reflectance Modeling from Observation. In Proc. SIGGRAPH, pages 379--388, August 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311559</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>203</ref_seq_no>
				<ref_text><![CDATA[Y. Yu, P. Debevec, J. Malik, and T. Hawkins. Inverse Global Illumination: Recovering Reflectance Models of Real Scenes From Photographs. In Proc. SIGGRAPH, pages 215--224, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280874</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>204</ref_seq_no>
				<ref_text><![CDATA[Y. Yu and J. Malik. Recovering Photometric Properties of Architectural Scenes from Photographs. In Proc. SIGGRAPH, pages 207--218, July 1998. Translucent Materials, BSSRDFs]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015726</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>205</ref_seq_no>
				<ref_text><![CDATA[Yanyun Chen, Xin Tong, Jiaping Wang, Stephen Lin, Baining Guo, and Heung-Yeung Shum. Shell texture functions. ACM Transactions on Graphics, 23(3):343--353, August 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015807</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>206</ref_seq_no>
				<ref_text><![CDATA[Michael Goesele, Hendrik P. A. Lensch, Jochen Lang, Christian Fuchs, and Hans-Peter Seidel. DISCO - Acquisition of Translucent Objects. ACM Transactions on Graphics (Proceedings of SIGGRAPH 2004), 23(3), 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>207</ref_seq_no>
				<ref_text><![CDATA[Akira Ishimaru. Wave Propagation and Scattering in Random Media. Academic Press, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566619</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>208</ref_seq_no>
				<ref_text><![CDATA[Henrik Wann Jensen and Juan Buhler. A Rapid Hierarchical Rendering Technique for Translucent Materials. In SIGGRAPH 2002, pages 576--581, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383319</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>209</ref_seq_no>
				<ref_text><![CDATA[Henrik Wann Jensen, Stephen R. Marschner, Marc Levoy, and Pat Hanrahan. A Practical Model for Subsurface Light Transport. In SIGGRAPH 2001, pages 511--518, 2001. Transparent and Specular Materials, Environment Matting]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>210</ref_seq_no>
				<ref_text><![CDATA[Sameer Agarwal, Satya P. Mallick, David J. Kriegman, and Serje J. Belongie. On refractive optical flow. In Proceedings of 8th European Conference on Computer Vision, pages 483--494, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344844</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>211</ref_seq_no>
				<ref_text><![CDATA[Yung-Yu Chuang, Douglas E. Zongker, Joel Hindorff, Brian Curless, David H. Salesin, and Richard Szeliski. Environment matting extensions: Towards higher accuracy and real-time capture. In Proceedings of ACM SIGGRAPH 2000, pages 121--130, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882427</ref_obj_id>
				<ref_obj_pid>882404</ref_obj_pid>
				<ref_seq_no>212</ref_seq_no>
				<ref_text><![CDATA[Pieter Peers and Philip Dutr&#233;. Wavelet environment matting. In Proceedings of the 14th Eurographics Symposium on Rendering, pages 157--166, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>581932</ref_obj_id>
				<ref_obj_pid>581896</ref_obj_pid>
				<ref_seq_no>213</ref_seq_no>
				<ref_text><![CDATA[Yonatan Wexler, Andrew W. Fitzgibbon, and Andrew Zisserman. Image-based environment matting. In Proceedings of the 13th Eurographics workshop on Rendering, pages 279--290, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1026063</ref_obj_id>
				<ref_obj_pid>1025128</ref_obj_pid>
				<ref_seq_no>214</ref_seq_no>
				<ref_text><![CDATA[Jiayuan Zhu and Yee-Hong Yang. Frequency-based environment matting. In Proceedings of 12th Pacific conference on Computer Graphics and Applications, pages 402--410, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311558</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>215</ref_seq_no>
				<ref_text><![CDATA[Douglas E. Zongker, Dawn M. Werner, Brian Curless, and David H. Salesin. Environment matting and compositing. In Proceedings of ACM SIGGRAPH 1999, pages 205--214, 1999. Fibers]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192246</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>216</ref_seq_no>
				<ref_text><![CDATA[David C. Banks. Illumination in diverse codimensions. In Proceedings of SIGGRAPH 94, July 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74361</ref_obj_id>
				<ref_obj_pid>74333</ref_obj_pid>
				<ref_seq_no>217</ref_seq_no>
				<ref_text><![CDATA[James T. Kajiya and Timothy L. Kay. Rendering fur with three dimensional textures. In Proceedings of SIGGRAPH 1989, pages 271--280, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882345</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>218</ref_seq_no>
				<ref_text><![CDATA[Stephen R. Marschner, Henrik Wann Jensen, Mike Cammarano, Steve Worley, and Pat Hanrahan. Light scattering from human hair fibers. ACM Transactions on Graphics (Proc. SIGGRAPH), 22(3):780--791, 2003. BTFs]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>794511</ref_obj_id>
				<ref_obj_pid>794189</ref_obj_pid>
				<ref_seq_no>219</ref_seq_no>
				<ref_text><![CDATA[Kristin J. Dana, Bram van Ginneken, Shree K. Nayar, and Jan J. Koenderink. Reflectance and texture of real-world surfaces. In IEEE Conference on Computer Vision and Pattern Recognition, pages 151--157, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569057</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>220</ref_seq_no>
				<ref_text><![CDATA[D. McAllister, A. Lastra, and W. Heidrich. Efficient rendering of spatial bi-directional reflectance distribution functions. Graphics Hardware 2002, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882429</ref_obj_id>
				<ref_obj_pid>882404</ref_obj_pid>
				<ref_seq_no>221</ref_seq_no>
				<ref_text><![CDATA[M. Sattler, R. Sarlette, and R. Klein. Efficient and realistic visualization of cloth. Proceedings of the Eurographics Symposium on Rendering 2003, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566634</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>222</ref_seq_no>
				<ref_text><![CDATA[Xin Tong, Jingdan Zhang, Ligang Liu, Xi Wang, Baining Guo, and Heung-Yeung Shum. Synthesis of bidirectional texture functions on arbitrary surfaces. In Proceedings of SIGGRAPH, pages 665--672. ACM Press, 2002. Reflectance Fields]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882341</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>223</ref_seq_no>
				<ref_text><![CDATA[Jefferson Y. Han and Ken Perlin. Measuring bidirectional texture reflectance with a kaleidoscope. ACM Trans. Graph., 22(3):741--748, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383575</ref_obj_id>
				<ref_obj_pid>2383533</ref_obj_pid>
				<ref_seq_no>224</ref_seq_no>
				<ref_text><![CDATA[Tim Hawkins, Andreas Wenger, Chris Tchou, Andrew Gardner, Fredrik G&#246;ransson, and Paul E. Debevec. Animatable facial reflectance fields. In Proceedings of the 15th Eurographics Workshop on Rendering, pages 309--321, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>225</ref_seq_no>
				<ref_text><![CDATA[Eric P. Lafortune and Yves D. Willems. A theoretical framework for physically based rendering. Computer Graphics Forum, 13(2):97--107, June 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882315</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>226</ref_seq_no>
				<ref_text><![CDATA[Vincent Masselus, Pieter Peers, Philip Dutr&#233;, and Yves D. Willems. Relighting with 4d incident light fields. ACM Transactions on Graphics, 22(3):613--620, July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566599</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>227</ref_seq_no>
				<ref_text><![CDATA[Wojciech Matusik, Hanspeter Pfister, Addy Ngan, Paul Beardsley, Remo Ziegler, and Leonard McMillan. Image-based 3d photography using opacity hulls. In Proceedings of ACM SIGGRAPH 2002, Computer Graphics Proceedings, Annual Conference Series, pages 427--437. ACM Press / ACM SIGGRAPH, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198602</section_id>
		<sort_key>11</sort_key>
		<section_seq_no>11</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Recent advances in haptic rendering & applications]]></section_title>
		<section_page_from>11</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP42050475</person_id>
				<author_profile_id><![CDATA[81452602436]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>P837814</person_id>
				<author_profile_id><![CDATA[81100035394]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Miguel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Otaduy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198603</article_id>
		<sort_key>3</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Introduction to haptic rendering]]></title>
		<page_from>3</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198603</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198603</url>
		<abstract>
			<par><![CDATA[For a long time, human beings have dreamed of a virtual world where it is possible to interact with synthetic entities as if they were real. To date, the advances in computer graphics allow us to <i>see</i> virtual objects and avatars, to <i>hear</i> them, to <i>move</i> them, and to <i>touch</i> them. It has been shown that the ability to touch virtual objects increases the sense of presence in virtual environments [Insko 2001].]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P362253</person_id>
				<author_profile_id><![CDATA[81100035394]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Miguel]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Otaduy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42050475</person_id>
				<author_profile_id><![CDATA[81452602436]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>836002</ref_obj_id>
				<ref_obj_pid>527216</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Adachi, Y., Kumano, T., and Ogino, K. 1995. Intermediate representation for stiff virtual objects. Virtual Reality Annual International Symposium, 203--210.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Adams, R. J., and Hannaford, B. 1998. A two-port framework for the design of unconditionally stable haptic interfaces. Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>642999</ref_obj_id>
				<ref_obj_pid>642992</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Agarwal, P., Guibas, L., Har-Peled, S., Rabinovitch, A., and Sharir, M. 2000. Penetration depth of two convex polytopes in 3d. Nordic J. Computing 7, 227--240.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Andriot, C. 2002. Advances in virtual prototyping. Clefs CEA Vol. 47, Research and Simulation.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Astley, O. R., and Hayward, V. 1998. Multirate haptic simulation achieved by coupling finite element meshes through norton equivalents. Proc. of IEEE International Conference on Robotics and Automation.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>245054</ref_obj_id>
				<ref_obj_pid>244979</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Avila, R. S., and Sobierajski, L. M. 1996. A haptic interaction method for volume visualization. In IEEE Visualization '96, IEEE. ISBN 0-89791-864-9.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280821</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Baraff, D., and Witkin, A. 1998. Large steps in cloth simulation. Proc. of ACM SIGGRAPH, 43--54.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Baraff, D., and Witkin, A. 2001. Physically-Based Modeling. ACM SIGGRAPH Course Notes.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74356</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Baraff, D. 1989. Analytical methods for dynamic simulation of non-penetrating rigid bodies. In Computer Graphics (SIGGRAPH '89 Proceedings), J. Lane, Ed., vol. 23, 223--232.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122722</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Baraff, D. 1991. Coping with friction for non-penetrating rigid body simulation. In Computer Graphics (SIGGRAPH '91 Proceedings), T. W. Sederberg, Ed., vol. 25, 31--40.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>165682</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Baraff, D. 1992. Dynamic simulation of non-penetrating rigid body simulation. PhD thesis, Cornell University.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192168</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Baraff, D. 1994. Fast contact force computation for nonpenetrating rigid bodies. In Proceedings of SIGGRAPH '94, A. Glassner, Ed., ACM SIGGRAPH, 23--34. ISBN 0-89791-667-0.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Basdogan, C., Ho, C.-H., and Srinivasan, M. A. 1997. A ray-based haptic rendering technique for displaying shape and texture of 3d objects in virtual environments. DSC-Vol. 61, Proceedings of the ASME Dynamic Systems and Control Division, pp. 77--84.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>98741</ref_obj_id>
				<ref_obj_pid>93597</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Beckmann, N., Kriegel, H., Schneider, R., and Seeger, B. 1990. The r*-tree: An efficient and robust access method for points and rectangles. Proc. SIGMOD Conf. on Management of Data, 322--331.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Bejczy, A., and Salisbury, J. K. 1980. Kinematic coupling between operator and remote manipulator. Advances in Computer Technology Vol. 1, 197--211.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>930452</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Berkelman, P. J. 1999. Tool-Based Haptic Interaction with Dynamic Physical Simulations Using Lorentz Magnetic Levitation. PhD thesis, Carnegie Mellon University.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F. 1978. Simulation of wrinkled surfaces. In Computer Graphics (SIGGRAPH '78 Proceedings), 286--292.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97899</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Brooks, Jr., F. P., Ouh-Young, M., Batter, J. J., and Kilpatrick, P. J. 1990. Project GROPE --- Haptic displays for scientific visualization. In Computer Graphics (SIGGRAPH '90 Proceedings), F. Baskett, Ed., vol. 24, 177--185.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>232471</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Burdea, G. 1996. Force and Touch Feedback for Virtual Reality. John Wiley and Sons.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Cameron, S., and Culley, R. K. 1986. Determining the minimum translational distance between two convex polyhedra. Proceedings of International Conference on Robotics and Automation, 591--596.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Cameron, S. 1997. Enhancing GJK: Computing minimum and penetration distance between convex polyhedra. IEEE International Conference on Robotics and Automation, 3112--3117.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>907242</ref_obj_id>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Catmull, E. E. 1974. A Subdivision Algorithm for Computer Display of Curved Surfaces. PhD thesis, Dept. of CS, U. of Utah.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[&#199;avu&#351;o&#287;lu, M. C., and Tendick, F. 2000. Multirate simulation for high fidelity haptic interaction with deformable objects in virtual environments. Proc. of IEEE International Conference on Robotics and Automation, 2458--2465.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[&#199;avu&#351;o&#287;lu, M. C., Tendick, F., and Sastry, S. S. 2002. Haptic interfaces to real and virtual surgical environments. In Touch in Virtual Environments, M. L. McLaughlin, J. P. Hespanha, and G. S. Sukhatme, Eds. Prentice Hall PTR, Upper Saddle River, NJ, ch. 13, 217--237.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Chang, B., and Colgate, J. E. 1997. Real-time impulse-based simulation of rigid body systems for haptic display. Proc. of ASME Dynamic Systems and Control Division.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Chen, E. 1999. Six degree-of-freedom haptic system for desktop virtual prototyping applications. In Proceedings of the First International Workshop on Virtual Reality and Prototyping, 97--106.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Choi, S., and Tan, H. Z. 2003. Aliveness: Perceived instability from a passive haptic texture rendering system. Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>797572</ref_obj_id>
				<ref_obj_pid>795683</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Choi, S., and Tan, H. Z. 2003. An experimental study of perceived instability during haptic texture rendering: Effects of collision detection algorithm. Proc. of Haptics Symposium, 197--204.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Colgate, J. E., and Brown, J. M. 1994. Factors affecting the z-width of a haptic display. IEEE International Conference on Robotics and Automation, 3205--3210.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Colgate, J. E., and Schenkel, G. G. 1994. Passivity of a class of sampled-data systems: Application to haptic interfaces. Proc. of American Control Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Colgate, J. E., Grafing, P. E., Stanley, M. C., and Schenkel, G. 1993. Implementation of stiff virtual walls in force-reflecting interfaces. Virtual Reality Annual International Symposium, 202--207.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>849725</ref_obj_id>
				<ref_obj_pid>846238</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Colgate, J. E., Stanley, M. C., and Brown, J. M. 1995. Issues in the haptic display of tool use. Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 140--145.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Connor, C. E., and Johnson, K. O. 1992. Neural coding of tactile texture: Comparison of spatial and temporal mechanisms for roughness perception. Journal of Neuroscience 12, pp. 3414--3426.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Constantinescu, D., Salcudean, S. E., and Croft, E. A. 2004. Impulsive forces for haptic rendering of rigid contact. Proc. of International Symposium on Robotics, 1--6.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Cottle, R. W., and Dantzig, G. B. 1968. Complementarity pivot theory of mathematical programming. Linear Algebra and its Applications, 103--125.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Cottle, R. W., pang, J. S., and Stone, R. E. 1992. The linear complementarity problem. Academic-Press, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300535</ref_obj_id>
				<ref_obj_pid>300523</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Dachille, F., Qin, H., Kaufman, A., and El-Sana, J. 1999. Haptic sculpting of dynamic surfaces. Proc. of ACM Symposium on Interactive 3D Graphics, 103--110.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383262</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Debunne, G., Desbrun, M., Cani, M. P., and Barr, A. H. 2001. Dynamic real-time deformations using space and time adaptive sampling. Proc. of ACM SIGGRAPH.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>684395</ref_obj_id>
				<ref_obj_pid>646244</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Dobkin, D. P., and Kirkpatrick, D. G. 1990. Determining the separation of preprocessed polyhedra - a unified approach. In Proc. 17th Internat. Colloq. Automata Lang. Program., Springer-Verlag, vol. 443 of Lecture Notes in Computer Science, 400--413.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Dobkin, D., Hershberger, J., Kirkpatrick, D., and Suri, S. 1993. Computing the intersection-depth of polyhedra. Algorithmica 9, 518--533.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1880309</ref_obj_id>
				<ref_obj_pid>1880269</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Duriez, C., Andriot, C., and Kheddar, A. 2004. A multi-threaded approach for deformable/rigid contacts with haptic feedback. Proc. of Haptics Symposium.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218440</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Eck, M., DeRose, T., Duchamp, T., Hoppe, H., Lounsbery, M., and Stuetzle, W. 1995. Multiresolution analysis of arbitrary meshes. In SIGGRAPH 95 Conference Proceedings, Addison Wesley, R. Cook, Ed., Annual Conference Series, ACM SIGGRAPH, 173--182. held in Los Angeles, California, 06--11 August 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Edmond, C., Heskamp, D., Sluis, D., Stredney, D., Wiet, G., Yagel, R., Weghorst, S., Oppenheimer, P., Miller, J., Levin, M., and Rosenberg, L. 1997. Ent endoscopic surgical simulator. Proc. of Medicine Meets VR, 518--528.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Ehmann, S., and Lin, M. C. 2000. Accelerated proximity queries between convex polyhedra using multi-level voronoi marching. Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems, 2101--2106.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Ehmann, S., and Lin, M. C. 2001. Accurate and fast proximity queries between polyhedra using convex surface decomposition. Computer Graphics Forum (Proc. of Eurographics'2001) 20, 3, 500--510.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2385948</ref_obj_id>
				<ref_obj_pid>2385930</ref_obj_pid>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[El-Sana, J., and Varshney, A. 2000. Continuously-adaptive haptic rendering. Virtual Environments 2000, pp. 135--144.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Ellis, R. E., Sarkar, N., and Jenkins, M. A. 1997. Numerical methods for the force reflection of contact. ASME Transactions on Dynamic Systems, Modeling and Control 119, 768--774.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[Ernst, M. O., and Banks, M. S. 2001. Does vision always dominate haptics? Touch in Virtual Environments Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[Fisher, S., and Lin, M. C. 2001. Fast penetration depth estimation for elastic bodies using deformed distance fields. Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1103908</ref_obj_id>
				<ref_obj_pid>1103900</ref_obj_pid>
				<ref_seq_no>50</ref_seq_no>
				<ref_text><![CDATA[Fisher, B., Fels, S., MacLean, K., Munzner, T., and Rensink, R. 2004. Seeing, hearing and touching: Putting it all together. In ACM SIGGRAPH course notes.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835880</ref_obj_id>
				<ref_obj_pid>580130</ref_obj_pid>
				<ref_seq_no>51</ref_seq_no>
				<ref_text><![CDATA[Foskey, M., Otaduy, M. A., and Lin, M. C. 2002. ArtNova: Touch-enabled 3D model design. Proc. of IEEE Virtual Reality Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>705098</ref_obj_id>
				<ref_obj_pid>646770</ref_obj_pid>
				<ref_seq_no>52</ref_seq_no>
				<ref_text><![CDATA[Gibson, S., Samosky, J., Mor, A., Fyock, C., Grimson, E., and Kanade, T. 1997. Simulating arthroscopic knee surgery using volumetric object representations, real-time volume rendering and haptic feedback. First Joint Conference on Computer Vision, Virtual Reality and Robotics in Medicine and Medical Robotics and Computer-Assisted Surgery (CVMed-MRCAS), 368--378.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>53</ref_seq_no>
				<ref_text><![CDATA[Gilbert, E. G., Johnson, D. W., and Keerthi, S. S. 1988. A fast procedure for computing the distance between objects in three-dimensional space. IEEE J. Robotics and Automation vol RA-4, 193--203.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>54</ref_seq_no>
				<ref_text><![CDATA[Goertz, R., and Thompson, R. 1954. Electronically controlled manipulator. Nucleonics, 46--47.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237244</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>55</ref_seq_no>
				<ref_text><![CDATA[Gottschalk, S., Lin, M., and Manocha, D. 1996. OBB-Tree: A hierarchical structure for rapid interference detection. Proc. of ACM Siggraph'96, 171--180.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>932845</ref_obj_id>
				<ref_seq_no>56</ref_seq_no>
				<ref_text><![CDATA[Gottschalk, S. 2000. Collision Queries using Oriented Bounding Boxes. PhD thesis, University of North Carolina. Department of Computer Science.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844178</ref_obj_id>
				<ref_obj_pid>844174</ref_obj_pid>
				<ref_seq_no>57</ref_seq_no>
				<ref_text><![CDATA[Govindaraju, N., Redon, S., Lin, M., and Manocha, D. 2003. CULLIDE: Interactive collision detection between complex models in large environments using graphics hardware. Proc. of ACM SIGGRAPH/Eurographics Workshop on Graphics Hardware, 25--32.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835691</ref_obj_id>
				<ref_obj_pid>554230</ref_obj_pid>
				<ref_seq_no>58</ref_seq_no>
				<ref_text><![CDATA[Gregory, A., Lin, M., Gottschalk, S., and Taylor, R. 1999. H-COLLIDE: A framework for fast and accurate collision detection for haptic interaction. In Proceedings of Virtual Reality Conference 1999, 38--45.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835797</ref_obj_id>
				<ref_obj_pid>832288</ref_obj_pid>
				<ref_seq_no>59</ref_seq_no>
				<ref_text><![CDATA[Gregory, A., Ehmann, S., and Lin, M. C. 2000. inTouch: Interactive multiresolution modeling and 3d painting with a haptic interface. Proc. of IEEE VR Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375232</ref_obj_id>
				<ref_obj_pid>375213</ref_obj_pid>
				<ref_seq_no>60</ref_seq_no>
				<ref_text><![CDATA[Gregory, A., Mascarenhas, A., Ehmann, S., Lin, M. C., and Manocha, D. 2000. 6-DoF haptic display of polygonal models. Proc. of IEEE Visualization Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882358</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>61</ref_seq_no>
				<ref_text><![CDATA[Guendelman, E., Bridson, R., and Fedkiw, R. 2003. Nonconvex rigid bodies with stacking. ACM Trans. on Graphics (Proc. of ACM SIGGRAPH) 22, 871--878.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304979</ref_obj_id>
				<ref_obj_pid>304893</ref_obj_pid>
				<ref_seq_no>62</ref_seq_no>
				<ref_text><![CDATA[Guibas, L., Hsu, D., and Zhang, L. 1999. H-Walk: Hierarchical distance computation for moving convex bodies. Proc. of ACM Symposium on Computational Geometry.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>63</ref_seq_no>
				<ref_text><![CDATA[Hannaford, B., Ryu, J.-H., and Kim, Y. S. 2002. Stable control of haptics. In Touch in Virtual Environments, M. L. McLaughlin, J. P. Hespanha, and G. S. Sukhatme, Eds. Prentice Hall PTR, Upper Saddle River, NJ, ch. 3, 47--70.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>64</ref_seq_no>
				<ref_text><![CDATA[Hasegawa, S., and Sato, M. 2004. Real-time rigid body simulation for haptic interactions based on contact volume of polygonal objects. In Proc. of Eurographics.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>662252</ref_obj_id>
				<ref_obj_pid>645626</ref_obj_pid>
				<ref_seq_no>65</ref_seq_no>
				<ref_text><![CDATA[Hayward, V., and Armstrong, B. 2000. A new computational model of friction applied to haptic rendering. Experimental Robotics VI.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>662097</ref_obj_id>
				<ref_obj_pid>645625</ref_obj_pid>
				<ref_seq_no>66</ref_seq_no>
				<ref_text><![CDATA[Hayward, V., Gregorio, P., Astley, O., Greenish, S., and Doyon, M. 1998. Freedom-7: A high fidelity seven axis haptic device with applications to surgical training. Experimental Robotics, 445--456. Lecture Notes in Control and Information Sciences 232.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>67</ref_seq_no>
				<ref_text><![CDATA[Heller, M. A., Calcaterra, J. A., Green, S. L., and Brown, L. 1999. Intersensory conflict between vision and touch: The response modality dominates when precise, attention-riveting judgements are required. Perception and Psychophysics 61, pp. 1384--1398.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>68</ref_seq_no>
				<ref_text><![CDATA[Hill, J. W., and Salisbury, J. K. 1977. Two measures of performance in a peg-in-hole manipulation task with force feedback. Thirteenth Annual Conference on Manual Control, MIT.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1246840</ref_obj_id>
				<ref_obj_pid>1246838</ref_obj_pid>
				<ref_seq_no>69</ref_seq_no>
				<ref_text><![CDATA[Ho, C.-H., Basdogan, C., and Srinivasan, M. A. 1999. Efficient point-based rendering techniques for haptic display of virtual objects. Presence 8, 5, pp. 477--491.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>364383</ref_obj_id>
				<ref_obj_pid>364338</ref_obj_pid>
				<ref_seq_no>70</ref_seq_no>
				<ref_text><![CDATA[Hoff, K., Zaferakis, A., Lin, M., and Manocha, D. 2001. Fast and simple 2d geometric proximity queries using graphics hardware. Proc. of ACM Symposium on Interactive 3D Graphics, 145--148.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>71</ref_seq_no>
				<ref_text><![CDATA[Hogan, N. 1985. Impedance control: An approach to manipulation, part i - theory, part ii - implementation, part iii - applications. Journal of Dynamic Systems, Measurement and Control 107, 1--24.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>72</ref_seq_no>
				<ref_text><![CDATA[Hogan, N. 1986. Multivariable mechanics of the neuromuscular system. IEEE Annual Conference of the Engineering in Medicine and Biology Society, 594--598.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>73</ref_seq_no>
				<ref_text><![CDATA[Hollins, M., and Risner, S. 2000. Evidence for the duplex theory of tactile texture perception. Perception & Psychophysics 62, 695--705.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258843</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>74</ref_seq_no>
				<ref_text><![CDATA[Hoppe, H. 1997. View dependent refinement of progressive meshes. In ACM SIGGRAPH Conference Proceedings, 189--198.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>239927</ref_obj_id>
				<ref_seq_no>75</ref_seq_no>
				<ref_text><![CDATA[Hubbard, P. 1994. Collision Detection for Interactive Graphics Applications. PhD thesis, Brown University.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>897971</ref_obj_id>
				<ref_seq_no>76</ref_seq_no>
				<ref_text><![CDATA[Insko, B., Meehan, M., Whitton, M., and Brooks, F. 2001. Passive haptics significantly enhances virtual environments. Tech. Rep. 01--010, Department of Computer Science, UNC Chapel Hill.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>933178</ref_obj_id>
				<ref_seq_no>77</ref_seq_no>
				<ref_text><![CDATA[Insko, B. 2001. Passive Haptics Significantly Enhance Virtual Environments. PhD thesis, University of North Carolina. Department of Computer Science.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015735</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>78</ref_seq_no>
				<ref_text><![CDATA[James, D. L., and Pai, D. K. 2004. Bd-tree: Output-sensitive collision detection for reduced deformable models. ACM Trans. on Graphics (Proc. of ACM SIGGRAPH).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>364380</ref_obj_id>
				<ref_obj_pid>364338</ref_obj_pid>
				<ref_seq_no>79</ref_seq_no>
				<ref_text><![CDATA[Johnson, D. E., and Cohen, E. 2001. Spatialized normal cone hierarchies. Proc. of ACM Symposium on Interactive 3D Graphics, pp. 129--134.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>797570</ref_obj_id>
				<ref_obj_pid>795683</ref_obj_pid>
				<ref_seq_no>80</ref_seq_no>
				<ref_text><![CDATA[Johnson, D. E., and Willemsen, P. 2003. Six degree of freedom haptic rendering of complex polygonal models. In Proc. of Haptics Symposium.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1880273</ref_obj_id>
				<ref_obj_pid>1880269</ref_obj_pid>
				<ref_seq_no>81</ref_seq_no>
				<ref_text><![CDATA[Johnson, D. E., and Willemsen, P. 2004. Accelerated haptic rendering of polygonal models through local descent. Proc. of Haptics Symposium.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835686</ref_obj_id>
				<ref_obj_pid>554230</ref_obj_pid>
				<ref_seq_no>82</ref_seq_no>
				<ref_text><![CDATA[Johnson, D., Thompson II, T. V., Kaplan, M., Nelson, D., and Cohen, E. 1999. Painting textures with a haptic interface. Proceedings of IEEE Virtual Reality Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>83</ref_seq_no>
				<ref_text><![CDATA[Karnopp, D. 1985. Computer simulation of stick slip friction in mechanical dynamic systems. Trans. ASME, Journal of Dynamic Systems, Measurement, and Control.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>84</ref_seq_no>
				<ref_text><![CDATA[Katz, D. 1989. The World of Touch. Erlbaum, Hillsdale, NJ. L. Krueger, Trans. (Original work published 1925).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>907929</ref_obj_id>
				<ref_seq_no>85</ref_seq_no>
				<ref_text><![CDATA[Kilpatrick, P. J. 1976. The use of a kinesthetic supplement in an interactive graphics system. Ph.d. thesis, The University of North Carolina at Chapel Hill.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>86</ref_seq_no>
				<ref_text><![CDATA[Kim, W., and Bejczy, A. 1991. Graphical displays for operator aid in telemanipulation. IEEE International Conference on Systems, Man and Cybernetics.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>87</ref_seq_no>
				<ref_text><![CDATA[Kim, Y. J., Lin, M. C., and Manocha, D. 2002. DEEP: an incremental algorithm for penetration depth computation between convex polytopes. Proc. of IEEE Conference on Robotics and Automation, 921--926.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>88</ref_seq_no>
				<ref_text><![CDATA[Kim, Y. J., Lin, M. C., and Manocha, D. 2002. Fast penetration depth computation using rasterization hardware and hierarchical refinement. Proc. of Workshop on Algorithmic Foundations of Robotics.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>942442</ref_obj_id>
				<ref_obj_pid>942439</ref_obj_pid>
				<ref_seq_no>89</ref_seq_no>
				<ref_text><![CDATA[Kim, Y. J., Otaduy, M. A., Lin, M. C., and Manocha, D. 2003. Six-degree-of-freedom haptic rendering using incremental and localized computations. Presence 12, 3, 277--295.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>90</ref_seq_no>
				<ref_text><![CDATA[Klatzky, R. L., and Lederman, S. J. 1995. Identifying objects from a haptic glance. Perception and Psychophysics 57, pp. 1111--1123.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>91</ref_seq_no>
				<ref_text><![CDATA[Klatzky, R. L., and Lederman, S. J. 1999. Tactile roughness perception with a rigid link interposed between skin and surface. Perception and Psychophysics 61, pp. 591--607.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>92</ref_seq_no>
				<ref_text><![CDATA[Klatzky, R. L., and Lederman, S. J. 2002. Perceiving texture through a probe. In Touch in Virtual Environments, M. L. McLaughlin, J. P. Hespanha, and G. S. Sukhatme, Eds. Prentice Hall PTR, Upper Saddle River, NJ, ch. 10, 180--193.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>93</ref_seq_no>
				<ref_text><![CDATA[Klatzky, R. L., and Lederman, S. J. 2003. Touch. In Experimental Psychology, 147--176. Volume 4 in I. B. Weiner (Editor-in-Chief). Handbook of Psychology.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>94</ref_seq_no>
				<ref_text><![CDATA[Klatzky, R. L., Lederman, S. J., Hamilton, C., Grindley, M., and Swendsen, R. H. 2003. Feeling textures through a probe: Effects of probe and surface geometry and exploratory factors. Perception and Psychophysics 65(4), pp. 613--631.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614390</ref_obj_id>
				<ref_obj_pid>614269</ref_obj_pid>
				<ref_seq_no>95</ref_seq_no>
				<ref_text><![CDATA[Klosowski, J., Held, M., Mitchell, J., Sowizral, H., and Zikan, K. 1998. Efficient collision detection using bounding volume hierarchies of k-dops. IEEE Trans. on Visualization and Computer Graphics 4, 1, 21--37.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>96</ref_seq_no>
				<ref_text><![CDATA[Kuhnapfel, U. G., Kuhn, C., Hubner, M., Krumm, H.-G., Maass, H., and Neisius, B. 1997. The karlsruhe endoscopic surgery trainer as an example for virtual reality in medical education. Minimally Invasive Therapy and Allied Technologies Vol. 6, 122--125.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>97</ref_seq_no>
				<ref_text><![CDATA[LaMotte, R. H., and Srinivasan, M. A. 1991. Surface microgeometry: Tactile perception and neural encoding. In Information Processing in the Somatosensory System, O. Franzen and J. Westman, Eds. Macmillan Press, London, 49--58.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>98</ref_seq_no>
				<ref_text><![CDATA[Larsen, E., Gottschalk, S., Lin, M., and Manocha, D. 2000. Distance queries with rectangular swept sphere volumes. Proc. of IEEE Int. Conference on Robotics and Automation.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>99</ref_seq_no>
				<ref_text><![CDATA[Larsen, E. 2001. A robot soccer simulator: A case study for rigid body contact. Game Developers Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>100</ref_seq_no>
				<ref_text><![CDATA[Lederman, S. J., Klatzky, R. L., Hamilton, C., and Ramsay, G. I. 1999. Perceiving roughness via a rigid stylus: Psychophysical effects of exploration speed and mode of touch. Haptics-e.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>101</ref_seq_no>
				<ref_text><![CDATA[Lederman, S. J., Klatzky, R. L., Hamilton, C., and Grindley, M. 2000. Perceiving surface roughness through a probe: Effects of applied force and probe diameter. Proceedings of the ASME DSCD-IMECE.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>102</ref_seq_no>
				<ref_text><![CDATA[Lederman, S. J. 1974. Tactile roughness of grooved surfaces: The touching process and the effects of macro- and microsurface structure. Perception and Psychophysics 16, pp. 385--395.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>103</ref_seq_no>
				<ref_text><![CDATA[Lemke, C. E. 1965. Bimatrix equilibrium points and mathematical programming. Management Science 11, 681--689.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>104</ref_seq_no>
				<ref_text><![CDATA[Lin, M. C., and Canny, J. F. 1991. Efficient algorithms for incremental distance computation. In Proc. IEEE Internat. Conf. Robot. Autom., vol. 2, 1008--1014.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>105</ref_seq_no>
				<ref_text><![CDATA[Lin, M., and Gottschalk, S. 1998. Collision detection between geometric models: A survey. Proc. of IMA Conference on Mathematics of Surfaces.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>106</ref_seq_no>
				<ref_text><![CDATA[Lin, M. C., and Manocha, D. 2004. Collision and proximity queries. In Handbook of Discrete and Computational Geometry, 2nd Ed., J. E. Goodman and J. O'Rourke, Eds. CRC Press LLC, Boca Raton, FL, ch. 35, 787--807.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>920962</ref_obj_id>
				<ref_seq_no>107</ref_seq_no>
				<ref_text><![CDATA[Lin, M. 1993. Efficient Collision Detection for Animation and Robotics. PhD thesis, Department of Electrical Engineering and Computer Science, University of California, Berkeley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>791558</ref_obj_id>
				<ref_obj_pid>791217</ref_obj_pid>
				<ref_seq_no>108</ref_seq_no>
				<ref_text><![CDATA[Lombardo, J. C., Cani, M.-P., and Neyret, F. 1999. Real-time collision detection for virtual surgery. Proc. of Computer Animation.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>109</ref_seq_no>
				<ref_text><![CDATA[L&#246;tstedt, P. 1984. Numerical simulation of time-dependent contact friction problems in rigid body mechanics. SIAM Journal of Scientific Statistical Computing 5, 370--393.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237750</ref_obj_id>
				<ref_obj_pid>237748</ref_obj_pid>
				<ref_seq_no>110</ref_seq_no>
				<ref_text><![CDATA[Lounsbery, M., DeRose, T. D., and Warren, J. 1997. Multiresolution analysis for surfaces of arbitrary topological type. ACM Trans. Graph. 16, 1 (Jan.), 34--73.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258847</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>111</ref_seq_no>
				<ref_text><![CDATA[Luebke, D., and Erikson, C. 1997. View-dependent simplification of arbitrary polygon environments. In Proc. of ACM SIGGRAPH.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>863276</ref_obj_id>
				<ref_seq_no>112</ref_seq_no>
				<ref_text><![CDATA[Luebke, D., Reddy, M., Cohen, J., Varshney, A., Watson, B., and Huebner, R. 2002. Level of Detail for 3D Graphics. Morgan-Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237284</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>113</ref_seq_no>
				<ref_text><![CDATA[Mark, W., Randolph, S., Finch, M., Van Verth, J., and Taylor II, R. M. 1996. Adding force feedback to graphics systems: Issues and solutions. In SIGGRAPH 96 Conference Proceedings, H. Rushmeier, Ed., Annual Conference Series, 447--452.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>114</ref_seq_no>
				<ref_text><![CDATA[Massie, T. M., and Salisbury, J. K. 1994. The phantom haptic interface: A device for probing virtual objects. Proc. of ASME Haptic Interfaces for Virtual Environment and Teleoperator Systems 1, 295--301.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>364395</ref_obj_id>
				<ref_obj_pid>364338</ref_obj_pid>
				<ref_seq_no>115</ref_seq_no>
				<ref_text><![CDATA[McDonnell, K., Qin, H., and Wlodarczyk, R. 2001. Virtual clay: A real-time sculpting system with haptic interface. Proc. of ACM Symposium on Interactive 3D Graphics, 179--190.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>116</ref_seq_no>
				<ref_text><![CDATA[McLaughlin, M., Hespanha, J. P., and Sukhatme, G. S. 2002. Touch in Virtual Environments. Prentice Hall.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311600</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>117</ref_seq_no>
				<ref_text><![CDATA[McNeely, W., Puterbaugh, K., and Troy, J. 1999. Six degree-of-freedom haptic rendering using voxel sampling. Proc. of ACM SIGGRAPH, 401--408.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383263</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>118</ref_seq_no>
				<ref_text><![CDATA[Milenkovic, V. J., and Schmidl, H. 2001. Optimization-based animation. SIGGRAPH 01 Conference Proceedings, 37--46.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>119</ref_seq_no>
				<ref_text><![CDATA[Miller, B. E., Colgate, J. E., and Freeman, R. A. 1990. Guaranteed stability of haptic systems with nonlinear virtual environments. IEEE Transactions on Robotics and Automation 16, 6, 712--719.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91451</ref_obj_id>
				<ref_obj_pid>91385</ref_obj_pid>
				<ref_seq_no>120</ref_seq_no>
				<ref_text><![CDATA[Minsky, M., Ouh-young, M., Steele, O., Brooks, Jr., F. P., and Behensky, M. 1990. Feeling and seeing: Issues in force display. In Computer Graphics (1990 Symposium on Interactive 3D Graphics), R. Riesenfeld and C. Sequin, Eds., vol. 24, 235--243.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>240160</ref_obj_id>
				<ref_seq_no>121</ref_seq_no>
				<ref_text><![CDATA[Minsky, M. 1995. Computational Haptics: The Sandpaper System for Synthesizing Texture for a Force-Feedback Display. PhD thesis, Ph.D. Dissertation, Program in Media Arts and Sciences, MIT. Thesis work done at UNC-CH Computer Science.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199436</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>122</ref_seq_no>
				<ref_text><![CDATA[Mirtich, B., and Canny, J. 1995. Impulse-based simulation of rigid bodies. In Symposium on Interactive 3D Graphics, ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>924581</ref_obj_id>
				<ref_seq_no>123</ref_seq_no>
				<ref_text><![CDATA[Mirtich, B. V. 1996. Impulse-based Dynamic Simulation of Rigid Body Systems. PhD thesis, University of California, Berkeley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>124</ref_seq_no>
				<ref_text><![CDATA[Mirtich, B. V. 1998. Rigid body contact: Collision detection to force computation. Tech. Rep. TR98--01, Mitsubishi Electric Research Laboratory.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>285860</ref_obj_id>
				<ref_obj_pid>285857</ref_obj_pid>
				<ref_seq_no>125</ref_seq_no>
				<ref_text><![CDATA[Mirtich, B. 1998. V-Clip: Fast and robust polyhedral collision detection. ACM Transactions on Graphics 17, 3 (July), 177--208.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344866</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>126</ref_seq_no>
				<ref_text><![CDATA[Mirtich, B. 2000. Timewarp rigid body simulation. SIGGRAPH 00 Conference Proceedings, 193--200.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378528</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>127</ref_seq_no>
				<ref_text><![CDATA[Moore, M., and Wilhelms, J. 1988. Collision detection and response for computer animation. In Computer Graphics (SIGGRAPH '88 Proceedings), J. Dill, Ed., vol. 22, 289--298.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>128</ref_seq_no>
				<ref_text><![CDATA[Nelson, D. D., Johnson, D. E., and Cohen, E. 1999. Haptic rendering of surface-to-surface sculpted model interaction. Proc. of ASME Dynamic Systems and Control Division.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>129</ref_seq_no>
				<ref_text><![CDATA[Okamura, A., and Cutkosky, M. 1999. Haptic exploration of fine surface features. Proc. of IEEE Int. Conf. on Robotics and Automation, pp. 2930--2936.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>130</ref_seq_no>
				<ref_text><![CDATA[Okamura, A. M., and Cutkosky, M. R. 2001. Feature detection for haptic exploration with robotic fingers. International Journal of Robotics Research 20, 12, 925--938.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>501788</ref_obj_id>
				<ref_obj_pid>501786</ref_obj_pid>
				<ref_seq_no>131</ref_seq_no>
				<ref_text><![CDATA[O'Sullivan, C., and Dingliana, J. 2001. Collisions and perception. ACM Trans. on Graphics 20, 3, pp. 151--168.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>132</ref_seq_no>
				<ref_text><![CDATA[O'Sullivan, C., Radach, R., and Collins, S. 1999. A model of collision perception for real-time animation. Computer Animation and Simulation, pp. 67--76.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882303</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>133</ref_seq_no>
				<ref_text><![CDATA[O'Sullivan, C., Dingliana, J., Giang, T., and Kaiser, M. K. 2003. Evaluating the visual fidelity of physically based animations. Proc. of ACM SIGGRAPH, 527--536.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882382</ref_obj_id>
				<ref_obj_pid>882370</ref_obj_pid>
				<ref_seq_no>134</ref_seq_no>
				<ref_text><![CDATA[Otaduy, M. A., and Lin, M. C. 2003. CLODs: Dual hierarchies for multiresolution collision detection. Eurographics Symposium on Geometry Processing, 94--101.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882305</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>135</ref_seq_no>
				<ref_text><![CDATA[Otaduy, M. A., and Lin, M. C. 2003. Sensation preserving simplification for haptic rendering. ACM Trans. on Graphics (Proc. of ACM SIGGRAPH), 543--553.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1050044</ref_obj_id>
				<ref_obj_pid>1048934</ref_obj_pid>
				<ref_seq_no>136</ref_seq_no>
				<ref_text><![CDATA[Otaduy, M. A., and Lin, M. C. 2005. Stable and responsive six-degree-of-freedom haptic manipulation using implicit integration. Proc. of World Haptics Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1034460</ref_obj_id>
				<ref_obj_pid>1032664</ref_obj_pid>
				<ref_seq_no>137</ref_seq_no>
				<ref_text><![CDATA[Otaduy, M. A., Jain, N., Sud, A., and Lin, M. C. 2004. Haptic display of interaction between textured models. Proc. of IEEE Visualization, 297--304.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>917155</ref_obj_id>
				<ref_seq_no>138</ref_seq_no>
				<ref_text><![CDATA[Ouh-Young, M. 1990. Force Display in Molecular Docking. PhD thesis, University of North Carolina, Computer Science Department.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>139</ref_seq_no>
				<ref_text><![CDATA[Pai, D. K., and Reissel, L. M. 1997. Haptic interaction with multiresolution image curves. Computer and Graphics 21, 405--411.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383268</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>140</ref_seq_no>
				<ref_text><![CDATA[Pai, D. K., van den Doel, K., James, D. L., Lang, J., Lloyd, J. E., Richmond, J. L., and Yau, S. H. 2001. Scanning physical interaction behavior of 3d objects. Computer Graphics (Proc. of ACM SIGGRAPH).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>141</ref_seq_no>
				<ref_text><![CDATA[Quinlan, S. 1994. Efficient distance computation between non-convex objects. In Proceedings of International Conference on Robotics and Automation, 3324--3329.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>142</ref_seq_no>
				<ref_text><![CDATA[Redon, S., Kheddar, A., and Coquillart, S. 2002. Fast continuous collision detection between rigid bodies. Proc. of Eurographics (Computer Graphics Forum).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>143</ref_seq_no>
				<ref_text><![CDATA[Renz, M., Preusche, C., P&#246;tke, M., Kriegel, H.-P., and Hirzinger, G. 2001. Stable haptic interaction with virtual environments using an adapted voxmap-pointshell algorithm. Eurohaptics Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>144</ref_seq_no>
				<ref_text><![CDATA[Rock, I., and Victor, J. 1964. Vision and touch: An experimentally created conflict between the two senses. Science 143, pp. 594--596.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>145</ref_seq_no>
				<ref_text><![CDATA[Ruspini, D., and Khatib, O. 2000. A framework for multi-contact multi-body dynamic simulation and haptic display. Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258878</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>146</ref_seq_no>
				<ref_text><![CDATA[Ruspini, D., Kolarov, K., and Khatib, O. 1997. The haptic display of complex graphical environments. Proc. of ACM SIGGRAPH, 345--352.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>147</ref_seq_no>
				<ref_text><![CDATA[Salcudean, S. E., and Vlaar, T. D. 1994. On the emulation of stiff walls and static friction with a magnetically levitated input/output device. Proc. of ASME Haptic Interfaces for Virtual Environment and Teleoperator Systems.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199426</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>148</ref_seq_no>
				<ref_text><![CDATA[Salisbury, K., Brock, D., Massie, T., Swarup, N., and Zilles, C. 1995. Haptic rendering: Programming touch interaction with virtual objects. In 1995 Symposium on Interactive 3D Graphics, P. Hanrahan and J. Winget, Eds., ACM SIGGRAPH, 123--130. ISBN 0-89791-736-7.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>98570</ref_obj_id>
				<ref_obj_pid>98524</ref_obj_pid>
				<ref_seq_no>149</ref_seq_no>
				<ref_text><![CDATA[Seidel, R. 1990. Linear programming and convex hulls made easy. In Proc. 6th Ann. ACM Conf. on Computational Geometry, 211--215.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>150</ref_seq_no>
				<ref_text><![CDATA[Shimoga, K. 1992. Finger force and touch feedback issues in dextrous manipulation. NASA-CIRSSE International Conference on Inetelligent Robotic Systems for Space Exploration.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>151</ref_seq_no>
				<ref_text><![CDATA[Siira, J., and Pai, D. K. 1996. Haptic textures - a stochastic approach. Proc. of IEEE International Conference on Robotics and Automation, 557--562.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>152</ref_seq_no>
				<ref_text><![CDATA[Slater, M., and Usoh, M. 1993. An experimental exploration of presence in virtual environments. Tech. Rep. 689, Department of Computer Science, University College London.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>153</ref_seq_no>
				<ref_text><![CDATA[Spence, C., Pavani, F., and Driver, J. 2000. Crossmodal links between vision and touch in covert endogenous spatial attention. Journal of Experimental Psychology: Human Perception and Performance 26, pp. 1298--1319.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>154</ref_seq_no>
				<ref_text><![CDATA[Stewart, D. E., and Trinkle, J. C. 1996. An implicit time-stepping scheme for rigid body dynamics with inelastic collisions and coulomb friction. International Journal of Numerical Methods in Engineering 39, 2673--2691.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>155</ref_seq_no>
				<ref_text><![CDATA[Stewart, D. E., and Trinkle, J. C. 2000. An implicit time-stepping scheme for rigid body dynamics with coulomb friction. IEEE International Conference on Robotics and Automation, 162--169.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>286071</ref_obj_id>
				<ref_seq_no>156</ref_seq_no>
				<ref_text><![CDATA[Stollnitz, E., DeRose, T., and Salesin, D. 1996. Wavelets for Computer Graphics: Theory and Applications. Morgan-Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>157</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. 1965. The ultimate display. Proc. of IFIP, 506--508.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166133</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>158</ref_seq_no>
				<ref_text><![CDATA[Taylor, R. M., Robinett, W., Chii, V., Brooks, F., and Wright, W. 1993. The nanomanipulator: A virtual-reality interface for a scanning tunneling microscope. In Proc. of ACM SIGGRAPH, 127--134.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>253336</ref_obj_id>
				<ref_obj_pid>253284</ref_obj_pid>
				<ref_seq_no>159</ref_seq_no>
				<ref_text><![CDATA[Thompson, T. V., Johnson, D., and Cohen, E. 1997. Direct haptic rendering of sculptured models. Proc. of ACM Symposium on Interactive 3D Graphics, pp. 167--176.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>797521</ref_obj_id>
				<ref_obj_pid>795682</ref_obj_pid>
				<ref_seq_no>160</ref_seq_no>
				<ref_text><![CDATA[Unger, B. J., Nicolaidis, A., Berkelman, P. J., Thompson, A., Lederman, S. J., Klatzky, R. L., and Hollis, R. L. 2002. Virtual peg-in-hole performance using a 6-dof magnetic levitation haptic device: Comparison with real forces and with visual guidance alone. Proc. of Haptics Symposium, 263--270.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>161</ref_seq_no>
				<ref_text><![CDATA[van den Bergen, G. 2001. Proximity queries and penetration depth computation on 3d game objects. Game Developers Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1081478</ref_obj_id>
				<ref_obj_pid>1081432</ref_obj_pid>
				<ref_seq_no>162</ref_seq_no>
				<ref_text><![CDATA[Wan, M., and McNeely, W. A. 2003. Quasi-static approximation for 6 degrees-of-freedom haptic rendering. Proc. of IEEE Visualization, 257--262.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>163</ref_seq_no>
				<ref_text><![CDATA[Wu, D. 2000. Penalty methods for contact resolution. Game Developers Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>849727</ref_obj_id>
				<ref_obj_pid>846238</ref_obj_pid>
				<ref_seq_no>164</ref_seq_no>
				<ref_text><![CDATA[Zilles, C., and Salisbury, K. 1995. A constraint-based god object method for haptics display. In Proc. of IEEE/RSJ Int. Conf. on Intelligent Robotics and Systems.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258863</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>165</ref_seq_no>
				<ref_text><![CDATA[Zorin, D., Schr&#246;der, P., and Sweldens, W. 1997. Interactive multiresolution mesh editing. Proc. of ACM SIGGRAPH, 259--268.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198620</article_id>
		<sort_key>3</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Introduction and overview]]></title>
		<page_from>3</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198620</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198620</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP42050475</person_id>
				<author_profile_id><![CDATA[81452602436]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[UNC-Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P362253</person_id>
				<author_profile_id><![CDATA[81100035394]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Miguel]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Otaduy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ETH-Zurich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198621</article_id>
		<sort_key>5</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Haptic perception and implications for design]]></title>
		<page_from>5</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198621</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198621</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39060566</person_id>
				<author_profile_id><![CDATA[81100209584]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Roberta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Klatzky]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198622</article_id>
		<sort_key>12</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Introduction to 3-DoF haptic rendering]]></title>
		<page_from>12</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198622</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198622</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP95043232</person_id>
				<author_profile_id><![CDATA[81452602436]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198623</article_id>
		<sort_key>18</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Introduction to 6-DoF haptic display]]></title>
		<page_from>18</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198623</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198623</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP24034418</person_id>
				<author_profile_id><![CDATA[81322500821]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bill]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McNeely]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Boeing Phantom Works]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198624</article_id>
		<sort_key>19</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Voxel sampling for Six-DoF haptic rendering]]></title>
		<page_from>19</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198624</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198624</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP24034567</person_id>
				<author_profile_id><![CDATA[81322500821]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bill]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McNeely]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Boeing Phantom Works]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198625</article_id>
		<sort_key>24</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Sensation preserving simplification for 6-DoF haptic display]]></title>
		<page_from>24</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198625</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198625</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P362253</person_id>
				<author_profile_id><![CDATA[81100035394]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Miguel]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Otaduy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ETH-Zurich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>882305</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Sensation Preserving Simplification for Haptic Rendering. Miguel A. Otaduy and Ming C. Lin. In Proc. of ACM SIGGRAPH 2003. http://gamma.cs.unc.edu/LODHaptics/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1050044</ref_obj_id>
				<ref_obj_pid>1048934</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Stable and Responsive Six-Degree-of-Freedom Haptic Manipulation Using Implicit Integration. Miguel A. Otaduy and Ming C. Lin. In Proc. of World Haptics Conference 2005. http://gamma.cs.unc.edu/SR6DoF/]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198604</article_id>
		<sort_key>34</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[A framework for fast and accurate collision detection for haptic interaction]]></title>
		<page_from>34</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198604</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198604</url>
		<abstract>
			<par><![CDATA[We present a framework for fast and accurate collision detection for haptic interaction with polygonal models. Given a model, we pre-compute a hybrid hierarchical representation, consisting of uniform grids and trees of tight-fitting oriented bounding box trees (OBB-Trees). At run time, we use hybrid hierarchical representations and exploit frame-to-frame coherence for fast proximity queries. We describe a new overlap test, which is specialized for intersection of a line segment with an oriented bounding box for haptic simulation and takes 6-36 operations excluding transformation costs. The algorithms have been implemented as part of H-COLLIDE and interfaced with a PHANToM arm and its haptic toolkit, GHOST, and applied to a number of models. As compared to the commercial implementation, we are able to achieve up to 20 times speedup in our experiments and sustain update rates over 1000Hz on a 400MHz Pentium II.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P316967</person_id>
				<author_profile_id><![CDATA[81406591681]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Arthur]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gregory]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina, Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42050475</person_id>
				<author_profile_id><![CDATA[81452602436]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina, Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P267285</person_id>
				<author_profile_id><![CDATA[81100288313]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Stefan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gottschalk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina, Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39046692</person_id>
				<author_profile_id><![CDATA[81405594834]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Russell]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Taylor]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina, Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>94794</ref_obj_id>
				<ref_obj_pid>94788</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Arvo and D. Kirk. A survey of ray tracing acceleration techniques. In An Introduction to Ray Tracing, pages 201--262, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>245054</ref_obj_id>
				<ref_obj_pid>244979</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. S. Avila and L. M. Sobierajski. A haptic interaction method for volume visualization. Proceedings of Visualization'96, pages 197--204, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97881</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D. Baraff. Curved surfaces and coherence for non-penetrating rigid body simulation. ACM Computer Graphics, 24(4):19--28, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[G. Barequet, B. Chazelle, L. Guibas, J. Mitchell, and A. Tal. Boxtree: A hierarchical representation of surfaces in 3d. In Proc. of Eurographics'96, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>98741</ref_obj_id>
				<ref_obj_pid>93597</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[N. Beckmann, H. Kriegel, R. Schneider, and B. Seeger. The r*-tree: An efficient and robust access method for points and rectangles. Proc. SIGMOD Conf. on Management of Data, pages 322--331, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97899</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Frederick P. Brooks, Jr., Ming Ouh-Young, James J. Batter, and P. Jerome Kilpatrick. Project GROPE --- Haptic displays for scientific visualization. In Forest Baskett, editor, Computer Graphics (SIGGRAPH '90 Proceedings), volume 24, pages 177--185, August 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>112537</ref_obj_id>
				<ref_obj_pid>112515</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Cameron. Approximation hierarchies and s-bounds. In Proceedings. Symposium on Solid Modeling Foundations and CAD/CAM Applications, pages 129--137, Austin, TX, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Stephen Cameron. A comparison of two fast algorithms for computing the distance between convex polyhedra. IEEE Transactions on Robotics and Automation, 13(6):915--920, December 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199437</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Cohen, M. Lin, D. Manocha, and M. Ponamgi. I-collide: An interactive and exact collision detection system for large-scale environments. In Proc. of ACM Interactive 3D Graphics Conference, pages 189--196, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. E. Colgate and J. M. Brown. Factors affecting the z-width of a haptic display. IEEE Conference on Robotics and Automation, pages 3205--3210, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. E. Colgate and et al. Issues in the haptic display of tool use. Proceedings of the ASME Haptic Interfaces for Virtual Environment and Teleoperator Systems, pages 140--144, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199406</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. Finch, M. Falvo, V. L. Chi, S. Washburn, R. M. Taylor, and R. Superfine. Surface modification tools in a virtual environment interface to a scanning probe microscope. In Pat Hanrahan and Jim Winget, editors, 1995 Symposium on Interactive 3D Graphics, pages 13--18. ACM SIGGRAPH, April 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[S. Gibson. Beyond volume rendering: Visualization, haptic exploration, and physical modeling of element-based objects. In Proc. Eurographics workshop on Visualization in Scientific Computing, pages 10--24, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[E. G. Gilbert, D. W. Johnson, and S. S. Keerthi. A fast procedure for computing the distance between objects in three-dimensional space. IEEE J. Robotics and Automation, vol RA-4:193--203, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237244</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[S. Gottschalk, M. Lin, and D. Manocha. Obb-tree: A hierarchical structure for rapid interference detection. In Proc. of ACM Siggraph'96, pages 171--180, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>897931</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[A. Gregory, M. Lin, S. Gottschalk, and R. Taylor. H-collide: A framework for fast and accurate collision detection for haptic interaction. Technical report, Department of Computer Science, University of North Carolina, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[M. Held, J. T. Klosowski, and J. S. B. Mitchell. Evaluation of collision detection methods for virtual reality fly-throughs. In Canadian Conference on Computational Geometry, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[P. M. Hubbard. Interactive collision detection. In Proceedings of IEEE Symposium on Research Frontiers in Virtual Reality, October 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[D. Johnson and E. Cohen. A framework for efficient minimum distance computation. IEEE Conference on Robotics and Automation, pages 3678--3683, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[J. Klosowski, M. Held, J. S. B. Mitchell, H. Sowizral, and K. Zikan. Efficient collision detection using bounding volume hierarchies of k-dops. In Siggraph'96 Visual Proceedings, page 151, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299006</ref_obj_id>
				<ref_obj_pid>298960</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[S. Krishnan, A. Pattekar, M. Lin, and D. Manocha. Spherical shell: A higher order bounding volume for fast proximity queries. In Proc. of Third International Workshop on Algorithmic Foundations of Robotics, pages 122--136, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[M. Lin and S. Gottschalk. Collision detection between geometric models: A survey. In Proc. of IMA Conference on Mathematics of Surfaces, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[M. C. Lin and John F. Canny. Efficient algorithms for incremental distance computation. In IEEE Conference on Robotics and Automation, pages 1008--1014, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237284</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[William Mark, Scott Randolph, Mark Finch, James Van Verth, and Russell M. Taylor II. Adding force feedback to graphics systems: Issues and solutions. In Holly Rushmeier, editor, SIGGRAPH 96 Conference Proceedings, Annual Conference Series, pages 447--452, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[T. M. Massie and J. K. Salisbury. The phantom haptic interface: A device for probing virtual objects. Proc. of ASME Hpatic Interfaces for Virtual Environment and Teleoperator Systems, 1:295--301, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[A. Nahvi, D. Nelson, J. Hollerbach, and D. Johnson. Haptic manipulation of virtual mechanisms from mechanical cad designs. In Proc. of 1998 Conference on Robotics and Automation, pages 375--380, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97892</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[B. Naylor, J. Amanatides, and W. Thibault. Merging bsp trees yield polyhedral modeling results. In Proc. of ACM Siggraph, pages 115--124, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>917155</ref_obj_id>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[M. Ouh-Young. Force Display in Molecular Docking. PhD thesis, University of North Carolina, Computer Science Department, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152574</ref_obj_id>
				<ref_obj_pid>152566</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[M. H. Overmars. Point location in fat subdivisions. Inform. Proc. Lett., 44:261--265, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[S. Quinlan. Efficient distance computation between non-convex objects. In Proceedings of International Conference on Robotics and Automation, pages 3324--3329, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258878</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[D. C. Ruspini, K. Kolarov, and O. Khatib. The haptic display of complex graphical environments. Proc. of ACM SIGGRAPH, pages 345--352, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199426</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[K. Salisbury, D. Brock, T. Massie, N. Swarup, and C. Zilles. Haptic rendering: Programming touch interaction with virtual objects. Proc. of 1995 ACM Symposium on Interactive 3D Graphics, pages 123--130, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[H. Samet. Spatial Data Structures: Quadtree, Octrees and Other Hierarchical Methods. Addison Wesley, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Inc. SensAble Technologies. ghost#8482;: Sofware developer's toolkit. Programmer's Guide, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166133</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[R. M. Taylor, W. Robinett, V. L. Chii, F. Brooks, and W. Wright. The nanomanipulator: A virtual-reality interface for a scanning tunneling microscope. In Proc. of ACM Siggraph, pages 127--134, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>253336</ref_obj_id>
				<ref_obj_pid>253284</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[T. V. Thompson, D. Johnson, and E. Cohen. Direct haptic rendering of sculptured models. Proc. of ACM Interactive 3D Graphics, pages 167--176, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198626</article_id>
		<sort_key>37</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Haptic rendering of polygonal models using local minimum distances]]></title>
		<page_from>37</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198626</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198626</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40027495</person_id>
				<author_profile_id><![CDATA[81100455711]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Johnson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39029679</person_id>
				<author_profile_id><![CDATA[81100146161]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Elaine]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cohen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P837816</person_id>
				<author_profile_id><![CDATA[81100417479]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Pete]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Willemsen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198605</article_id>
		<sort_key>42</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Six degree-of-freedom haptic rendering using voxel sampling]]></title>
		<page_from>42</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198605</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198605</url>
		<abstract>
			<par><![CDATA[A simple, fast, and approximate voxel-based approach to 6-DOF haptic rendering is presented. It can reliably sustain a 1000 Hz haptic refresh rate without resorting to asynchronous physics and haptic rendering loops. It enables the manipulation of a modestly complex rigid object within an arbitrarily complex environment of static rigid objects. It renders a short-range force field surrounding the static objects, which repels the manipulated object and strives to maintain a voxel-scale minimum separation distance that is known to preclude exact surface interpenetration. Force discontinuities arising from the use of a simple penalty force model are mitigated by a dynamic simulation based on virtual coupling. A generalization of octree improves voxel memory efficiency. In a preliminary implementation, a commercially available 6-DOF haptic prototype device is driven at a constant 1000 Hz haptic refresh rate from one dedicated haptic processor, with a separate processor for graphics. This system yields stable and convincing force feedback for a wide range of user controlled motion inside a large, complex virtual environment, with very few surface interpenetration events. This level of performance appears suited to applications such as certain maintenance and assembly task simulations that can tolerate voxel-scale minimum separation distances.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[force feedback]]></kw>
			<kw><![CDATA[virtual environments]]></kw>
			<kw><![CDATA[voxel representations]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P299578</person_id>
				<author_profile_id><![CDATA[81100559765]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[McNeely]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Boeing Company, Seattle, WA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31038207</person_id>
				<author_profile_id><![CDATA[81100346010]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kevin]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Puterbaugh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Boeing Company, Seattle, WA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31032249</person_id>
				<author_profile_id><![CDATA[81100210312]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Troy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Boeing Company, Seattle, WA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>836002</ref_obj_id>
				<ref_obj_pid>527216</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Adachi, T., Kumano, T., Ogino, K., "Intermediate Representations for Stiff Virtual Objects," Proc. IEEE Virtual Reality Annual Intl. Symposium, pp. 203--210, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Adams, R. J. and Hannaford, B., "A Two-Port Framework for the Design of Unconditionally Stable Haptic Interfaces," Proc. IROS, Anaheim CA, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>245054</ref_obj_id>
				<ref_obj_pid>244979</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Avila, R. S. and Sobierajski, L. M., "A Haptic Interaction Method for Volume Visualization," Proc. Visualization '96, pp. 197--204, Oct. 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97881</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Baraff, D., "Curved Surfaces and Coherence for Non-Penetrating Rigid Body Simulation," Computer Graphics (proc. SIGGRAPH 90), vol 24, no. 4, pp. 19--28, Aug. 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192168</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Baraff, D., "Fast Contact Force Computation for Nonpenetrating Rigid Bodies," Computer Graphics (proc. SIGGRAPH 94), pp. 23--42, July 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Berkelman, P. J. and Hollis, R. L., "Dynamic performance of a hemispherical magnetic levitation haptic interface device," in SPIE Int. Symposium on Intelligent Systems and Intelligent Manufacturing, (Proc. SPIE), Vol. 3602, Greensburg PA, Sept. 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97899</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Brooks, F. P., Ouh-Young, M., Batter, J. J., Jerome, P., "Project GROPE --- Haptic Displays for Scientific Visualization," Computer Graphics (proc. SIGGRAPH 90), pp. 177--185, Aug. 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199437</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cohen, J. D., Lin, M. C., Manocha, D., and Ponamgi, M. K., "I-COLLIDE: An Interactive and Exact Collision Detection System for Large-Scale Environments," Computer Graphics (proc. SIGGRAPH 95), pp. 189--196, Aug. 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>923097</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Clover, C. L., Control system design for robots used in simulating dynamic force and moment interaction in virtual reality applications, Ph.D. thesis, Iowa State University, Ames, IA, Apr. 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Colgate, J. E., Grafing, P. E., Stanley, M. C., and Schenkel, G., "Implementation of Stiff Virtual Walls in Force-Reflecting Interfaces," Proc. IEEE Virtual Reality Annual International Symposium (VRAIS), Seattle, WA, pp. 202--208, Sept., 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>534661</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Craig, J. J., Introduction to Robotics: Mechanics and Control. 2nd ed., Addison-Wesley, Reading MA, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>176968</ref_obj_id>
				<ref_obj_pid>176962</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Garcia-Alonso, A., Serrano, N., and Flaquer J., "Solving the Collision Detection Problem," IEEE Computer Graphics and Applications, vol. 14, no. 3, pp. 36--43, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237244</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Gottschalk, S., Lin, M. C., Manocha, D., "OBBTree: A Hierarchical Structure for Rapid Interference Detection," Computer Graphics (proc. SIGGRAPH 96), pp. 171--180, Aug. 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Jackins, C., and Tanimoto, S. L., "Oct-Trees and Their Use in Representing Three-Dimensional Objects," Computer Graphics and Image Processing, vol. 14, no. 3, pp. 249--270, 1980.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>619635</ref_obj_id>
				<ref_obj_pid>161477</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Kaufman, A., Cohen, D., Yagle, R., "Volume Graphics," IEEE Computer, 26(7), pp. 51--64, July, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Logan, I. P., Wills D. P. M., Avis N. J., Mohsen, A. M. M. A., and Sherman, K. P., "Virtual Environment Knee Arthroscopy Training System," Society for Computer Simulation, Simulation Series, vol. 28, no. 4, pp. 17--22, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237284</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Mark, W. R., Randolph, S. C., Finch, M., Van Verth, J. M., and Taylor II, R. M., "Adding Force Feedback to Graphics Systems: Issues and Solutions," Computer Graphics (proc. SIGGRAPH 96), pp. 447--452, Aug. 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Massie, T. H. and Salisbury, J. K., "The Phantom Haptic Interface: A Device for Probing Virtual Objects," Proc. of the ASME International Mechanical Engineering Congress and Exhibition, Chicago, pp. 295--302, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>215111</ref_obj_id>
				<ref_obj_pid>215074</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Mirtich, B. and Canny, J., "Impulse-based Dynamic Simulation." Proceedings of Workshop on Algorithmic Foundations of Robotics, Feb. 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[OpenGL Architecture Review Board, Woo, M., Neider, J., and Davis, T. OpenGL Programming Guide, 2nd, Addison-Wesley, Reading, MA, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258878</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Ruspini, D. C., Kolarov, K., and Khatib, O., "The Haptic Display of Complex Graphical Environments," Computer Graphics (Proc. SIGGRAPH 97), pp. 345--352, Aug. 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122745</ref_obj_id>
				<ref_obj_pid>122718</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Sclaroff, S. and Pentland, A., "Generalized Implicit Functions for Computer Graphics," Computer Graphics (Proc. SIGGRAPH 96), pp. 247--250, July, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>565650</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Witkin A. and Welch, W., "Fast Animation and Control of Nonrigid Structures," Computer Graphics (Proc. SIGGRAPH 90), pp. 243--252, Aug. 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>836042</ref_obj_id>
				<ref_obj_pid>832290</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Yokokohji, Y, Hollis, R. L., and Kanade, T., "What you can see is what you can feel. Development of a visual/haptic interface to virtual environment," Proc. IEEE Virtual Reality Annual Int. Symposium (VRAIS), pp. 46--53, Mar., 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>849727</ref_obj_id>
				<ref_obj_pid>846238</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Zilles, C. B. and Salisbury, J. K., "A Constraint-based God-object Method for Haptics Display," Proc. IEEE/RSJ Int. Conf. on Intelligent Robots and Systems, Pittsburgh, PA, pp. 146--151, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198627</article_id>
		<sort_key>45</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Haptic rendering of sculptured models]]></title>
		<page_from>45</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198627</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198627</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39029679</person_id>
				<author_profile_id><![CDATA[81100146161]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Elaine]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cohen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24037848</person_id>
				<author_profile_id><![CDATA[81328490545]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tom]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Thompson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P837800</person_id>
				<author_profile_id><![CDATA[81100407983]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Don]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nelson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40031493</person_id>
				<author_profile_id><![CDATA[81100455711]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Johnson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198628</article_id>
		<sort_key>49</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Wearable vibrotactile displays]]></title>
		<page_from>49</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198628</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198628</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P111644</person_id>
				<author_profile_id><![CDATA[81100315053]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hong]]></first_name>
				<middle_name><![CDATA[Z.]]></middle_name>
				<last_name><![CDATA[Tan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Purdue University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198606</article_id>
		<sort_key>50</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[Advances in voxel-based 6-DOF haptic rendering]]></title>
		<page_from>50</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198606</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198606</url>
		<abstract>
			<par><![CDATA[An approach is presented for realizing an order-of-magnitude improvement in spatial accuracy for voxel-based 6-DOF haptics. It trades constant-time performance for greater spatial accuracy. This helps to make 6-DOF haptics applicable to extraordinarily complex real-world task simulations, which often admit no other known solution short of physical mockup. A reduction of haptic fidelity is tactically incurred but simultaneously mitigated by augmenting standard voxel-sampling methodology with distance fields, temporal coherence, and culling of redundant polyhedral surface interactions. This is applied to large-scale haptic scenarios involving multiple moving objects and to collaborative virtual environments.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[collaborative virtual environments]]></kw>
			<kw><![CDATA[collision detection]]></kw>
			<kw><![CDATA[haptics]]></kw>
			<kw><![CDATA[physically based modeling]]></kw>
			<kw><![CDATA[voxel sampling]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P299578</person_id>
				<author_profile_id><![CDATA[81100559765]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[McNeely]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Boeing Phantom Works]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31038207</person_id>
				<author_profile_id><![CDATA[81100346010]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kevin]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Puterbaugh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Boeing Phantom Works]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31032249</person_id>
				<author_profile_id><![CDATA[81100210312]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Troy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Boeing Phantom Works]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Adams, R. and Hannaford, B. "A Two-Port Framework for the Design of Unconditionally Stable Haptic Interfaces." Proc. IROS, Anaheim CA, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>17147</ref_obj_id>
				<ref_obj_pid>17140</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Borgefors, G., "Distance Transformations on Digital Images", Computer Vision Graphics Image Processing, v34, pp. 344--371, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Borro, D., Garcia-Alonso, A., and Matey, L., "Approximation of Optimal Voxel Size for Collision Detection in Maintainability Simulations within Massive Virtual Environments" Computer Graphics Forum, 23(1), p.13, Mar 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Buttolo, P., Oboe, R., Hannaford, B., and McNeely W., "Force Feedback in Shared Virtual Simulations." Proc MICAD, Paris, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Choi, M. and Cremer, J., "Geometrically-Aware Interactive Object Manipulation", Computer Graphics Forum, 19(1), pp. 65--76, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199437</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cohen, J., Lin, M., Manocha, D., and Ponamgi, M., "I-COLLIDE: An Interactive and Exact Collision Detection System for large-Scale Environments", 1995 Symposium on Interactive 3D Graphics, pp. 189--196, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Colgate, J. E., Grafing, P. E., Stanley, M. C., and Schenkel, G., "Implementation of Stiff Virtual Walls in Force-Reflecting Interfaces." PRoc. IEEE Virtual Reality Annual Internation Symposium (VRAIS), Seattle WA, pp. 202--208, Sept 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375232</ref_obj_id>
				<ref_obj_pid>375213</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Gregory, A., Mascarenhas, A., Ehmann, S., Lin, M., and Manocha, D., "Six Degree-of-Freedom Haptic Display of Polygonal Models", Proc. IEEE Visualization, pp. 139--146, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Homan, D. "Virtual Reality Applications Development", NASA JSC Annual Report for FY-1995 of the Automation, Robotics & Simulation Division, http://tommy.jsc.nasa.gov/ARSD/report_FY95/homan_fy955.html, including private correspondence.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1880273</ref_obj_id>
				<ref_obj_pid>1880269</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Johnson, D and Willemsen, P., "Accelerated Haptic Rendering of Polygonal Models through Local Decent", Int. Symposium on Haptic Interfaces for VR and Teleop Systems, pp. 18--23, Mar 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1029419</ref_obj_id>
				<ref_obj_pid>1029412</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kim, J., Kim, H., Tay, B. K., Muniyandi, M., Jordan, J., Mortensen, J., Oliveira, M., Slater, M., and Srinivasan, M. A., "Transatlantic Touch: A Study of Haptic Collaboration over Long Distance." Presence, 13(3), pp. 328--337, June 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>920962</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Lin, M., "Efficient Collision Detection for Animation and Robotics", Ph.D. Thesis, University of California, Berkeley, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311600</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[McNeely, W., Puterbaugh, K., and Troy, J., "Six Degree-of-Freedom Haptic Rendering Using Voxel Sampling", Proc. ACM SIGGRAPH, pp. 401--408, Aug 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237284</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Mark, W., Randolph, S., Finch, M., Jan Verth, J., and Taylor II, R., "Adding Force Feedback to Graphics Systems: Issues and Solutions", Proc. ACM SIGGRAPH, pp. 447--452, Aug 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>285860</ref_obj_id>
				<ref_obj_pid>285857</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Mirtich, B., "V-Clip: Fast and Robust Polyhedral Collision Detection", ACM Transactions on Graphics, 17(3), pp. 177--208, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835798</ref_obj_id>
				<ref_obj_pid>832288</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Nelson, D. and Cohen, E., "Optimization-Based Virtual Surface Contact Manipulation at Force Control Rates", Proc. IEEE Virtual Reality, pp. 37--44, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882305</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Otaduy M. and Lin, M., "Sensation Preserving Simplification for Haptic Rendering", Proc. ACM SIGGRAPH, pp. 543--553, Aug 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1050138</ref_obj_id>
				<ref_obj_pid>1048934</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Prior, A. and Haines, K., "The use of a Proximity Agent in a Collaborative Virtual Environment with 6 Degrees-of-Freedom Voxel-based Haptic Rendering." Proc. World Haptics Conf., Pisa, Italy, pp. 631--632, Mar 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Renz, M., Preusche, C., P&#246;tke, M., Kriegel, H.-P., and Hirzinger, G., "Stable Haptic Interaction with Virtual Environments using an Adapted Voxmap-Pointshell Algorithm" Proc. Eurohaptics, Birmingham, UK, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Troy, J., "Haptic Control of a Simplified Human Model with Multibody Dynamics" Phantom Users Group Conf., Aspen, CO, pp. 43--46, Oct 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1081478</ref_obj_id>
				<ref_obj_pid>1081432</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Wan, M. and McNeely, W. A. "Quasi-Static Approximation for 6-DOF Haptic Rendering". Proc. IEEE Visualization conference, Seattle, WA, pp. 257--262, Oct 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Woo, M., Neider, J., Davis, T., and Shreiner, D., OpenGL Programming Guide, Version 1.2, 3rd, Addison Wesley, Reading, MA, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198629</article_id>
		<sort_key>52</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Towards realistic haptic rendering of surface texture]]></title>
		<page_from>52</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198629</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198629</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40027728</person_id>
				<author_profile_id><![CDATA[81100480604]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Seungmoon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Choi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Purdue University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P837807</person_id>
				<author_profile_id><![CDATA[81100315053]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Purdue University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198630</article_id>
		<sort_key>56</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Haptic rendering of textured surfaces]]></title>
		<page_from>56</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198630</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198630</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P362253</person_id>
				<author_profile_id><![CDATA[81100035394]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Miguel]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Otaduy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ETH-Zurich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1034460</ref_obj_id>
				<ref_obj_pid>1032664</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Haptic Display of Interaction between Textured Models. Miguel A. Otaduy, Nitin Jain, Avneesh Sud and Ming C. Lin. In Proc. of IEEE Visualization Conference 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1012574</ref_obj_id>
				<ref_obj_pid>1012551</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A Perceptually-Inspired Force Model for Haptic Texture Rendering. Miguel A. Otaduy and Ming C. Lin. In Proc. of the Symposium on Applied Perception in Graphics and Visualization 2004. http://gamma.cs.unc.edu/HTextures/]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198631</article_id>
		<sort_key>68</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[Modeling deformable objects for haptics]]></title>
		<page_from>68</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198631</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198631</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P67322</person_id>
				<author_profile_id><![CDATA[81100642559]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dinesh]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Pai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rutgers University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39041734</person_id>
				<author_profile_id><![CDATA[81100415142]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Doug]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[James]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198607</article_id>
		<sort_key>72</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Sensation preserving simplification for haptic rendering]]></title>
		<page_from>72</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198607</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198607</url>
		<abstract>
			<par><![CDATA[We introduce a novel "sensation preserving" simplification algorithm for faster collision queries between two polyhedral objects in haptic rendering. Given a polyhedral model, we construct a multiresolution hierarchy using "filtered edge collapse", subject to constraints imposed by collision detection. The resulting hierarchy is then used to compute fast contact response for haptic display. The computation model is inspired by human tactual perception of contact information. We have successfully applied and demonstrated the algorithm on a time-critical collision query framework for haptically displaying complex object-object interaction. Compared to existing exact contact query algorithms, we observe noticeable performance improvement in update rates with little degradation in the haptic perception of contacts.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[collision detection]]></kw>
			<kw><![CDATA[haptics]]></kw>
			<kw><![CDATA[level-of-detail algorithms]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Hierarchy and geometric transformations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Virtual reality</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010240.10010244</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision representations->Hierarchical representations</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P362253</person_id>
				<author_profile_id><![CDATA[81100035394]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Miguel]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Otaduy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42050475</person_id>
				<author_profile_id><![CDATA[81452602436]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>97899</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Brooks, Jr., F. P., Ouh-Young, M., Batter, J. J., and Kilpatrick, P. J. 1990. Project GROPE --- Haptic displays for scientific visualization. In Computer Graphics (SIGGRAPH '90 Proceedings), F. Baskett, Ed., vol. 24, 177--185.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280656</ref_obj_id>
				<ref_obj_pid>280651</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Chazelle, B., Dobkin, D., Shouraboura, N., and Tal, A. 1997. Strategies for polyhedral surface decomposition: An experimental study. Computational Geometry: Theory and Applications 7, 327--342.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Ehmann, S., and Lin, M. C. 2000. Accelerated proximity queries between convex polyhedra using multi-level voronoi marching. Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Ehmann, S., and Lin, M. C. 2001. Accurate and fast proximity queries between polyhedra using convex surface decomposition. Computer Graphics Forum (Proc. of Eurographics'2001) 20, 3.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2385948</ref_obj_id>
				<ref_obj_pid>2385930</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[El-Sana, J., and Varshney, A. 2000. Continuously-adaptive haptic rendering. Virtual Environments 2000, pp. 135--144.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258849</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Garland, M., and Heckbert, P. S. 1997. Surface simplification using quadric error metrics. In Proc. of ACM SIGGRAPH, 209--216.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237244</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Gottschalk, S., Lin, M., and Manocha, D. 1996. OBB-Tree: A hierarchical structure for rapid interference detection. Proc. of ACM SIGGRAPH, pp. 171--180.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375232</ref_obj_id>
				<ref_obj_pid>375213</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Gregory, A., Mascarenhas, A., Ehmann, S., Lin, M. C., and Manocha, D. 2000. 6-dof haptic display of polygonal models. Proc. of IEEE Visualization Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304979</ref_obj_id>
				<ref_obj_pid>304893</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Guibas, L., Hsu, D., and Zhang, L. 1999. H-Walk: Hierarchical distance computation for moving convex bodies. Proc. of ACM Symposium on Computational Geometry.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311577</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Guskov, I., Sweldens, W., and Schroder, P. 1999. Multiresolution signal processing for meshes. Proc. of ACM SIGGRAPH, pp. 325--334.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>364383</ref_obj_id>
				<ref_obj_pid>364338</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Hoff, K., Zaferakis, A., Lin, M., and Manocha, D. 2001. Fast and simple geometric proximity queries using graphics hardware. Proc. of ACM Symposium on Interactive 3D Graphics.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hollerbach, J., Cohen, E., Thompson, W., Freier, R., Johnson, D., Nahvi, A., Nelson, D., and II, T. T. 1997. Haptic interfacing for virtual prototyping of mechanical CAD designs. CDROM Proc. of ASME Design for Manufacturing Symposium.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>239927</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hubbard, P. 1994. Collision Detection for Interactive Graphics Applications. PhD thesis, Brown University.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>797498</ref_obj_id>
				<ref_obj_pid>795682</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Kim, Y., Otaduy, M., Lin, M., and Manocha, D. 2002. 6-dof haptic display using localized contact computations. Proc. of Haptics Symposium.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Klatzky, R., and Lederman, S. 1995. Identifying objects from a haptic glance. Perception and Psychophysics 57, pp. 1111--1123.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614390</ref_obj_id>
				<ref_obj_pid>614269</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Klosowski, J., Held, M., Mitchell, J., Sowizral, H., and Zikan, K. 1998. Efficient collision detection using bounding volume hierarchies of k-dops. IEEE Trans. on Visualization and Computer Graphics 4, 1, 21--37.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Larsen, E., Gottschalk, S., Lin, M., and Manocha, D. 2000. Distance queries with rectangular swept sphere volumes. Proc. of IEEE Int. Conference on Robotics and Automation.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Lin, M., and Gottschalk, S. 1998. Collision detection between geometric models: A survey. Proc. of IMA Conference on Mathematics of Surfaces.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>791558</ref_obj_id>
				<ref_obj_pid>791217</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Lombardo, J. C., Cani, M.-P., and Neyret, F. 1999. Real-time collision detection for virtual surgery. Proc. of Computer Animation.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732291</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Luebke, D., and Hallen, B. 2001. Perceptually driven simplification for interactive rendering. Rendering Techniques; Springer-Verlag.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>863276</ref_obj_id>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Luebke, D., Reddy, M., Cohen, J., Varshney, A., Watson, B., and Huebner, R. 2002. Level of Detail for 3D Graphics. Morgan-Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237284</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Mark, W., Randolph, S., Finch, M., Van Verth, J., and Taylor II, R. M. 1996. Adding force feedback to graphics systems: Issues and solutions. Proc. of ACM SIGGRAPH, 447--452.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311600</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[McNeely, W., Puterbaugh, K., and Troy, J. 1999. Six degree-of-freedom haptic rendering using voxel sampling. Proc. of ACM SIGGRAPH, 401--408.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Okamura, A., and Cutkosky, M. 1999. Haptic exploration of fine surface features. Proc. of IEEE Int. Conf. on Robotics and Automation, pp. 2930--2936.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>501788</ref_obj_id>
				<ref_obj_pid>501786</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[O'Sullivan, C., and Dingliana, C. 2001. Collisions and perception. ACM Trans. on Graphics 20, 3, pp. 151--168.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Otaduy, M. A., and Lin, M. C. 2003. CLODs: Dual hierarchies for multiresolution collision detection. UNC Technical Report TR03--013.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Pai, D. K., and Reissel, L. M. 1997. Haptic interaction with multiresolution image curves. Computer and Graphics 21, 405--411.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Redon, S., Kheddar, A., and Coquillart, S. 2002. Fast continuous collision detection between rigid bodies. Proc. of Eurographics (Computer Graphics Forum).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258878</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Ruspini, D., Kolarov, K., and Khatib, O. 1997. The haptic display of complex graphical environments. Proc. of ACM SIGGRAPH, 345--352.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>310976</ref_obj_id>
				<ref_obj_pid>310930</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Salisbury, J. K. 1999. Making graphics physically tangible. Communications of the ACM 42, 8.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218473</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Taubin, G. 1995. A signal processing approach to fair surface design. In Proc. of ACM SIGGRAPH, 351--358.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198632</article_id>
		<sort_key>73</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[Reality-based modeling for haptics and multimodal displays]]></title>
		<page_from>73</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198632</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198632</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P67322</person_id>
				<author_profile_id><![CDATA[81100642559]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dinesh]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Pai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rutgers University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198633</article_id>
		<sort_key>80</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[Applications in scientific visualization]]></title>
		<page_from>80</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198633</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198633</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39061510</person_id>
				<author_profile_id><![CDATA[81405594834]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Russell]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Taylor]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[UNC-Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>245054</ref_obj_id>
				<ref_obj_pid>244979</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Avila, R. S. and L. M. Sobierajski (1996). "A Haptic Interaction Method for Volume Visualization," Proceedings of IEEE Visualization '96, San Francisco.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97899</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Brooks, F. P., Jr., M. Ouh-Young, et Al., "Project GROPE - Haptic displays for scientific visualization," Computer Graphics: Proceedings of SIGGRAPH '90, Dallas, Texas. 177--185, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Fritz, J. and K. Barner (1996). Stochastic Models for haptic texture. Proceedings of the SPIE International Symposium on Intelligent Systems and Advanced Manufacturing - Telemanipulator and Telepresence Technologies III, Boston, MA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[William Humphrey, Andrew Dalke, and Klaus Schulten, VMD - Visual Molecular Dynamics," Journal of Molecular Graphics, 14:33--38, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Milan Ikits and J. Dean Brederson, "The Visual Haptic Workbench," Visualization Handbook, eds. Charles Hansen and Christopher Johnson, Elsevier, 2005]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Iwata, H.; Noma, "Volume haptization", 1993. Proceedings, IEEE 1993 Symposium on Research Frontiers in Virtual Reality, pp. 16--23, 25--26 Oct. 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375231</ref_obj_id>
				<ref_obj_pid>375213</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. A. Lawrence, C. D. Lee, L. Y. Pao, and R. Y. Novoselov. "Shock and Vortex Visualization Using a Combined Visual/Haptic Interface," Proc. IEEE Conference on Visualization and Computer Graphics Salt Lake City, UT, Oct. 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91451</ref_obj_id>
				<ref_obj_pid>91385</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Minsky, M., M. Ouh-young, et al., "Feeling and Seeing: Issues in Force Display," Proceedings ACM Siggraph Symposium on Interactive 3D Graphics. 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Seeger, A., A. Henderson, et al., "Haptic Display of Multiple Scalar Fields on a Surface," Workshop on New Paradigms in Information Visualization and Manipulation; ACM Press. 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198608</article_id>
		<sort_key>84</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[A haptic system for virtual prototyping of polygonal models]]></title>
		<page_from>84</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198608</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198608</url>
		<abstract>
			<par><![CDATA[Virtual prototyping attempts to replace physical models with virtual models for the purpose of design evaluation. One task a virtual prototyping environment can address is the accessibility of the components of a mechanical system. In this paper, we demonstrate a haptics-based virtual prototyping system for finding collision-free paths for moving models in complex polygonal environments. The system can handle models and environments with hundreds of thousands of triangles, and augments innate human talents at searching for collision-free paths.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40027467</person_id>
				<author_profile_id><![CDATA[81100455711]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Johnson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P225568</person_id>
				<author_profile_id><![CDATA[81100417479]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Willemsen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39029679</person_id>
				<author_profile_id><![CDATA[81100146161]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Elaine]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cohen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>49142</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. F. Canny. The Complexity of Robot Motion Planning. ACM Doctoral Dissertation Award. MIT Press, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[L. Kavraki, P. Svestka, J. C. Latombe, and M. Overmars. "Probabilistic roadmaps for path planning in high-dimensional configuration spaces," IEEE Trans. Robot. Automat., pages 12(4):566--580, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Foskey, M. Garber, M. Lin, and D. Manocha, "A Voronoi-Based Hybrid Motion Planner", Proc. IEEE/RSJ International Conf. on Intelligent Robots and Systems, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>6812</ref_obj_id>
				<ref_obj_pid>6806</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[O. Khatib. "Real-time obstacle avoidance for manipulators and mobile robots," in IJRR, 5(1):90--98, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199426</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[K. Salisbury et al., "Haptic rendering: programming touch interaction with virtual objects", in Symp. on Interactive 3D Graphics, 1995. pp. 123--130.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Hollerbach et al., "Haptic interfacing for virtual prototyping of mechanical CAD designs," ASME Design for Manufacturing Symposium, (Sacramento, CA), Sept. 14--17, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[P. Stewart et al., "CAD Data Representations For Haptic Virtual Prototyping", Proceedings of DETC'97, 1997 ASME Design Engineering Technical Conferences, Sept. 14--17, 1997, Sacramento, California.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D. Nelson, D. Johnson, and E. Cohen, "Haptic Rendering of Surface-to-Surface Sculpted Model Interaction," in Proc. 8th Annual Symp. on Haptic Interfaces for Virtual Environment and Teleoperator Systems, (Nashville, TN), ASME, November 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835798</ref_obj_id>
				<ref_obj_pid>832288</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[D. Nelson and E. Cohen., "Optimization-Based Virtual Surface Contact Manipulation at Force Control Rates," in IEEE Virtual Reality 2000, (New Brunswick, NJ), IEEE, March 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258878</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[D. Ruspini, K. Kolarov, and O. Khatib, "The Haptic Display of Complex Graphical Environments," in Computer Graphics Proceedings, SIGGRAPH 1997. Aug. 3--8. pp. 345--352.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311600</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[W. McNeely, K. Puterbaugh, and J. Troy. "Six degree-of-freedom haptic rendering using voxel sampling". Proc. of ACM SIGGRAPH, pages 401--408, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>797570</ref_obj_id>
				<ref_obj_pid>795683</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[D. Johnson and P. Willemsen, "Six Degree-of-Freedom Haptic Rendering of Complex Polygonal Models," in Proc. 2003 Haptics Symposium, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1880273</ref_obj_id>
				<ref_obj_pid>1880269</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[D. Johnson and P. Willemsen, "Accelerated Haptic Rendering of Polygonal Models through Local Descent," in Haptics Symposium 2004, IEEE, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>364380</ref_obj_id>
				<ref_obj_pid>364338</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[D. Johnson and E. Cohen, "Spatialized Normal Cone Hierarchies," in Proc. 2001 ACM Symposium on Interactive 3D Graphics, Research Triangle Park, NC, March 19-21, 2001. pp. 129--134.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882305</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[M. Otaduy and M. Lin, "Sensation Preserving Simplification for Haptic Rendering", in Proceedings of ACM SIGGRAPH 2003/ACM Transactions on Graphics, Vol. 22, pp. 543--553, San Diego, CA. 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198634</article_id>
		<sort_key>87</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[Haptic interaction with fluid media]]></title>
		<page_from>87</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198634</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198634</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35034288</person_id>
				<author_profile_id><![CDATA[81100207483]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Baxter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42050475</person_id>
				<author_profile_id><![CDATA[81452602436]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198609</article_id>
		<sort_key>89</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[Direct haptic rendering of complex trimmed NURBS models]]></title>
		<page_from>89</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198609</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198609</url>
		<abstract>
			<par><![CDATA[The most accurate haptic rendition of a virtual model is produced when the haptic algorithm acts directly on the actual model and not an intermediate representation. In the modeling and design communities the de facto model representation standard is NURBS. Further, more powerful systems provide trimming and adjacency information within the models representation. This additional information permits more complex models to be expressed succinctly but also increases the complexity of representation. In this paper we present an algorithm that supports direct haptic rendering of models constructed from trimmed NURBS surfaces. Our distributed system links an advanced modeling system to a force-reflecting device. In addition, we present extensions to the algorithm which support model manipulation, dimensioned probes, and multi-probe contact.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35029432</person_id>
				<author_profile_id><![CDATA[81328490545]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[V.]]></middle_name>
				<last_name><![CDATA[Thompson]]></last_name>
				<suffix><![CDATA[II]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39029679</person_id>
				<author_profile_id><![CDATA[81100146161]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Elaine]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cohen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Adachi, Y., 1993, "Touch And Trace On The Free-Form Surface Of Virtual Object," in Proc. Virtual Reality Annual Intl. Symp., Seattle, WA, pp. 162--168.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>836002</ref_obj_id>
				<ref_obj_pid>527216</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Adachi, Y., Kumano, T., and Ogino, K., 1995, "Intermediate Representation For Stiff Virtual Objects," in Proc. Virtual Reality Annual Intl. Symp., Research Triangle Park, NC, pp. 203--210.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cohen, E., Lyche, T., and Riesenfeld, R., 1980, "Discrete B-Splines And Subdivision Techniques In Computer Aided Geometric Design And Computer Graphics," Computer Graphics and Image Processing, Vol. 14, Number 2.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Colgate, J. E., and Brown, J. M., 1994, "Factors Affecting The Z-Width Of A Haptic Display," in Proc. IEEE 1994 International Conference on Robotics & Automation, San Diego, CA, pp. 3205--10.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Nelson, D., Johnson, D., Cohen, E., 1999, "Haptic Rendering of Surface-to-Surface Sculpted Model Interaction," in 8th Annual Symp. Haptic Interfaces for Virtual Environment and Teleoperator Systems, Nashville, TN.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Gibson, J. J., 1966, The Senses Considered as a Perceptual System, Boston, MA, Houghton Mifflin Co.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>926014</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Ho, C., 1997, Feature-Based Process Planning and Automatic Numerical Control Part Programming, Ph.D. Thesis, University of Utah, Computer Science Department.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hollerbach, J. M., Cohen, E. C., Thompson, W. B., and Jacobsen, S. C., 1996, "Rapid Virtual Prototyping Of Mechanical Assemblies," NSF Design and Manufacturing Grantees Conference, Albuquerque, NM.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Jacobsen, S. C., Smith, F. M., Iversen, E. K., and Backman, D. K., 1990, "High Performance, High Dexterity, Force Reflective Teleoperator," in Proc. 38th Conf. Remote Systems Technology, Washington, D.C., pp. 180--185.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Johnson, D. E., and Cohen, E., 1997, "Minimum Distance Queries For Polygonal and Parametric Models," Technical Report UUCS-97-003, University of Utah, Department of Computer Science.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Johnson, D. E., and Cohen, E., 1998, "An improved method for haptic tracing of sculptured surfaces," in 7th Annual Symp. Haptic Interfaces for Virtual Environment and Teleoperator Systems, Anaheim, CA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Maekawa, H. and Hollerbach, J. M., 1998, "Haptic Display for Object Grasping and Manipulating in Virtual Environment," in Proc. IEEE Intl. Conf. Robotics & Automation, Leuven, Belgium, pp. 2566--2573.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Marhefka, D. W., and Orin, D. E., 1996, "Simulation Of Contact Using A Nonlinear Damping Model," in Proc. International Conference on Robotics and Animation, Minneapolis, Minnesota, pp. 1662--1668.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237284</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Mark, W. R., Randolph, S. C., Finch, M., Van Verth, J. M., and Taylor III, R. M., 1996, "Adding Force Feedback To Graphics Systems: Issues And Solutions," in Proc. SIGGRAPH 96, New Orleans, LA, pp. 447--452.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Massie, T. M. and Salisbury, J. K., 1994, "The PHANToM Haptic Interface: A Device for Probing Virtual Objects," in 3rd Annual Symp. Haptic Interfaces for Virtual Environment and Teleoperator Systems, Chicago, IL, DSC-Vol 1, pp. 295--301.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91451</ref_obj_id>
				<ref_obj_pid>91385</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Minsky, M., Ouh-Young, M., Steele, M., Brooks, F. P. Jr., Behensky, M., 1990, "Feeling And Seeing: Issues In Force Display," in Proc. Symposium on Interactive 3D Graphics, Snowbird, UT, pp. 235--243.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>208469</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Piegl, L. and Tiller, W., 1995, The NURBS Book, Berlin, Springer.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>93840</ref_obj_id>
				<ref_obj_pid>93803</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Riesenfeld, R., 1989, "Design Tools For Shaping Spline Models," in Mathematical Methods in Computer Aided Geometric Design, (Edited by T. Lyche and L. Schumaker), Academic Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Riesenfeld, R., 1993, "Modeling With Nurbs Curves And Surfaces," in Fundamental Developments of Computer Aided Geometric Design, L. Piegl (ed.), Academic Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258878</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Ruspini, D. C., Koloarov, K., and Khatib, O., 1997, "The Haptic Display of Complex Graphical Environments," in Proc. SIGGRAPH 97, Los Angeles, CA, pp. 345--351.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Salisbury, K. and Tarr, C., 1997, "Haptic Rendering of Surfaces Defined by Implicit Functions," in Proc. 6th Annual Symp. Haptic Interfaces for Virtual Environment and Teleoperator Systems, Dallas, TX, DSC-Vol. 61, pp. 61--67.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218444</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Snyder, J., 1995, "An Interactive Tool For Placing Curved Surfaces Without Interpenetration," in Proc. SIGGRAPH 95, Los Angeles, CA, pp. 209--218.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Stewart, P., Buttolo, P., and Chen, Y., 1997, "CAD Data Representations for Haptic Virtual Prototyping," in Proc. ASME Design Engineering Technical Conference, Sacramento, CA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>253336</ref_obj_id>
				<ref_obj_pid>253284</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Thompson II, T. V., Johnson, D. E., Cohen, E., 1997, "Direct Haptic Rendering Of Sculptured Models," in Proc. Symposium on Interactive 3D Graphics, Providence, RI, pp. 167--176.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Thompson II, T. V., Nelson, D. D., Cohen, E., and Holler-bach, J. M., 1997, "Maneluverable NURBS Models within a Haptic Virtual Environment," in Proc. 6th Annual Symp. Haptic Interfaces for Virtual Environment and Teleoperator Systems, Dallas, TX, DSC-Vol. 61, pp. 37--44.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>849727</ref_obj_id>
				<ref_obj_pid>846238</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Zilles, C. B., and Salisbury, J. K., 1995, "A Constraint-Based God-Object Method For Haptic Display," in Proc. IEE/RSJ International Conference on Intelligent Robots and Systems, Human Robot Interaction, and Cooperative Robots, Vol 3, pp. 146--151.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198610</article_id>
		<sort_key>97</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[Haptic rendering of surface-to-surface sculpted model interaction]]></title>
		<page_from>97</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198610</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198610</url>
		<abstract>
			<par><![CDATA[Previous work in haptics surface tracing for virtual prototyping and surface design applications has used a point model for virtual finger-surface interaction. We extend this tracing method for surface-to-surface interactions. A straightforward extension of the point-surface formulation to surface-surface can yield extraneous, undesirable solutions, although we rework the formulation to yield more satisfactory solutions. Additionally, we derive an alternative novel velocity formulation for use in a surface-surface tracing paradigm that exhibits additional stability beyond the Newton methods. Both methods require evaluating the surface point and first and second surface partial derivatives for both surfaces, an efficient kilohertz rate computation. These methods are integrated into a three step tracking process that uses a global minimum distance method, the local Newton formulation, and the new velocity formulation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39060976</person_id>
				<author_profile_id><![CDATA[81100407983]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Nelson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40027467</person_id>
				<author_profile_id><![CDATA[81100455711]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Johnson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39029679</person_id>
				<author_profile_id><![CDATA[81100146161]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Elaine]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cohen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>55282</ref_obj_id>
				<ref_obj_pid>55279</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{Bajaj, 1988} Bajaj, C., Hoffmann, C., Lynch, R., Hopcroft, J., "Tracing surface intersections," in Computer Aided Geometric Design, Vol 5, 1988, pp. 285--307.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97881</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{Baraff, 1990} Baraff, D., "Curved surfaces and coherence for non-penetrating rigid body simulation", in Computer Graphics Proceedings, SIGGRAPH, 24(4): 19--28, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{Cai, 1987} Cai, C., Roth, B., "On the spatial motion of rigid bodies with point contact," in International Conference on Robotics and Automation, pp. 686--695, March 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{Cameron, 1997} Cameron, S., "Enhancing GFK: Computing Minimum and Penetration Distances between Convex Polyhedra," in International Conference on Robotics and Automation, April 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{Cremer, 1996} Anitescu, M., Cremer, J., and Potra, F., "Formulating 3D Contact Dynamics Problems," Mech. Struct. & Mach., vol. 24, no. 4, pp. 405--437, Nov. 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{Cohen, 1980} Cohen, E., Lyche, T., and Riesenfeld, R., "Discrete B-Splines And Subdivision Techniques In Computer Aided Geometric Design And Computer Graphics," Computer Graphics and Image Processing, Vol 14, Number 2, October 1980.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{De, 1998} De, S., Srinivasan, M., "Rapid Rendering of "Tool-Tissue" Interactions in Surgical Simulations: Thin Walled Membrane Models", PHANToM User's Group Proceedings, PUG 1998, http://www.sensable.com/ community/PUG98_papers.htm.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>897931</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{Gregory, 1998} Gregory, A., Lin, M., Gottschalk, S., Taylor, R., "H-Collide: A Framework for Fast and Accurate Collision Detection for Haptic Interaction," UNC Report, currently unpublished, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{Gilbert, 1988} Gilbert, E., Johnson, D., Keerthi, S. "A Fast Procedure for Computing the Distance between Complex Objects in Three-Dimensional Space," IEEE Journal of Robotics and Automation, pp. 193--203, April 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{Haug, 1992} Haug, E., Intermediate Dynamics, Prentice Hall, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{Johnson, 1998a} Johnson, D. E., and Cohen, E., " A framework for efficient minimum distance computations," Proc. IEEE Intl. Conf. Robotics & Automation, Leuven, Belgium, May 16--21, 1998, pp. 3678--3684.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{Johnson, 1998b} Johnson, D. E., and Cohen, E., "An improved method for haptic tracing of sculptured surfaces," Symp. on Haptic Interfaces, ASME International Mechanical Engineering Congress and Exposition, Anaheim, CA, Nov. 15--20, 1998, in press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{Kriezis, 1992} Kriezis, G., Patrikalakis, N., Wolder, F., "Topological and differential-equation methods for surface intersections," in Computer-Aided Design, vol. 24, no. 1, January 1992, pp. 41--51.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{Lin, 1994} M. C. Lin, D. Manocha, and J. Canny. Fast contact determination in dynamic environments, in IEEE Conference on Robotics and Automation, pp. 602--609, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>226383</ref_obj_id>
				<ref_obj_pid>226379</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{Maekawa, 1996} Maekawa, T., Wolter, F., Patrikalakis, N., "Um-bilics and lines of curvature for shape interrogation," in Computer Aided Geometric Design, vol. 13, no. 2, March 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{McCalla, 1967} McCalla, T., Introduction to Numerical Methods and FORTRAN Programming, John Wiley & Sons, Inc., 1967.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>913114</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[{Montana, 1986} Montana, D., J., 1986, Tactile sensing and the kinematics of contact, Ph.D. Thesis, Division of Applied Sciences, Harvard University.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>46386</ref_obj_id>
				<ref_obj_pid>46384</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[{Montana, 1988} Montana, D., "The Kinematics of Contact and Grasp", in Int. J. of Rob. Res., vol. 7, no. 3, June 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>918651</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[{Murray, 1990} Murray, R., Robotic Control and Nonholonomic Motion Planning, PhD. Dissertation, Electronics Research Laboratory, College of Engineering, University of California, Berkeley, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[{NRC, 1995} National Research Council, Virtual Reality: Scientific and Technological Challenges, Committee on Virtual Reality Research and Development, National Academy Pres, 1995, p.69.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[{Quinlan, 1994} Quinlan, S. "Efficient Distance Computation between Non-Convex Objects," IEEE Int. Conference on Robotics and Automation, pp. 3324--3329, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258878</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[{Ruspini, 1997} Ruspini, D., Kolarov, K., Khatib, O., "The Haptic Display of Complex Graphical Environments," in Computer Graphics Proceedings, SIGGRAPH, August, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[{Ruspini, 1998} Ruspini, D., Khatib, O., "Dynamic Models for Haptic Rendering Systems." in Advances in Robot Kinematics: ARK'98, June 1998, Strobl/Salzburg, Austria, pp 523--532.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[{Sato, 1996} Sato, Y., Hirata M., Maruyama T., Arita Y., "Efficient Collision Detection using Fast Distance Calculation: Algorithms for Convex and Non-Convex Objects," in Proceedings of the 1996 IEEE International Conference on Robotics and Automation, April, 1996, pp. 771--778.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[{Shabana, 1998} Shabana, A., Dynamics of Multibody Systems, Cambridge University Press, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[{Stewart, 1997} Stewart P., Chen Y., Buttolo P., "CAD Data Representations for Haptics Virtual Prototyping," in Proceedings of DETC '97, 1997 ASME Design Engineering Technical Conferences, Sept. 14--17, 1997, Sacramento, CA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218444</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[{Snyder, 1995} Snyder, J., "An Interactive Tool for Placing Curved Surfaces without Interpenetration," in Computer Graphics Proceedings, SIGGRAPH, Los Angeles, August 6--11, 1995, pp. 209--216.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[{Thompson, 1997} Thompson II, T. V., Nelson, D. D., Cohen, E., and Hollerbach, J. M., "Maneuverable NURBS models within a haptic virtual environment," 6th Annual Symp. Haptic Interfaces for Virtual Environment and Teleoperator Systems, DSC-Vol. 61, (Dallas, TX), pp. 37--44, Nov. 15--21, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[{Thompson, 1999} Thompson II, T. V., Cohen, E., "DIRECT HAPTIC RENDERING OF COMPLEX TRIMMED NURBS MODELS," in 8th Annual Symp. Haptic Interfaces for Virtual Environment and Teleoperator Systems, (Nashville, TN), 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>849727</ref_obj_id>
				<ref_obj_pid>846238</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[{Zilles, 1995} Zilles, C. B., and Salisbury, J. K., "A Constraint-based God-object Method For Haptic Display," in Proc. IEE/RSJ International Conference on Intelligent Robots and Systems, Human Robot Interaction, and Cooperative Robots, Vol 3, pp. 146--151, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198611</article_id>
		<sort_key>105</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[Tactual displays for sensory substitution and wearable computers]]></title>
		<page_from>105</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198611</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198611</url>
		<abstract>
			<par><![CDATA[A major challenge in building practical wearable computer systems is the development of output devices to display or transmit information to the human user. Much effort has been devoted to visual displays that are lightweight and have high resolution. Such efforts are warranted since visual displays are still the dominant output devices used by most computing systems. Auditory displays are now becoming the norm of multimedia systems in addition to visual displays. Whereas vision is best suited for perceiving text and graphics, and audition for speech and music, the sense of touch is intimately involved in nonverbal communication. Whether it is a tap on the shoulder to get someone's attention or a firm handshake to convey trust, touch enables us to exchange information directly with people and the environment through physical contact. The skin is the largest organ of our body, yet only a small portion of it (i.e., the hands) is engaged in most human-computer interactions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P111644</person_id>
				<author_profile_id><![CDATA[81100315053]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hong]]></first_name>
				<middle_name><![CDATA[Z.]]></middle_name>
				<last_name><![CDATA[Tan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Purdue University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP311053500</person_id>
				<author_profile_id><![CDATA[81452609342]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alex]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pentland]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Massachusetts Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bach-y-Rita, P. (1972). Brain Mechanisms in Sensory Substitution. New York: Academic Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bliss, J. C. (1961). Communication via the kinesthetic and tactile senses. Ph.D. Dissertation, Dept. of Electrical Engineering, M.I.T.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>232471</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Burdea, G. C. (1996). Force and Touch Feedback for Virtual Reality. New York: John Wiley & Sons, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cholewiak, R. W., & Collins, A. A. (1995). Exploring the conditions that generate a good vibrotactile line. Presented at the Psychonomic Society Meeting, Los Angeles, CA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cholewiak, R. W., Sherrick, C. E., & Collins, A. A. (1996). Studies of saltation. Princeton Cutaneous Research Project (No. 62). Princeton University, Department of Psychology.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Clark, F. J., & Horch, K. W. (1986). Kinesthesia. In K. R. Boff, L. Kaufman, & J. P. Thomas (Eds.), Handbook of Perception and Human Performance: Sensory Processes and Perception (pp. 13/1--13/62). New York: Wiley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Collins, A. A. (1996). Presentation at the Tactile Research Group Meeting of the Psychonomic Society Meetings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Craig, J. C. (1973). Pictorial and abstract cutaneous displays. In F. A. Geldard (Ed.), Cutaneous Communication Systems and Devices (pp. 78--83). The Psychonomic Society, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Craig, J. C. (1977). Vibrotactile pattern perception: Extraordinary observers. Science, 196, 450--452.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Craig, J. C., & Sherrick, C. E. (1982). Dynamic tactile displays. In W. Schiff & E. Foulke (Eds.), Tactual Perception: A Sourcebook. Cambridge University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Eberhardt, S. P., Bernstein, L. E., Barac-Cikoja, D., Coulter, D. C., & Jordan, J. (1994). Inducing dynamic haptic perception by the hand: system description and some results. In Proceedings of the American Society of Mechanical Engineers, DSC-1, 345--351.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Geldard, F. A. (1966). Cutaneous coding of optical signals: The optohapt. Perception & Psychophysics, 1, 377--381.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Geldard, F. A. (1975). Sensory Saltation: Metastability in the Perceptual World. Hillsdale, New Jersey: Lawrence Erlbaum Associates.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Keidel, W. D. (1973). The cochlear model in skin stimulation. In F. A. Geldard (Ed.), Cutaneous Communication Systems and Devices (pp. 27--32). The Psychonomic Society, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Linvill, J. G., & Bliss, J. C. (1966). A direct translation reading aid for the blind. Proceedings of the Institute of Electrical and Electronics Engineers, 54, 40--51.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Loomis, J. M., & Lederman, S. J. (1986). Tactual perception. In K. R. Boff, L. Kaufman, & J. P. Thomas (Eds.), Handbook of Perception and Human Performance: Cognitive Processes and Performance (pp. 31/1--31/41). New York: Wiley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Massie, T. H., & Salisbury, J. K. (1994). The PHANToM haptic interface: A device for probing virtual objects. In Proceedings of the American Society of Mechanical Engineers, DSC-55(1), 295--299.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Reed, C. M., & Delhorne, L. A. (1995). Current results of field study of adult users of tactile aids. Seminars in Hearing, 16(4), 305--315.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Reed, C. M., Durlach, N. I., & Delhorne, L. A. (1992). The tactual reception of speech, fingerspelling, and sign language by the deaf-blind. Digest of Technical Papers of the Society for Information Display International Symposium, XXIII, 102--105.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Reed, C. M., Durlach, N. I., Delhorne, L. A., Rabinowitz, W. M., & Grant, K. W. (1989). Research on tactual communication of speech: Ideas, issues, and findings. The Volta Review, 91, 65--78.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Reed, C. M., Rabinowitz, W. M., Durlach, N. I., Braida, L. D., Conway-Fithian, S., & Schultz, M. C. (1985). Research on the Tadoma method of speech communication. Journal of the Acoustical Society of America, 77(1), 247--257.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Rollman, G. B. (1973). Electrocutaneous stimulation. In F. A. Geldard (Ed.), Cutaneous Communication Systems and Devices (pp. 38--51). The Psychonomic Society, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Shannon, C. E. (1951). Prediction and entropy of printed English. Bell System Technical Journal, 30, 50--64.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Tan, H. Z., Durlach, N. I., Rabinowitz, W. M., Reed, C. M., & Santos, J. R. (1997). Reception of Morse code through motional, vibrotactile, and auditory stimulation. Perception & Psychophysics, 59(7), 1004--1017.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Tan, H. Z., Durlach, N. I., Reed, C. M., & Rabinowitz, W. M. (1999). Information transmission with a multi-finger tactual display. Perception & Psychophysics, 61(6), 993--1008.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>856452</ref_obj_id>
				<ref_obj_pid>851036</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Tan, H. Z., & Pentland, A. (1997). Tactual displays for wearable computing. Digest of the First International Symposium on Wearable Computers, 84--89. IEEE Computer Society.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Tan, H. Z., & Rabinowitz, W. M. (1996). A new multi-finger tactual display. In Proceedings of the American Society of Mechanical Engineers, DSC-58, 515--522.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Tan, H. Z., Srinivasan, M. A., Eberman, B., & Cheng, B. (1994). Human factors for the design of force-reflecting haptic interfaces. In Proceedings of the American Society of Mechanical Engineers, DSC-55(1), 353--359.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Weisenberger, J. M., & Percy, M. E. (1994). Use of the Tactaid II and Tactaid VII with children. The Volta Review, 96(5), 41--57.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[White, B. W. (1973). What other senses can tell us about cutaneous communication. In F. A. Geldard (Ed.), Cutaneous Communication Systems and Devices (pp. 15--19). The Psychonomic Society, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[White, B. W., Saunders, F. A., Scadden, L., Bach-Y-Rita, P., & Collins, C. C. (1970). Seeing with the skin. Perception & Psychophysics, 7(1), 23--27.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198612</article_id>
		<sort_key>125</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[Toward realistic haptic rendering of surface textures]]></title>
		<page_from>125</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198612</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198612</url>
		<abstract>
			<par><![CDATA[The emerging science of haptic rendering consists of delivering properties of physical objects through the sense of touch. Owing to the recent development of sophisticated haptic-rendering algorithms, users can now experience virtual objects through touch in many exciting applications, including surgical simulations, virtual prototyping, and data per-ceptualization. Haptics holds great promise to enrich the sensory attributes of virtual objects that these systems can produce.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40027728</person_id>
				<author_profile_id><![CDATA[81100480604]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Seungmoon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Choi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Purdue University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P111644</person_id>
				<author_profile_id><![CDATA[81100315053]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hong]]></first_name>
				<middle_name><![CDATA[Z.]]></middle_name>
				<last_name><![CDATA[Tan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Purdue University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[T. H. Massie, Initial Haptic Explorations with the Phantom: Virtual Touch through Point Interaction, master's thesis, Dept. of Mechanical Eng., Massachusetts Inst. of Technology, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1246840</ref_obj_id>
				<ref_obj_pid>1246838</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. Ho, C. Basdogan, and M. A. Srinivasan, "Efficient Point-Based Rendering Techniques for Haptic Display of Virtual Objects," Presence, vol. 8, no. 5, 1999, pp. 477--491.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1246964</ref_obj_id>
				<ref_obj_pid>1246961</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Choi and H. Z. Tan, "Perceived Instability of Virtual Haptic Texture. I. Experimental Studies," Presence, 2003, to be published.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>797523</ref_obj_id>
				<ref_obj_pid>795682</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. Choi and H. Z. Tan, "An Analysis of Perceptual Instability During Haptic Texture Rendering," Proc. 10th Int'l Symp. Haptic Interfaces for Virtual Environment and Teleoperator Systems (IEEE VR 02), IEEE CS Press, 2002, pp. 129--36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Choi and H. Z. Tan, "A Study on the Sources of Perceptual Instability During Haptic Texture Rendering," Proc. IEEE Int'l Conf. Robotics and Automation, IEEE CS Press, 2002, pp. 1261--1268.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>797572</ref_obj_id>
				<ref_obj_pid>795683</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Choi and H. Z. Tan, "An Experimental Study of Perceived Instability During Haptic Texture Rendering: Effects of Collision Detection Algorithm," Proc. 11th Int'l Symp. Haptic Interfaces for Virtual Environment and Teleoperator Systems (IEEE VR 03), IEEE CS Press, 2003, pp. 197--204.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Choi and H. Z. Tan, "Aliveness: Perceived Instability from a Passive Haptic Texture Rendering System," Proc. IEEE/RSJ Int'l Conf. Intelligent Robots and Systems, IEEE CS Press, 2003, pp. 2678--2683.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[B. Hannaford and J.-H. Ryu, "Time-Domain Passivity Control of Haptic Interfaces," IEEE Trans. Robotics and Automation, IEEE CS Press, vol. 18, no. 1, 2002, pp. 1--10.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S. J. Lederman and R. L. Klatzky, "Hand Movement: A Window into Haptic Object Recognition," Cognitive Psychology, vol. 19, 1987, pp. 342--368.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[G. A. Gescheider, Psychophysics: Method, Theory, and Application, 2nd ed., Lawrence Erlbaum Assoc., 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198613</article_id>
		<sort_key>133</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[Haptic display of interaction between textured models]]></title>
		<page_from>133</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198613</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198613</url>
		<abstract>
			<par><![CDATA[Surface texture is among the most salient haptic characteristics of objects; it can induce vibratory contact forces that lead to perception of roughness. In this paper, we present a new algorithm to display haptic texture information resulting from the interaction between two textured objects. We compute contact forces and torques using low-resolution geometric representations along with texture images that encode surface details. We also introduce a novel force model based on directional penetration depth and describe an efficient implementation on programmable graphics hardware that enables interactive haptic texture rendering of complex models. Our force model takes into account important factors identified by psychophysics studies and is able to haptically display interaction due to fine surface textures that previous algorithms do not capture.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[graphics hardware]]></kw>
			<kw><![CDATA[haptics]]></kw>
			<kw><![CDATA[textures]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P362253</person_id>
				<author_profile_id><![CDATA[81100035394]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Miguel]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Otaduy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P209581</person_id>
				<author_profile_id><![CDATA[81100110153]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nitin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jain]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P396740</person_id>
				<author_profile_id><![CDATA[81100512563]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Avneesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sud]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42050475</person_id>
				<author_profile_id><![CDATA[81452602436]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. J. Adams and B. Hannaford. A two-port framework for the design of unconditionally stable haptic interfaces. Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>907242</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Edwin E. Catmull. A Subdivision Algorithm for Computer Display of Curved Surfaces. PhD thesis, Dept. of CS, U. of Utah, December 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Choi and H. Z. Tan. Aliveness: Perceived instability from a passive haptic texture rendering system. Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280832</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Cohen, M. Olano, and D. Manocha. Appearance preserving simplification. In Proc. of ACM SIGGRAPH, pages 115--122, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. Dobkin, J. Hershberger, D. Kirkpatrick, and S. Suri. Computing the intersection-depth of polyhedra. Algorithmica, 9:518--533, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[E. G. Gilbert and C. J. Ong. New distances for the separation and penetration of objects. In Proceedings of International Conference on Robotics and Automation, pages 579--586, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1007594</ref_obj_id>
				<ref_obj_pid>1007568</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[N. K. Govindaraju, B. Lloyd, W. Wang, M. C. Lin, and D. Manocha. Fast computation of database operations using graphics processors. Proc. of ACM SIGMOD, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[L. J. Guibas and J. Stolfi. Ruler, compass and computer: the design and analysis of geometric algorithms. In R. A. Earnshaw, editor, Theoretical Foundations of Computer Graphics and CAD, volume 40 of NATO ASI Series F, pages 111--165. Springer-Verlag, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>662252</ref_obj_id>
				<ref_obj_pid>645626</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[V. Hayward and B Armstrong. A new computational model of friction applied to haptic rendering. Experimental Robotics VI, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1246840</ref_obj_id>
				<ref_obj_pid>1246838</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[C.-H. Ho, C. Basdogan, and M. A. Srinivasan. Efficient point-based rendering techniques for haptic display of virtual objects. Presence, 8(5):pp. 477--491, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>797570</ref_obj_id>
				<ref_obj_pid>795683</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[D. Johnson and P. Willemsen. Six degree of freedom haptic rendering of complex polygonal models. In Proc. of Haptics Symposium, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[S. S. Keerthi and K. Sridharan. Efficient algorithms for computing two measures of depth of collision between convex polygons. Technical Report, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Y. Kim, M. Lin, and D. Manocha. DEEP: an incremental algorithm for penetration depth computation between convex polytopes. Proc. of IEEE Conference on Robotics and Automation, pages 921--926, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>545266</ref_obj_id>
				<ref_obj_pid>545261</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Y. Kim, M. Otaduy, M. Lin, and D. Manocha. Fast penetration depth computation for physically-based animation. Proc. of ACM Symposium on Computer Animation, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>942442</ref_obj_id>
				<ref_obj_pid>942439</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Y. J. Kim, M. A. Otaduy, M. C. Lin, and D. Manocha. Six-degree-of-freedom haptic rendering using incremental and localized computations. Presence, 12(3):277--295, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[R. L. Klatzky and S. J. Lederman. Perceiving texture through a probe. In M. L. McLaughlin, J. P. Hespanha, and G. S. Sukhatme, editors, Touch in Virtual Environments, chapter 10, pages 180--193. Prentice Hall PTR, Upper Saddle River, NJ, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311600</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[W. McNeely, K. Puterbaugh, and J. Troy. Six degree-of-freedom haptic rendering using voxel sampling. Proc. of ACM SIGGRAPH, pages 401--408, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>240160</ref_obj_id>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[M. Minsky. Computational Haptics: The Sandpaper System for Synthesizing Texture for a Force-Feedback Display. PhD thesis, Ph.D. Dissertation, Program in Media Arts and Sciences, MIT, 1995. Thesis work done at UNC-CH Computer Science.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[A. M. Okamura and M. R. Cutkosky. Feature detection for haptic exploration with robotic fingers. International Journal of Robotics Research, 20(12):925--938, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882305</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[M. A. Otaduy and M. C. Lin. Sensation preserving simplification for haptic rendering. ACM Trans. on Graphics (Proc. of ACM SIGGRAPH), pages 543--553, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1012574</ref_obj_id>
				<ref_obj_pid>1012551</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[M. A. Otaduy and M. C. Lin. A perceptually-inspired force model for haptic texture rendering. Proc. of Symposium APGV, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[M. Peshkin and J. E. Colgate. Cobots. Industrial Robot, 26(5):335--341, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[D. Ruspini and O. Khatib. A framework for multi-contact multi-body dynamic simulation and haptic display. Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>310976</ref_obj_id>
				<ref_obj_pid>310930</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[J. K. Salisbury. Making graphics physically tangible. Communications of the ACM, 42(8), 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383307</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[P. V. Sander, J. Snyder, S. J. Gortler, and H. Hoppe. Texture mapping progressive meshes. Proc. of ACM SIGGRAPH, pages 409--416, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[J. Siira and D. K. Pai. Haptic textures - a stochastic approach. Proc. of IEEE International Conference on Robotics and Automation, pages 557--562, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1081478</ref_obj_id>
				<ref_obj_pid>1081432</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[M. Wan and W. A. McNeely. Quasi-static approximation for 6 degrees-of-freedom haptic rendering. Proc. of IEEE Visualization, pages 257--262, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198614</article_id>
		<sort_key>141</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[A unified treatment of elastostatic contact simulation for real time haptics]]></title>
		<page_from>141</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198614</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198614</url>
		<abstract>
			<par><![CDATA[We describe real-time, physically-based simulation algorithms for haptic interaction with elastic objects. Simulation of contact with elastic objects has been a challenge, due to the complexity of physically accurate simulation and the difficulty of constructing useful approximations suitable for real time interaction. We show that this challenge can be effectively solved for many applications. In particular global deformation of linear elastostatic objects can be efficiently solved with low run-time computational costs, using precomputed Green's functions and fast low-rank updates based on <i>Capacitance Matrix Algorithms</i>. The capacitance matrices constitute exact force response models, allowing contact forces to be computed much faster than global deformation behavior. <i>Vertex pressure masks</i> are introduced to support the convenient abstraction of localized scale-specific point-like contact with an elastic and/or rigid surface approximated by a polyhedral mesh. Finally, we present several examples using the CyberGlove#8482; and PHANToM#8482; haptic interfaces.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P69488</person_id>
				<author_profile_id><![CDATA[81100415142]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Doug]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[James]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of British Columbia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P67322</person_id>
				<author_profile_id><![CDATA[81100642559]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dinesh]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Pai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of British Columbia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Oliver Astley and Vincent Hayward. Multirate haptic simulation achieved by coupling finite element meshes through norton equivalents. In Proceedings of the IEEE International Conference on Robotics and Automation, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Remis Balaniuk. Building a haptic interface based on a buffer model. In Proceedings of the IEEE International Conference on Robotics and Automation, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[James R. Barber. Elasticity. Kluwer Press, Dordrecht, first edition, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. A. Brebbia, J. C. F. Telles, and L. C. Wrobel. Boundary Element Techniques: Theory and Applications in Engineering. Springer-Verlag, New York, second edition, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>718980</ref_obj_id>
				<ref_obj_pid>647241</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Morten Bro-Nielsen. Surgery simulation using fast finite elements. Lecture Notes in Computer Science, 1131:529-, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Morten Bro-Nielsen and Stephane Cotin. Real-time volumetric deformable models for surgery simulation using finite elements and condensation. Computer Graphics Forum, 15(3):57--66, August 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Murak Cenk &#199;avu&#351;o&#287;lu and Frank Tendick. Multirate simulation for high fidelity haptic interaction with deformable objects in virtual environments. In Proceedings of the IEEE International Conference on Robotics and Automation, San Francisco, USA, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614422</ref_obj_id>
				<ref_obj_pid>614273</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Cotin, H. Delingette, and N. Ayache. Realtime elastic deformations of soft tissues for surgery simulation. IEEE Transactions On Visualization and Computer Graphics, 5(1):62--73, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Stephane Cotin, Herve Delingette, and Nicholas Ayache. Efficient linear elastic models of soft tissues for real-time surgery simulation. Technical Report RR-3510, Inria, Institut National de Recherche en Informatique et en Automatique, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Diego d'Aulignac, Remis Balaniuk, and Christian Laugier. A haptic interface for a virtual exam of a human thigh. In Proceedings of the IEEE International Conference on Robotics and Automation, San Francisco, USA, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Gilles Debunne, Mathieu Desbrun, Alan Barr, and Marie-Paule Cani. Interactive multiresolution animation of deformable models. In N. Magnenat-Thalmann and D. Thalmann, editors, Computer Animation and Simulation '99, SpringerComputerScience, pages 133--144. Springer-Verlag Wien New York, 1999. Proceedings of the Eurographics Workshop in Milano, Italy, September 7--8, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Y. Ezawa and N. Okamoto. High-speed boundary element contact stress analysis using a super computer. In Proc. of the 4th International Conference on Boundary Element Technology, pages 405--416, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Sarah Gibson, Christina Fyock, Eric Grimson, Takeo Kanade, Rob Kikinis, Hugh Lauer, Neil McKenzie, Andrew Mor, Shin Nakajima, Hide Ohkami, Randy Osborne, Joseph Samosky, and Akira Sawada. Volumetric object modeling for surgical simulation. Medical Image Analysis, 2(2):121--132, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Sarah F. Gibson and Brian Mirtich. A survey of deformable models in computer graphics. Technical Report TR-97-19, Mitsubishi Electric Research Laboratories, Cambridge, MA, November 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Gene H. Golub and Charles F. Van Loan. Matrix Computations. Johns Hopkins University Press, Baltimore and London, third edition, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>75570</ref_obj_id>
				<ref_obj_pid>75568</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[William W. Hager. Updating the inverse of a matrix. SIAM Review, 31(2):221--239, June 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>709475</ref_obj_id>
				<ref_obj_pid>646921</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[K. V. Hansen and O. V. Larsen. Using region-of-interest based finite element modeling for brain-surgery simulation. Lecture Notes in Computer Science, 1496:305-, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Friedel Hartmann. The mathematical foundation of structural mechanics. Springer-Verlag, New York, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1246840</ref_obj_id>
				<ref_obj_pid>1246838</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[C.-H. Ho, C. Basdogan, and M. A. Srinivasan. Efficient point-based rendering techniques for haptic display of virtual objects. Presence, 8(5):477--491, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Doug L. James. http://www.cs.ubc.ca/~djames/deformable.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311542</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Doug L. James and Dinesh K. Pai. ARTDEFO: Accurate Real Time Deformable Objects. Computer Graphics, 33(Annual Conference Series):65--72, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[A. M. Abu Kassim and B. H. V. Topping. Static reanalysis: a review. Journal of Structural Engineering, 113:1029--1045, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[U. K&#252;hnapfel, H. K. &#199;akmak, and H. Maa&#223;. 3d modeling for endoscopic surgery. In Proceedings of IEEE Symposium on Simulation, pages 22--32, Delft University, Delft, NL, October 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Charles Loop. Smooth subdivision surfaces based on triangles. Master's thesis, University of Utah, Department of Mathematics, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[K. W. Man, M. H. Aliabadi, and D. P. Rooke. Analysis of Contact Friction using the Boundary Element Method. In M. H. Aliabadi and C. A. Brebbia, editors, Computational Methods in Contact Mechanics, chapter 1, pages 1--60. Computational Mechanics Publications and Elsevier Applied Science, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[T. H. Massie and J. K. Salisbury. The phantom haptic interface: A device for probing virtual objects. In ASME Winter Annual Meeting, Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, Chicago, IL, Nov. 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Hugh B. Morgenbesser and Mandayam A. Srinivasan. Force shading for haptic shape perception. In Proceedings of the ASME Dynamics Systems and Control Division, volume 58, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383268</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Dinesh K. Pai, Kees van den Doel, Doug L. James, Jochen Lang, John E. Lloyd, Joshua L. Richmond, and Som H. Yau. Scanning Physical Interaction Behavior of 3D Objects. In Computer Graphics Proceedings (SIGGRAPH 2001). ACM Siggraph, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[G. Picinbono, J. C. Lombardo, H. Delingette, and N. Ayache. Anisotropic elasticity and force extrapolation to improve realism of surgery simulation. In Proceedings of IEEE International Conference on Robotics and Automation, San Francisco, USA, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>6771</ref_obj_id>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[William H. Press, Brian P. Flannery, Saul A. Teukolsky, and William T. Vetterling. Numerical Recipes: The Art of Scientific Computing, chapter Sherman-Morrison and Woodbury, pages 66--70. Cambridge University Press, Cambridge, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835796</ref_obj_id>
				<ref_obj_pid>832288</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[R. Ramanathan and D. Metaxas. Dynamic deformable models for enhanced haptic rendering in virtual environments. In IEEE Virtual Reality Conference, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[P. Schr&#246;der, D. Zorin, T. DeRose, D. R. Forsey, L. Kobbelt, M. Lounsbery, and J. Peters. Subdivision for modeling and animation. SIGGRAPH 99 Course Notes, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Sensable Technologies, Inc. GHOST SDK, http://www.sensable.com.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Yan Zhuang and John Canny. Haptic interaction with global deformations. In Proceedings of the IEEE International Conference on Robotics and Automation, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[O. C. Zienkiewicz. The Finite Element Method. McGraw-Hill Book Company (UK) Limited, Maidenhead, Berkshire, England, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[C. B. Zilles and J. K. Salisbury. A constraint-based god-object method for haptic display. In ASME Haptic Interfaces for Virtual Environment and Teleoperator Systems, volume 1, pages 149--150, Chicago, IL (US), 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198615</article_id>
		<sort_key>154</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[Scanning physical interaction behavior of 3D objects]]></title>
		<page_from>154</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198615</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198615</url>
		<abstract>
			<par><![CDATA[We describe a system for constructing computer models of several aspects of physical interaction behavior, by scanning the response of real objects. The behaviors we can successfully scan and model include deformation response, contact textures for interaction with force-feedback, and contact sounds. The system we describe uses a highly automated robotic facility that can scan behavior models of whole objects. We provide a comprehensive view of the modeling process, including selection of model structure, measurement, estimation, and rendering at interactive rates. The results are demonstrated with two examples: a soft stuffed toy which has significant deformation behavior, and a hard clay pot which has significant contact textures and sounds. The results described here make it possible to quickly construct physical interaction models of objects for applications in games, animation, and e-commerce.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[behavioral animation]]></kw>
			<kw><![CDATA[deformations]]></kw>
			<kw><![CDATA[haptics]]></kw>
			<kw><![CDATA[multimedia]]></kw>
			<kw><![CDATA[physically based modeling]]></kw>
			<kw><![CDATA[robotics]]></kw>
			<kw><![CDATA[sound visualization]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P67322</person_id>
				<author_profile_id><![CDATA[81100642559]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dinesh]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Pai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of British Columbia, Vancouver, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP27007484</person_id>
				<author_profile_id><![CDATA[81322508645]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kees]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[van den Doel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of British Columbia, Vancouver, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P69488</person_id>
				<author_profile_id><![CDATA[81100415142]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Doug]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[James]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of British Columbia, Vancouver, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39041418</person_id>
				<author_profile_id><![CDATA[81100407473]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jochen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of British Columbia, Vancouver, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42049215</person_id>
				<author_profile_id><![CDATA[81339514644]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Lloyd]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of British Columbia, Vancouver, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P337924</person_id>
				<author_profile_id><![CDATA[81342508805]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Joshua]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Richmond]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of British Columbia, Vancouver, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P337994</person_id>
				<author_profile_id><![CDATA[81100418176]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Som]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Yau]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of British Columbia, Vancouver, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>229157</ref_obj_id>
				<ref_obj_pid>229144</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M. J. Black and P. Anandan. The Robust Estimation of Multiple Motions: Parametric and Piecewise-smooth Flow Fields. Computer Vision and Image Understanding, 63(1):75--104, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>939028</ref_obj_id>
				<ref_obj_pid>938978</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Y. Bouguet and P. Perona. 3D Photography on Your Desk. In Proc. ICCV98, pages 43--50, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. C. Brown and M. S. Puckette. A High Resolution Fundamental Frequency Determination Based on Phase Changes of the Fourier Transform. J. Acoust. Soc. Am., 94(2):662--667, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258911</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M. Cohen, M. Levoy, J. Malik, L. McMillan, and E. Chen. Image-based Rendering: Really New or Deja Vu? ACM SIGGRAPH 97 Panel, pages 468--470.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[P. R. Cook. Integration of Physical Modeling for Synthesis and Animation. In Proceedings of the International Computer Music Conference, pages 525--528, Banff, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[P. R. Cook and D. Trueman. NBody: Interactive Multi-directional Musical Instrument Body Radiation Simulations, and a Database of Measured Impulse Responses. In Proceedings of the International Computer Music Conference, San Francisco, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Cotin, H. Delingette, J-M Clement, V. Tassetti, J. Marescaux, and N. Ayache. Geometric and Physical Representations for a Simulator of Hepatic Surgery. In Proceedings of Medicine Meets Virtual Reality IV, pages 139--151. IOS Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237269</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[B. Curless and M. Levoy. A Volumetric Method for Building Complex Models from Range Images. In SIGGRAPH 96 Conference Proceedings, pages 303--312, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300778</ref_obj_id>
				<ref_obj_pid>300776</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[K. J. Dana, B. van Ginneken, S. K. Nayar, and J. J. Koenderink. Reflectance and Texture of Real-world Surfaces. ACM Transactions on Graphics, 18(1):1--34, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344855</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[P. Debevec, T. Hawkins, C. Tchou, H-P Duiker, W. Sarokin, and M. Sagar. Acquiring the Reflectance Field of a Human Face. In SIGGRAPH 2000 Conference Proceedings, pages 145--156, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237191</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[P. E. Debevec, C. J. Taylor, and J. Malik. Modeling and Rendering Architecture from Photographs: A Hybrid Geometry- and Image-Based Approach. In SIGGRAPH 96 Conference Proceedings, pages 11--20, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[T. A. Funkhouser, I. Carlbom, G. Pingali G. Elko, M. Sondhi, and J. West. Interactive Acoustic Modeling of Complex Environments. J. Acoust. Soc. Am., 105(2), 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258849</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[M. Garland and P. S. Heckbert. Surface Simplification Using Quadric Error Metrics. In SIGGRAPH 97 Conference Proceedings, pages 209--216, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>169184</ref_obj_id>
				<ref_obj_pid>169059</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[W. W. Gaver. Synthesizing Auditory Icons. In Proceedings of the ACM INTERCHI 1993, pages 228--235, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258914</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[D. P. Greenberg, K. E. Torrance, P. Shirley, J. Arvo, J. A. Ferwerda, S. Pattanaik, E. P. F. Lafortune, B. Walter, S. Foo, and B. Trumbore. A Framework for Realistic Image Synthesis. In SIGGRAPH 97 Conference Proceedings, pages 477--494, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344831</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[I. Guskov, K. Vidimce, W. Sweldens, and P. Schroder. Normal Meshes. In SIGGRAPH 2000 Conference Proceedings, pages 95--102, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192233</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[H. Hoppe, T. DeRose, T. Duchamp, M. Halstead, H. Jin, J. McDonald, J. Schweitzer, and W. Stuetzle. Piecewise Smooth Surface Reconstruction. In SIGGRAPH 94 Conference Proceedings, pages 295--302, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311542</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[D. L. James and D. K. Pai. ARTDEFO, Accurate Real Time Deformable Objects. In SIGGRAPH 99 Conference Proceedings, pages 65--72, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[D. L. James and D. K. Pai. A Unified Treatment of Elastostatic Contact Simulation for Real Time Haptics. Haptics-e, The Electronic Journal of Haptics Research (www.haptics-e.org), 2001. (To appear).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[J. Lang and D. K. Pai. Estimation of Elastic Constants from 3D Range-Flow. In Proceedings of the Third International Conference on 3-D Digital Imaging and Modeling, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344829</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[A. Lee, H. Moreton, and H. Hoppe. Displaced Subdivision Surfaces. In SIGGRAPH 2000 Conference Proceedings, pages 85--94, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280828</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[A. Lee, W. Sweldens, P. Schr&#246;der, L. Cowsar, and D. Dobkin. MAPS: Multiresolution Adaptive Parameterization of Surfaces. In SIGGRAPH 98 Conference Proceedings, pages 95--104, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344849</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[M. Levoy, et al. The Digital Michelangelo Project: 3D Scanning of Large Statues. In SIGGRAPH 2000 Conference Proceedings, pages 131--144, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>662553</ref_obj_id>
				<ref_obj_pid>645627</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[D. K. Pai, J. Lang, J. E. Lloyd, and J. L. Richmond. Reality-based Modeling with ACME: A Progress Report. In Proceedings of the Intl. Symp. on Experimental Robotics, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>662381</ref_obj_id>
				<ref_obj_pid>645626</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[D. K. Pai, J. Lang, J. E. Lloyd, and R. J. Woodham. ACME, A Telerobotic Active Measurement Facility. In Proceedings of the Sixth Intl. Symp. on Experimental Robotics, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311536</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Z. Popovic and A. Witkin. Physically Based Motion Transformation. In SIGGRAPH 99 Conference Proceedings, pages 11--20, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383828</ref_obj_id>
				<ref_obj_pid>2383815</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[C. Rocchini, P. Cignoni, C. Montani, and P. Scopigno. Multiple Textures Stitching and Blending on 3D Objects. In 10th Eurographics Workshop on Rendering, pages 173--180, Granada, Spain, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>266797</ref_obj_id>
				<ref_obj_pid>266774</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[G. Roth and E. Wibowoo. An Efficient Volumetric Method for Building Closed Triangular Meshes from 3-D Image and Point Data. In Proc. Graphics Interface, pages 173--180, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[P. J. Rousseeuw. Least Median of Squares Regression. Journal of the American Statistical Association, 79(388):871--880, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[P. J. Rousseeuw and K. Van Driessen. Computing LTS Regression for Large Data Sets. Technical report, University of Antwerp, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[H. Rushmeier, F. Bernardini, J. Mittleman, and G. Taubin. Acquiring Input for Rendering at Appropriate Levels of Detail: Digitizing a Piet&#224;. Eurographics Rendering Workshop 1998, pages 81--92, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258878</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[D. C. Ruspini, K. Kolarov, and O. Khatib. The Haptic Display of Complex Graphical Environments. In SIGGRAPH 97 Conference Proceedings, pages 345--352, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258885</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Y. Sato, M. D. Wheeler, and K. Ikeuchi. Object Shape and Reflectance Modeling from Observation. In SIGGRAPH 97 Conference Proceedings, pages 379--388, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>877429</ref_obj_id>
				<ref_obj_pid>876866</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[H. Spies, B. J&#228;hne, and J. L. Barron. Dense Range Flow from Depth and Intensity Data. In International Conference on Pattern Recognition, pages 131--134, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>265600</ref_obj_id>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[K. Steiglitz. A Digital Signal Processing Primer with Applications to Digital Audio and Computer Music. Addison-Wesley, New York, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[K. Steiglitz and L. E. McBride. A Technique for the Identification of Linear System. IEEE Trans. Automatic Control, AC-10:461--464, 1965.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[D. Terzopoulos, J. Platt, A. Barr, and K. Fleischer. Elastically Deformable Models. In Computer Graphics (SIGGRAPH 87 Proceedings), volume 21, pages 205--214, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[T. R. Thomas. Rough Surfaces. Imperial College Press, London, second edition, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383322</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[K. van den Doel, P. G. Kry, and D. K. Pai. FoleyAutomatic: Physically-based Sound Effects for Interactive Simulations and Animations. In SIGGRAPH 2001 Conference Proceedings, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1246774</ref_obj_id>
				<ref_obj_pid>1246770</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[K. van den Doel and D. K. Pai. The Sounds of Physical Shapes. Presence, 7(4):382--395, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>851537</ref_obj_id>
				<ref_obj_pid>850924</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[S. Vedula, S. Baker, P. Rander, R. Collins, and T. Kanade. Three-dimensional Scene Flow. In International Conference on Computer Vision, pages 722--729, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628442</ref_obj_id>
				<ref_obj_pid>628298</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[M. Yamamoto, P. Boulanger, J.-A. Beraldin, and M. Rioux. Direct Estimation of Range Flow on Deformable Shape from a Video Rate Range Camera. PAMI, 15(1):82--89, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Y. Zhang and C. Kambhamettu. Integrated 3D Scene Flow and Structure Recovery from Multiview Image Sequences. In Computer Vision and Pattern Recognition, volume 2, pages 674--681, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198616</article_id>
		<sort_key>164</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[The AHI]]></title>
		<subtitle><![CDATA[an audio and haptic interface for contact interactions]]></subtitle>
		<page_from>164</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198616</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198616</url>
		<abstract>
			<par><![CDATA[We have implemented a computer interface that renders synchronized auditory and haptic stimuli with very low (0.5ms) latency. The audio and haptic interface (AHI) includes a Pantograph haptic device that reads position input from a user and renders force output based on this input. We synthesize audio by convolving the force profile generated by user interaction with the impulse response of the virtual surface. Auditory and haptic modes are tightly coupled because we produce both stimuli from the same force profile. We have conducted a user study with the AHI to verify that the 0.5ms system latency lies below the perceptual threshold for detecting separation between auditory and haptic contact events. We discuss future applications of the AHI for further perceptual studies and for synthesizing continuous contact interactions in virtual environments.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[audio]]></kw>
			<kw><![CDATA[haptics]]></kw>
			<kw><![CDATA[latency]]></kw>
			<kw><![CDATA[multimodal]]></kw>
			<kw><![CDATA[synchronization]]></kw>
			<kw><![CDATA[user interface]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P66068</person_id>
				<author_profile_id><![CDATA[81100240893]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Derek]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[DiFilippo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of British Columbia, Vancouver, BC, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P67322</person_id>
				<author_profile_id><![CDATA[81100642559]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dinesh]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Pai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of British Columbia, Vancouver, BC, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>188466</ref_obj_id>
				<ref_obj_pid>188465</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Armstrong, B., Dupont P. and Canudas de Wit C. A Survey of Models, Analysis Tools and Compensation Methods for the Control of Machines with Friction. Automatica. 30,7 (1994), 1083--1138.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cook, P. R. Physically Informed Sonic Modeling (PhISM): Synthesis of Percussive Sounds. Computer Music Journal. 21, 3 (1997), 38--49.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[DiFranco, D. E. and Beauregard, G. L. and Srinivasan, M. A. The Effect of Auditory Cues on the Haptic Perception of Stiffness in Virtual Environments. Proc. ASME Dynamic Systems and Control Division, (1997).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>551861</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Ebert, D. S., Musgrave, F. K., Peachey, D., Perlin, K. and Worley, K. Texturing and Modelling. AP Professional, New York NY, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Fritz, J. P. and Barner K. E. Stochastic models for haptic texture. Proc. SPIE Int. Symp. on Intelligent Systems and Advanced Manufacturing, Boston MA, November 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>662252</ref_obj_id>
				<ref_obj_pid>645626</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hayward, V. and Armstrong, B. A new computational model of friction applied to haptic rendering. Experimental Robotics VI, Lecture Notes in Control and Information Sciences, Springer-Verlag, NY, Vol. 250, 403--412.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1246897</ref_obj_id>
				<ref_obj_pid>1246889</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Klatzky, R. L., Pai, D. K. and Krotkov, E. P. Hearing Material: Perception of Material from Contact Sounds. To appear in Presence, October 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Lederman, S. J. Auditory Texture Perception. Perception. 8 (1979), 93--103.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Lederman, S. J., Klatzky, R. L., Hamilton, C. L. and Ramsay, G. I. Perceiving Surface Roughness via a Rigid Probe: Effects of Exploration Speed and Mode of Touch. The Electronic Journal of Haptics Research, 1, 1, (1999).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Levitin, D. J., MacLean, K. and Mathews, M. The Perception of Cross-Modal Simultaneity. To appear in Int. Journal of Computing Anticipatory Systems, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>561828</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Murray, R. M., Li, Z. and Sastry, S. S. A Mathematical Introduction to Robotic Manipulation. CRC Press, Ann Arbor MI, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Miner, N., Gillespie, B. and Caudell, T. Examining the Influence of Audio and Visual Stimuli on a Haptic Display. Proc. of the 1996 IMAGE Conf., Phoenix AZ, June 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304653</ref_obj_id>
				<ref_obj_pid>304632</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Pierce, J. Hearing in Time and Space. Chapter 8 of Music, Cognition, and Computerized Sound. The MIT Press, Cambridge MA, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>260039</ref_obj_id>
				<ref_obj_pid>259963</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Ramstein, C. and Hayward, V. The Pantograph: a large workspace haptic device for a multi-modal Human-computer interaction. Conf. on Human Factors in Computing Systems ACM/SIGCHI, Boston MA, April 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Richmond, J. L. and Pai, D. K. Active Measurement of Contact Sounds. Proc. of the 2000 IEEE Int. Conf. on Robotics and Automation, San Francisco, April 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Salcudean, S. E., and Vlaar, T. On the Emulation of Stiff Walls and Static Friction with a Magnetically Levitated Input-Output Device. ASME J. Dynamic Systems, Meas., Control. 119 (1997), 127--132.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Serafin, S., Vergez, C. and Rodet, X. Friction and Application to Real-time Physical Modeling of a Violin. Int. Computer Music Conf., Beijing, October 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Siira J. and Pai D. K. Haptic Textures --- A Stochastic Approach. IEEE International Conference on Robotics and Automation, Minneapolis MN, April 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Srinivasan, M. A. and Basdogan C., Haptics in Virtual Environments: Taxonomy, Research Status, and Challenges. Comput. & Graphics. 4, 21 (1997), 393--404.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1246774</ref_obj_id>
				<ref_obj_pid>1246770</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[van den Doel, K. and Pai, D. K. The Sounds of Physical Shapes. Presence 7, 4 (1998), 382--395.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198617</article_id>
		<sort_key>174</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[Haptics for scientific visualization]]></title>
		<page_from>174</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198617</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198617</url>
		<abstract>
			<par><![CDATA[The use of haptics in scientific visualization has barely begun, yet it already shows great promise. While haptics may be useful for pure visualization tasks, its true power comes from its ability to allow the user to simultaneously push on and be pushed by the computer. This allows direct and immediate control and sensing of parameters in a simulation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39046691</person_id>
				<author_profile_id><![CDATA[81405594834]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Russell]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Taylor]]></last_name>
				<suffix><![CDATA[II]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[ASEL (1998). http://www.asel.udel.edu/sem/research/haptics/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>245054</ref_obj_id>
				<ref_obj_pid>244979</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Avila, R. S. and L. M. Sobierajski (1996). <u>A Haptic Interaction Method for Volume Visualization</u>. Proceedings of IEEE Visualization '96, San Francisco. 197--204.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97899</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Brooks, F. P., Jr., M. Ouh-Young, et al. (1990). <u>Project GROPE - Haptic displays for scientific visualization</u>. Computer Graphics: Proceedings of SIGGRAPH '90, Dallas, Texas. 177--185.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[DiFranco, D. E., G. L. Beauregard, et al. (1997). <u>The effect of auditory cues on the haptic perception of stiffness in virtual environments</u>. Proceedings of the ASME Dynamic Systems and Control Division, ASME. 17--22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199406</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Finch, M., V. Chi, et al. (1995). <u>Surface Modification Tools in a Virtual Environment Interface to a Scanning Probe Microscope</u>. Computer Graphics: Proceedings of the ACM Symposium on Interactive 3D Graphics, Monterey, CA, ACM SIGGRAPH. 13--18.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Fritz, J. and K. Barner (1996). <u>Stochastic models for haptic texture</u>. Proceedings of the SPIE International Symposium on Intelligent Systems and Advanced Manufacturing - Telemanipulator and Telepresence Technologies III, Boston, MA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Fritz, J. P. (1996). Haptic Rendering Techniques for Scientific Visualization. <u>Electrical Engineering</u>, University of Delaware: 148.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hollins, M., A. Seeger, et al. (2004). "Haptic perception of virtual surfaces: Scaling subjective qualities and interstimulus differences." <u>Perception</u> 33: 1001--1019.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Iwata, H. and H. Noma (1993). <u>Volume Haptization</u>. Proc. IEEE 1993 Symposium on Research Frontiers in Virtual Reality. 16--23.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Minsky, M. (1995). Computational Haptics: The Sandpaper System for Synthesizing Texture for a ForFeedback Display. <u>Program in Media Arts and Sciences</u>, MIT: 217.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91451</ref_obj_id>
				<ref_obj_pid>91385</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Minsky, M., M. Ouh-young, et al. (1990). <u>Feeling and Seeing: Issues in Force Display</u>. Proceedings ACM Siggraph Symposium on Interactive 3D Graphics.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Mitsuishi, M., Y. Hatamura, et al. (1993). <u>Auditory and Force Display of Key Physical Information in Machining/Handling for Macro/Micro Teleoperation</u>. Proceedings of the 1993 IEEE International Conference on Robotics and Automation, Atlanta, Georgia. 137--169.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Ouh-young, M. (1990). Force Display In Molecular Docking. <u>Computer Science</u>. Chapel Hill, University of North Carolina: Tech Report #90-004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Seeger, A., A. Henderson, et al. (2000). <u>Haptic Display of Multiple Scalar Fields on a Surface</u>. Workshop on New Paradigms in Information Visualization and Manipulation, ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Srinivasan, M. A., G. L. Beauregard, et al. (1996). <u>The impact of visual information on the haptic perception of stiffness in virtual environments</u>. Proceedings of the ASME Dynamics Systems and Control Division, ASME. 555--559.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>267123</ref_obj_id>
				<ref_obj_pid>266989</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Taylor II, R. M., J. Chen, et al. (1997). <u>Pearls Found on the way to the Ideal Interface for Scanned-probe Microscopes</u>. Visualization '97, Phoenix, AZ, IEEE Computer Society Press. 467--470.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166133</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Taylor II, R. M., W. Robinett, et al. (1993). <u>The Nanomanipulator: A Virtual-Reality Interface for a Scanning Tunneling Microscope</u>. SIGGRAPH 93, Anaheim, California, ACM SIGGRAPH. 127--134.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198618</article_id>
		<sort_key>180</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[DAB]]></title>
		<subtitle><![CDATA[interactive haptic painting with 3D virtual brushes]]></subtitle>
		<page_from>180</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198618</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198618</url>
		<abstract>
			<par><![CDATA[We present a novel painting system with an intuitive haptic interface, which serves as an expressive vehicle for interactively creating painterly works. We introduce a deformable, 3D brush model, which gives the user natural control of complex brush strokes. The force feedback enhances the sense of realism and provides tactile cues that enable the user to better manipulate the paint brush. We have also developed a bidirectional, two-layer paint model that, combined with a palette interface, enables easy loading of complex blends onto our 3D virtual brushes to generate interesting paint effects on the canvas. The resulting system, DAB, provides the user with an artistic setting, which is conceptually equivalent to a real-world painting environment. Several users have tested DAB and were able to start creating original art work within minutes.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[deformable brush model]]></kw>
			<kw><![CDATA[haptics]]></kw>
			<kw><![CDATA[human computer interaction]]></kw>
			<kw><![CDATA[painting systems]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P338042</person_id>
				<author_profile_id><![CDATA[81100207506]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bill]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Baxter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP28017499</person_id>
				<author_profile_id><![CDATA[81100646589]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Vincent]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Scheib]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42050475</person_id>
				<author_profile_id><![CDATA[81452602436]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P67316</person_id>
				<author_profile_id><![CDATA[81100618474]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Dinesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Manocha]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>199429</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{ABL95} M. Agrawala, A. Beers, and M. Levoy. 3D painting on scanned surfaces. In the Proc. of 1995 Symposium on Interactive 3D Graphics, pages 145--150. ACM SIGGRAPH, April 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280821</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{BW98} D. Baraff and A. Witkin. Large steps in cloth simulation. Proc. of ACM SIGGRAPH, pages 43--54, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258896</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{CAS+97} C. Curtis, S. Anderson, J. Seims, K. Fleischer, and D. Salesin. Computer-generated watercolor. Proc. of SIGGRAPH'97, pages 421--430, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{COR00} COREL. Painter. http://newgraphics.corel.com/products/painter6.html, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{CPE92} T. Cockshott, J. Patterson, and D. England. Modelling the texture of paint. Computer Graphics Forum (Eurographics'92 Proc.), 11(3):C217--C226, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>351638</ref_obj_id>
				<ref_obj_pid>351631</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{DSB99} M. Desbrun, P. Schroder, and A. Barr. Interactive animation of structured deformable objects. Proc. of Graphics Interface'99, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835797</ref_obj_id>
				<ref_obj_pid>832288</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{GEL00} A. Gregory, S. Ehmann, and M. C. Lin. inTouch: Interactive multiresolution modeling and 3D painting with a haptic interface. Proc. of IEEE VR Conference, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192233</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{HDD+94} H. Hoppe, T. DeRose, T. Duchamp, M. Halstead, H. Jin, J. McDonald, J. Schweitzer, and W. Stuetzle. Piecewise smooth surface reconstruction. In Proceedings of ACM SIGGRAPH, pages 295--302, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{hem00} RIGHT hemisphere. Deep paint. http://www.us.deeppaint.com/, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280951</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{Her98} A. Hertzmann. Painterly rendering with curved brush strokes of multiple sizes. Proc. of ACM SIGGRAPH'98, pages 453--460, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97903</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{HH90} P. Hanrahan and P. Haeberli. Direct WYSIWYG painting and texturing on 3D shapes. In Computer Graphics (SIGGRAPH '90 Proceedings), volume 24, pages 215--223, August 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835686</ref_obj_id>
				<ref_obj_pid>554230</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{JTK+99} D. Johnson, T. V. Thompson II, M. Kaplan, D. Nelson, and E. Cohen. Painting textures with a haptic interface. Proceedings of IEEE Virtual Reality Conference, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258893</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{Lit97} P. Litwinowicz. Processing images and video for an impressionist effect. Proc. of SIGGRAPH'97, pages 407--414, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{May70} R. Mayer. The Artist's Handbook of Materials and Techniques. The Viking Press, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237288</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{Mei96} B. Meier. Painterly rendering for animation. In SIGGRAPH 96 Conference Proceedings, pages 477--484. August 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{Pix00} Pixologic. Z-brush. http://pixologic.com, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[{Smi78} Alvy Ray Smith. Paint. TM 7, NYIT Computer Graphics Lab, July 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312110</ref_obj_id>
				<ref_obj_pid>311625</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[{SN99} S. Saito and M. Nakajima. 3D physically based brush model for painting. SIGGRAPH99 Conference Abstracts and Applications, page 226, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15911</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[{Str86} S. Strassmann. Hairy brushes. Computer Graphics (SIGGRAPH'86 Proc.), 20:225--232, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[{WB97} A. Witkin and D. Baraff. Physically Based Modeling: Principles and Practice. ACM Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[{W100} H. Wong and H. Ip. Virtual brush: A model-based synthesis of chinese calligraphy. Computers & Graphics, 24, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198619</article_id>
		<sort_key>188</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[ArtNova]]></title>
		<subtitle><![CDATA[touch-enabled 3D model design]]></subtitle>
		<page_from>188</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198619</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198619</url>
		<abstract>
			<par><![CDATA[We present a system, <i>ArtNova</i>, for 3D model design with a haptic interface. <i>ArtNova</i> offers the novel capability of interactively applying textures onto 3D surfaces directly by brush strokes, with the orientation of the texture determined by the stroke. Building upon the framework of inTouch [GEL00], it further provides an intuitive physically-based force response when deforming a model. This system also uses a user-centric viewing technique that seamlessly integrates the haptic and visual presentation, by taking into account the user's haptic manipulation in dynamically determining the new viewpoint locations. Our algorithm permits automatic placement of the user viewpoint to navigate about the object. <i>ArtNova</i> has been tested by several users and they were able to start modeling and painting with just a few minutes of training. Preliminary user feedback indicates promising potential for 3D texture painting and modeling.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[3D painting]]></kw>
			<kw><![CDATA[haptics]]></kw>
			<kw><![CDATA[modeling]]></kw>
			<kw><![CDATA[textures]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P334962</person_id>
				<author_profile_id><![CDATA[81100335977]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Foskey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P362253</person_id>
				<author_profile_id><![CDATA[81100035394]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Miguel]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Otaduy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42050475</person_id>
				<author_profile_id><![CDATA[81452602436]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>199429</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{ABL95} Maneesh Agrawala, Andrew C. Beers, and Marc Levoy. 3D painting on scanned surfaces. In Pat Hanrahan and Jim Winget, editors, 1995 Symposium on Interactive 3D Graphics, pages 145--150. ACM SIGGRAPH, April 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>245054</ref_obj_id>
				<ref_obj_pid>244979</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{AS96} R. S. Avila and L. M. Sobierajski. A haptic interaction method for volume visualization. Proceedings of Visualization'96, pages 197--204, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122744</ref_obj_id>
				<ref_obj_pid>122718</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{BVIG91} Chakib Bennis, Jean-Marc V&#233;zien, G&#233;rard Igl&#233;sias, and Andr&#233; Gagalowicz. Piecewise surface flattening for non-distorted texture mapping. In Thomas W. Sederberg, editor, Computer Graphics (SIGGRAPH '91 Proceedings), volume 25, pages 237--246, July 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378497</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{CMS88} Michael Chen, S. Joy Mountford, and Abigail Sellen. A study in interactive 3-D rotation using 2-D control devices. In John Dill, editor, Computer Graphics (SIGGRAPH '88 Proceedings), volume 22, pages 121--129, August 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{COR00} COREL. Painter. http://newgraphics.corel.com/products/painter6.html, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280826</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{DKT98} T. DeRose, M. Kass, and T. Troung. Subdivision surfaces in character animation. Proc. of ACM SIGGRAPH, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378512</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{FB88} D. Forsey and R H. Bartels. Heirarchical B-spline refinement. In Proc. of ACM Siggraph, pages 205--212, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835797</ref_obj_id>
				<ref_obj_pid>832288</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{GEL00} A. Gregory, S. Ehmann, and M. C. Lin. inTouch: Interactive multiresolution modeling and 3d painting with a haptic interface. Proc. of IEEE VR Conference, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122747</ref_obj_id>
				<ref_obj_pid>122718</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{GH91} Tinsley A. Galyean and John F. Hughes. Sculpting: An interactive volumetric modeling technique. In Thomas W. Seder-berg, editor, Computer Graphics (SIGGRAPH '91 Proceedings), volume 25, pages 267--274, July 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{Gib95} S. Gibson. Beyond volume rendering: Visualization, haptic exploration, and physical modeling of element-based objects. In Proc. Eurographics workshop on Visualization in Scientific Computing, pages 10--24, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>338422</ref_obj_id>
				<ref_obj_pid>338401</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{GLGT00} A. Gregory, M. Lin, S. Gottschalk, and R. Taylor. Real-time collision detection for haptic interaction using a 3-dof force feedback device. Computational Geometry: Theory and Applications, Special Issue on Virtual Environments, 15(1-3):pp. 69--89, February 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134088</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{GW92} Michael Gleicher and Andrew Witkin. Through-the-lens camera control. In Edwin E. Catmull, editor, Computer Graphics (SIGGRAPH '92 Proceedings), volume 26, pages 331--340, July 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{HCT+97} J. Hollerbach, E. Cohen, W. Thompson, R. Freier, D. Johnson, A. Nahvi, D. Nelson, and T. Thompson II. Haptic interfacing for virtual prototyping of mechanical CAD designs. CDROM Proc. of ASME Design for Manufacturing Symposium, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192233</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{HDD+94} H. Hoppe, T. DeRose, T. Duchamp, M. Halstead, H. Jin, J. McDonald, J. Schweitzer, and W. Stuetzle. Piecewise smooth surface reconstruction. In Proceedings of ACM SIGGRAPH, pages 295--302, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{Hem00} Right Hemisphere. Deep paint. http://www.us.deeppaint.com/, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97903</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{HH90} Pat Hanrahan and Paul E. Haeberli. Direct WYSIWYG painting and texturing on 3D shapes. In Forest Baskett, editor, Computer Graphics (SIGGRAPH '90 Proceedings), volume 24, pages 215--223, August 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>364404</ref_obj_id>
				<ref_obj_pid>364338</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[{IC01} T. Igarashi and D. Cosgrove. Adaptive unwrapping for interactive texture painting. Proc. of ACM Symposium on Interactive 3D Graphics, pages 209--216, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835686</ref_obj_id>
				<ref_obj_pid>554230</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[{JTK+99} D. Johnson, T. V. Thompson II, M. Kaplan, D. Nelson, and E. Cohen. Painting textures with a haptic interface. Proceedings of IEEE Virtual Reality Conference, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304033</ref_obj_id>
				<ref_obj_pid>304012</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[{KS99} A. Khodakovsky and P. Schr&#246;der. Fine level feature editing for subdivision surfaces. Proceedings of ACM Symposium on Solid Modeling and Applications, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618528</ref_obj_id>
				<ref_obj_pid>616052</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[{Mas98} Thomas Massie. A tangible goal for 3D modeling. IEEE Computer Graphics and Applications, May/June, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>364395</ref_obj_id>
				<ref_obj_pid>364338</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[{MQW01} K. McDonnell, H. Qin, and R. Wlodarczyk. Virtual clay: A real-time sculpting system with haptic interface. Proc. of ACM Symposium on Interactive 3D Graphics, pages 179--190, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237284</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[{MRF+96} William Mark, Scott Randolph, Mark Finch, James Van Verth, and Russell M. Taylor II. Adding force feedback to graphics systems: Issues and solutions. In Holly Rushmeier, editor, SIGGRAPH 96 Conference Proceedings, Annual Conference Series, pages 447--452, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[{MS94} T. M. Massie and J. K. Salisbury. The phantom haptic interface: A device for probing virtual objects. Proc. of ASME Haptic Interfaces for Virtual Environment and Teleoperator Systems, 1:295--301, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166120</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[{MYV93} J&#233;rome Maillot, Hussein Yahia, and Anne Verroust. Interactive texture mapping. In James T. Kajiya, editor, Computer Graphics (SIGGRAPH '93 Proceedings), volume 27, pages 27--34, August 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>601719</ref_obj_id>
				<ref_obj_pid>601671</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[{OL01} M. Otaduy and M. Lin. User-centric viewpoint computation for haptic exploration and manipulation. Proc. of IEEE Visualization, 2001. To appear.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>147167</ref_obj_id>
				<ref_obj_pid>147156</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[{PBG92} C. Phillips, N. Badler, and J. Granieri. Automatic viewing control for 3D direct manipulation. Proc. of ACM Symposium on Interactive 3D Graphics, pages 71--74, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383264</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[{PF01} R. Perry and S. Friskin. Kizamu: A system for sculpting digital characters. Computer Graphics (ACM SIGGRAPH'01), 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>253303</ref_obj_id>
				<ref_obj_pid>253284</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[{PFC+97} J. Pierce, A. Forsberg, M. Conway, S. Hong, R. Zeleznik, and M. Mine. Image plane interaction techniques in 3D immersive environments. Proc. of ACM Symposium on Interactive 3D Graphics, pages 39--44, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344987</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[{PFH00} E. Praun, A. Finkelstein, and H. Hoppe. Lapped textures. Proc. of ACM SIGGRAPH, pages 465--470, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>208469</ref_obj_id>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[{PT97} L. A. Piegl and W. Tiller. The NURBS Book. Springer Verlag, 1997. 2nd Edition.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614331</ref_obj_id>
				<ref_obj_pid>614261</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[{QT96} Hong Qin and Demetri Terzopoulos. D-NURBS: A physics-Based framework for geometric design. IEEE Transactions on Visualization and Computer Graphics, 2(1):85--96, March 1996. ISSN 1077--2626.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304037</ref_obj_id>
				<ref_obj_pid>304012</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[{RE99} A. Raviv and G. Elber. Three dimensional freeform sculpting via zero sets of scalar trivariate functions. ACM Symposium on Solid Modeling and Applications, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>147201</ref_obj_id>
				<ref_obj_pid>147156</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[{RH92} Warren Robinett and Richard Holloway. Implementation of flying, scaling, and grabbing in virtual worlds. In David Zeltzer, editor, Computer Graphics (1992 Symposium on Interactive 3D Graphics), volume 25, pages 189--192, March 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258878</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[{RKK97} D. C. Ruspini, K. Kolarov, and O. Khatib. The haptic display of complex graphical environments. Proc. of ACM SIGGRAPH, pages 345--352, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[{SP86} Thomas W. Sederberg and Scott R. Parry. Free-form deformation of solid geometric models. In David C. Evans and Russell J. Athay, editors, Computer Graphics (SIGGRAPH '86 Proceedings), volume 20, pages 151--160, August 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[{ST99} SensAble Technologies Inc. freeform#8482; modeling system. http://www.sensable.com/freeform, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[{SZ98} P. Schr&#246;der and D. Zorin. Subdivision for modeling and animation. ACM SIGGRAPH Course Notes, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280942</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[{SZMS98} T. Sederberg, J. Zheng, M. Sabin, and D. Sewell. Non-uniform recursive subdivision surfaces. Computer Graphics (ACM SIGGRAPH'98), 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218473</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[{Tau95} Gabriel Taubin. A signal processing approach to fair surface design. In Robert Cook, editor, SIGGRAPH 95 Conference Proceedings, Annual Conference Series, pages 351--358. ACM SIGGRAPH, Addison Wesley, August 1995. held in Los Angeles, California, 06--11 August 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[{VRPN} Virtual Reality Peripheral Network. http://www.cs.unc.edu/research/nano/manual/vrpn.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[{Wer94} Josie Wernecke. The Inventor Mentor. Addison-Wesley, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91442</ref_obj_id>
				<ref_obj_pid>91385</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[{WO90} C. Ware and S. Osborne. Exploration and virtual camera control in virtual three dimensional environments. Proc. of ACM Symposium on Interactive 3D Graphics, pages 175--183, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300546</ref_obj_id>
				<ref_obj_pid>300523</ref_obj_pid>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[{ZF99} Robert Zeleznik and A. Forsberg. Unicam 2D gestural camera controls for 3D environments. Proc. of ACM Symposium on Interactive 3D Graphics, pages 169--173, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258863</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[{ZSS97} D. Zorin, P. Schr&#246;der, and W. Sweldens. Interactive multiresolution mesh editing. Computer Graphics (ACM SIG-GRAPH'97), 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198635</section_id>
		<sort_key>12</sort_key>
		<section_seq_no>12</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Introduction to SIGGRAPH and computer graphics]]></section_title>
		<section_page_from>12</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP39059923</person_id>
				<author_profile_id><![CDATA[81100645484]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mike]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bailey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198636</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Introduction to SIGGRAPH and computer graphics]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198636</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198636</url>
		<abstract>
			<par><![CDATA[The SIGGRAPH conference is an exciting event, but it is often an intimidating experience for first-time attendees. There are so many new terms, new concepts, and new products to try to understand. It is like standing in a room with 100 doors and having no idea which door to open because you have no idea what the label on each door actually means. This leaves new attendees baffled and frustrated about how to spend their time. This course is designed to ease newcomers into the SIGGRAPH conference experience by presenting the fundamental concepts and vocabulary at a level that can be readily understood. Far from being made up of dry facts, this course will also portray the fun and excitement that led most of us here in the first place. Attendees in the course will become well-prepared to understand, appreciate, enjoy, network, and learn from the rest of the SIGGRAPH experience.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39056350</person_id>
				<author_profile_id><![CDATA[81324487523]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mike]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bailey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Oregon State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[SIGGRAPH Online Bibliography Database: http://www.siggraph.org/publications/bibliography]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1214845</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[F. S. Hill, Computer Graphics Using OpenGL, Prentice Hall, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1051917</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Edward Angel, Interactive Computer Graphics: A Top-down Approach with OpenGL, Addison-Wesley, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>529420</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Alan Watt, 3D Computer Graphics, 3rd Edition, Addison-Wesley, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>515330</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Peter Shirley, Fundamentals of Computer Graphics, AK Peters, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>861562</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Donald Hearn and Polly Baker, Computer Graphics with OpenGL, Pearson/Prentice-Hall, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>261113</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Olin Lathrop, The Way Computer Graphics Works, John Wiley & Sons, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>533021</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Andrew Glassner, Graphics Gems, Academic Press, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[James Arvo, Graphics Gems 2, Academic Press, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[David Kirk, Graphics Gems 3, Academic Press, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Paul Heckbert, Graphics Gems 4, Academic Press, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Alan Paeth, Graphics Gems 5, Academic Press, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>286105</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Jim Blinn, A Trip Down the Graphics Pipeline, Morgan Kaufmann, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>286104</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Jim Blinn, Dirty Pixels, Morgan Kaufmann, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2213</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[David Rogers, Procedural Elements for Computer Graphics, McGraw-Hill, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[SIGGRAPH Conference Final program.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507109</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Eric Lengyel, Mathematics for 3D Game Programming and Computer Graphics, Charles River Media, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>320367</ref_obj_id>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Jean Gallier, Curves and Surfaces in Geometric Modeling, Morgan Kaufmann, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>119990</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Walter Taylor, The Geometry of Computer Graphics, Wadsworth & Brooks/Cole, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>151048</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Gerald Farin, Curves and Surfaces for Computer Aided Geometric Design, 3rd Edition, Academic Press, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280475</ref_obj_id>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Gerald Farin and Dianne Hansford, The Geometry Toolbox for Graphics and Modeling, AK Peters, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>580358</ref_obj_id>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Joe Warren and Henrik Weimer, Subdivision Methods for Geometric Design: A Constructive Approach, Morgan Kaufmann, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Barrett O'Neil, Elementary Differential Geometry, Academic Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>184684</ref_obj_id>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Joseph O'Rourke, Computational Geometry in C, Cambridge University Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Christopher Hoffman, Geometric & Solid Modeling, Morgan Kaufmann, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>4159</ref_obj_id>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Michael Mortenson, Geometric Modeling, John Wiley & Sons, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>578513</ref_obj_id>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[I. D. Faux and M. J. Pratt, Computational Geometry for Design and Manufacture, Ellis-Horwood, 1979.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>286071</ref_obj_id>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Eric Stollnitz, Tony DeRose, and David Salesin, Wavelets for Computer Graphics, Morgan-Kaufmann, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>140548</ref_obj_id>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Ronen Barzel, Physically-Based Modeling for Computer Graphics, Academic Press, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>575646</ref_obj_id>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[David Rogers and J. Alan Adams, Mathematical Elements for Computer Graphics, McGraw-Hill, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>130368</ref_obj_id>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[John Snyder, Generative Modeling for Computer Graphics and Computer Aided Design, Academic Press, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>993936</ref_obj_id>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Christopher Johnson and Charles Hansen, The Visualization Handbook, Elsevier Academic Press, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[David Thompson, Jeff Braun, and Ray Ford, OpenDX: Paths to Visualization, Visualization and Imagery Solutions, Inc., 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Chandrajit Bajaj, Data Visualization Techniques, John Wiley & Sons, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Min Chen, Arie Kaufman, and Roni Yagel, Volume Graphics, Springer-Verlag, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Will Schroeder, Ken Martin, and Bill Lorensen, The Visualization Toolkit, Prentice-Hall, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Greg Nielson, Hans Hagen, and Heinrich M&#252;ller, Scientific Visualization: Overviews, Methodologies, Techniques, IEEE Computer Society Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Lenny Lipton, The CrystalEyes Handbook, StereoGraphics Corporation, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>204534</ref_obj_id>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Brand Fortner, The Data Handbook: A Guide to Understanding the Organization and Visualization of Technical Data, Spyglass, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>573078</ref_obj_id>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[William Kaufmann and Larry Smarr, Supercomputing and the Transformation of Science, Scientific American Library, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>160983</ref_obj_id>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Robert Wolff and Larry Yaeger, Visualization of Natural Phenomena, Springer-Verlag, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>169238</ref_obj_id>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[David McAllister, Stereo Computer Graphics and Other True 3D Technologies, Princeton University Press, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>562139</ref_obj_id>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Peter Keller and Mary Keller, Visual Cues: Practical Data Visualization, IEEE Press, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>863149</ref_obj_id>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Maureen Stone, A Field Guide to Digital Color, AK Peters, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>63450</ref_obj_id>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Roy Hall, Illumination and Color in Computer Generated Imagery, Springer-Verlag, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[David Travis, Effective Color Displays, Academic Press, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>77787</ref_obj_id>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[L. G. Thorell and W. J. Smith, Using Computer Color Effectively, Prentice Hall, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>33404</ref_obj_id>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[Edward Tufte, The Visual Display of Quantitative Information, Graphics Press, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>78223</ref_obj_id>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[Edward Tufte, Envisioning Information, Graphics Press, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>50</ref_seq_no>
				<ref_text><![CDATA[Edward Tufte, Visual Explanations, Graphics Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>60571</ref_obj_id>
				<ref_seq_no>51</ref_seq_no>
				<ref_text><![CDATA[Howard Resnikoff, The Illusion of Reality, Springer-Verlag, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>527570</ref_obj_id>
				<ref_seq_no>52</ref_seq_no>
				<ref_text><![CDATA[Andrew Glassner, Principles of Digital Image Synthesis, Morgan Kaufmann, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>94788</ref_obj_id>
				<ref_seq_no>53</ref_seq_no>
				<ref_text><![CDATA[Andrew Glassner, An Introduction to Ray Tracing, Academic Press, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>519042</ref_obj_id>
				<ref_seq_no>54</ref_seq_no>
				<ref_text><![CDATA[Rosalee Wolfe, 3D Graphics: A Visual Approach, Oxford Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>55</ref_seq_no>
				<ref_text><![CDATA[Ken Joy et al, Image Synthesis, IEEE Computer Society Press, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299787</ref_obj_id>
				<ref_seq_no>56</ref_seq_no>
				<ref_text><![CDATA[Alan Watt and Fabio Policarpo, The Computer Image, Addison-Wesley, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>551861</ref_obj_id>
				<ref_seq_no>57</ref_seq_no>
				<ref_text><![CDATA[David Ebert et al, Texturing and Modeling, 2nd Edition, Academic Press, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>320164</ref_obj_id>
				<ref_seq_no>58</ref_seq_no>
				<ref_text><![CDATA[Ron Brinkman, The Art and Science of Digital Compositing, Morgan Kaufmann, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>316738</ref_obj_id>
				<ref_seq_no>59</ref_seq_no>
				<ref_text><![CDATA[John Miano, Compressed Image File Formats, Addison-Wesley, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>107217</ref_obj_id>
				<ref_seq_no>60</ref_seq_no>
				<ref_text><![CDATA[Alan Watt and Mark Watt, Advanced Animation and Rendering Techniques, Addison-Wesley, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>242521</ref_obj_id>
				<ref_seq_no>61</ref_seq_no>
				<ref_text><![CDATA[Nadia Magnenat Thalmann and Daniel Thalmann, Interactive Computer Animation, Prentice-Hall, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>62</ref_seq_no>
				<ref_text><![CDATA[Philip Hayward and Tana Wollen, Future Visions: New Technologies of the Screen, Indiana University Press, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>63</ref_seq_no>
				<ref_text><![CDATA[David Eberly, 3D Game Engine Design: A Practical Approach to Real-Time Computer Graphics, Morgan Kaufmann, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>64</ref_seq_no>
				<ref_text><![CDATA[Alan Watt and Fabio Policarpo, 3D Games: Real-time Rendering and Software Technology, Addison-Wesley, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507109</ref_obj_id>
				<ref_seq_no>65</ref_seq_no>
				<ref_text><![CDATA[Eric Lengyel, Mathematics for 3D Game Programming and Computer Graphics, Charles River Media, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1205650</ref_obj_id>
				<ref_seq_no>66</ref_seq_no>
				<ref_text><![CDATA[David Bourg, Physics for Game Developers, O'Reilly and Associates, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>380465</ref_obj_id>
				<ref_seq_no>67</ref_seq_no>
				<ref_text><![CDATA[Munlo Coutinho, Dynamic Simulations of Multibody Systems, Springer Verlag, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>572747</ref_obj_id>
				<ref_seq_no>68</ref_seq_no>
				<ref_text><![CDATA[Mark DeLoura, Game Programming Gems, Charles River Media, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>516343</ref_obj_id>
				<ref_seq_no>69</ref_seq_no>
				<ref_text><![CDATA[Mark DeLoura, Game Programming Gems 2, Charles River Media, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>550581</ref_obj_id>
				<ref_seq_no>70</ref_seq_no>
				<ref_text><![CDATA[Mark DeLoura, Game Programming Gems 3, Charles River Media, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>71</ref_seq_no>
				<ref_text><![CDATA[http://www.gamedev.net]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>72</ref_seq_no>
				<ref_text><![CDATA[http://www.gamasutra.net]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>208466</ref_obj_id>
				<ref_seq_no>73</ref_seq_no>
				<ref_text><![CDATA[John Vince, Virtual Reality Systems, Addison-Wesley, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>74</ref_seq_no>
				<ref_text><![CDATA[Gene Davis, Learning Java Bindings for OpenGL (JOGL), AuthorHouse, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>261190</ref_obj_id>
				<ref_seq_no>75</ref_seq_no>
				<ref_text><![CDATA[Andrea Ames, David Nadeau, John Moreland, The VRML 2.0 Sourcebook, John Wiley & Sons, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>579108</ref_obj_id>
				<ref_seq_no>76</ref_seq_no>
				<ref_text><![CDATA[Bruce Eckel, Thinking in Java, Prentice-Hall, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>77</ref_seq_no>
				<ref_text><![CDATA[David Flanagan, Java in a Nutshell, O'Reilly & Associates, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>550065</ref_obj_id>
				<ref_seq_no>78</ref_seq_no>
				<ref_text><![CDATA[David Flanagan, Java Examples in a Nutshell, O'Reilly & Associates, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>556698</ref_obj_id>
				<ref_seq_no>79</ref_seq_no>
				<ref_text><![CDATA[Henry Sowizral, Kevin Rushforth, and Michael Deering, The Java 3D API Specification, Addison-Wesley, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>560434</ref_obj_id>
				<ref_seq_no>80</ref_seq_no>
				<ref_text><![CDATA[Rasmus Lerdorf and Kevin Tatroe, Programming PHP, O'Reilly, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1202387</ref_obj_id>
				<ref_seq_no>81</ref_seq_no>
				<ref_text><![CDATA[Yukihiro Matsumoto, Ruby In A Nutshell, O'Reilly, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>82</ref_seq_no>
				<ref_text><![CDATA[Steve Upstill, The RenderMan Companion, Addison-Wesley, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>555371</ref_obj_id>
				<ref_seq_no>83</ref_seq_no>
				<ref_text><![CDATA[Tony Apodaca and Larry Gritz, Advanced RenderMan: Creating CGI for Motion Pictures, Morgan Kaufmann, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>984281</ref_obj_id>
				<ref_seq_no>84</ref_seq_no>
				<ref_text><![CDATA[Randi Rost, OpenGL Shading Language, Addison-Wesley, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>85</ref_seq_no>
				<ref_text><![CDATA[Randima Fernando, GPU Gems, NVIDIA, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>86</ref_seq_no>
				<ref_text><![CDATA[Matt Pharr, Randima Fernando, GPU Gems 2, NVIDIA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>87</ref_seq_no>
				<ref_text><![CDATA[OpenGL 1.2 Reference Manual, Addison-Wesley, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>88</ref_seq_no>
				<ref_text><![CDATA[OpenGL 1.2 Programming Guide, Addison-Wesley, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>516514</ref_obj_id>
				<ref_seq_no>89</ref_seq_no>
				<ref_text><![CDATA[Edward Angel, OpenGL: A Primer, Addison-Wesley, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>318952</ref_obj_id>
				<ref_seq_no>90</ref_seq_no>
				<ref_text><![CDATA[Andrew Glassner, Recreational Computer Graphics, Morgan Kaufmann, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>521041</ref_obj_id>
				<ref_seq_no>91</ref_seq_no>
				<ref_text><![CDATA[Anne Spalter, The Computer in the Visual Arts, Addison-Wesley, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>92</ref_seq_no>
				<ref_text><![CDATA[Jef Raskin, The Humane Interface, Addison-Wesley, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>93</ref_seq_no>
				<ref_text><![CDATA[Ben Shneiderman, Designing the User Interface, Addison-Wesley, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>94</ref_seq_no>
				<ref_text><![CDATA[Clark Dodsworth, Digital Illusion, Addison-Wesley, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>95</ref_seq_no>
				<ref_text><![CDATA[Isaac Victor Kerlow, The Art of 3-D: Computer Animation and Imaging, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>96</ref_seq_no>
				<ref_text><![CDATA[Isaac Victor Kerlow and Judson Rosebush, Computer Graphics for Designers and Artists, Van Nostrand Reinhold, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>581837</ref_obj_id>
				<ref_seq_no>97</ref_seq_no>
				<ref_text><![CDATA[Mehmed Kantardzic, Data Mining: Concepts, Models, Methods, and Algorithms, Wiley, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>98</ref_seq_no>
				<ref_text><![CDATA[William Press, Saul Teukolsky, William Vetterling, and Brian Flannery, Numerical Recipes in C, Second Edition, Cambridge University Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>99</ref_seq_no>
				<ref_text><![CDATA[James Skakoon and W. J. King, The Unwritten Laws of Engineering, ASME Press, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198637</section_id>
		<sort_key>13</sort_key>
		<section_seq_no>13</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Modern techniques for implicit modeling]]></section_title>
		<section_page_from>13</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>P133156</person_id>
				<author_profile_id><![CDATA[81100311781]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[O'Brien]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>P279429</person_id>
				<author_profile_id><![CDATA[81100009681]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Terry]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yoo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198638</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Modern techniques for implicit modeling]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198638</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198638</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P133156</person_id>
				<author_profile_id><![CDATA[81100311781]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[O'Brien]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California Berkeley]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P279429</person_id>
				<author_profile_id><![CDATA[81100009681]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Terry]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yoo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Library of Medicine, NIH]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198639</article_id>
		<sort_key>13</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Shape transformation using variational implicit functions]]></title>
		<page_from>13</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198639</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198639</url>
		<abstract>
			<par><![CDATA[Traditionally, shape transformation using implicit functions is performed in two distinct steps: 1) creating two implicit functions, and 2) interpolating between these two functions. We present a new shape transformation method that combines these two tasks into a single step. We create a transformation between two <i>N</i>-dimensional objects by casting this as a scattered data interpolation problem in <i>N</i> + 1 dimensions. For the case of 2D shapes, we place all of our data constraints within two planes, one for each shape. These planes are placed parallel to one another in 3D. Zero-valued constraints specify the locations of shape boundaries and positive-valued constraints are placed along the normal direction in towards the center of the shape. We then invoke a variational interpolation technique (the 3D generalization of thin-plate interpolation), and this yields a single implicit function in 3D. Intermediate shapes are simply the zero-valued contours of 2D slices through this 3D function. Shape transformation between 3D shapes can be performed similarly by solving a 4D interpolation problem. To our knowledge, ours is the first shape transformation method to unify the tasks of implicit function creation and interpolation. The transformations produced by this method appear smooth and natural, even between objects of differing topologies. If desired, one or more additional shapes may be introduced that influence the intermediate shapes in a sequence. Our method can also reconstruct surfaces from multiple slices that are not restricted to being parallel to one another.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[contour interpolation]]></kw>
			<kw><![CDATA[implicit surfaces]]></kw>
			<kw><![CDATA[shape morphing]]></kw>
			<kw><![CDATA[shape transformation]]></kw>
			<kw><![CDATA[thin-plate techniques]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP39043704</person_id>
				<author_profile_id><![CDATA[81100457973]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Greg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Turk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P133156</person_id>
				<author_profile_id><![CDATA[81100311781]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[O'Brien]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>245044</ref_obj_id>
				<ref_obj_pid>244979</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Barequet, Gill, Daniel Shapiro and Ayellet Tal, "History Consideration in Reconstructing Polyhedral Surfaces from Parallel Slices," Proceedings of Visualization '96, San Francisco, California, Oct. 27 - Nov. 1, 1996, pp. 149--156.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808573</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barr, Alan H., "Global and Local Deformations of Solid Primitives," Computer Graphics, Vol. 18, No. 3 (SIGGRAPH 84), pp. 21--30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134003</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Beier, Thaddeus and Shawn Neely, "Feature-Based Image Metamorphosis," Computer Graphics, Vol. 26, No. 2 (SIGGRAPH 92), July 1992, pp. 35--42.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>180923</ref_obj_id>
				<ref_obj_pid>180895</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal, Jules, "An Implicit Surface Polygonizer," in Graphics Gems IV, edited by Paul S. Heckbert, Academic Press, 1994, pp. 324--349.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>66134</ref_obj_id>
				<ref_obj_pid>66131</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bookstein, Fred L., "Principal Warps: Thin Plate Splines and the Decomposition of Deformations," IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 11, No. 6, June 1989, pp. 567--585.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122746</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Celniker, George and Dave Gossard, "Deformable Curve and Surface Finite-Elements for Free-Form Shape Design," Computer Graphics, Vol. 25, No. 4 (SIGGRAPH 91), July 1991, pp. 257--266.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>274366</ref_obj_id>
				<ref_obj_pid>274363</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cohen-Or, Daniel, David Levin and Amira Solomovici, "Three Dimensional Distance Field Metamorphosis," ACM Transactions on Graphics, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Duchon, Jean, "Splines Minimizing Rotation-Invariant Semi-Norms in Sobolev Spaces," in Constructive Theory of Functions of Several Variables, Lecture Notes in Mathematics, edited by A. Dolb and B. Eckmann, Springer-Verlag, 1977, pp. 85--100.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Duncan, Jody, "A Once and Future War," Cinefex, No. 47 (entire issue devoted to the film Terminator 2), August 1991, pp. 4--59.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>359846</ref_obj_id>
				<ref_obj_pid>359842</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H., Z. M. Kedem and S. P. Uselton, "Optimal Surface Reconstruction from Planar Contours," Communications of the ACM, Vol. 20, No. 10, October 1977, pp. 693--702.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Golub, Gene H. and Charles F. Ban Loan, Matrix Computations, John Hopkins University Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>791540</ref_obj_id>
				<ref_obj_pid>521641</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Gregory, Arthur, Andrei State, Ming C. Lin, Dinesh Manocha, Mark A. Livingston, "Feature-based Surface Decomposition for Correspondence and Morphing between Polyhedra", Proceedings of Computer Animation, Philadelphia, PA., 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>951107</ref_obj_id>
				<ref_obj_pid>951087</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[He, Taosong, Sidney Wang and Arie Kaufman, "Wavelet- Based Volume Morphing," Proceedings of Visualization '94, Washington, D. C., edited by Daniel Bergeron and Arie Kaufman, October 17-21, 1994, pp. 85--92.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617752</ref_obj_id>
				<ref_obj_pid>616023</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Herman, Gabor T., Jingsheng Zheng and Carolyn A. Bucholtz, "Shape-Based Interpolation," IEEE Computer Graphics and Applications, Vol. 12, No. 3 (May 1992), pp. 69--79.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134004</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Hugues, John F., "Scheduled Fourier Volume Morphing," Computer Graphics, Vol. 26, No. 2 (SIGGRAPH 92), July 1992, pp. 43--46.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Kaul, Anil and Jarek Rossignac, "Solid- Interpolating Deformations: Construction and animation of PIPs," Proceedings of Eurographics '91, Vienna, Austria, 2-6 Sept. 1991, pp. 493--505.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134007</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Kent, James R., Wayne E. Carlson and Richard E. Parent, "Shape Transformation for Polyhedral Objects," Computer Graphics, Vol. 26, No. 2 (SIGGRAPH 92), July 1992, pp. 47--54.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218502</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Lerios, Apostolos, Chase Garfinkle and Marc Levoy, "Feature-Based Volume Metamorphosis," Computer Graphics Proceedings, Annual Conference Series (SIGGRAPH 95), pp. 449--456.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Levin, David, "Multidimensional Reconstruction by Set-valued Approximation," IMA J. Numerical Analysis, Vol. 6, 1986, pp. 173--184.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192270</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Litwinowicz, Peter and Lance Williams, "Animating Images with Drawings," Computer Graphics Proceedings, Annual Conference Series (SIGGRAPH 94), pp. 409--412.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Lorenson, William and Harvey E. Cline, "Marching Cubes: A High Resolution 3-D Surface Construction Algorithm," Computer Graphics, Vol. 21, No. 4 (SIGGRAPH 87), July 1987, pp. 163--169.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Meyers, David and Shelley Skinner, "Surfaces From Contours: The Correspondence and Branching Problems," Proceedings of Graphics Interface '91, Calgary, Alberta, 3-7 June 1991, pp. 246--254.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617722</ref_obj_id>
				<ref_obj_pid>616021</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Payne, Bradley A. and Arthur W. Toga, "Distance Field Manipulation of Surface Models," IEEE Computer Graphics and Applications, Vol. 12, No. 1, January 1992, pp. 65--71.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Rossignac, Jarek and Anil Kaul, "AGRELs and BIPs: Metamorphosis as a Bezier Curve in the Space of Polyhedra," Proceedings of Eurographics '94, Oslo, Norway, Sept. 12-16, 1994, pp. 179--184.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134001</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Sederberg, Thomas W. and Eugene Greenwood, "A Physically Based Approach to 2-D Shape Blending," Computer Graphics, Vol. 26, No. 2 (SIGGRAPH 92), July 1992, pp. 25--34.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Sederberg, Thomas W. and Scott R. Parry, "Free-Form Deformations of Solid Geometric Models," Computer Graphics, Vol. 20, No. 4 (SIGGRAPH 86), pp. 151--160.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Turk, Greg and James F. O'Brien, "Variational Implicit Surfaces," Tech Report GIT-GVU-99-15, Georgia Institute of Technology, May 1999, 9 pages.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>528718</ref_obj_id>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Wolberg, George, Digital Image Warping, IEEE Computer Society Press, Los Alamitos, California 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198640</article_id>
		<sort_key>21</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Modelling with implicit surfaces that interpolate]]></title>
		<page_from>21</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198640</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198640</url>
		<abstract>
			<par><![CDATA[We introduce new techniques for modelling with <i>interpolating implicit surfaces</i>. This form of implicit surface was first used for problems of surface reconstruction and shape transformation, but the emphasis of our work is on model creation. These implicit surfaces are described by specifying locations in 3D through which the surface should pass, and also identifying locations that are interior or exterior to the surface. A 3D implicit function is created from these constraints using a variational scattered data interpolation approach, and the iso-surface of this function describes a surface. Like other implicit surface descriptions, these surfaces can be used for CSG and interference detection, may be interactively manipulated, are readily approximated by polygonal tilings, and are easy to ray trace. A key strength for model creation is that interpolating implicit surfaces allow the direct specification of both the location of points on the surface and the surface normals. These are two important manipulation techniques that are difficult to achieve using other implicit surface representations such as sums of spherical or ellipsoidal Gaussian functions ("blobbies"). We show that these properties make this form of implicit surface particularly attractive for interactive sculpting using the particle sampling technique introduced by Witkin and Heckbert. Our formulation also yields a simple method for converting a polygonal model to a smooth implicit model, as well as a new way to form blends between objects.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[function interpolation]]></kw>
			<kw><![CDATA[implicit surfaces]]></kw>
			<kw><![CDATA[modeling]]></kw>
			<kw><![CDATA[thin-plate techniques]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39043704</person_id>
				<author_profile_id><![CDATA[81100457973]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Greg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Turk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P133156</person_id>
				<author_profile_id><![CDATA[81100311781]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[O'Brien]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Berkeley]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bittar, E., Tsingos, N., and Gascuel, M.-P. 1995. Automatic reconstruction of unstructured 3D data: Combining a medial axis and implicit surfaces. Computer Graphics Forum (Proceedings of Eurographics '95) 14, 3, 457--468.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357310</ref_obj_id>
				<ref_obj_pid>357306</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F. 1982. A generalization of algebraic surface drawing. ACM Trans. Graph. 1, 3, 235--256.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>55285</ref_obj_id>
				<ref_obj_pid>55279</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal, J. 1988. Polygonization of implicit surfaces. Computer-Aided Geometric Design 5, 4, 341--355.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>180923</ref_obj_id>
				<ref_obj_pid>180895</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal, J. 1994. An implicit surface polygonizer. In Graphics Gems IV, P. S. Heckbert, Ed. Academic Press, Cambridge, 324--349.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>549676</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal, J. 1997. Introduction to Implicit Surfaces. Morgan Kaufmann Publishers, Inc., San Francisco, CA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383266</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Carr, J. C., Mitchell, T. J., Beatson, R. K., Cherrie, J. B., Fright, W. R., McCallum, B. C., and Evans, T. R. 2001. Reconstruction and representation of 3d objects with radial basis functions. Computer Graphics Proceedings, Annual Conference Series (SIGGRAPH 2001), 67--76.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122746</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Celniker, G. and Gossard, D. 1991. Deformable curve and surface finite-elements for free-form shape design. Computer Graphics (SIGGRAPH 91) 25, 4 (July), 257--266.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Duchon, J. 1977. Spline minimizing rotation-invariant semi-norms in Sobolev spaces. In Constructive Theory of Functions on Several Variables, Lecture Notes in Mathematics 571, W. Schempp and K. Zeller, Eds. Springer-Verlag, Berlin.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134027</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Duff, T. 1992. Interval arithmetic and recursive subdivision for implicit functions and constructive solid geometry. Computer Graphics (SIGGRAPH 92) 26, 2 (July), 154--168.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Dyn, N. 1987. Interpolation of scattered data by radial basis functions. In Topics in Multivariate Approximation, L. L. S. C. K. Chui and F. I. Utreras, Eds. Academic Press, Cambridge, 47--61.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>889072</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Girosi, F., Jones, M., and Poggio, T. 1993. Priors, stabilizers and basis functions: from regularization to radial, tensor and additive splines. Tech. rep., MIT Artificial Intelligence Laboratory. June. A.I. Memo No. 1430.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Grimson, W. E. L. 1983. Surface consistancy constraints in vision. Computer Vision, Graphics, and Image Processing 24, 1 (Oct.), 28--51.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hart, J. 1993. Ray tracing implicit surfaces. Siggraph 93 Course Notes: Design, Visualization and Animation of Implicit Surfaces, 1--16.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Hart, J. 1997. Sphere tracing: A geometric method for the antialiased ray tracing of implicit surfaces. The Visual Computer 12, 10, 527--545.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74364</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Kalra, D. and Barr, A. 1989. Guarenteed ray intersection with implicit surfaces. Computer Graphics (SIGGRAPH 89) 23, 4, 297--306.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Keren, D. and Gotsman, C. 1998. Tight fitting of convex polyhedral shapes. Int. J. Shape Modeling, 111--126.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Lorensen, W. and Cline, H. E. 1987. Marching cubes: A high resolution 3-D surface construction algorithm. Computer Graphics (SIGGRAPH 87) 21, 4 (July), 163--169.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122743</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Miraki, S. 1991. Volumetric shape description of range data using 'blobby model'. Computer Graphics (SIGGRAPH 91) 25, 4 (July), 227--235.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>884073</ref_obj_id>
				<ref_obj_pid>882486</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Morse, B., Yoo, T. S., Rheingans, P., Chen, D. T., and Subramanian, K. 2001. Interpolating implicit surfaces from scattered surface data using compactly supported radial basis functions. Shape Modelling International, 89--98.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Nishimura, H., Hirai, M., Kawai, T., Kawata, T., Shirkawa, I., and Omura, K. 1985. Object modeling by distribution function and a method of image generation. Trans. Inst. Elect. Commun. Eng. Japan J68-D, 4, 718--725.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218458</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Pedersen, H. 1995. Decorating implicit surfaces. Computer Graphics Proceedings, Annual Conference Series (SIGGRAPH 95), 291--300.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237268</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Pedersen, H. 1996. A framework for interactive texturing on curved surfaces. Computer Graphics Proceedings, Annual Conference Series (SIGGRAPH 96), 295--302.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Roth, S. 1982. Ray casting as a method for solid modeling. Computer Graphics and Image Processing 18, 2, 109--144.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Savchenko, V. V., Pasko, A. A., Okunev, O. G., and Kunni, T. L. 1995. Function representation of solids reconstructed from scattered surface points and contours. Computer Graphics Forum 14, 4 (Oct.), 181--188.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134024</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Snyder, J. 1992. Interval analysis for computer graphics. Computer Graphics (SIGGRAPH 92) 26, 2 (July), 121--130.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258868</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Stander, B. T. and Hart, J. C. 1997. Guaranteeing the topology of an implicit surface polygonization for interactive modeling. Computer Graphics Proceedings, Annual Conference Series (SIGGRAPH 97), 279--286.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>80963</ref_obj_id>
				<ref_obj_pid>80960</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Szeliski, R. 1990. Fast surface interpolation using hierarchical basis functions. IEEE Trans. Pattern Anal. Mach. Intell. 12, 6 (June), 513--528.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Taubin, G 1993. An improved algorithm for algebraic curve and surface fitting. In Fourth International Conference on Computer Vision (ICCV'93). IEEE, Berlin, Germany, 658--665.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>48905</ref_obj_id>
				<ref_obj_pid>48904</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D. 1988. The computation of visible-surface representations. IEEE Trans. Pattern Anal. Mach. Intell. 10, 4 (July), 417--438.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311580</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Turk, G. and O'Brien, J. 1999. Shape transformation using variational implicit functions. Computer Graphics Proceedings, Annual Conference Series (SIGGRAPH 1999), 335--342.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192216</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Welch, W. and Witkin, A. 1994. Free-form shape design using triangulated surfaces. Computer Graphics Proceedings, Annual Conference Series (SIGGRAPH 94), 247--256.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192227</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Witkin, A. P. and Heckbert, P. S. 1994. Using particles to sample and control implicit surfaces. Computer Graphics Proceedings, Annual Conference Series (SIGGRAPH 94), 269--278.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Wyvill, G., McPheeters, C., and Wyvill, B. 1986. Data structures for soft objects. The Visual Computer 2, 4, 227--234.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198641</article_id>
		<sort_key>40</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Some notes on radial basis functions and thin plate splines]]></title>
		<page_from>40</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198641</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198641</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40023956</person_id>
				<author_profile_id><![CDATA[81100123210]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Hart]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois Urbana-Champaign]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>383266</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Carr, J., Beatson, R., Cherrie, J., Mitchell, T., Fright, W., McCallum, B., and Evans, T. Reconstruction and representation of 3d objects with radial basis functions. Computer Graphics (Proc. SIGGRAPH '01) 35 (2001), 67--76.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>884073</ref_obj_id>
				<ref_obj_pid>882486</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Morse, B., Yoo, T., Rheingans, P., Chen, D., and Subramanian, K. Interpolating implicit surfaces from scattered surface data using compactly supported radial basis functions. In Proc. Shape Modeling International (2001), pp. 89--98.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882293</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Ohtake, Y., Belyaev, A., Alexa, M., Turk, G., and Seidel, H.-P. Multi-level partition of unity implicits. ACM Trans. on Graphics 22, 3 (2003), 463--470. Proc. SIGGRAPH.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>830307</ref_obj_id>
				<ref_obj_pid>829510</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Ohtake, Y., Belyaev, A., and Seidel, H.-P. A multi-scale approach to 3d scattered data interpolation with compactly supported basis functions. In SMI '03: Proceedings of the Shape Modeling International 2003 (2003), IEEE Computer Society, p. 292.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1007026</ref_obj_id>
				<ref_obj_pid>998687</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Ohtake, Y., Belyaev, A., and Seidel, H.-P. 3d scattered data approximation with adaptive compactly supported radial basis functions. In Proc. Shape Modeling Intl. (2004), pp. 31--39.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>571650</ref_obj_id>
				<ref_obj_pid>571647</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Turk, G., and O'Brien, J. F. Modelling with implicit surfaces that interpolate. ACM Trans. on Graphics 21, 4 (2002), 855--873.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198642</article_id>
		<sort_key>44</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Guaranteeing the topology of an implicit surface polygonization for interactive modeling]]></title>
		<page_from>44</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198642</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198642</url>
		<abstract>
			<par><![CDATA[Morse theory shows how the topology of an implicit surface is affected by its function's critical points, whereas catastrophe theory shows how these critical points behave as the function's parameters change. Interval analysis finds the critical points, and they can also be tracked efficiently during parameter changes. Changes in the function value at these critical points cause changes in the topology. Techniques for modifying the polygonization to accommodate such changes in topology are given. These techniques are robust enough to guarantee the topology of an implicit surface polygonization, and are efficient enough to maintain this guarantee during interactive modeling. The impact of this work is a topologically-guaranteed polygonization technique, and the ability to directly and accurately manipulate polygonized implicit surfaces in real time.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[catastrophe theory]]></kw>
			<kw><![CDATA[critical points]]></kw>
			<kw><![CDATA[implicit surfaces]]></kw>
			<kw><![CDATA[interactive modeling]]></kw>
			<kw><![CDATA[interval analysis]]></kw>
			<kw><![CDATA[morse theory]]></kw>
			<kw><![CDATA[particle systems]]></kw>
			<kw><![CDATA[polygonization]]></kw>
			<kw><![CDATA[topology]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Modeling packages</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10011007.10011006.10011066.10011070</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Development frameworks and environments->Application specific development environments</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011066.10011070</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Development frameworks and environments->Application specific development environments</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P28284</person_id>
				<author_profile_id><![CDATA[81100396959]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Barton]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[Stander]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Washington State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40023956</person_id>
				<author_profile_id><![CDATA[81100123210]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Hart]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Washington State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>357310</ref_obj_id>
				<ref_obj_pid>357306</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F. A generalization of algebraic surface drawing. ACM Transactions on Graphics 1, 3 (July 1982), 235--256.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>55285</ref_obj_id>
				<ref_obj_pid>55279</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal, J. Polygonization of implicit surfaces. Computer Aided Geometric Design 5, 4 (Nov. 1988), 341--355.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91427</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal, J., and Wyvill, B. Interactive techniques for implicit modeling. Computer Graphics 24, 2 (Mar. 1990), 109--116.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bottino, A., Nuij, W., and van Overveld, K. How to shrinkwrap through a critical point: an algorithm for the adaptive triangulation of iso-surfaces with arbitrary topology. In Proc. Implicit Surfaces '96 (Oct. 1996), pp. 53--72.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>94443</ref_obj_id>
				<ref_obj_pid>94424</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cheng, K.-P. Using plane vector fieldsto obtain all the intersection curves of two general surfaces. In Theory and Practice of Geometric Modeling (New York, 1989), Springer-Verlag.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>155323</ref_obj_id>
				<ref_obj_pid>155294</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[de Figueiredo, L. H., de Miranda Gomes, J., Terzopoulos, D., and Velho, L. Physically-based methods for polygonization of implicit surfaces. In Proceedings of Graphics Interface '92 (May 1992), pp. 250--257.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>951115</ref_obj_id>
				<ref_obj_pid>951087</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Delmarcelle, T., and Hesselink, L. The topology of symmetric, second-order tensor fields. Proceedings IEEE Visualization '94 (October 1994), 140--147.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Desbrun, M., Tsingos, N., and Gascuel, M.-P. Adaptive sampling of implicit surfaces for interactive modeling and animation. Implicit Surfaces '95 Proceedings (April 1995), 171--185.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218447</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Fleischer, K. W., Laidlaw, D. H., Currin, B. L., and Barr, A. H. Cellular texture generation. In Computer Graphics (Annual Conference Series) (Aug. 1995), pp. 239--248.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Hansen, E. A globally convergent interval method for computing and bounding real roots. BIT 18 (1978), 415--424.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Hansen, E. R., and Greenberg, R. I. An interval newton method. Applied Mathematics and Computation 12 (1983), 89--98.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hart, J. C. Morse theory for computer graphics. Tech. Rep. EECS-97-002, Washington State University, May 1997. Also in: SIGGRAPH '97 Course #14 Notes "New Frontiers in Modeling and Texturing".]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617655</ref_obj_id>
				<ref_obj_pid>616017</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Helman, J. L., and Hesselink, L. Visualizing vector field topology in fluid flows. IEEE Computer Graphics and Applications (May 1991), 36--46.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74364</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Kalra, D., and Barr, A. H. Guaranteed ray intersections with implicit surfaces. Computer Graphics 23, 3 (July 1989), 297--306.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617691</ref_obj_id>
				<ref_obj_pid>616019</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Kergosien, Y. L. Generic sign systems in medical imaging. IEEE Computer Graphics and Applications 11, 5 (Sep. 1991), 46--65.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Lorensen, W. E., and Cline, H. E. Marching cubes: A high resolution 3-d surface construction algorithm. Computer Graphics 21, 4 (July 1987), 163--170.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Mitchell, D. Three applications of interval analysis in computer graphics. In Frontiers of Rendering. SIGGRAPH '91 Course Notes, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134082</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Mitchell, D., and Hanrahan, P. Illumination from curved reflectors. Computer Graphics 26, 2 (July 1992), 283--291.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Moore, R. E. Interval Analysis. Prentice Hall, 1966.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617872</ref_obj_id>
				<ref_obj_pid>616030</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Ning, P., and Bloomenthal, J. An evaluation of implicit surface tilers. Computer Graphics and Applications 13, 6 (Nov. 1993), 33--41.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Nishimura, H., Hirai, M., Kawai, T., Kawata, T., Shirakawa, I., and Omura, K. Object modeling by distribution function and a method of image generation. In Proc. of Electronics Communication Conference '85 (1985), pp. 718--725. (Japanese).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801263</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Norton, A. Generation and rendering of geometric fractals in 3-D. Computer Graphics 16, 3 (1982), 61--67.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Ratschek, H., and Rokne, J. Computer Methods for the Range of Functions. John Wiley and Sons, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Rodrian, H.-C., and Moock, H. Dynamic triangulation of animated skeleton-based implicit surfaces. In Proc. Implicit Surfaces '96 (Oct. 1996), pp. 37--52.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Rosch, A., Ruhl, M., and Saupe, D. Interactive visualization of implicit surfaces with singularities. In Proc. Implicit Surfaces '96 (Oct. 1996), pp. 73--87.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134001</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Sederberg, T. W., and Greenwood, E. A physically based approach to 2-D shape blending. Computer Graphics 26, 2 (July 1992), 25--34.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617692</ref_obj_id>
				<ref_obj_pid>616019</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Shinagawa, Y, Kunii, T. L., and Kergosien, Y. L. Surface coding based on morse theory. IEEE Computer Graphics and Applications 11, 5 (Sep. 1991), 66--78.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>130368</ref_obj_id>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Snyder, J. Generative Modeling for Computer Graphics and CAD. Academic Press, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>926924</ref_obj_id>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Stander, B. T. Polygonizing Implicit Surfaces with Guaranteed Topology. PhD thesis, School of EECS, Washington State University, May 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Suffern, K., and Fackerell, E. Interval methods in computer graphics. In Proc. AUSGRAPH 90 (1990), pp. 35--44.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134037</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Szeliski, R., and Tonnesen, D. Surface modeling with oriented particle systems. In Computer Graphics (SIGGRAPH '92 Proceedings) (July 1992), E. E. Catmull, Ed., vol. 26, pp. 185--194.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Taylor, A. E. Advanced Calculus. Ginn and Company, 1955.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122749</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Turk, G. Generating textures for arbitrary surfaces using reaction-diffusion. In Computer Graphics (SIGGRAPH '91 Proceedings) (July 1991), T. W Sederberg, Ed., vol. 25, pp. 289--298.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[van Overveld, C., and Wyvill, B. Shrinkwrap: an adaptive algorithm for polygonizing and implicit surface. Tech. Rep. 93/514/19, University of Calgary, Dept. of Computer Science, March 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192227</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Witkin, A. P., and Heckbert, P. S. Using particles to sample and control implicit surfaces. In Computer Graphics (Annual Conference Series) (July 1994), pp. 269--278.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Wyvill, G., McPheeters, C., and Wyvill, B. Data structure for soft objects. Visual Computer 2, 4 (1986), 227--234.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198643</article_id>
		<sort_key>52</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Using the CW-complex to represent the topological structure of implicit surfaces and solids]]></title>
		<page_from>52</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198643</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198643</url>
		<abstract>
			<par><![CDATA[We investigate the CW-complex as a data structure for visualizing and controlling the topology of implicit surfaces. Previous methods for contolling the blending of implicit surfaces redefined the contribution of a metaball or unioned blended components. Morse theory provides new insight into the topology of the surface a function implicitly defines by studying the critical points of the function. These critical points are organized by a separatrix structure into a CW-complex. This CW-complex forms a topological skeleton of the object, indicating connectedness and the possibility of connectedness at various locations in the surface model. Definitions, algorithms and applications for the CW-complex of an implicit surface and the solid it bounds are given as a preliminary step toward direct control of the topology of an implicit surface.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40023956</person_id>
				<author_profile_id><![CDATA[81100123210]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Hart]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Washington State University, Pullman WA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>357310</ref_obj_id>
				<ref_obj_pid>357306</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{Blinn, 1982} Blinn, J. F. A generalization of algebraic surface drawing. ACM Transactions on Graphics 1(3), July 1982, pp. 235--256.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{Fomenko & Kunii, 1997} Fomenko, A. T. and Kunii, T. L. Topological Modeling for Visualization. Springer, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166157</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{Gascuel, 1993} Gascuel, M.-P. An implicit formulation for precise contact modeling between flexible solids. In Computer Graphics (Annual Conference Series.), Aug. 1993, pp. 313--320. Proc. SIGGRAPH 93.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{Goresky & MacPherson, 1988} Goresky, M. and MacPherson, R. Stratified Morse Theory. Springer, April 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{Guy & Wyvill, 1996} Guy, A. and Wyvill, B. Controlled blending for implicit surfaces using a graph. In Proc. Implicit Surfaces '95. Eurographics, 1996, pp. 107--112.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{Hart et al., 1998} Hart, J., Durr, A., and Harsch, D. Critical points of polynomial metaballs. In Proc. Workshop on Implicit Surfaces. Eurographics/SIGGRAPH, June 1998, pp. 69--76.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{Hart, 1998} Hart, J. C. Morse theory for implicit surface modeling. In Hege, H.-C. and Polthier, K., eds., Mathematical Visualization, pp. 257--268. Springer-Verlag, Heidelberg, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{Johnson et al., 1999} Johnson, C, Burnett, M., and Dunbar, W. Crystallographic topology and its applications. In Bourne, P. and Watenpaugh, K., eds., Crystallographics Computing 7: Proceedings from the Macromolecular Crystallography Computing School. University Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{Johnson, 1999} Johnson, C. K. Crystallographic topology 2: Overview and work in progress. In Alexiades, V. and Siopsis, G., eds., Trends in Mathematical Physics, pp. 275--306. AMS/International Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{Milnor, 1963} Milnor, J. Morse Theory, vol. 51 of Annals of Mathematics Studies. Princeton University Press, Princeton, NJ, 1963.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{Pasko et al., 1995} Pasko, A., Adzhiev, V., Sourin, A., and Savchenko, V. Function representation in geometric modeling: concepts, implementation and applications. The Visual Computer 11(8), 1995, pp. 429--446.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258868</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{Stander & Hart, 1997} Stander, B. T. and Hart, J. C. Guaranteeing the topology of an implicit surface polygonization for interactive modeling. In Computer Graphics (Annual Conference Series), Aug. 1997, pp. 279--286.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192227</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{Witkin & Heckbert, 1994} Witkin, A. P. and Heckbert, P. S. Using particles to sample and control implicit surfaces. In Computer Graphics (Annual Conference Series), July 1994, pp. 269--277.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198644</article_id>
		<sort_key>58</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Compactly supported RBFs in the management of implicit surfaces]]></title>
		<page_from>58</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198644</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198644</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P279429</person_id>
				<author_profile_id><![CDATA[81100009681]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Terry]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yoo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Library of Medicine, NIH]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198645</article_id>
		<sort_key>78</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Interpolating implicit surfaces from scattered surface data using compactly supported radial basis functions]]></title>
		<page_from>78</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198645</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198645</url>
		<abstract>
			<par><![CDATA[We describe algebraic methods for creating implicit surfaces using linear combinations of radial basis interpolants to form complex models from scattered surface points. Shapes with arbitrary topology are easily represented without the usual interpolation or aliasing errors arising from discrete sampling. These methods were first applied to implicit surfaces by Savchenko, et al. and later developed independently by Turk and O'Brien as a means of performing shape interpolation. Earlier approaches were limited as a modeling mechanism because of the order of the computational complexity involved. We explore and extend these implicit interpolating methods to make them suitable for systems of large numbers of scattered surface points by using compactly supported radial basis interpolants. The use of compactly supported elements generates a sparse solution space, reducing the computational complexity and making the technique practical for large models. The local nature of compactly supported radial basis functions permits the use of computational techniques and data structures such as k-d trees for spatial subdivision, promoting fast solvers and methods to divide and conquer many of the subproblems associated with these methods. Moreover, the representation of complex models permits the exploration of diverse surface geometry. This reduction in computational complexity enables the application of these methods to the study of shape properties of large complex shapes.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P34029</person_id>
				<author_profile_id><![CDATA[81100405205]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bryan]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Morse]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Brigham Young University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P279429</person_id>
				<author_profile_id><![CDATA[81100009681]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Terry]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yoo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Library of Medicine]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39044127</person_id>
				<author_profile_id><![CDATA[81100467637]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Penny]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rheingans]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Maryland Baltimore County]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24040885</person_id>
				<author_profile_id><![CDATA[81407593533]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Library of Medicine]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43123548</person_id>
				<author_profile_id><![CDATA[81341497237]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Subramanian]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Charlotte]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>361007</ref_obj_id>
				<ref_obj_pid>361002</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. L. Bentley. Multidimensional binary search trees used for associative searching. CACM, 18(9):509--517, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357310</ref_obj_id>
				<ref_obj_pid>357306</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. Blinn. A generalization of algebraic surface drawing. IEEE Transactions on Graphics, 1(3):235--246, 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>549676</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Bloomenthal, editor. Introduction to Implicit Surfaces. Morgan-Kaufman, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>79170</ref_obj_id>
				<ref_obj_pid>77626</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. J. Dongarra, J. D. Croz, S. Hammarling, and I. Duff. A set of level 3 Basic Linear Algebra Subprograms. ACM Transactions on Mathematical Software, 16(1):1--17, Mar. 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Duchon. Sur l'erruer d'interpolation des fonctions de plusieurs variables par les dm splines. R.A.I.R.O Analyse numerique, 12(4):325--334, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Hart and e. D. Ebert. New Fontiers in Modeling and Texturing. Siggraph 97 Course Notes, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[B. Kimia, A. Tannenbaum, and S. Zucker. On optimal control methods in computer vision and image processing. In B. t. H. Romeny, editor, Geometry Driven Diffusion in Computer Vision, pages 307--338 Kluwer, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>528688</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[T. Lindeberg. Scale-space theory in computer vision. Kluwer Academic Publishers, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>56815</ref_obj_id>
				<ref_obj_pid>56813</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S. Osher and J. A. Sethian. Fronts propogating with curvature dependent speed: Algorithms based on Hamilton-Jacobi formulation. J. Comput. Phys., 79:12--49, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[R. A. Saleh, K. A. Gallivan, M. Chang, I. N. Hajj, D. Smart, and T. N. Patrick. Parallel circuit simulation on supercomputers. Proceedings of the IEEE, 77(12):1915--1930, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[V. V. Savchenko, A. A. Pasko, O. G. Okunev, and T. L. Kunii. Function representation of solids reconstructed from scattered surface points and contours. Computer Graphics Forum, 14(4):181--188, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. A. Sethian. Level Set Methods: Evolving Interfaces in Geometry, Fluid Mechanics, Computer Vision, and Material Sciences. Cambridge University Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. Thirion. New feature points based on geometric invariants for 3d image registration. Technical Report INRIA-RR-1901, INRIA, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[G. Turk and J. F. O'Brien. Variational implicit surfaces. Technical Report GIT-GVU-99-15, Georgia Institute of Technology, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311580</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[G. Turk and J. F. O'Brien. Shape transformation using variational implicit surfaces. In Computer Graphics Proceedings, Annual Conference Series, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[H. Wendland. Piecewise polynomial, positive definite and compactly supported radial functions of minimal degree. AICM, 4:389--396, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[R. Whitaker and D. Breen. Level-set models for the deformation of solid objects. In The Third International Workshop on Implicit Surfaces, pages 19--35. Eurographics, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192227</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[A. Witkin and P. Heckbert. Using particles to sample and control implicit surfaces. In A. Glassner, editor, SIGGRAPH '94 Proceedings, Computer Graphics Proceedings, Annual Conference Series, pages 269--278. ACM SIGGRAPH, ACM Press, July 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[A. P. Witkin and J. M. Tenenbaum. On the role of structure in vision. In J. Beck, B. Hope, and A. Rosenfeld, editors, Human and Machine Vision, pages 481--543. Academic Press, New York, NY, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198646</article_id>
		<sort_key>88</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Implicit modeling with PDE-based techniques]]></title>
		<page_from>88</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198646</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198646</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39060225</person_id>
				<author_profile_id><![CDATA[81100306770]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Haixia]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Du]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Institute of Health]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198647</article_id>
		<sort_key>116</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[A shape design system using volumetric implicit PDEs]]></title>
		<page_from>116</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198647</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198647</url>
		<abstract>
			<par><![CDATA[Solid modeling based on partial differential equations (PDEs) can potentially unify both geometric constraints and functional requirements within a single design framework to model real-world objects via its explicit, direct integration with parametric geometry. In contrast, implicit functions indirectly define geometric objects as the level-set of underlying scalar fields. To maximize the modeling potential of PDE-based methodology, in this paper we tightly couple PDEs with volumetric implicit functions in order to achieve interactive, intuitive shape representation, manipulation, and deformation. In particular, the unified approach can reconstruct the PDE geometry of arbitrary topology from scattered data points or a set of sketch curves. We make use of elliptic PDEs for boundary value problems to define the volumetric implicit function. The proposed implicit PDE model has the capability to reconstruct a complete solid model from partial information and facilitates the direct manipulation of underlying volumetric datasets via sketch curves and iso-surface sculpting, deformation of arbitrary interior regions, as well as a set of CSG operations inside the working space. The prototype system that we have developed allows designers to interactively sketch the curve outlines of the object, define intensity values and gradient directions, and specify interpolatory points in the 3D working space. The governing implicit PDE treats these constraints as generalized boundary conditions to determine the unknown scalar intensity values over the entire working space. The implicit shape is reconstructed with specified intensity value accordingly and can be deformed using a set of sculpting toolkits. We use the finite-difference discretization and variational interpolating approach with the localized iterative solver for the numerical integration of our PDEs in order to accommodate the diversity of generalized boundary and additional constraints.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[geometric constraints]]></kw>
			<kw><![CDATA[implicit functions]]></kw>
			<kw><![CDATA[partial differential equation techniques]]></kw>
			<kw><![CDATA[scattered data fitting]]></kw>
			<kw><![CDATA[shape design]]></kw>
			<kw><![CDATA[volume graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39036953</person_id>
				<author_profile_id><![CDATA[81100306770]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Haixia]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Du]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[State University of New York at Stony Brook, Stony Brook, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39048158</person_id>
				<author_profile_id><![CDATA[81100550215]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Qin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[State University of New York at Stony Brook, Stony Brook, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>884154</ref_obj_id>
				<ref_obj_pid>882487</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B&#230;rentzen A, Christensen N. Volume sculpting using level-set method. In Shape Modeling International 2002, Banff, Alberta, Canada; 2002. p. 175--82.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344972</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bertalmio M, Sapiro G, Caselles V, Ballester C. Image inpainting. In SIGGRAPH 2000, New Orleans, USA; 2000. p. 417--24.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>549676</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal J, Bajaj C, Blinn J, Cani-Gascuel M-P, Rockwood A, Wyvill B, Wyvill G. Introduction to Implicit Surfaces. Los Altos, CA: Morgan Kaufmann; 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91427</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal J, Wyvill B. Interactive techniques for implicit modeling. Comput Graphics 1990;24(2):109--16.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>63723</ref_obj_id>
				<ref_obj_pid>63718</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bloor MIG, Wilson MJ. Generating blend surfaces using partial differential equations. Comput Aided Des 1989;21(3):165--71.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91781</ref_obj_id>
				<ref_obj_pid>91778</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Bloor MIG, Wilson MJ. Using partial differential equations to generate free-form surfaces. Comput Aided Des 1990;22(4):202--12.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>163312</ref_obj_id>
				<ref_obj_pid>163300</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Bloor MIG, Wilson MJ. Functionality in solids obtained from partial differential equations. Computing Suppl 1993;8:21--42.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614490</ref_obj_id>
				<ref_obj_pid>614282</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Breen D, Whitaker R. A level-set approach for the metamorphosis of solid models. IEEE Transact Vis Comput Graphics 2001;7(2):173--92.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383266</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Carr J, Beatson R, Cherrie J, Mitchell T, Fright W, McCallum B. Reconstruction and representation of 3D objects with radial basis functions. In SIGGRAPH 2000, Los Angeles, USA;2001. p. 67--76.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>274366</ref_obj_id>
				<ref_obj_pid>274363</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Cohen-Or D, Levin D. Three-dimensional distance field metamorphosis. ACM Transact Graphics 1998;17(2):116--41.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566581</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Cutler B, Dorsey J, McMillan L, M&#252;ller M, Jagnow R. A procedural approach to authoring solid models. In SIGGRAPH 2002, San Antonio, TX; 2002. 302--11.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Desbrun M, Cani-Gascuel M-P. Active implicit surfaces for animation. Graphics Interface 1998;143--50.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Desbrun M, Tsingos N, Gascuel M-P. Adaptive sampling of implicit surfaces for interactive modelling and animation. Comput Graphics Forum 1996;15(5):319--25.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Du H, Qin H. Direct manipulation and interactive sculpting of PDE surfaces. Comput Graphics Forum 2000;19(3):C261-70.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>826519</ref_obj_id>
				<ref_obj_pid>826029</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Du H, Qin H. Dynamic PDE surfaces with flexible and general constraints. In Pacific Graphics 2001, Hong Kong; 2000. p. 213--22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>883437</ref_obj_id>
				<ref_obj_pid>882473</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Du H, Qin H. Integrating physics-based modeling with PDE solids for geometric design. In Pacific graphics, Tokyo, Japan; 2001. p. 198--207.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Ebert DS, Musgrave FK, Prusinkiewicz P, Stam J, Tessendorf J. Simulating nature: from theory to practice. SIGGRAPH 2000 Course notes 25; 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Ferley E, Cani M, Gascuel J. Practical volumetric sculpting. Visual Comput 2000;16(8):469--80.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>241077</ref_obj_id>
				<ref_obj_pid>241020</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Foster N, Metaxas D. Realistic animation of liquids. In Proceedings of GI; 1996. p. 204--12.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258838</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Foster N, Metaxas D. Modeling the motion of hot, turbulent gas. In SIGGRAPH 1997, Los Angeles, CA, USA; 1997. p. 181--8.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344899</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Frisken S, Perry R, Rockwood A, Jones T. Adaptive sampled distance fields: a general representation of shape for computer graphics. In SIGGRAPH 2000, New Orleans, USA; 2000. p. 249--54.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134011</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Hoppe H, DeRose T, Duchamp T, McDonald J, Stuetzle W. Surface reconstruction from unorganized points. In SIGGRAPH 1992; 1992. p. 71--8.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>883452</ref_obj_id>
				<ref_obj_pid>882473</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Hua J, Qin H. Haptic sculpting of volumetric implicit functions. In Pacific Graphics 2001, Tokyo, Japan; 2001. p. 254--64.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>884150</ref_obj_id>
				<ref_obj_pid>882487</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Hua J, Qin H. Dynamic implicit solids with constraints for haptic sculpting. In Shape Modeling International 2001, Banff, Alberta, Canada; 2002. p. 119--28.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Lorensen W, Cline H. Marching cubes: a high resolution 3D surface construction algorithm. In SIGGRAPH 1987; 1987. p. 163--9.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>884073</ref_obj_id>
				<ref_obj_pid>882486</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Morse B, Yoo T, Rheingans P, Chen D, Subramanian K. Interpolating implicit surfaces from scattered surface data using compactly supported radial basis functions. In Shape Modeling International 2001. Genova, Italy; 2001. p. 89--98.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122743</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Muraki S. Volumetric shape description of range data using blobby model. Comput Graphics 1991;25(4):227--35.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566585</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Museth K, Breen D, Whitaker R, Barr A. Level set surface editing operators. In SIGGRAPH 2002, San Antonio, TX, USA; 2002. p. 330--8.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882293</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Ohtake Y, Belyaev A, Alexa M, Turk G, Seidel H-S. Multi-level partition of unity implicits. In SIGGRAPH 2003, San Diego, USA; 2003. p. 463--70.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383264</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Perry R, Frisken S. Kizamu: a system for sculpting digital characters. In SIGGRAPH 2001, Los Angeles, USA; 2001. p. 47--56.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Press WH, Teulolsky SA, Vetterling WT, Flannery BP. Numerical recipes in C. Cambridge University Press; 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304037</ref_obj_id>
				<ref_obj_pid>304012</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Raviv A, Elber G. Three dimensional freeform sculpting via zero sets of scalar trivariate functions. In Proceedings of 5th ACM Symposium on Solid Modeling and Applications, Ann Arbor, Michigan, United States; 1999. p. 246--257.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>718512</ref_obj_id>
				<ref_obj_pid>647260</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Sarti A, Tubaro S. Multiresolution implicit object modeling. In VMV 2001, Stuttgart, Germany; 2001. p. 93--100.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Savchenko VV, Pasko AA, Okunev OG, Kunii TL. Function representation of solids reconstructed from scattered surface points and contours. Comput Graphics Forum 1995;14(4):181--8.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>797432</ref_obj_id>
				<ref_obj_pid>795680</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Schneider R, Kobbelt L. Generating fair meshes with G1 boundary conditions. In Geometric Modeling and Processing Conference Proceedings; 2000. p. 251--61.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122745</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Sclaroff S, Pentland A. Generalized implicit functions for computer graphics. Comput Graphics 1991;25(4):247--50.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311548</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Stam J. Stable fluids. In SIGGRAPH 1999, Los Angeles, CA, USA; 1999. p. 121--7.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Strang G. Introduction to applied mathematics. Wellesley-Cambridge Press; 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>884077</ref_obj_id>
				<ref_obj_pid>882486</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Turk G, Dinh HQ, O'Brien J. Implicit surfaces that interpolate. In Shape Modeling International 2001, Genova, Italy; 2001. p. 62--71.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311580</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Turk G, O'Brien J. Shape transformation using variational implicit functions. In SIGGRAPH 1999, Los Angeles, CA, USA; 1999. p. 335--42.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>571650</ref_obj_id>
				<ref_obj_pid>571647</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Turk G, O'Brien J. Modeling with implicit surfaces that interpolate. ACM Transact Graphics 2002;21(4):855--73.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>318078</ref_obj_id>
				<ref_obj_pid>318009</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Ugail H, Bloor MIG, Wilson MJ. Techniques for interactive design using the PDE method. ACM Transact Graphics 1999;18(2):195--212.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Whitaker R, Breen D. Level-set models for the deformation of solid objects. In Conference of Implicit Surface 1998, Seattle, USA; 1998. p. 19--36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192227</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Witkin A, Heckbert P. Using particles to sample and control implicit surfaces. In SIGGRAPH 1994; 1994. p. 269--77.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>884099</ref_obj_id>
				<ref_obj_pid>882486</ref_obj_pid>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Zhang JJ, You L. Surface representation using second, fourth and mixed order partial differential equations. In Shape Modeling International 2001, Genova, Italy; 2001. p. 250--6.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835639</ref_obj_id>
				<ref_obj_pid>832286</ref_obj_pid>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Zhao HK, Osher S, Fedkiw R. Fast surface reconstruction using level set method. In IEEE Workshop on Variational and Level Set Methods (VLSM 01) Vancover, Canada; 2001. p. 194--202.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>364070</ref_obj_id>
				<ref_obj_pid>364058</ref_obj_pid>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Zhao HK, Osher S, Merriman B, Kang M. Implicit and non-parametric shape reconstruction from unorganized points using variational level set method. Comput Vision Image Understanding 2000;80(3):295--319.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198648</article_id>
		<sort_key>132</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Multi-level partitions of unity]]></title>
		<page_from>132</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198648</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198648</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40031318</person_id>
				<author_profile_id><![CDATA[81100235480]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Marc]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Alexa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198649</article_id>
		<sort_key>173</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Multi-level partition of unity implicits]]></title>
		<page_from>173</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198649</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198649</url>
		<abstract>
			<par><![CDATA[We present a new shape representation, the <i>multi-level partition of unity</i> implicit surface, that allows us to construct surface models from very large sets of points. There are three key ingredients to our approach: 1) piecewise quadratic functions that capture the local shape of the surface, 2) weighting functions (the partitions of unity) that blend together these local shape functions, and 3) an octree subdivision method that adapts to variations in the complexity of the local shape.Our approach gives us considerable flexibility in the choice of local shape functions, and in particular we can accurately represent sharp features such as edges and corners by selecting appropriate shape functions. An error-controlled subdivision leads to an adaptive approximation whose time and memory consumption depends on the required accuracy. Due to the separation of local approximation and local blending, the representation is not global and can be created and evaluated rapidly. Because our surfaces are described using implicit functions, operations such as shape blending, offsets, deformations and CSG are simple to perform.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[adaptive distance field approximation]]></kw>
			<kw><![CDATA[error-controlled subdivision]]></kw>
			<kw><![CDATA[implicit modeling]]></kw>
			<kw><![CDATA[partition of unity approximation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P382272</person_id>
				<author_profile_id><![CDATA[81100073752]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yutaka]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ohtake]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MPI Informatik]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39056388</person_id>
				<author_profile_id><![CDATA[81100139548]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alexander]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Belyaev]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MPI Informatik]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40025189</person_id>
				<author_profile_id><![CDATA[81100235480]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Marc]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Alexa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[TU Darmstadt]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39043704</person_id>
				<author_profile_id><![CDATA[81100457973]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Greg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Turk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Tech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P107233</person_id>
				<author_profile_id><![CDATA[81100315426]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Hans-Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Seidel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MPI Informatik]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>601673</ref_obj_id>
				<ref_obj_pid>601671</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Alexa, M., Behr, J., Cohen-Or, D., Fleishman, S., Levin, D., and Silva, C. T. 2001. Point set surfaces. In IEEE Visualization 2001, 21--28.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280947</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Amenta, N., Bern, M., and Kamvysselis, M. 1998. A new Voronoi-based surface reconstruction algorithm. In Proceedings of ACM SIGGRAPH 1998, 415--421.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Babu&#353;ka, I., and Melenk, J. M. 1997. The partition of unity method. International Journal of Numerical Methods in Engineering 40, 727--758.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>190490</ref_obj_id>
				<ref_obj_pid>190489</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Babu&#353;ka, Caloz, G., and Osborn, J. E. 1994. Special finite element methods for a class of second order elliptic problems with rough coefficients. SIAM J. Numerical Analysis 31, 4, 745--981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218424</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bajaj, C. L., Bernardini, F., and Xu, G. 1995. Automatic reconstruction of surfaces and scalar fields from 3D scans. In Proceedings of ACM SIGGRAPH 95, 109--118.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>587360</ref_obj_id>
				<ref_obj_pid>587162</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Beatson, R. K., Light, W. A., and Billings, S. 2000. Fast solution of the radial basis function interpolation equations: domain decomposition methods. SIAM J. Sci. Comput. 22, 5, 1717--1740.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Bernardini, F., Bajaj, C, Chen, J., and Schikore, D. 1999. Automatic reconstruction of 3D CAD models from digital scans. International Journal of Computational Geometry & Applications 9, 4, 327--369.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357310</ref_obj_id>
				<ref_obj_pid>357306</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F. 1982. A generalization of algebraic surface drawing. ACM Transactions on Graphics 1, 3 (July), 235--256.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>549676</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal, J., Bajaj, C, Blinn, J., Cani-Gascuel, M. P., Rockwood, A., Wyvill, B., and Wyvill, G. 1997. Introduction to Implicit Surfaces. Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>180923</ref_obj_id>
				<ref_obj_pid>180895</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal, J. 1994. An implicit surface polygonizer. In Graphics Gems IV. 324--349.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383266</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Carr, J. C, Beatson, R. K., Cherrie, J. B., Mitchell, T. J., Fright, W. R., McCallum, B. C., and Evans, T. R. 2001. Reconstruction and representation of 3D objects with radial basis functions. In Proceedings of ACM SIGGRAPH 2001, 67--76.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Curless, B. VripPack User's Guide, http://graphics.stanford.edu/software/vrip/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237269</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Curless, B., and Levoy, M. 1996. A volumetric method for building complex models from range images. In Proceedings of ACM SIGGRAPH 1996, 303--312.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Dinh, H. Q., Slabaugh, G., and Turk, G. 2001. Reconstructing surfaces using anisotropic basis functions. In International Conference on Computer Vision (ICCV) 2001, 606--613.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628833</ref_obj_id>
				<ref_obj_pid>628331</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Dinh, H. Q., Turk, G., and Slabaugh, G. 2002. Reconstructing surfaces by volumetric regularization. IEEE Trans. on Pattern Analysis and Machine Intelligence 24, 10 (October), 1358--1371.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>156635</ref_obj_id>
				<ref_obj_pid>174462</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Edelsbrunner, H., and M&#252;cke, E. P. 1994. Three-dimensional alpha shapes. ACM Transactions on Graphics 13, 1 (January), 43--72.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944023</ref_obj_id>
				<ref_obj_pid>944020</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Fleishman, S., Cohen-Or, D., Alexa, M., and Silva, C. T. 2003. Progressive point set surfaces. ACM Transactions on Graphics 22, 4 (October).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Franke, R., and Nielson, G. 1980. Smooth interpolation of large sets of scattered data. International Journal of Numerical Methods in Engineering 15, 1691--1704.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344899</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Frisken, S. F., Perry, R. N., Rockwood, A., and Jones, T. R. 2000. Adaptively sampled distance fields: A general representation of shape for computer graphics. In Proceedings of ACM SIGGRAPH 2000, 249--254.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>587244</ref_obj_id>
				<ref_obj_pid>587155</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Griebel, M., and Schweitzer, M. A. 2000. A Particle-Partition of Unity Method for the solution of Elliptic, Parabolic and Hyperbolic PDE. SIAM J. Sci. Comp. 22, 3, 853--890.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>587312</ref_obj_id>
				<ref_obj_pid>587159</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Griebel, M., and Schweitzer, M. A. 2002. A Particle-Partition of Unity Method - Part III: A Multilevel Solver. SIAM J. Sci. Comp. 24, 2, 377--409.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Hart, J. C. 1996. Sphere tracing: a geometric method for the antialiased ray tracing of implicit surfaces. The Visual Computer 12, 527--545.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134011</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Hoppe, H., DeRose, T., Duchamp, T., McDonald, J., and Stuetzle, W. 1992. Surface reconstruction from unorganized point. In Proceedings of ACM SIGGRAPH 1992, 71--78.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[HyperFun: F-rep Library, http://cis.k.hosei.ac.jp/F-rep/HF_lib.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Iske, A., and Levesley, J. 2002. Multilevel scattered data approximation by adaptive domain decomposition. Tech. rep., University of Leicester, April.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>570847</ref_obj_id>
				<ref_obj_pid>570828</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Iske, A. 2001. Hierarchical scattered data filtering for multilevel interpolation schemes. In Mathematical methods for curves and surfaces (Oslo, 2000). Vanderbilt Univ. Press, Nashville, TN, 211--221.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566586</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Ju, T., Losasso, F., Schaefer, S., and Warren, J. 2002. Dual contouring of hermite data. ACM Transactions on Graphics 21, 3 (July), 339--346. Proceedings of ACM SIGGRAPH 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383265</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Kobbelt, L. P., Botsch, M., Schwanecke, U., and Seidel, H.-P. 2001. Feature sensitive surface extraction from volume data. In Proceedings of ACM SIGGRAPH 2001, 57--66.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Kojekine, N., Hagiwara, I., and Savchenko, V. 2003. Software tools using CSRBFs for processing scattered data. Computers & Graphics 27, 2 (April).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344849</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Levoy, M., Pulli, K., Curless, B., Rusinkiewicz, S., Roller, D., Pereira, L., Ginzton, M., Anderson, S., Davis, J., Ginsberg, J., Shade, J., and Fulk, D. 2000. The Digital Michelangelo Project: 3D scanning of large statues. In Proceedings of ACM SIGGRAPH 2000, 131--144.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218090</ref_obj_id>
				<ref_obj_pid>218013</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Lim, C., Turkiyyah, G. M., Ganter, M. A., and Storti, D. W. 1995. Implicit reconstruction of solids from cloud point sets. In Proceedings of the third ACM symposium on Solid Modeling and Applications, ACM Press, 393--402.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Moore, D., and Warren, J. 1991. Approximation of dense scattered data using algebraic surfaces. In Proceedings of the 24th Hawaii International Conference on System Sciences, IEEE Computer Society Press, Kauai, Hawaii, 681--690.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>884073</ref_obj_id>
				<ref_obj_pid>882486</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Morse, B. S., Yoo, T. S., Rheingans, P., Chen, D. T., and Subramanian, K. R. 2001. Interpolating implicit surfaces from scattered surface data using compactly supported radial basis functions. In Shape Modeling International 2001, 89--98.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122743</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Muraki, S. 1991. Volumetric shape description of range data using "Blobby Model". Computer Graphics 25, 4 (July), 227--235. Proceedings of ACM SIGGRAPH 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566308</ref_obj_id>
				<ref_obj_pid>566282</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Ohtake, Y., and Belyaev, A. G. 2002. Dual/primal mesh optimization for polygonized implicit surfaces. In 7th ACM Symposium on Solid Modeling and Applications, 171--178.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>830307</ref_obj_id>
				<ref_obj_pid>829510</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Ohtake, Y., Belyaev, A. G., and Seidel, H.-P. 2003. A multi-scale approach to 3D scattered data interpolation with compactly supported basis functions. In Shape Modeling International 2003. Accepted.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Pasko, A., and Savchenko, V. 1994. Blending operations for the functionally based constructive geometry. In Set-theoretic Solid Modeling: Techniques and Applications, CSG 94 Conference Proceedings, Information Geometers, 151--161.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>45055</ref_obj_id>
				<ref_obj_pid>45054</ref_obj_pid>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Renka, R. J. 1988. Multivariate interpolation of large sets of scattered data. ACM Transactions on Mathematical Software 14, 2 (June), 139--148.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Ricci, A. 1973. A constructive geometry for computer graphics. The Computer Journal 16, 2 (May), 157--160.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Savchenko, V. V., Pasko, A. A., Okunev, O. G., and Kunii, T. L. 1995. Function representation of solids reconstructed from scattered surface points and contours. Computer Graphics Forum 14, 4, 181--188.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Schaback, R., and Wendland, H. 2000. Adaptive greedy techniques for approximate solution of large RBF systems. Numerical Algorithms 24, 239--254.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>123055</ref_obj_id>
				<ref_obj_pid>123050</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Taubin, G. 1991. Estimation of planar curves, surfaces and nonplanar space curves defined by implicit equations, with applications to edge and range image segmentation. IEEE Trans. on Pattern Analysis and Machine Intelligence 13, 11, 1115--1138.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192241</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Turk, G., and Levoy, M. 1994. Zippered polygon meshes from range images. In Proceedings of ACM SIGGRAPH 1994, 311--318.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>571650</ref_obj_id>
				<ref_obj_pid>571647</ref_obj_pid>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Turk, G., and O'Brien, J. 2002. Modelling with implicit surfaces that interpolate. ACM Transactions on Graphics 21, A (October), 855--873.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>133688</ref_obj_id>
				<ref_obj_pid>133687</ref_obj_pid>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Warren, J. 1992. Free-form blending: a technique for creating piecewise implicit surfaces. In Topics in Surface Modeling, H. Hagen, Ed. SIAM Press, Philadelphia, 473--483.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Wendland, H. 2002. Fast evaluation of radial basis functions: Methods based on partition of unity. In Approximation Theory X: Wavelets, Splines, and Applications, Vanderbilt University Press, Nashville, L. Schumaker and J. Stockier, Eds., 473--483.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Zhao, H., and Osher, S. 2002. Visualization, analysis and shape reconstruction of unorganized data sets. In Geometric Level Set Methods in Imaging, Vision and Graphics, Springer, S. Osher and N. Paragios, Eds.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198650</article_id>
		<sort_key>181</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[Interpolating and approximating implicit surfaces from polygon soup]]></title>
		<page_from>181</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198650</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198650</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP37026597</person_id>
				<author_profile_id><![CDATA[81451596212]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Berkeley]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P133156</person_id>
				<author_profile_id><![CDATA[81100311781]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[O'Brien]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Berkeley]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P147456</person_id>
				<author_profile_id><![CDATA[81100474718]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jonathan]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Shewchuk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Berkeley]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198651</article_id>
		<sort_key>204</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Interpolating and approximating implicit surfaces from polygon soup]]></title>
		<page_from>204</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198651</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198651</url>
		<abstract>
			<par><![CDATA[This paper describes a method for building interpolating or approximating implicit surfaces from polygonal data. The user can choose to generate a surface that exactly interpolates the polygons, or a surface that approximates the input by smoothing away features smaller than some user-specified size. The implicit functions are represented using a moving least-squares formulation with constraints integrated over the polygons. The paper also presents an improved method for enforcing normal constraints and an iterative procedure for ensuring that the implicit surface tightly encloses the input vertices.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[implicit surfaces]]></kw>
			<kw><![CDATA[physically based animation]]></kw>
			<kw><![CDATA[point-based surfaces]]></kw>
			<kw><![CDATA[polygon soup]]></kw>
			<kw><![CDATA[simulation envelopes]]></kw>
			<kw><![CDATA[surface reconstruction]]></kw>
			<kw><![CDATA[surface representation]]></kw>
			<kw><![CDATA[surface smoothing]]></kw>
			<kw><![CDATA[topological simplification]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.2</cat_node>
				<descriptor>Approximation of surfaces and contours</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010918</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Approximation algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP37026597</person_id>
				<author_profile_id><![CDATA[81451596212]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Berkeley]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P133156</person_id>
				<author_profile_id><![CDATA[81100311781]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[O'Brien]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Berkeley]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P147456</person_id>
				<author_profile_id><![CDATA[81100474718]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jonathan]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Shewchuk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Berkeley]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>601673</ref_obj_id>
				<ref_obj_pid>601671</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Alexa, M., Behr, J., Cohen-Or, D., Fleishman, S., Levin, D., and Silva, C. T. 2001. Point set surfaces. In IEEE Visualization 2001, 21--28.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614541</ref_obj_id>
				<ref_obj_pid>614289</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Alexa, M., Behr, J., Cohen-Or, D., Fleishman, S., Levin, D., and Silva, C. T. 2003. Computing and rendering point set surfaces. IEEE Transactions on Visualization and Computer Graphics 9, 1 (Jan.), 3--15.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Belytschko, T., Krongauz, Y., Organ, D., Fleming, M., and Krysl, P. 1996. Meshless methods: An overview and recent developments. Computer Methods in Applied Mechanics and Engineering 139, 3--47. Special issue on meshless methods.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bittar, E., Tsingos, N., and Gascuel, M.-P. 1995. Automatic reconstruction of unstructured 3d data: Combining a medial axis and implicit surfaces. Proceedings of Eurographics 95, 457--468.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>180923</ref_obj_id>
				<ref_obj_pid>180895</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal, J. 1994. An implicit surface polygonizer. In Graphics Gems IV. 324--349.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>549676</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal, J., Ed. 1997. Introduction to Implicit Surfaces. Morgan Kaufmann Publishers, Inc., San Francisco, California.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882372</ref_obj_id>
				<ref_obj_pid>882370</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Boissonnat, J. D., and Oudot, S. 2003. Provably good surface sampling and approximation. In Proceedings of the ACM SIGGRAPH Symposium on Geometry Processing, 9--18.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383266</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Carr, J. C., Beatson, R. K., Cherrie, J. B., Mitchell, T. J., Fright, W. R., McCallum, B. C., and Evans, T. R. 2001. Reconstruction and representation of 3d objects with radial basis functions. In Proceedings of ACM SIGGRAPH 2001, 67--76.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237220</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Cohen, J., Varshney, A., Manocha, D., Turk, C, Weber, H., Agarwal, P., Jr., F. P. B., and Wright, W. 1996. Simplification envelopes. In Proceedings of ACM SIGGRAPH 1996, 119--128.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>274366</ref_obj_id>
				<ref_obj_pid>274363</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Cohen-Or, D., Solomovici, A., and Levin, D. 1998. Three-dimensional distance field metamorphosis. ACM Transactions on Graphics 17, 2 (Apr.), 116--141.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311576</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Desbrun, M., Meyer, M., Schroder, P., and Barr, A. H. 1999. Implicit fairing of irregular meshes using diffusion and curvature flow. In Proceedings of ACM SIGGRAPH 1999, 317--324.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944023</ref_obj_id>
				<ref_obj_pid>944020</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Fleishman, S., Alexa, M., Cohen-Or, D., and Silva, C. T. 2003. Progressive point set surfaces. ACM Transactions on Graphics 22, 4 (Oct.), 97--1011.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882367</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Jones, T. R., Durand, F., and Desbrun, M. 2003. Non-iterative, feature-preserving mesh smoothing. ACM Transactions on Graphics 22, 3 (July), 943--949.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Keren, D., and Gotsman, C. 1998. Tight fitting of convex polyhedral shapes. International Journal of Shape Modeling, 111--126.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>884073</ref_obj_id>
				<ref_obj_pid>882486</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Morse, B., Yoo, T. S., Rheingans, P., Chen, D. T., and Subramanian, K. 2001. Interpolating implicit surfaces from scattered surface data using compactly supported radial basis functions. In Proceedings of Shape Modelling International, 89--98.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122743</ref_obj_id>
				<ref_obj_pid>122718</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Muraki, S. 1991. Volumetric shape description of range data using "blobby model". In Proceedings of ACM SIGGRAPH 1991, 227--235.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566585</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Museth, K., Breen, D. E., Whitaker, R. T., and Barr, A. H. 2002. Level set surface editing operators. ACM Transactions on Graphics 21, 3 (July), 330--338.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375281</ref_obj_id>
				<ref_obj_pid>375213</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Nooruddin, F. S., and Turk, G. 2000. Interior/exterior classification of polygonal models. In IEEE Visualization 2000, 415--422.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>776770</ref_obj_id>
				<ref_obj_pid>776751</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Nooruddin, F. S., and Turk, G. 2003. Simplification and repair of polygonal models using volumetric techniques. IEEE Transactions on Visualization and Computer Graphics 9, 2 (Apr.), 191--205.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882293</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Ohtake, Y., Belyaev, A., Alexa, M., Turk, G., and Seidel, H.-P. 2003. Multi-level partition of unity implicits. ACM Transactions on Graphics 22, 3 (July), 463--470.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>830307</ref_obj_id>
				<ref_obj_pid>829510</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Ohtake, Y., Belyaev, A., and Seidel, H.-P. 2003. A multi-scale approach to 3d scattered data interpolation with compactly supported basis functions. In Proceedings of Shape Modelling International, 292--300.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Savchenko, V. V., Pasko, A. A., Okunev, O. G., and Kunii, T. L. 1995. Function representation of solids reconstructed from scattered surface points and contours. Computer Graphics Forum 14, 4 (Oct.), 181--188.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218473</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Taubin, G. 1995. A signal processing approach to fair surface design. In Proceedings of ACM SIGGRAPH 1995, 351--358.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311580</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Turk, G., and O'Brien, J. F. 1999. Shape transformation using variational implicit functions. In Proceedings of ACM SIGGRAPH 1999, 335--342.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>571650</ref_obj_id>
				<ref_obj_pid>571647</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Turk, G., and O'Brien, J. F. 2002. Modelling with implicit surfaces that interpolate. ACM Transactions on Graphics 21, 4 (Oct.), 855--873.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614534</ref_obj_id>
				<ref_obj_pid>614288</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Yngve, G., and Turk, G. 2002. Robust creation of implicit surfaces from polygonal meshes. IEEE Transactions on Visualization and Computer Graphics 8, 4 (Oct.), 346--359.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835639</ref_obj_id>
				<ref_obj_pid>832286</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Zhao, H.-K., Osher, S., and Fedkiw, R. 2001. Fast surface reconstruction using the level set method. In IEEE Workshop on Variational and Level Set Methods, 194--202.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198652</article_id>
		<sort_key>213</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Provably good moving least squares]]></title>
		<page_from>213</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198652</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198652</url>
		<abstract>
			<par><![CDATA[We analyze a <i>moving least squares</i> algorithm for reconstructing a surface from point cloud data. Our algorithm defines an implicit function <i>I</i> whose zero set <i>U</i> is the reconstructed surface. We prove that <i>I</i> is a good approximation to the signed distance function of the sampled surface <i>F</i> and that <i>U</i> is geometrically close to and homeomorphic to <i>F</i>. Our proof requires sampling conditions similar to &#949;-sampling, used in Delaunay reconstruction algorithms.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P721560</person_id>
				<author_profile_id><![CDATA[81100419269]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ravikrishna]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kolluri]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Berkeley, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>882401</ref_obj_id>
				<ref_obj_pid>882370</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Adamson and M. Alexa, Approximating and Intersecting Surfaces from Points, in Proceedings of the Eurographics Symposium on Geometry Processing, Eurographics Association, 2003, pp. 230--239.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614541</ref_obj_id>
				<ref_obj_pid>614289</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M. Alexa, J. Behr, D. Cohen-Or, S. Fleishman, D. Levin, and C. T. Silva, Computing and Rendering Point Set Surfaces, IEEE Transactions on Visualization and Computer Graphics, 9 (2003), pp. 3--15.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[N. Amenta and M. Bern, Surface Reconstruction by Voronoi Filtering, Discrete & Computational Geometry, 22 (1999), pp. 481--504.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[N. Amenta, S. Choi, T. K. Dey, and N. Leekha, A Simple Algorithm for Homeomorphic Surface Reconstruction, International Journal of Computational Geometry and Applications, 12 (2002), pp. 125--141.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>376986</ref_obj_id>
				<ref_obj_pid>376957</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[N. Amenta, S. Choi, and R. Kolluri, The Power Crust, in Proceedings of the Sixth Symposium on Solid Modeling, Association for Computing Machinery, 2001, pp. 249--260.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015713</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[N. Amenta and Y. Kil, Defining Point-Set Surfaces, ACM Transactions on Graphics, 23 (2004), pp. 264--270.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>549676</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Bloomenthal, ed., Introduction to Implicit Surfaces, Morgan Kaufman, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>336208</ref_obj_id>
				<ref_obj_pid>336154</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J.-D. Boissonnat and F. Cazals, Smooth Surface Reconstruction via Natural Neighbour Interpolation of Distance Functions, in Proceedings of the Sixteenth Annual Symposium on Computational geometry, ACM, 2000, pp. 223--232.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2295345</ref_obj_id>
				<ref_obj_pid>2295319</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J.-D. Boissonnat and F. Cazals, Natural Neighbor Coordinates of Points on a Surface, Computational Geometry Theory and Applications, 19 (2001), pp. 155--173.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1007401</ref_obj_id>
				<ref_obj_pid>1007352</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J.-D. Boissonnat, D. Cohen-Steiner, and G. Vegter, Isotopic Implicit Surface Meshing, in Proceedings of the Thirty-Sixth Annual ACM Symposium on Theory of Computing, 2004, pp. 301--309.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882372</ref_obj_id>
				<ref_obj_pid>882370</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. D. Boissonnat and S. Oudot, Provably Good Surface Sampling and Approximation, in Proceedings of the Eurographics Symposium on Geometry Processing, Eurographics Association, 2003, pp. 9--18.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383266</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. C. Carr, R. K. Beatson, J. B. Cherrie, T. J. Mitchell, W. R. Fright, B. C. McCallum, and T. R. Evans, Reconstruction and Representation of 3D Objects with Radial Basis Functions, in Computer Graphics (SIGGRAPH 2001 Proceedings), Aug. 2001, pp. 67--76.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237269</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[B. Curless and M. Levoy, A Volumetric Method for Building Complex Models from Range Images, in Computer Graphics (SIGGRAPH '96 Proceedings), 1996, pp. 303--312.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>997867</ref_obj_id>
				<ref_obj_pid>997817</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[T. K. Dey and S. Goswami, Provable Surface Reconstruction from Noisy Samples, in Proceedings of the Twentieth Annual Symposium on Computational Geometry, Brooklyn, New York, June 2004, Association for Computing Machinery.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944023</ref_obj_id>
				<ref_obj_pid>944020</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[S. Fleishman, M. Alexa, D. Cohen-Or, and C. T. Silva, Progressive Point Set Surfaces, ACM Transactions on Computer Graphics, 22 (2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134011</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[H. Hoppe, T. DeRose, T. Duchamp, J. McDonald, and W. Stuetzle, Surface Reconstruction from Unorganized Points, in Computer Graphics (SIGGRAPH '92 Proceedings), 1992, pp. 71--78.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[D. Levin, Mesh-Independent Surface Interpolation, in Geometric Modeling for Scientific Visualization, G. Brunett, B. Hamann, K. Mueller, and L. Linsen, eds., Springer-Verlag, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344849</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[M. Levoy, K. Pulli, B. Curless, S. Rusinkiewicz, D. Roller, L. Pereira, M. Ginzton, S. Anderson, J. Davis, J. Ginsberg, J. Shade, and D. Fulk, The Digital Michelangelo Project: 3D Scanning of Large Statues, in Computer Graphics (SIGGRAPH 2000 Proceedings), 2000, pp. 131--144.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[W. E. Lorensen and H. E. Cline, Marching Cubes: A High Resolution 3D Surface Construction Algorithm, in Computer Graphics (SIGGRAPH '87 Proceedings), July 1987, pp. 163--170.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1057435</ref_obj_id>
				<ref_obj_pid>1057432</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[N. J. Mitra, N. Gelfand, H. Pottmann, and L. Guibas, Registration of Point Cloud Data from a Geometric Optimization Perspective, in Symposium on Geometry Processing, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[N. J. Mitra, A. Nguyen, and L. Guibas, Estimating Surface Normals in Noisy Point Cloud Data, International Journal of Computational Geometry and Applications, 14 (2004), pp. 261--276.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882293</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Y. Ohtake, A. Belyaev, M. Alexa, G. Turk, and H.-P. Seidel, Multi-Level Partition of Unity Implicits, ACM Transactions on Graphics, 22 (2003), pp. 463--470.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[S. Osher and R. Fedkiw, The Level Set Method and Dynamic Implicit Surfaces, Springer-Verlag, New York, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882319</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[M. Pauly, R. Keiser, L. P. Kobbelt, and M. Gross, Shape Modeling with Point-Sampled Geometry, ACM Trans. Graph., 22 (2003), pp. 641--650.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015816</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[C. Shen, J. F. O'Brien, and J. R. Shewchuk, Interpolating and Approximating Implicit Surfaces from Polygon Soup, ACM Transactions on Graphics, 23 (2004), pp. 896--904.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311580</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[G. Turk and J. O'Brien, Shape Transformation Using Variational Implicit Functions, in Computer Graphics (SIGGRAPH '99 Proceedings), 1999, pp. 335--342.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835639</ref_obj_id>
				<ref_obj_pid>832286</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[H.-K. Zhao, S. Osher, and R. Fedkiw, Fast Surface Reconstruction Using the Level Set Method, in First IEEE Workshop on Variational and Level Set Methods, 2001, pp. 194--202.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198653</article_id>
		<sort_key>223</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[Medical applications of implicit surfaces]]></title>
		<page_from>223</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198653</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198653</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P279429</person_id>
				<author_profile_id><![CDATA[81100009681]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Terry]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yoo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Library of Medicine, NIH]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198654</article_id>
		<sort_key>245</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Anatomic modeling from unstructured samples using variational implicit surfaces]]></title>
		<page_from>245</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198654</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198654</url>
		<abstract>
			<par><![CDATA[We describe the use of variational implicit surfaces (level sets of an embedded generating function modeled using radial basis interpolants) in anatomic modeling. This technique allows the practitioner to employ sparsely and unevenly sampled data to represent complex biological surfaces, including data acquired as a series of non-parallel image slices. The method inherently accommodates interpolation across irregular spans. In addition, shapes with arbitrary topology are easily represented without interpolation or aliasing errors arising from discrete sampling. To demonstrate the medical use of variational implicit surfaces, we present the reconstruction of the inner surfaces of blood vessels from a series of endovascular ultrasound images.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P279429</person_id>
				<author_profile_id><![CDATA[81100009681]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Terry]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yoo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Institutes of Health, Bethesda]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36027931</person_id>
				<author_profile_id><![CDATA[81100405205]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bryan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Morse]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Brigham Young University, Provo UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43136725</person_id>
				<author_profile_id><![CDATA[81341497237]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Subramanian]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Univ. of North Carolina Charlotte, Charlotte NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39044127</person_id>
				<author_profile_id><![CDATA[81100467637]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Penny]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rheingans]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Univ. Maryland Baltimore County, Baltimore MD]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43115183</person_id>
				<author_profile_id><![CDATA[81537286256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Ackerman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Institutes of Health, Bethesda, MD]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bookstein, F. L. 1991. Morphometric tools for landmark data. Cambridge University Press]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Duchon, J. 1977. Splines minimizing rotation--invariant semi-norms in Sobolev spaces, in Constructive theory of functions of several variables, Lecture Notes in Mathematics, edited by A. Dolb and B. Eckmann, Springer-Verlag, 1977, pp. 85--100.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>243837</ref_obj_id>
				<ref_obj_pid>243833</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Floater, M. S. and A. Iske. 1996. Multistep scattered data interpolation using compactly supported radial basis functions. J. Comp. Appl. Math. 73, pp 65--78.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>709482</ref_obj_id>
				<ref_obj_pid>646921</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Gibson, S. 1998. Constrained elastic surface nets: generating smooth surfaces from binary segmented data, in Proceedings of Medical Image Computing and Computer Assisted Interventions (MICCAI 1998) W. M. Wells, A. Colchester, and S. Delp, eds., Lecture Notes in Computer Science 1496, Springer-Verlag, pp. 888--898.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>288142</ref_obj_id>
				<ref_obj_pid>288126</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Gibson, S. 1998. Using distance maps for accurate surface representation in sampled volumes, in Proceedings of the 1998 Symposium on Volume Visualization, ACM SIGGRAPH, pp. 23--30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>532835</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kaufman, A. Volume visualization. IEEE Computer Society Press, Los Alamitos, CA, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Lorensen, W. and H. Cline. 1987. Marching Cubes: a high-resolution 3D surface construction algorithm. In Proc. SIGGRAPH 87, Computer Graphics, 21(4), pp. 163--169.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Morse, B., T. Yoo, P. Rheingans, D. Chen, and K. R. Subramanian. 2000. Complex Models Using Variational Implicit Surfaces. Submitted to Shape Modeling International 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[V. Spitzer, M. J. Ackerman, A. L. Scherzinger, and D. Whitlock. 1996. The Visible Human Male: A Technical Report. J. of the Am. Medical Informatics Assoc. 3(2) 118--130.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>80963</ref_obj_id>
				<ref_obj_pid>80960</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Szeliski, R. 1990. Fast surface interpolation using hierarchical basis functions. IEEE Transactions on Pattern Analysis and Machine Intelligence, 12(6):513--528, June 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Turk, G. and J. F. O'Brien. 1999. Variational implicit surfaces, Tech Report GIT-GVU-99-15, Georgia Institute of Technology, May 1999, 9 pages.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311580</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Turk, G. and J. F. O Brien. 1999. Shape transformation using variational implicit functions. Computer Graphics Proceedings, Annual Conference Series (SIGGRAPH 99), pp. 335--342.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Wendland, H. 1995. Piecewise polynomial positive definite and compactly supported radial basis functions of minimal degree. AICM 4 (1995), pp. 389--396.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>353893</ref_obj_id>
				<ref_obj_pid>353888</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Whitaker, R. 2000. Reducing Aliasing Artifacts in Iso-Surfaces of Binary Volumes, in Volume Visualization and Graphics Symposium 2000, ACM SIGGRAPH, pp. 23--32.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198655</article_id>
		<sort_key>252</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[Active contours using a constraint-based implicit representation]]></title>
		<page_from>252</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198655</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198655</url>
		<abstract>
			<par><![CDATA[We present a new constraint-based implicit active contour, which shares desirable properties of both parametric and implicit active contours. Like parametric approaches, their representation is compact and can be manipulated interactively. Like other implicit approaches, they can naturally adapt to non-simple topologies.Unlike implicit approaches using level-set methods, representation of the contour does not require a dense mesh. Instead, it is based on specified on-curve and off-curve constraints, which are interpolated using radial basis functions. These constraints are evolved according to specified forces drawn from the relevant literature of both parametric and implicit approaches.This new type of active contour is demonstrated through synthetic images, photographs, and medical images with both simple and non-simple topologies. For complex input, this approach produces results comparable to those of level set or parameterized finite-element active models, but with a compact analytic representation. As with other active contours they can also be used for tracking, especially for multiple objects that split or merge.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P34029</person_id>
				<author_profile_id><![CDATA[81100405205]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bryan]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Morse]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Brigham Young University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P731382</person_id>
				<author_profile_id><![CDATA[81547529156]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Weiming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Brigham Young University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P279429</person_id>
				<author_profile_id><![CDATA[81100009681]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Terry]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yoo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Library of Medicine]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P706559</person_id>
				<author_profile_id><![CDATA[81341497237]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Kalpathi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Subramanian]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of North Carolina at Charlotte]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>205143</ref_obj_id>
				<ref_obj_pid>205127</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[D. Adalsteinsson and J. Sethian. A fast level set method for propagating interfaces. J. Computational Physics, 118:269--277, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383266</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. C. Carr, T. J. Mitchell, R. K. Beatson, J. B. Cherrie, W. R. Fright, B. C. McCallum, and T. R. Evans. Reconstruction and representation of 3D objects with radial basis. In SIGGRAPH 2001 Proceedings, Annual Conference Series. ACM SIGGRAPH, ACM Press, August 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[V. Caselles, E Catt&#233;, B. Coll, and E Dibos. A geometric model for active contours in image processing. Numerische Mathematik, 66(1), 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>840137</ref_obj_id>
				<ref_obj_pid>839277</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[V. Caselles, R. Kimmel, and G. Sapiro. Geodesic active contours. In In Proc. Fifth International Conf. on Computer Vision (ICCV'95), pages 694--699, Los Alamitos, CA, June 1995. IEEE Computer Society Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>167522</ref_obj_id>
				<ref_obj_pid>167509</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[L. D. Cohen. On active contour models and balloons. CVGIP: Image Understanding, 56(2):242--263, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628833</ref_obj_id>
				<ref_obj_pid>628331</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[H. Dinh, G. Turk, and G. Slabaugh. Reconstructing surfaces by volumetric regularization using radial basis functions. IEEE Transactions on Pattern Analysis and Machine Intelligence, October 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[H. Q. Dinh, G. Turk, and G. Slabaugh. Reconstructing surfaces using anisotropic basis functions. In Proceedings Eighth International Conference on Computer Vision (ICCV 2001), 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>214721</ref_obj_id>
				<ref_obj_pid>214720</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Ivins and J. Porrill. Statistical snakes: Active region models. In Proceedings Fifth British Machine Vision Conference (BMVC'04), pages 377--386, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[M. Kass, A. Witkin, and D. Terzopoulos. Snakes: active contour models. International Journal of Computer Vision, 1(4):321--331, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>840023</ref_obj_id>
				<ref_obj_pid>839277</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[S. Kichenassamy, A. Kumar, P. Older, A. Tannenbaum, and A. Yezzi. Gradient flows and geometric active contour models. In In Proc. Fifth International Conf. on Computer Vision (ICCV'95), pages 810--815, Los Alamitos, CA, June 1995. IEEE Computer Society Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[W. Liu. Constraint-based implicit snakes using thin-plate spline radial basis functions. Master's thesis, Brigham Young University, April 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>200867</ref_obj_id>
				<ref_obj_pid>200862</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[R. Malladi, J. Sethian, and B. C. Vemuri. Shape modeling with front propogation: a level-set approach. IEEE Transactions on Pattern Analysis and Machine Intelligence, 17(2):158--175, Feb. 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>840040</ref_obj_id>
				<ref_obj_pid>839277</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[T. McInerney and D. Terzopoulos. Topologically adaptable snakes. In Proceedings Fifth International Conference on Computer Vision, pages 840--845. IEEE Computer Society Press, June 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[T. McInerney and D. Terzopoulos. Deformable models in medical image analysis: a survey. Medical Imaging Analysis, 1(2), 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[T. McInerney and D. Terzopoulos. Topologically adaptive deformable surfaces for medical image volume segmentation. IEEE Trans. Medical Imaging, 20:100--111, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[T. McInerney and D. Terzopoulos. T-snakes: Topology adaptive snakes. Medical Image Analysis, 4:73--91, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>884073</ref_obj_id>
				<ref_obj_pid>882486</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[B. S. Morse, T. S. Yoo, D. T. Chen, P. Rheingans, and K. R. Subramanian. Interpolating implicit surfaces from scattered surface data using compactly supported radial basis functions. In Proceedings Shape Modeling International, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[M. Mullan, R. Whitaker, and J. Hart. Procedural level sets. Presented at the NSF/DARPA CARGO meeting, May 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882293</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Y Ohtake, A. Belyaev, M. Alexa, G. Turk, and H.-P. Seidel. Multilevel partition of unity implicits. In Proceedings 2003 SIGGRAPH, Annual Conference Series. ACM SIGGRAPH, ACM Press, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[S. Osher and R. Fedkiw. Level-Set Methods and Dynamic Implicit Surfaces. Springer-Verlag New York, Inc., 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>861631</ref_obj_id>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[S. Osher and N. Paragios. Geometric Level Set Methods in Imaging, Vision, and Graphics. Springer-Verlag New York, Inc., 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>56815</ref_obj_id>
				<ref_obj_pid>56813</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[S. Osher and J. A. Sethian. Fronts propogating with curvature dependent speed: Algorithms based on Hamilton-Jacobi formulation. J. Comput. Phys., 79:12--49, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[V. V. Savchenko, A. A. Pasko, O. G. Okunev, and T. L. Kunii. Function representation of solids reconstructed from scattered surface points and contours. Computer Graphics Forum, 14(4):181--188, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[J. A. Sethian. Level Set Methods. Cambridge University Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[J. A. Sethian. Level Set Methods and Fast Marching Methods. Cambridge University Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015816</ref_obj_id>
				<ref_obj_pid>1186562</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[C. Shen, J. F. O'Brien, and J. R. Shewchuk. Interpolating and approximating implicit surfaces from polygon soup. In Proceedings 2004 SIGGRAPH, Annual Conference Series. ACM SIGGRAPH, ACM Press, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[R. Szeliski, D. Tonnesen, and D. Terzopoulos. Modeling surfaces of arbitrary topology with dynamic particles. In Proceedings Computer Vision and Pattern Recognition (CVPR). IEEE Computer Society Press, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311580</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[G. Turk and J. F. O'Brien. Shape transformation using variational implicit surfaces. In SIGGRAPH '99 Proceedings, Annual Conference Series. ACM SIGGRAPH, ACM Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>571650</ref_obj_id>
				<ref_obj_pid>571647</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[G. Turk and J. F. O'Brien. Modelling with implicit surfaces that interpolate. ACM Transactions on Graphics, 21(4):855--873, October 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[J. Weickert and G. K&#252;hne. Fast methods for implicit active contour models. In S. Osher and N. Paragios, editors, Geometric Level Set Methods in Imaging, Vision, and Graphics, pages 43--77. Springer-Verlag New York, Inc., NY: New York, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[R. Whitaker. Volumetric deformable models: active blobs. In R. Robb, editor, Visualization in Biomedical Computing, pages 122--134, November 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299682</ref_obj_id>
				<ref_obj_pid>299660</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[R. T. Whitaker. A level-set approach to 3D reconstruction from range data. International Journel of Comp. Vision, 10(3):203--231, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192227</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[A. P. Witkin and P. S. Heckbert. Using particles to sample and control implicit surfaces. Computer Graphics, 28(Annual Conference Series):269--277, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2319503</ref_obj_id>
				<ref_obj_pid>2318958</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[C. Xu and J. L. Prince. Snakes, shapes, and gradient vector flow. IEEE Trans. on Image processing, 7(3):359--369, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835628</ref_obj_id>
				<ref_obj_pid>832286</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[C. Xu, A. Yezzi, and J. Prince. A summary of geometric level-set analogues for a general class of parametric active contour and surface models. In Proc. of 1st IEEE Workshop on Variational and Level Set Methods in Computer Vision, pages 104--111, July 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[T. S. Yoo, B. S. Morse, K. R. Subramanian, P. Rheingans, and M. J. Ackerman. Anatomic modeling from unstructured samples using variational implicit surfaces. In Proceedings of Medicine Meets Virtual Reality (MMVR 2001), Jan. 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198656</article_id>
		<sort_key>260</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[Using particles to sample and control implicit surfaces]]></title>
		<page_from>260</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198656</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198656</url>
		<abstract>
			<par><![CDATA[We present a new particle-based approach to sampling and controlling implicit surfaces. A simple constraint locks a set of particles onto a surface while the particles and the surface move. We use the constraint to make surfaces follow particles, and to make particles follow surfaces. We implement <i>control points</i> for direct manipulation by specifying particle motions, then solving for surface motion that maintains the constraint. For sampling and rendering, we run the constraint in the other direction, creating <i>floater</i> particles that roam freely over the surface. Local repulsion is used to make floaters spread evenly across the surface. By varying the radius of repulsion adaptively, and fissioning or killing particles based on the local density, we can achieve good sampling distributions very rapidly, and maintain them even in the face of rapid and extreme deformations and changes in surface topology.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[adaptive sampling]]></kw>
			<kw><![CDATA[constrained optimization]]></kw>
			<kw><![CDATA[interaction]]></kw>
			<kw><![CDATA[physically based modeling]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>G.1.6</cat_node>
				<descriptor>Constrained optimization</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003716</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Mathematical optimization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003716</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Mathematical optimization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P18515</person_id>
				<author_profile_id><![CDATA[81100295587]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Witkin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P221481</person_id>
				<author_profile_id><![CDATA[81100383628]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Heckbert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>159734</ref_obj_id>
				<ref_obj_pid>159730</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Chandrajit Bajaj, Insung Ihm, and Joe Warren. Higher-order interpolation and least-squares approximation using implicit algebraic surfaces. ACM Trans. on Graphics, 12(4):327--347, Oct. 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74356</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[David Baraff. Analytical methods for dynamic simulation of non-penetrating rigid bodies. Computer Graphics, 23(3):223--232, July 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97881</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[David Baraff. Curved surfaces and coherence for non-penetrating rigid body simulation. Computer Graphics, 24(4):19--28, August 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134084</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[David Baraff and Andrew Witkin. Dynamic simulation of non-penetrating flexible bodies. Computer Graphics, 26(2):303--308, 1992. Proc. Siggraph '92.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378509</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Ronen Barzel and Alan H. Barr. A modeling system based on dynamic constaints. Computer Graphics, 22:179--188, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Baumgarte. Stabilization of constraints and integrals of motion in dynamical systems. Computer Methods in Applied Mechanics, 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Thaddeus Beier. Practical uses for implicit surfaces in animation. In Modeling, Visualizing, and Animating Implicit Surfaces (SIGGRAPH '93 Course Notes), pages 20.1--20.10. 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357310</ref_obj_id>
				<ref_obj_pid>357306</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[James F. Blinn. A generalization of algebraic surface drawing. ACM Trans, on Graphics, 1(3):235--256, July 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>55285</ref_obj_id>
				<ref_obj_pid>55279</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Jules Bloomenthal. Polygonization of implicit surfaces. Computer Aided Geometric Design, 5:341--355, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>180923</ref_obj_id>
				<ref_obj_pid>180895</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Jules Bloomenthal. An implicit surface polygonizer. In Paul Heckbert, editor, Graphics Gems IV, pages 324--350. Academic Press, Boston, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91427</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Jules Bloomenthal and Brian Wyvill. Interactive techniques for implicit modeling. Computer Graphics (1990 Symp. on Interactive 3D Graphics), 24(2):109--116, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>155323</ref_obj_id>
				<ref_obj_pid>155294</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Luiz Henrique de Figueiredo, Jonas de Miranda Gomes, Demetri Terzopoulos, and Luiz Velho. Physically-based methods for polygonization of implicit surfaces. In Graphics Interface '92, pages 250--257, May 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Phillip Gill, Walter Murray, and Margret Wright. Practical Optimization. Academic Press, New York, NY, 1981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134088</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Michael Gleicher and Andrew Witkin. Through-the-lens camera control. Computer Graphics, 26(2):331--340, 1992. Proc. Siggraph '92.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Herbert Goldstein. Classical Mechanics. Addision Wesley, Reading, MA, 1950.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166119</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Huges Hoppe, Tony DeRose, Tom Duchamp, John McDonald, and Werner Stuetzle. Mesh optimization. In SIGGRAPH 93 Proceedings, pages 19--26, July 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[David J. Jevans, Brian Wyvill, and Geoff Wyvill. Speeding up 3-D animation for simulation. In Proc. MAP CON IV (Multi and Array Processors), pages 94--100, Jan. 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[William E. Lorensen and Harvey E. Cline. Marching cubes: A high resolution 3D surface reconstruction algorithm. Computer Graphics (SIGGRAPH '87 Proceedings), 21(4):163--170, July 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134035</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Henry Moreton and Carlo S&#233;quin. Functional minimization for fair surface design. Computer Graphics, 26(2):167--176, 1992. Proc. Siggraph '92.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122743</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Shigeru Muraki. Volumetric shape description of range data using "blobby model". Computer Graphics (SIGGRAPH '91 Proceedings), 25(4):227--235, July 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617872</ref_obj_id>
				<ref_obj_pid>616030</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Paul Ning and Jules Bloomenthal. An evaluation of implicit surface tilers. Computer Graphics and Applications, pages 33--41, Nov. 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37420</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Vaughan Pratt. Direct least-squares fitting of algebraic surfaces. Computer Graphics (SIGGRAPH '87 Proceedings), 21(4):145--152, July 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[W. H. Press, B. P. Flannery, S. A. Teukolsky, and W. T. Vetterling. Numerical Recipes in C. Cambridge University Press, Cambridge, England, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[A. Ricci. A constructive geometry for computer graphics. Computer Journal, 16(2):157--160, May 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[T. Sederberg. Piecewise algebraic surface patches. Computer Aided Geometric Design, 2(1-3):53--60, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>130368</ref_obj_id>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[John M. Snyder. Generative Modeling for Computer Graphics and CAD. Academic Press, Boston, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134037</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Richard Szeliski and David Tonnesen. Surface modeling with oriented particle systems. Computer Graphics (SIGGRAPH '92 Proceedings), 26(2): 185--194, July 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122749</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Greg Turk. Generating textures on arbitrary surfaces using reaction-diffusion. Computer Graphics (SIGGRAPH '91 Proceedings), 25(4):289--298, July 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134008</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Greg Turk. Re-tiling polygonal surfaces. Computer Graphics (SIGGRAPH '92 Proceedings), 26(2):55--64, July 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134033</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[William Welch and Andrew Witkin. Variational surface modeling. Computer Graphics, 26(2):157--166, 1992. Proc. Siggraph '92.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91400</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Andrew Witkin, Michael Gleicher, and William Welch. Interactive dynamics. Computer Graphics, 24(2): 11--21, March 1990. Proc. 1990 Symposium on 3-D Interactive Graphics.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>565650</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Andrew Witkin and William Welch. Fast animation and control of non-rigid structures. Computer Graphics, 24(4):243--252, July 1990. Proc. Siggraph '90.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Brian Wyvill, Craig McPheeters, and Geoff Wyvill. Data structure for soft objects. The Visual Computer, 2(4):227--234, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198657</article_id>
		<sort_key>269</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[Using particles to sample and control more complex implicit surfaces]]></title>
		<page_from>269</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198657</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198657</url>
		<abstract>
			<par><![CDATA[In 1994, Witkin and Heckbert developed a method for interactively modeling implicit surfaces by simultaneously constaining a particle system to lie on an implicit surface and vice-versa. This interface was demonstrated to be effective and easy to use on example models containing a few blobby spheres and cylinders. This system becomes much more difficult to implement and operate on more complex implicit models. The derivatives needed for the particle system behavior can become laborious and error-prone when implemented for more complex models. We have developed, implemented and tested techniques for automatic and numerical differentiation of the implicit surface function. Complex models also require a large number of parameters, and the management and control of these parameters is often not intuitive. We have developed adapters, which are special shape-transformation operators that automatically adjust the underlying parameters to yield the same effect as the transformation. These new techniques allow constrained particle systems to sample and control more complex models than before possible.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40023956</person_id>
				<author_profile_id><![CDATA[81100123210]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Hart]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P588327</person_id>
				<author_profile_id><![CDATA[81100368977]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ed]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bachta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP311157500</person_id>
				<author_profile_id><![CDATA[81545181956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wojciech]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jarosz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39060275</person_id>
				<author_profile_id><![CDATA[81322493522]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Terry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fleury]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[V. Adzhiev, R. Cartwright, E. Fausett, A. Ossipov, A. Pasko, and V. Savchenko. Hyperfun project: a framework for collaborative multidimensional f-rep modeling. Proc. Implicit Surfaces '99, pages 59--69, Sept. 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808573</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. H. Barr. Global and local deformations of solid primitives. Computer Graphics, 18(3):21--30, July 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>270437</ref_obj_id>
				<ref_obj_pid>270430</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C. H. Bischof, L. Roh, and A. J. Mauer-Oats. ADIC: an extensible automatic differentiation tool for ANSI-C. Software: Practice and Experience, 27(12):1427--1456, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357310</ref_obj_id>
				<ref_obj_pid>357306</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. F. Blinn. A generalization of algebraic surface drawing. ACM Transactions on Graphics, 1(3):235--256, July 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>229474</ref_obj_id>
				<ref_obj_pid>229473</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. Griewank, D. Juedes, H. Mitev, J. Utke, O. Vogel, and A. Walther. ADOL-C: A package for the automatic differentiation of algorithms written in C/C++. ACM Trans. Math. Software, 22(2):131--167, June 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[C. Hoffman and J. Hopcroft. Automatic surface generation in computer aided design. Visual Computer, 1:92--100, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[A. Pasko, V. Adzhiev, A. Sourin, and V. Savchenko. Function representation in geometric modeling: concepts, implementation and applications. Visual Computer, 11:429--446, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[H. K. Pedersen. imp. Source code available via implicit.eecs.wsu.edu, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>951099</ref_obj_id>
				<ref_obj_pid>951087</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[W. Schroeder, W. Lorensen, and S. Linthicum. Implicit modeling of swept surfaces and volumes. Proc. Visualization '94, pages 40--45, Oct. 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>272980</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[W. Schroeder, K. Martin, and W. Lorensen. The Visualization Toolkit: An Object-Oriented Appriach to 3D Graphics. Prentice Hall, Dec. 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>245018</ref_obj_id>
				<ref_obj_pid>244979</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[W. J. Schroeder, K. M. Martin, and W. E. Lorensen. The design and implementation of an object-oriented toolkit for 3d graphics and visualization. IEEE Visualization '96, pages 93--100, Oct. 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258868</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[B. T. Stander and J. C. Hart. Guaranteeing the topology of an implicit surface polygonization for interactive modeling. In Computer Graphics (Annual Conference Series), pages 279--286, Aug. 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311580</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[G. Turk and J. O'Brien. Shape transformation using variational implicit functions. Computer Graphics (Proc. SIGGRAPH 99), pages 335--342, Aug. 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192227</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[A. P. Witkin and P. S. Heckbert. Using particles to sample and control implicit surfaces. In Computer Graphics (Annual Conference Series), pages 269--277, July 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[B. Wyvill, E. Galin, and A. Guy. Extending the CSG tree: Warping, blending and boolean operations in an implicit surface modeling system. Computer Graphics Forum, 18(2):149--158, June 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198658</article_id>
		<sort_key>277</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[A programmable particle system framework for shape modeling]]></title>
		<page_from>277</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198658</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198658</url>
		<abstract>
			<par><![CDATA[Particle systems are an effective tool for visualizing information in a variety of contexts. This paper focuses on the use of surface-constrained particles to visualize information about the surface. We have designed a particle system programming framework consisting of behaviors, attributes and shaders that allows users to rapidly create, debug, and deploy particle systems for sensing and extracting specific surface information and displaying this information in an visually effective manner. We also introduce a simple particle system "little language" to facilitate the articulation of these particle programs. We demonstrate the flexibility and power of this framework for surface visualization with the applications of singularity detection and display, non-photorealistic surface illustration, and surface mesh algorithm visualization.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P756162</person_id>
				<author_profile_id><![CDATA[81300378301]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wen]]></first_name>
				<middle_name><![CDATA[Y.]]></middle_name>
				<last_name><![CDATA[Su]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois Urbana-Champaign]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40023956</person_id>
				<author_profile_id><![CDATA[81100123210]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Hart]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois Urbana-Champaign]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>357310</ref_obj_id>
				<ref_obj_pid>357306</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[James F. Blinn. A generalization of algebraic surface drawing. ACM Trans. Graph., 1(3):235--256, 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218462</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Jules Bloomenthal and Keith Ferguson. Polygonization of non-manifold implicit surfaces. In Proceedings of the 22nd annual conference on Computer graphics and interactive techniques, pages 309--316. ACM Press, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[David J. Bremer and John F. Hughes. Rapid approximate silhouette rendering of implicit surfaces. In Proceedings of Implicit Surfaces 1998, pages 155--164, jun 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808602</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Robert L. Cook. Shade trees. In Proc. SIGGRAPH 84, pages 223--231, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>319443</ref_obj_id>
				<ref_obj_pid>319351</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Patricia Crossno and Edward Angel. Visual debugging of visualization software: a case study for particle systems. In Proceedings of the conference on Visualization '99, pages 417--420. IEEE Computer Society Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Greg Turk Eugene Zhang, Konstantin Mischaikow. Feature-based surface parameterization and texture mapping. technical report GIT-GVU-03-29, Georgia Institute of Technology, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218447</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Kurt W. Fleischer, David H. Laidlaw, Bena L. Currin, and Alan H. Barr. Cellular texture generation. In Proc. SIGGRAPH 95, pages 239--248, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97911</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Pat Hanrahan and Jim Lawson. A language for shading and lighting calculations. In Proc. SIGGRAPH 90, pages 289--298, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>884151</ref_obj_id>
				<ref_obj_pid>882487</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. C. Hart, E. Bachta, W. Jarosz, and T. Fleury. Using particles to sample and control more complex implicit surfaces. In Proc. Shape Modeling International, pages 129--136, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>641507</ref_obj_id>
				<ref_obj_pid>641480</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Takeo Igarashi and John F. Hughes. Smooth meshes for sketch-based freeform modeling. In Proceedings of the 2003 symposium on Interactive 3D graphics, pages 139--142. ACM Press, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>331504</ref_obj_id>
				<ref_obj_pid>331499</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. K. Jain, M. N. Murty, and P. J. Flynn. Data clustering: a review. ACM Computing Surveys, 31(3):264--323, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882355</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Robert D. Kalnins, Philip L. Davidson, Lee Markosian, and Adam Finkelstein. Coherent stylized silhouettes. ACM Transactions on Graphics, 22(3):856--861, July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882369</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Sagi Katz and Ayellet Tal. Hierarchical mesh decomposition using fuzzy clustering and cuts. ACM Trans. Graph., 22(3):954--961, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311586</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Aaron W. F. Lee, David Dobkin, Wim Sweldens, and Peter Schr&#246;der. Multiresolution mesh morphing. In Proc. SIGGRAPH 99, pages 343--350, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566590</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Bruno L&#233;vy, Sylvain Petitjean, Nicolas Ray, and J&#233;rome Maillot. Least squares conformal maps for automatic texture atlas generation. In Proceedings of the 29th annual conference on Computer graphics and interactive techniques, pages 362--371. ACM Press, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311595</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Lee Markosian, Jonathan M. Cohen, Thomas Crulli, and John Hughes. Skin: a constructive approach to modeling free-form shapes. In Proc. SIGGRAPH 99, pages 393--400. ACM Press/Addison-Wesley Publishing Co., 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258894</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Lee Markosian, Michael A. Kowalski, Daniel Goldstein, Samuel J. Trychin, John F. Hughes, and Lubomir D. Bourdev. Real-time nonphotorealistic rendering. In Proceedings of the 24th annual conference on Computer graphics and interactive techniques, pages 415--420. ACM Press/Addison-Wesley Publishing Co., 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218458</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Hans Kohling Pedersen. Decorating implicit surfaces. In Proc. SIGGRAPH 95, pages 291--300, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Ken Perlin. An image synthesizer. In Proc. SIGGRAPH 85, pages 287--296, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357320</ref_obj_id>
				<ref_obj_pid>357318</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[W. T. Reeves. Particle systems a technique for modeling a class of fuzzy objects. ACM Trans. Graph., 2(2):91--108, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Angela Rosch, Matthias Ruhl, and Dietmar Saupe. Interactive visualization of implicit surfaces with singularities. Computer Graphics Forum, 16(5):295--306, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882390</ref_obj_id>
				<ref_obj_pid>882370</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[P. V. Sander, Z. J. Wood, S. J. Gortler, J. Snyder, and H. Hoppe. Multi-chart geometry images. In Proceedings of the Eurographics/ACM SIGGRAPH symposium on Geometry processing, pages 146--155. Eurographics Association, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258868</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Barton T. Stander and John C. Hart. Guaranteeing the topology of an implicit surface polygonization for interactive modeling. In Proceedings of the 24th annual conference on Computer graphics and interactive techniques, pages 279--286. ACM Press/Addison-Wesley Publishing Co., 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134037</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Richard Szeliski and David Tonnesen. Surface modeling with oriented particle systems. In Proceedings of the 19th annual conference on Computer graphics and interactive techniques, pages 185--194. ACM Press, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>164427</ref_obj_id>
				<ref_obj_pid>164360</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Gabriel Taubin. An accurate algorithm for rasterizing algebraic curves. In Proceedings on the second ACM symposium on Solid modeling and applications, pages 221--230. ACM Press, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122749</ref_obj_id>
				<ref_obj_pid>122718</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Greg Turk. Generating textures on arbitrary surfaces using reaction-diffusion. In Proc. SIGGRAPH 91, pages 289--298, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134008</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Greg Turk. Re-tiling polygonal surfaces. In Proc. SIGGRAPH 92, pages 55--64, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383297</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Greg Turk. Texture synthesis on surfaces. In Proc. SIGGRAPH 2001, pages 347--354, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383298</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Li-Yi Wei and Marc Levoy. Texture synthesis over arbitrary manifold surfaces. In Proc. SIGGRAPH 2001, pages 355--360, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192216</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[William Welch and Andrew Witkin. Free-form shape design using triangulated surfaces. In Proceedings of the 21st annual conference on Computer graphics and interactive techniques, pages 247--256. ACM Press, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192184</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Georges Winkenbach and David H. Salesin. Computer-generated pen-and-ink illustration. In Proceedings of the 21st annual conference on Computer graphics and interactive techniques, pages 91--100. ACM Press, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192227</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Andrew P. Witkin and Paul S. Heckbert. Using particles to sample and control implicit surfaces. In Proceedings of the 21st annual conference on Computer graphics and interactive techniques, pages 269--277. ACM Press, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198659</section_id>
		<sort_key>14</sort_key>
		<section_seq_no>14</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Discrete differential geometry: an applied introduction]]></section_title>
		<section_page_from>14</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP40031128</person_id>
				<author_profile_id><![CDATA[81320489894]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Eitan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Grinspun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198660</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Introduction to discrete differential geometry]]></title>
		<subtitle><![CDATA[the geometry of plane curves]]></subtitle>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198660</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198660</url>
		<abstract>
			<par><![CDATA[The nascent field of discrete differential geometry deals with discrete geometric objects (such as polygons) which act as analogues to continuous geometric objects (such as curves). The discrete objects can be measured (length, area) and can interact with other discrete objects (collision/response). From a computational standpoint, the discrete objects are attractive, because they have been designed from the ground up with data-structures and algorithms in mind. From a mathematical standpoint, they present a great challenge: the discrete objects should have properties which are analogues of the properties of continuous objects. One important property of curves and surfaces is their curvature, which plays a significant role in many application areas (see, <i>e.g.</i>, Chapters 4 and 5). In the continuous domain there are remarkable theorems dealing with curvature; a key requirement for a discrete curve with discrete curvature is that it satisfies analogous theorems. In this chapter we examine the curvature of continuous and discrete curves on the plane.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40030676</person_id>
				<author_profile_id><![CDATA[81320489894]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Eitan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Grinspun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Columbia University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31054091</person_id>
				<author_profile_id><![CDATA[81100356956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Adrian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Secord]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[New York University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198661</article_id>
		<sort_key>2</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[What can we measure?]]></title>
		<page_from>2</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198661</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198661</url>
		<abstract>
			<par><![CDATA[When characterizing a shape or changes in shape we must first ask, what can we measure about a shape? For example, for a region in &int;<inf>3</inf> we may ask for its volume or its surface area. If the object at hand undergoes deformation due to forces acting on it we may need to formulate the laws governing the change in shape in terms of measurable quantities and their change over time. Usually such measurable quantities for a shape are defined with the help of integral calculus and often require some amount of smoothness on the object to be well defined. In this chapter we will take a more abstract approach to the question of measurable quantities which will allow us to define notions such as mean curvature integrals and the curvature tensor for piecewise linear meshes without having to worry about the meaning of second derivatives in settings in which they do not exist. In fact in this chapter we will give an account of a classical result due to Hadwiger, which shows that for a convex, compact set in R<sup><i>n</i></sup> there are only <i>n</i> + 1 unique measurements if we require that the measurements be invariant under Euclidian motions (and satisfy certain "sanity" conditions). We will see how these measurements are constructed in a very straightforward and elementary manner and that they can be read off from a characteristic polynomial due to Steiner. This polynomial describes the volume of a family of shapes which arise when we "grow" a given shape. As a practical tool arising from these consideration we will see that there is a well defined notion of the curvature tensor for piece-wise linear meshes and we will see very simple formulas for quantities needed in physical simulation with piecewise linear meshes. Much of the treatment here will initially be limited to convex bodies to keep things simple. This limitation that will be removed at the very end.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40031352</person_id>
				<author_profile_id><![CDATA[81100117380]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schr&#246;der]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>777839</ref_obj_id>
				<ref_obj_pid>777792</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Cohen-Steiner, D., And Morvan, J.-M. 2003. Restricted Delaunay Triangulations and Normal Cycle. In Proceedings of the 19th Annual Symposium on Computational Geometry, 312--321.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Klain, D. A., And Rota, G.-C. 1997. Introduction to Geometric Probability. Cambridge University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Klain, D. A. 1995. A Short Proof of Hadwiger's Characterization Theorem. Mathematika 42, 84, 329--339.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198662</article_id>
		<sort_key>3</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Curvature measures for discrete surfaces]]></title>
		<page_from>3</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198662</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198662</url>
		<abstract>
			<par><![CDATA[The curvatures of a smooth curve or surface are local measures of its shape. Here we consider analogous measures for discrete curves and surfaces, meaning polygonal curves and triangulated polyhedral surfaces. We find that the most useful analogs are those which preserve integral relations for curvature, like the Gau&#223;-Bonnet theorem. For simplicity, we usually restrict our attention to curves and surfaces in euclidean space R<sup>3</sup>, although many of the results would easily generalize to other ambient manifolds of arbitrary dimension.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP31059013</person_id>
				<author_profile_id><![CDATA[81100394982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Sullivan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[TU Berlin, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198663</article_id>
		<sort_key>4</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[A discrete model of thin shells]]></title>
		<page_from>4</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198663</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198663</url>
		<abstract>
			<par><![CDATA[We present a discrete model for the behavior of thin flexible structures, such as hats, leaves, and aluminum cans, which are characterized by a curved undeformed configuration. Previously such models required complex continuum mechanics formulations and correspondingly complex algorithms. We show that a simple shell model can be derived geometrically for triangle meshes and implemented quickly by modifying a standard cloth simulator. Our technique convincingly simulates a variety of curved objects with materials ranging from paper to metal, as we demonstrate with several examples including a comparison of a real and simulated falling hat.This chapter is based on the paper by Grinspun, Hirani, Desbrun, and Schr&#246;der which appeared in the Proceedings of the Symposium for Computer Animation 2003 [Grinspun et al. 2003].]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40031132</person_id>
				<author_profile_id><![CDATA[81320489894]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Eitan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Grinspun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Columbia University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[ADIFOR, 2002. Argonne National Laboratory / Rice University. http://www-unix.mcs.anl.gov/autodiff/ADIFOR/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Arnold, D., 2000. Questions on Shell Theory. Workshop on Elastic Shells: Modeling, Analysis, and Computation. Mathematical Sciences Research Institute, Bekeley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Autodiff.org, 2002. http://www.autodiff.org.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280821</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Baraff, D., and Witkin, A. 1998. Large Steps in Cloth Simulation. In Proceedings of SIGGRAPH, 43--54.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bobenko, A. I. 2004. A Conformal Energy for Simplicial Surfaces. Published online at http://arxiv.org/abs/math.DG/0406128, August.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566623</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Bridson, R., Fedkiw, R. P., and Anderson, J. 2002. Robust Treatment of Collisions, Contact, and Friction for Cloth Animation. ACM Trans. on Graphics 21, 3 (July), 594--603.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>846281</ref_obj_id>
				<ref_obj_pid>846276</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Bridson, R., Marino, S., and Fedkiw, R. 2003. Simulation of Clothing with Folds and Wrinkles. In Proceedings of ACM SIGGRAPH / Eurographics Symposium on Computer Animation, D. Breen and M. Lin, Eds.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134017</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Carignan, M., Yang, Y., Thalmann, N. M., and Thalmann, D. 1992. Dressing Animated Synthetic Actors with Complex Deformable Clothes. In Proceedings of SIGGRAPH, 99--104.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122746</ref_obj_id>
				<ref_obj_pid>122718</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Celniker, G., and Gossard, D. 1991. Deformable Curve and Surface Finite Elements for Free-Form Shape Design. Computer Graphics (Proceedings of SIGGRAPH 91) 25, 4, 257--266.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Ciarlet, P. 2000. Mathematical Elasticity. Vol. III, vol. 29 of Studies in Mathematics and its Applications. Amsterdam. Theory of shells.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Cirak, F., Ortiz, M., and Schr&#246;der, P. 2000. Subdivision Surfaces: A New Paradigm for Thin-Shell Finite-Element Analysis. Internat. J. Numer. Methods Engrg. 47, 12, 2039--2072.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Cirak, F., Scott, M., Antonsson, E., Ortiz, M., and Schr&#246;der, P. 2002. Integrated Modeling, Finite-Element Analysis, and Engineering Design for Thin-Shell Structures Using Subdivision. CAD 34, 2, 137--148.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>777839</ref_obj_id>
				<ref_obj_pid>777792</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Cohen-Steiner, D., and Morvan, J.-M. 2003. Restricted Delaunay Triangulations and Normal Cycle. In Proc. 19th Annu. ACM Sympos. Comput. Geom., 237--246.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>571034</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Corliss, G., Faure, C., Griewank, A., Hasco&#235;t, L., and Naumann, U., Eds. 2001. Automatic Differentiation of Algorithms: From Simulation to Optimization. Springer.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Desbrun, M., Meyer, M., and Alliez, P. 2002. Intrinsic Parameterizations of Surface Meshes. In Proceedings of Eurographics, 209--218.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Feynman, C. 1986. Modeling the Appearance of Cloth. MSc thesis, MIT.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Ge, Z., Kruse, H. P., and Marsden, J. E. 1996. The Limits of Hamiltonian Structures in Three-Dimensional Elasticity, Shells, and Rods. Journal of Nonlinear Science 6, 19--57.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Gingold, Y., Secord, A., Han, J. Y., Grinspun, E., and Zorin, D. 2004. Poster: A Discrete Model for In-elastic Deformation of Thin Shells. In ACM/Eurographics Symposium on Computer Animation '04.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>922879</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Gleicher, M. 1994. A Differential Approach to Graphical Manipulation (Chapter 5). PhD thesis.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>524240</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Gray, A. 1998. Modern Differential Geometry of Curves and Surfaces. Second edition. CRC Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566321</ref_obj_id>
				<ref_obj_pid>566282</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Green, S., Turkiyyah, G., and Storti, D. 2002. Subdivision-Based Multilevel Methods for Large Scale Engineering Simulation of Thin Shells. In Proceedings of ACM Solid Modeling, 265--272.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Greiner, G. 1994. Variational Design and Fairing of Spline Surfaces. Computer Graphics Forum 13, 3, 143--154.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566578</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Grinspun, E., Krysl, P., and Schr&#246;der, P. 2002. CHARMS: A Simple Framework for Adaptive Simulation. ACM Transactions on Graphics 21, 3 (July), 281--290.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>846284</ref_obj_id>
				<ref_obj_pid>846276</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Grinspun, E., Hirani, A., Desbrun, M., and Schr&#246;der, P. 2003. Discrete Shells. In ACM SIGGRAPH Symposium on Computer Animation. to appear.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Haumann, R. 1987. Modeling the Physical Behavior of Flexible Objects. In Topics in Physically-based Modeling, Eds. Barr, Barrel, Haumann, Kass, Platt, Terzopoulos, and Witkin, SIGGRAPH Course Notes.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>350448</ref_obj_id>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[House, D. H., and Breen, D. E., Eds. 2000. Coth Modeling and Animation. A.K. Peters.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134087</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Kass, M. 1992. CONDOR: Constraint-based Dataflow. In Proceedings of SIGGRAPH, 321--330.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>182234</ref_obj_id>
				<ref_obj_pid>182227</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Kergosien, Y. L., Gotoda, H., and Kunii, T. L. 1994. Bending and Creasing Virtual Paper. IEEE Computer Graphics and Applications, 40--48.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Meyer, M., Desbrun, M., Schr&#246;der, P., and Barr, A. H. 2003. Discrete Differential-Geometry Operators for Triangulated 2-Manifolds. In Visualization and Mathematics III, H.-C. Hege and K. Polthier, Eds. Springer-Verlag, Heidelberg, 35--57.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Newmark, N. M. 1959. A Method of Computation for Structural Dynamics. ASCE J. of the Engineering Mechanics Division 85, EM 3, 67--94.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614331</ref_obj_id>
				<ref_obj_pid>614261</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Qin, H., and Terzopoulos, D. 1996. D-NURBS: A Physics-Based Framework for Geometric Design. IEEE Transactions on Visualization and Computer Graphics 2, 1, 85--96.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>252095</ref_obj_id>
				<ref_obj_pid>252084</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Qin, H., and Terzopoulos, D. 1997. Triangular NURBS and their dynamic generalizations. Computer Aided Geometric Design 14, 4, 325--347.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>176580</ref_obj_id>
				<ref_obj_pid>176579</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., and Qin, H. 1994. Dynamic NURBS with Geometric Constraints for Interactive Sculpting. ACM Transactions on Graphics 13, 2, 103--136.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., Platt, J., Barr, A., and Fleischer, K. 1987. Elastically Deformable Models. In Proceedings of SIGGRAPH, 205--214.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134033</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Welch, W., and Witkin, A. 1992. Variational Surface Modeling. Computer Graphics (Proceedings of SIGGRAPH 92) 26, 2, 157--166.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[West, M., Kane, C., Marsden, J. E., and Ortiz, M. 2000. Variational Integrators, the Newmark Scheme, and Dissipative Systems. In International Conference on Differential Equations 1999, World Scientific, Berlin, 1009--1011.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198664</article_id>
		<sort_key>5</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Discrete Willmore flow]]></title>
		<page_from>5</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198664</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198664</url>
		<abstract>
			<par><![CDATA[The Willmore energy of a surface, &int;(<i>H</i><sup>2</sup> - <i>K</i>) <i>dA</i>, as a function of mean and Gaussian curvature, captures the deviation of a surface from (local) sphericity. As such this energy and its associated gradient flow play an important role in digital geometry processing, geometric modeling, and physical simulation. In this paper we consider a <i>discrete</i> Willmore energy and its flow. In contrast to traditional approaches it is not based on a finite element discretization, but rather on an ab initio discrete formulation which preserves the M&#246;bius symmetries of the underlying continuous theory in the discrete setting. We derive the relevant gradient expressions including a linearization (approximation of the Hessian), which are required for non-linear numerical solvers. As examples we demonstrate the utility of our approach for surface restoration, n-sided hole filling, and non-shrinking surface smoothing.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Willmore energy]]></kw>
			<kw><![CDATA[digital geometry processing]]></kw>
			<kw><![CDATA[discrete differential geometry]]></kw>
			<kw><![CDATA[geometric flow]]></kw>
			<kw><![CDATA[variational surface modeling]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>G.1.8</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.6.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010349</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003727.10003729</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Differential equations->Partial differential equations</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P828538</person_id>
				<author_profile_id><![CDATA[81320488357]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alexander]]></first_name>
				<middle_name><![CDATA[I.]]></middle_name>
				<last_name><![CDATA[Bobenko]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[TU Berlin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40031377</person_id>
				<author_profile_id><![CDATA[81100117380]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schr&#246;der]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Balay, S., Buschelman, K., Eijkhout, V., Gropp, W. D., Kaushik, D., Knepley, M. G., McInnes, L. C., Smith, B. F., and Zhang, H. 2004. PETSc Users Manual. Tech. Rep. ANL-95/11 - Revision 2.1.5, Mathematics and Computer Science Division, Argonne National Laboratory. Available at http://www-unix.mcs.anl.gov/petsc/petsc-2/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Benson, S. J., McInnes, L. C., Mor&#233;, J., and Sarich, J. 2004. TAO User Manual (Revision 1.7). Tech. Rep. ANL/MCS-TM-242, Mathematics and Computer Science Division, Argonne National Laboratory. Available at http://www-unix.mcs.anl.gov/tao.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Blaschke, W. 1929. Vorlesungen &#252;ber Differentialgeometrie III. Springer.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bobenko, A. I. 2005. A Conformal Energy for Simplicial Surfaces. In Combinatorial and Computational Geometry, J. E. Goodman, J. Pach, and E. Welzl, Eds., MSRI Publications. Cambridge University Press, 133--143.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>846281</ref_obj_id>
				<ref_obj_pid>846276</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bridson, R., Marino, S., And Fedkiw, R. 2003. Simulation of clothing with folds and wrinkles. In Proceedings of the 2003 ACM SIGGRAPH/Eurographics Symposium on Computer animation, Eurographics Association, 28--36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Canham, P. B. 1970. The Minimum Energy of Bending as a Possible Explanation of the Biconcave Shape of the Human Red Blood Cell. Journal of Theoretical Biology 26, 61--81.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Chen, B.-Y. 1973. An Invariant of Conformal Mappings. Proceedings of the American Mathematical Society 40, 2, 563--564.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Chopp, D. L., And Sethian, J. A. 1999. Motion by Intrinsic Laplacian of Curvature. Interfaces and Free Boundaries 1, 1, 107--123.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1012067</ref_obj_id>
				<ref_obj_pid>1012066</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Clarenz, U., Diewald, U., Dziuk, G., Rumpf, M., and Rusu, R. 2004. A Finite Element Method for Suface Restoration with Smooth Boundary Conditions. Computer Aided Geometric Design. To appear.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Deckelnick, K., Dzuik, G., and Elliott, C. M. 2003. Fully Discrete Semi-Implicit Second order Splitting for Anisotropic Surface Diffusion of Graphs. Tech. Rep. 33, University of Magdeburg.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311576</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Desbrun, M., Meyer, M., Schr&#246;der, P., and Barr, A. 1999. Implicit Fairing of Irregular Meshes using Diffusion and Curvature Flow. In Computer Graphics (Proceedings of SIGGRAPH), 317--324.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Desbrun, M., Meyer, M., and Alliez, P. 2002. Intrinsic Parameterizations of Surface Meshes. Computer Graphics Forum (Proceedings of Eurographics 2002) 21, 3, 209--218.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Droske, M., and Rumpf, M. 2004. A Level Set Formulation for Willmore Flow. Interfaces and Free Boundaries. To appear.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Duchamp, T., Certain, A., DeRose, T., and Stuetzle, W. 1997. Hierarchical Computation of PL Harmonic Embeddings. Tech. rep., University of Washington.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218440</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Eck, M., DeRose, T. D., Duchamp, T., Hoppe, H., Lounsbery, M., and Stuetzle, W. 1995. Multiresolution Analysis of Arbitrary Meshes. In Proceedings of SIGGRAPH, 173--182.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Fenchel, W. 1929. &#220;ber die Kr&#252;mmung und Windung geschlossener Raumkurven. Math. Ann. 101, 238--252.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Greiner, G. 1994. Variational Design and Fairing of Spline Surfaces. In Proceedings of EUROGRAPHICS, vol. 13, 143--154.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566578</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Grinspun, E., Krysl, P., and Schr&#246;der, P. 2002. CHARMS: A Simple Framework for Adaptive Simulation. ACM Transactions on Graphics 21, 3, 281--290.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>846284</ref_obj_id>
				<ref_obj_pid>846276</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Grinspun, E., Hirani, A., Desbrun, M., and Schr&#246;der, P. 2003. Discrete Shells. In Symposium on Computer Animation, 62--67.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882388</ref_obj_id>
				<ref_obj_pid>882370</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Gu, x., and Yau, S.-T. 2003. Global Conformal Surface Parameterization. In Eurographics/ACM SIGGRAPH Symposium on Geometry Processing, 127--137.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>374010</ref_obj_id>
				<ref_obj_pid>373751</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Hari, L. P., Givoli, D., and Rubinstein, J. 2001. Computation of Open Willmore-Type Surfaces. Applied Numerical Mathematics 37, 257--269.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Hauth, M., Etzmuss, O., and Strasser, W. 2003. Analysis of Numerical Methods for the Simulation of Deformable Models. The Visual Computer 19, 7-8, 581--600.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Helfrich, W. 1973. Elastic Properties of Lipid Bilayers: Theory and Possible Experiments. Zeitschrift f&#252;r Naturforschung Teil C 28, 693--703.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>63739</ref_obj_id>
				<ref_obj_pid>63735</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Lott, N. J., and Pullin, D. I. 1988. Method for Fairing B-Spline Surfaces. Computer-Aided Design 20, 10, 597--600.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Mayer, U. F., And Simonett, G. 2000. Self-Intersections for the Surface Diffusion and the Volume Preserving Mean Curvature Flow. Differential and Integral Equations 13, 1189--1199.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Mayer, U. F. 2001. Numerical Solution for the Surface Diffusion Flow in Three Space Dimensions. Computational and Applied Mathematics 20, 3, 361--379.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Mercat, C. 2001. Discrete Riemann Surfaces and the Ising Model. Communications in Mathematical Physics 218, 1, 177--216.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Pinkall, U., and Polthier, K. 1993. Computing Discrete Minimal Surfaces and Their Conjugates. Experimental Mathematics 2, 1, 15--36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2246286</ref_obj_id>
				<ref_obj_pid>2246203</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Schneider, R., and Kobbelt, L. 2001. Geometric Fairing of Irregular Meshes for Free-From Surface Design. Computer Aided Geometric Design 18, 4, 359--379.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944024</ref_obj_id>
				<ref_obj_pid>944020</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Tasdizen, T., Whitaker, R., Burchard, P., and Osher, S. 2003. Geometric Surface Processing via Normal Maps. ACM Transactions on Graphics 22, 4, 1012--1033.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192216</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Welch, W., and Witkin, A. 1994. Free-Form Shape Design Using Triangulated Surfaces. Computer Graphics (Proceedings of SIGGRAPH) 28, 247--256.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[White, J. H. 1973. A Global Invariant of Conformal Mappings in Space. Proceedings of the American Mathematical Society 38, 1, 162--164.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Willmore, T. J. 2000. Surfaces in Conformal Geometry. Annals of Global Analysis and Geometry 18, 3-4, 255--264.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Xu, G., Pan, Q., and Bajaj, C. L. 2003. Discrete Surface Modeling using Geometric Flows. Tech. rep., University of Texas.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>797475</ref_obj_id>
				<ref_obj_pid>795681</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Yoshizawa, S., and Belyaev, A. G. 2002. Fair Triangle Mesh Generation with Discrete Elastica. In Geometric Modeling and Processing, IEEE Computer Society, 119--123.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198665</article_id>
		<sort_key>6</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Discrete conformal mappings via circle patterns]]></title>
		<page_from>6</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198665</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198665</url>
		<abstract>
			<par><![CDATA[We introduce a novel method for the construction of discrete conformal mappings from (regions of) embedded meshes to the plane. Our approach is based on <i>circle patterns, i.e</i>., arrangements of circles---one for each face---with prescribed intersection angles. Given these angles the circle radii follow as the <i>unique</i> minimizer of a convex energy. The method has two principal advantages over earlier approaches based on discrete harmonic mappings: (1) it supports very flexible boundary conditions ranging from natural boundaries to control of the boundary shape via prescribed curvatures; (2) the solution is based on a convex energy as a function of <i>logarithmic</i> radius variables with simple explicit expressions for gradients and Hessians, greatly facilitating robust and efficient numerical treatment. We demonstrate the versatility and performance of our algorithm with a variety of examples.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[circle patterns]]></kw>
			<kw><![CDATA[conformal parameterizations]]></kw>
			<kw><![CDATA[discrete analytic functions]]></kw>
			<kw><![CDATA[discrete differential geometry]]></kw>
			<kw><![CDATA[meshing]]></kw>
			<kw><![CDATA[texture mapping]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>G.1.0</cat_node>
				<descriptor>Numerical algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003724</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Numerical differentiation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P683410</person_id>
				<author_profile_id><![CDATA[81100503896]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Liliya]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kharevych]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P790078</person_id>
				<author_profile_id><![CDATA[81314491710]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Boris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Springborn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[TU Berlin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40031350</person_id>
				<author_profile_id><![CDATA[81100117380]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schr&#246;der]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bobenko, A. I., and Springborn, B. A. 2004. Variational Principles for Circle Patterns and Koebe's Theorem. Transactions of the American Mathematical Society 356, 659--689.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bowers, P. L., and Hurdal, M. K. 2003. Planar Conformal Mappings of Piecewise Flat Surfaces. In Visualization and Mathematics III, Springer-Verlag, Berlin, H.-C. Hege and K. Polthier, Eds., Mathematics and Visualization, 3--34. Papers from the 3rd International Workshop held in Berlin, May 22--25, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Br&#228;gger, W. 1992. Kreispackungen und Triangulierungen. Enseign. Math. 38, 201--217.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Colin De Verdi&#232;re, Y. 1991. Un principe variationnel pour les empilements de cercles. Invent. Math. 104, 655--669.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>782361</ref_obj_id>
				<ref_obj_pid>782358</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Collins, C., and Stephenson, K. 2003. A Circle Packing Algorithm. Computational Geometry: Theory and Applications 25, 233--256.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Desbrun, M., Meyer, M., and Alliez, P. 2002. Intrinsic Parameterizations of Surface Meshes. Computer Graphics Forum (Proceedings of Eurographics 2002) 21, 3, 209--218.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Gr&#252;nbaum, B. 2003. Convex polytopes, second ed., vol. 221 of Graduate Texts in Mathematics. Springer-Verlag, New York.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882388</ref_obj_id>
				<ref_obj_pid>882370</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Gu, X., and Yau, S.-T. 2003. Global Conformal Surface Parameterization. In Symposium on Geometry Processing, Eurographics/ACM SIGGRAPH, 127--137.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>959640</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Hirani, A. N. 2003. Discrete Exterior Calculus. PhD thesis, California Institute of Technology.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1034456</ref_obj_id>
				<ref_obj_pid>1032664</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Jin, M., Wang, Y., Yau, S.-T., and Gu, X. 2004. Optimal Global Conformal Surface Parameterizations. In Proceedings of IEEE Visualization, IEEE, 267--274.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Leibon, G. 2002. Characterizing the Delaunay Decompositions of Compact Hyperbolic Surfaces. Geom. Topol. 6, 361--391.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566590</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[L&#233;vy, B., Petitjean, S., Ray, N., and Maillot, J. 2002. Least Squares Conformal Maps for Automatic Texture Atlas Generation. ACM Transactions on Graphics 21, 3, 362--371.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Mercat, C. 2001. Discrete Riemann Surfaces and the Ising Model. Communications in Mathematical Physics 218, 1, 177--216.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Mosek, 2005. Constrained Quadratic Minimization Software. http://www.mosek.com/. Version 3.1r42.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Pinkall, U., and Polthier, K. 1993. Computing Discrete Minimal Surfaces and Their Conjugates. Experimental Mathematics 2, 1, 15--36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Rivin, I. 1994. Euclidean Structures on Simplicial Surfaces and Hyperbolic Volume. Annals of Mathematics 139, 3, 553--580.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Rodin, B., and Sullivan, D. 1987. The Convergence of Circle Packings to the Riemann Mapping. J. Differential Geom. 26, 2, 349--360.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Sheffer, A., and De Sturler, E. 2000. Surface Parameterization for Meshing by Triangulation Flattening. In Proceedings of the 9th International Meshing Roundtable, Sandia National Labs, 161--172.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1061354</ref_obj_id>
				<ref_obj_pid>1061347</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Sheffer, A., L&#233;vy, B., Mogilnitski, M., and Bogomyakov, A. 2004. ABF++: Fast and Robust Angle Based Flattening. ACM Transactions on Graphics. To appear.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Thurston, W. P. 1980. The Geometry and Topology of Three-Manifolds. Available at http://www.msri.org/publications/books/gt3m/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Thurston, W. P. 1985. The finite Riemann mapping theorem. Invited talk at the symposium on the occasion of the proof of the Bieberbach conjecture held at Purdue University, March 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198666</article_id>
		<sort_key>7</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Discrete differential forms for computational modeling]]></title>
		<page_from>7</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198666</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198666</url>
		<abstract>
			<par><![CDATA[The emergence of computers as an essential tool in scientific research has shaken the very foundations of differential modeling. Indeed, the deeply-rooted abstraction of smoothness, or <i>differentiability</i>, seems to inherently clash with a computer's ability of storing only finite sets of numbers. While there has been a series of computational techniques that proposed discretizations of differential equations, the geometric structures they are supposed to simulate are often lost in the process.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40023038</person_id>
				<author_profile_id><![CDATA[81100041821]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mathieu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Desbrun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Applied Geometry Lab, Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31055988</person_id>
				<author_profile_id><![CDATA[81332507901]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Eva]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kanso]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Applied Geometry Lab, Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40026788</person_id>
				<author_profile_id><![CDATA[81100393143]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yiying]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Applied Geometry Lab, Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Abraham, R., and Shaw, C., Eds. 1984. Dynamics: The Geometry of Behavior. Ariel Press (Santa Cruz, CA).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>50877</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Abraham, R., Marsden, J., and Ratiu, T., Eds. 1988. Manifolds, Tensor Analysis, and Applications. Applied Mathematical Sciences Vol. 75, Springer.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bj&#246;rner, A., and Welker, V. 1995. The homology of "k-equal" manifolds and related partition lattices. Advances in Math. 110, 277--313.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bobenko, A., and Seiler, R., Eds. 1999. Discrete Integrable Geometry and Physics. Clarendon Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bossavit, A. 1998. Computational Electromagnetism. Academic Press, Boston.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Bossavit, A. 2003. Personal Communications.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Burke, W. L. 1985. Applied Differential Geometry. Cambridge University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Carroll, S. 2003. Spacetime and Geometry: An Introduction to General Relativity. Pearson Education.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Cartan, &#201;. 1945. Les Syst&#232;mes Differentiels Exterieurs et leurs Applications G&#233;ometriques. Hermann, Paris.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Desbrun, M., Leok, M., and Marsden, J. E. 2004. Discrete Poincar&#233; Lemma. Appl. Num. Math.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Dimakis, A., and M&#252;ller-Hoissen, F. 1994. Discrete Differential Calculus, Graphs, Topologies, and Gauge Theory. Journal of Mathematical Physics 35, 6703--6735.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Doran, C., and Lasenby, A., Eds. 2003. Geometric Algebra for Physicists. Cambridge University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>796607</ref_obj_id>
				<ref_obj_pid>795666</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Edelsbrunner, H., Letscher, D., and Zomorodian, A. 2000. Topological persistence and simplification. In IEEE Symposium on Foundations of Computer Science, 454--463.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Elcott, S., Tong, Y., Kanso, E., Desbrun, M., and Schr&#246;der, P. 2005. Discrete, Circulation-preserving and Stable Simplicial Fluid. under review.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Flanders, H. 1990. Differential Forms and Applications to Physical Sciences. Dover Publications.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Flanders, H., Ed. 2001. Geometric Methods for Computational Electromagnetics. EMW Publishing, Cambridge Mass.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Forman, R. 2005. Bochner's Method for Cell Complexes and Combinatorial Ricci Curvature. to appear in the J. of Discrete and Computational Geom.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Frankel, T. 2004. The Geometry of Physics. Second Edition. Cambridge University Press, United Kingdom.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Gortler, S., Gotsman, C., and Thurston, D. 2004. One-Forms on Meshes and Applications to 3D Mesh Parameterization. Tech. Rep. TR-12-04, Harvard University.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>524240</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Gray, A., Ed. 1998. Modern Differential Geometry of Curves and Surfaces. Second edition. CRC Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Gross, P. W., and Kotiuga, R. 2004. Electromagnetic Theory and Computation: A Topological Approach. Cambridge University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882388</ref_obj_id>
				<ref_obj_pid>882370</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Gu, X., and Yau, S.-T. 2003. Global conformal surface parameterization. In Proceedings of the Eurographics/ACM SIGGRAPH symposium on Geometry processing, Eurographics Association, 127--137.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Harrison, J. 2005. Ravello Lecture Notes on Geometric Calculus - Part I. Tech. rep., UC Berkeley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Hatcher, A. 2004. Algebraic Topology. Cambridge University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Hildebrandt, K., and Polthier, K. 2004. Anisotropic filtering of non-linear surface features. In Computer Graphics Forum, M.-P. Cani and M. Slater, Eds., vol. 23. Proc. Eurographics 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>959640</ref_obj_id>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Hirani, A. N. 2003. Discrete Exterior Calculus. PhD thesis, Caltech.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Hyman, J. M., and Shashkov, M. 1997. Natural Discretizations for the Divergence, Gradient, and Curl. International Journal of Computers and Mathematics with Applications 33, 277--313.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Kanso, E., Arroyo, M., Desbrun, M., Marsden, J. E., and Tong, Y. 2004. On the geometric character of continuum mechanics, completed and to be submitted.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304025</ref_obj_id>
				<ref_obj_pid>304012</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Lazarus, F., and Verroust, A. 1999. Level Set Diagrams of Polyhedral Objects. In Proceedings of the 5th ACM Symposium on Solid Modeling and Applications, 130--140.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Lovelock, D., and Rund, H. 1993. Tensors, Differential Forms, and Variational Principles. Dover Publications.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Madsen, I. H., and Tornehave, J. 1997. From Calculus to Cohomology: De Rham Cohomology and Characteristic Classes. Cambridge University Press, United Kingdom.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Marsden, J. E., and Hughes, T. 1983. Mathematical Foundations of Elasticity. Dover, New York.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Marsden, J. E., and Weinstein, A. 1983. Coadjoint orbits, vortices and Clebsch variables for incompressible fluids. Physica D 7, 305--323.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Marsden, J. E., and West, M. 2001. Discrete Mechanics and Variational Integrators. Acta Numerica.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[McCormick, S. F. 1989. Multilevel Adaptive Methods for Partial Differential Equations --- Chapter 2: The Finite Volume Method, vol. 6. SIAM.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Mercat, C. 2001. Discrete Riemann Surfaces and the Ising Model. Commun. Math. Phys. 218, 1, 177--216.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Meyer, M., Desbrun, M., Schr&#246;der, P., and Barr, A. H. 2002. Discrete Differential-Geometry Operators for Triangulated 2-Manifolds. In Proceedings of VisMath.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Morita, S. 2001. Geometry of Differential Forms. Translations of Mathematical Monographs, Vol. 201. Am. Math. Soc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Munkres, J. R. 1984. Elements of Algebraic Topology. Addison-Wesley, Menlo Park, CA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Pinkall, U., and Polthier, K. 1993. Computing Discrete Minimal Surfaces. Experimental Mathematics 2, 1, 15--36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Polthier, K., and Preuss, E. 2000. Variational Approach to Vector Field Decomposition. Scientific Visualization, Springer Verlag (Proc. of Eurographics Workshop on Scientific Visualization).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Polthier, K., and Preuss, E. 2002. Identifying Vector Fields Singularities using a Discrete Hodge Decomposition. Visualization and Mathematics III, Eds: H. C. Hege, K. Polthier, Springer Verlag.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Polthier, K. 2002. Computational Aspects of Discrete Minimal Surfaces. Proceedings of the Clay Summer School on Global Theory of Minimal Surfaces (Hass, Hoffman, Jaffe, Rosenberg, Schoen, and Wolf Editors).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Schreiber, U. 2003. On Superstrings in Schr&#246;dinger Representation. Preprint.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Sharpe, R. W. 1997. Differential Geometry: Cartan's Generalization of Klein's Erlangen Programme. Springer-Verlag, NY.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882290</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Tong, Y., Lombeyda, S., Hirani, A. N., and Desbrun, M. 2003. Discrete Multiscale Vector Field Decomposition. ACM Trans. Graph. 22, 3, 445--452.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2255166</ref_obj_id>
				<ref_obj_pid>2254881</ref_obj_pid>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Warnick, K. F., Selfridge, R. H., and Arnold, D. V. 1997. Teaching Electromagnetic Field Theory Using Differential Forms. IEEE Trans. on Education 40, 1, 53--68.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[Whitney, H. 1957. Geometric Integration Theory. Princeton Press, Princeton.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[Zapatrin, R. 1996. Polyhedral Representations of Discrete Differential Manifolds. Preprint.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198667</article_id>
		<sort_key>8</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Building your own DEC at home]]></title>
		<page_from>8</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198667</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198667</url>
		<abstract>
			<par><![CDATA[The methods of Discrete Exterior Calculus (DEC) have given birth to many new algorithms applicable to areas such as fluid simulation, deformable body simulation, and others. Despite the (possibly intimidating) mathematical theory that went into deriving these algorithms, in the end they lead to simple, elegant, and straightforward implementations. However, readers interested in implementing them should note that the algorithms presume the existence of a suitable simplicial complex data structure. Such a data structure needs to support local traversal of elements, adjacency information for all dimensions of simplices, a notion of a <i>dual mesh</i>, and all simplices must be <i>oriented</i>. Unfortunately, most publicly available tetrahedral mesh libraries provide only <i>unoriented</i> representations with little more than vertex-tet adjacency information (while we need vertex-edge, edge-triangle, edge-tet, <i>etc.</i>). For those eager to implement and build on the algorithms presented in this course without having to worry about these details, we provide an implementation of a DEC-friendly tetrahedral mesh data structure in C++. This chapter documents the ideas behind the implementation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP31057732</person_id>
				<author_profile_id><![CDATA[81332497491]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sharif]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Elcott]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40023875</person_id>
				<author_profile_id><![CDATA[81100117380]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schr&#246;der]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Joy, K. I., Legakis, J., and MacCracken, R. 2002. Data Structures for Multiresolution Representation of Unstructured Meshes. Springer-Verlag, Heidelberg, Germany.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198668</article_id>
		<sort_key>9</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Discrete, vorticity-preserving, and stable simplicial fluids]]></title>
		<page_from>9</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198668</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198668</url>
		<abstract>
			<par><![CDATA[Visual accuracy, low computational cost, and numerical stability are foremost goals in computer animation. An important ingredient in achieving these goals is the conservation of fundamental motion invariants. For example, rigid or deformable body simulation have benefited greatly from conservation of linear and angular momenta. In the case of fluids, however, none of the current techniques focuses on conserving invariants, and consequently, they often introduce a visually disturbing numerical diffusion of <i>vorticity</i>. Visually just as important is the resolution of complex simulation domains. Doing so with regular (even if adaptive) grid techniques can be computationally delicate.In this chapter, we propose a novel technique for the simulation of fluid flows. It is designed to respect the defining differential properties, i.e., the <i>conservation of circulation</i> along arbitrary loops as they are transported by the flow. Consequently, our method offers several new and desirable properties: (1) arbitrary simplicial meshes (triangles in 2D, tetrahedra in 3D) can be used to define the fluid domain; (2) the computations are efficient due to discrete operators with small support; (3) the method is stable for arbitrarily large time steps; and (4) it preserves a <i>discrete circulation</i> avoiding numerical diffusion of vorticity. The underlying ideas are easy to incorporate in current approaches to fluid simulation and should thus prove valuable in many applications.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[circulation preservation]]></kw>
			<kw><![CDATA[computational algorithms]]></kw>
			<kw><![CDATA[discrete exterior calculus]]></kw>
			<kw><![CDATA[fluid dynamics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP31057747</person_id>
				<author_profile_id><![CDATA[81332497491]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sharif]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Elcott]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40026788</person_id>
				<author_profile_id><![CDATA[81100393143]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yiying]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31058113</person_id>
				<author_profile_id><![CDATA[81332507901]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Eva]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kanso]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40023875</person_id>
				<author_profile_id><![CDATA[81100117380]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schr&#246;der]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40023038</person_id>
				<author_profile_id><![CDATA[81100041821]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Mathieu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Desbrun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>50877</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Abraham, R., Marsden, J., and Ratiu; T., Eds. 1988. Manifolds, Tensor Analysis, and Applications. Applied Mathematical Sciences Vol. 75, Springer.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bossavit, A., and Kettunen, L. 1999. Yee-like schemes on a tetrahedral mesh. Int. J. Num. Modelling: Electr. Networks, Dev. and Fields 12 (July), 129--142.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bossavit, A. 1998. Computational Electromagnetism. Academic Press, Boston.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Chorin, A., and Marsden, J. 1979. A Mathematical Introduction to Fluid Mechanics, 3rd edition ed: Springer-Verlag.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383260</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Fedkiw, R., Stam, J., and Jensen, H. W. 2001. Visual Simulation of Smoke. In Proceedings of ACM SIGGRAPH, Computer Graphics Proceedings, Annual Conference Series, 15--22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015746</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Feldman, B. E., O'Brien, J. F., and Klingner, B. M. 2005. A method for animating viscoelastic fluids. ACM Transactions on Graphics (SIGGRAPH) (Aug.).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Fetecau, R. C., Marsden, J. E., Ortiz, M., and West, M. 2003. Nonsmooth Lagrangian Mechanics and Variational Collision Integrators. SIAM J. Applied Dynamical Systems 2, 381--416.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383261</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Foster, N., and Fedkiw, R. 2001. Practical Animation of Liquids. In Proceedings of ACM SIGGRAPH, Computer Graphics Proceedings, Annual Conference Series, 23--30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258838</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Foster, N., and Metaxas, D. 1997. Modeling the Motion of a Hot, Turbulent Gas. In Proceedings of SIGGRAPH 97, Computer Graphics Proceedings, Annual Conference Series, 181--188.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015746</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Goktekin, T. G., Bargteil, A. W., and O'Brien, J. F. 2004. A method for animating viscoelastic fluids. ACM Transactions on Graphics 23, 3 (Aug.), 463--468.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>959640</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Hirani, A. 2003. Discrete Exterior Calculus. PhD thesis, California Institute of Technology.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Kane, C., Marsden, J. E., Ortiz, M., and West, M. 2000. Variational integrators and the Newmark algorithm for conservative and dissipative mechanical systems. Internat. J. Numer. Methods Engrg. 49, 1295--1325.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Langtangen, H.-P., Mardal, K.-A., and Winter, R. 2002. Numerical Methods for Incompressible Viscous Flow. Advances in Water Resources 25, 8--12 (Aug-Dec), 1125--1146.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Lew, A., Marsden, J. E., Ortiz, M., and West, M. 2003. Asynchronous Variational Integrators. Arch. Rational Mech. Anal. 167, 85--146.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015745</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Losasso, F., Gibou, F., and Fedkiw, R. 2004. Simulating water and smoke with an octree data structure. ACM Transactions on Graphics 23, 3 (Aug.), 457--462.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Marsden, J. E., and Wenstein, A. 1983. Coadjoint orbits, vortices and Clebsch variables for incompressible fluids. Physica D 7, 305--323.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Marsden, J. E., and West, M. 2001. Discrete Mechanics and Variational Integrators. Acta Numerica, 357--515.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015744</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[McNamara, A., Treuille, A., Popovic, Z., and Stam, J. 2004. Fluid Control Using the Adjoint Method. ACM Transactions on Graphics 23, 3 (Aug.), 449--456.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>587241</ref_obj_id>
				<ref_obj_pid>587154</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Morton, K. W., and Roe, P. 2001. Vorticity-Preserving Lax-Wendroff-Type Schemes for the System Wave Equation. SIAM Journal on Scientific Computing 23, 1 (July), 170--192.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Munkres, J. R. 1984. Elements of Algebraic Topology. Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1028552</ref_obj_id>
				<ref_obj_pid>1028523</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Pighin, F., Cohen, J. M., and Shah, M. 2004. Modeling and Editing Flows Using Advected Radial Basis Functions. In ACM SIGGRAPH/Eurographics Symposium on Computer Animation, 223--232.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1028551</ref_obj_id>
				<ref_obj_pid>1028523</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Shah, M., Cohen, J. M., Patel, S., Lee, P., and Pighin, F. 2004. Extended Galilean Invariance for Adaptive Fluid Simulation. In ACM SIGGRAPH/Eurographics Symposium on Computer Animation, 213--221.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1071162</ref_obj_id>
				<ref_obj_pid>1071157</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Shi, L., and Yu, Y. 2004. Inviscid and Incompressible Fluid Simulation on Triangle Meshes. Journal of Computer Animation and Virtual Worlds 15, 3--4 (June), 173--181.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311548</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Stam, J. 1999. Stable Fluids. In Proceedings of ACM SIGGRAPH, Computer Graphics Proceedings, Annual Conference Series, 121--128.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>607965</ref_obj_id>
				<ref_obj_pid>607961</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Stam, J. 2001. A Simple Fluid Solver Based on the FFT. Journal of Graphics Tools 6, 2, 43--52.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882338</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Stam, J. 2003. Flows on Surfaces of Arbitrary Topology. ACM Transactions on Graphics 22, 3 (July), 724--731.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Steinhoff, J., and Underhill, D. 1994. Modification of the Euler Equations for Vorticity Confinement: Applications to the Computation of Interacting Vortex Rings. Physics of Fluids 6, 8 (Aug.), 2738--2744.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882290</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Tong, Y., Lombeyda, S., Hirani, A. N., and Desbrun, M. 2003. Discrete Multiscale Vector Field Decomposition. ACM Trans. Graph. 22, 3, 445--452.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1087236</ref_obj_id>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Tong, Y. 2004. Towards Applied Geometry in Graphics. PhD thesis, University of Southern California.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882337</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Treuille, A., McNamara, A., Popovi&#263;, Z., and Stam, J. 2003. Keyframe Control of Smoke Simulations. ACM Transactions on Graphics 22, 3 (July), 716--723.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Warren, J., Schaefer, S., Hirani, A., and Desbrun, M., 2004. Barycentric Coordinates for Convex Sets. Preprint.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15895</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Yaeger, L., Upson, C., and Myers, R. 1986. Combining Physical and Visual Simulation -Creation of the Planet Jupiter for the Film 2010. Computer Graphics (Proceedings of SIGGRAPH 86) 20, 4, 85--93.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Zhong, G., and Marsden, J. E. 1988. Lie-Poisson Hamilton-Jacobi Theory and Lie-Poisson Integrators. Physics Letters A 133, 3 (Nov.).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198669</article_id>
		<sort_key>10</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Variational tetrahedral meshing]]></title>
		<page_from>10</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198669</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198669</url>
		<abstract>
			<par><![CDATA[In this chapter, a novel Delaunay-based variational approach to isotropic tetrahedral meshing is presented. To achieve both robustness and efficiency, we minimize a simple mesh-dependent energy through global updates of both vertex positions <i>and</i> connectivity. As this energy is known to be the L<sup>1</sup> distance between an isotropic quadratic function and its linear interpolation on the mesh, our minimization procedure generates well-shaped tetrahedra. Mesh design is controlled through a gradation smoothness parameter and selection of the desired number of vertices. We provide the foundations of our approach by explaining both the underlying variational principle and its geometric interpretation. We demonstrate the quality of the resulting meshes through a series of examples. <i>Work published in ACM SIGGRAPH'05 proceedings</i>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[delaunay mesh]]></kw>
			<kw><![CDATA[isotropic meshing]]></kw>
			<kw><![CDATA[sizing field]]></kw>
			<kw><![CDATA[slivers]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39033302</person_id>
				<author_profile_id><![CDATA[81100223488]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pierre]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Alliez]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[INRIA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39060132</person_id>
				<author_profile_id><![CDATA[81100183127]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cohen-Steiner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[INRIA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P189266</person_id>
				<author_profile_id><![CDATA[81100130679]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Mariette]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yvinec]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[INRIA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40023038</person_id>
				<author_profile_id><![CDATA[81100041821]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Mathieu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Desbrun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>276889</ref_obj_id>
				<ref_obj_pid>276884</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Amenta, N., and Bern, M. 1998. Surface Reconstruction by Voronoi Filtering. In Proc. of 14th Symp. on Computational Geometry (SCG'98), 39--48.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>336207</ref_obj_id>
				<ref_obj_pid>336154</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Amenta, N., Choi, S., Dey, T., and Leekhau, N. 200. A Simple Algorithm for Homeomorphic Surface Reconstruction. In Proceedings of the Symposium on Computational geometry, 213--222.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1120643</ref_obj_id>
				<ref_obj_pid>1120639</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Boissonnat, J.-D., and Oudot, S. 2005. Provably Good Sampling and Meshing of Surfaces. Graphical Models (special issue on Solid Modeling). To appear.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>249284</ref_obj_id>
				<ref_obj_pid>249274</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Borouchaki, H., George, P., Hecht, F., Laug, P., and Saltel, E. 1997. Delaunay mesh generation governed by metric specifications. Part 1: Algorithms. Finite Elements in Analysis and Design 25, 61--83.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>249285</ref_obj_id>
				<ref_obj_pid>249274</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Borouchaki, H., George, P., and Mohammadi, B. 1997. Delaunay mesh generation governed by metric specifications. Part 2: Application examples. Finite Elements in Analysis and Design 25, 85--109.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Carey, G. F. 1997. Computational Grids: Generation, Adaptation, and Solution Strategies. Taylor & Francis eds.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Chen, L., and Xu, J. 2004. "Optimal Delaunay triangulations". Journal of Computational Mathematics 22, 2, 299--308.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Chen, L. 2004. Mesh smoothing schemes based on optimal Delaunay triangulations. In Proceedings of 13th International Meshing Roundtable, 109--120.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>545399</ref_obj_id>
				<ref_obj_pid>545381</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Cheng, S. W., and Dey, T. K. 2002. Quality meshing with weighted Delaunay refinement. In Proc. 13th ACM-SIAM Sympos. Discrete Algorithms, 137--146.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>644158</ref_obj_id>
				<ref_obj_pid>644108</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Cheng, S.-W., and Poon, S.-H. 2003. Graded conforming Delaunay tetrahedralization with bounded radius-edge ratio. In Proc, of the 14th ACM-SIAM Symposium on Discrete algorithms (SODA), 295--304.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304894</ref_obj_id>
				<ref_obj_pid>304893</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Cheng, S.-W., Dey, T. K., Edelsbrunner, H., Facello, M. A., and Teng, S.-H. 1999. Sliver Exudation. In Proc. 15th ACM Symp. Comput. Geom., 1--13.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>997862</ref_obj_id>
				<ref_obj_pid>997817</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Cheng, S.-W., Dey, T. K., Ramos, E., and Ray, T. 2004. Quality Meshing for Polyhedra with Small Angles. In Proc. of ACM Symp. on Comp. Geom., 290--299.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>513425</ref_obj_id>
				<ref_obj_pid>513400</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Cohen-Steiner, D., de Verdiere, E. C., and Yvinec, M. 2002. Conforming Delaunay triangulations in 3D. In Proc. of Symp. on Comp. Geom., 237--246.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015817</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Cohen-Steiner, D., Alliez, P., and Desbrun, M. 2004. Variational Shape Approximation. ACM Trans. on Graphics (SIGGRAPH), 905--914.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1057445</ref_obj_id>
				<ref_obj_pid>1057432</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Cutler, B., Dorsey, J., and McMillan, L. 2004. Simplification and Improvement of Tetrahedral Models for Simulation. In Proceedings of the 2004 Eurographics/ACM SIGGRAPH Symposium on Geometry Processing, 95--104.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Du, Q., and Wang, D. 2003. Tetrahedral mesh generation and optimization based on centroidal Voronoi tessellations. International Journal on Numerical Methods in Engineering 56(9), 1355--1373.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>767429</ref_obj_id>
				<ref_obj_pid>767408</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Du, Q., Gunzburger, M., and Ju, L. 2003. Constrained Centroidal Voronoi Tessellations for Surfaces. SIAM J. Sci. Comput. 24, 5, 1488--1506.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Eppstein, D., 2001. Global optimization of mesh quality. Tutorial at the 10th Int. Meshing Roundtable, Newport Beach.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>358687</ref_obj_id>
				<ref_obj_pid>358668</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Fabri, A., Giezeman, G.-J., Kettner, L., Schirra, S., and Sch&#246;nherr, S. 2000. On the Design of CGAL, a Computational Geometry Algorithms Library. Softw. - Pract. Exp. 30, 11, 1167--1202. www.cgal.org.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Freitag, L., and Ollivier-Gooch, C. 1996. A comparison of Tetrahedral Mesh Improvement Techniques. In Proc. of 6th Int. Meshing Roundtable, 87--1000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1205626</ref_obj_id>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Frey, J. L., and George, P. L. 2000. Mesh Generation: Applications to Finite Elements. Herm&#232;s, Paris.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Hardin, D. P., and Saff, E. B. 2004. Discretizing Manifolds via Minimum Energy Points. Notices of the AMS 51(10), 1186--1194.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166119</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Hoppe, H., DeRose, T., Duchamp, T., McDonald, J., and Stuetzle, W. 1993. "Mesh Optimization". ACM Trans. on Graphics (SIGGRAPH), 19--26.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Krysl, P., and Ortiz, M. 2001. Variational Delaunay Approach to the Generation of Finite Element Meshes. Int. J. for Num. Meth. in Eng. 50(7), 1681--1700.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Li, X.-Y., and Teng, S.-H. 2001. Generate Sliver Free Three Dimensional Mesh. In Proc. 12th ACM-SIAM Sympos. Discrete Algorithms.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Li, X.-Y., Teng, S.-H., and Ungor, A. 2000. "Biting: Advancing Front Meets Sphere Packing". Int. J. on Num. Methods in Eng. 49, 1, 61--81.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Lloyd, S. P. 1957. Least Squares Quantization in PCM's. Tech. rep., Bell Telephone Laboratories, Murray Hill, NJ.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>345794</ref_obj_id>
				<ref_obj_pid>345769</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Mitchell, S., and Vavasis, S. 2000. Quality Mesh Generation in Higher Dimensions. SIAM J. Sci. Comput. 29, 1334--1370.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Molino, N., Bridson, R., Teran, J., and Fedkiw, R. 2003. A Crystalline, Red Green Strategy for Meshing Highly Deformable Objects with Tetrahedra. In Proceedings of the 12th International Meshing Roundtable, 103--114.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383326</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Ostromoukhov, V. 2001. A simple and efficient error-diffusion algorithm. In Proceedings of ACM SIGGRAPH, 567--572.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Owen, S. J. 1998. A Survey of Unstructured Mesh Generation Technology. In Proceedings of the 7th International Meshing Roundtable, 239--267.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1217927</ref_obj_id>
				<ref_obj_pid>1217875</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Quadros, W. R., Shimada, K., and Owen, S. J., 2004. 3D Discrete Skeleton Generation by Wave Propagation on PR-Octree for Finite Element Mesh Sizing. Poster, Solid Modeling Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>313615</ref_obj_id>
				<ref_obj_pid>313559</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Ruppert, J. 1993. A New and Simple Algorithm for Quality 2-Dimensional Mesh Generation. In Proc. of the 4th ACM/SIAM Symp. on Disc. Algo. (SODA), 83--92.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276893</ref_obj_id>
				<ref_obj_pid>276884</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Shewchuk, J. R. 1998. A Condition Guaranteeing the Existence of Higher-Dimensional Constrained Delaunay Triangulations. In Proc. 14th Annu. ACM Sympos. Comput. Geom., 76--85.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276894</ref_obj_id>
				<ref_obj_pid>276884</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Shewchuk, J. R. 1998. Tetrahedral mesh generation by Delaunay refinement. In Proc. 14th Annu. ACM Sympos. Comput. Geom., 86--95.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Shewchuk, J. 2002. What Is a Good Linear Element? Interpolation, Conditioning, and Quality Measure. In Proc. of 11th Int. Meshing Roundtable, 115--126.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2295334</ref_obj_id>
				<ref_obj_pid>2295317</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Shewchuk, J. R. 2002. Delaunay Refinement Algorithms for Triangular Mesh Generation. Computational Geometry: Theory and Applications 22, 21--74.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Surazhsky, V., Alliez, P., and Gotsman, C. 2003. Isotropic Remeshing of Surfaces: a Local Parameterization Approach. In Proc. of 12th Int. Meshing Round-table.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Teng, S.-H., Wong, C. W., and Lee, D. T. 2000. Unstructured Mesh Generation: Theory, Practice, and Perspectives. International Journal Computational Geometry and Applications 10, 3 (June), 227--266.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Warren, J., Schaefer, S., Hirani, A., and Desbrun, M., 2004. Barycentric Coordinates for Convex Sets. Preprint.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198670</section_id>
		<sort_key>15</sort_key>
		<section_seq_no>15</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Crowd and group animation]]></section_title>
		<section_page_from>15</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP40031437</person_id>
				<author_profile_id><![CDATA[81100534488]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Thalmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198671</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Crowd and group animation]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198671</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198671</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40028321</person_id>
				<author_profile_id><![CDATA[81100534488]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Thalmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[EPFL VRlab, Switzerland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24033008</person_id>
				<author_profile_id><![CDATA[81322497424]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Laurent]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kermel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[PDI/Dream Works]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39061034</person_id>
				<author_profile_id><![CDATA[81100640822]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Opdyke]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[PDI/Dream Works]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P760261</person_id>
				<author_profile_id><![CDATA[81309494134]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Stephen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Regelous]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Massive Software, New Zealand]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198672</article_id>
		<sort_key>2</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Groups and crowd simulation]]></title>
		<page_from>2</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198672</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198672</url>
		<abstract>
			<par><![CDATA[A crowd is not only a group of many individuals: crowd modeling involves problems arising only when we focus on crowds. For instance, collision avoidance among a large number of individuals in the same area requires different resolving strategies in comparison with the methods used to avoid collisions between just two individuals. Also, motion planning for a group walking together requires more information than needed to implement individual motion planning. This Chapter presents the related works on the subject of groups and crowd simulation as well as discusses the requirements to model behaviors of groups and crowds of virtual actors; current applications, recently applied approaches and challenges of crowd simulations are described.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP38027943</person_id>
				<author_profile_id><![CDATA[81332517802]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Soraia]]></first_name>
				<middle_name><![CDATA[Raupp]]></middle_name>
				<last_name><![CDATA[Musse]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[EPFL-VRlab]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P511584</person_id>
				<author_profile_id><![CDATA[81100064298]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Branislav]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ulicny]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[EPFL-VRlab]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35026840</person_id>
				<author_profile_id><![CDATA[81100269613]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Amaury]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Aubel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[EPFL-VRlab]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40028321</person_id>
				<author_profile_id><![CDATA[81100534488]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Thalmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[AntZ movie, homepage, http://www.pdi.com/feature/antz.htm]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>171179</ref_obj_id>
				<ref_obj_pid>171174</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Arbib MA, Lee HB (1993) Anuran visuomotor coordination for detour behaviour: from retina to motor schemas. In: Meyer JA, Roitblat HL, Wilson SW (eds) From Animals to Animats II. Cambridge, MA: MIT Press, pp 42--51]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Arkin RA (1990) Integrating behavioral, perceptual and world knowledge in reactive navigation. In: Maes P (ed) Designing Autonomous Agents. Cambridge, MA: MIT Press, pp 105--122]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Benesch H (1995) Atlas de la Psychologie. Encyclop&#233;dies d'Aujourd'hui]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bottaci L (1995) A Direct Manipulation Interface for a User Enhanceable Crowd Simulator. Journal Of Intelligent Systems, 5(2--4), pp 249--272]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>261156</ref_obj_id>
				<ref_obj_pid>261135</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Boulic R, Becheiraz P, Emering L, Thalmann D (1997) Integration of Motion Control Techniques for Virtual Human and Avatar Real-Time Animation. In: Proc. VRST '97. ACM Press, pp 111--118]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Bouvier E, Cohen E, Najman L (1997) From crowd simulation to airbag deployment: particle systems, a new paradigm of simulation. Journal of Electrical Imaging 6(1): 94--107, January, 1997]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276045</ref_obj_id>
				<ref_obj_pid>276034</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Bouvier E, Guilloteau P (1996) Crowd Simulation in Immersive Space Management. In: Proc. Eurographics Workshop on Virtual Environments and Scientific Visualization '96. Springer-Verlag, pp 104--110]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>591449</ref_obj_id>
				<ref_obj_pid>591438</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Brogan D, Hodgins J (1997) Group Behaviors for Systems with Significant Dynamics. Autonomous Robots, vol 4, pp. 137--153]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Character Studio 3 (2001) homepage, http://www.discreet.com/products/cs]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97900</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Coquillart S (1990) Extended Free-form Deformation: A Sculpturing Tool for 3D Geometric Modelin. Computer Graphics (SIGGRAPH '90 Proceedings), 24(4):187--196]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>217857</ref_obj_id>
				<ref_obj_pid>217853</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Cremer J, Kearney J, Papelis Y (1995) HCSM: Framework for Behavior and Scenario Control in Virtual Environments. ACM Transactions on Modeling and Computer Simulation 5(3):242--267]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Drogou LA, Ferber J (1994) Multi-agent simulation as a tool for studying emergent processes in societies. In: Gilbert N, Doran J (eds) Proceedings of Simulating Societies: the computer simulation of social phenomena. North-Holland]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Exodus, the evacuation model for the safety industry, homepage, http://fseg.gre.ac.uk/exodus/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Farenc N, Boulic R, Thalmann D (1999) An Informed Environment Dedicated to the Simulation of Virtual Humans in Urban Context. In: Proc. Eurographics'99. Blackwell, pp 309--318]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Gilbert N (1996) Simulation: an emergent perspective http://www.soc.surrey.ac.uk/research/simsoc/tutorial.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Giroux S (1996) Open Reflective Agents. In: Wooldridge M, Muller JP, Tambe M (eds), Intelligent Agents vol. II, Agent Theories, Architectures, and Languages. Springer-Verlag, LNAI (1037) Edition, pp 315--330]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Hareesh PV et al (2000) Evacuation Simulation: Visualisation Using Virtual Humans in a Distributed multi-user Immersive VR System. In: Proc. VSMM'00]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Helbing D, Farkas I, Vicsek T (2000) Simulating dynamical features of escape panic. Nature 407:487--490]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Hodgins J, Brogan D (1994) Robot Herds: Group Behaviors for Systems with Significant Dynamics. In: Proc. Artificial Life IV, pp 319--324]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Hosoi M, Ishijima S, Kojima A (1996) Dynamical Model of a Pedestrian in a Crowd. In: Proc. IEEE International Workshop on Robot and Human Communication]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Jager W, Popping R, van de Sande H (2001) Clustering and Fighting in Two-party Crowds: Simulating the Approach-avoidance Conflict. Journal of Artificial Societies and Social Simulation 4(3)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>791566</ref_obj_id>
				<ref_obj_pid>791217</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Kallmann M, Thalmann D (1999) A Behavioral Interface to Simulate Agent-Object Interactions in Real-Time. In: Proc. Computer Animation 99. IEEE Computer Society Press, pp 138--146]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Kalra D, Barr AH (1992) Modeling with Time and Events in Computer Animation. In: Proc. Eurographics'92. Blackwell, pp 45--58]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>723438</ref_obj_id>
				<ref_obj_pid>647298</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Kl&#252;pfel H, Meyer-K&#246;nig M, Wahle J, Schreckenberg M (2000) Microscopic Simulation of Evacuation Processes on Passenger Ships. In: Bandini S, Worsch T (eds) Theoretical and Practical Issues on Cellular Automata. Springer, London, pp 63--71]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237270</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Krishnamurthy V, Levoy M (1996) Fitting Smooth Surfaces to Dense Polygon Meshes. Computer Graphics (SIGGRAPH '96 Proceedings), pp 313--324]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[LeBon G (1895) Psychologie des Foules. Alcan, Paris]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199420</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Maciel P, Shirley P (1995) Visual Navigation of Large Environments using Textured Clusters. In: 1995 Symposium on Interactive 3D Graphics, pp 95--102]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[McPhail C (1991) The Myth of Madding Crowd. Aldine De Gruyter, NY]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[McPhail C, Powers WT, Tucker CW (1992) Simulating individual and collective actions in temporary gatherings. Social Science Computer Review 10(1): 1--28, Spring, 1992]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2225867</ref_obj_id>
				<ref_obj_pid>2225288</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Molnar P, Starke J (2001) Control of distributed autonomous robotic systems using principles of pattern formation in nature and pedestrian behavior. IEEE Trans. Syst. Man Cyb. B 31(3): 433--436, Jun, 2001]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Motivate product information, Motion Factory, http://www.motion-factory.com (acquired by http://www.softimage.com under name Softimage|RTK)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Musse SR (2000) Human Crowd Modelling with Various Levels of Behaviour Control. PhD thesis, EPFL, Lausanne]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614488</ref_obj_id>
				<ref_obj_pid>614282</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Musse SR, Thalmann D (2001) Hierarchical Model for Real Time Simulation of Virtual Human Crowds. IEEE Trans. on Visualization & Computer Graphics 7(2): 152--164, April-June, 2001]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Okazaki S, Matsushita S (1993) A Study of Simulation Model For Pedestrian Movement With Evacuation And Queuing. In: Proc. International Conference on Engineering for Crowd Safety]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Owen M, Galea ER, Lawrence PJ, Filippidis L. (1998) The numerical simulation of aircraft evacuation and its application to aircraft design and certification. The Aeronautical Journal, 102(1016): 301--312]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Parent R (2002) Computer Animation, Algorithms and Techniques. Morgan Kaufmann Publishers]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Penn A, Turner A, (2001) Space Syntax Based Agent Simulation. In: Schreckenberg M, Sharma SD (eds) Pedestrian and Evacuation Dynamics. Springer-Verlag, Berlin]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Powers WT (1973) The Control of Perception. Aldine, Chicago.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37406</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Reynolds CW (1987) Flocks, Herds, and Schools: A Distributed Behavioral Model. Computer Graphics 21(4) (SIGGRAPH '87 Conference Proceedings) pp. 25--34.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Robbins Ch (1999) Computer Simulation of Crowd Behaviour and Evacuation. ECMI Newsletter, No. 25, March 1999. http://www.it.lut.fi/fac/mat/EcmiNL/ecmi25/node5.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>562625</ref_obj_id>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Rosenbloom PS, Laird JE, Newell A (1993) The Soar papers: Research on Artificial Intelligence. MIT Press]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Saiwaki N, Komatsu T, Nishida S (1999) Automatic Generation of Moving Crowds in the Virtual Environments. In: Proc. AMCP'98, LNCS 1554, Springer-Verlag]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Sederberg T, Parry S (1986) Free-From Deformation of Solid Geometric Models. Computer Graphics (SIGGRAPH '86 Proceedings), pp 151--160]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>731976</ref_obj_id>
				<ref_obj_pid>647651</ref_obj_pid>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Schaufler G (1997) Nailboards: A Rendering Primitive for Image Caching in Dynamic Scenes. In: Proc. of 8th Eurographics Workshop'97 on Rendering, St. Etienne, France, pp. 151--162]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Schaufler G, St&#252;rzlinger W (1996) A Three Dimensional Image Cache for virtual reality. In: Proc. Eurographics'96, pp C-227--C-234]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Schweingruber D (1995) A Computer Simulation of a Sociological Experiment. Social Science Computer Review 13(3):351--359]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>792824</ref_obj_id>
				<ref_obj_pid>792755</ref_obj_pid>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[Shen J, Chauvineau E, Thalmann D (1996) Fast Realistic Human Body Deformations for Animation and VR Applications. In: Proc. Computer Graphics International'96, pp 166--173]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[Simulex, evacuation modeling software, product information, http://www.ies4d.com/products/4DPerformanceAssessmentTools/simulex/simulex.htm]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>50</ref_seq_no>
				<ref_text><![CDATA[Smelser N (1962) Theory of collective behavior. Routledge & Keganpaul, London]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280878</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>51</ref_seq_no>
				<ref_text><![CDATA[Snyder J, Lengyel J (1998) Visibility Sorting and Compositing without Splitting for Image Layer Decompositions. In: SIGGRAPH'98 proceedings, pp 219--229]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>52</ref_seq_no>
				<ref_text><![CDATA[Sommer R (1979) Personal Space. Englewood Cliffs, Prentice Hall]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>53</ref_seq_no>
				<ref_text><![CDATA[STEPS, Simulation of Transient Evacuation and Pedestrian movements, http://www.fusion2.mottmac.com/html/06/06_01.cfm]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>54</ref_seq_no>
				<ref_text><![CDATA[Still GK (2000) Crowd Dynamics. PhD thesis, Warwick University]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>55</ref_seq_no>
				<ref_text><![CDATA[Takahashi T, Shiizuka H (1992) Refuge Behavior Simulation by Network Model. Memoirs of Kougakuin University, No 73, pp 213--220, October 1992]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732276</ref_obj_id>
				<ref_obj_pid>647652</ref_obj_pid>
				<ref_seq_no>56</ref_seq_no>
				<ref_text><![CDATA[Tecchia F, Chrysanthou Y (2000) Real-Time Rendering of Densely Populated Urban Environments. In: Proc. Eurographics Rendering Workshop]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>57</ref_seq_no>
				<ref_text><![CDATA[Thompson PA, Marchant EW (1995) A Computer-model for the Evacuation of Large Building Population. Fire Safety Journal 24(2): 131--148]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237274</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>58</ref_seq_no>
				<ref_text><![CDATA[Torborg J, Kajiya J (1996) Talisman: Commodity Real-time 3D Graphics for the PC. In: SIGGRAPH '96 Proceedings, pp. 353--363]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>261143</ref_obj_id>
				<ref_obj_pid>261135</ref_obj_pid>
				<ref_seq_no>59</ref_seq_no>
				<ref_text><![CDATA[Tromp J, Snowdon D (1997) Virtual Body Language: Providing appropriate user interfaces in collaborative virtual environments. In: Proc. Symposium on Virtual Reality Software and Technology 1997 (VRST'97) September 15--17, 1997, Swiss Federal Institute of Technology (EPFL), Lausanne, Switzerland.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>324027</ref_obj_id>
				<ref_obj_pid>324013</ref_obj_pid>
				<ref_seq_no>60</ref_seq_no>
				<ref_text><![CDATA[Tucker CW, Schweingruber D, McPhail C (1999) Simulating arcs and rings in temporary gatherings. International Journal of Human-Computer Systems, vol 50, pp 581--588]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>776365</ref_obj_id>
				<ref_obj_pid>776350</ref_obj_pid>
				<ref_seq_no>61</ref_seq_no>
				<ref_text><![CDATA[Ulicny B, Thalmann D (2001) Crowd simulation for interactive virtual environments and VR training systems. In: Proc. Eurographics Workshop on Animation and Simulation'01, Springer-Verlag]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>62</ref_seq_no>
				<ref_text><![CDATA[Varner D, Scott DR, Micheletti J, Aicella G (1998) UMSC Small Unit Leader Non-Lethal Trainer. In: Proc. ITEC'98]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>107217</ref_obj_id>
				<ref_seq_no>63</ref_seq_no>
				<ref_text><![CDATA[Watt A, Watt M (1992) Advanced Animation and Rendering Techniques. Addison-Wesley, Second edn.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>64</ref_seq_no>
				<ref_text><![CDATA[Williams JR (1995) A Simulation Environment to Support Training for Large Scale Command and Control Task. PhD thesis, University of Leeds]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198673</article_id>
		<sort_key>3</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Crowdbrush]]></title>
		<subtitle><![CDATA[interactive authoring of real-time crowd scenes]]></subtitle>
		<page_from>3</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198673</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198673</url>
		<abstract>
			<par><![CDATA[Recent advances in computer graphics techniques and increasing power of graphics hardware made it possible to display and animate large crowds in real-time. Most of the research efforts have been directed towards improving rendering or behavior control; the question how to author crowd scenes in an efficient way is usually not addressed. We introduce a novel approach to create complex scenes involving thousands of animated individuals in a simple and intuitive way. By employing a brush metaphor, analogous to the tools used in image manipulation programs, we can distribute, modify and control crowd members in real-time with immediate visual feedback. We define concepts of operators and instance properties that allow to create and manage variety in populations of virtual humans. An efficient technique allowing to render up to several thousands of fully three-dimensional polygonal characters with keyframed animations at interactive framerates is presented. The potential of our approach is demonstrated by authoring a scenario of a virtual audience in a theater and a scenario of a pedestrian crowd in a city.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P511584</person_id>
				<author_profile_id><![CDATA[81100064298]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Branislav]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ulicny]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Virtual Reality Lab, EPFL, Switzerland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P837815</person_id>
				<author_profile_id><![CDATA[81322491880]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Pablo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[de Heras Ciechomski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Virtual Reality Lab, EPFL, Switzerland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40028321</person_id>
				<author_profile_id><![CDATA[81100534488]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Thalmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Virtual Reality Lab, EPFL, Switzerland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{3DS04} 3ds max, 2004. http://www.discreet.com/3dsmax. 6]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>846317</ref_obj_id>
				<ref_obj_pid>846276</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{AMC03} Anderson M., MCDANIEL E., CHENNEY S.: Constrained animation of flocks. In Proc. ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA '03) (2003), pp. 286--297. 1]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>288574</ref_obj_id>
				<ref_obj_pid>288392</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{Bau98} BAUDISCH P.: Don't click, paint! Using toggle maps to manipulate sets of toggle switches. In Proc. UIST '98 (1998), pp. 65--66. 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{BP304} Bones Pro 3, 2004. http://www.digimation.com. 6]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{CS04} Character Studio, 2004. http://www.discreet.com/products/cs. 1]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{GBO04} Gamebryo, game engine, 2004. http://www.ndl.com. 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97903</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{HH90} Hanrahan P., Haeberli P. E.: Direct WYSIWYG painting and texturing on 3D shapes. In Proc. SIGGRAPH '90 (1990), pp. 215--223. 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{HM95} Helbing D., Molnar P.: Social force model for pedestrian dynamics. Phys. Rev. E 51 (1995), 4282--4286. 5]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566648</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{KMM*02} Kalnins R. D., Markosian L., Meier B. J., Kowalski M. A., LEE J. C., Davidson P. L., Webb M., Hughes J. F., Finkelstein A.: WYSIWYG NPR: Drawing strokes directly on 3D models. In Proc. SIGGRAPH'02 (2002), pp. 755--762. 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{Lan99} Lander J.: Over my dead, polygonal body. Game Developer Magazine (May 1999), 1--4.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{Mas03} Massive, crowd animation software for visual effects, 2003. http://www.massivesoftware.com. 1]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{MAY04} Maya, 2004. http://www.alias.com/maya. 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614488</ref_obj_id>
				<ref_obj_pid>614282</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{MT01} Musse S. R., Thalmann D.: A hierarchical model for real time simulation of virtual human crowds. IEEE Transactions on Visualization and Computer Graphics 7, 2 (April-June 2001), 152--164. 4]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{OSG04} OpenSceneGraph, 2004. http://www.openscenegraph.org. 6, 8]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280825</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{PHL*98} Pighin F., Hecker J., Lischinski D., Szeliski R., Salesin D. H.: Synthesizing realistic facial expressions from photographs. In Proc. SIGGRAPH '98 (1998). 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{PPM*02} Ponder M., Papagiannakis G., Molet T., Magnenat-Thalmann N., Thalmann D.: VHD++ real-time development framework architecture: Building flexible and extendible VR/AR systems with reusable components. In Proc. Computer Graphics International 2002 (2002). 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[{Qua96} Quake, game homepage, 1996. http://www.idsoftware.com/games/quake/quake. 5]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37406</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[{Rey87} Reynolds C. W.: Flocks, herds, and schools: A distributed behavioral model. In Proc. SIGGRAPH '87 (1987), pp. 25--34. 1]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[{Rey00} Reynolds C. W.: Interaction with groups of autonomous characters. In Proc. Game Developpers Conference '00 (2000), pp. 449--460. 5]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[{RWS04} RenderWare Studio, game development platform, 2004. http://www.renderware.com/renderwarestudio.html. 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>214378</ref_obj_id>
				<ref_obj_pid>169728</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[{SB93} Salesin D., Barzel R.: Adjustable tools: An object-oriented interaction metaphor. ACM Transactions on Graphics 12, 1 (1993), 103--107. 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[{SIB04} Softimage XSI Behavior, 2004. http://www.softimage.com/products/behavior. 1]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>940748</ref_obj_id>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[{SWND03} Shreiner D., Woo M., Neider J., Davis T.: OpenGL Programming Guide: The Official Guide to Learning OpenGL, Version 1.4. Addison-Wesley, 2003. 6]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618887</ref_obj_id>
				<ref_obj_pid>616075</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[{TLC02} Tecchia F., Loscos C., Chrysanthou Y.: Image-based crowd rendering. IEEE Computer Graphics and Applications 22, 2 (March-April 2002), 36--43. 1, 5, 9]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[{Tob03} Tobita H.: VelvetPath - layout design system with sketch and paint manipulations. In Proc. Eurographics '03 Short Presentations (2003). 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[{UT02} Ulicny B., Thalmann D.: Towards interactive real-time crowd behavior simulation. Computer Graphics Forum 21, 4 (Dec. 2002), 767--775. 4]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[{Wol02} Wolfram S.: A New Kind of Science. Wolfram Media, Inc., 2002. 1]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[{WS02} Wand M., Strasser W.: Multi-resolution rendering of complex animated scenes. Computer Graphics Forum 21, 3 (2002). (Proc. Eurographics'02). 1, 5]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[{XLTP03} Xu S., Lau F. C. M., Tang F., Pan Y.: Advanced design for a realistic virtual brush. Computer Graphics Forum 22, 3 (2003), 533--542. (Proc. Eurographics'03). 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237238</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[{ZHH96} Zeleznik R. C., Herndon K. P., Hughes J. F.: SKETCH: An interface for sketching 3D scenes. In Proc. SIGGRAPH '96 (1996), pp. 163--170. 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198674</article_id>
		<sort_key>4</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[A case study of a virtual audience in a reconstruction of an ancient Roman Odeon in Aphrodisias]]></title>
		<page_from>4</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198674</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198674</url>
		<abstract>
			<par><![CDATA[The benefits of including virtual humans into cultural heritage reconstructions are twofold: the realism of architectural models is increased by populating them; and, as well, it allows to preserve the intangible heritage describing how people in historical times behaved. We present a case study, where we create an interactive real-time scenario of a virtual audience in an ancient Roman odeon in Aphrodisias. Based on historical sources, we reconstruct both the building and the people. Inhabited virtual heritage applications require careful balancing of computational resources between the visualization of environment and the visualization of people. We describe several techniques that allow us to achieve high visual quality for a large number of virtual humans rendered together with a complex architectural model while still keeping interactive framerates. An important part of the heritage recontruction is the authoring, we propose a comprehensive framework for authoring of crowd scenarios.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P837811</person_id>
				<author_profile_id><![CDATA[81100506574]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cain]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39056534</person_id>
				<author_profile_id><![CDATA[81100561258]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Y.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chrysanthou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P837804</person_id>
				<author_profile_id><![CDATA[81322506493]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[F.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Silberman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{3DS04} 3ds max, 2004. http://www.discreet.com/3dsmax. 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{Cro02} CROOM A. T.: Roman clothing and fashion. Tempus Publishing, 2002. 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{DeL99} Deleon V. J.: VRND: NOTRE-DAME CATHEDRAL: A globally accessible multiuser real-time virtual reconstruction. In Proc. Virtual Systems and Multimedia 1999 (1999). 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{Eri86} Erim K. T.: Aphrodisias: city of Venus Aphrodite. Muller Blond & White, London, 1986. 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>245626</ref_obj_id>
				<ref_obj_pid>244979</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{ESV96} Evans F., Skiena S., Varshney A.: Optimizing triangle strips for fast rendering. In IEEE VISUALIZATION '96 (1996), pp. 319--326. 6]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{FLKB01} Fr&OElig;hlich T., LUTZ B., KRESSE W., BEHR J.: The virtual cathedral of Siena. Computer Graphik topics 3 (2001). 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{FPMT02} Foni A., Papagiannakis G., Magnenat-Thalmann N.: Virtual Hagia Sophia: Restitution, visualization and virtual life simulation. In Proc. UNESCO World Heritage Congress (October 2002). 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258849</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{GH97} Garland M., Heckbert P.: Surface simplification using quadric error metrics. In Proc. SIGGRAPH '97 (1997), pp. 209--216. 5]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{HLTC03} He&#239;geas L., Luciani A., Thollot J., Castagn&#233; N.: A physically-based particle model of emergent crowd behaviors. In Proc. Graphikon '03 (2003). 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311565</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{Hop99} Hoppe H.: Optimization of mesh locality for transparent vertex caching. In Proc. SIGGRAPH '99 (1999), pp. 269--276. 6]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{Ize92} Izenour G.: Roofed theaters of Classical Antiquity. Yale University Press, New Haven & London, 1992. 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{Kin79} Kindermann H.: Das Theater Publikum der Antike. Otto M&#252;ller, Salzburg, 1979. 3, 4, 7]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{MTPM97} Magnenat-Thalmann N., Pandzic I. S., Moussaly J.-C.: The making of the terracotta Xian soldiers. Digital Creativity 8, 2 (1997), 66--73. 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{PFMT03} Papagiannakis G., Foni A., Magnenat-Thalmann N.: Real-time recreated ceremonies in vr restituted cultural heritage sites. In Proc. CIPA '03 (2003). 2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>884797</ref_obj_id>
				<ref_obj_pid>882502</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{PLFMT01} Papagiannakis G., L'Hoste G., Foni A., Magnenat-Thalmann N.: Real-time photo realistic simulation of complex heritage edifices. In Proc. Virtual Systems and Multimedia 2001 (2001), pp. 218--227. 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{SCGK03} Shreiner D., Commike A., Grantham B., Kuehne B.: Performance OpenGL: Platform independent techniques. In SIGGRAPH '03 Course (2003). 5]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[{Sym87} Symons D. J.: Costume of Ancient Rome. Chelsea House, New York, 1987. 3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1028555</ref_obj_id>
				<ref_obj_pid>1028523</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[{UdHCT04} Ulicny B., De Heras Ciechomski P., Thalmann D.: Crowdbrush: Interactive authoring of real-time crowd scenes. In Proc. ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA'03) (2004), pp. 243--252. 4, 7, 8]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[{UT02} Ulicny B., Thalmann D.: Crowd simulation for virtual heritage. In Proc. First International Workshop on 3d Virtual Heritage (Geneva, 2002), pp. 28--32. 2, 4]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198675</article_id>
		<sort_key>5</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Autonomy]]></title>
		<page_from>5</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198675</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198675</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40031406</person_id>
				<author_profile_id><![CDATA[81322507523]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Thalmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198676</article_id>
		<sort_key>6</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Crowds in Madagascar]]></title>
		<page_from>6</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198676</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198676</url>
		<abstract>
			<par><![CDATA[In <i>Madagascar</i>, crowds here created using PDI/Dream Works' proprietary mob system. The mob system allows a large crowd to be built by combining a small number of cycle-based animations with small numbers of character types, body types, hair/fur styles, clothing styles, hat styles, materials, colors, behaviors, and so on, in addition to customizations for final tweaking. Assignment of these features, as well as placement of the characters and their direction of motion, can be controlled and simultaneously randomized.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP24032987</person_id>
				<author_profile_id><![CDATA[81322497424]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Laurent]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kermel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Feature Effects Lead, PDI/DreamWorks]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198677</section_id>
		<sort_key>16</sort_key>
		<section_seq_no>16</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Video-based rendering]]></section_title>
		<section_page_from>16</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP39057002</person_id>
				<author_profile_id><![CDATA[81100477906]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Marcus]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Magnor]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>PP39057159</person_id>
				<author_profile_id><![CDATA[81100638521]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Marc]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pollefeys]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198678</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Video-based rendering]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198678</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198678</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39056992</person_id>
				<author_profile_id><![CDATA[81100477906]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Marcus]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Magnor]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MPI Informatik]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39051936</person_id>
				<author_profile_id><![CDATA[81100638521]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Marc]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pollefeys]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24030083</person_id>
				<author_profile_id><![CDATA[81538902356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[German]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cheung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Neven Vision Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40031264</person_id>
				<author_profile_id><![CDATA[81100458116]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Wojciech]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Matusik]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratory (MERL)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39061470</person_id>
				<author_profile_id><![CDATA[81331505042]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Christian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Theobalt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MPI Informatik]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198679</section_id>
		<sort_key>17</sort_key>
		<section_seq_no>17</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Acting and movement for animators: students, teachers, and professionals]]></section_title>
		<section_page_from>17</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP24042089</person_id>
				<author_profile_id><![CDATA[81452607137]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Finnegan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198680</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Acting for animators]]></title>
		<subtitle><![CDATA[students, teachers and professionals]]></subtitle>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198680</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198680</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP24009647</person_id>
				<author_profile_id><![CDATA[81452607140]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Finnegan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Purdue University School of Technology at South Bend]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24032331</person_id>
				<author_profile_id><![CDATA[81100470505]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ed]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hooks]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Adler, Stella, The Technique of Acting, Bantam Books]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Black, Lendley C., Mikhail Checkov as Actor, Director, and Teacher, UMI Research Press]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bruder, Melissa et al, A Practical Handbook for the Actor, Vintage Books, Random House]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Checkov, Michael, To The Actor, Harper and Row]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cohen, Robert, Acting One, Mayfield Publishing]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cohen, Robert, Acting Power, Mayfield Publishing]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Hooks, Ed, Acting for Animators, Heinemann]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[O'Neill, Rosemary, The Actor's Checklist, Harcourt, Brace, Jovanovich]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Spolin, Viola, Theater Games for Rehearsal: A Director's Handbook]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Suzuki, Tadashi, The Way of Acting, Theater Communications Group Animation:]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Whitaker, Harold & Halas, John, Timing for Animation. Focal Press]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[White, Tony, The Animator's Workbook, Watson, Guptill]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Williams, Richard, The Animator's Survival Kit, Faber and Faber]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198681</section_id>
		<sort_key>18</sort_key>
		<section_seq_no>18</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Pre-computed radiance transfer: theory and practice]]></section_title>
		<section_page_from>18</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP40031538</person_id>
				<author_profile_id><![CDATA[81100016395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kautz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>PP42054557</person_id>
				<author_profile_id><![CDATA[81339512060]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jaakko]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lehtinen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>P225694</person_id>
				<author_profile_id><![CDATA[81100524617]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Peter-Pike]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sloan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198682</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Precomputed radiance transfer]]></title>
		<subtitle><![CDATA[theory and practice]]></subtitle>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198682</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198682</url>
		<abstract>
			<par><![CDATA[Interactive rendering of realistic objects under general lighting models poses three principal challenges. Handling complex light transport phenomena like shadows, inter-reflections, caustics and sub-surface scattering is difficult to do in real time. Integrating these effects over large area light sources compounds the difficulty, and finally real objects have complex spatially-varying BRDF's. Precomputed Radiance Transfer (PRT) encapsulates a family of techniques that partially addresses these challenges. PRT is an active of area of research that has relevance to both the academic research community and practitioners of interactive computer graphics. This technique and its variants are being actively investigated in the game development community and there is quite a lot of interest due to the recent appearance of PRT techniques in games such as "Halo 2".This course covers these techniques, compares them and discusses their various strengths and weaknesses. A more rigorous derivation directly from the rendering equation is presented along with practical implementation details, both of which are generally not included in technical papers. After introducing the necessary foundation (rendering equation, basis functions, etc.), we begin with simple PRT for diffuse objects. We continue with general PRT using the concept of transfer matrices, which allow for arbitrary reflectance models. The possible choices for basis functions are discussed as well. Different light source representations are presented and compared. Finally, we discuss practical issues with PRT, such as data compression, spatial sampling, normal mapping, precomputation, and more. By the end of the course the audience will be able to pick the right algorithm for their needs and will hopefully have gained some of the unpublished insights the speakers have gained by working in this area.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40022745</person_id>
				<author_profile_id><![CDATA[81100016395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kautz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Massachusetts Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P225694</person_id>
				<author_profile_id><![CDATA[81100524617]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Peter-Pike]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sloan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42051030</person_id>
				<author_profile_id><![CDATA[81339512060]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jaakko]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lehtinen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Helsinki University of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>91416</ref_obj_id>
				<ref_obj_pid>91385</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{Airey90} J. Airey, J. Rohlf, F. Brooks, Jr. Towards image realism with interactive update rates in complex virtual building environments. In Proceedings of the 1990 Symposium on Interactive 3D Graphics, pp. 41--50, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383578</ref_obj_id>
				<ref_obj_pid>2383533</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{Annen05} T. Annen, J. Kautz, F. Durand, H.-P. Seidel. Spherical Harmonic Gradients for Mid-Range Illumination. In Proceedings Eurographics Symposium on Rendering 2004. June 2004, pages 331--336.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>504790</ref_obj_id>
				<ref_obj_pid>504789</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{Ashikhmin02} M. Ashikhmin, P. Shirley. Steerable illumination textures. ACM Transactions on Graphics 21(1), pp. 1--19, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566601</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{Chen02} W.-C. Chen, J.-Y. Bouguet, M. Chu, R. Grzeszczuk. Light field mapping: efficient representation and hardware rendering of surface light fields. ACM Transactions on Graphics 21(3), pp. 447--456, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122723</ref_obj_id>
				<ref_obj_pid>122718</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{Dorsey92} J. Dorsey, F. Sillion, D. Greenberg. Design and simulation of opera lighting and projection effects. In Proceedings of ACM SIGGRAPH 91, pp. 41--50, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383577</ref_obj_id>
				<ref_obj_pid>2383533</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{Gautron04} P. Gautron, J. Krivanek, S. Pattanaik, K. Bouatouch. A Novel Hemispherical Basis for Accurate and Efficient Rendering. In Proceedings of Eurographics Symposium on Rendering 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>641497</ref_obj_id>
				<ref_obj_pid>641480</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{Hao03} X. Hao, T. Baby, A. Varshney. Interactive subsurface scattering for translucent meshes. In Proceedings of the 2003 symposium on Interactive 3D graphics, pp. 75--82, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>641497</ref_obj_id>
				<ref_obj_pid>641480</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{Hao03} X. Hao, T. Baby, and A. Varshney, "Interactive Subsurface Scattering for Translucent Meshes", ACM Symposium on Interactive 3D Graphics April 28--30, 2003, Monterey, CA, pp. 75--82.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383838</ref_obj_id>
				<ref_obj_pid>2383815</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{Kautz99} J. Kautz, M. McCool. Interactive Rendering with Arbitrary BRDFs using Separable Approximations. In Proceedings of the 10th Eurographics Workshop on Rendering, pp. 281--292, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>581934</ref_obj_id>
				<ref_obj_pid>581896</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{Kautz02} J. Kautz, P.-P. Sloan, J. Snyder. Fast, arbitrary BRDF shading for low-frequency lighting using spherical harmonics. In Proceedings of the 13th Eurographics workshop on Rendering, pp. 291--296, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>641495</ref_obj_id>
				<ref_obj_pid>641480</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{Lehtinen03} J. Lehtinen, J. Kautz. Matrix Radiance Transfer. In Proceedings of the 2003 ACM SIGGRAPH Symposium on Interactive 3D Graphics, pp. 59--64, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383579</ref_obj_id>
				<ref_obj_pid>2383533</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{Liu04} X. Liu, P.-P. Sloan, H.-Y. Shum, J. Snyder. All-Frequency Precomputed Radiance Transfer for Glossy Objects. In Proceedings of the Eurographics Symposium on Rendering 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566599</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{Matusik02} Matusik, W., H. Pfister, A. Ngan, P. Beardsley, R. Ziegler, L. McMillan. "Image-based 3D Photography using Opacity Hulls." In Proceedings of SIGGRAPH 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{Miller98} Miller, Gavin S. P., Steven M. Rubin, Dulce Ponceleon, "Lazy Decompression of Surface Light Fields for Precomputed Global Illumination", Proceedings of the 9th Eurographics Workshop on Rendering, Vienna, Austria, June 29th - July 1st, 1998]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{Mueller03} G. M&#252;ller, J. Meseth, R. Klein "Compression and Real-Time Rendering of Measured BTFs Using Local PCA", Vision, Modeling and Visualisation 2003]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1009594</ref_obj_id>
				<ref_obj_pid>1009379</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{Muller04} G. M&#252;ller, J. Meseth, R. Klein, "Fast Environmental Lighting for Local-PCA Encoded BTFs", Computer Graphics International 2004]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882280</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[{Ng03} R. Ng, R. Ramamoorthi, P. Hanrahan. All-frequency shadows using non-linear wavelet lighting approximation. ACM Transaction on Graphics 22(3), pp. 376--381, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015749</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[{Ng04} R. Ng, R. Ramamoorthi, P. Hanrahahan. Triple product wavelet integrals for all-frequency relighting. ACM Transactions on Graphics 23(3), pp. 477--487, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[{Nimeroff94} J. Nimeroff, E. Simoncelli, J. Dorsey. Efficient Re-rendering of Naturally Illuminated Environments. In Proceedings of the Fifth Eurographics Workshop on Rendering, pp. 359--373, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[{Nishino99} K. Nishino, Y. Sato and K. Ikeuchi, "Eigen-Texture Method: Appearance Compression based on 3D Model", in Proc. of Computer Vision and Pattern Recognition CVPR '99, vol.1, pp618--624, Jun., 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383271</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[{Ramamoorthi01} R. Ramamoorthi, P. Hanrahan. A signal-processing framework for inverse rendering. In Proceedings of SIGGRAPH 2001, pp. 117--128, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566612</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[{Sloan02} P.-P. Sloan, J. Kautz, J. Snyder. Precomputed radiance transfer for real-time rendering in dynamic, low-frequency lighting environments. ACM Transactions on Graphics 21(3), pp. 527--369, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882279</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[{Sloan03BRT} P.-P. Sloan, X. Liu, H.-Y. Shum, J. Snyder. Bi-scale Radiance Transfer. ACM Transaction on Graphics 22(3), pp. 370--375, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882281</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[{Sloan03CPC} P.-P. Sloan, J. Hall, J. Hart, J. Snyder. Clustered principal components for precomputed radiance transfer. ACM Transactions on Graphics 22(3), pp. 382--391, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>892215</ref_obj_id>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[{Teo97} P. Teo, E. Simoncelli, D. Heeger. Efficient Linear Re-rendering for Interactive Lighting Design. Technical Report CS-TN-97-60, Stanford University, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383580</ref_obj_id>
				<ref_obj_pid>2383533</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[{Wang04} R. Wang, J. Tran, D. Luebke. All-Frequency Relighting of Non-Diffuse Objects using Separable BRDF Approximation. In Proceedings of the Eurographics Symposium on Rendering 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134075</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[{Westin92} S. Westin, J. Arvo, K. Torrance. Predicting reflectance functions from complex surfaces. In Proceedings of SIGGRAPH 92, pp. 255--264, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344925</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[{Wood00} Daniel Wood, Daniel Azuma, Wyvern Aldinger, Brian Curless, Tom Duchamp, David Salesin, Werner Stuetzle, "Surface Light Fields for 3D Photography", In Proceedings of SIGGRAPH 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073332</ref_obj_id>
				<ref_obj_pid>1186822</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[{Zhou05} K. Zhou, Y. Hu, S. Lin, B. Guo, H.-Y. Shum, "Precomputed Shadow Fields for Dynamic Scenes", In Proceedings Siggraph 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198683</section_id>
		<sort_key>19</sort_key>
		<section_seq_no>19</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Performance OpenGL: platform independent techniques]]></section_title>
		<section_page_from>19</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP24044651</person_id>
				<author_profile_id><![CDATA[81309505785]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bob]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kuehne]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>PP39057336</person_id>
				<author_profile_id><![CDATA[81322506343]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dave]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shreiner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198684</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Performance OpenGL]]></title>
		<subtitle><![CDATA[platform independent techniques]]></subtitle>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198684</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198684</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP24033593</person_id>
				<author_profile_id><![CDATA[81309505785]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bob]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kuehne]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24047376</person_id>
				<author_profile_id><![CDATA[81322508396]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tom]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[True]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P837792</person_id>
				<author_profile_id><![CDATA[81322491090]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Alan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Commike]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39057361</person_id>
				<author_profile_id><![CDATA[81322506343]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Dave]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shreiner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[ARB and Dave Shreiner, editors. The OpenGL Reference Manual. Addison-Wesley, fourth edition, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[The OpenGL Architecture Review Board. The GL_ARB_fragment_program specification. The OpenGL Architecture Review Board, 2003. http://oss.sgi.com/projects/ogl-sample/registry/ARB/fragment_program.txt.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[The OpenGL Architecture Review Board. The GL_ARB_vertex_program specification. The OpenGL Architecture Review Board, 2003. http://oss.sgi.com/projects/ogl-sample/registry/ARB/vertex_program.txt.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>186897</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides. Design Patterns: Elements of Reusable Object-Oriented Software. Addison-Wesley, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Silicon Graphics Computer Systems Inc. The OpenGL Sample Implementation. http://oss.sgi.com/projects/ogl-sample.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Mark Segal, Kurt Akeley, and Jon Leech. The OpenGL Graphics System: A Specification (Version 1.4). Silicon Graphics Computer Systems Inc., 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1199347</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Dave Shreiner, Mason Woo, Jackie Neider, and Tom Davis. The OpenGL Programming Guide: The Official Guide to Learning OpenGL. Addison-Wesley, fourth edition, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[OpenGL Programming Guide, 4thEdition Shreiner, Dave, et. al, Addison-Wesley]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>984432</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[OpenGL Reference Manual, 4th Edition OpenGL Architecture Review Board, Addison-Wesley]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1696393</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[OpenGL Shading Language, Rost, Randi, et. al, Addison Wesley]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[The Cg Tutorial, Fernando and Kilgard, Addison-Wesley]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[GPU Gems, Addison-Wesley]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[OpenGL Specification, Version 1.5 OpenGL Architecture Review Board]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[OpenGL Shading Language Specification, OpenGL Architectural Review Board]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198685</section_id>
		<sort_key>20</sort_key>
		<section_seq_no>20</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[An open-source CVE for programming education: a case study]]></section_title>
		<section_page_from>20</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP24046070</person_id>
				<author_profile_id><![CDATA[81100322033]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Phelps]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198686</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[An open-source CVE for programming education]]></title>
		<subtitle><![CDATA[a case study]]></subtitle>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198686</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198686</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P641817</person_id>
				<author_profile_id><![CDATA[81100322033]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Phelps]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[CASCI Laboratory for Graphical Simulation, Visualization & Virtual Worlds]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39056589</person_id>
				<author_profile_id><![CDATA[81100494587]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Christopher]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Egert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Mediated Experiences Group]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P641851</person_id>
				<author_profile_id><![CDATA[81100325624]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kevin]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Bierre]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Enterprise Computing Group]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24045871</person_id>
				<author_profile_id><![CDATA[81100290109]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Parks]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Entertainment Technology Lab]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>947143</ref_obj_id>
				<ref_obj_pid>947121</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Phelps, Andrew M., Kevin J Bierre and David M. Parks. "MUPPETS: multi-user programming pedagogy for enhancing traditional study", Proceedings of the 4th Conference on Information Technology Education. pp100--105. October 2003, Lafayette, Indianna. Available ACM Digital Library.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>971592</ref_obj_id>
				<ref_obj_pid>971564</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Phelps, Andrew M. and David M Parks. "Fun & Games With Multi-Language Development. ACM Queue, Vol 1, Issue 10, pp46--56. February 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1029564</ref_obj_id>
				<ref_obj_pid>1029533</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Phelps, Andrew M. and Kevin J Bierre. "The Use of MUPPETS in an Introductory Programming Course". Proceedings of the 5th Conference on Information Technology Education. pp122--127. October 2004, Salt Lake City, Utah. Available ACM Digital Library.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>544437</ref_obj_id>
				<ref_obj_pid>544414</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Alphonce, C. and Ventura, P., "Object orientation in CS1-CS2 by design", in Proceedings of the 32nd SIGCSE Technical Symposium on Computer Science Education, 2001, pp. 70--74.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>949391</ref_obj_id>
				<ref_obj_pid>949344</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Alphonce, C. and Ventura, P., "Using graphics to support the teaching of fundamental object-oriented principles in CS1", in Conference on Object Oriented Programming Systems Languages: Educator's Consortium Companion, 2003, pp. 156--161.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563397</ref_obj_id>
				<ref_obj_pid>563340</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Barnes, D, Teaching Introductory Java through LEGO MINDSTORMS Models, SIGCSE '02, Feb 27 - Mar 3, 2002, Covington, Kentucky, USA 147--151]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Baron, J., "Glory and shame: Powerful psychology in multiplayer online games", in Proceedings of the Computer Game Developer's Conference (GDC), 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Baum, D. Not Quite C compiler Online: http://www.baumfamily.org/nqc/index.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>364536</ref_obj_id>
				<ref_obj_pid>364447</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Becker, B, Teaching CS1 with Karel the Robot in Java, SIGCSE 2001, Feb 2001, Charlotte, NC, USA, 50--54]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>548005</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Bergin, J, Stehlik, M, Roberts, J, and Pattis, R, Karel++: A Gentile Introduction to the Art of Object-Oriented Programming, John Wiley & Sons, 1997]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1029564</ref_obj_id>
				<ref_obj_pid>1029533</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Bierre, K. J. and Phelps, A. M., "The use of MUPPETS in an introductory Java programming course", in Proceedings of the 5th Conference on Information Technology Education, 2004, pp. 122--127.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Bloom, B. S., Engelhart, M. D., Furst, E. J., Hill, W., and Krathwohl, D. R., Taxonomy of Educational Objectives - The Classification of Educational Goals: Handbook I: Cognitive Domain, 1956.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Borner, K, Smart Collaborative Content Access & Navigation (SC2 AN) Research Group. (2001) Indiana University. Online: http://scan.indiana.edu/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Br&#228;ndle, M. and Reichert, R. Kara: Online: http://www.eeduceth.ch/compscience/karatojava/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Bruckman, A., Can Educational Be Fun? (2000) Georgia Institute of Technology. Computer Game Developers Conference (GDC) Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Campbell, K., "The web: Designed for active learning", {Online}, http://www.atl.ualberta.ca/articles/idesign/activel.cfm]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>331888</ref_obj_id>
				<ref_obj_pid>330908</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Chase, J. D. and Okie, E. G., "Combining cooperative learning and peer instruction in introductory computer science", in Proceedings of the 31st SIGCSE Technical Symposium on Computer Science Education, 2000, pp. 372--376.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>332481</ref_obj_id>
				<ref_obj_pid>332040</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Conway, M., Audia, S., Burnette, T., Cosgrove, D., Christiansen, K., et al., "Alice: Lessons learned from building a 3D system for novices", in Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 2000, pp. 486--493.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>611966</ref_obj_id>
				<ref_obj_pid>611892</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Cooper, S., Dann, W., and Pausch, R., "Teaching objects-first in introductory computer science", in Proceedings of the 34th SIGCSE Technical Symposium on Computer Science Education, 2003, pp. 191--195.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Corbit, M., Jumping Genes. Cornell Theory Center (with RIT - IT Lab and other collaborators). Funded by the National Science Foundation, available under FastTrack.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>948820</ref_obj_id>
				<ref_obj_pid>948785</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Decker, A., "A tale of two paradigms", Journal of Computing Sciences in Colleges, Vol. 19, No. 2, 2003, pp. 238--246.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>191054</ref_obj_id>
				<ref_obj_pid>191029</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Decker, R. and Hirshfield, S., "The top 10 reasons why object-oriented programming can't be taught in CS 1", in Proceedings of the 25th SIGCSE Symposium on Computer Science Education, 1994, pp. 51--55.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Denton, L. F. and McKinney, D., "Affective factors and student achievement: A quantitative and qualitative study", in Proceedings of the 34th ASEE/IEEE Conference on Frontiers in Education, 2004, pp. T1G 6--11.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Denton, L. F., Doran, M. V., and McKinney, D., "Integrated use of Bloom and Maslow for instructional success in technical and scientific fields", in Proceeding of the American Society for Engineering Education Annual Conference and Exposition, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775755</ref_obj_id>
				<ref_obj_pid>775742</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Flowers, T, and Gossett, K, Teaching Problem Solving, Computing, and Information Technology with Robots, Journal of Computing in Small Colleges, 2002 17, 2, pg 45--55]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1026642</ref_obj_id>
				<ref_obj_pid>1026633</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Geigel, J. and Schweppe, M., "Theatrical storytelling in a virtual space", in Proceedings of the 1st ACM Workshop on Story Representation, Mechanism and Context, 2004, pp. 39--46.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>996052</ref_obj_id>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Gutschmidt, T., Game Programming with Python, Ruby, and Lua, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>505261</ref_obj_id>
				<ref_obj_pid>505248</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Guzdial, M. and Soloway, E., "Log on education" Teaching the Nintendo generation to program", Communications of the ACM, Vol. 45, No. 4, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>971341</ref_obj_id>
				<ref_obj_pid>971300</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Hansen, S., "The game of Set - An ideal example for introducing polymorphism and design patterns", in Proceedings of the 35th SIGCSE Technical Symposium on Computer Science Education, 2004, pp. 110--114.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Jenkins, T. On the Difficulty of Learning to Program. 3rd Annual LTSN-ICS Conference, Loughborough University, Leicestershire, UK, 2002, 53--58]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>363378</ref_obj_id>
				<ref_obj_pid>363361</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Kirner, T. G., Kirner, K., Kawamoto, A. L. S., Cant&#227;no, J., Pinto, A., et al., "Development of a collaborative virtual environment for educational applications", in Proceedings of the 6th Annual Conference on 3D Web Technology, 2001, pp. 61--68.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>377461</ref_obj_id>
				<ref_obj_pid>377435</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[K&#246;lling, M. and Rosenberg, J., "Guidelines for teaching object orienatation with Java", in Proceedings of the 6th Annual Conference on Innovation and Technology in Computer Science Education (ITiCSE), 2001, pp. 33--36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Krathwohl, D. R., Bloom, B. S., and Masia, B. B., Taxonomy of Educational Objectives - The Classification of Educational Goals: Handbook II: Affective Domain, 1964.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>948776</ref_obj_id>
				<ref_obj_pid>948737</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[LeJeune, N., "Critical components for successful collaborative learning in CS1", Journal of Computing Sciences in Colleges, Vol. 19, No. 1, 2003, pp. 275--285.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[IeJOS. Online: http://lejos.sourceforge.net]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1040199</ref_obj_id>
				<ref_obj_pid>1040196</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Leska, C. and Rabung, J., "Refactoring the CS1 course", Journal of Computing Sciences in Colleges, Vol. 20, No. 3, 2005, pp. 6--18.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>331863</ref_obj_id>
				<ref_obj_pid>330908</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Lewis, J., "Myths about object-orientation and its pedagogy", in Proceedings of the 31st SIGCSE Technical Symposium on Computer Science Education, 2000, pp. 245--249.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>359393</ref_obj_id>
				<ref_obj_pid>359369</ref_obj_pid>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Lister, R., "On blooming first year programming, and its blooming assessment", in Proceedings of the Australasian Conference on Computing Education, 2000, pp. 158--162.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Logo Foundation, "Logo Foundation Home Page", {Online}, http://el.media.mit.edu/logo-foundation/logo/index.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Marshall, P, Rogers, Y, and Scaife, M, PUPPET: playing and learning in a virtual world, http://www.cogs.susx.ac.uk/interact/papers/pdfs/Playing%20and%20Learning/Tangibles%20and%20virtual%20environments/Marshall_IJCEELL.pdf]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1047494</ref_obj_id>
				<ref_obj_pid>1047344</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[McKinney, D. and Denton, L. F., "Affective assessment of team skills in agile CS1 labs: The good, the bad, and the ugly", in Proceedings of the 36th SIGCSE Technical Symposium on Computer Science Education, 2005, pp. 465--469.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>971386</ref_obj_id>
				<ref_obj_pid>971300</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[McKinney, D. and Denton, L. F., "Houston, we have a problem. There's a leak in the CS1 affective oxygen tank", in Proceedings of the 35th SIGCSE Technical Symposium on Computer Science Education, 2004, pp. 236--239.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>369334</ref_obj_id>
				<ref_obj_pid>369279</ref_obj_pid>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Mitchell, W., "A paradigm shift to OOP has occurred.. Implemetation to follow", Journal of Computing Sciences in Colleges, Vol. 16, No. 2, 2001, pp. 95--106.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>971328</ref_obj_id>
				<ref_obj_pid>971300</ref_obj_pid>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Moskal, B., Lurie, D., and Cooper, S., "Evaluating the effectiveness of new instructional support", in Proceedings of the 35th SIGCSE Technical Symposium on Computer Science Education, 2004, pp. 75--79.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Nelson, M. Robocode: Online: http://robocode.alphaworks.ibm.com/home/home.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>979996</ref_obj_id>
				<ref_obj_pid>979968</ref_obj_pid>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Nevison, C. and Wells, B., "Using a maze case study to teach object-oriented programming and design patterns", in Proceedings of the 6th Conference on Australian Computing Education, 2004, pp. 207--215.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[NGP, "NGP Homepage", {Online}, http://www.cs.brown.edu/courses/cs015/2004/ref/ngp/home.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1024378</ref_obj_id>
				<ref_obj_pid>1024338</ref_obj_pid>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[Or-Bach, R. and Lavy, I., "Cognitive activities of abstraction in object orientation: An empirical study", ACM SIGCSE Bulletin, Vol. 36, No. 2, 2004, pp. 82--86.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[Papert, S., "Situating constructionism", in Constructionism: Research Reports and Essays 1985-1990, 1991, pp. 1--12.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>50</ref_seq_no>
				<ref_text><![CDATA[Pattis, R <u>Karel the Robot: A Gentle Introduction to the Art of Programming with Pascal</u>. 1981 John Wiley & Sons, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>51</ref_seq_no>
				<ref_text><![CDATA[Pattis, R. E., Karel the Robot: A Gentle Introduction to the Art of Programming with Pascal, 1981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>971592</ref_obj_id>
				<ref_obj_pid>971564</ref_obj_pid>
				<ref_seq_no>52</ref_seq_no>
				<ref_text><![CDATA[Phelps, A. M. and Parks, D. M., "Fun and games with multi-language development", QUEUE, Vol. 1, No. 10, 2004, pp. 2--12.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>947143</ref_obj_id>
				<ref_obj_pid>947121</ref_obj_pid>
				<ref_seq_no>53</ref_seq_no>
				<ref_text><![CDATA[Phelps, A. M., Bierre, K. J., and Parks, D. M., "MUPPETS: Multi-user programming pedagogy for enhancing traditional study", in Proceedings of the 4th Conference on Information Technology Curriculum, 2003, pp. 100--105.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>54</ref_seq_no>
				<ref_text><![CDATA[Powers, K. and Powers, D. T., "Making sense of the teaching methods in computing education", in Proceedings of the 29th ASEE/IEEE Conference on Frontiers in Education, 1999, pp. 11B3 30--35.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1150297</ref_obj_id>
				<ref_obj_pid>1150240</ref_obj_pid>
				<ref_seq_no>55</ref_seq_no>
				<ref_text><![CDATA[Puntambekar, S., "An integrated approach to individual and collaborative learning in a web-based learning environment", in Proceedings of the Computer Support for Collaborative Learning (CSCL), 1999, pp. 458--465.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>234762</ref_obj_id>
				<ref_obj_pid>234757</ref_obj_pid>
				<ref_seq_no>56</ref_seq_no>
				<ref_text><![CDATA[Resnick, M., Bruckman, A. and Martin, F., "Pianos not stereos: Creating computational construction kits", Interactions, Vol. 3, No. 6, 1996, pp. 40--50.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>57</ref_seq_no>
				<ref_text><![CDATA[Rheingold, H., <u>The Virtual Community</u>. (1993, revised edition 2000). Cambridge: Mass: The MIT Press. Pp 150--160.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>58</ref_seq_no>
				<ref_text><![CDATA[Rosenzweig, G., "Creating Web-Based Games", in Proceedings of the Computer Game Developer's Conference (GDC), 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>948775</ref_obj_id>
				<ref_obj_pid>948737</ref_obj_pid>
				<ref_seq_no>59</ref_seq_no>
				<ref_text><![CDATA[Scott, T., "Bloom's taxonomy applied to testing in computer science classes", Journal of Computing Sciences in Colleges, Vol. 19, No. 1, 2003, pp. 267--274.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>60</ref_seq_no>
				<ref_text><![CDATA[The Joint Task Force on Computing Curricula (IEEE/ACM), Computing Curriculum 2001 Computer Science -- Final Report, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>949392</ref_obj_id>
				<ref_obj_pid>949344</ref_obj_pid>
				<ref_seq_no>61</ref_seq_no>
				<ref_text><![CDATA[Towell, J and Towell, E, Reality Abstraction and OO Pedagogy: Results from 5 Weeks in Virtual Reality, OOPSLA '03 October 26-30, 2003, Anaheim, California, 162--165]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>62</ref_seq_no>
				<ref_text><![CDATA[Tucker, M. T., "Better games through psychology", in Proceedings of the Computer Game Developer's Conference (GDC), 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>63</ref_seq_no>
				<ref_text><![CDATA[Van Haaster, K. and Hagan, D., "Teaching and learning with BlueJ: An evaluation of pedagogical tool", in Informing Science and Information Technology Joint Conference, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>64</ref_seq_no>
				<ref_text><![CDATA[Varanese, A., Game Scripting Mastery, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>65</ref_seq_no>
				<ref_text><![CDATA[Ventura, P. R., On the Origins of Programmers: Identifying Predictors of Success for an Objects First CS1, 2003]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>66</ref_seq_no>
				<ref_text><![CDATA[VLearn 3D 2001 Online: http://www.vlearn3d.org/about/index.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>947132</ref_obj_id>
				<ref_obj_pid>947121</ref_obj_pid>
				<ref_seq_no>67</ref_seq_no>
				<ref_text><![CDATA[Whittington, K, Bills, D., and Hill, L, Implementation of alternative pacing in an introductory programming sequence, Proceedings of the 4th conference on Information technology education, October 2003, Lafayette, Indiana, USA, 47--53]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>68</ref_seq_no>
				<ref_text><![CDATA[Young, J., Virtual Reality Hailed as New Tool in Distance Education. Chronicle of Higher Education. (2000) Online: http://chronicle.merit.edu/free/v47/i06/06a04301.htm]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198687</section_id>
		<sort_key>21</sort_key>
		<section_seq_no>21</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Manifolds and modeling]]></section_title>
		<section_page_from>21</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP39056691</person_id>
				<author_profile_id><![CDATA[81100553787]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Cindy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Grimm]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>P65502</person_id>
				<author_profile_id><![CDATA[81100328351]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Denis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zorin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198688</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Surface modeling and parameterization with manifolds]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198688</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198688</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39054926</person_id>
				<author_profile_id><![CDATA[81100553787]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Cindy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Grimm]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Washington University in St. Louis]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P65502</person_id>
				<author_profile_id><![CDATA[81100328351]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Denis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zorin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[New York University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>377360</ref_obj_id>
				<ref_obj_pid>377340</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{BK01} Oscar P. Bruno and Leonid A. Kunyansky. A fast, high-order algorithm for the solution of surface scattering problems: basic implementation, tests, and applications. J. Comput. Phys., 169(1):80--110, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1057453</ref_obj_id>
				<ref_obj_pid>1057432</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{BMZ04} I. Boier-Martin and D. Zorin. Smooth parametrization of catmull-clark subdivision surfaces. In Eurographics/SIGGRAPH Symposium on Geometry Processing, pages 155--164, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{Bra03} Matthew Brand. Charting a manifold. Technical Report TR-2003-13, MERL: Mitsubishi Electric Research Laboratory, March 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{DCDS97} T. Duchamp, A. Certain, A. DeRose, and W. Stuetzle. Hierarchical computation of pl harmonic embeddings. Technical report, University of Washington, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280826</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{DKT98} Tony D. DeRose, Michael Kass, and Tien Truong. Subdivision surfaces in character animation. In Proceedings of SIGGRAPH 98, Computer Graphics Proceedings, Annual Conference Series, pages 85--94, July 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218440</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{EDD+95} Matthias Eck, Tony DeRose, Tom Duchamp, Hugues Hoppe, Michael Lounsbery, and Werner Stuetzle. Multiresolution analysis of arbitrary meshes. Proceedings of SIGGRAPH 95, pages 173--182, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237271</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{EH96} Matthias Eck and Hugues Hoppe. Automatic reconstruction of b-spline surfaces of arbitrary topological type. In Proceedings of SIGGRAPH 96, Computer Graphics Proceedings, Annual Conference Series, pages 325--334, August 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{FH05} M. S. Floater and K. Hormann. Surface parameterization: a tutorial and survey. In N. A. Dodgson, M. S. Floater, and M. A. Sabin, editors, Advances in Multiresolution for Geometric Modelling, Mathematics and Visualization, pages 157--186. Springer, Berlin, Heidelberg, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>172386</ref_obj_id>
				<ref_obj_pid>172372</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{FR93} H. Ferguson and A. Rockwood. Multiperiodic functions for surface design. Computer Aided Geometric Design, 10(3):315--328, August 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{GG83} Theodore Gamelin and Robert Greene. Introduction to Topology. Dover, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882276</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{GGS03} Craig Gotsman, Xianfeng Gu, and Alla Sheffer. Fundamentals of spherical parameterization for 3d meshes. ACM Transactions on Graphics, 22(3):358--363, July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{GGT04} S. J. Gortler, C. Gotsman, and D. Thurston. One-forms on meshes and applications to 3d mesh parameterization. Technical report, Harvard University, June 2004. TR-12-04.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{GH95} Cindy Grimm and John Hughes. Modeling surfaces of arbitrary topology using manifolds. Computer Graphics, 29(2), July 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{GH03} Cindy Grimm and John Hughes. Parameterizing n-holed tori. Mathematics of Surfaces X, pages 14--29, Sept. 17--19th 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{GLC02} Cindy Grimm, David Laidlaw, and Joseph Crisco. Fitting manifold surfaces to 3d point clouds. IEEE Transactions on Biomedical Engineering, 124:136--140, Feb 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{Gri02} Cindy Grimm. Simple manifolds for surface modeling and parameterization. Shape Modelling International, May 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[{GS05} Rob Glaubius and William D. Smart. Manifold representations for continuous-state reinforcement learning. Technical Report WUCSE-2005-19, Washington Univ. in St. Louis, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[{GVSS00} Igor Guskov, Kiril Vidimce, Wim Sweldens, and Peter Schr&#246;der. Normal meshes. In Proceedings of ACM SIGGRAPH 2000, Computer Graphics Proceedings, Annual Conference Series, pages 95--102, July 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882388</ref_obj_id>
				<ref_obj_pid>882370</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[{GY03} Xianfeng Gu and Shing-Tung Yau. Global conformal surface parameterization. In Proceedings of the Eurographics/ACM SIGGRAPH symposium on Geometry processing, pages 127--137. Eurographics Association, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614459</ref_obj_id>
				<ref_obj_pid>614278</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[{HAT+00} Steven Haker, Sigurd Angenent, Allen Tannenbaum, Ron Kikinis, Guillermo Sapiro, and Michael Halle. Conformal surface parameterization for texture mapping. IEEE Transactions on Visualization and Computer Graphics, 6(2):181--189, April - June 2000. ISSN 1077--2626.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>285310</ref_obj_id>
				<ref_obj_pid>285305</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[{HS98} Wolfgang Heidrich and Hans-Peter Seidel. View-independent environment maps. In 1998 SIGGRAPH / Eurographics Workshop on Graphics Hardware, pages 39--46, August 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311542</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[{JP99} Doug L. James and Dinesh K. Pai. Artdefo: accurate real time deformable objects. In Proceedings of the 26th annual conference on Computer graphics and interactive techniques, pages 65--72. ACM Press/Addison-Wesley Publishing Co., 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237270</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[{KL96} Venkat Krishnamurthy and Marc Levoy. Fitting smooth surfaces to dense polygon meshes. In Proceedings of SIGGRAPH 96, Computer Graphics Proceedings, Annual Conference Series, pages 313--324, August 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882275</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[{KLS03} Andrei Khodakovsky, Nathan Litke, and Peter Schr&#246;der. Globally smooth parameterizations with low distortion. ACM Transactions on Graphics, 22(3):350--357, July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383308</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[{Lev01} Bruno Levy. Constrained texture mapping for polygonal meshes. Computer graphics, pages 417--424, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614384</ref_obj_id>
				<ref_obj_pid>614268</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[{LF97} Paul Lalonde and Alain Fournier. A wavelet representation of reflectance functions. IEEE Transactions on Visualization and Computer Graphics, 3(4):329--336, October 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344829</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[{LMH00} Aaron Lee, Henry Moreton, and Hugues Hoppe. Displaced subdivision surfaces. In Proceedings of ACM SIGGRAPH 2000, Computer Graphics Proceedings, Annual Conference Series, pages 85--94, July 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[{Loo00} Charles Loop. Managing adjacency in triangular meshes. Technical Report MSR-TR-2000-24, Microsoft Research, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566590</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[{LPRM02} Bruno L&#233;vy, Sylvain Petitjean, Nicolas Ray, and J&#233;rome Maillot. Least squares conformal maps for automatic texture atlas generation. ACM Transactions on Graphics, 21(3):362--371, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280828</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[{LSS+98} Aaron W. F. Lee, Wim Sweldens, Peter Schr&#246;der, Lawrence Cowsar, and David Dobkin. MAPS: Multiresolution adaptive parameterization of surfaces. In Proceedings of SIGGRAPH 98, Computer Graphics Proceedings, Annual Conference Series, pages 95--104, July 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218398</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[{MB95} Leonard McMillan and Gary Bishop. Plenoptic modeling: An image-based rendering system. In Proceedings of SIGGRAPH 95, Computer Graphics Proceedings, Annual Conference Series, pages 39--46, August 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882343</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[{MPBM03} Wojciech Matusik, Hanspeter Pfister, Matthew Brand, and Leonard McMillan. A data-driven reflectance model. ACM Transactions on Graphics, 22(3):759--769, July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>341169</ref_obj_id>
				<ref_obj_pid>341166</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[{NG00} J. Cotrina Navau and N. Pla Garcia. Modelling surfaces from planar irregular meshes. Computer Aided Geometric Design, 17(1):1--15, January 2000. ISSN 0167--8396.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[{NHo} NHoled. http://cs.unm.edu/joel/noneuclid/, http://www.math.ksu.edu/math572/hyp.html, http://www.maths.gla.ac.uk/wws/cabripages/hyperbolic/hyperbolic0.html, http://mathworld.wolfram.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344987</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[{PFH00} Emil Praun, Adam Finkelstein, and Hugues Hoppe. Lapped textures. In Proceedings of ACM SIGGRAPH 2000, Computer Graphics Proceedings, Annual Conference Series, pages 465--470, July 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[{PH97} Shmuel Peleg and Joshua Herman. Panoramic mosaics by manifold projection. Computer Vision and Pattern Recognition (CVPR), 6(17):338, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882274</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[{PH03} Emil Praun and Hugues Hoppe. Spherical parameterization and remeshing. ACM Transactions on Graphics, 22(3):340--349, July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[{Rus98} Szymon M. Rusinkiewicz. A new change of variables for efficient brdf representation. In Eurographics Rendering Workshop 1998, pages 11--22, June 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[{SB} Ole Stauning and Claus Bendtsen. http://www.imm.dtu.dk/nag/proj_km/fadbad/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218439</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[{SS95} Peter Schr&#246;der and Wim Sweldens. Spherical wavelets: Efficiently representing functions on the sphere. In Proceedings of SIGGRAPH 95, Computer Graphics Proceedings, Annual Conference Series, pages 161--172, August 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882338</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[{Sta03} Jos Stam. Flows on surfaces of arbitrary topology. ACM Trans. Graph., 22(3):724--731, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015810</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[{THCM04} Marco Tarini, Kai Hormann, Paolo Cignoni, and Claudio Montani. Polycube-maps. ACM Transactions on Graphics, 23(3):853--860, August 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122749</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[{Tur91} Greg Turk. Generating textures for arbitrary surfaces using reaction-diffusion. In Computer Graphics (Proceedings of SIGGRAPH 91), volume 25, pages 289--298, July 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383297</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[{Tur01} Greg Turk. Texture synthesis on surfaces. In Proceedings of ACM SIGGRAPH 2001, Computer Graphics Proceedings, Annual Conference Series, pages 347--354, August 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134075</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[{WAT92} Stephen H. Westin, James R. Arvo, and Kenneth E. Torrance. Predicting reflectance functions from complex surfaces. In Computer Graphics (Proceedings of SIGGRAPH 92), volume 26, pages 255--264, July 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[{Wei} Eric W. Weisstein. Klein-beltrami model.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258859</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[{WFH+97} Daniel N. Wood, Adam Finkelstein, John F. Hughes, Craig E. Thayer, and David H. Salesin. Multiperspective panoramas for cel animation. In Proceedings of SIGGRAPH 97, Computer Graphics Proceedings, Annual Conference Series, pages 243--250, August 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122750</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[{WK91} Andrew Witkin and Michael Kass. Reaction-diffusion textures. In Computer Graphics (Proceedings of SIGGRAPH 91), volume 25, pages 299--308, July 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383298</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[{WL01} Li-Yi Wei and Marc Levoy. Texture synthesis over arbitrary manifold surfaces. In Proceedings of ACM SIGGRAPH 2001, Computer Graphics Proceedings, Annual Conference Series, pages 355--360, August 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>50</ref_seq_no>
				<ref_text><![CDATA[{WP97} J. Wallner and H. Pottmann. Spline orbifolds. Curves and Surfaces with Applications in CAGD, pages 445--464, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732304</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>51</ref_seq_no>
				<ref_text><![CDATA[{YHBZ01} Lexing Ying, Aaron Hertzmann, Henning Biermann, and Denis Zorin. Texture and shape synthesis on surfaces. In Rendering Techniques 2001: 12th Eurographics Workshop on Rendering, pages 301--312, June 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015714</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>52</ref_seq_no>
				<ref_text><![CDATA[{YZ04} Lexing Ying and Denis Zorin. A simple manifold-based construction of surfaces of arbitrary smoothness. ACM Transactions on Graphics, 23(3):271--275, August 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198689</section_id>
		<sort_key>22</sort_key>
		<section_seq_no>22</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[R&eacute;sum&eacute;s and demo reels: if yours aren't working, neither are you!]]></section_title>
		<section_page_from>22</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP35036422</person_id>
				<author_profile_id><![CDATA[81332531549]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pamela]]></first_name>
				<middle_name><![CDATA[Kleibrink]]></middle_name>
				<last_name><![CDATA[Thompson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198690</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Resumes and demo reels]]></title>
		<subtitle><![CDATA[if yours aren't working, neither are you!]]></subtitle>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198690</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198690</url>
		<abstract>
			<par><![CDATA[What does it take to get a job at a visual effects, computer animation or interactive company? This course shows how to open the door to interviews, put your life on a one-page resume, and showcase your talent in a three-minute-or-less demo reel.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35036415</person_id>
				<author_profile_id><![CDATA[81332531549]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pamela]]></first_name>
				<middle_name><![CDATA[Kleibrink]]></middle_name>
				<last_name><![CDATA[Thompson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198691</section_id>
		<sort_key>23</sort_key>
		<section_seq_no>23</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Taxonomy of digital creatures: interpreting character designs as computer graphics techniques]]></section_title>
		<section_page_from>23</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP35035902</person_id>
				<author_profile_id><![CDATA[81332515066]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McLaughlin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198692</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Taxonomy of digital creatures: interpreting character designs as computer graphics techniques]]></title>
		<subtitle><![CDATA[Copyright restrictions prevent ACM from providing the full text for this work.]]></subtitle>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198692</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198692</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35036165</person_id>
				<author_profile_id><![CDATA[81332515066]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McLaughlin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	</section>
	<section>
		<section_id>1198693</section_id>
		<sort_key>24</sort_key>
		<section_seq_no>24</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Digital modeling of the appearance of materials]]></section_title>
		<section_page_from>24</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP40031347</person_id>
				<author_profile_id><![CDATA[81100255828]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Holly]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rushmeier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198694</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Digital modeling of the appearance of materials]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198694</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198694</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P150906</person_id>
				<author_profile_id><![CDATA[81100369597]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Julie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dorsey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Yale University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40025377</person_id>
				<author_profile_id><![CDATA[81100255828]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Holly]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rushmeier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Yale University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>237278</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Dorsey, J., and Hanrahan, P. Modeling and rendering of metallic patinas. In Proceedings of the 23rd annual conference on Computer graphics and interactive techniques (1996), ACM Press, pp. 387--396.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237280</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Dorsey, J., Pedersen, H. K., and Hanrahan, P. Flow and changes in appearance. In Proceedings of the 23rd annual conference on Computer graphics and interactive techniques (1996), ACM Press, pp. 411--420.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311560</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Dorsey, J., Edelman, A., Jensen, H. W., Legakis, J., and Pedersen, H. K. Modeling and rendering of weathered stone. In Proceedings of the 26th annual conference on Computer graphics and interactive techniques (1999), ACM Press/Addison-Wesley Publishing Co., pp. 225--234.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198695</article_id>
		<sort_key>2</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Modeling and rendering of metallic patinas]]></title>
		<page_from>2</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198695</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198695</url>
		<abstract>
			<par><![CDATA[An important component that has been missing from image synthesis is the effect of weathering. In this paper, we present an approach for the modeling and rendering of one type of weathering --- metallic <i>patinas</i>. A patina is a film or incrustation on a surface that is produced by the removal of material, the addition of material, or the chemical alteration of a surface. Oxidation, sulphidization, and painting are examples of phenomena that produce patinas.We represent a surface as a series of layers. Patinas are simulated with a collection of operators, such as "coat," "erode," and "polish," which are applied to the layered structure. The development of patinas is modulated according to an object's geometry and local environmental factors. We introduce a technique to model the reflectance and transmission of light through the layered structure using the Kubelka-Munk model. This representation yields a model that can simulate many aspects of the time-dependent appearance of metals as they are exposed to the atmosphere or treated chemically. We demonstrate the approach with a collection of copper models.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[material models]]></kw>
			<kw><![CDATA[reflection models]]></kw>
			<kw><![CDATA[time-dependent phenomena]]></kw>
			<kw><![CDATA[weathering and appearance]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P150906</person_id>
				<author_profile_id><![CDATA[81100369597]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Julie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dorsey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Massachusetts Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P219805</person_id>
				<author_profile_id><![CDATA[81100482576]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Pat]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hanrahan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Barab&#225;si, A. L., and Stanley, H. E. Fractal Concepts in Surface Growth. Cambridge University Press, Cambridge, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Becket, W., and Badler, N. I. Imperfection for realistic image synthesis. Journal of Visualization and Computer Animation 1, 1 (Aug. 1990), 26--32.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801255</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F. Light reflection functions for simulation of clouds and dusty surfaces. Computer Graphics 16, 3 (July 1982), 21--29.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808602</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cook, R. L. Shade trees. Computer Graphics 18, 3 (July 1984), 223--231.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237280</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Dorsey, J., Pedersen, H. K., and Hanrahan, P. Flow and changes in appearance. In Computer Graphics Proceedings (1996), Annual Conference Series, ACM SIGGRAPH.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>551861</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Ebert, D. S., Ed. Texturing and Modeling. Academic Press, New York, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Fleming, S. J. Dating in Archaeology. St. Martin's Press, New York, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Franey, J. P., and Davis, M. E. Metallographic studies of the copper patina formed in the atmosphere. Corrosion Science 27, 7 (1987), 659--688.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[French, L. Toy story. Cinefantastique 27, 2 (1995), 36--37.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Graedel, T. E. Copper patinas formed in the atmosphere - a qualitative assessment of mechanisms. Corrosion Science 27, 7 (1987), 721--740.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Graedel, T. E., Nassau, K., and Franey, J. P. Copper patinas formed in the atmosphere. Corrosion Science 27, 7 (1987), 639--652.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>146452</ref_obj_id>
				<ref_obj_pid>146443</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Haase, C. S., and Meyer, G. W. Modeling pigmented materials for realistic image synthesis. ACM Tran. Graphics 11, 4 (Oct. 1992), 305--335.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166139</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hanrahan, P., and Krueger, W. Reflection from layered surfaces due to subsurface scattering. In Computer Graphics Proceedings (1993), Annual Conference Series, ACM SIGGRAPH, pp. 165--174.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97911</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Hanrahan, P., and Lawson, J. A language for shading and lighting calculations. Computer Graphics 24, 4 (Aug. 1990), 289--298.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617946</ref_obj_id>
				<ref_obj_pid>616034</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Hsu, S., and Wong, T. Simulating dust accumulation. IEEE Computer Graphics and Applications 15, 1 (Jan. 1995), 18--22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Hughes, R., and Rowe, M. The Colouring, Bronzing and Patination of Metals. Watson-Guptill Publications, New York, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Judd, D. B., and Wyszecki, G. Color in Business, Science, and Industry. John Wiley & Sons, New York, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Kortum, G. Reflectance Spectroscopy. Springer-Verlag, New York, 1969.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Kubelka, P. New contributions to the optics of intensely light-scattering material, part 1. J. Opt. Soc. Am. 38 (1948), 448.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Kubelka, P. New contributions to the optics of intensely light-scattering material, part II: Non-homogeneous layers. J. Opt. Soc. Am. 44 (1954), 330.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Kubelka, P., and Munk, F. Ein beitrag zur optik der farbanstriche. Z. tech. Physik. 22 (1931), 593.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Mattsson, E. Basic Corrosion Technology for Scientists and Engineers. Ellis Horwood Limited, New York, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192244</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Miller, G. Efficient algorithms for local and global accessibility shading. In Computer Graphics Proceedings (1994), Annual Conference Series, ACM SIGGRAPH, pp. 319--326.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Mostafavi, M., and Leatherbarrow, D. On Weathering: The Life of Buildings in Time. MIT Press, Cambridge, MA, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Newman, R. C., and Sieradzki, K. Metallic corrosion. Science 263 (1994), 1708--1709.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Perlin, K. An image synthesizer. Computer Graphics 19, 4 (July 1985), 287--296.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808606</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Porter, T., and Duff, T. Compositing digital images. Computer Graphics 18, 3 (July 1984), 253--259.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Simpson, J. W., and Horrobin, P. J. The Weathering and Performance of Building Materials. MTP Publishing Co, London, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Thomas, T. R., Ed. Rough Surfaces. Longman, New York, 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122749</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Turk, G. Generating textures for arbitrary surfaces using reaction-diffusion. Computer Graphics 25, 4 (July 1991), 289--298.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Upstill, S. The Renderman Companion. Addison-Wesley, New York, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Vernon, W. H. J., and Whitby, L. The open air corrosion of copper, a chemical surface patina. Journal Instit. of Metals 42, 6 (1932), 181--195.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122750</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Witkin, A., and Kass, M. Reaction-diffusion textures. Computer Graphics 25, 4 (July 1991), 299--308.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198696</article_id>
		<sort_key>3</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Flow and changes in appearance]]></title>
		<page_from>3</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198696</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198696</url>
		<abstract>
			<par><![CDATA[An important, largely unexplored area of computer image generation is the simulation of weathering and its effects on appearance. Weathering results from the interaction of the environment with the materials in the world. The flow of water is one of the most pervasive and important natural forces involved in the weathering of materials, producing a distinctive set of patterns of washes and stains. This paper presents an intuitive phenomenological model for the flow of water over surfaces that is capable of generating such changes in appearance.We model the flow as a particle system, each particle representing a "drop" of water. The motion of the water particles is controlled by parameters such as gravity, friction, wind, roughness, and constraints that force the particles to maintain contact with the surface. The chemical interaction of the water with the surface materials is governed by a set of coupled differential equations describing both the rate of absorption of water by the surface and the rate of solubility and sedimentation of deposits on the surface. To illustrate the power of this simple model, we show examples of flows over complex geometries made from different materials; the resulting patterns are striking and very difficult to achieve using traditional texturing techniques.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[light reflection models]]></kw>
			<kw><![CDATA[material models]]></kw>
			<kw><![CDATA[particle systems]]></kw>
			<kw><![CDATA[physically-inspired texturing]]></kw>
			<kw><![CDATA[weathering]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P150906</person_id>
				<author_profile_id><![CDATA[81100369597]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Julie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dorsey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Massachusetts Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31027116</person_id>
				<author_profile_id><![CDATA[81332520351]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hans]]></first_name>
				<middle_name><![CDATA[K&#248;hling]]></middle_name>
				<last_name><![CDATA[Pedersen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P219805</person_id>
				<author_profile_id><![CDATA[81100482576]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Pat]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hanrahan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Acheson, D. J. Elementary Fluid Dynamics. Oxford Univerity Press, New York, NY, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Addleson, L., and Rice, C. Performance of Materials in Buildings. Butterworth Heinemann, Boston, MA, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237278</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Dorsey, J., and Hanrahan, P. Modeling and rendering of metallic patinas. In Computer Graphics Proceedings (1996), Annual Conference Series, ACM SIGGRAPH.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Dullien, F. A. L. Porous Media: Fluid Transport and Pore Structure, second ed. Academic Press, New York, NY, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15894</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Fournier, A., and Reeves, W. T. A simple model of ocean waves. Computer Graphics 20, 4 (Aug. 1986), 75--84.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[French, L. Toy story. Cinefantastique 27, 2 (1995), 36--37.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Johnson, J. B., Haneef, S. J., and Hepburn, B. J. Laboratory exposure systems to simulate atmospheric degradation of building stone under dry and wet deposition. Atmospheric Environment 24A, 10 (Oct 1990), 2785--2792.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97884</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kass, M., and Miller, G. Rapid, stable fluid dynamics for computer graphics. Computer Graphics 24, 4 (Aug. 1990), 49--57.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Lippert, H. G. Systeme zur dachentwasserung bei gotischen kirchenbauten. Architecture: Zeitschrift fur Geschichte der Baukunst 24, 1 (1994), 111--128.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Maso, J. C., Ed. Pore Structure and Moisture Characteristics. Chapman and Hall, New York, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192244</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Miller, G. Efficient algorithms for local and global accessibility shading. In Computer Graphics Proceedings (1994), Annual Conference Series, ACM SIGGRAPH, pp. 319--326.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Miller, G., and Pearce, A. Globular dynamics: A connected particle system for animating viscous fluids. Computers and Graphics 13, 3 (1989), 305--309.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Mostafavi, M., and Leatherbarrow, D. On Weathering: The Life of Buildings in Time. MIT Press, Cambridge, MA, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74337</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Musgrave, F. K., Kolb, C. E., and Mace, R. S. The synthesis and rendering of eroded fractal terrains. Computer Graphics 23 (July 1989), 41--50.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Paz, O. A Draft of Shadows and Other Poems. New Directions, New York, NY, 1979.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15893</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Peachey, D. R. Modeling waves and surf. Computer Graphics 20, 4 (Aug. 1986), 65--74.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357320</ref_obj_id>
				<ref_obj_pid>357318</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Reeves, W. T. Particle systems - a technique for modeling a class of fuzzy objects. ACM Trans. Graphics 2 (Apr. 1983), 91--108.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325250</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Reeves, W. T., and Blau, R. Approximate and probabilistic algorithms for shading and rendering structured particle systems. Computer Graphics 19, 4 (July 1985), 313--322.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Small, D. Simulating watercolor by modeling diffusion, pigment, and paper fibers. In Proceedings of SPIE '91 (Feb. 1991), pp. 70--76.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122749</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Turk, G. Generating textures for arbitrary surfaces using reaction-diffusion. Computer Graphics 25, 4 (July 1991), 289--298.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Winkler, E. M. Stone in Architecture: Properties and Durability. Springer-Verlag, New York, NY, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192227</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Witkin, A. P., and Heckbert, P. S. Using particles to sample and control implicit surfaces. In Computer Graphics Proceedings (1994), Annual Conference Series, ACM SIGGRAPH, pp. 269--278.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15895</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Yaeger, L., Upson, C., and Myers, R. Combining physical and visual simulation --- creation of the planet Jupiter for the film "2010". Computer Graphics 20, 4 (Aug. 1986), 85--93.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Yalin, M. S. Mechanics of sediment transport, second ed. Oxford, New York, NY, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198697</article_id>
		<sort_key>4</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Modeling and rendering of weathered stone]]></title>
		<page_from>4</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198697</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198697</url>
		<abstract>
			<par><![CDATA[Stone is widespread in its use as a building material and artistic medium. One of its most remarkable qualities is that it changes appearance as it interacts with the environment. These changes are mainly confined to the surface but involve complex volumetric effects such as erosion and mineral dissolution. This paper presents an approach for the modeling and rendering of changes in the shape and appearance of stone.To represent stone, we introduce a <i>slab</i> data structure, which is a surface-aligned volume confined to a narrow region around the boundary of the stone. Our weathering model employs a simulation of the flow of moisture and the transport, dissolution, and recrystallization of minerals within the porous stone volume. In addition, this model governs the erosion of material from the surface. To render the optical effects of translucency and coloration due to the composition of minerals near the surface, we simulate the scattering of light inside the stone using a general subsurface Monte Carlo ray tracer. These techniques can capture many aspects of the time-dependent appearance of stone. We demonstrate the approach with models of granite and marble statues, as well as a sandstone column.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[erosion]]></kw>
			<kw><![CDATA[material models]]></kw>
			<kw><![CDATA[natural phenomena]]></kw>
			<kw><![CDATA[physical simulation]]></kw>
			<kw><![CDATA[ray tracing]]></kw>
			<kw><![CDATA[subsurface scattering]]></kw>
			<kw><![CDATA[texturing]]></kw>
			<kw><![CDATA[volume modeling]]></kw>
			<kw><![CDATA[weathering]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P150906</person_id>
				<author_profile_id><![CDATA[81100369597]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Julie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dorsey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Massachusetts Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39037240</person_id>
				<author_profile_id><![CDATA[81100308159]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Edelman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Massachusetts Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P109434</person_id>
				<author_profile_id><![CDATA[81100640205]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Henrik]]></first_name>
				<middle_name><![CDATA[Wann]]></middle_name>
				<last_name><![CDATA[Jensen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Massachusetts Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P151625</person_id>
				<author_profile_id><![CDATA[81100586454]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Justin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Legakis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Massachusetts Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31027116</person_id>
				<author_profile_id><![CDATA[81332520351]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Hans]]></first_name>
				<middle_name><![CDATA[K&#248;hling]]></middle_name>
				<last_name><![CDATA[Pedersen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Massachusetts Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Giovanni G. Amoroso and Vasco Fassina. Stone Decay and Conservation. Elsevier, New York, NY, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[John Ashurst and Francis Dimes, editors. Conservation of Building and Decorative Stone. Butterworth-Heinemann, London, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Michael Bass, editor. Handbook of Optics. McGraw-Hill, Inc., New York, NY, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Philippe Blasi, Bertrand Le Saec, and Christophe Schlick. A rendering algorithm for discrete volume density objects. In R. J. Hubbold and R. Juan, editors, Eurographics '93, pages 201--210, Oxford, UK, 1993. Eurographics, Blackwell Publishers.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[E. Catmull and J. Clark. Recursively generated B-spline surfaces on arbitrary topological meshes. Computer-Aided Design, 10:350--355, September 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258896</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cassidy J. Curtis, Sean E. Anderson, Joshua E. Seims, Kurt W. Fleischer, and David H. Salesin. Computer-generated watercolor. In Computer Graphics Proceedings, Annual Conference Series, pages 421--430. ACM SIGGRAPH, August 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237278</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Julie Dorsey and Pat Hanrahan. Modeling and rendering of metallic patinas. In Computer Graphics Proceedings, Annual Conference Series, pages 387--396. ACM SIGGRAPH, August 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237280</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Julie Dorsey, Hans K&#248;hling Pedersen, and Pat Hanrahan. Flow and changes in appearance. In Computer Graphics Proceedings, Annual Conference Series, pages 411--420. ACM SIGGRAPH, August 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[F. A. L. Dullien. Porous Media: Fluid Transport and Pore Structure. Academic Press, New York, NY, second edition, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>551861</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[David S. Ebert, editor. Texturing and Modeling. Academic Press, New York, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[K. Lal Gauri. The preservation of stone. Scientific American, 238(6):126--136, June 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166139</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Pat Hanrahan and Wolfgang Krueger. Reflection from layered surfaces due to subsurface scattering. In Computer Graphics Proceedings, Annual Conference Series, pages 165--174. ACM SIGGRAPH, August 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[L. G. Henyey and J. L. Greenstein. Diffuse radiation in the galaxy. Astrophysics Journal, 93:70--83, 1941.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280925</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Henrik Wann Jensen and Per H. Christensen. Efficient simulation of light transport in scenes with participating media using photon maps. In Computer Graphics Proceedings, pages 311--320. ACM SIGGRAPH, August 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74361</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[James T. Kajiya and Timothy L. Kay. Rendering fur with three dimensional textures. In Computer Graphics (SIGGRAPH '89 Proceedings), volume 23, pages 271--280, July 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>619635</ref_obj_id>
				<ref_obj_pid>161477</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Arie Kaufman, Daniel Cohen, and Roni Yagel. Volume graphics. IEEE Computer, 26(7):51--64, July 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192283</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Philippe Lacroute and Marc Levoy. Fast volume rendering using a shear-warp factorization of the viewing transformation. In Computer Graphics Proceedings, Annual Conference Series, pages 451--458. ACM SIGGRAPH, July 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>78965</ref_obj_id>
				<ref_obj_pid>78964</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Marc Levoy. Efficient ray tracing of volume data. ACM Transactions on Graphics, 9(3):245--261, July 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192244</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Gavin Miller. Efficient algorithms for local and global accessibility shading. In Proceedings of SIGGRAPH '94, Annual Conference Series, pages 319--326, July 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74337</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[F. Kenton Musgrave, Craig E. Kolb, and Robert S. Mace. The synthesis and rendering of eroded fractal terrains. Computer Graphics, 23(3):41--50, July 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614392</ref_obj_id>
				<ref_obj_pid>614269</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Fabrice Neyret. Modeling, animating, and rendering complex scenes using volumetric textures. IEEE Transactions on Visualization and Computer Graphics, 4(1), January - March 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311550</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[James F. O'Brien and Jessica K. Hodgins. Graphical modeling and animation of brittle fracture. In Computer Graphics Proceedings. ACM SIGGRAPH, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Andrew Peckett. The Colours of Opaque Minerals. John Wiley and Sons Ltd, Chichester, England, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Ken Perlin. An image synthesizer. In B. A. Barsky, editor, Computer Graphics (SIGGRAPH '85 Proceedings), volume 19, pages 287--296, July 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[D. G. Price. Weathering and weathering processes. Quarterly Journal of Engineering Geology, 16(28):243--252, June 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>914720</ref_obj_id>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Holly E. Rushmeier. Realistic Image Synthesis for Scenes with Radiatively Participating Media. Phd thesis, Cornell University, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Muhammad Sahimi. Flow and Transport in Porous Media and Fractured Rock. VCH, New York, NY, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>951099</ref_obj_id>
				<ref_obj_pid>951087</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[William J. Schroeder and William E. Lorensen. Implicit modeling of swept surfaces and volumes. In Visualization '94, pages 40--45. IEEE, IEEE Computer Society Press, October 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Walter Schumann. Handbook of Rocks, Minerals, and Gemstones. HarperCollins Publishers and Houghton Mifflin Company, New York, NY, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[M. J. Selby. Hillslope Materials and Processes. Oxford University Press, Oxford, England, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Robert Siegel and John R. Howell. Thermal Radiation Heat Transfer. Hemisphere Publishing Corporation, Washington, D.C., 3rd edition, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Gilbert Strang. Introduction to Applied Mathematics. Wellesley-Cambridge Press, Wellesley, MA, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>64816</ref_obj_id>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[John C. Strikwerda. Finite Difference Schemes and Partial Differential Equations. Wadsworth and Brooks, Pacific Grove, CA, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617876</ref_obj_id>
				<ref_obj_pid>616030</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Jayaram K. Udupa and Dewey Odhner. Shell rendering. IEEE Computer Graphics and Applications, 13(6):58--67, November 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617911</ref_obj_id>
				<ref_obj_pid>616032</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Sidney W. Wang and Arie E. Kaufman. Volume-sampled 3d modeling. IEEE Computer Graphics and Applications, 14:26--32, September 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Erhard M. Winkler. Stone in Architecture: Properties, Durablity. Springer-Verlag, New York, NY, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237267</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Steven P. Worley. A cellular texture basis function. In SIGGRAPH 96 Conference Proceedings, Annual Conference Series, pages 291--294. ACM SIGGRAPH, August 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198698</section_id>
		<sort_key>25</sort_key>
		<section_seq_no>25</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Open source 2005 and beyond: thriving despite the DMCA and patent threats to Linux]]></section_title>
		<section_page_from>25</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP77028224</person_id>
				<author_profile_id><![CDATA[81414603127]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Cogan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198699</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Open source 2005 and beyond: thriving despite the DMCA and patent threats to Linux]]></title>
		<subtitle><![CDATA[Copyright restrictions prevent ACM from providing the full text for this work.]]></subtitle>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198699</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198699</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP77035924</person_id>
				<author_profile_id><![CDATA[81408592668]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Cogan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	</section>
	<section>
		<section_id>1198700</section_id>
		<sort_key>26</sort_key>
		<section_seq_no>26</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Visualizing quaternions]]></section_title>
		<section_page_from>26</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP39056730</person_id>
				<author_profile_id><![CDATA[81100647585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Hanson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198701</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Visualizing quaternions]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198701</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198701</url>
		<abstract>
			<par><![CDATA[This intermediate-level tutorial provides a comprehensive approach to the visualization of quaternions and their relationships to computer graphics and scientific visualization. The introduction focuses on a selection of everyday phenomena involving rotating objects whose explanation for an audience that is technically trained but not pure mathematicians is essentially impossible without a quaternion visualization. The course will then pursue selected examples of quaternion-based visualization methods to help explain the behavior of <i>quaternion manifolds:</i> quaternion representations of orientation frames attached to curves, surfaces, and volumes.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39052350</person_id>
				<author_profile_id><![CDATA[81100647585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Hanson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Indiana University, Bloomington, IN]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>949881</ref_obj_id>
				<ref_obj_pid>949845</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B. Alpern, L. Carter, M. Grayson, and C. Pelkie. Orientation maps: Techniques for visualizing rotations (a consumer's guide). In Proceedings of Visualization '93, pages 183--188. IEEE Computer Society Press, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[S. L. Altmann. Rotations, Quaternions, and Double Groups. Oxford University Press, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. F. Atiyah, R. Bott, and A. Shapiro. Clifford modules. Topology, 3, Suppl. 1:3--38, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. Banchoff and J. Werner. Linear Algebra through Geometry. Springer-Verlag, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[T. F. Banchoff. Visualizing two-dimensional phenomena in four-dimensional space: A computer graphics approach. In E. Wegman and D. Priest, editors, Statistical Image Processing and Computer Graphics, pages 187--202. Marcel Dekker, Inc., New York, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>533317</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Thomas F. Banchoff. Beyond the Third Dimension: Geometry, Computer Graphics, and Higher Dimensions. Scientific American Library, New York, NY, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>147205</ref_obj_id>
				<ref_obj_pid>147156</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[David Banks. Interactive display and manipulation of two-dimensional surfaces in four dimensional space. In Symposium on Interactive 3D Graphics, pages 197--207, New York, 1992. ACM.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>147205</ref_obj_id>
				<ref_obj_pid>147156</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[David Banks. Interactive manipulation and display of two-dimensional surfaces in four-dimensional space. In David Zeltzer, editor, Computer Graphics (1992 Symposium on Interactive 3D Graphics), volume 25, pages 197--207, March 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192246</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[David C. Banks. Illumination in diverse codimensions. In Computer Graphics, pages 327--334, New York, 1994. ACM. Proceedings of SIGGRAPH 1994; Annual Conference Series 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134086</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[A. Barr, B. Currin, S. Gabriel, and J. Hughes. Smooth interpolation of orientations with angular velocity constraints using quaternions. In Computer Graphics Proceedings, Annual Conference Series, pages 313--320, 1992. Proceedings of SIGGRAPH '92.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Richard L. Bishop. There is more than one way to frame a curve. Amer. Math. Monthly, 82(3):246--251, March 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Wilhelm Blaschke. Kinematik und Quaternionen. VEB Deutscher Verlag der Wissenschaften, Berlin, 1960.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>90927</ref_obj_id>
				<ref_obj_pid>90767</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Jules Bloomenthal. Calculation of reference frames along a space curve. In Andrew Glassner, editor, Graphics Gems, pages 567--571. Academic Press, Cambridge, MA, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Kenneth A. Brakke. The surface evolver. Experimental Mathematics, 1(2):141--165, 1992. The "Evolver" system, manual, and sample data files are available by anonymous ftp from geom.umn.edu, The Geometry Center, Minneapolis MN.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[D. W. Brisson, editor. Hypergraphics: Visualizing Complex Relationships in Art, Science and Technology, volume 24. Westview Press, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[S. A. Carey, R. P. Burton, and D. M. Campbell. Shades of a higher dimension. Computer Graphics World, pages 93--94, October 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378497</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Michael Chen, S. Joy Mountford, and Abigail Sellen. A study in interactive 3-d rotation using 2-d control devices. In Proceedings of Siggraph 88, volume 22, pages 121--130, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[H. S. M. Coxeter. Regular Complex Polytopes. Cambridge University Press, second edition, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>951118</ref_obj_id>
				<ref_obj_pid>951087</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[R. A. Cross and A. J. Hanson. Virtual reality performance for virtual geometry. In Proceedings of Visualization '94, pages 156--163. IEEE Computer Society Press, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[A. R. Edmonds. Angular Momentum in Quantum Mechanics. Princeton University Press, Princeton, New Jersey, 1957.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[N. V. Efimov and E. R. Rozendorn. Linear Algebra and Multi-Dimensional Geometry. Mir Publishers, Moscow, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[T. Eguchi, P. B. Gilkey, and A. J. Hanson. Gravitation, gauge theories and differential geometry. Physics Reports, 66(6):213--393, December 1980.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[L. P. Eisenhart. A Treatise on the Differential Geometry of Curves and Surfaces. Dover, New York, 1909 (1960).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91412</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[S. Feiner and C. Beshers. Visualizing n-dimensional virtual worlds with n-vision. Computer Graphics, 24(2):37--38, March 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97933</ref_obj_id>
				<ref_obj_pid>97924</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[S. Feiner and C. Beshers. Worlds within worlds: Metaphors for exploring n-dimensional virtual worlds. In Proceedings of UIST '90, Snowbird, Utah, pages 76--83, October 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Gerd Fischer. Mathematische Modelle, volume I and II. Friedr. Vieweg & Sohn, Braunschweig/Wiesbaden, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[H. Flanders. Differential Forms. Academic Press, New York, 1963.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>83821</ref_obj_id>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[J. D. Foley, A. van Dam, S. K. Feiner, and J. F. Hughes. Computer Graphics, Principles and Practice. Addison-Wesley, second edition, 1990. page 227.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[A. R. Forsyth. Geometry of Four Dimensions. Cambridge University Press, 1930.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[George K. Francis. A Topological Picturebook. Springer Verlag, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Herbert Goldstein. Classical Mechanics. Addison-Wesley, 1950.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>781241</ref_obj_id>
				<ref_obj_pid>781238</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[F. S. Grassia. Practical parameterization of rotations using the exponential map. Journal of Graphics Tools, 3(3):29--48, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>524240</ref_obj_id>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Alfred Gray. Modern Differential Geometry of Curves and Surfaces. CRC Press, Inc., Boca Raton, FL, second edition, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218475</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Cindy M. Grimm and John F. Hughes. Modeling surfaces with arbitrary topology using manifolds. In Computer Graphics Proceedings, Annual Conference Series, pages 359--368, 1995. Proceedings of SIGGRAPH '95.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[W. R. Hamilton. Lectures on Quaternions. Cambridge University Press, 1853.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>130757</ref_obj_id>
				<ref_obj_pid>130745</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson. The rolling ball. In David Kirk, editor, Graphics Gems III, pages 51--60. Academic Press, Cambridge, MA, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson. A construction for computer visualization of certain complex curves. Notices of the Amer. Math. Soc., 41(9): 1156--1163, November/December 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>180909</ref_obj_id>
				<ref_obj_pid>180895</ref_obj_pid>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson. Geometry for n-dimensional graphics. In Paul Heckbert, editor, Graphics Gems IV, pages 149--170. Academic Press, Cambridge, MA, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson. Rotations for n-dimensional graphics. In Alan Paeth, editor, Graphics Gems V, pages 55--64. Academic Press, Cambridge, MA, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>288324</ref_obj_id>
				<ref_obj_pid>288216</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson. Constrained optimal framings of curves and surfaces using quaternion gauss maps. In Proceedings of Visualization '98, pages 375--382. IEEE Computer Society Press, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1202145</ref_obj_id>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson. Visualizing Quaternions. Morgan Kaufmann, San Francisco, CA, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>949883</ref_obj_id>
				<ref_obj_pid>949845</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson and R. A. Cross. Interactive visualization methods for four dimensions. In Proceedings of Visualization '93, pages 196--203. IEEE Computer Society Press, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>949660</ref_obj_id>
				<ref_obj_pid>949607</ref_obj_pid>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson and P. A. Heng. Visualizing the fourth dimension using geometry and light. In Proceedings of Visualization '91, pages 321--328. IEEE Computer Society Press, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>949704</ref_obj_id>
				<ref_obj_pid>949685</ref_obj_pid>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson and P. A. Heng. Four-dimensional views of 3d scalar fields. In Proceedings of Visualization '92, pages 84--91. IEEE Computer Society Press, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson and P. A. Heng. Foursight. In Siggraph Video Review, volume 85. ACM Siggraph, 1992. Scene 11, Presented in the Animation Screening Room at SIGGRAPH '92, Chicago, Illinois, July 28--31, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617766</ref_obj_id>
				<ref_obj_pid>616024</ref_obj_pid>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson and P. A. Heng. Illuminating the fourth dimension. Computer Graphics and Applications, 12(4):54--62, July 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>951110</ref_obj_id>
				<ref_obj_pid>951087</ref_obj_pid>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson and H. Ma. Visualizing flow with quaternion frames. In Proceedings of Visualization '94, pages 108--115. IEEE Computer Society Press, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614304</ref_obj_id>
				<ref_obj_pid>614258</ref_obj_pid>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson and H. Ma. Quaternion frame approach to streamline visualization. IEEE Trans. on Visualiz. and Comp. Graphics, 1(2):164--174, June 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>833861</ref_obj_id>
				<ref_obj_pid>832271</ref_obj_pid>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson and H. Ma. Space walking. In Proceedings of Visualization '95, pages 126--133. IEEE Computer Society Press, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>182464</ref_obj_id>
				<ref_obj_pid>182452</ref_obj_pid>
				<ref_seq_no>50</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson, T. Munzner, and G. K. Francis. Interactive methods for visualizable geometry. IEEE Computer, 27(7):73--83, July 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>51</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson. Quaternion gauss maps and optimal framings of curves and surfaces. Indiana University Computer Science Department Technical Report 518 (October, 1998).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>52</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson, K. Ishkov, and J. Ma. Meshview. A portable 4D geometry viewer written in OpenGL/Motif, available by anonymous ftp from ftp.cs.indiana.edu:pub/hanson.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>53</ref_seq_no>
				<ref_text><![CDATA[A. J. Hanson, K. Ishkov, and J. Ma. Meshview: Visualizing the fourth dimension. Overview of the MeshView 4D geometry viewer.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>197480</ref_obj_id>
				<ref_obj_pid>195784</ref_obj_pid>
				<ref_seq_no>54</ref_seq_no>
				<ref_text><![CDATA[John C. Hart, George K. Francis, and Louis H. Kauffman. Visualizing quaternion rotation. ACM Trans. on Graphics, 13(3):256--276, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>55</ref_seq_no>
				<ref_text><![CDATA[L. Herda, R. Urtasun, and P. Fua. Hierarchical Implicit Surface Joint Limits to Constrain Video-Based Motion Capture. In ECCV, Prague, Czech Republic, May 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>875444</ref_obj_id>
				<ref_obj_pid>874061</ref_obj_pid>
				<ref_seq_no>56</ref_seq_no>
				<ref_text><![CDATA[L. Herda, R. Urtasun, A. Hanson, and P. Fua. An Automatic Method For Determining Quaternion Field Boundaries for Ball-and-Socket Joint Limits. In Proceedings of the 5th International Conference on Automated Face and Gesture Recognition (FGR), pages 95--100, Washington, DC, May 2002. IEEE Computer Society.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>57</ref_seq_no>
				<ref_text><![CDATA[L. Herda, R. Urtasun, A. Hanson, and P. Fua. Automatic Determination of Shoulder Joint Limits using Experimentally Determined Quaternion Field Boundaries. International Journal of Robotics Research, 22(6):419--434, June 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>58</ref_seq_no>
				<ref_text><![CDATA[D. Hilbert and S. Cohn-Vossen. Geometry and the Imagination. Chelsea, New York, 1952.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>59</ref_seq_no>
				<ref_text><![CDATA[John G. Hocking and Gail S. Young. Topology. Addison-Wesley, 1961.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>115611</ref_obj_id>
				<ref_obj_pid>115604</ref_obj_pid>
				<ref_seq_no>60</ref_seq_no>
				<ref_text><![CDATA[C. Hoffmann and J. Zhou. Some techniques for visualizing surfaces in four-dimensional space. Computer-Aided Design, 23:83--91, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>61</ref_seq_no>
				<ref_text><![CDATA[S. Hollasch. Four-space visualization of 4D objects. Master's thesis, Arizona State University, August 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>62</ref_seq_no>
				<ref_text><![CDATA[H. B. Lawson Jr. and M. L. Michelsohn. Spin Geometry. Princeton University Press, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>63</ref_seq_no>
				<ref_text><![CDATA[B. J&#252;ttler. Visualization of moving objects using dual quaternion curves. Computers and Graphics, 18(3):315--326, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>64</ref_seq_no>
				<ref_text><![CDATA[B. J&#252;ttler and M. G. Wagner. Computer-aided design with saptial rational B-spline motions. Journal of Mechanical Design, 118:193--201, June 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218486</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>65</ref_seq_no>
				<ref_text><![CDATA[Myoung-Jun Kim, Myung-Soo Kim, and Sung Yong Shin. A general construction scheme for unit quaternion curves with simple high order derivatives. In Computer Graphics Proceedings, Annual Conference Series, pages 369--376, 1995. Proceedings of SIGGRAPH '95.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>18701</ref_obj_id>
				<ref_obj_pid>18695</ref_obj_pid>
				<ref_seq_no>66</ref_seq_no>
				<ref_text><![CDATA[F. Klock. Two moving coordinate frames for sweeping along a 3d trajectory. Computer Aided Geometric Design, 3, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>67</ref_seq_no>
				<ref_text><![CDATA[J. B. Kuipers. Quaternions and Rotation Sequences. Princeton University Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>68</ref_seq_no>
				<ref_text><![CDATA[J. Milnor. Topology from the Differentiable Viewpoint. The University Press of Virginia, Charlottesville, 1965.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>69</ref_seq_no>
				<ref_text><![CDATA[Hans Robert M&#252;ller. Sph&#228;rische Kinematik. VEB Deutscher Verlag der Wissenschaften, Berlin, 1962.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>70</ref_seq_no>
				<ref_text><![CDATA[G. M. Nielson. Smooth interpolation of orientations. In N. M. Thalman and D. Thalman, editors, Computer Animation '93, pages 75--93, Tokyo, June 1993. Springer-Verlag.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>363544</ref_obj_id>
				<ref_obj_pid>363534</ref_obj_pid>
				<ref_seq_no>71</ref_seq_no>
				<ref_text><![CDATA[Michael A. Noll. A computer technique for displaying n-dimensional hyperobjects. Communications of the ACM, 10(8):469--473, August 1967.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>72</ref_seq_no>
				<ref_text><![CDATA[Mark Phillips, Silvio Levy, and Tamara Munzner. Geomview: An interactive geometry viewer. Notices of the Amer. Math. Society, 40(8):985--988, October 1993. Available by anonymous ftp from geom.umn.edu, The Geometry Center, Minneapolis MN.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>73</ref_seq_no>
				<ref_text><![CDATA[D. Pletincks. Quaternion calculus as a basic tool in computer graphics. The Visual Computer, 5(1):2--13, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258870</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>74</ref_seq_no>
				<ref_text><![CDATA[Ravi Ramamoorthi and Alan H. Barr. Fast construction of accurate quaternion splines. In Turner Whitted, editor, SIGGRAPH 97 Conference Proceedings, Annual Conference Series, pages 287--292. ACM SIGGRAPH, Addison Wesley, August 1997. ISBN 0-89791-896-7.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>75</ref_seq_no>
				<ref_text><![CDATA[John Schlag. Using geometric constructions to interpolate orientation with quaternions. In James Arvo, editor, Graphics Gems II, pages 377--380. Academic Press, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>76</ref_seq_no>
				<ref_text><![CDATA[Uri Shani and Dana H. Ballard. Splines as embeddings for generalized cylinders. Computer Vision, Graphics, and Image Processing, 27:129--156, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325242</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>77</ref_seq_no>
				<ref_text><![CDATA[K. Shoemake. Animating rotation with quaternion curves. In Computer Graphics, volume 19, pages 245--254, 1985. Proceedings of SIGGRAPH 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>78</ref_seq_no>
				<ref_text><![CDATA[K. Shoemake. Animation with quaternions. Siggraph Course Lecture Notes, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>180910</ref_obj_id>
				<ref_obj_pid>180895</ref_obj_pid>
				<ref_seq_no>79</ref_seq_no>
				<ref_text><![CDATA[Ken Shoemake. Arcball rotation control. In Paul Heckbert, editor, Graphics Gems IV, pages 175--192. Academic Press, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>180915</ref_obj_id>
				<ref_obj_pid>180895</ref_obj_pid>
				<ref_seq_no>80</ref_seq_no>
				<ref_text><![CDATA[Ken Shoemake. Fiber bundle twist reduction. In Paul Heckbert, editor, Graphics Gems IV, pages 230--236. Academic Press, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>81</ref_seq_no>
				<ref_text><![CDATA[D. M. Y. Sommerville. An Introduction to the Geometry of N Dimensions. Reprinted by Dover Press, 1958.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>82</ref_seq_no>
				<ref_text><![CDATA[N. Steenrod. The Topology of Fibre Bundles. Princeton University Press, 1951. Princeton Mathematical Series 14.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>83</ref_seq_no>
				<ref_text><![CDATA[K. V. Steiner and R. P. Burton. Hidden volumes: The 4th dimension. Computer Graphics World, pages 71--74, February 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>84</ref_seq_no>
				<ref_text><![CDATA[D. J. Struik. Lectures on Classical Differential Geometry. Addison-Wesley, 1961.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>85</ref_seq_no>
				<ref_text><![CDATA[P. G. Tait. An Elementary Treatise on Quaternions. Cambridge University Press, 1890.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>86</ref_seq_no>
				<ref_text><![CDATA[J. R. Weeks. The Shape of Space. Marcel Dekker, New York, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>87</ref_seq_no>
				<ref_text><![CDATA[S. Weinberg. Gravitation and Cosmology: Principles and Applications of General Relativity. John Wiley and Sons, 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>88</ref_seq_no>
				<ref_text><![CDATA[E. T. Whittaker. A Treatise on the Analytical Dynamics of Particles and Rigid Bodies. Dover, New York, New York, 1944.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198702</section_id>
		<sort_key>27</sort_key>
		<section_seq_no>27</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Layered manufacturing as a graphics display device]]></section_title>
		<section_page_from>27</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP39057040</person_id>
				<author_profile_id><![CDATA[81100416435]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sara]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McMains]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198703</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Layered manufacturing as a graphics display device]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198703</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198703</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39041811</person_id>
				<author_profile_id><![CDATA[81100416435]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sara]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McMains]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[U.C. Berkeley]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39059890</person_id>
				<author_profile_id><![CDATA[81324487523]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mike]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bailey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Oregon State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24030274</person_id>
				<author_profile_id><![CDATA[81405592656]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Crawford]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Texas at Austin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198704</section_id>
		<sort_key>28</sort_key>
		<section_seq_no>28</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[From mocap to movie: the making of "The Polar Express"]]></section_title>
		<section_page_from>28</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP35035479</person_id>
				<author_profile_id><![CDATA[81335488469]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Rob]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bredow]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198705</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[From mocap to movie: the making of "The Polar Express"]]></title>
		<subtitle><![CDATA[Copyright restrictions prevent ACM from providing the full text for this work.]]></subtitle>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198705</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198705</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35035747</person_id>
				<author_profile_id><![CDATA[81335488469]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Rob]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bredow]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35036075</person_id>
				<author_profile_id><![CDATA[81335497089]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schaub]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP18005560</person_id>
				<author_profile_id><![CDATA[81537614656]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Rob]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Engle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35036002</person_id>
				<author_profile_id><![CDATA[81335492933]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kramer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31057983</person_id>
				<author_profile_id><![CDATA[81100061602]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Albert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hastings]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	</section>
	<section>
		<section_id>1198706</section_id>
		<sort_key>29</sort_key>
		<section_seq_no>29</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[High-dynamic-range imaging and image-based lighting]]></section_title>
		<section_page_from>29</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>P221188</person_id>
				<author_profile_id><![CDATA[81100086933]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Debevec]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>P78852</person_id>
				<author_profile_id><![CDATA[81100331006]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Erik]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Reinhard]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198707</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[High dynamic range imaging and image-based lighting]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198707</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198707</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P78852</person_id>
				<author_profile_id><![CDATA[81100331006]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Erik]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Reinhard]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Central Florida]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P221188</person_id>
				<author_profile_id><![CDATA[81100086933]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Debevec]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[USC ICT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39057518</person_id>
				<author_profile_id><![CDATA[81100633003]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Greg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ward]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Anyhere Software]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14020468</person_id>
				<author_profile_id><![CDATA[81350599694]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Sumanta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pattanaik]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Central Florida]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198708</article_id>
		<sort_key>2</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[JPEG-HDR]]></title>
		<subtitle><![CDATA[a backwards-compatible, high dynamic range extension to JPEG]]></subtitle>
		<page_from>2</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198708</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198708</url>
		<abstract>
			<par><![CDATA[The transition from traditional 24-bit RGB to high dynamic range (HDR) images is hindered by excessively large file formats with no backwards compatibility. In this paper, we demonstrate a simple approach to HDR encoding that parallels the evolution of color television from its grayscale beginnings. A tone-mapped version of each HDR original is accompanied by restorative information carried in a subband of a standard output-referred image. This subband contains a compressed <i>ratio image</i>, which when multiplied by the tone-mapped foreground, recovers the HDR original. The tone-mapped image data is also compressed, and the composite is delivered in a standard JPEG wrapper. To na&#239;ve software, the image looks like any other, and displays as a tone-mapped version of the original. To HDR-enabled software, the foreground image is merely a tone-mapping suggestion, as the original pixel data are available by decoding the information in the subband. Our method further extends the color range to encompass the visible gamut, enabling a new generation of display devices that are just beginning to enter the market.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39055233</person_id>
				<author_profile_id><![CDATA[81100633003]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Greg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ward]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sunnybrook Technologies]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31058877</person_id>
				<author_profile_id><![CDATA[81341496532]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Maryann]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Simmons]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Walt Disney Feature Animation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>581916</ref_obj_id>
				<ref_obj_pid>581896</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Ashikhmin, M. 2002. A Tone Mapping Algorithm for High Contrast Images. In Proceedings of 13th Eurographics Workshop on Rendering, 145--156.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628815</ref_obj_id>
				<ref_obj_pid>628330</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Baker, S & Kanade, T. 2002. Limits on super-resolution and how to break them. IEEE Transactions on Pattern Analysis and Machine Intelligence., 24(9):1167--1183, September. 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>581916</ref_obj_id>
				<ref_obj_pid>581896</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Chiu, K. Herf, M., Shirley, P., Swamy, M., Wang, C., and Zimmerman, K., 2002. A Tone Mapping Algorithm for High Contrast Images. In Proceedings of 13th Eurographics Workshop on Rendering, 245--253.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>197783</ref_obj_id>
				<ref_obj_pid>197765</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Daly, S. 1993. The Visible Differences Predictor: An Algorithm for the Assessment of Image Fidelity. In Digital Images and Human Vision, A. B. Watson, editor, MIT Press, Cambridge, Massachusetts.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258884</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Debevec, P., and Malik, J. 1997. Recovering High Dynamic Range Radiance Maps from Photographs. In Proceedings of ACM SIGGRAPH 1997, 369--378.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280864</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Debevec, P. 1998. Rendering Synthetic Objects into Real Scenes: Bridging Traditional and Image-Based Graphics with Global Illumination and High Dynamic Range Photography. In Proceedings of ACM SIGGRAPH 1998, 189--198.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566574</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Durand, F., and Dorsey, J. 2002. Fast Bilateral Filtering for the Display of High-Dynamic Range Images. ACM Transactions on Graphics, 21, 3, 249--256.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566573</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Fattal, R., Lischinski, D., and Werman, M. 2002. Gradient Domain High Dynamic Range Compression. ACM Transactions on Graphics, 21, 3, 257--266.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[IEC. 2003. 61966-2-2. Extended RGB colour space - scRGB, Multimedia systems and equipment - Colour measurement and management - Part 2-2: Colour management.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Independent JPEG Group. 1998. www.ijg.org/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Jolliffe, C. B., 1950. Answers to Questions about Color Television. members.aol.com/ajaynejr/rca2.htm.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Jourlin, M., Pinoli, J-C., 1988. A model for logarithmic image processing, Journal of Microscopy, 149(1), pp. 21--35.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kains, F., Bogart, R., Hess, D., Schneider, P., Anderson, B., 2002. OpenEXR. www.openexr.org/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Leffler, S., Warmerdam, F., Kiselev, A., 1999. libTIFF. remotesensing.org/libtiff.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015794</ref_obj_id>
				<ref_obj_pid>1186562</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Mantiuk, R., Krawczyk, G., Myszkowski, K., Seidel, H-P. 2004. "Perception-motivated High Dynamic Range Video Encoding," SIGGRAPH 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Moon P., and Spencer, D. 1945. The Visual Effect of Non-Uniform Surrounds. Journal of the Optical Society of America, 35, 3, 233--248.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280922</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Pattanaik, S., Ferwerda, J., Fairchild, M., and Greenberg, D. 1998. A Multiscale Model of Adaptation and Spatial Vision for Realistic Image Display, In Proceedings of ACM SIGGRAPH 1998, 287--298.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566575</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Reinhard, E., Stark, M., Shirley, P., and Ferwerda, J. 2002. Photographic Tone Reproduction for Digital Images. ACM Transactions on Graphics, 21, 3, 267--276.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015797</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Seetzen, H., Heidrich, W., Stuezlinger, W., Ward, G., Whitehead, L., Trentacoste, M., Ghosh, A., Vorozcovs, A. 2004. "High Dynamic Range Display Systems," ACM Trans. Graph. (special issue SIGGRAPH 2004).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Spaulding, K., Woolfe, G., & Joshi, R. 2003. "Using a Residual Image to Extend the Color Gamut and Dynamic Range of an sRGB Image," white paper posted on the Kodak website.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Spinal Tap, This is. 1984. Dir. Rob Reiner. MGM Home Entertainment.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Stokes, M., Anderson, M., Chandrasekar, S., and Motta, R. 1996. Standard Default Color Space for the Internet. www.w3.org/Graphics/Color/sRGB.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Tumblin, J., and Turk, G. 1999. LCIS: A Boundary Hierarchy for Detail-Preserving Contrast Reduction. ACM Trans. on Graphics, 21, 3, 83--90.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>103089</ref_obj_id>
				<ref_obj_pid>103085</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Wallace, G. 1991. The JPEG Still Picture Compression Standard. Communications of the ACM, 34, 4, 30--44.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614380</ref_obj_id>
				<ref_obj_pid>614268</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Ward Larson, G., Rushmeier, H., and Piatko, C. 1997. A Visibility Matching Tone Reproduction Operator for High Dynamic Range Scenes. IEEE Trans. on Visualization and Computer Graphics, 3, 4.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Ward Larson, G. 1998. Overcoming Gamut and Dynamic Range Limitations in Digital Images. Proc. of 1S&T 6th Color Imaging Conf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Ward, G. 1991. Real Pixels. In Graphics Gems II, edited by James Arvo, Academic Press, 80--83.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192286</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Ward, G. 1994. The RADIANCE Lighting Simulation and Rendering System. In Proceedings of ACM SIGGRAPH 1994, 459--472.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1012566</ref_obj_id>
				<ref_obj_pid>1012551</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Ward, G. & Simmons, M. 2004. "Subband Encoding of High Dynamic Range Imagery," First Symposium on Applied Perception in Graphics and Visualization (APGV).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198709</article_id>
		<sort_key>3</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Image-based lighting]]></title>
		<page_from>3</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198709</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198709</url>
		<abstract>
			<par><![CDATA[This tutorial shows how image-based lighting can illuminate synthetic objects with measurements of real light, making objects appear as if they're actually in a real-world scene.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P221188</person_id>
				<author_profile_id><![CDATA[81100086933]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Debevec]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[USC Institute for Creative Technologies]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>360353</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. F. Blinn, "Texture and Reflection in Computer Generated Images," Comm. ACM, vol. 19, no. 10, Oct. 1976, pp. 542--547.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[G. S. Miller and C. R. Hoffman, "Illumination and Reflection Maps: Simulated Objects in Simulated and Real Environments," Proc. Siggraph 84, Course Notes for Advanced Computer Graphics Animation, ACM Press, New York, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280864</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. Debevec, "Rendering Synthetic Objects Into Real Scenes: Bridging Traditional and Image-Based Graphics with Global Illumination and High Dynamic Range Photography," Computer Graphics (Proc. Siggraph 98), ACM Press, New York, 1998, pp. 189--198.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>13023</ref_obj_id>
				<ref_obj_pid>13021</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[N. Greene, "Environment Mapping and Other Applications of World Projections," IEEE Computer Graphics and Applications, vol. 6, no. 11, Nov. 1986, pp. 21--29.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258884</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[P. E. Debevec and J. Malik, "Recovering High Dynamic Range Radiance Maps from Photographs," Computer Graphics (Proc. Siggraph 97), ACM Press, New York, 1997, pp. 369--378.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[G. Ward, "Real Pixels," Graphics Gems II, J. Arvo, ed., Academic Press, Boston, 1991, pp. 80--83.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344855</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[P. Debevec et. al, "Acquiring the Reflectance Field of a Human Face," Computer Graphics (Proc. Siggraph 2000), ACM Press, New York, 2000, pp. 145--156.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311558</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D. E. Zongker et. al, "Environment Matting and Compositing," Computer Graphics (Proc. Siggraph 99), ACM Press, New York, 1999, pp. 205--214.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198710</section_id>
		<sort_key>30</sort_key>
		<section_seq_no>30</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Spatial augmented reality: a modern approach to augmented reality]]></section_title>
		<section_page_from>30</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP40029142</person_id>
				<author_profile_id><![CDATA[81100622976]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Oliver]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bimber]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>PP40022814</person_id>
				<author_profile_id><![CDATA[81100022847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ramesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Raskar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198711</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Modern approaches to augmented reality]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198711</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198711</url>
		<abstract>
			<par><![CDATA[This tutorial discusses the Spatial Augmented Reality (SAR) concept, its advantages and limitations. It will present examples of state-of-the-art display configurations, appropriate real-time rendering techniques, details about hardware and software implementations, and current areas of application. Specifically, it will describe techniques for optical combination using single/multiple spatially aligned mirror-beam splitters, image sources, transparent screens and optical holograms. Furthermore, it presents techniques for projector-based augmentation of geometrically complex and textured display surfaces, and (along with optical combination) methods for achieving consistent illumination and occlusion effects. Emerging technologies that have the potential of enhancing future augmented reality displays will be surveyed.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.5.1</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP40029142</person_id>
				<author_profile_id><![CDATA[81100622976]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Oliver]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bimber]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bauhaus University, Weimar, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40022814</person_id>
				<author_profile_id><![CDATA[81100022847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ramesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Raskar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MERL - Mitsubishi Electric Research Lab, Cambridge]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{Azu97} Azuma, R. T., A Survey of Augmented Reality. Presence: Teleoperators and Virtual Environments, vol. 6, no. 4, pp. 355--385, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{Bim00} Bimber, O., Encarna&#231;&#227;o, L. M., and Schmalstieg, D. Augmented Reality with Back-Projection Systems using Transflective Surfaces. Computer Graphics Forum (proceedings of EUROGRAPHICS 2000 - EG'2000), vol. 19, no. 3, pp.161--168, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618863</ref_obj_id>
				<ref_obj_pid>616073</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{Bim01a} Bimber, O., Fr&#246;hlich, B., Schmalstieg, D., and Encarna&#231;&#227;o, L. M. The Virtual Showcase. IEEE Computer Graphics & Applications, vol. 21, no.6, pp. 48--55, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1246734</ref_obj_id>
				<ref_obj_pid>1246729</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{Bim01b} Bimber, O., Encarna&#231;&#227;o, L. M. and Branco, P. The Extended Virtual Table: An Optical Extension for Table-Like Projection Systems. Presence: Teleoperators and Virtual Environments, vol.10, no. 6, pp. 613--631, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>854984</ref_obj_id>
				<ref_obj_pid>850976</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{Bim02a} Bimber, O. and Fr&#246;hlich, B. Occlusion Shadows: Using Projected Light to Generate Realistic Occlusion Effects for View-Dependent Optical See-Through Displays. In proceedings of International Symposium on Mixed and Augmented Reality (ISMAR'02), pp. 186--195, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>622059</ref_obj_id>
				<ref_obj_pid>619079</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{Bim02b} Bimber, O., Gatesy, S. M., Witmer, L. M., Raskar, R. and Encarna&#231;&#227;o, L. M. Merging Fossil Specimens with Computer-Generated Information. IEEE Computer, September, pp. 45--50, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{Bim03} Bimber, O., Fr&#246;hlich, B., Schmalstieg, D., and Encarna&#231;&#227;o, L. M. Real-Time View-Dependent Image Warping to correct Non-Linear Distortion for Curved Virtual Showcase Displays. To appear in Computers and Graphics - The international Journal of Systems and Applications in Computer Graphics, vol. 27, no. 4, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>968735</ref_obj_id>
				<ref_obj_pid>968717</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{Bim04a} Bimber, O. Combining Optical Holograms with Interactive Computer Graphics. In IEEE Computer, January issue, pp. 85--91, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1042326</ref_obj_id>
				<ref_obj_pid>1042196</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{Bim04b} Bimber, O., Coriand, F., Kleppe, A., Bruns, E., Zollmann, S., and Langlotz, T. Superimposing Pictorial Artwork with Projected Imagery. To appear in IEEE MultiMedia, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>168657</ref_obj_id>
				<ref_obj_pid>168642</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{Fei93} Feiner, S., MacIntyre, B., et al. Windows on the World: 2D Windows for 3D Augmented Reality. In proceedings of ACM Symposium on User Interface Software and Technology, pp. 145--155, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>854977</ref_obj_id>
				<ref_obj_pid>850976</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{Fig02} Figl, M., Birkfellner, W., Ede, C., Hummel, J., Hanel, R. Watzinger, F., Wanschitz, F., Ewers, R., and Bergmann H. The Control Unit for a Head Mounted Operating Microscope used for Augmented Reality Visualization in Computer Aided Surgery. In proceedings of International Symposium on Mixed and Augmented Reality (ISMAR'02), pp. 69--76, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>159566</ref_obj_id>
				<ref_obj_pid>159544</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{Fiz93} Fitzmaurice, G. W. Situated Information Spaces and Spatially Aware Palmtop Computer. CACM, vol. 35(7), pp. 38--49, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{Fru01} Fr&#252;nd, J.; Geiger, C.; Grafe, M.; Kleinjohann, B.: The augmented reality personal digital assistant. In proceedings of International Symposium on Mixed Reality, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>602355</ref_obj_id>
				<ref_obj_pid>602330</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{Gau03} Gausemeier, J., Fruend, J., Matysczok, C., Bruederlin, B., and Beier, D. Development of a real time image based object recognition method for mobile AR-devices. In proceedings of International Conference on Computer graphics, Virtual Reality, Visualisation and Interaction in Africa, pp. 133--139, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>881335</ref_obj_id>
				<ref_obj_pid>582828</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{Gei01} Geiger, C., Kleinjohann, B., Reimann, C. Stichling, D. Mobile Ar4All. In proceedings of IEEE and ACM International Symposium on Augmented Reality, pp. 181--182, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>881322</ref_obj_id>
				<ref_obj_pid>582828</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{Hua01} Hua, H., Gao, C., Brown, L., Ahuja, N., and Rolland, J. P. Using a head-mounted projective display in interactive augmented environments. In Proceedings of IEEE and ACM International Symposium on Augmented Reality 2001, pp. 217--223, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835773</ref_obj_id>
				<ref_obj_pid>832288</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[{Ina00} Inami, M., Kawakami, N., Sekiguchi, D., Yanagida, Y., Maeda, T. and Tachi, S., Visuo-Haptic Display Using Head-Mounted Projector, Proceedings of IEEE Virtual Reality 2000, pp.233--240, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>836087</ref_obj_id>
				<ref_obj_pid>523977</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[{Kij97} Kijima, R. and Ojika, T. Transition between virtual environment and workstation environment with projective head-mounted display, In proceedings of IEEE Virtual Reality Annual International Symposium, pp. 130--137, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[{Kiy00} Kiyokawa, K., Kurata, Y. and Ohno, H. An Optical See-through Display for Mutual Occlusion of Real and Virtual Environments. In proceedings of IEEE & ACM ISAR 2000, pp. 60--67, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[{Kol93} Kollin, J. A Retinal Display For Virtual-Environment Applications. In proceedings of SID International Symposium, Digest Of Technical Papers, pp. 827, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1045958</ref_obj_id>
				<ref_obj_pid>1045950</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[{Lew04} Lewis, J. R. In the eye of the beholder. IEEE Spectrum, May issue, pp. 16--20, 2004]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>505026</ref_obj_id>
				<ref_obj_pid>505008</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[{Low01} Low, K., Welch, G., Lastra, A., and Fuchs, H. Life-Sized Projector-Based Dioramas. Symposium on Virtual Reality Software and Technology, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033722</ref_obj_id>
				<ref_obj_pid>1032652</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[{Moe04} Moehring, M., Lessig, C., and Bimber, O. Video see-through AR on consumer cell-phones. Submitted to IEEE/ACM ISMAR'04, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383768</ref_obj_id>
				<ref_obj_pid>2383737</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[{Ogi01} Ogi, T., Yamada, T., Yamamoto, K. and Hirose, M. Invisible Interface for Immersive Virtual World. In proceedings of the Immersive Projection Technology Workshop (IPT'01), pp. 237--246, Stuttgart, Germany, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[{Par98} Parsons, J., and Rolland, J. P., A non-intrusive display technique for providing real-time data within a surgeons critical area of interest, In proceedings of Medicine Meets Virtual Reality'98, pp. 246--251, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[{Par65} Parks, T. E. Post Retinal Visual Storage. American Journal of Psychology, vol. 78, pp. 145--147, 1965.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>946844</ref_obj_id>
				<ref_obj_pid>946248</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[{Pas03} Pasman, W. and Woodward, C. Implementation of an augmented reality system on a PDA. In proceedings of IEEE and ACM International Symposium on Mixed and Augmented Reality, pp. 276--277, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>332479</ref_obj_id>
				<ref_obj_pid>332040</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[{Pat00} Patrick, E., Cosgrove, D., Slavkovic, A., Rode, J. A., Verratti, T., and Chiselko, G. Using a Large Projection Screen as an Alternative to Head-Mounted Displays for Virtual Environments. In proceedings of CHI' 2000, vol. 2, no. 1, pp. 479--485, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>741324</ref_obj_id>
				<ref_obj_pid>647987</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[{Pin01} Pinhanez, C. The everywhere displays projector: A device to create ubiquitous graphical interfaces, In proceedings of Ubiquitous Computing, pp. 315--331, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[{Pry98} Pryor, Homer L., Furness, Thomas A. and Viirre, E. The Virtual Retinal Display: A New Display Technology Using Scanned Laser Light. In proceedings of Human Factors and Ergonomics Society, 42nd Annual Meeting, pp. 1570--1574, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>322696</ref_obj_id>
				<ref_obj_pid>322690</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[{Ras98} Raskar, R., Welch, G., and Fuchs, H. Spatially Augmented Reality. In proceedings of First IEEE Workshop on Augmented Reality (IWAR'98), San Francisco, CA, pp. 63--72, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>858144</ref_obj_id>
				<ref_obj_pid>857202</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[{Ras99} Raskar, R., Welch, G., and Chen, W-C. Table-Top Spatially Augmented Reality: Bringing Physical Models to Life with Projected Imagery. In proceedings of Second International IEEE Workshop on Augmented Reality (IWAR'99), San Francisco, CA, pp. 64--71, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732300</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[{Ras01} Raskar, R., Welch, G., Low, K. L. and Bandyopadhyay, D. Shader Lamps: Animating real objects with image-based illumination, In proceedings of Eurographics Rendering Workshop, pp. 89--102, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>508532</ref_obj_id>
				<ref_obj_pid>508530</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[{Ras02} Raskar, R., Ziegler, R. and Willwacher, T. Cartoon Dioramas in Motion, In proceedings of Int. Symp. on Non-photorealistic Animation and Rendering, pp. 7-ff, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882349</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[{Ras03} Raskar, R., van Baar, J., Beardsly, P., Willwacher, T., Rao, S. and Forlines, C. iLamps: Geometrically Aware and Self-Configuring Projectors, In proceedings of ACM Siggraph, pp. 809--818, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[{Rol94} Rolland, J., Rich, H. and Fuchs, H. A Comparison of Optical and Video See-Through Head-Mounted Displays. In proceedings of SPIE: Telemanipulator and Telepresence Technologies, pp. 293--307, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>854951</ref_obj_id>
				<ref_obj_pid>850976</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[{Sch02} Schwald, B., Seibert, H., Weller, T. A Flexible Tracking Concept Applied to Medical Scenarios Using an AR Window. In proceedings of International Symposium on Mixed and Augmented Reality (ISMAR'02), pp. 261--262, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>881317</ref_obj_id>
				<ref_obj_pid>582828</ref_obj_pid>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[{Ste01} Stetten, G., Chib, V., Hildebrand, D., and Bursee, J. Real Time Tomographic Reflection: Phantoms for Calibration and Biopsy, In proceedings of IEEE/ACM International Symposium on Augmented Reality (ISMAR'01), pp. 11--19, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311593</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[{Und99} Underkoffler, J., Ullmer, B. and Ishii, H. Emancipated pixels: real-world graphics in the luminous room, In proceedings of ACM Siggraph, pp. 385--392, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>946910</ref_obj_id>
				<ref_obj_pid>946249</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[{Wag03} Wagner, D., and Schmalstieg, D. First steps towards handheld augmented reality. In proceedings of International Conference on Wearable Computers, pp. 127--136, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>769983</ref_obj_id>
				<ref_obj_pid>769953</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[{All03} Allard, J., Gouranton, V., Lamarque, G., Melin, E., and Raffin, B. Softgenlock: active stereo and GenLock for PC clusters. In proceedings of Immersive Projection Technology and Eurographics Virtual Environments Workshop 2003 (IPT/EGVE'03), pp. 255--260, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[{Azu97} Azuma, R. T., A Survey of Augmented Reality. Presence: Teleoperators and Virtual Environments, vol. 6, no. 4, pp. 355--385, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[{Bim00} Bimber, O., Encarna&#231;&#227;o, L. M., and Schmalstieg, D. Augmented Reality with Back-Projection Systems using Transflective Surfaces. Computer Graphics Forum (proceedings of EUROGRAPHICS 2000 - EG'2000), vol. 19, no. 3, pp.161--168, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618863</ref_obj_id>
				<ref_obj_pid>616073</ref_obj_pid>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[{Bim01a} Bimber, O., Fr&#246;hlich, B., Schmalstieg, D., and Encarna&#231;&#227;o, L. M. The Virtual Showcase. IEEE Computer Graphics & Applications, vol. 21, no.6, pp. 48--55, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1246734</ref_obj_id>
				<ref_obj_pid>1246729</ref_obj_pid>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[{Bim01b} Bimber, O., Encarna&#231;&#227;o, L. M. and Branco, P. The Extended Virtual Table: An Optical Extension for Table-Like Projection Systems. Presence: Teleoperators and Virtual Environments, vol.10, no. 6, pp. 613--631, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[{Bim02} Bimber, O. Interactive rendering for Projection-Based Augmented Reality Displays. Ph.D. Dissertation, University of Technology Darmstadt, http://elib.tu-darmstadt.de/diss/000270/, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[{Bim03} Bimber, O., Fr&#246;hlich, B., Schmalstieg, D., and Encarna&#231;&#227;o, L. M. Real-Time View-Dependent Image Warping to correct Non-Linear Distortion for Curved Virtual Showcase Displays. To appear in Computers and Graphics - The international Journal of Systems and Applications in Computer Graphics, vol. 27, no. 4, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[{Bre73} Brent, R. P. Algorithms for minimization without derivatives. Prentice-Hall, Engelwood Cliffs, NJ, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808588</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[{Hec84} Heckbert, P. and Hanrahan, P. Beam tracing polygonal objects. Compute Graphics (proceedings of SIGGRAPH'84), vol. 18, no. 3, pp. 119--127, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237216</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>50</ref_seq_no>
				<ref_text><![CDATA[{Hop96} Hoppe H. Progressive meshes. Computer Graphics (Proceedings of SIGGRAPH'96), New Orleans, LA, p. 99--108, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258843</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>51</ref_seq_no>
				<ref_text><![CDATA[{Hop97} Hoppe H. View-dependent refinement of progressive meshes. Computer Graphics (Proceedings of SIGGRAPH'97), Los Angeles, CA, p. 189--97, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>288221</ref_obj_id>
				<ref_obj_pid>288216</ref_obj_pid>
				<ref_seq_no>52</ref_seq_no>
				<ref_text><![CDATA[{Hop98} Hoppe H. Smooth view-dependent level-of-detail control and its application to terrain rendering. Proceedings of IEEE Visualization'98, Research Triangle Park, NC, p. 35--42, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237217</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>53</ref_seq_no>
				<ref_text><![CDATA[{Lin96} Lindstrom P, Koller D, Ribarsky W, Hughes L, Faust N, Turner G. Realtime, continuous level of detail rendering for height fields. Computer Graphics (Proceedings of SIGGRAPH'96), New Orleans, LA, p. 109--18, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>54</ref_seq_no>
				<ref_text><![CDATA[{Mck99a} McKay, S., Mason, S., Mair, L. S., Waddell, P., and Fraser, M. Membrane Mirror-Based Display For Viewing 2D and 3D Images. In proceedings of SPIE, vol. 3634, pp. 144--155, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134082</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>55</ref_seq_no>
				<ref_text><![CDATA[{Mit92} Mitchell, D. and Hanrahan, P. Illumination from Curved Reflectors. Computer Graphics (proceedings of SIGGRAPH'92), pp. 283--291, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>272315</ref_obj_id>
				<ref_obj_pid>272313</ref_obj_pid>
				<ref_seq_no>56</ref_seq_no>
				<ref_text><![CDATA[{Moe97} M&#246;ller, T., and Trumbore, B. Fast, Minimum Storage Ray-Triangle Intersection. Journal of graphics tools. vol. 2, no. 1, pp. 21--28, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>57</ref_seq_no>
				<ref_text><![CDATA[{Mck99b} McKay, S., Mason, S., Mair, L. S., Waddell, P., and Fraser, M. Stereoscopic Display using a 1.2-M Diameter Stretchable Membrane Mirror. In proceedings of SPIE, vol. 3639, pp. 122--131, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280929</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>58</ref_seq_no>
				<ref_text><![CDATA[{Ofe98} Ofek, E. and Rappoport A. Interactive reflections on curved objects. Computer Graphics (proceedings of SIGGRAPH'98), pp. 333--342, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>59</ref_seq_no>
				<ref_text><![CDATA[{Ofe99} Ofek. E. Interactive Rendering of View-Dependent Global Lighting Phenomena. Ph.D. Dissertation, Hebrew University (Israel), 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>898009</ref_obj_id>
				<ref_seq_no>60</ref_seq_no>
				<ref_text><![CDATA[{Rol93} Rolland, J. P., and Hopkins, T. A Method of Computational Correction for Optical Distortion in Head-Mounted Displays. (Tech. Rep. No. TR93-045). UNC Chapel Hill, Department of Computer Science, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134071</ref_obj_id>
				<ref_obj_pid>142920</ref_obj_pid>
				<ref_seq_no>61</ref_seq_no>
				<ref_text><![CDATA[{Seg92} Segal, M., Korobkin, C., van Widenfelt, R. Foran, J., and Haeberli, P. Fast Shaddows and Lighting Effects Using Texture Mapping. Computer Graphics (proceedings of SIGGRAPH'92), vol. 26, no. 2, pp. 249--252, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>62</ref_seq_no>
				<ref_text><![CDATA[{Spa92} Spanguolo, M. Polyhedral surface decomposition based on curvature analysis. Modern Geometric Computing for Visualization, Springer Verlag, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383273</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>63</ref_seq_no>
				<ref_text><![CDATA[{Stol01} Stoll, G., Eldridge, M., Patterson, D., Webb, A., Berman, S., Levy, R., Caywood, C., Taveira, M., Hunt, S., Hanrahan, P. Lightning-2: A high-performance subsystem for PC clusters. Computer Graphics (proceedings of SIGGRAPH'01), 2001, pp. 141--148.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>836009</ref_obj_id>
				<ref_obj_pid>527216</ref_obj_pid>
				<ref_seq_no>64</ref_seq_no>
				<ref_text><![CDATA[{Wat95} Watson, B., and Hodges, L. Using Texture Maps to Correct for Optical Distortion in Head Mounted Displays. In proceedings of IEEE VRAIS'95, pp. 172--178, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1246841</ref_obj_id>
				<ref_obj_pid>1246838</ref_obj_pid>
				<ref_seq_no>65</ref_seq_no>
				<ref_text><![CDATA[{Wei99} Wiegand, T. E., von Schloerb, D. W., and Sachtler, W. L. Virtual Workbench: Near-Field Virtual Environment System with Applications. Presence: Teleoperators and Virtual Environments, vol. 8, no. 5, pp. 492--519, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>897967</ref_obj_id>
				<ref_seq_no>66</ref_seq_no>
				<ref_text><![CDATA[{Ban01} D. Bandyopadhyay, R. Raskar, A. State, H. Fuchs, Dynamic Spatially Augmented 3D Painting. UNC Chapel Hill Tech Report TR01--006, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618863</ref_obj_id>
				<ref_obj_pid>616073</ref_obj_pid>
				<ref_seq_no>67</ref_seq_no>
				<ref_text><![CDATA[{Bim01} Bimber, O., Fr&#246;hlich, B., Schmalstieg, D., and Encarna&#231;&#227;o, L. M. The Virtual Showcase. IEEE Computer Graphics & Applications, vol. 21, no. 6, pp. 48--55, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>622059</ref_obj_id>
				<ref_obj_pid>619079</ref_obj_pid>
				<ref_seq_no>68</ref_seq_no>
				<ref_text><![CDATA[{Bim02b} Bimber, O., Gatesy, S. M., Witmer, L. M., Raskar, R. and Encarna&#231;&#227;o, L. M. Merging Fossil Specimens with Computer-Generated Information. IEEE Computer, September, pp. 45--50, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>854984</ref_obj_id>
				<ref_obj_pid>850976</ref_obj_pid>
				<ref_seq_no>69</ref_seq_no>
				<ref_text><![CDATA[{Bim02a} Bimber, O. and Fr&#246;hlich, B. Occlusion Shadows: Using Projected Light to Generate Realistic Occlusion Effects for View-Dependent Optical See-Through Displays. In proceedings of International Symposium on Mixed and Augmented Reality (ISMAR'02), pp. 186--195, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>946789</ref_obj_id>
				<ref_obj_pid>946248</ref_obj_pid>
				<ref_seq_no>70</ref_seq_no>
				<ref_text><![CDATA[{Bim03} Bimber, O. Grundh&#246;fer, A., Wetzstein, G., and Kn&#246;del, S. Consistent Illumination within Optical See-Through Augmented Environments, In proceedings of IEEE/ACM International Symposium on Mixed and Augmented Reality (ISMAR'03), pp. 198--207, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>968735</ref_obj_id>
				<ref_obj_pid>968717</ref_obj_pid>
				<ref_seq_no>71</ref_seq_no>
				<ref_text><![CDATA[{Bim04a} Bimber, O. Combining Optical Holograms with Interactive Computer Graphics. In IEEE Computer, January issue, pp. 85--91, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1042326</ref_obj_id>
				<ref_obj_pid>1042196</ref_obj_pid>
				<ref_seq_no>72</ref_seq_no>
				<ref_text><![CDATA[{Bim04b} Bimber, O., Coriand, F., Kleppe, A., Bruns, E., Zollmann, S., and Langlotz, T. Superimposing Pictorial Artwork with Projected Imagery. Submitted to IEEE MultiMedia, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383270</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>73</ref_seq_no>
				<ref_text><![CDATA[{Boi01} Boivin, S. and Gagalowicz, A. Image-based rendering of diffuse, specular and glossy surfaces from a single image. In proceedings of ACM Siggraph, pp. 107--116, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>74</ref_seq_no>
				<ref_text><![CDATA[{Bre73} Brent, R. P. Algorithms for minimization without derivatives. Prentice-Hall, Engelwood Cliffs, NJ, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>75</ref_seq_no>
				<ref_text><![CDATA[{Bre96} Breen, D. E., Whitaker, R. T., Rose, E. and Tuceryan, M. Interactive Occlusion and Automatic Object Placement for Augmented Reality. Computer and Graphics Forum (proceedings of EUROGRAPHICS'96), vol. 15, no. 3, pp. C11--C22, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375230</ref_obj_id>
				<ref_obj_pid>375213</ref_obj_pid>
				<ref_seq_no>76</ref_seq_no>
				<ref_text><![CDATA[{Che00} Chen, Y., D. Clark, Finkelstein, A., Housel, T. and Li., K., Automatic Alignment of high resolution Multi-Projector Displays using an un-calibrated Camera, In proceedings of IEEE Visualization, pp. 125--130, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166153</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>77</ref_seq_no>
				<ref_text><![CDATA[{Che93} S. E. Chen, and L. Williams. View Interpolation from Image Synthesis. SIGGRAPH '93, pp. 279--288, July 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>78</ref_seq_no>
				<ref_text><![CDATA[{Deb96} P. Debevec, C. J. Taylor, and J. Malik. Modeling and Rendering Architecture from Photographs. SIGGRAPH '96, August 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>79</ref_seq_no>
				<ref_text><![CDATA[{Deb98} P. Debevec, Y. Yu, and G. Borshukov. Efficient View-Dependent Image-Based Rendering with Projective Texture-Mapping. Proc. of 9th Eurographics Workshop on Rendering, June 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>80</ref_seq_no>
				<ref_text><![CDATA[{Dre97} Dreesen, F., von Bally, G. Color holography in a single layer for documentation and analysis of cultural heritage. In Optics within Life Sciences (OWLS IV), Springer Verlag Berlin, Heidelberg, New York, pp. 79--82, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>81</ref_seq_no>
				<ref_text><![CDATA[{Dre00} Dreesen, F., Deler&#233;, H., von Bally, G. High Resolution Color-Holography for Archeological and Medical Applications. In Optics within Life Sciences (OWLS V), Springer Verlag Berlin, Heidelberg, New York, pp. 349--352, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258772</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>82</ref_seq_no>
				<ref_text><![CDATA[{Dre97} Drettakis, G. and Sillion, F. Interactive update of global illumination using a line-space hierarchy. In proceedings of ACM Siggraph'97, pp. 57--64, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>171658</ref_obj_id>
				<ref_seq_no>83</ref_seq_no>
				<ref_text><![CDATA[{Fau93} O. Faugeras. Three-Dimensional Computer Vision: A Geometric Viewpoint. MIT Press, Cambridge, Massachusetts, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>84</ref_seq_no>
				<ref_text><![CDATA[{For93} Fournier, A. Gunawan, A. S., and Romanzin, C. Common illumination between real and computer generated scenes. In proceedings of Graphics Interface'93, pp. 254--262, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732277</ref_obj_id>
				<ref_obj_pid>647652</ref_obj_pid>
				<ref_seq_no>85</ref_seq_no>
				<ref_text><![CDATA[{Gib00} Gibson, S. and Murta, A. Interactive rendering with real-world illumination. In proceedings of 11th Eurographics Workshop on Rendering, pp. 365--376, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>86</ref_seq_no>
				<ref_text><![CDATA[{Gor84} Goral, C. M., Torrance, K. E., Greenberg, D. P., and Battaile, B. Modeling the interaction of light between diffuse surfaces. Computer In proceedings of ACM Siggraph'84, vol. 18, no. 3, pp. 212--222, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237200</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>87</ref_seq_no>
				<ref_text><![CDATA[{Gor96} S. J. Gortler, R. Grzeszczuk, R. Szeliski, and M. F. Cohen. The Lumigraph. SIGGRAPH '96, August 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>881322</ref_obj_id>
				<ref_obj_pid>582828</ref_obj_pid>
				<ref_seq_no>88</ref_seq_no>
				<ref_text><![CDATA[{Hua01} Hua, H., Gao, C., Brown, L., Ahuja, N., and Rolland, J. P. Using a head-mounted projective display in interactive augmented environments. In proceedings of IEEE and ACM International Symposium on Augmented Reality (ISAR'01), pp. 217--223, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>89</ref_seq_no>
				<ref_text><![CDATA[{Kaj86} J. T. Kajiya. The Rendering Equation. Computer Graphics 20(4) (1986), pp. 143--151.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>90</ref_seq_no>
				<ref_text><![CDATA[{Kiy00} Kiyokawa, K., Kurata, Y. and Ohno, H. An Optical See-through Display for Mutual Occlusion of Real and Virtual Environments. In proceedings of IEEE & ACM ISAR 2000, pp. 60--67, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>91</ref_seq_no>
				<ref_text><![CDATA[{Klu02} Klug, M. A., Scalable digital holographic displays, IS&T PICS 2001: Image Processing, Image Quality, Image Capture Systems Conference, Montreal, Quebec, Canada, pp. 26--32, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>92</ref_seq_no>
				<ref_text><![CDATA[{Kol89} Kollin, J. S., Benton, S. A., and Jepsen, M. L. Real-Time Dispaly of 3-D Computer Holograms by Scanning the Image of an Acousto-Optic Mudulator. In Proceedings of SPIE, vol. 1136, Holographic Optics II: Principle and Applications, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237199</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>93</ref_seq_no>
				<ref_text><![CDATA[{Lev96} M. Levoy, and P. Hanrahan. Light Field Rendering. SIGGRAPH '96, August 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614468</ref_obj_id>
				<ref_obj_pid>614280</ref_obj_pid>
				<ref_seq_no>94</ref_seq_no>
				<ref_text><![CDATA[{Los00} Loscos, C., Drettakis, G., and Robert, L. Interactive virtual relighting of real scenes. IEEE Transactions on Visualization and Computer Graphics, vol, 6, no. 3, pp. 289--305, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>505026</ref_obj_id>
				<ref_obj_pid>505008</ref_obj_pid>
				<ref_seq_no>95</ref_seq_no>
				<ref_text><![CDATA[{Low01} Low, K., Welch, G., Lastra, A. and Fuchs, H. Life-Sized Projector-Based Dioramas, In proceedings of Symposium on Virtual Reality Software and Technology, pp-93-101, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>96</ref_seq_no>
				<ref_text><![CDATA[{Luc93} Lucente, M. Interactive computation of holograms using a look-up table. Journal of Electronic Imaging, vol. 2, no. 1, pp. 28--34, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218490</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>97</ref_seq_no>
				<ref_text><![CDATA[{Luc95} Lucente, M. and Tinsley, A. Rendering interactive images. Computer Graphics (proceedings of SIGGRAPH'95), pp. 387--394, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>271312</ref_obj_id>
				<ref_obj_pid>271283</ref_obj_pid>
				<ref_seq_no>98</ref_seq_no>
				<ref_text><![CDATA[{Luc97} Lucente, M. Interactive three-dimensional holographic displays: seeing the future in depth. SIGGRAPH Computer Graphics, special issue on Current, New, and Emerging Display Systems, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>99</ref_seq_no>
				<ref_text><![CDATA[{Mat98} Mather G, Verstraten F, and Anstis S The Motion Aftereffect: a Modern Perspective. Cambridge, Mass: MIT Press, 1998. (http://www.biols.susx.ac.uk/home/George_Mather/Motion/)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375227</ref_obj_id>
				<ref_obj_pid>375213</ref_obj_pid>
				<ref_seq_no>100</ref_seq_no>
				<ref_text><![CDATA[{Maj00} Majumder, A., He, Z., Towles, H., and Welch, G., Achieving Color Uniformity Across Multi-Projector Displays, In proceedings of IEEE Visualization, pp. 117--124, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>101</ref_seq_no>
				<ref_text><![CDATA[{McM96} L. McMillan, and G. Bishop. Plenoptic Modeling. SIGGRAPH '95, August 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835870</ref_obj_id>
				<ref_obj_pid>580130</ref_obj_pid>
				<ref_seq_no>102</ref_seq_no>
				<ref_text><![CDATA[{Nae02} Naemura, T., Nitta, T., Mimura, A., Harashima, H. Virtual Shadows - Enhanced Interaction in Mixed Reality Environments. In proceedings of IEEE Virtual Reality (IEEE VR'02), pp. 293--294, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15909</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>103</ref_seq_no>
				<ref_text><![CDATA[{Nak01} Nakamae, E., Harada, K., Ishizaki, T., and Nishita, T. A montage method: The overlaying of computer generated images onto background photographs. In proceedings of ACM Siggraph'86, pp. 207--214, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>104</ref_seq_no>
				<ref_text><![CDATA[{Nei96} Neider, J., Davis, T., and Woo, M. OpenGL Programming Guide. Release 1, Addison Wesley, ISBN 0-201-63274-8, pp. 157--194, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>105</ref_seq_no>
				<ref_text><![CDATA[{Nod99} Noda, S., Ban, Y., Sato, K., and Chihara, K. An Optical See-Through Mixed Reality Display with Realtime Rangefinder and an Active Pattern Light Source. Transactions of the Virtual Reality Society of Japan, vol. 4, no. 4, pp. 665--670, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>106</ref_seq_no>
				<ref_text><![CDATA[{Pan} Panoram Technology. http://www.panoramtech.com]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>107</ref_seq_no>
				<ref_text><![CDATA[{Pet03} Petz, C. and Magnor, M. Fast Hologram Synthesis for 3D Geometry Models using Graphics Hardware. In proceedings of SPIE'03, Practical Holography XVII and Holographic Materials IX, vol. 5005, pp 266--275, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>741324</ref_obj_id>
				<ref_obj_pid>647987</ref_obj_pid>
				<ref_seq_no>108</ref_seq_no>
				<ref_text><![CDATA[{Pin01} Pinhanez, C. The everywhere displays projector: A device to create ubiquitous graphical interfaces, In proceedings of Ubiquitous Computing, pp. 315--331, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>148286</ref_obj_id>
				<ref_seq_no>109</ref_seq_no>
				<ref_text><![CDATA[{Pre92} Press, W. H., Teukolsky, S. A., Vetterling, W. T. and Flannery, B. P. Numerical Recipes in C - The Art of Scientific Computing (2nd edition), Cambridge University Press, ISBN 0-521-43108-5, pp. 412--420, 19 2.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280861</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>110</ref_seq_no>
				<ref_text><![CDATA[{Ras98} R. Raskar, G. Welch, M. Cutts, A. Lake, L. Stesin, and H. Fuchs. The Office of the Future: A Unified Approach to Image-Based Modeling and Spatially Immersive Displays. SIGGRAPH '98, July 1998]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>319370</ref_obj_id>
				<ref_obj_pid>319351</ref_obj_pid>
				<ref_seq_no>111</ref_seq_no>
				<ref_text><![CDATA[{Ras99} R. Raskar, M. Brown, R. Yang, W. Chen, G. Welch, H. Towles, B. Seales, H. Fuchs. Multi-Projector Displays Using Camera-Based Registration. IEEE Visualization 99, October 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>858144</ref_obj_id>
				<ref_obj_pid>857202</ref_obj_pid>
				<ref_seq_no>112</ref_seq_no>
				<ref_text><![CDATA[{Ras99b} R. Raskar, G. Welch, W. Chen. Tabletop Spatially Augmented Reality: Bringing Physical Models to Life using Projected Imagery. Second Int Workshop on Augmented Reality (IWAR'99), October 1999, San Francisco, CA]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732300</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>113</ref_seq_no>
				<ref_text><![CDATA[{Ras01} Raskar, R., Welch, G., Low, K. L. and Bandyopadhyay, D. Shader Lamps: Animating real objects with image-based illumination, In proceedings of Eurographics Rendering Workshop, pp. 89--102, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>508532</ref_obj_id>
				<ref_obj_pid>508530</ref_obj_pid>
				<ref_seq_no>114</ref_seq_no>
				<ref_text><![CDATA[{Ras02} Raskar, R., Ziegler, R. and Willwacher, T. Cartoon Dioramas in Motion, In proceedings of Int. Symp on Non-photorealistic Animation and Rendering, pp. 7-ff, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882349</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>115</ref_seq_no>
				<ref_text><![CDATA[{Ras03} Raskar, R., van Baar, J., Beardsly, P., Willwacher, T., Rao, S. and Forlines, C. iLamps: Geometrically Aware and Self-Configuring Projectors, In proceedings of ACM Siggraph, pp. 809--818, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>116</ref_seq_no>
				<ref_text><![CDATA[{Ras04} R. Raskar, P Bearsdley, J VanBaar, Y Wang, P Dietz, J Lee, D Leigh, T Willwacher. RFIG Lamps: Interacting with a Self-Describing World via Photosensing Wireless Tags and Projectors. SIGGRAPH '04, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258861</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>117</ref_seq_no>
				<ref_text><![CDATA[{Sze97} R. Szeliski and H. Shum. Creating Full View Panoramic Mosaics and Environment Maps. SIGGRAPH '97, August 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311593</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>118</ref_seq_no>
				<ref_text><![CDATA[{Und99} Underkoffler, J., Ullmer, B. and Ishii, H. Emancipated pixels: real-world graphics in the luminous room, In proceedings of ACM Siggraph, pp. 385--392, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>601697</ref_obj_id>
				<ref_obj_pid>601671</ref_obj_pid>
				<ref_seq_no>119</ref_seq_no>
				<ref_text><![CDATA[{Yan01} Yang, R., Gotz, D., Hensley, J., Towels., H., and Borwn, M., PixelFlex: A Reconfigurable Multi-Projector Display System, In proceedings of IEEE Visualization, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>120</ref_seq_no>
				<ref_text><![CDATA[{Yam90} Yamaguchi, M, Ohyama, N., and Honda, T. Holographic 3-D Printer. In Proceedings of SPIE, V. 1212, p. 84, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>121</ref_seq_no>
				<ref_text><![CDATA[{Yos03} Yoshida, T., Horii, C. and Sato, K. A Virtual Color reconstruction System for Real Heritage with Light Projection, In proceedings of Virtual Systems and Multimedia, pp. 158--164, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311559</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>122</ref_seq_no>
				<ref_text><![CDATA[{Yu99} Yu, Y., Debevec, P., Malik, J., and Hawkins, T. Inverse global illumination: Recovering reflectance models of real scenes from photographs. In proceedings of ACM Siggraph' 99, pp. 215--224, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618863</ref_obj_id>
				<ref_obj_pid>616073</ref_obj_pid>
				<ref_seq_no>123</ref_seq_no>
				<ref_text><![CDATA[{Bim01} Bimber, O., Fr&#246;hlich, B., Schmalstieg, D., and Encarna&#231;&#227;o, L. M. The Virtual Showcase. IEEE Computer Graphics & Applications, vol. 21, no. 6, pp. 48--55, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>968735</ref_obj_id>
				<ref_obj_pid>968717</ref_obj_pid>
				<ref_seq_no>124</ref_seq_no>
				<ref_text><![CDATA[{Bim04} Bimber, O. Combining Optical Holograms with Interactive Computer Graphics. In IEEE Computer, January issue, pp. 85--91, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>125</ref_seq_no>
				<ref_text><![CDATA[{Bur90} Burroughes, J. H. Light Emitting Polymers. Nature, pp. 347, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>126</ref_seq_no>
				<ref_text><![CDATA[{Cas02} Canesta. Miniature Laser Projector Keyboard. Retrieved from the World Wide Web: http://www.canesta.com. 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>127</ref_seq_no>
				<ref_text><![CDATA[{Dow96} Downing, E. A., Hesselink, L., Ralston, J. and Macfarlane, R. A three-color, solid-state three-dimensional display. Science, vol. 273, pp. 1185--1189, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>128</ref_seq_no>
				<ref_text><![CDATA[{Fog04} Fogscreen Inc. Projecting Images in thin Air. Retrieved from the World Wide Web: http://www.fogscreen.com/, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>129</ref_seq_no>
				<ref_text><![CDATA[{How01} Howard, W. E. Organic Light Emitting Diodes (OLED). OLED Technology Primer, Retrieved from the World Wide Web: http://www.emagin.com/oledpri.htm, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>130</ref_seq_no>
				<ref_text><![CDATA[{IO204} IO2 Technology, The HelioDisplay. Retrieved from the World Wide Web: http://www.io2technology.com/, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>131</ref_seq_no>
				<ref_text><![CDATA[{Jen02} Jenoptik. Laser Projector. Retrieved from the World Wide Web: http://www.jenoptik.com, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>132</ref_seq_no>
				<ref_text><![CDATA[{Klu01} Klug, M. A., Scalable digital holographic displays, IS&T PICS 2001: Image Processing, Image Quality, Image Capture Systems Conference, Montreal, Quebec, Canada, pp. 26--32, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>271312</ref_obj_id>
				<ref_obj_pid>271283</ref_obj_pid>
				<ref_seq_no>133</ref_seq_no>
				<ref_text><![CDATA[{Luc97} Lucente, M. Interactive three-dimensional holographic displays: seeing the future in depth. SIGGRAPH Computer Graphics, special issue on "Current, New, and Emerging Display Systems", 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>977271</ref_obj_id>
				<ref_obj_pid>977240</ref_obj_pid>
				<ref_seq_no>134</ref_seq_no>
				<ref_text><![CDATA[{Pau04} Paulson, L. D. Displaying Data in Thin Air. IEEE Computer, March issue, p. 19, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344933</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>135</ref_seq_no>
				<ref_text><![CDATA[{Per00} Perlin, K., Paxia, S., and Kollin, J. S. An autostereoscopic display. Computer Graphics (proceedings of SIGGRAPH'00), pp. 319--326, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015738</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>136</ref_seq_no>
				<ref_text><![CDATA[{Ras04} R. Raskar, P Bearsdley, J VanBaar, Y Wang, P Dietz, J Lee, D Leigh, T Willwacher. RFIG Lamps: Interacting with a Self-Describing World via Photosensing Wireless Tags and Projectors. SIGGRAPH '04, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>137</ref_seq_no>
				<ref_text><![CDATA[{Sie02} Siemens. Siemens Mini Beamer. Retrieved from the World Wide Web: http://w4.siemens.de/en2/html/press//newsdeskarchive/2002/-foe02121b.html, Cited December 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>138</ref_seq_no>
				<ref_text><![CDATA[{Sym02} Symbol. Laser Projection Display. Retrieved from the World Wide Web: http://www.symbol.com/products/oem/lpd.html, December, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>139</ref_seq_no>
				<ref_text><![CDATA[{Tra02} Travis, A., Payne, F., Zhong, J., and More, J. Flat panel display using projection within a wedge-shaped waveguide. Retrieved from the World Wide Web: http://ds.dial.pipex.com/cam3d/technology/technology01.html, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>140</ref_seq_no>
				<ref_text><![CDATA[{Xer03} Xerox PARC, Electronic Reusable Paper. Retrieved from the World Wide Web: http://www2.parc.com/dhl/projects/gyricon/, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198712</article_id>
		<sort_key>2</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Cartoon dioramas in motion]]></title>
		<page_from>2</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198712</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198712</url>
		<abstract>
			<par><![CDATA[Cartoon animations delight the audience with moving characters but they remain on a flat 2D screen. The cartoon dioramas, on the other hand, are detailed, three-dimensional and allow physical interaction but they are static. We present techniques to combine the two in some limited cases. We illuminate static physical models with projectors. The images are generated with real time three dimensional computer graphics. We describe a system to demonstrate various visual effects such as non-photorealistic shading, apparent motion and virtual lighting on a toy-car model.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[augmented reality]]></kw>
			<kw><![CDATA[immersive environments]]></kw>
			<kw><![CDATA[non-photorealistic rendering]]></kw>
			<kw><![CDATA[perception]]></kw>
			<kw><![CDATA[virtual reality]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP40022814</person_id>
				<author_profile_id><![CDATA[81100022847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ramesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Raskar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MERL, Mitsubishi Electric Research Labs]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31042562</person_id>
				<author_profile_id><![CDATA[81100444984]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Remo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ziegler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MERL, Mitsubishi Electric Research Labs]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P345963</person_id>
				<author_profile_id><![CDATA[81100647519]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Willwacher]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MERL, Mitsubishi Electric Research Labs]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>881324</ref_obj_id>
				<ref_obj_pid>582828</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bandyopadhyay D., Raskar R., Fuchs H. 2001. Dynamic Shader Lamps: Painting on Movable Objects. In Proceedings of Int. Symp. On Augmented Reality.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>171658</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Faugeras, O. 1993 Three-Dimensional Computer Vision: A Geometric Viewpoint. MIT Press, Cambridge, Massachusetts.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Kersten, D., Mamassian P., and Knill D. 1997. Moving cast shadows induce apparent motion in depth. Perception, 26, 171--192.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>340918</ref_obj_id>
				<ref_obj_pid>340916</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Lake, A., Marshall, C, Harris, M. and Blackstein, M. 2000. Stylized Rendering Techniques for Scalable Real-Time 3D Animation, In Proceedings of Non-Photorealistic Animation and Rendering, Annecy, France, June 5--7.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Liljegren, G. E. and Foster, E. L. 1990. Figure with Back Projected Image Using Fiber Optics. US Patent # 4,978.216, Walt Disney Company, USA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>505026</ref_obj_id>
				<ref_obj_pid>505008</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Low, K., Welch, G., Lastra, A., Fuchs H. 2001. Life-Sized Projector-Based Dioramas. Symposium on Virtual Reality Software and Technology.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Mather, G., Verstraten, F., and Anstis, S. 1998. The Motion Aftereffect: a Modern Perspective. MIT Press, Cambridge, Massachusetts. (http://www.biols.susx.ac.uk/home/George_Mather/Motion/)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Milgram, P., Takemura, H., Utsumi, A., and Kishino, F. 1994. Augmented Reality: A class of displays on the reality-virtuality continuum. SPIE Vol. 2351--34, Telemanipulator and Telepresence Technologies.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383328</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Praun, E., Hoppe, H., Webb, M., Finkelstein, A. 2001 Real-Time Hatching. In Proceedings of ACM SIGGRAPH 2001, ACM Press / ACM SIGGRAPH, E. Fiume, Ed., Computer Graphics Proceedings, Annual Conference Series, ACM.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732300</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., Welch, G., Low, K., Bandyopadhyay D. 2001. Shader Lamps, Animating Real Objects with Image Based Illumination. In Proceedings of the 12th Eurographics Workshop on Rendering.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383525</ref_obj_id>
				<ref_obj_pid>383507</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Raskar, R. 2001. Hardware Support for Non-photorealistic Rendering. In Proceedings of the ACM/Eurographics Workshop on Graphics Hardware.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Shams, L., Kamitani Y. and Shimojo, S. 2000. What you see is what you hear. Nature, pp 788. Dec 14, 2000. (http://neuro.caltech.edu/publications/shams.shtml)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Smith A, and Snowden R. 1994. Visual Detection of Motion. London: Academic Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Underkoffler, J. 97. A View From the Luminous Room. Springer-Verlag London Ltd., Personal Technologies (1997) 1:49--59.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>159630</ref_obj_id>
				<ref_obj_pid>159544</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Wellner, P. 1993. Interacting with paper on the DigitalDesk. Communications of the ACM, 36(7):87--96. July]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198713</article_id>
		<sort_key>3</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[The virtual showcase]]></title>
		<page_from>3</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198713</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198713</url>
		<abstract>
			<par><![CDATA[We present the Virtual Showcase, a new multiviewer augmented reality display device that has the same form factor as a real showcase traditionally used for museum exhibits.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40029142</person_id>
				<author_profile_id><![CDATA[81100622976]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Oliver]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bimber]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Fraunhofer Institute for Computer Graphics, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35025232</person_id>
				<author_profile_id><![CDATA[81100162399]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bernd]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fr&#246;hlich]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bauhaus University Weimar, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P550213</person_id>
				<author_profile_id><![CDATA[81100091694]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Dieter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schmalstieg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Vienna University of Technology, Austria]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P165553</person_id>
				<author_profile_id><![CDATA[81100063439]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[L.]]></first_name>
				<middle_name><![CDATA[Miguel]]></middle_name>
				<last_name><![CDATA[Encarna&#231;&#227;o]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Fraunhofer Center for Research in Computer Graphics]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>322696</ref_obj_id>
				<ref_obj_pid>322690</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Raskar, G. Welch, and H. Fuchs, "Spatially Augmented Reality," Augmented Reality: Placing Artificial Objects in Real Scenes (Proc. First IEEE Workshop Augmented Reality, IWAR 98), R. Behringer, G. Klinker, and D. Mizell, eds., A. K. Peters, Natick, Mass., 1998, pp. 64--71.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M. Walker, Ghostmasters: A Look Back at America's Midnight Spook Shows, Cool Hand Communications, Boca Raton, Fla., 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[K. C. Knowlton, "Computer Displays Optically Superimpose on Input Devices," Bell Systems Tech. J., vol. 53, no. 3, March 1977, pp. 36--383.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>207133</ref_obj_id>
				<ref_obj_pid>207072</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. Poston and L. Serra, "The Virtual Workbench: Dextrous VR," Proc. Virtual Reality Software and Technology (VRST 94), IEEE CS Press, Los Alamitos, Calif., 1994, pp. 111--121.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1246841</ref_obj_id>
				<ref_obj_pid>1246838</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[T. E. Weigand, D. W. von Schloerb, and W. L. Sachtler, "Virtual Workbench: Near-Field Virtual Environment System with Applications," Presence, vol. 8, no. 5, Oct. 1999, pp. 492--519.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[C. Chinnock, "Holographic 3D images Float in Free Space," Laser Focus World, vol. 31, no. 6, June 1995, pp. 22--24.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. McKay et al., "Membrane Mirror Based Display For Viewing 2D and 3D Images," Proc. SPIE 3634---Projection Displays V, vol. 3634, SPIE Press, Bellingham, Wash., 1999, pp. 144--155.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[H. Fuchs et al., "Adding a True 3-D Display to a Raster Graphics System," IEEE Computer Graphics and Applications, vol. 2, no. 7, Sept. 1982, pp. 73--78.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[O. Bimber, L. M. Encarna&#231;&#227;o, and D. Schmalstieg, "Augmented Reality with Back-Projection Systems using Trans-flective Surfaces," Computer Graphics Forum (Proc. Eurographics 2000), vol. 19, no. 3, Blackwell Publishers, Oxford, UK, 2000, pp. 161--168.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[H. L&#246;ffelmann and E. Gr&#246;ller, "Ray Tracing with Extended Cameras," J. Visualization and Computer Animation, vol. 7, no. 4, Oct. 1996, pp. 211--228.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134071</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Segal et al., "Fast Shadows and Lighting Effects Using Texture Mapping," Computer Graphics (Proc. Siggraph 92), ACM Press, New York, 1992, pp. 249--252.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>272315</ref_obj_id>
				<ref_obj_pid>272313</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[T. M&#246;ller and B. Trumbore, "Fast, Minimum Storage Ray-Triangle Intersection," J. Graphics Tools, vol. 2, no. 1, Jan. 1997, pp. 21--28.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198714</article_id>
		<sort_key>4</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Combining optical holograms with interactive computer graphics]]></title>
		<page_from>4</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198714</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198714</url>
		<abstract>
			<par><![CDATA[Merging optical holograms with 3D graphical elements can provide an acceptable tradeoff between quality and interactivity: The holographic data provides high-quality but static content, while additional graphical information can be generated, inserted, modified, and animated at interactive rates.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40029142</person_id>
				<author_profile_id><![CDATA[81100622976]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Oliver]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bimber]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bauhaus University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M. Yamaguchi, N. Ohyama, and T. Honda, "Holographic 3-D Printer," Proc. SPIE, vol. 1212, Springer, 1990, p. 84.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M. A. Klug, "Scalable Digital Holographic Displays," Image Processing, Image Quality, Image Capture Systems Conf. (IS&T PICS 2001), 2001, pp. 26--32.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. S. Kollin, S. A. Benton, and M. L. Jepsen, "Real-Time Display of 3-D Computed Holograms by Scanning the Image of an Acousto-Optic Modulator," Proc. SPIE, vol. 1136, Holographic Optics II: Principles and Applications, Springer, 1989, pp. 178--185.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>271312</ref_obj_id>
				<ref_obj_pid>271283</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M. Lucente, "Interactive Three-Dimensional Holographic Displays: Seeing the Future in Depth," Siggraph Computer Graphics, special issue on Current, New, and Emerging Display Systems, ACM Press, 1997, pp. 63--67.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218490</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. Lucente and A. Tinsley, "Rendering Interactive Images," Proc. Siggraph 95, ACM Press, 1995, pp. 387--394.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Lucente, "Interactive Computation of Holograms Using a Look-Up Table," J. Electronic Imaging, vol. 2, no. 1, 1993, pp. 28--34.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[C. Petz and M. Magnor, "Fast Hologram Synthesis for 3D Geometry Models Using Graphics Hardware," Proc. SPIE 03, Practical Holography XVII and Holographic Materials IX, vol. 5005, Springer, 2003, pp. 266--275.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[F. Dreesen and G. von Bally, "Color Holography in a Single Layer for Documentation and Analysis of Cultural Heritage," Optics within Life Sciences (OWLS IV), Springer, 1997, pp. 79--82.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[F. Dreesen, H. Deler&#233;, and G. von Bally, "High-Resolution Color Holography for Archaeological and Medical Applications," Optics within Life Sciences (OWLS V), Springer, 2000, pp. 349--352.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198715</article_id>
		<sort_key>5</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[iLamps]]></title>
		<subtitle><![CDATA[geometrically aware and self-configuring projectors]]></subtitle>
		<page_from>5</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198715</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198715</url>
		<abstract>
			<par><![CDATA[Projectors are currently undergoing a transformation as they evolve from static output devices to portable, environment-aware, communicating systems. An enhanced projector can determine and respond to the geometry of the display surface, and can be used in an ad-hoc cluster to create a self-configuring display. Information display is such a prevailing part of everyday life that new and more flexible ways to present data are likely to have significant impact. This paper examines geometrical issues for enhanced projectors, relating to customized projection for different shapes of display surface, object augmentation, and co-operation between multiple units.We introduce a new technique for adaptive projection on non-planar surfaces using conformal texture mapping. We describe object augmentation with a hand-held projector, including interaction techniques. We describe the concept of a display created by an ad-hoc cluster of heterogeneous enhanced projectors, with a new global alignment scheme, and new parametric image transfer methods for quadric surfaces, to make a seamless projection. The work is illustrated by several prototypes and applications.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[ad-hoc clusters]]></kw>
			<kw><![CDATA[augmented reality]]></kw>
			<kw><![CDATA[calibration]]></kw>
			<kw><![CDATA[projector]]></kw>
			<kw><![CDATA[quadric transfer]]></kw>
			<kw><![CDATA[seamless display]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>B.4.2</cat_node>
				<descriptor>Image display</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Artificial, augmented, and virtual realities</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.1</cat_node>
				<descriptor>Imaging geometry</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010392</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Mixed / augmented reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010235</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->Epipolar geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010866</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP40022814</person_id>
				<author_profile_id><![CDATA[81100022847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ramesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Raskar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs (MERL), Cambridge MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P138848</person_id>
				<author_profile_id><![CDATA[81100490339]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jeroen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[van Baar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs (MERL), Cambridge MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P220909</person_id>
				<author_profile_id><![CDATA[81100489358]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Beardsley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs (MERL), Cambridge MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P345963</person_id>
				<author_profile_id><![CDATA[81100647519]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Willwacher]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs (MERL), Cambridge MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P511634</person_id>
				<author_profile_id><![CDATA[81100593187]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Srinivas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs (MERL), Cambridge MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP38026076</person_id>
				<author_profile_id><![CDATA[81100584798]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Clifton]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Forlines]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs (MERL), Cambridge MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Agarwal, P., Amenta, N., Aronov, B., and Sharir, M. 1996. Largest Placements and Motion Planning of a Convex Polygon. In 2nd International Workshop on Algorithmic Foundation of Robotics, 1996, 28--37.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166126</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bier, E. A., Stone, M. C., Pier, K., Buxton, W., and DeRose, T. D. 1993. Toolglass and Magic Lenses: The See-Through Interface. In Proceedings of ACM SIGGRAPH 1993, 73--80.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>622059</ref_obj_id>
				<ref_obj_pid>619079</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bimber, O., Gatesy, S., Witmer, L., Raskar, R., and Encarnao, E. 2002. Merging Fossil Specimens with Computer-Generated Information. In IEEE Computer, 32--39.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>826633</ref_obj_id>
				<ref_obj_pid>826030</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Brown, M. S., and Seales, W. B. 2002. A Practical and Flexible Large Format Display System. In The Tenth Pacific Conference on Computer Graphics and Applications, 178--183.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Canesta, 2002. Miniature Laser Projector Keyboard. http://www.canesta.com, Cited December 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375230</ref_obj_id>
				<ref_obj_pid>375213</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Chen, Y., Chen, H., Clark, D. W., Liu, Z., Wallace, G., and Li, K. 2000. Automatic Alignment of High-Resolution Multi-Projector Displays Using An Un-Calibrated Camera. In IEEE Visualization 2000, 125--130.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>602151</ref_obj_id>
				<ref_obj_pid>602099</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Chen, H., Sukthankar, R., Wallace, G., and Li, K. 2002. Scalable Alignment of Large-Format Multi-Projector Displays Using Camera Homography Trees. In Proceedings of Visualization, 2002, 135--142.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>939186</ref_obj_id>
				<ref_obj_pid>938978</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cross, G., and Zisserman, A. 1998. Quadric Surface Reconstruction from Dual-Space Geometry. In Proceedings of 6th International Conference on Computer Vision(Bombay, India), 25--31.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>330540</ref_obj_id>
				<ref_obj_pid>330534</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Crowley, J., Coutaz, J., and Berard, F. 2000. Things That See. Communications of the ACM (Mar.), 54--64.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>794798</ref_obj_id>
				<ref_obj_pid>794191</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Davis, J. 1998. Mosaics of Scenes with Moving Objects. In IEEE Computer Vision and Pattern Recognition (CVPR), 354--360.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618741</ref_obj_id>
				<ref_obj_pid>616065</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Hereld, M., Judson, I. R., and Stevens, R. L. 2000. Introduction to Building Projection-based Tiled Display Systems. IEEE Computer Graphics and Applications 20, 4, 22--28.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383272</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Humphreys, G., Eldridge, M., B., I., Stoll, G., Everett, M., and HANRAHAN, P. 2001. WireGL: A Scalable Graphics System for Clusters. In Proceedings of SIGGRAPH 2001, 129--140.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Jarvis, K. 1997. Real Time 60Hz Distortion Correction on a Silicon Graphics IG. Real Time Graphics 5, 7 (Feb.), 6--7.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>601698</ref_obj_id>
				<ref_obj_pid>601671</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Jaynes, C., Webb, S., Steele, R., Brown, M., and Seales, B. 2001. Dynamic Shadow Removal from Front Projection Displays, In IEEE Visualization 2001, 152--157.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Jenoptik, 2002. Laser Projector. http://www.jenoptik.com, Cited December 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>875412</ref_obj_id>
				<ref_obj_pid>874061</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Kjeldsen, R., Pinhanez, C., Pingali, G., Hartman, J., Levas, T., and Podlaseck, M. 2002. Interacting with Steerable Projected Displays. In Proc. of the 5th International Conference on Automatic Face and Gesture Recognition, 12--17.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566590</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Levy, B., Petitjean, S., Ray, N., and Maillot, J. 2002. Least Squares Conformal Maps for Automatic Texture Atlas Generation. In ACM Transactions on Graphics, vol. 21, 3, 162--170.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>355097</ref_obj_id>
				<ref_obj_pid>355091</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Lu, C., Hager, G., and Mjolsness, E. 2000. Fast and Globally Convergent Pose Estimation from Video Images. IEEE Transactions on Pattern Analysis and Machine Intelligence 22, 6, 610--622.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Majumder, A., He, Z., Towles, H., and Welch, G. 2000. Color Calibration of Projectors for Large Tiled Displays. In IEEE Visualization 2000, 102--108.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>741324</ref_obj_id>
				<ref_obj_pid>647987</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Pinhanez, C. 2001. The Everywhere Displays Projector: A Device to Create Ubiquitous Graphical Interfaces. In Ubiquitous Computing 2001 (Ubicomp "01), 12--17.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., and Beardsley, P. 2001. A Self Correcting Projector. In IEEE Computer Vision and Pattern Recognition (CVPR), 626--631.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280861</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., Welch, G., Cutts, M., Lake, A., Stesin, L., and Fuchs, H. 1998. The Office of the Future: A Unified Approach to Image-Based Modeling and Spatially Immersive Displays. In Proceedings of ACM SIGGRAPH 1998, 179--188.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>319370</ref_obj_id>
				<ref_obj_pid>319351</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., Brown, M., Ruigang, Y., Chen, W., Welch, G., Towles, H., Seales, B., and Fuchs, H. 1999. Multiprojector Displays using Camera-based Registration. In IEEE Visualization, 161--168.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732300</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., Welch, G., Low, K., and Bandyopadhyay, B. 2001. Shader Lamps: Animating Real Objects With Image-Based Illumination. In Rendering Techniques 2001, The Eurographics Workshop on Rendering, 89--102.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., VanBaar, J., and Chai, X. 2002. A Low Cost Projector Mosaic with Fast Registration. In Fifth Asian Conference on Computer Vision, 114--119.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835738</ref_obj_id>
				<ref_obj_pid>832288</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Raskar, R. 2000. Immersive Planar Display using Roughly Aligned Projectors. In IEEE VR 2000, 27--34.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>215639</ref_obj_id>
				<ref_obj_pid>215585</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Rekimoto, J., and Nagao, K. 1995. The World Through the Computer: Computer Augmented Interaction with Real World Environments. In Proceedings of UIST '95, 29--36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>303113</ref_obj_id>
				<ref_obj_pid>302979</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Rekimoto, J., and Saitoh, M. 1999. Augmented Surfaces: A Spatially Continuous Workspace for Hybrid Computing Environments. In Proceedings of CHI'99, 378--385.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>274692</ref_obj_id>
				<ref_obj_pid>274644</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Rekimoto, J. 1999. A Multiple-device Approach for Supporting Whiteboard-based Interactions. In Proceedings of CHI'98, 344--351.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311584</ref_obj_id>
				<ref_obj_pid>311534</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Samanta, R., Zheng, J., Funkhouser, T., Li, K., and Singh, J. P. 1999. Load Balancing for Multi-Projector Rendering Systems. In SIGGRAPH/Eurographics Workshop on Graphics Hardware, 12--19.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>257972</ref_obj_id>
				<ref_obj_pid>257956</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Shashua, A., and Toelg, S. 1997. The Quadric Reference Surface: Theory and Applications. In IJCV, vol. 23(2), 185--189.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Siemens, 2002. Siemens Mini Beamer. http://w4.siemens.de/en2/html/press//newsdesk_archive/2002/-foe02121b.html, Cited December 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Sukthankar, R., Stockton, R., and Mullin, P. 2001. Smarter Presentations: Exploiting Homography in Camera-Projector Systems. In International Conference on Computer Vision, 82--87.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Symbol, 2002. Laser Projection Display. http://www.symbol.com/products/oem/lpd.html, Cited December 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Travis, A., Payne, F., Zhong, J., and Moore, J. 2002. Flat panel display using projection within a wedge-shaped waveguide. http://ds.dial.pipex.com/cam3d/technology/technology01.html, Cited December 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Trimension Systems Ltd, 2002. http://www.trimension-inc.com/, Cited Dec 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311593</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Underkoffler, J., Ullmer, B., and Ishii, H. 1999. Emancipated Pixels: Real-world Graphics in the Luminous Room. In Proceedings of ACM SIGGRAPH 1999, 385--392.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Watson, B., and Hodges, L. 1989. A Fast Algorithm for Rendering Quadratic Curves on Raster Displays. In Proc. 27th Annual SE ACM Conference, 160--165.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>159630</ref_obj_id>
				<ref_obj_pid>159544</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Wellner, P. 1993. Interacting with paper on the DigitalDesk. Communications of the ACM 36, 7, 86--97.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Wexler, Y., and Shashua, A. 1999. Q-warping: Direct Computation of Quadratic Reference Surfaces. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), June, 1999, 333--338.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>601697</ref_obj_id>
				<ref_obj_pid>601671</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Yang, R., Gotz, D., Hensley, J., Towles, H., and Brown, M. 2001. PixelFlex: A Reconfigurable Multi-Projector Display System. In IEEE Visualization 01, 68--75.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Yotsukura, T., Morishima, S., Nielsen, F., Binsted, K., and Pinhanez, C. 2002. Hyper Mask - Talking Head Projected onto Real Object. The Visual Computer 18, 2, 111--120.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198716</article_id>
		<sort_key>6</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Superimposing pictorial artwork with projected imagery]]></title>
		<page_from>6</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198716</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198716</url>
		<abstract>
			<par><![CDATA[We present a novel approach for using pictorial artwork as information displays and show how to combine almost any kind of computergenerated visual information directly with the painted content.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40029142</person_id>
				<author_profile_id><![CDATA[81100622976]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Oliver]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bimber]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bauhaus University Weimar]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31035310</person_id>
				<author_profile_id><![CDATA[81100280218]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Franz]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Coriand]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bauhaus University Weimar]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P708720</person_id>
				<author_profile_id><![CDATA[81100534945]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Alexander]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kleppe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bauhaus University Weimar]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40024453</person_id>
				<author_profile_id><![CDATA[81100166035]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Erich]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bruns]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bauhaus University Weimar]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31031742</person_id>
				<author_profile_id><![CDATA[81100198962]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Stefanie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zollmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bauhaus University Weimar]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P708802</person_id>
				<author_profile_id><![CDATA[81100355442]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Tobias]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Langlotz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bauhaus University Weimar]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>375230</ref_obj_id>
				<ref_obj_pid>375213</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Y. Chen et al., "Automatic Alignment of High Resolution Multi-Projector Displays Using an Uncalibrated Camera," Proc. IEEE Visualization, IEEE CS Press, 2000, pp. 125--130.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>601697</ref_obj_id>
				<ref_obj_pid>601671</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Yang et al., "PixelFlex: A Reconfigurable Multi-Projector Display System," Proc. IEEE Visualization, IEEE CS Press, 2001, pp. 21--26.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732300</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Raskar et al., "Shader Lamps: Animating Real Objects with Image-Based Illumination," Proc. Eurographics Rendering Workshop, Eurographics Assoc., 2001, pp. 89--102.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375227</ref_obj_id>
				<ref_obj_pid>375213</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Majumder et al., "Achieving Color Uniformity Across Multi-Projector Displays," Proc. IEEE Visualization, IEEE CS Press, 2000, pp. 117--124.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166126</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[E. Bier et al., "Toolglasses and Magic Lenses: The See-Through Interface," Proc. ACM Siggraph, ACM Press, 1993, pp. 73--80.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[T. Yoshida, C. Horii, and K. Sato, "A Virtual Color Reconstruction System for Real Heritage with Light Projection," Proc. Virtual Systems and Multimedia, IEEE CS Press, 2003, pp. 158--164.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198717</article_id>
		<sort_key>7</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[RFIG lamps]]></title>
		<subtitle><![CDATA[interacting with a self-describing world via photosensing wireless tags and projectors]]></subtitle>
		<page_from>7</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198717</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198717</url>
		<abstract>
			<par><![CDATA[This paper describes how to instrument the physical world so that objects become self-describing, communicating their identity, geometry, and other information such as history or user annotation. The enabling technology is a wireless tag which acts as a radio frequency identity and geometry (RFIG) transponder. We show how addition of a photo-sensor to a wireless tag significantly extends its functionality to allow <i>geometric</i> operations - such as finding the 3D position of a tag, or detecting change in the shape of a tagged object. Tag data is presented to the user by direct projection using a handheld locale-aware mobile projector. We introduce a novel technique that we call interactive projection to allow a user to interact with projected information e.g. to navigate or update the projected information.The ideas are demonstrated using objects with active radio frequency (RF) tags. But the work was motivated by the advent of unpowered passive-RFID, a technology that promises to have significant impact in real-world applications. We discuss how our current prototypes could evolve to passive-RFID in the future.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[augmented reality]]></kw>
			<kw><![CDATA[human-machine communication]]></kw>
			<kw><![CDATA[image stabilization]]></kw>
			<kw><![CDATA[projector]]></kw>
			<kw><![CDATA[radio frequency identification]]></kw>
			<kw><![CDATA[stucture from motion]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Artificial, augmented, and virtual realities</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Interaction styles (e.g., commands, menus, forms, direct manipulation)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.1</cat_node>
				<descriptor>Imaging geometry</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010235</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->Epipolar geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010392</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Mixed / augmented reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010866</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP40022814</person_id>
				<author_profile_id><![CDATA[81100022847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ramesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Raskar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs, Cambridge MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P220909</person_id>
				<author_profile_id><![CDATA[81100489358]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Beardsley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs, Cambridge MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P138848</person_id>
				<author_profile_id><![CDATA[81100490339]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jeroen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[van Baar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs, Cambridge MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40025139</person_id>
				<author_profile_id><![CDATA[81100232956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Yao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs, Cambridge MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P221214</person_id>
				<author_profile_id><![CDATA[81100246613]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dietz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs, Cambridge MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P438791</person_id>
				<author_profile_id><![CDATA[81388599173]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Johnny]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs, Cambridge MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P60017</person_id>
				<author_profile_id><![CDATA[81100491228]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Darren]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Leigh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs, Cambridge MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P345963</person_id>
				<author_profile_id><![CDATA[81100647519]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Willwacher]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Labs, Cambridge MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>332842</ref_obj_id>
				<ref_obj_pid>332833</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Abelson, H., Allen, D., Coore, D., Hanson, C., Homsy, G., Knight, T., Nagpal, R., Rauch, E., Sussman, G., and Weiss., R. 2000. Amorphous computing. In Communications of the ACM, vol. 43(5), 74--82.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618862</ref_obj_id>
				<ref_obj_pid>616073</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Azuma, R., Baillot, Y., Behringer, R., Feiner, S., Julier, S., and MacIntyre, B. 2001. Recent Advances in Augmented Reality. In IEEE Computer Graphics and Applications, vol. 21(6), 34--47.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Beardsley, P., Raskar, R., Forlines, C., and VanBaar, J. 2004. Interactive Projection. TR 2004/042, MERL.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Beardsley, P., VanBaar, J., and Raskar, R. 2004. Augmenting a Projector-Camera Device with Laser Pointers. TR 2004/035, MERL.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618863</ref_obj_id>
				<ref_obj_pid>616073</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bimber, O., Frolich, B., Schmalstieg, D., and Encarnaro, L. M. 2001. The Virtual Showcase. IEEE Comput. Graph. Appl. 21, 6, 48--55.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Canesta, 2002. Miniature Laser Projector Keyboard. http://www.canesta.com.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>358692</ref_obj_id>
				<ref_obj_pid>358669</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Fischler, M. A., and Bolles, R. C. 1981. Random Sample Consensus: a paradigm for model fitting with application to image analysis and automated cartography. Commun. Assoc. Comp. Mach. vol. 24, 381--95.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Foxlin, E., and Naimark, M. 2002. Shadow Effects of Virtual Objects on Real Surfaces with a Handheld Projector. Unpublished.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>373536</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Hartley, R., and Zisserman, A. 2000. Multiple View Geometry in Computer Vision. Cambridge University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>354417</ref_obj_id>
				<ref_obj_pid>354401</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Hinckley, K., Pierce, J., Sinclar, M., and Horvitz, E. 2000. Sensing Techniques for Mobile Interaction. In ACM UIST CHI Letters, vol. 2(2), 91--100.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>741340</ref_obj_id>
				<ref_obj_pid>647987</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Holmquist, L. E., Mattern, F., Schiele, B., Alahuhta, P., Beigl, M., and Gellersen, H.-W. 2001. Smart-Its Friends: A Technique for Users to Easily Establish Connections between Smart Artefacts. In Ubicomp, Springer-Verlag LNCS 2201, 273--291.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Lumileds, 2003. (Bright LEDs). http://lumileds.com.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>741472</ref_obj_id>
				<ref_obj_pid>647988</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Ma, H., and Paradiso, J. A. 2002. The FindIT Flashlight: Responsive Tagging Based on Optically Triggered Microprocessor Wakeup. In Ubicomp, 160--167.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>322585</ref_obj_id>
				<ref_obj_pid>320719</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Moore, D. J., Want, R., and et al. 1999. Implementing Phicons: Combining Computer Vision with InfraRed Technology for Interactive Physical Icons. In Proceedings of ACM UIST'99, 67--68.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Nayar, S. K., Peri, H., Grossberg, M. D., and Belhumeur, P. N. 2003. A Projection System with Radiometric Compensation for Screen Imperfections. In Proc. ICCV Workshop on Projector-Camera Systems (PROCAMS).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1011449</ref_obj_id>
				<ref_obj_pid>1011416</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Omojola, O., Post, E. R., Hancher, M. D., Maguire, Y., Pappu, R., Schoner, B., Russo, P. R., Fletcher, R., and Gershen-feld, N. 2000. An installation of interactive furniture. In IBM Systems Journal, vol. 39(3,4).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Patel, S. N., and Abowd, G. D. 2003. A 2-Way Laser-Assisted Selection Scheme for Handhelds in a Physical Environment. In Ubicomp, 200--207.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>365112</ref_obj_id>
				<ref_obj_pid>365024</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Patten, J., Ishii, H., and Pangaro, G. 2001. Sensetable: A Wireless Object Tracking Platform for Tangible User Interfaces. In Conference on Human Factors in Computing Systems (ACM CHI).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>741324</ref_obj_id>
				<ref_obj_pid>647987</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Pinhanez, C. 2001. The Everywhere Displays Projector: A Device to Create Ubiquitous Graphical Interfaces. In Ubiquitous Computing 2001 (Ubicomp"01).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>322696</ref_obj_id>
				<ref_obj_pid>322690</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., Welch, G., and Fuchs, H. 1998. Spatially Augmented Reality. In The First IEEE International Workshop on Augmented Reality (IWAR).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732300</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., Welch, G., Low, K.-L., and Bandyopadhyay, D. 2001. Shader Lamps: Animating Real Objects With Image-Based Illumination. In Rendering Techniques 2001, Proceedings of the Eurographics Workshop in London, United Kingdom.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882349</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., van Baar, J., Beardsley, P., Willwacher, T., Rao, S., and Forlines, C. 2003. iLamps: Geometrically Aware and Self-configuring Projectors. ACM Trans. Graph. (SIGGRAPH) 22, 3, 809--818.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>365115</ref_obj_id>
				<ref_obj_pid>365024</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Rekimoto, J., Ullmer, B., and Oba, H. 2001. DataTiles: A Modular Platform for Mixed Physical and Graphical Interactions. In CHI 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Ringwald, M. 2002. Spontaneous Interaction with Everyday Devices Using a PDA Workshop on Supporting Spontaneous Interaction in Ubiquitous Computing Settings. In UbiComp.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Siemens, 2002. Siemens Mini Beamer. http://w4.siemens.de/en2/html/press//newsdesk_archive/2002/-foe02121b.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Symbol, 2002. Laser Projection Display. http://www.symbol.com/products/oem/lpd.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>858649</ref_obj_id>
				<ref_obj_pid>858619</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Teller, S., Chen, J., and Balakrishnan, H. 2003. Pervasive pose-aware applications and infrastructure. IEEE Computer Graphics and Applications (Jul).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[The CoolTown Project, 2001. http://www.cooltown.com/research/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311593</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Underkoffler, J., Ullmer, B., and Ishii, H. 1999. Emancipated pixels: Real-world graphics in the luminous room. In Proc. Siggraph 99, ACM Press, 385--392.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Verlinden, J. C., de Smit, A., Peeters, A. W. J., and van Gelderen, M. H. 2003. Development of a Flexible Augmented Prototyping System. In The 11th International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision '2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>128759</ref_obj_id>
				<ref_obj_pid>128756</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Want, R., Hopper, A., Falco, V., and Gibbons, J. 1992. The Active Badge Location System. ACM Trans. Inf. Syst. 10, 1, 91--102.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Want, R., Schilit, B. N., Adams, N. I., Gold, R., Petersen, K., Goldberg, D., Ellis, J. R., and Weiser, M. 1995. An Overview of the ParcTab Ubiquitous Computing Experiment. In IEEE Personal Communications, 28--43.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>303111</ref_obj_id>
				<ref_obj_pid>302979</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Want, R., Harrison, B. L., Fishkin, K., and Gujar, A. 1999. Bridging Physical and Virtual Worlds with Electronic Tags. In ACM SIGCHI, 370--377.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Want, R. 2003. RFID, A Key to Automating Everything. In Scientific American, vol. 290(1), 56--65.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357025</ref_obj_id>
				<ref_obj_pid>357014</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Zhang, Z. 1999. A Flexible New Technique for Camera Calibration. IEEE Pattern Analysis and Machine Intelligence 22, 1330--1334.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198718</article_id>
		<sort_key>8</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Embedded entertainment with smart projectors]]></title>
		<page_from>8</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198718</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198718</url>
		<abstract>
			<par><![CDATA[Essentially video projectors enhanced with sensors to gain information about the environment, smart projectors do not require artificial canvases and allow correct projection of images onto many arbitrary existing surfaces, such as papered walls or curtained windows.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40029142</person_id>
				<author_profile_id><![CDATA[81100622976]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Oliver]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bimber]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bauhaus University Weimar]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24030978</person_id>
				<author_profile_id><![CDATA[81320489199]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Andreas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Emmerling]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bauhaus University Weimar]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P708799</person_id>
				<author_profile_id><![CDATA[81100364921]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Klemmer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bauhaus University Weimar]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. G&#252;hring, "Dense 3D Surface Acquisition by Structured Light Using Off-the-Shelf Components," Proc. Videometrics and Optical Methods for 3D Shape Measuring, SPIE, 2001, vol. 4309, pp. 220--231.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Raskar, G. Welch, and H. Fuchs, "Seamless Projection Overlaps Using Image Warping and Intensity Blending," Proc. 4th Int'l Conf. Virtual Systems and Multimedia, IEEE Press, 1998, www.cs.unc.edu/~fuchs/publications/VSMM_seamless.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>601697</ref_obj_id>
				<ref_obj_pid>601671</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Yang et al., "PixelFlex: A Reconfigurable Multi-Projector Display System," Proc. IEEE Conf. Visualization, IEEE Press, 2001, pp. 68--75.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Majumder et al., "Color Calibration of Projectors for Large Tiled Displays," Proc. IEEE Conf. Visualization, IEEE Press, 2000, pp. 102--108.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882349</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. Raskar et al., "iLamps: Geometrically Aware and Self-Configuring Projectors," Proc. ACM Siggraph, ACM Press, 2003, pp. 809--818.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>319370</ref_obj_id>
				<ref_obj_pid>319351</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. Raskar et al., "Multiprojector Displays Using Camera-Based Registration," Proc. IEEE Conf. Visualization, IEEE Press, 1999, pp. 161--168.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1042326</ref_obj_id>
				<ref_obj_pid>1042196</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[O. Bimber et al., "Superimposing Pictorial Artwork with Projected Imagery," to appear in IEEE Multi-Media, Jan.-Mar. 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. Sukthankar, T. J. Cham, and G. Sukthankar, "Dynamic Shadow Elimination for Multi-Projector Displays," Proc. IEEE Conf. Computer Vision and Pattern Recognition, vol. 2, IEEE CS Press, 2001, pp. 151--157.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[R. Sukthankar, R. Stockton, and M. Mullin, "Automatic Keystone Correction for Camera-Assisted Presentation Interfaces," Proc. Int'l Conf. Multimodal Interfaces; http://www.ri.cmu.edu/pubs/pub_3396.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198719</section_id>
		<sort_key>31</sort_key>
		<section_seq_no>31</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Computer-generated medical, technical, and scientific illustration]]></section_title>
		<section_page_from>31</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>P61351</person_id>
				<author_profile_id><![CDATA[81100113675]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Ebert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>PP38027759</person_id>
				<author_profile_id><![CDATA[81100306501]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mario]]></first_name>
				<middle_name><![CDATA[Costa]]></middle_name>
				<last_name><![CDATA[Sousa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198720</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Computer-generated medical, technical, and scientific illustration]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198720</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198720</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P61351</person_id>
				<author_profile_id><![CDATA[81100113675]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Ebert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP38027756</person_id>
				<author_profile_id><![CDATA[81100306501]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mario]]></first_name>
				<middle_name><![CDATA[Costa]]></middle_name>
				<last_name><![CDATA[Sousa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35035604</person_id>
				<author_profile_id><![CDATA[81100057321]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Amy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gooch]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31056805</person_id>
				<author_profile_id><![CDATA[81100627733]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Don]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stredney]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198721</section_id>
		<sort_key>32</sort_key>
		<section_seq_no>32</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Quantum rendering: an introduction to quantum computing and quantum algorithms, and their applications to computer graphics]]></section_title>
		<section_page_from>32</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP15024581</person_id>
				<author_profile_id><![CDATA[81100161363]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Marco]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lanzagorta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>P138061</person_id>
				<author_profile_id><![CDATA[81100514918]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jeffrey]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Uhlmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198722</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Quantum rendering]]></title>
		<subtitle><![CDATA[an introduction to quantum computing, quantum algorithms and their applications to computer graphics]]></subtitle>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198722</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198722</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15024581</person_id>
				<author_profile_id><![CDATA[81100161363]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Marco]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lanzagorta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[George Mason University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31059026</person_id>
				<author_profile_id><![CDATA[81100514918]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jeffrey]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Uhlmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Missouri-Columbia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1965179</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bouwmeester, Ekert and Zeilinger (eds), <i>The Physics of Quantum Information</i>, Springer Verlag, 2000. (It presents good, but sometimes advanced, discussions on QC and its applications).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>544199</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Nielsen & Chuang, <i>Quantum Computation and Quantum Information</i>, Cambridge University Press, 2000. (Probably the best QC textbook available. Features a good introduction to quantum physics, and eventually touches rather complex subjects).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>270052</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Williams & Clearwater, <i>Explorations in Quantum Computing</i>, Springer, 1998. (A good, but very basic, introduction to quantum computing).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>863597</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Brylinski and Chen (eds.), <i>Mathematics of Quantum Computation</i>, Chapman & Hall / CRC, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>374924</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Calude & Paun, <i>Computing with Cells and Atoms: An introduction to quantum, DNA and membrane computing</i>, Taylor & Francis, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>380451</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hirvensalo, <i>Quantum Computing</i>, Springer Verlag, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>519277</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Pittenger, <i>An Introduction to Quantum Computing Algorithms</i>, Birkhauser, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618840</ref_obj_id>
				<ref_obj_pid>616071</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Glassner, "Quantum Computing", Parts 1-3, <i>IEEE Computer Graphics and Applications</i>, July, September, November 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Lanzagorta, Uhlmann & Gomez, "Quantum Rendering" in the <i>Proceedings of the Quantum Information and Computation Conference</i>, SPIE 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Lanzagorta & Uhlmann, "Quantum Computational Geometry", <i>Proceedings of the Quantum Information and Computation Conference</i>, SPIE 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Lanzagorta & Uhlmann, "Hybrid Quantum Computing", <i>Proceedings of the Quantum Information and Computation Conference</i>, SPIE 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Lanzagorta & Uhlmann, "Quantum Rendering", course notes, <i>Proceedings of the 2005 Siggraph Conference</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>83821</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Foley, van Dam, Feiner and Hughes, <i>Computer Graphics: Principles and Practice</i>, Addison Wesley, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>529420</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Watt, <i>3D Computer Graphics</i>, Addison Wesley, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>261226</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Berg, Kreveld, Overmars and Schwarzkopf, <i>Computational Geometry: Algorithms and Applications</i>, Springer, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198723</article_id>
		<sort_key>2</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Hybrid quantum-classical computing with applications to computer graphics]]></title>
		<page_from>2</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198723</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198723</url>
		<abstract>
			<par><![CDATA[Quantum computing (QC) has become an important area of research in computer science because of its potential to provide more efficient algorithmic solutions to certain problems than are possible with classical computing (CC). In particular, QC is able to exploit the special properties of quantum superposition to achieve computational parallelism beyond what can be achieved with parallel CC computers. However, these special properties are not applicable for general computation. Therefore, we propose the use of "hybrid quantum computers" (HQCs) that combine both classical and quantum computing architectures in order to leverage the benefits of both. We demonstrate how an HQC can exploit quantum search to support general database operations more efficiently than is possible with CC. Our solution is based on new quantum results that are of independent significance to the field of quantum computing. More specifically, we demonstrate that the most restrictive implications of the quantum No-Cloning Theorem can be avoided through the use of <i>semiclones</i>. In this paper we discuss specific applications of quantum search to problems in computational geometry, simulation, and computer graphics.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[collision detection]]></kw>
			<kw><![CDATA[computational geometry]]></kw>
			<kw><![CDATA[computer graphics]]></kw>
			<kw><![CDATA[databases]]></kw>
			<kw><![CDATA[grover's algorithm]]></kw>
			<kw><![CDATA[quantum algorithms]]></kw>
			<kw><![CDATA[quantum cloning]]></kw>
			<kw><![CDATA[quantum computing]]></kw>
			<kw><![CDATA[simulation]]></kw>
			<kw><![CDATA[state estimation]]></kw>
			<kw><![CDATA[virtual reality]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15024581</person_id>
				<author_profile_id><![CDATA[81100161363]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Marco]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lanzagorta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NCI Information Systems]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P138061</person_id>
				<author_profile_id><![CDATA[81100514918]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jeffrey]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Uhlmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Missouri-Columbia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>261557</ref_obj_id>
				<ref_obj_pid>261555</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Andersson and K. Swanson. On the difficulty of range searching. Computational Geometry with Applications, 8(3):115--122, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[H. Bechmann-Pasquinucci and N. Gisin. Incoherent and coherent eavesdropping in the six-state protocol of quantum cryptography. Physical Review A, 59(4238), 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Boyer, G. Brassard, P. Hoyer, and A. Tapp. Tight bounds on quantum searching. Proceedings of the Fourth Workshop on Physics and Computation, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[G. Brassard, P. Hoyer, M. Mosca, and A. Tapp. Quantum amplitude amplification and estimation. e-print quant-ph/0005055, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[V. Buzek and M. Hillery. Quantum copying: Beyond the no-cloning theorem. Physical Review A, 54(1844), 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[V. Buzek and M. Hillery. Quantum copying: A network. e-print quant-ph/9703046, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[V. Buzek and M. Hillery. Universal optimal cloning of arbitrary quantum states: From qubits to quantum registers. Physical Review Letters, 81(22), 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>371683</ref_obj_id>
				<ref_obj_pid>371673</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[C. S. Calude, M. J. Dinneen, and K. Svozil. Reflections on quantum computing. Complexity, 6(1):35--37, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>154731</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[M. F. Cohen and J. R. Wallace. Radiosity and Realistic Image Synthesis. Morgan Kauffman, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[C. Durr and P. Hoyer. A quantum algorithm for finding the minimum. e-print quant-ph/9607014, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>264407</ref_obj_id>
				<ref_obj_pid>264393</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[C. H. Bennet et. al. Strengths adn weaknesses of quantum computing. SIAM Journal on Computing, 26(5):1510--1524, Oct 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>208249</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. D. Foley, A. Van Dam, S. K. Feiner, and J. F. Hughes. Computer Graphics, Principles and Practice. Addison Wesley, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[E. Galvao and L. Hardy. Cloning and quantum computation. Physical Review A, 62(022301), 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>94788</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[A. Glassner. An Introduction to Ray Tracing. Academic Press, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618840</ref_obj_id>
				<ref_obj_pid>616071</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[A. Glassner. Andrew glassner's notebook: Quantum computing, part 1. IEEE Computer Graphics with Applications, 21(4), Jul/Aug 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618854</ref_obj_id>
				<ref_obj_pid>616072</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[A. Glassner. Andrew glassner's notebook: Quantum computing, part 2. IEEE Computer Graphics with Applications, 21(5), Sep/Oct 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618866</ref_obj_id>
				<ref_obj_pid>616073</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[A. Glassner. Andrew glassner's notebook: Quantum computing, part 3. IEEE Computer Graphics with Applications, 21(6), Nov/Dec 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237866</ref_obj_id>
				<ref_obj_pid>237814</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[L. Grover. A fast quantum mechanical algorithm for database search. Proc. of 28th ACM Annual STOC, pages 212--219, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280635</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[D. E. Knuth. The Art of Computer Programming Vol. 3: Sorting and Searching. Addison Wesley Longman, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[M. Lanzagorta and J. Uhlmann. Quantum computational geometry. In Proceedings of the Quantum Information and Quantum Computation Conference. SPIE Defense and Security Symposium, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[M. Lanzagorta and J. Uhlmann. Hybrid quantum computing. In Proceedings of the Quantum Information and Quantum Computation Conference. SPIE Defense and Security Symposium, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[M. Lanzagorta, J. Uhlmann, and R. Gomez. Quantum rendering. In Proceedings of the Quantum Information and Quantum Computation Conference. SPIE Defense and Security Symposium, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>863276</ref_obj_id>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[D. Luebke, M. Reddy, J. D. Cohen, A. Varshney, B. Watson, and R. Huebner. Level of Detail for 3D Graphics. Morgan Kauffman, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[K. Murayama and P. L. Knight. Quantum state restoration by quantum cloning and measurement. e-print quant-ph/0309167, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>544199</ref_obj_id>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[M. A. Nielsen and I. L. Chuang. Quantum Computation and Quantum Information. Cambridge University Press, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>4333</ref_obj_id>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[F. P. Preparata and M. I. Shamos. Computational Geometry. Springer-Verlag, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[P. Shor. Scheme for reducing decoherence in quantum computer memory. Phys. Rev. A, 52(2493), 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[R. Werner. Optimal cloning of pure states. Physical Review A, 58(1827), 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[W. Wooters and W. Zurek. A single quantum cannot be copied. Nature, 299(802), 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198724</article_id>
		<sort_key>3</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Quantum computing]]></title>
		<page_from>3</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198724</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198724</url>
		<abstract>
			<par><![CDATA[There's a revolution coming in the field of computing. And it's coming from the smallest of all places: the subatomic particles that form the basis of all matter.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P837794</person_id>
				<author_profile_id><![CDATA[81322494455]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Glassner'S]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198725</section_id>
		<sort_key>33</sort_key>
		<section_seq_no>33</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Hot topics in 3D medical visualization]]></section_title>
		<section_page_from>33</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP31058058</person_id>
				<author_profile_id><![CDATA[81100275743]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Luis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ibanez]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198726</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Hot topics in 3D medical image visualization]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198726</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198726</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP31035119</person_id>
				<author_profile_id><![CDATA[81100275743]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Luis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ibanez]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Kitware Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39056879</person_id>
				<author_profile_id><![CDATA[81100236754]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Gordon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kindlmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Harvard Brigham and Women's Hospital, Surgical Planning Lab]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24029385</person_id>
				<author_profile_id><![CDATA[81342488616]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Stephen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Aylward]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198727</section_id>
		<sort_key>34</sort_key>
		<section_seq_no>34</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[The invisible actor]]></section_title>
		<section_page_from>34</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP31055990</person_id>
				<author_profile_id><![CDATA[81452615289]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ewan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Johnson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>PP24034862</person_id>
				<author_profile_id><![CDATA[81322501624]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Denise]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Minter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198728</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[The invisible actor]]></title>
		<subtitle><![CDATA[Copyright restrictions prevent ACM from providing the full text for this work.]]></subtitle>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198728</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198728</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP31055976</person_id>
				<author_profile_id><![CDATA[81452615289]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ewan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Johnson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24035142</person_id>
				<author_profile_id><![CDATA[81322501624]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Denise]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Minter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	</section>
	<section>
		<section_id>1198729</section_id>
		<sort_key>35</sort_key>
		<section_seq_no>35</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Developing mobile 3D applications with OpenGL ES and M3G]]></section_title>
		<section_page_from>35</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP39057233</person_id>
				<author_profile_id><![CDATA[81100567347]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kari]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pulli]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198730</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Developing mobile 3D applications with OpenGL ES and M3G]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198730</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198730</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39048910</person_id>
				<author_profile_id><![CDATA[81100567347]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kari]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pulli]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Nokia Research Center & MIT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P758145</person_id>
				<author_profile_id><![CDATA[81309492364]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jani]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vaarala]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Nokia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36034513</person_id>
				<author_profile_id><![CDATA[81336491583]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ville]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Miettinen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hybrid Graphics]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36033646</person_id>
				<author_profile_id><![CDATA[81309482580]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Tomi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Aarnio]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Nokia Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36033738</person_id>
				<author_profile_id><![CDATA[81336487875]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Callow]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[HI Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198731</section_id>
		<sort_key>36</sort_key>
		<section_seq_no>36</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Spatial displays and computer graphics]]></section_title>
		<section_page_from>36</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP39056726</person_id>
				<author_profile_id><![CDATA[81100453651]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Halle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198732</article_id>
		<sort_key>2</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Three-dimensional displays and computer graphics]]></title>
		<page_from>2</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198732</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198732</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39060393</person_id>
				<author_profile_id><![CDATA[81100453651]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Halle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24035502</person_id>
				<author_profile_id><![CDATA[81322502535]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Joshua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Napoli]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P297828</person_id>
				<author_profile_id><![CDATA[81100192858]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wendy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Plesniak]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198733</article_id>
		<sort_key>29</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Holography and holographic stereograms <i>plus</i> computation and bandlimiting for discrete parallax displays]]></title>
		<page_from>29</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198733</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198733</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39060392</person_id>
				<author_profile_id><![CDATA[81100453651]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Halle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198734</article_id>
		<sort_key>50</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Volumetric displays & implementation experience]]></title>
		<page_from>50</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198734</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198734</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP24035467</person_id>
				<author_profile_id><![CDATA[81322502535]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Joshua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Napoli]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Actuality Systems, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[W. Chun, J. Napoli, O. S. Cossairt, R. K. Dorval, D. M. Hall, T. J. Purtell II, J. F. Schooler, Y. Banker and G. E. Favalora, "Spatial 3D infrastructure: display-independent software framework, high-speed rendering electronics, and several new displays," <i>Proc. SPIE Vol. 5664</i>, p. 302-312, Stereoscopic Displays and Virtual Reality Systems XII; Andrew J. Woods, Mark T. Bolas, John O. Merritt, Ian E. McDowall; Eds., Mar 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>555369</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[B. G. Blundell and A. J. Schwarz, <i>Volumetric Three-Dimensional Display Systems</i>, John Wiley & Sons, New York, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1029644</ref_obj_id>
				<ref_obj_pid>1029632</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[T. Grossman, D. Wigdor, R. Balakrishnan, "Multi-Finger Gestural Interaction with 3D Volumetric Displays," <i>Proceedings of the 17th annual ACM symposium on User</i>.., ACM Press, New York, NY, USA, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>983611</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. Ware, <i>Information visualization: Perception for Design</i>, 2nd ed., Morgan Kaufmann, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. Sullivan, "A Solid-state Multi-planar Volumetric Display", <i>SID Symposium Digest of Technical Papers</i>, May 2003, Volume 34, Issue 1, pp. 1531-1533.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[G. Favalora, D. Hall, M. Giovinco, J. Napoli, R. Dorval and W. Chun, "Multimegavoxel Volumetric 3-D Display System for Distributed Collaboration," <i>Virtual Reality Technologies for Future Telecommunications Systems</i>, 2002, pp. 145-157.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198735</article_id>
		<sort_key>69</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Computed holograms and holographic video display of 3D data]]></title>
		<page_from>69</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198735</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198735</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P297828</person_id>
				<author_profile_id><![CDATA[81100192858]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wendy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Plesniak]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39060394</person_id>
				<author_profile_id><![CDATA[81100453651]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Halle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198736</article_id>
		<sort_key>104</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Autostereoscopic displays and computer graphics]]></title>
		<page_from>104</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198736</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198736</url>
		<abstract>
			<par><![CDATA[Autostereoscopic displays present a three-dimensional image to a viewer without the need for glasses or other encumbering viewing aids. Three classes of autostereoscopic displays are described: reimaging displays, volumetric displays, and parallax displays. Reimaging displays reproject an existing three-dimensional object to a new location or depth. Volumetric displays illuminate points in a spatial volume. Parallax displays emit directionally-varying image information into the viewing zone. Parallax displays are the most common autostereoscopic displays and are most compatible with computer graphics. Different display technologies of the three types are described. Computer graphics techniques useful for three-dimensional image generation are outlined.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39060438</person_id>
				<author_profile_id><![CDATA[81100453651]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Halle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Brigham and Women's Hospital, Boston, Massachusetts]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Benton, Stephen A. Display Holography: an SPIE Critical Review of Technology. Proc. SPIE, Holography, A86-32351 14-35, (1985), pp. 8--13.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Benton, Stephen A. Survey of Holographic Stereograms. Proc. SPIE, Processing and Display of Three-Dimensional Data, 367, (1982), pp. 15--19.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Downing, Elizabeth et. al. A Three-Color, Solid-State, Three-Dimensional Display. Science 273, 5279 (August 30, 1996), pp. 1185--1189]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Halle, Michael W. Holographic Stereograms as Discrete Imaging Systems. Proc. SPIE, Practical Holography VIII, 2176, (May 1994), pp. 73--84.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Hart S. J. and M. N. Dalton, Display Holography for Medical Tomography, Proc. SPIE, Practical Holography IV, 1212 (May 1990), pp. 116--135.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Ives, F. E. U.S. Patent No. 725, 567, (1903).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Ives, H. E., A Camera for Making Parallax Panoramagrams, J. Opt. Soc. Amer., 17, (Dec. 1928), pp. 435--439.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kawamoto, Wayne 3-D Images That Float in Air. Byte (Oct. 1995).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Ketchpel R. D. U.S. Patent No. 3, 140, 415, (July 7, 1964).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Lasher, Mark et. al. Laser-Projected 3D Volumetric Displays. Proc. SPIE, Projection Displays II, 2650 (1996), pp.285--295.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Lewis, J. D. et al. A True Three-Dimensional Display. IEEE Transactions on Electron Devices, ED-18, 9, (Sept. 1971), pg. 724--732.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218490</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Lucente, Mark and Tinsley A. Galyean. Rendering Interactive Holographic Images. Proceedings of SIGGRAPH '95 (Los Angeles, CA, Aug. 6-11, 1995). In Computer Graphics Proceedings, Annual Conference Series, 1995, ACM SIGGRAPH, New York, 1995, pp 387--394.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>169238</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[McAllister, David F. Stereo Computer Graphics and Other True 3D Technologies. Princeton Univ. Press, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>196549</ref_obj_id>
				<ref_obj_pid>195966</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[McKenna, Michael and David Zeltzer. Three Dimensional Visual Display Systems for Virtual Environments. Presence, 1, 4 (Fall 1992), pp 421--458.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Okoshi, Takanori. Three-Dimensional Imaging Techniques. Academic Press, New York, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Sandin, Daniel J., et al. Computer-Generated Barrier-Strip Autostereography. Proc SPIE, Non-Holographic True 3D Display Technologies, 1083, (Jan. 1989), pp. 65--75.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Saxby, Graham. Practical Holography, 2nd edition. Prentice Hall, Dec. 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[St.-Hilaire, Pierre et. al. Scaling Up the MIT Holographic Video System. Proc. SPIE, Fifth International Symposium on Display Holography, 2333, (Feb 1995), pp. 374--380.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Starks, Michael R., Stereoscopic video and the quest for virtual reality: an annotated bibliography of selected topics. Proceedings Stereoscopic Displays and Applications II, 1457. SPIE, pp. 327--342, Aug. 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Starks, Michael R., Stereoscopic video and the quest for virtual reality: an annotated bibliography of selected topics. Proceedings Stereoscopic Displays and Applications III, 1669. SPIE, pp. 216--227, June 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Traub, A. C. Stereoscopic Display Using Varifocal Mirror Oscillations. Applied Optics, 6, 6 (June 1967), pp. 1085--1087.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198737</section_id>
		<sort_key>37</sort_key>
		<section_seq_no>37</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[GPU shading and rendering]]></section_title>
		<section_page_from>37</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP31058568</person_id>
				<author_profile_id><![CDATA[81334487411]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Marc]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Olano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198738</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[GPU shading and rendering]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198738</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198738</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP31058550</person_id>
				<author_profile_id><![CDATA[81334487411]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Marc]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Olano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24029751</person_id>
				<author_profile_id><![CDATA[81100213796]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Avi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bleiweiss]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39056695</person_id>
				<author_profile_id><![CDATA[81100091740]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Larry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gritz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40031479</person_id>
				<author_profile_id><![CDATA[81100123210]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Hart]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31058137</person_id>
				<author_profile_id><![CDATA[81100186713]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kilgard]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P198024</person_id>
				<author_profile_id><![CDATA[81100112613]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McCool]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31058761</person_id>
				<author_profile_id><![CDATA[81319500593]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Pedro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sander]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198739</section_id>
		<sort_key>38</sort_key>
		<section_seq_no>38</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Introduction to real-time ray tracing]]></section_title>
		<section_page_from>38</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP39061398</person_id>
				<author_profile_id><![CDATA[81100449948]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shirley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>PP40031395</person_id>
				<author_profile_id><![CDATA[81100159926]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Philipp]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Slusallek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198740</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Introduction to real-time ray tracing]]></title>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198740</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198740</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40024383</person_id>
				<author_profile_id><![CDATA[81100159926]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Philipp]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Slusallek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Saarland University, Saarbr&#252;cken, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39043298</person_id>
				<author_profile_id><![CDATA[81100449948]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shirley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35035889</person_id>
				<author_profile_id><![CDATA[81547494456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mark]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Texas at Austin, Austin, TX]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39031627</person_id>
				<author_profile_id><![CDATA[81100189931]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Gordon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stoll]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Intel Corporation, Santa Clara, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40030613</person_id>
				<author_profile_id><![CDATA[81100041422]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Ingo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wald]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Max-Planck-Institut f&#252;r Informatik, Saarbr&#252;cken, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 I n t r o d u c t i o n t o R e a l t i m e R a y T r a c i n g  Introduction to Ray Tracing What 
is Ray Tracing?  Comparison with Rasterization  Why Now? / Timeline  Reasons and Examples for Using 
Ray Tracing  Open Issues   I n t r o d u c t i o n t o R e a l t i m e R a y T r a c i n g  R e n 
d e r i n g i n C o m p u t e r G r a p h i c s  Rasterization: Ray Tracing: Projection geometry forward 
Project image samples backwards Computer graphics has only two basic algorithms for rendering 3D scenes 
to a 2D screen. The dominant algorithms for interactive computer graphics today is the rasterization 
algorithm implemented in all graphic chips. It conceptually takes a single triangle at a time, projects 
it to the screen and paints all covered pixels (subject to the Z-buffer and other test and more or less 
complex shading computations). Because the HW has no knowledge about the scene it must process every 
triangle leading to a linear complexity with respect to scene size: Twice the number of triangles leads 
to twice the rendering time. While here are options to optimize this, must be done in the application 
separate from the HW. The other algorithm ray tracing works in fundamentally different ways. It starts 
by shooting rays for each pixel into the scenes and uses advanced spatial indexes (aka. acceleration 
structures) to quickly locate the geometric primitive that is being hit. Because these indexes are hierarchical 
they allow for a logarithmic complexity: Above something like 1 million triangles the rendering time 
hardly changes any more. Computer graphics knows two different technologies for generating a 2D image 
from 3D scene description: rasterization and ray tracing. Virtually all interactive graphics today uses 
the rasterization technique. Because it was easier to implement in hardware during early days of interactive 
computer graphics (early 1980s), it took over the world. Mainly driven by companies such as SGI, Nvidia, 
ATI, and some others rasterization hardware developed rapidly to the point that this graphics technology 
is already embedded in many motherboard chip sets. And the technology is still developing at an astonishing 
pace. In particular, significant programmability is being added to the rasterization pipeline in every 
new generation. The basic operation of rasterization is to sequentially project each triangle sent by 
the application and projecting it to the 2D screen. Then the pixel covered by the triangle are computed 
and each one is colored according to some programmable shader functions. It is important to note that 
the rasterization pipeline derives its basic efficiency from the fact that it conceptually looks only 
at a single triangle at a time in the order they ar submitted by the application. At no point does the 
graphics chip have the ability to look at the rest of the scene. Yet, this ability is key to some of 
the most basic and simple optical effects that are required for faithfully rendering 3D scenes. Computing 
the shadows cast on a triangle requires knowing about the triangles casting the shadow, computing the 
reflection requires the ability to find the triangles being reflected, and computing indirect illumination 
on a triangle requires access to the entire scene. With rasterization such functionality cannot be computed 
accurately and approximations and fakes must be used (e.g. shadow maps, reflection maps). However, they 
necessarily have inaccuracies and artifacts and are generally less efficient. Ray tracing can be formulated 
very much like the pipeline known from rasterization (an with similar efficiency). A significant change, 
however, is the feedback loops in the pipeline, which are the key to its ability to compute global information 
in the scene. The first stage in the pipeline computes a rays from the camera s parameter and a 2D sample 
location on the screen. The traversal stage takes the ray and traverses the spatial index to locate 
the first hit point of the ray with a geometric object. Here we visualize the spatial index as a (2D-) 
grid. Obviously the index is a 3D structure. However, 3D-grids are not often used (except in some HW 
projects) as they waste much memory and cannot adapt to local changes, such as a highly dense region 
with many close-by triangles. The grid only symbolizes the spatial index here. Objects and primitives 
are spatially sorted and pointers to them are inserted into all 3D grid cells, that they overlap. This 
is done in a preprocessing step. During runtime, we can quickly traverse all cells hat are pierced by 
a ray and only compute intersections with primitives that are in these cells and are thus close to the 
rays and like to get intersected. Traversal is done is a simple algorithm that will be explained in 
another part of the course. When possible objects are located the intersection stage computed the exact 
intersection of the ray with the geometric primitive (e.g. triangle). It not hit point is found with 
any of the objects in the cell, we go back to the traversal stage and continue traversal. Once a hit 
point has been found it is forwarded to the shading stage, which job it is to compute the color of the 
returned light, which can then be used to color the corresponding pixel. In order to know how much light 
is reflected from the intersected location towards the camera, we must first know how much light arrives 
at this location. We can do this by shooting some more rays. For example, we can send a shadow ray to 
all light sources in order to find out if there is a free path between the point and the light. This 
is the case if there is no intersection with any object from ray segment between the hit point and the 
light source. This elegantly, accurately, and efficiently solves the shadow computation problem in graphics 
once and for all. The shadow ray is fed into the pipeline just as a normal ray but some optimizations 
can be done because we do not need to find the first intersection because any intersection would be fine. 
 The show rays are then traversed and intersected as normal, but no shading computations need to be done 
for them. When the original shader get the information from the shadow ray it can adapt its shading 
results accordingly. Note that this operation requires full recursion in the shader, as we must wait 
until the results of tracing the shadow ray returns. Similarly the shader may trace additional rays 
for querying the incoming illumination from other directions. For refraction or reflection, new rays 
are send to find out how much light arrived from that particular directions. This is a full recursive 
ray tracing procedure as the new hit point may in turns start new rays (which a shadow ray would not 
do). A fraction of the light from these additional rays is then added to the pixels color based on the 
reflection propertied of the primary hit point and finally the results of the rays tracing process is 
a single color that can be directly written to the frame buffer. No z-buffer, accumulation buffer, stencil 
buffer, alpha buffer are needed as these computations are performed by the surface and other shaders 
or are not even needed with ray tracing at all. This property of ray tracing to only write the final 
result to memory is one of its major strengths and leads to significantly reduced memory bandwidth. 
 W h a t i s R a y T r a c i n g ?  Global effects Parallel (as nature) Fully automatic Demand driven 
Per pixel operations Highly efficient Fundamental Technology for Next Generation Graphics This slide 
summarized the most important reasons for using ray tracing: -IT supports computing global effects because 
global information can be queried from a scene by tracing rays into its environment. -Each primary ray 
is completely independent from all other primary rays, which would ultimate make it possible to assign 
one processor per primary ray. Ray tracing has also been called embarrassingly parallel . -Ray tracing 
can deal with declarative scene descriptions that specify how a scene should look like, without specifying 
how this effect should be achieved. This includes full orthogonal descriptions of the geometry, its appearance 
(surface shaders), the camera, as well as the lighting environment and any light sources. This scene 
description can then be rendered fully automatically without the help of the creating application. -Ray 
tracing is demand driven, meaning it only ever accesses something if that something is hit by a ray. 
This means that there might be gigabytes of stuff hidden behind a wall, yet a ray tracer might not even 
load it into memory. -All operations are performed per pixel, including occlusion culling, interpolations, 
illumination etc. This leads to a high image quality. -In summary of the above points ray tracing is 
highly efficient and in many cases more efficient than rasterization. For instance, it does not need 
to build a complete reflection map but simply computes the reflection where relevant. C o m p a r i 
s o n R a s t e r i z a t i o n v s . R a y T r a c i n g  Definition: Rasterization Given a set of 
rays and a primitive, efficiently compute the subset of rays hitting the primitive Uses 2D grid as an 
index structure for efficiency Definition: Ray Tracing Given a ray and set of primitives, efficiently 
compute the subset of primitives hit by the ray Uses a (hierarchical) 3D spatial index for efficiency 
The two definitions show that the two algorithms are quite related but start at different end of the 
spectrum. Rasterization only uses a 2D grid as an index structure in image space. This limits the set 
of rays to those, that start at a single point and go through a regular set of sample points on a plane. 
This is a severe limitation already. No 3D index structure in object space is supported, even though 
this can be added by the application. This, however, means that it cannot be supported in hardware and 
there is always a communication overhead. In contrast ray tracing is flexible in the number and the set 
of traced rays but needs a hierarchical spatial index for efficient computations. Ray tracing does not 
need to look at all scene objects but only deals with those that are visible. It uses an efficient 3D 
spatial index structure to quickly find any primitive that may be hit by a ray. A hierarchical index 
structure leads to logarithmic scalability in terms of scene size, which is a significant advantage over 
rasterization. These spatial index structure can also be reused for other purposes such as collision 
detection and many others. However, this index structure must be built to great detail, which poses challenges 
for dynamic and interactive scenes. Because of the spatial 3D index, ray tracing can efficiently answer 
queries for individual or small groups of rays, which is handy for tracing just the necessary rays for 
a small reflective object or such. C o m p a r i s o n R a s t e r i z a t i o n v s . R a y T r a c 
i n g  3D object space index (e.g. kd-tree)  Limits scene dynamics (may require index rebuilt)  Increases 
scalability with scene size . O(log n)  Efficiently supports small &#38; arbitrary sets of rays  Few 
rays reflecting off of surface . ray tracing problem  2D image space grid  Rays limited to regular 
sampling &#38; planar perspective See previous slide. C o m p a r i s o n R a s t e r i z a t i o n 
v s . R a y T r a c i n g  Convergence: 2D grid plus object space index Brings rasterization closer 
to ray tracing  Performs front to back traversal with groups of rays  At leafs parallel intersection 
computation using rasterization   Introduces same limitations (e.g. scene dynamics) But coarser index 
may be OK (traversal vs. intersection cost)  Computation split into HW and application SW More complex, 
latency, communication bandwidth,  Object space 3D spatial indices can be used with rasterization. It 
brings rasterization close to being ray tracing as it then performs a front to back traversal operation 
(for larger packets of rays) and uses the rasterization engine for doing the ray triangle intersection 
test. However, this approach imposes the same limitations on rasterization such as the complexity to 
support dynamic scenes. It also splits the computations between the HW and the application software, 
which adds overhead and complications. C o m p a r i s o n R a s t e r i z a t i o n v s . R a y T r 
a c i n g  Per Pixel Efficiency Surface shaders principally have same complexity  Rasterization: 
 Incremental computation between pixels (triangle setup)  Overhead due to overdraw (Z buffer)   Ray 
tracing:  No incremental computation (less important with complexity)  Caching works well even for 
finely tessellated surfaces  May shoot arbitrary rays to query about global environment   Shaders 
in GPUs and RPUs are fundamentally similar and have the same complexity for their basic operations. The 
main difference is that ray tracing can just shoot rays to query about global information in a scene 
(reflection, indirect lighting, ), where rasterization must fall back to inefficient multi-pass methods. 
Rasterization has the option of doing incremental operations between pixels of the same triangle, but 
looses is the scene is too finely tesselated where this advantage can turn into a disadvantage. Ray tracing 
must re-compute all properties of the hit geometry for every ray but can take advantage of caching and 
SIMD computations to optimize for this case (see HW section). C o m p a r i s o n R a s t e r i z a 
t i o n v s . R a y T r a c i n g  Benefits of On-Demand Computation Only required computations efficiency 
E.g.: must not compute entire reflection map No re-sampling of pre-computed data accuracy Exact computation 
reliability Fully performed in renderer (not app.) simplicity Data loaded only if needed resources The 
on-demand computation offers many benefits: -It only computes information that is known to contribute 
to the image, which leads to increased efficiency. It also offers tighter control over the computer 
work load. -Because data is computed on-the-fly when it is needed, ray tracing rarely stores temporary 
results in memory. An example are shadow: It traces the rays as needed instead of storing a discretely 
sampled representation all possible rays, which must be re-sampled when queried. This re-sampling can 
significantly reduce the accuracy and lead to artifacts. -Because the computations are performed accurately 
and physically correct for exactly the necessary rays, the results have less artifacts and are much more 
reliable. -because ray tracing supports a full declarative scene description, the entire rendering computation 
can be implemented in hardware or at least with in a separate rendering engine. The application is only 
needed to update the scene between frames. -Due to the on-demand approach necessary data is only loaded 
when needed, which can greatly reduce the working set and thus the resources needed for a given computation. 
 C o m p a r i s o n R a s t e r i z a t i o n v s . R a y T r a c i n g  Hardware Support Rasterization 
has mature &#38; quickly evolving HW High performance, highly parallel, stream computing engine  Ray 
tracing mostly implemented in SW  Requires flexible control flow, recursion &#38; stacks, flexible i/o, 
 Requires virtual memory and demand loading due scene size  Requires loops in the HW pipeline (e.g. 
generating new rays)  Depend heavily on caching and suitable working sets   Not well supported by 
current HW Ray tracing is still lacking significantly with respect to hardware support. While rasterization 
has seen more than twenty years of intense development, hardware for ray tracing is only just appearing. 
Nonetheless, it has been shown that ray tracing can be implemented highly efficiently in hardware (see 
RPU section). However, ray tracing requires significantly more flexibility from a hardware architecture, 
which necessitates extensions and new approaches compared to today s graphics architectures.  R e q 
u i r e m e n t s f o r R e a l t i m e R a y T r a c i n g  Requirements High floating point performance 
 Traversal &#38; intersection computations  Flexible control flow, multiple threads Recursion, efficient 
traversal of kd tree,  Exploitation of coherence Caching, packets, efficient traversal,  High bandwidth 
  Between traversal, intersection, and shading; to caches Ray tracing can only be implemented efficiently 
with floating point computations. Traversal, intersection, and shading all require many FLOPS per ray. 
Because of the traversal of hierarchical tree structures and the more-or-less general purpose nature 
of shading computations, a flexible hardware support is required. However, ray tracing inherently has 
a high degree of coherence that can be used to reduce the computational and memory bandwidth requirements 
of a nave implementation. W h y N o w ? T i m e l i n e  Early 1980s:  FLOPS in HW very expensive 
(8087 used 1980-89)  Very limited HW resources ( 3M )  Small 3D scenes with large triangles   Consequences 
 Raster-pipeline model for parallelism &#38; throughput  Mainly rasterization, limited FLOPS  RT required 
many FLOPS, bandwidth, no pipeline   An interesting question to ask is: Why has realtime ray tracing 
not been done before? It turns out that many researchers have repeatedly stated very early that ray tracing 
would eventually become faster than rasterization because of its logarithmic complexity in terms of scene 
size. However, these claims have not been fulfilled for more than twenty years, and research on ray tracing 
essentially stopped in the late 1980s / early 1990s. There had been no research that has explored WHY 
ray tracing has been so dramatically slower than rasterization despite other expectations. Even though, 
there are several reasons why realtime performance could not be realized in the early days. FLOPS have 
been very expensive in these days, scenes usually had few large polygons, and hardware resources were 
very scarce. Due to its purely local computational model, rasterization is much better suited for such 
an environment. Since then a complete generation of researchers, developers, and users grew up exclusive 
in a rasterization based world. Now everyone just knew that ray tracing is slow and cannot be implemented 
in hardware. W h y N o w ? T i m e l i n e   Mid 1990s:  Nvidia &#38; ATI create integrated 3D graphics 
chips  Mainly rasterization, limited FLOPS   Ray Tracing  SW research had mostly stopped, lack of 
progress  HW research limited by HW resources   Mostly focusing on intersection computation only 
In the mid 1990s VLSI graphics chips mainly accelerated the rasterization part of OpenGL, which mainly 
consists of fixed point arithmetic. FLOPS were still expensive to realize in hardware. Thus the rasterization 
took off in the mass market while ray tracing still could not be realized on a competitive basis. W 
h y N o w ? T i m e l i n e   1998-2000:  GPUs: Geometry engine, many fixed function FLOPS  Parallel 
RTRT on supercomputers &#38; PC clusters   2001-2002  Programmable GPUs  RT on GPUs: Unsuitable 
programming model  Simulation show: HW for RTRT is possible   At the end of the late 1990s the hardware 
resources became available to perform realtime ray tracing on large supercomputers and a few years later 
also on clusters of PCs. FLOPS became cheap and were available in every PC through SIMD, high clock rates, 
long CPU pipelines, etc. However, the new architecture was not well suited for the inner loops of traditional 
ray tracing algorithms. Only when the algorithms were re-implemented could these new hardware features 
be exploited effectively. A few years later large numbers of FLOPS also became available in programmable 
GPUs. However, until now their programming model is to inflexible to effectively exploit the raw performance 
for ray tracing. W h y N o w ? T i m e l i n e   ~2004:  Fully programmable, high-performance GPUs 
 Limited control flow, no recursion, no stack  First fixed-function RTRT-HW (FPGA)   Now:  Fully 
programmable, scalable RPU (FPGA) The features and flexibility of GPUs has increased significantly since 
then. But it is still insufficient to implement fast ray tracing on GPUs except in toy examples. It will 
be interesting to see where GPUs will be moving in the next few years. The dominant stream programming 
model seems not well suited for ray tracing type algorithms. However, in the mean time custom hardware 
has been developed that performs the entire computation highly efficiently in hardware. In 2004 a first 
fixed-function ray tracing chip was presented. A year later the first fully programmable RPU (ray processing 
unit) was presented at Siggraph. Interesting enough the latter architecture is based to large degrees 
on GPUs but extends then in key locations by dedicated hardware units as well as significantly increased 
programming flexibility. W h y N o w ?  Summary  Success of rasterization and lack of progress eliminated 
RT research in 1990s  Little low level optimization, assumption there is no coherence  CPUs got faster 
but RT did not take advantage of it SSE, stalls due to long pipelines, coherence,  Better algorithms 
later allowed to catch up with HW  RT in HW: resources only became available recently  In summary, 
it becomes clear that ray tracing has a much higher fixed cost in terms of cost of hardware. This has 
held back ray tracing for long enough to discourage most researchers that by the time the resources became 
available, nobody was interested any more. However, at this point progress could be made in great leaps 
because of catching up with the then current hardware and software possibilities. R e a s o n s f o 
r U s i n g R T R T  What are the reasons for industry to choose Realtime Ray Tracing? Highly realistic 
images by default  Physical correctness and dependability  Support for massive scenes  Integration 
of many different primitive types  Declarative scene description  Realtime global illumination  We 
are providing realtime ray tracing technology to industry through our spin-off company inTrace GmbH. 
We have seen a significant interest from industry already three years ago. inTrace customers are now 
all major German car manufactures (Volkswagen, DaimlerChrysler, BMW, Audi) and Airbus with additional 
projects run at Skoda, Boeing, and other companies. From this contacts we see the following main reasons 
for industry to be interested in this new technology. However, the reasons are weighted very differently 
by different departments even of the same company. -The better image quality due to accurate shadows, 
reflections, and refraction even on highly complex models is a major motivation for most departments. 
-Often more important is the fact that the viewer can be confident that what he sees on the screen has 
been computed physically correct and that he can depend of these results. Given that at design reviews 
major investments are made based on the visual appearance of a virtual model, this dependability if of 
paramount importance. -Large CAD models usually had to be simplified significantly for achieving realtime 
performance even with the best rasterization technology. Due to the logarithmic scaling, companies can 
now work interactively with full detail models like entire cars or airplanes down to details like individual 
screws. This greatly simplifies their process pipeline. -Ray tracing is also able to render spline surfaces 
and points directly, which has caused significant interest. Similarly, global illumination is interesting 
for providing the still missing level of realism. -Finally, the ability to easily and fully automatically 
describe an entire highly complex scene with shaders from a predefined library, such that the visualization 
works on the press of a button is highly interesting to industry R e a s o n s f o r U s i n g R T R 
T H i g h l y R e a l i s t i c I m a g e s  Highly Realistic Images by Default Typical effects are 
automatically accounted for  E.g.: shadows, reflection, refraction,  No special code necessary, but 
tricks can still be used   All effects are correctly ordered globally Do need for application to do 
sorting (e.g. for transparency)  Orthogonality of geometry, shading, lighting,  Can be created independently 
and used without side effects  Reusability: e.g. shader libraries   See previous slide. This image 
shows a simple example of the complex optical effects that need to be rendered with a car model, including 
shadows of curved surfaces, multiple reflections, environment maps, and many more. R e a s o n s f o 
r U s i n g R a y T r a c i n g  Physical Correctness and Dependability  Numerous approximations caused 
by rasterization  Might be good enough for games (but maybe not?)  Industry needs dependable visual 
results   Benefits  Users develop trust in the visual results  Important decisions can be based on 
virtual models   See before. Only ray tracing is able to render a complex image like this. Rays trees 
of at least depth of 10 and up to 25 and more must be traced to obtain faithful results. In total this 
adds up to more than 50 rays per pixel. This images runs in 5-7 fps on a small PC cluster. In a recent 
project an entire car was rendered directly with trimmed NURBS surfaces instead of many triangles. In 
addition, we used a highly accurate car paint shader and global illumination from a sky dome. For realtime 
purposes a large PC cluster is required. This image shows the difference between using texture mapping 
(lower right image) and using measured BTF data, which captures the fine detail of illumination on surfaces 
with micro structure like leather. The data sets have been provided by Prof. Klein, Bonn University and 
are directly rendered on trimmed NURBS surfaces. Ray tracing can also be used in a VR or mixed reality 
context. Instead of compositing multiple 2D images, here the compositing is performed in the surface 
shaders of the models. In addition environment lighting is integrated from the TV screen and a 180 degree 
light probe, which also provides the reflections on the car. R e a s o n s f o r U s i n g R T R T : 
M a s s i v e M o d e l s  Massive Scenes  Scales logarithmically with scene size  Supports billions 
of triangles   Benefits  Can render entire CAD models without simplification  Greatly simplifies 
and speeds up many tasks   See before. Ray tracing has been the first and (to our knowledge) only 
technology to interactively render the entire Boeing 777 data set. It consists of 350 million polygons 
and takes up to 30 GB of data on disk. Every detail is models including tiny screws, cables, pipes, values, 
and many more. With ray tracing this model can be rendered interactively even on a dual-processor PC 
with 2-3 fps at video resolution. The right image contains 365 000 plants with a total of roughly 1.5 
billion polygons. All leafs use alpha-mapped textures leading to an extremely high depth complexity. 
Still the scene can be rendered with interactive performance on a decent PC cluster. Even smooth lighting 
from the sky dome can be integrated. An good approximation is then shown during interaction but the image 
converges to a high quality solution with a few seconds. R e a s o n s f o r U s i n g R T R T : F l 
e x i b l e P r i m i t i v e T y p e s  Flexible Primitive Types Triangles  Volumes data sets  Iso 
surfaces &#38; direct visualization  Regular, rectilinear, curvilinear, unstructured,   Splines and 
subdivision surfaces  Points  See before. The image shows a mixture of triangles, splines, and subdivision 
surfaces rendered directly using ray tracing at interactive performance. Volume data sets can also be 
visualized interactively with ray tracing. These images show iso-surfaces (combined with surfaces in 
the lower left). IN recent work we also integrated direct volume rendering as well as volume rendering 
semi-and unstructured data sets at interactive performance. These images show large point clouds being 
interactively ray traced. Even huge scenes with 24 million points can be rendered interactively with 
shadows. R e a s o n s f o r U s i n g R T R T : D e c l a r a t i v e G r a p h i c s  Declarative 
Graphics Interface  Application specifies scene once, plus updates  Rendering fully performed by renderer 
(e.g. in HW)  Similar to scene graphs, PostScript, or latest GUIs   Benefits  Greatly simplifies 
application programming  Allows for complete HW acceleration   See before. This simple image the 
orthogonality of geometry, appearance, and lighting that is a prerequisite for declarative scene descriptions. 
The scene contains simple surfaces, a volume and a hologram (light field) together with a procedural 
wood shader, a bump mapped mirror, and direct volume rendering effects. Every object and appearance has 
been separately modeled, but the ray tracer combines all the combinations of effects fully automatically 
and always physically-correct (at least as long each object is correctly modeled). These images are 
from a prototype computer game running in realtime on the ray tracer. It consists of more than 40 million 
polygons and all optical effects are fully simulated at rendering time. All trees are fully models and 
no LOD is being used. R e a s o n s f o r U s i n g R T R T : G l o b a l I l l u m i n a t i o n  
 Global Illumination  Simulating global lighting through tracing rays  Indirect diffuse and caustic 
illumination  Fully recomputed at up to 20 fps   Benefits  Add the subtle but highly important clue 
for realism  Allows flexible light planning and control   See before. Conference room rendered with 
global illumination (converged view). Due to the shape of the light sources that are long and thin oriented 
along the table, the differences in the shadow boundaries are clearly visible being almost sharp in one 
direction and very smooth in the other. The scene also contains many specular materials such as metal 
frames of chairs and metal frames of the boards. This image shows the results of interactive photon 
mapping for simulating the emission properties of this complex car headlight consisting of 800,000 polygons 
(top image). The left image shows the quality of simulating the illumination of the headlight on a grey 
wall with 250,000 photons. We can fully simulate the illumination at 3 fps on a cluster of 25 PCs. Once 
the accumulate 30 seconds worth of photons (25 million) and then only visualize them, we even reach 11 
fps. The quality of the simulation results is extremely good As the image on the far right shows. Nearly 
all features are accurately represented. Commercial applications take several hours for this type of 
simulation. O p e n I s s u e s w i t h R e a l t i m e R a y T r a c i n g   Dynamic scenes  Changes 
to geometry updates to spatial index  Key: Need information from application !!!  No information must 
inspect everything O(n)  Approaches  Separate scenes by temporal characteristic  Build index lazily, 
build fuzzy index  Adapt built parameters (fast vs. thorough)   Many dynamic scenes work reasonable 
well already with ray tracing but a lot of improvements can still be done. In particular fully dynamic 
scenes are still problematic. This problem can only be solved efficiently when the application can provide 
enough information about the movement of surfaces. If now information is known, any rendering algorithms 
must resolve to sequentially render every single surface. However, with the proper information, significant 
speed-up can be reached. The remaining question is which information can be made available, how is it 
represented best, and how can the renderer make best use of it.  O p e n I s s u e s w i t h R e a l 
t i m e R a y T r a c i n g  Efficient Anti-Aliasing &#38; Glossy Reflection Requires many samples 
for proper integration  Image plane Can we do better than super sampling?  Shading and texture aliasing 
ray differentials (integration?)  Large/detailed scenes geometry aliasing, temporal noise   Super-sampling 
too costly and LOD undesirable  Anti-aliasing and glossy reflections are just one example of the difficulty 
to integrate over large domains efficiently with a point sampling approach. This is still a large open 
question. O p e n I s s u e s w i t h R e a l t i m e R a y T r a c i n g  Hardware Support Goal: 
realtime ray tracing on every desktop >60 fps, 2 3 Mpix, huge models, complex lighting,  Possible Solutions 
 Faster, multi-core CPUs: might take too long  Cell: Highly interesting, but no caches  GPUs: interesting 
but limited control flow  Custom HW: RPU (flexible GPU + custom traversal)   There has been a lot 
of work recently on improved hardware support for realtime ray tracing. While PC clusters are a reasonable 
solution for larger industries, they cannot work in the mass market. Here a small-form factor (PC) solution 
needs to be found. A number of options are available ranging from highly-parallel multi-core designs 
of general purpose CPUs, over the new Cell architecture to GPUs and custom ray tracing hardware. Exactly 
what will be the best solution for what market is still an open question. 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198741</article_id>
		<sort_key>2</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Ray tracing]]></title>
		<page_from>2</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198741</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198741</url>
		<abstract>
			<par><![CDATA[<i>Ray tracing</i> is a method to produce realistic images; it determines visible surfaces in an image at the pixel level (Appel, 1968; Kay & Greenberg, 1979; Whitted, 1980). Unlike the z-buffer and BSP tree, ray tracing operates pixel-by-pixel rather than primitive-by-primitive. This tends to make ray tracing relatively slow for scenes with large objects in screen space. However, it has a variety of nice features which often make it the right choice for batch rendering and even for some interactive applications.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39043298</person_id>
				<author_profile_id><![CDATA[81100449948]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shirley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Introduction to Realtime Ray Tracing Siggraph 2005 Course 38 PART I: Fundamentals The Basic Algorithm 
  Ray Tracing  Ray tracing is a method to produce realistic images; it determines visible surfaces 
in an image at the pixel level (Appel, 1968; Kay &#38; Greenberg, 1979; Whitted, 1980). Unlike the z-buffer 
and BSP tree, ray tracing operates pixel-by-pixel rather than primitive-by-primitive. This tends to make 
ray tracing relatively slow for scenes with large objects in screen space. However, it has a variety 
of nice features which often make it the right choice for batch rendering and even for some interactive 
applications. Ray tracing s primary bene.t is that it is relatively straightforward to compute shadows 
and re.ections. In addition, ray tracing is well suited to walkthroughs of extremely large models due 
to advanced ray tracing s low asymptotic time complexity which makes up for the required preprocessing 
of the model (Snyder &#38; Barr, 1987; Muuss, 1995; Parker et al., 1999; Wald, Slusallek, &#38; Benthin, 
2001). In an interactive 3D program implemented in a conventional z-buffer environment, it is often 
useful to be able to select an object using a mouse. The mouse is clicked in pixel (i, j) and the picked 
object is whatever object is seen through that pixel. If the rasterization process includes an object 
identi.cation buffer, this is just a matter of looking up the value in pixel (i, j) of that buffer. However, 
if that buffer is not available, we can solve the problem of which object is visible via brute force 
geometrical computation using a ray intersection test. In this way, ray tracing is useful also to programmers 
who use only standard graphics APIs. 9. Ray Tracing This chapter also discusses distribution ray tracing 
(Cook, Porter, &#38; Carpenter, 1984), where multiple random rays are sent through each pixel in an 
image to simultaneously solve the antialiasing, soft shadow, fuzzy re.ection, and depth-of.eld problems. 
9.1 The Basic Ray Tracing Algorithm The simplest use of ray tracing is to produce images similar to 
those produced by the z-buffer and BSP-tree algorithms. Fundamentally, those methods make sure the appropriate 
object is seen through each pixel,and that the pixel color is shaded based on that object s material 
properties, the surface normal seen through that pixel, and the light geometry. Figure 9.1 shows the 
basic viewing geometry for ray tracing, which is the same as we saw earlier in Chapter 6. The geometry 
is aligned to a uvw coordinate system with the origin at the eye location e. The key idea in ray tracing 
is to identify locations on the view plane at w = n that correspond to pixel centers, as shown in Figure 
9.2. A ray, really just a directed 3D line, is then sent from e to that point. We then gaze in the direction 
of the ray to see the .rst object seen in that direction. This is shown in Figure 9.3, where the ray 
intersects two triangles, but only the .rst triangle hit, T2, is returned. 9.2. Computing Viewing Rays 
 The structure of the basic ray tracing program is: Compute u, v, w basis vectors for each pixel do compute 
viewing ray .nd .rst object hit by ray and its surface normal n set pixel color to value based on material, 
light, and n The pixel color can be computed using the shading equations of the last chapter.  9.2 
Computing Viewing Rays First we need to determine a mathematical representation for a ray. A ray is really 
just an origin point and a propagation direction; a 3D parametric line is ideal for Figure 9.4. The 
ray from the eye to a point on the screen. 156 9. Ray Tracing this. As discussed in Section 2.8.1, the 
3D parametric line from the eye e to a point s on the screen (see Figure 9.4) is given by p(t)=e +t(s 
- e). This should be interpreted as, we advance from e along the vector (s - e) a fractional distance 
t to .nd the point p. So given t, we can determine a point p. Note that p(0)=e, and p(1)=s. Also note 
that for positive t,if t1 <t2, then p(t1)is closer to the eye than p(t2). Also, if t< 0, then p(t)is 
behind the eye. These facts will be useful when we search for the closest object hit by the ray that 
is not behind the eye. Note that we are overloading the variable t here which is also used for the top 
of the screen s v-coordinate. To compute a viewing ray, we need to know e (which is given) and s. Finding 
s may look somewhat dif.cult. In fact, it is relatively straightforward using the same transform machinery 
we used for viewing in the context of projecting lines and triangles. First, we .nd the coordinates of 
s in the uvw-coordinate system with origin e. For all points on the screen, ws =n as shown in Figure 
9.2. The uv-coordinates are found by the windowing transform that takes [-0.5,nx-0.5][-0.5,ny-0.5] to 
[l, r] [b, t]: i +0.5 us =l +(r - l), nx j +0.5 vs =b +(t - b), ny where (i, j)are the pixel indices. 
This gives us s in uvw-coordinates. By de.nition, we can convert to canonical coordinates: s =e +usu 
+vsv +wsw. (9.1) Alternatively, we could use the matrix form (Equation 5.8): xs . . . 100 xe . xu . xv 
xw 0 . . us . . . . ys zs . . . = . . . 010 001 ye ze . . . . . . yu zu yv zv yw zw 0 0 . . . . . . vs 
ws . . . , (9.2) 1 000 1 0 0 0 1 1 which is just the matrix form of Equation 9.1. We can compose this 
with the windowing transform in matrix form if we wished, but this is probably not worth doing unless 
you like the matrix form of equations better. 9.3. Ray-Object Intersection 157 9.3 Ray-Object Intersection 
Given a ray e +td, we want to .nd the .rst intersection with any object where t> 0. It will later prove 
useful to solve a slightly more general problem of .nding the .rst intersection in the interval [t0,t1], 
and using [0,8)for viewing rays. We solve this for both spheres and triangles in this section. In the 
next section, multiple objects are discussed. 9.3.1 Ray-Sphere Intersection Given a ray p(t)=e +td and 
an implicit surface f(p)=0, we d like to know where they intersect. The intersection points occur when 
points on the ray satisfy the implicit equation f(p(t))=0. This is just f(e +td)=0. A sphere with center 
c =(xc,yc,zc)and radius R can be represented by the implicit equation (x- xc)2 +(y- yc)2 +(z- zc)2 - 
R2 =0. We can write this same equation in vector form: (p - c) (p - c)- R2 =0. Any point p that satis.es 
this equation is on the sphere. If we plug points on the ray p(t)=e +td into this equation, we can solve 
for the values of ton the ray that yield points on the sphere: (e +td - c) (e +td - c)- R2 =0. Rearranging 
terms yields (d  d)t2 +2d  (e - c)t+(e - c) (e - c)- R2 =0. Here, everything is known except the 
parameter t, so this is a classic quadratic equation in t, meaning it has the form At2 +Bt+C =0. The 
solution to this equation is discussed in Section 2.2. The term under the square root sign in the quadratic 
solution, B2 - 4AC, is called the discriminant 158 9. Ray Tracing and tells us how many real solutions 
there are. If the discriminant is negative, its square root is imaginary and there are no intersections 
between the sphere and the line. If the discriminant is positive, there are two solutions: one solution 
where the ray enters the sphere and one where it leaves. If the discriminant is zero, the ray grazes 
the sphere touching it at exactly one point. Plugging in the actual terms for the sphere and eliminating 
the common factors of two, we get -d  (e - c) (d  (e - c))2 - (d  d)((e - c) (e - c)- R2) t = . 
(d  d) In an actual implementation, you should .rst check the value of the discriminant before computing 
other terms. If the sphere is used only as a bounding object for more complex objects, then we need only 
determine whether we hit it; checking the discriminant suf.ces. As discussed in Section 2.7.1, the normal 
vector at point p is given by the gradient n =2(p - c). The unit normal is (p - c)/R.  9.3.2 Ray-Triangle 
Intersection There are many algorithms for computing ray-triangle intersections. We will use the form 
that uses barycentric coordinates for the parametric plane containing the triangle, because it requires 
no long-term storage other than the vertices of the triangle (Snyder &#38; Barr, 1987). To intersect 
a ray with a parametric surface, we set up a system of equations where the Cartesian coordinates all 
match: xe +txd =f(u, v), ye +tyd =g(u, v), ze +tzd =h(u, v). Here, we have three equations and three 
unknowns (t, u, and v), so we can solve numerically for the unknowns. If we are lucky, we can solve for 
them analytically. In the case where the parametric surface is a parametric plane, the parametric equation 
can be written in vector form as discussed in Section 2.11.2. If the vertices of the triangle are a, 
b and c, then the intersection will occur when e +td =a +(b - a)+.(c - a). (9.3) The hitpoint p will 
be at e + td as shown in Figure 9.5. Again, from Section 2.11.2, we know the hitpoint is in the triangle 
if and only if > 0, .> 0, 9.3. Ray-Object Intersection and +.<1. Otherwise, it hits the plane outside 
the triangle. If there are no solutions, either the triangle is degenerate or the ray is parallel to 
the plane containing the triangle. To solve for t, , and .in Equation 9.3, we expand it from its vector 
form into the three equations for the three coordinates: xe +txd =xa +(xb - xa)+.(xc - xa), ye +tyd 
=ya +(yb - ya)+.(yc - ya), ze +tzd =za +(zb - za)+.(zc - za). This can be rewritten as a standard 
linear equation: . ... . . xa - xb xa - xc xd xa - xe . .... . ya - yb ya - yc yd . = ya - ye . za - 
zb za - zc zd tza - ze The fastest classic method to solve this 33linear system is Cramer s Rule. This 
gives us the solutions xa - xe xa - xc xd ya - ye ya - yc yd za - ze za - zc zd = , |A| xa - xb xa - 
xe xd ya - yb ya - ye yd za - zb za - ze zd .= , |A| xa - xb xa - xc xa - xe ya - yb ya - yc ya - ye 
za - zb za - zc za - ze t= , |A| where the matrix A is . . xa - xb xa - xc xd . . A = ya - yb ya - yc 
yd , z- zz- zz abacd and |A| denotes the determinant of A. The 33determinants have common subterms 
that can be exploited. Looking at the linear systems with dummy variables . ... .. adg  j . ... .. beh 
. = k, cfit l 160 9. Ray Tracing Cramer s rule gives us j(ei - hf)+k(gf - di)+l(dh - eg)  = , M i(ak 
- jb)+h(jc - al)+g(bl - kc) . = , M f(ak - jb)+e(jc - al)+d(bl - kc) t =- , M where M =a(ei - hf)+b(gf 
- di)+c(dh - eg). We can reduce the number of operations by reusing numbers such as ei-minus-hf. The 
algorithm for the ray-triangle intersection for which we need the linear solution can have some conditions 
for early termination. Thus, the function should look something like: boolean raytri (ray r, vector3 
a, vector3 b, vector3 c, interval [t0,t1]) compute t if (t<t0)or (t>t1)then return false compute . if 
(.< 0)or (.> 1)then return false compute  if (< 0)or (> 1- .)then return false return true  9.3.3 
Ray-Polygon Intersection Given a polygon with m vertices p1 through pand surface normal n,we .rst m 
compute the intersection points between the ray e +td and the plane containing the polygon with implicit 
equation (p - p1) n =0. We do this by setting p =e +td and solving for t to get (p1 - e) n t = . d 
 n  9.4. A Ray Tracing Program 161 This allows us to compute p.If p is inside the polygon, then the 
ray hits it, and otherwise it does not. We can answer the question of whether p is inside the polygon 
by projecting the point and polygon vertices to the xy plane and answering it there. The easiest way 
to do this is to send any 2D ray out from p and to count the number of intersections between that ray 
and the boundary of the polygon (Sutherland et al., 1974; Glassner, 1989). If the number of intersections 
is odd, then the point is inside the polygon, and otherwise it is not. This is true, because a ray that 
goes in must go out, thus creating a pair of intersections. Only a ray that starts inside will not create 
such a pair. To make computation simple, the 2D ray may as well propagate along the x-axis: xxp 1 =+ 
s. yyp 0 It is straightforward to compute the intersection of that ray with the edges such as (x1,y1,x2,y2) 
for s . (0, 8). A problem arises, however, for polygons whose projection into the xy plane is a line. 
To get around this, we can choose among the xy, yz,or zx planes for whichever is best. If we implement 
our points to allow an indexing operation, e.g., p(0) = xp then this can be accomplished as follows: 
if (abs(zn) > abs(xn)) and (abs(zn) > abs(xn)) then index0 = 0 index1 = 1 else if (abs(yn) > abs (xn)) 
then index0 = 0 index1 = 2 else index0 = 1 index1 = 2 Now, all computations can use p(index0) rather 
than xp, and so on.  9.4 A Ray Tracing Program We now know how to generate a viewing ray for a given 
pixel and how to .nd the intersection with one object. This can be easily extended to a program that 
produces images similar to the z-buffer or BSP-tree codes of earlier chapters: 9. Ray Tracing for each 
pixel do compute viewing ray if (ray hits an object with t. [0,8)) then Compute n Evaluate lighting equation 
and set pixel to that color else set pixel color to background color Here the statement if ray hits 
an object... can be implemented as a function that tests for hits in the interval t. [t0,t1]: hit = false 
for each object o do if (object is hit at ray parameter tand t. [t0,t1]) then hit = true hitobject = 
o t1 = t return hit In an actual implementation, you will need to somehow return either a reference 
to the object that is hit or at least its normal vector and material properties. This is often done by 
passing a record/structure with such information. In an objectoriented implementation, it is a good 
idea to have a class called something like surface with derived classes triangle, sphere, surface-list, 
etc. Anything that a ray can intersect would be under that class. The ray tracing program would then 
have one reference to a surface for the whole model, and new types of objects and ef.ciency structures 
can be added transparently. 9.4.1 Object-Oriented Design for a Ray Tracing Program As mentioned earlier, 
the key class hierarchy in a ray tracer are the geometric objects that make up the model. These should 
be subclasses of some geometric object class, and they should support a hit function (Kirk &#38; Arvo, 
1988). To avoid confusion from use of the word object, surface is the class name often used. With such 
a class, you can create a ray tracer that has a general interface that assumes little about modeling 
primitives and debug it using only spheres. An important point is that anything that can be hit by a 
ray should be part of this class hierarchy, e.g., even a collection of surfaces should be considered 
a subclass of the surface class. This includes ef.ciency structures, such as bounding volume hierarchies; 
they can be hit by a ray, so they are in the class.  9.5. Shadows 163 For example, the abstract or base 
class would specify the hit function as well as a bounding box function that will prove useful later: 
class surface virtual bool hit(ray e + td, real t0, real t1, hit-record rec) virtual box bounding-box() 
Here (t0,t1) is the interval on the ray where hits will be returned, and rec is a record that is passed 
by reference; it contains data such as the t at intersection when hit returns true. The type box is a 
3D bounding box , that is two points that de.ne an axis-aligned box that encloses the surface. For example, 
for a sphere, the function would be implemented by: box sphere::bounding-box() vector3 min = center -vector3(radius,radius,radius) 
vector3 max = center + vector3(radius,radius,radius) return box(min, max) Another class that is useful 
is material. This allows you to abstract the material behavior and later add materials transparently. 
A simple way to link objects and materials is to add a pointer to a material in the surface class, although 
more programmable behavior might be desirable. A big question is what to do with textures; are they part 
of the material class or do they live outside of the material class? This will be discussed more in Chapter 
10.  9.5 Shadows Once you have a basic ray tracing program, shadows can be added very easily. Recall 
from Chapter 8 that light comes from some direction l. If we imagine ourselves at a point p on a surface 
being shaded, the point is in shadow if we look in direction l and see an object. If there are no objects, 
then the light is not blocked. This is shown in Figure 9.6, where the ray p + tl does not hit any objects 
and is thus not in shadow. The point q is in shadow because the ray q + tl does hit an object. The vector 
l is the same for both points because the light is far away. This assumption will later be relaxed. The 
rays that determine in or out of shadow are called shadow rays to distinguish them from viewing rays. 
To get the algorithm for shading, we add an if statement to determine whether the point is in shadow. 
In a naive implementation, the shadow ray will check for t . [0,8), but because of numerical imprecision, 
this can result in an inter-   Figure 9.8. When looking into a perfect mirror, the viewer looking in 
direction d will see whatever the viewer below the surfacewouldseeindirection r. 164 9. Ray Tracing section 
with the surface on which p lies. Instead, the usual adjustment to avoid that problem is to test for 
t . [., 8) where . is some small positive constant (Figure 9.7). If we implement shadow rays for Phong 
lighting with Equation 8.9 then we have: function raycolor( ray e + td, real t0, real t1 ) hit-record 
rec, srec if (scene.hit(e + td, t0, t1,rec)) then p = e + rec.td color c = rec.cr rec.ca if (not scene.hit(p 
+ sl, ., 8,srec)) then vector3 h = normalized(normalized(l)+ normalized(-d)) c = c + rec.cr clmax (0, 
rec.n  l)+ clrec.cp(h  rec.n)rec.p return c else return background-color Note that the ambient color 
is added in either case. If there are multiple light sources, we can send a shadow ray and evaluate the 
diffuse/phong terms for each light. The code above assumes that d and l are not necessarily unit vectors. 
This is crucial for d, in particular, if we wish to cleanly add instancing later. 9.6 Specular Re.ection 
 It is straightforward to add specular re.ection to a ray tracing program. The key observation is shown 
in Figure 9.8 where a viewer looking from direction e sees what is in direction r as seen from the surface. 
The vector r is found using a variant of the Phong lighting re.ection Equation 8.6. There are sign changes 
because the vector d points toward the surface in this case, so, r = d +2(d  n)n, (9.4) In the real 
world, some energy is lost when the light re.ects from the surface, and this loss can be different for 
different colors. For example, gold re.ects yellow more ef.ciently than blue, so it shifts the colors 
of the objects it re.ects. This can be implemented by adding a recursive call in raycolor: color c = 
c + csraycolor(p + sr, ., 8) where cs is the specular RGB color. We need to make sure we test for s 
. [., 8) 9.7. Refraction 165 for the same reason as we did with shadow rays; we don t want the re.ection 
ray to hit the object that generates it. The problem with the recursive call above is that it may never 
terminate. For example, if a ray starts inside a room, it will bounce forever. This can be .xed by adding 
a maximum recursion depth. The code will be more ef.cient if a re.ection ray is generated only if cs 
is not zero (black). 9.7 Refraction Another type of specular object is a dielectric a transparent material 
that refracts light. Diamonds, glass, water, and air are dielectrics. Dielectrics also .lter light; some 
glass .lters out more red and blue light than green light, so the glass takes on a green tint. When a 
ray travels from a medium with refractive index n into one with a refractive index nt, some of the light 
is transmitted, and it bends. This is shown for nt >n in Figure 9.9. Snell s law tells us that n sin 
. = nt sin f. Computing the sine of an angle between two vectors is usually not as convenient as computing 
the cosine which is a simple dot product for the unit vectors such as we have here. Using the trigonometric 
identity sin2 . +cos2 . =1, we can derive a refraction relationship for cosines: n2 1 - cos2 . cos2 f 
=1 - . 2 n t Note that if n and nt are reversed, then so are . and f as shown on the right of Figure 
9.9.  166 9. Ray Tracing To convert sin f and cos f into a 3D vector, we can set up a 2D orthonormal 
basis in the plane of n and d. From Figure 9.10, we can see that n and b form an orthonormal basis for 
the plane of refraction. By de.nition, we can describe t in terms of this basis: t =sin fb - cos fn. 
 Since we can describe d in the same basis, and d is known, we can solve for b: d =sin .b - cos .n, d 
+ n cos . b = . sin . This means that we can solve for t with known variables: n (d + n cos .)) t = - 
n cos f nt n (d - n(d  n)) n2 (1 - (d  n)2) = - n 1 - 2 . nt nt Note that this equation works regardless 
of which of n and nt is larger. An im mediate question is, What should you do if the number under the 
square root is negative? In this case, there is no refracted ray and all of the energy is re.ected. This 
is known as total internal re.ection, and it is responsible for much of the rich appearance of glass 
objects. The re.ectivity of a dielectric varies with the incident angle according to the Fresnel Equations. 
A nice way to implement something close to the Fresnel Equa tions is to use the Schlick approximation, 
 R(.)= R0 +(1 - R0)(1 - cos .)5 , where R0 is the re.ectance at normal incidence: 2 nt - 1 R0 = . nt 
+1 Note that the cos . terms above are always for the angle in air (the larger of the internal and external 
angles relative to the normal). For homogeneous impurities, as is found in typical glass, a light-carrying 
ray s intensity will be attenuated according to Beer s Law. As the ray travels through the medium it 
loses intensity according to dI = -CI dx, where dx is distance. Thus, dI/dx = -CI. We can solve this 
equation and get the exponential I = k exp(-Cx)+ k.. The degree of attenuation is described by the RGB 
attenuation 9.7. Refraction constant a, which is the amount of attenuation after one unit of distance. 
Putting in boundary conditions, we know that I(0) = I0, and I(1) = aI(0). The former implies I(x)= I0 
exp(-Cx). The latter implies I0a = I0 exp(-C),so -C = ln(a). Thus, the .nal formula is - ln(a)s I(s)= 
I(0)e, where I(s) is the intensity of the beam at distance s from the interface. In practice, we reverse-engineer 
a by eye, because such data is rarely easy to .nd. The effect of Beer s Law can be seen in Figure 9.11, 
where the glass takes on a green tint. To add transparent materials to our code, we need a way to determine 
when a ray is going into an object. The simplest way to do this is to assume that all objects are embedded 
in air with refractive index very close to 1.0, and that surface normals point out (toward the air). 
The code segment for rays and dielectrics with these assumptions is: if (p is on a dielectric) then r 
= re.ect(d, n ) if (d  n < 0) then refract(d, n,n, t )  168 9. Ray Tracing c= -d  n kr = kg = kb =1 
else kr =exp(-art) kg =exp(-agt) kb =exp(-abt) if refract(d,-n,1/n, t ) then c= t  n else return k*color(p 
+ tr) R0 =(n- 1)2/(n+1)2 R = R0 +(1 - R0)(1 - c)5 return k(Rcolor(p + tr) + (1 - R) color(p + tt))  
The code above assumes that the natural log has been folded into the constants (ar,ag,ab). The refract 
function returns false if there is total internal re.ection, and otherwise it .lls in the last argument 
of the argument list. 9.8 Instancing An elegant property of ray tracing is that it allows very natural 
instancing. The basic idea of instancing is to distort all points on an object by a transformation matrix 
before the object is displayed. For example, if we transform the unit circle (in 2D) by a scale factor 
(2,1) in xand y, respectively, then rotate it by 45., and move one unit in the x-direction, the result 
is an ellipse with an eccentricity of 2 and a long axis along the x = -y-direction centered at (0,1) 
(Figure 9.12). The key thing that makes that entity an instance is that we store the circle and the composite 
transform matrix. Thus, the explicit construction of the ellipse is left as a future procedure operation 
at render time. The advantage of instancing in ray tracing is that we can choose the space in which 
to do intersection. If the base object is composed of a set of points, one of which is p, then the transformed 
object is composed of that set of points transformed by matrix M, where the example point is transformed 
to Mp.If we have a ray a + tb which we want to intersect with the transformed object, we can instead 
intersect an inverse-transformed ray with the untransformed object (Fig ure 9.13). There are two potential 
advantages to computing in the untransformed space (i.e., the right-hand side of Figure 9.13): 1. the 
untransformed object may have a simpler intersection routine, e.g., a sphere versus an ellipsoid; 9.8. 
Instancing 2. many transformed objects can share the same untransformed object thus reducing storage, 
e.g., a traf.c jam of cars, where individual cars are just transforms of a few base (untransformed) models. 
As discussed in Section 5.2.2, surface normal vectors transform differently. With this in mind and using 
the concepts illustrated in Figure 9.13, we can determine the intersection of a ray and an object transformed 
by matrix M.If we create an instance class of type surface, we need to create a hit function: instance::hit(ray 
a + tb, real t0, real t1, hit-record rec) ray r. = M-1a + tM-1b if (base-object.hit(r. , t0, t1,rec)) 
then rec.n =(M-1)T rec.n return true else return false An elegant thing about this function is that 
the parameter rec.t does not need to be changed, because it is the same in either space. Also note that 
we need not compute or store the matrix M. 170 9. Ray Tracing This brings up a very important point: 
the ray direction b must not be re stricted to a unit-length vector, or none of the infrastructure above 
works. For this reason, it is useful not to restrict ray directions to unit vectors. For the purpose 
of solid texturing, you may want to record the local coordi nates of the hitpoint and return this in 
the hit-record. This is just ray r. advanced by parameter rec.t. To implement the bounding-box function 
of class instance, we can just take the eight corners of the bounding box of the base object and transform 
all of them by M, and then take the bounding box of those eight points. That will not necessarily yield 
the tightest bounding box, but it is general and straightforward to implement.  9.9 Sub-Linear Ray-Object 
Intersection In the earlier ray-object intersection pseudocode, all objects are looped over, checking 
for intersections. For N objects, this is an O(N) linear search and is thus slow for large values of 
N. Like most search problems, the ray-object intersection can be computed in sub-linear time using divide 
and conquer tech niques, provided we can create an ordered data structure as a preprocess. There are 
many techniques to do this. This section discusses three of these techniques in detail: bounding volume 
hierarchies (Rubin &#38; Whitted, 1980; Whitted, 1980; Goldsmith &#38; Salmon, 1987), uniform spatial 
subdivision (Cleary, Wyvill, Birtwistle, &#38; Vatti, 1983; Fujimoto, Tanaka, &#38; Iwata, 1986; Amanatides 
&#38; Woo, 1987), and binary-space partition- 9.9. Sub-Linear Ray-Object Intersection 171 ing (Glassner, 
1984; Jansen, 1986; Havran, 2000). An example of the .rst two strategies is shown in Figure 9.14. References 
for other popular strategies are given in the notes at the end of the chapter. 9.9.1 Bounding Boxes 
A key operation in most intersection acceleration schemes is computing the intersection of a ray with 
a bounding box (Figure 9.15). This differs from conventional intersection tests in that we do not need 
to know where the ray hits the box; we only need to know whether it hits the box. To build an algorithm 
for ray-box intersection, we begin by considering a 2D ray whose direction vector has positive x and 
y components. We can generalize this to arbitrary 3D rays later. The 2D bounding box is de.ned by two 
horizontal and two vertical lines: x=xmin, x=x max, y =ymin, y =ymax. The points bounded by these lines 
can be described in interval notation: (x,y). [xmin,xmax] [ymin,ymax]. As shown in Figure 9.16, the 
intersection test can be phrased in terms of these intervals. First, we compute the ray parameter where 
the ray hits the line x = xmin: xmin - xe txmin = . xd We then make similar computations for txmax, 
tymin, and tymax. The ray hits the box if and only if the intervals [txmin,txmax]and [tymin,tymax]overlap, 
i.e., their intersection is non-empty. In pseudocode this algorithm is: txmin =(xmin - xe)/xd txmax =(xmax 
- xe)/xd tymin =(ymin - ye)/xd tymax =(ymax - ye)/xd if (txmin >tymax)or (tymin >txmax)then return false 
else return true  9. Ray Tracing The if statement may seem non-obvious. To see the logic of it, note 
that there is no overlap if the .rst interval is either entirely to the right or entirely to the left 
of the second interval. The .rst thing we must address is the case when xd or yd is negative. If xd is 
negative, then the ray will hit xmax before it hits xmin. Thus the code for computing txmin and txmax 
expands to: if (xd = 0) then txmin =(xmin - xe)/xd txmax =(xmax - xe)/xd  else txmin =(xmax - xe)/xd 
txmax =(xmin - xe)/xd A similar code expansion must be made for the y cases. A major concern is that 
horizontal and vertical rays have a zero value for yd and xd, respectively. This will cause divide by 
zero which may be a problem. However, before addressing this directly, we check whether IEEE .oating 
point computation handles these 9.9. Sub-Linear Ray-Object Intersection cases gracefully for us. Recall 
from Section 1.6 the rules for divide by zero: for any positive real number a, +a/0=+8; -a/0=-8. Consider 
the case of a vertical ray where xd =0and yd > 0. We can then calculate xmin - xe txmin =; 0 xmax - x 
e txmax = . 0 There are three possibilities of interest: 1. xe = xmin (no hit); 2. xmin <xe <xmax (hit); 
 3. xmax = xe (no hit).  For the .rst case we have positive number txmin =; 0 positive number txmax 
=. 0 This yields the interval (txmin,txmin)=(8,8). That interval will not overlap with any interval, 
so there will be no hit, as desired. For the second case, we have negative number txmin =; 0 positive 
number txmax =. 0 This yields the interval (txmin,txmin)=(-8,8)which will overlap with all intervals 
and thus will yield a hit as desired. The third case results in the interval (-8,-8)which yields no hit, 
as desired. Because these cases work as desired, we need no special checks for them. As is often the 
case, IEEE .oating point conventions are our ally. However, there is still a problem with this approach. 
 174 9. Ray Tracing Consider the code segment:  if (xd = 0)then tmin =(xmin - xe)/xd tmax =(xmax - 
xe)/xd  else tmin =(xmax - xe)/xd tmax =(xmin - xe)/xd  This code breaks down when xd =-0. This can 
be overcome by testing on the reciprocal of xd (A. Williams, Barrus, Morley, &#38; Shirley, 2005): a 
=1/xd if (a = 0)then tmin =a(xmin - xe) tmax =a(xmax - xe)  else tmin =a(xmax - xe) tmax =a(xmin - 
xe)  9.9.2 Hierarchical Bounding Boxes The basic idea of hierarchical bounding boxes can be seen by 
the common tactic of placing an axis-aligned 3D bounding box around all the objects as shown in Figure 
9.17. Rays that hit the bounding box will actually be more expensive to compute than in a brute force 
search, because testing for intersection with the box is not free. However, rays that miss the box are 
cheaper than the brute force search. Such bounding boxes can be made hierarchical by partitioning the 
set of objects in a box and placing a box around each partition as shown in Figure 9.18. The data structure 
for the hierarchy shown in Figure 9.19 might be a tree with the large bounding box at the root and the 
two smaller bounding boxes as left and right subtrees. These would in turn each point to a list of three 
triangles. The intersection of a ray with this particular hard-coded tree would be: if (ray hits root 
box)then if (ray hits left subtree box)then check three triangles for intersection if (ray intersects 
right subtree box)then check other three triangles for intersection if (an intersections returned from 
each subtree)then return the closest of the two hits  9.9. Sub-Linear Ray-Object Intersection 175 else 
if (a intersection is returned from exactly one subtree) then return that intersection else return false 
else return false Some observations related to this algorithm are that there is no geometric ordering 
between the two subtrees, and there is no reason a ray might not hit both subtrees. Indeed, there is 
no reason that the two subtrees might not overlap. A key point of such data hierarchies is that a box 
is guaranteed to bound all objects that are below it in the hierarchy, but they are not guaranteed to 
contain all objects that overlap it spatially, as shown in Figure 9.19. This makes this geometric search 
somewhat more complicated than a traditional binary search on strictly ordered one-dimensional data. 
The reader may note that several possible optimizations present themselves. We defer optimizations until 
we have a full hierarchical algorithm. If we restrict the tree to be binary and require that each node 
in the tree have a bounding box, then this traversal code extends naturally. Further, assume that all 
nodes are either leaves in the tree and contain a primitive, or that they contain one or two subtrees. 
The bvh-node class should be of type surface, so it should implement surface::hit. The data it contains 
should be simple: class bvh-node subclass of surface virtual bool hit(ray e + td, real t0, real t1, hit-record 
rec) virtual box bounding-box() surface-pointer left surface-pointer right box bbox The traversal code 
can then be called recursively in an object-oriented style: bool bvh-node::hit(ray a + tb, real t0, real 
t1, hit-record rec) if (bbox.hitbox(a + tb, t0, t1)) then hit-record lrec, rrec left-hit = (left . = 
NULL) and (left . hit(a + tb, t0, t1,lrec)) right-hit = (right . = NULL) and (right . hit(a + tb, t0, 
t1,rrec)) if (left-hit and right-hit) then if (lrec.t < rrec.t) then rec = lrec Figure 9.19. The grey 
box is a tree node that points to the three grey spheres, and the thick black box points to the three 
black spheres. Note that not allspheresenclosedby the box are guaranteed to be pointed to by the corresponding 
tree node. 176 9. Ray Tracing else rec = rrec return true else if (left-hit) then rec = lrec return 
true else if (right-hit) then rec = rrec return true else return false else return false Note that because 
left and right point to surfaces rather than bvh-nodes speci.cally, we can let the virtual functions 
take care of distinguishing between internal and leaf nodes; the appropriate hit function will be called. 
Note, that if the tree is built properly, we can eliminate the check for left being NULL. If we want 
to eliminate the check for right being NULL, we can replace NULL right pointers with a redundant pointer 
to left. This will end up checking left twice, but will eliminate the check throughout the tree. Whether 
that is worth it will depend on the details of tree construction. There are many ways to build a tree 
for a bounding volume hierarchy. It is convenient to make the tree binary, roughly balanced, and to have 
the boxes of sibling subtrees not overlap too much. A heuristic to accomplish this is to sort the surfaces 
along an axis before dividing them into two sublists. If the axes are de.ned by an integer with x =0, 
y =1, and z =2 we have: bvh-node::bvh-node(object-array A, int AXIS) N = A.length if (N=1) then left 
= A[0] right = NULL bbox = bounding-box(A[0]) else if (N=2) then left-node = A[0] right-node = A[1] bbox 
= combine(bounding-box(A[0]), bounding-box(A[1]))  else sort A by the object center along AXIS  9.9. 
Sub-Linear Ray-Object Intersection left= new bvh-node(A[0..N/2 - 1], (AXIS +1) mod 3) right = new bvh-node(A[N/2..N-1], 
(AXIS +1) mod 3) bbox = combine(left-node . bbox, right-node . bbox) The quality of the tree can be 
improved by carefully choosing AXIS each time. One way to do this is to choose the axis such that the 
sum of the volumes of the bounding boxes of the two subtrees is minimized. This change compared to rotating 
through the axes will make little difference for scenes composed of isotopically distributed small objects, 
but it may help signi.cantly in less well-behaved scenes. This code can also be made more ef.cient by 
doing just a partition rather than a full sort. Another, and probably better, way to build the tree is 
to have the subtrees contain about the same amount of space rather than the same number of objects. To 
do this we partition the list based on space: bvh-node::bvh-node(object-array A, int AXIS) N = A.length 
if (N =1) then left = A[0] right = NULL bbox = bounding-box(A[0]) else if (N =2) then left= A[0] right 
= A[1] bbox = combine(bounding-box(A[0]), bounding-box(A[1]))  else .nd the midpoint m of the bounding 
box of A along AXIS partition A into lists with lengths k and (N-k) surrounding m left = new node(A[0..k], 
(AXIS +1) mod 3) right = new node(A[k+1..N-1], (AXIS +1)mod 3) bbox = combine(left-node . bbox, right-node 
. bbox) Although this results in an unbalanced tree, it allows for easy traversal of empty space and 
is cheaper to build because partitioning is cheaper than sorting. 9.9.3 Uniform Spatial Subdivision 
Another strategy to reduce intersection tests is to divide space. This is fundamentally different from 
dividing objects as was done with hierarchical bounding volumes: 9. Ray Tracing  In hierarchical bounding 
volumes, each object belongs to one of two sibling nodes, whereas a point in space may be inside both 
sibling nodes.  In spatial subdivision, each point in space belongs to exactly one node, whereas objects 
may belong to many nodes.  The scene is partitioned into axis-aligned boxes. These boxes are all the 
same size, although they are not necessarily cubes. The ray traverses these boxes as shown in Figure 
9.20. When an object is hit, the traversal ends.  9.9. Sub-Linear Ray-Object Intersection 179 The grid 
itself should be a subclass of surface and should be implemented as a 3D array of pointers to surface. 
For empty cells these pointers are NULL. For cells with one object, the pointer points to that object. 
For cells with more than one object, the pointer can point to a list, another grid, or another data structure, 
such as a bounding volume hierarchy. This traversal is done in an incremental fashion. The regularity 
comes from the way that a ray hits each set of parallel planes, as shown in Figure 9.21. To see how this 
traversal works, .rst consider the 2D case where the ray direction has positive x and y components and 
starts outside the grid. Assume the grid is bounded by points (xmin,ymin) and (xmax,ymax). The grid has 
nx by ny cells. Our .rst order of business is to .nd the index (i, j) of the .rst cell hit by the ray 
e + td. Then, we need to traverse the cells in an appropriate order. The key parts to this algorithm 
are .nding the initial cell (i, j) and deciding whether to increment i or j (Figure 9.22). Note that 
when we check for an intersection with objects in a cell, we restrict the range of t to be within the 
cell (Figure 9.23). Most implementations make the 3D array of type pointer to surface. To improve the 
locality of the traversal, the array can be tiled as discussed in Section 12.4. 9.9.4 Binary-Space Partitioning 
We can also partition space in a hierarchical data structure such as a binary-spacepartioning tree (BSP 
tree). This is similar to the BSP tree used for a painter s algorithm in Chapter 7, but it usually uses 
axis-aligned cutting planes for easier ray intersection. A node in this structure might contain a single 
cutting plane and a left and right subtree. These subtrees would contain all objects on either side of 
the cutting plane. Objects that pass through the plane would be in each subtree. If we assume the cutting 
plane is parallel to the yz plane at x = D, then the node class is: class bsp-node subclass of surface 
virtual bool hit(ray e + td, real t0, real t1, hit-record rec) virtual box bounding-box() surface-pointer 
left surface-pointer right real D We generalize this to y and z cutting planes later. The intersection 
code can then be called recursively in an object-oriented style. The code considers the four cases shown 
in Figure 9.24. For our purposes, the origin of these rays is a point at parameter t0: p = a + t0b. 
Figure 9.22. To decide whether we advance right or upwards, we keep track of the intersections with the 
next vertical and horizontal boundary of the cell. Figure 9.23. Only hits within the cell should be 
reported. Otherwise the case above would cause us to report hitting object brather than object a. 
Figure 9.24. The four cases of how a ray relates to the BSP cutting plane x=D. 180 9. Ray Tracing The 
four cases are: 1. The ray only interacts with the left subtree, and we need not test it for intersection 
with the cutting plane. It occurs for xp <Dand xb <0. 2. The ray is tested against the left subtree, 
and if there are no hits, it is then tested against the right subtree. We need to .nd the ray parameter 
at x= D, so we can make sure we only test for intersections within the subtree. This case occurs for 
xp <Dand xb >0. 3. This case is analogous to case 1 and occurs for xp >Dand xb >0. 4. This case is 
analogous to case 2 and occurs for xp >Dand xb <0.  The resulting traversal code handling these cases 
in order is: bool bsp-node::hit( ray a + tb, real t0, real t1, hit-record rec) xp = xa + t0xb if (xp 
<D) then if (xb <0) then return (left .b, t0, t = NULL) and (left.hit(a + t1,rec)) t=(D- xa)/xb if (t>t1) 
then return (left .b, t1,rec)) = NULL) and (left.hit(a + t0, t if (left .b, t,rec)) then = NULL) and 
(left.hit(a + t0, t return true return (right .b, t, t1,rec)) = NULL) and (right.hit(a + t  else analogous 
code for cases 3 and 4 This is very clean code. However, to get it started, we need to hit some root 
object that includes a bounding box so we can initialize the traversal, t0 and t1. An issue we have to 
address is that the cutting plane may be along any axis. We can add an interger index axis to the bsp-node 
class. If we allow an indexing operator for points, this will result in some simple modi.cations to the 
code above, for example, xp = xa + t0xb would become up = a[axis]+ t0b[axis] which will result in some 
additional array indexing, but will not generate more branches. 9.10. Constructive Solid Geometry 181 
While the processing of a single bsp-node is faster than processing a bvh-node, the fact that a single 
surface may exist in more than one subtree means there are more nodes and, potentially, a higher memory 
use. How well the trees are built determines which is faster. Building the tree is similar to building 
the BVH tree. We can pick axes to split in a cycle, and we can split in half each time, or we can try 
to be more sophisticated in how we divide.  9.10 Constructive Solid Geometry One nice thing about ray 
tracing is that any geometric primitive whose intersection with a 3D line can be computed can be seamlessly 
added to a ray tracer. It turns out to also be straightforward to add constructive solid geometry (CSG) 
to a ray tracer (Roth, 1982). The basic idea of CSG is to use set operations to combine solid shapes. 
These basic operations are shown in Figure 9.25. The operations can be viewed as set operations. For 
example, we can consider Cthe set of all points in the circle, and S the set of all points in the square. 
The intersection operation Cn Sis the set of all points that are both members of Cand S. The other operations 
are analogous. Although one can do CSG directly on the model, if all that is desired is an image, we 
do not need to explicitly change the model. Instead, we perform the set operations directly on the rays 
as they interact with a model. To make this natural, we .nd all the intersections of a ray with a model 
rather than just the closest. For example, a ray a + tb might hit a sphere at t =1 and t =2. In the context 
of CSG, we think of this as the ray being inside the sphere for t . [1,2].We can compute these inside 
intervals for all of the surfaces and do set operations on those intervals (recall Section 2.1.2). This 
is illustrated in Figure 9.26, where the hit intervals are processed to indicate that there are two intervals 
inside the difference object. The .rst hit for t>0 is what the ray actually intersects. In practice, 
the CSG intersection routine must maintain a list of intervals. When the .rst hitpoint is determined, 
the material property and surface normal is that associated with the hitpoint. In addition, you must 
pay attention to precision issues because there is nothing to prevent the user from taking two objects 
that abut and taking an intersection. This can be made robust by eliminating any interval whose thickness 
is below a certain tolerance. 9.11 Distribution Ray Tracing For some applications, ray-traced images 
are just too clean. This effect can be mitigated using distribution ray tracing (Cook et al., 1984) . 
The conventionally   182 9. Ray Tracing ray-traced images look clean, because everything is crisp; 
the shadows are perfectly sharp, the re.ections have no fuzziness, and everything is in perfect focus. 
Sometimes we would like to have the shadows be soft (as they are in real life), the re.ections be fuzzy 
as with brushed metal, and the image have variable degrees of focus as in a photograph with a large aperture. 
While accomplishing these things from .rst principles is somewhat involved (as is developed in Chapter 
??), we can get most of the visual impact with some fairly simple changes to the basic ray tracing algorithm. 
In addition, the framework gives us a relatively simple way to antialias (recall Section 3.7) the image. 
9.11.1 Antialiasing Recall that a simple way to antialias an image is to compute the average color for 
the area of the pixel rather than the color at the center point. In ray tracing, our computational primitive 
is to compute the color at a point on the screen. If we average many of these points across the pixel, 
we are approximating the true average. If the screen coordinates bounding the pixel are [i, i +1] [j, 
j +1], then we can replace the loop: for each pixel (i, j)do cij =ray-color(i +0.5,j +0.5)  with code 
that samples on a regular n  n grid of samples within each pixel: for each pixel (i, j)do c =0 for p 
=0to n - 1do  for q =0to n - 1do c =c + ray-color(i +(p +0.5)/n, j +(q +0.5)/n) cij =c/n2 This is usually 
called regular sampling. The 16 sample locations in a pixel for n =4 are shown in Figure 9.27. Note that 
this produces the same answer as rendering a traditional ray-traced image with one sample per pixel at 
nxn by nyn resolution and then averaging blocks of n by n pixels to get a nx by ny image. One potential 
problem with taking samples in a regular pattern within a pixel is that regular artifacts such as Moire 
patterns can arise. These artifacts can be turned into noise by taking samples in a random pattern within 
each pixel as shown in Figure 9.28. This is usually called random sampling and involves just a small 
change to the code:  9.11. Distribution Ray Tracing 183 for each pixel (i, j)do c =0 for p =1to n2 do 
c =c + ray-color(i +., j +.) cij =c/n2 Here . is a call that returns a uniform random number in the 
range [0, 1). Unfortunately, the noise can be quite objectionable unless many samples are taken. A compromise 
is to make a hybrid strategy that randomly perturbs a regular grid: for each pixel (i, j)do c =0 for 
p =0to n - 1do for q =0to n - 1do c =c + ray-color(i +(p +.)/n, j +(q +.)/n) cij =c/n2 That method 
is usually called jittering or strati.ed sampling (Figure 9.29). 9.11.2 Soft Shadows The reason shadows 
are hard to handle in standard ray tracing is that lights are in.nitesimal points or directions and are 
thus either visible or invisible. In real life, lights have non-zero area and can thus be partially visible. 
This idea is shown in 2D in Figure 9.30. The region where the light is entirely invisible is called the 
umbra. The partially visible region is called the penumbra. There is not a commonly used term for the 
region not in shadow, but it is sometimes called the anti-umbra. The key to implementing soft shadows 
is to somehow account for the light being an area rather than a point. An easy way to do this is to approximate 
the light with a distributed set of N point lights each with one Nth of the intensity of the base light. 
This concept is illustrated at the left of Figure 9.31 where nine lights are used. You can do this in 
a standard ray tracer, and it is a common trick to get soft shadows in an off-the-shelf renderer. There 
are two potential problems with this technique. First, typically dozens of point lights are needed to 
achieve visually smooth results, which slows down the program a great deal. The second problem is that 
the shadows have sharp transitions inside the penumbra. Distribution ray tracing introduces a small change 
in the shadowing code. Instead of representing the area light at a discrete number of point sources, 
we represent it as an in.nite number and choose one at random for each viewing ray.  184 9. Ray Tracing 
 Figure 9.32. The geometry of a parallelogram light speci.ed by a corner point and two edge vectors. 
This amounts to choosing a random point on the light for any surface point being lit as is shown at the 
right of Figure 9.31. If the light is a parallelogram speci.ed by a corner point c and two edge vectors 
a and b (Figure 9.32), then choosing a random point r is straightforward: r = c + .1a + .2b, where .1 
and .2 are uniform random numbers in the range [0, 1). We then send a shadow ray to this point as shown 
at the right in Figure 9.31. Note that the direction of this ray is not unit length, which may require 
some modi.cation to your basic ray tracer depending upon its assumptions. We would really like to jitter 
points on the light. However, it can be dangerous to implement this without some thought. We would not 
want to always have the ray in the upper left-hand corner of the pixel generate a shadow ray to the upper 
left-hand corner of the light. Instead we would like to scramble the samples, such that the pixel samples 
and the light samples are each themselves jittered, but so that there is no correlation between pixel 
samples and light samples. A good way to accomplish this is to generate two distinct sets of n2 jittered 
samples and pass samples into the light source routine: for each pixel (i, j) do c =0 generate N = n2 
jittered 2D points and store in array r[] generate N = n2 jittered 2D points and store in array s[] shuf.e 
the points in array s[] for p =0 to N - 1 do c = c + ray-color(i + r[p].x(), j + r[p].y(),s[p]) cij = 
c/N  9.11. Distribution Ray Tracing 185 This shuf.e routine eliminates any coherence between arrays 
r and s. The shadow routine will just use the 2D random point stored in s[p] rather than calling the 
random number generator. A shuf.e routine for an array indexed from 0 to N - 1 is: for i = N - 1 downto 
1 do choose random integer j between 0 and i inclusive swap array elements i and j  9.11.3 Depth of 
Field The soft focus effects seen in most photos can be simulated by collecting light at a non-zero size 
lens rather than at a point. This is called depth of .eld. The lens collects light from a cone of directions 
that has its apex at a distance where everything is in focus (Figure 9.33). We can place the window we 
are sampling on the plane where everything is in focus (rather than at the z = n plane as we did previously), 
and the lens at the eye. The distance to the plane where everything is in focus we call the focus plane, 
and the distance to it is set by the user, just as the distance to the focus plane in a real camera is 
set by the user or range .nder.  Figure 9.33. The lens averages over a cone of directions that hit the 
pixel location being sampled.  Figure 9.36. The re.ection ray is perturbed to a random vector r . 
186 9. Ray Tracing To be most faithful to a real camera, we should make the lens a disk. However, we 
will get very similar effects with a square lens (Figure 9.35). So we choose the side-length of the lens 
and take random samples on it. The origin of the view rays will be these perturbed positions rather than 
the eye position. Again, a shuf.ing routine is used to prevent correlation with the pixel sample positions. 
An example using 25 samples per pixel and a large disk lens is shown in Figure 9.34. 9.11.4 Glossy Re.ection 
 Some surfaces, such as brushed metal, are somewhere between an ideal mirror and a diffuse surface. Some 
discernible image is visible in the re.ection but it is blurred. We can simulate this by randomly perturbing 
ideal specular re.ection rays as shown in Figure 9.36. Only two details need to be worked out: how to 
choose the vector r., and what to do when the resulting perturbed ray is below the surface from which 
the ray is re.ected. The latter detail is usually settled by returning a zero color when the ray is below 
the surface. To choose r., we again sample a random square. This square is perpendicular to r and has 
width a which controls the degree of blur. We can set up the square s orientation by creating an orthonormal 
basis with w = r using the techniques in Section 2.4.6. Then, we create a random point in the 2D square 
with side length a centered at the origin. If we have 2D sample points (., ..) . [0, 1]2, then the analogous 
point on the desired square is a u = - + .a, 2 a v = - + .. a. 2 Because the square over which we will 
perturb is parallel to both the u and v vectors, the ray r. is just r= r + uu + vv. Note that r. is 
not necessarily a unit vector and should be normalized if your code requires that for ray directions. 
 9.11.5 Motion Blur We can add a blurred appearance to objects as shown in Figure 9.37. This is called 
motion blur and is the result of the image being formed over a non-zero 9.11. Distribution Ray Tracing 
 span of time. In a real camera, the aperture is open for some time interval during which objects move. 
We can simulate the open aperture by setting a time variable ranging from T0 to T1. For each viewing 
ray we choose a random time, T = T0 + .(T1 - T0). We may also need to create some objects to move with 
time. For example, we might have a moving sphere whose center travels from c0 to c1 during the interval. 
Given T , we could compute the actual center and do a ray intersection with that sphere. Because each 
ray is sent at a different time, each will encounter the sphere at a different position, and the .nal 
appearance will be blurred. Note that the bounding box for the moving sphere should bound its entire 
path so an ef.ciency structure can be built for the whole time interval (Glassner, 1988). 188 9. Ray 
Tracing  Frequently Asked Questions Why is there no perspective matrix in ray tracing? The perspective 
matrix in a z-buffer exists so that we can turn the perspective projection into a parallel projection. 
This is not needed in ray tracing, because it is easy to do the perspective projection implicitly by 
fanning the rays out from the eye. What is the best ray-intersection ef.ciency structure? The most popular 
structures are binary space partitioning trees (BSP trees), uniform subdivision grids, and bounding 
volume hierarchies. There is no clear-cut answer for which is best, but all are much, much better than 
brute-force search in practice. If I were to implement only one, it would be the bounding volume hierarchy 
because of its simplicity and robustness. Why do people use bounding boxes rather than spheres or ellipsoids? 
Sometimes spheres or ellipsoids are better. However, many models have polygonal elements that are tightly 
bounded by boxes, but they would be dif.cult to tightly bind with an ellipsoid. Can ray tracing be made 
interactive? For suf.ciently small models and images, any modern PC is suf.ciently powerful for ray 
tracing to be interactive. In practice, multiple CPUs with a shared frame buffer are required for a full-screen 
implementation. Computer power is increasing much faster than screen resolution, and it is just a matter 
of time before conventional PCs can ray trace complex scenes at screen resolution. Is ray tracing useful 
in a hardware graphics program? Ray tracing is frequently used for picking. When the user clicks the 
mouse on a pixel in a 3D graphics program, the program needs to determine which object is visible within 
that pixel. Ray tracing is an ideal way to determine that. 9.11. Distribution Ray Tracing  Exercises 
1. What are the ray parameters of the intersection points between ray (1, 1, 1)+ t(-1, -1, -1) and the 
sphere centered at the origin with radius 1? Note: this is a good debugging case. 2. What are the barycentric 
coordinates and ray parameter where the ray (1, 1, 1) + t(-1, -1, -1) hits the triangle with vertices 
(1, 0, 0), (0, 1, 0), and (0, 0, 1)? Note: this is a good debugging case. 3. Do a back of the envelope 
computation of the approximate time complexity of ray tracing on nice (non-adversarial) models. Split 
your analysis into the cases of preprocessing and computing the image, so that you can predict the behavior 
of ray tracing multiple frames for a static model.   
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198742</article_id>
		<sort_key>3</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Data structures for graphics]]></title>
		<page_from>3</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198742</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198742</url>
		<abstract>
			<par><![CDATA[There are a variety of data structures that seem to pop up repeatedly in graphics applications. This chapter talks about three basic and unrelated data structures that are among the most common and useful. There are many variants of these data structures, but the basic ideas behind them can be conveyed using an example of each.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39043298</person_id>
				<author_profile_id><![CDATA[81100449948]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shirley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Amanatides, J., & Woo, A. (1987). A fast voxel traversal algorithm for ray tracing. In Proceedings of Eurographics (pp. 1--10).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Appel, A. (1968). Some techniques for shading machine renderings of solids. In Proceedings of the AFIPS spring joint computing conference (p. 37--49).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Association, I. S. (1985). IEEE standard for binary floating-point arithmetic. IEEE Report (New York). (ANSI/IEEE Std 754-1985)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Baumgart, B. (1974, October). Geometric modeling for computer vision (Tech. Rep. No. AIM-249). Seattle, WA: Stanford University AI Laboratory.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bayer, B. E. (1976). Color imaging array. (U.S. Patent 3,971,065)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1076267</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Beck, K., & Andres, C. (2004). Extreme programming explained: Embrace change (Second ed.). Reading, MA: Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. (1978). Simulation of wrinkled surfaces. In Proceedings of SIGGRAPH (pp. 286--292).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>286104</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. (1996). Jim blinn's corner. San Francisco, CA: Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807398</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Blinn, J., & Newell, M. (1978). Clipping using homogeneous coordinates. In Proceedings of SIGGRAPH (pp. 245--251).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360353</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F. (1976). Texture and reflection in computer generated images. Communications of the ACM, 19(10), 542--547.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Bresenham, J. E. (1965). Algorithm for computer control of a digital plotter. IBM Systems Journal, 4(1), 25--30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335548</ref_obj_id>
				<ref_obj_pid>335547</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Campagna, S., Kobbelt, L., & Seidel, H.-P. (1998). Directed edges-a scalable representation for triangle meshes. Journal of Graphics Tools, 3(4), 1--12.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Catmull, E. (1975). Computer display of curved surfaces. In IEEE conference on computer graphics, pattern recognition and data structures (pp. 11--17).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Cleary, J., Wyvill, B., Birtwistle, G., & Vatti, R. (1983). A Parallel Ray Tracing Computer. In Proceedings of the association of simula users conference (p. 77--80).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37414</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Cook, R. L., Carpenter, L., & Catmull, E. (1987). The reyes image rendering architecture. In Proceedings of SIGGRAPH (pp. 95--102).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Cook, R. L., Porter, T., & Carpenter, L. (1984). Distributed ray tracing. In Proceedings of SIGGRAPH (p. 165--174).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807359</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Crow, F. C. (1978). The use of grey scale for improved raster display of vectors and characters. In Proceedings of SIGGRAPH (pp. 1--5).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Crowe, M. J. (1994). A history of vector analysis. Mineola, NY: Dover.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Cyrus, M., & Beck, J. (1978). Generalized two- and three-dimensional clipping. Computers and Graphics, 3(1), 23--28.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[DeRose, T. (1989, September). A coordinate-free approach to geometric programming (Tech. Rep. No. 89-09-16). Seattle, WA: Universit of Washington.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Dobkin, D. P., & Mitchell, D. P. (1993). Random-edge discrepancy of supersampling patterns. In Proceedings of Graphics Interface (pp. 62--69).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91422</ref_obj_id>
				<ref_obj_pid>91385</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Dooley, D., & Cohen, M. (1990). Automatic illustration of 3d geometric models: Lines. In Symposium on interactive 3D graphics (pp. 77--82).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Doran, C., & Lasenby, A. (2003). Geometric algebra for physicists. Cambridge: Cambridge University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Eberly, D. (2000). Game engine design. San Francisco, CA: Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1050935</ref_obj_id>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Farin, G., & Hansford, D. (2004). Practical linear algebra: A geometry toolbox. Wellesley, MA: AK Peters.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807481</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H., Kedem, Z. M., & Naylor, B. F. (1980). On visible surface generation by a priori tree structures. In Proceedings of SIGGRAPH (pp. 124--133).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>13044</ref_obj_id>
				<ref_obj_pid>13043</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Fujimoto, A., Tanaka, T., & Iwata, K. (1986, April). Arts: Accelerated ray-tracing system. IEEE Computer Graphics & Applications, 16--26.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Glassner, A. (1984). Space subdivision for fast ray tracing. IEEE Computer Graphics and Applications, 4(10), 15--22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617407</ref_obj_id>
				<ref_obj_pid>615999</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Glassner, A. (1988). Spacetime ray tracing for animation. IEEE Computer Graphics & Applications, 8(2), 60--70.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>94788</ref_obj_id>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Glassner, A. (Ed.). (1989). An introduction to ray tracing. London: Academic Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>282969</ref_obj_id>
				<ref_obj_pid>282957</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Goldman, R. (1985). Illicit expressions in vector algebra. ACM Transactions on Graphics, 4(3), 223--243.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>31469</ref_obj_id>
				<ref_obj_pid>31468</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Goldsmith, J., & Salmon, J. (1987, May). Automatic creation of object hierarchies for ray tracing. IEEE Computer Graphics & Applications, 14--20.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280950</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Gooch, A., Gooch, B., Shirley, P., & Cohen, E. (1998). A non-photorealistic lighting model for automatic technical illustration. In Proceedings of SIGGRAPH (pp. 447--452).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Gouraud, H. (1971). Continuous shading of curved surfaces. Communications of the ACM, 18(6), 623--629.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Hammersley, J., & Handscomb, D. (1964). Monte-carlo methods. Methuen, London.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Hanson, A. J. (2005). Visualizing quaternions. San Francisco, CA: Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Hausner, M. (1998). A vector space approach to geometry. Mineola, NY: Dover.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Havran, V. (2000). Heuristic ray shooting algorithms. Unpublished doctoral dissertation, Czech Technical University in Prague.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>6251</ref_obj_id>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Hearn, D., & Baker, M. P. (1986). Computer graphics. Englewood Cliffs, N. J.: Prentice-Hall.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Heidrich, W., & Seidel, H.-P. (1998). Ray-tracing procedural displacement shaders. In Graphics interface (pp. 8--16).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Hoffmann, B. (1975). About vectors. Mineola, NY: Dover.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>643333</ref_obj_id>
				<ref_obj_pid>643328</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Hughes, J. F., & M&ouml;&#246;&#246;ller, T. (1999). Building an orthonormal basis from a unit vector. Journal of Graphics Tools, 4(4), 33--35.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>24316</ref_obj_id>
				<ref_obj_pid>18928</ref_obj_pid>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Jansen, F. W. (1986). Data structures for ray tracing. In Proceedings of the workshop on data structures for raster graphics (p. 57--73).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>7050</ref_obj_id>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Kalos, M., & Whitlock, P. (1986). Monte carlo methods, basics. Wiley-Interscience.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807438</ref_obj_id>
				<ref_obj_pid>800249</ref_obj_pid>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Kay, D. S., & Greenberg, D. P. (1979). Transparency for computer synthesized images. In Proceedings of SIGGRAPH (pp. 158--164).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>295125</ref_obj_id>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Kernighan, B. W., & Pike, R. (1999). The practice of programming. Reading, MA: Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>602145</ref_obj_id>
				<ref_obj_pid>602099</ref_obj_pid>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Kindlmann, G., Reinhard, E., & Creem, S. (2002). Face-based luminance matching for perceptual colormap generation. In Proceedings of Visualization (pp. 299--306).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[Kirk, D., & Arvo, J. (1988). The ray tracing kernel. In Proceedings of Ausgraph.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[Kollig, T., & Keller, A. (2002). Efficient multidimensional sampling. Computer Graphics Forum, 21(3), 557--564.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>235119</ref_obj_id>
				<ref_seq_no>50</ref_seq_no>
				<ref_text><![CDATA[Lakos, J. (1996). Large-scale C++ software design. Reading, MA: Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357333</ref_obj_id>
				<ref_obj_pid>357332</ref_obj_pid>
				<ref_seq_no>51</ref_seq_no>
				<ref_text><![CDATA[Liang, Y.-D., & Barsky, B. A. (1984). A new concept and method for line clipping. ACM Transactions on Graphics, 3(1), 1--22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>525754</ref_obj_id>
				<ref_seq_no>52</ref_seq_no>
				<ref_text><![CDATA[Meyers, S. (1995). More effective C++: 35 new ways to improve your programs and designs. Reading, MA: Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>264000</ref_obj_id>
				<ref_seq_no>53</ref_seq_no>
				<ref_text><![CDATA[Meyers, S. (1997). Effective C++: 50 specific ways to improve your programs and designs (Second ed.). Reading, MA: Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237265</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>54</ref_seq_no>
				<ref_text><![CDATA[Mitchell, D. P. (1996). Consequences of stratified sampling in graphics. In Proceedings of SIGGRAPH (pp. 277-280).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312306</ref_obj_id>
				<ref_seq_no>55</ref_seq_no>
				<ref_text><![CDATA[M&#246;ller, T., & Haines, E. (1999). Real-time rendering. Wellesley, MA: AK Peters.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>56</ref_seq_no>
				<ref_text><![CDATA[M&#246;ller, T., & Haines, E. (2002). Real-time rendering (Second ed.). Wellesley, MA: AK Peters.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>643329</ref_obj_id>
				<ref_obj_pid>643328</ref_obj_pid>
				<ref_seq_no>57</ref_seq_no>
				<ref_text><![CDATA[M&#246;ller, T., & Hughes, J. (1999). Efficiently building a matrix to rotate one vector to another. Journal of Graphics Tools, 4(4), 1--4.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>58</ref_seq_no>
				<ref_text><![CDATA[Muuss, M. J. (1995). Towards real-time ray-tracing of combinatorial solid geometric models. In Proceedings of BRL-CAD symposium.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>90811</ref_obj_id>
				<ref_obj_pid>90767</ref_obj_pid>
				<ref_seq_no>59</ref_seq_no>
				<ref_text><![CDATA[Paeth, A. W (1990). A fast algorithm for general raster rotation. In Graphics gems (pp. 179--195).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300537</ref_obj_id>
				<ref_obj_pid>300523</ref_obj_pid>
				<ref_seq_no>60</ref_seq_no>
				<ref_text><![CDATA[Parker, S., Martin, W., Sloan, P., Shirley, P., Smits, B., & Hansen, C. (1999). Interactive ray tracing. In ACM symposium on interactive 3D graphics (pp. 119--126).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>61</ref_seq_no>
				<ref_text><![CDATA[Patterson, J., Hoggar, S., & Logie, J. (1991). Inverse displacement mapping. Computer Graphics Forum, 10(2), 129--139.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325246</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>62</ref_seq_no>
				<ref_text><![CDATA[Peachey, D. (1985). Solid texturing of complex surfaces. In Proceedings of SIGGRAPH (pp. 279--286).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>6757</ref_obj_id>
				<ref_seq_no>63</ref_seq_no>
				<ref_text><![CDATA[Penna, M., & Patterson, R. (1986). Projective geometry and its applications to computer graphics. Englewood Cliffs, NJ: Prentice Hall.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>64</ref_seq_no>
				<ref_text><![CDATA[Perlin, K. (1985). An image synthesizer. In Proceedings of SIGGRAPH (pp. 287--296).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>275462</ref_obj_id>
				<ref_obj_pid>275458</ref_obj_pid>
				<ref_seq_no>65</ref_seq_no>
				<ref_text><![CDATA[Pharr, M., & Hanrahan, P. (1996). Geometry caching for ray-tracing displacement maps. In Eurographics rendering workshop (pp. 31--40).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258791</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>66</ref_seq_no>
				<ref_text><![CDATA[Pharr, M., Kolb, C., Gershbein, R., & Hanrahan, P. (1997). Rendering complex scenes with memory-coherent ray tracing. In Proceedings of SIGGRAPH (pp. 101--108).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>67</ref_seq_no>
				<ref_text><![CDATA[Phong, B.-T. (1975). Illumination for computer generated images. Communications of the ACM, 18(6), 311--317.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378457</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>68</ref_seq_no>
				<ref_text><![CDATA[Pineda, J. (1988). A parallel algorithm for polygon rasterization. In Proceedings of SIGGRAPH (pp. 17--20).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>69</ref_seq_no>
				<ref_text><![CDATA[Pitteway, M. L. V. (1967). Algorithm for drawing ellipses or hyperbolae with a digital plotter. Computer Journal, 10(3), 282--289.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>532092</ref_obj_id>
				<ref_seq_no>70</ref_seq_no>
				<ref_text><![CDATA[Plauger, P. J. (1991). The standard C library. Englewood Cliffs, NJ: Prentice Hall.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808606</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>71</ref_seq_no>
				<ref_text><![CDATA[Porter, T., & Duff, T. (1984). Compositing digital images. In Proceddings of SIGGRAPH (p. 253--259).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>72</ref_seq_no>
				<ref_text><![CDATA[Riesenfeld, R. F. (1981, January). Homogeneous coordinates and projective planes in computer graphics. IEEE Computer Graphics & Applications, 1, 50--55.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>73</ref_seq_no>
				<ref_text><![CDATA[Roberts, L. (1965, May). Homogenous matrix representation and manipulation of n-dimensional constructs (Tech. Rep. No. MS-1505). Lexington, MA: MIT Lincoln Laboratory.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>74</ref_seq_no>
				<ref_text><![CDATA[Roth, S. (1982). Ray casting for modelling solids. Computer Graphics and Image Processing, 18(2), 109--144.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807479</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>75</ref_seq_no>
				<ref_text><![CDATA[Rubin, S., & Whitted, J. T. (1980). A 3-dimensional representation for fast rendering of complex scenes. In Proceedings of SIGGRAPH (pp. 110--116).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97901</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>76</ref_seq_no>
				<ref_text><![CDATA[Saito, T., & Takahashi, T. (1990). Comprehensible rendering of 3-d shapes. In Proceedings of SIGGRAPH (pp. 197--206).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>553841</ref_obj_id>
				<ref_seq_no>77</ref_seq_no>
				<ref_text><![CDATA[Salomon, D. (1999). Computer graphics and geometric modeling. New York, NY: Springer Verlag.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134071</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>78</ref_seq_no>
				<ref_text><![CDATA[Segal, M., Korobkin, C., Widenfelt, R. van, Foran, J., & Haeberli, P. E. (1992). Fast shadows and lighting effects using texture mapping. In Proceedings of SIGGRAPH (pp. 249--252).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732125</ref_obj_id>
				<ref_obj_pid>647652</ref_obj_pid>
				<ref_seq_no>79</ref_seq_no>
				<ref_text><![CDATA[Smits, B., Shirley, P., & Stark, M. M. (2000). Direct ray tracing of displacement mapped triangles. In Eurographics workshop on rendering (pp. 307--318).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37417</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>80</ref_seq_no>
				<ref_text><![CDATA[Snyder, J., & Barr, A. (1987). Ray tracing complex models containing surface tessellations. In Proceedings of SIGGRAPH (pp. 119--128).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>81</ref_seq_no>
				<ref_text><![CDATA[Sobel, I., Stone, J., & Messer, R. (1975). The monte carlo method. Chicago, IL: University of Chicago Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>82</ref_seq_no>
				<ref_text><![CDATA[Solomon, H. (1978). Geometric probability. Philadelphia, PA: SIAM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>83</ref_seq_no>
				<ref_text><![CDATA[Strang, G. (1988). Linear algebra and its applications (third ed.). Florence, KY: Brooks Cole.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>84</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. E., Sproull, R. F., & Schumacker, R. A. (1974). A characterization of ten hidden-surface algorithms. ACM Computing Surveys, 6(1), 1--55.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>90920</ref_obj_id>
				<ref_obj_pid>90767</ref_obj_pid>
				<ref_seq_no>85</ref_seq_no>
				<ref_text><![CDATA[Turkowski, K. (1990). Properties of surface-normal transformations. In Graphics gems (pp. 539--547).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>282943</ref_obj_id>
				<ref_obj_pid>282918</ref_obj_pid>
				<ref_seq_no>86</ref_seq_no>
				<ref_text><![CDATA[Van Aken, J., & Novak, M. (1985). Curve-drawing algorithms for raster displays. ACM Transactions on Graphics, 4(2), 147--169.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258775</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>87</ref_seq_no>
				<ref_text><![CDATA[Veach, E., & Guibas, L. J. (1997). Metropolis light transport. In Proceedings of SIGGRAPH (pp. 65--76).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732298</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>88</ref_seq_no>
				<ref_text><![CDATA[Wald, I., Slusallek, P., & Benthin, C. (2001). Interactive distributed ray tracing of highly complex models. In Proceedings of the Eurographics workshop on rendering (pp. 277--288).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801127</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>89</ref_seq_no>
				<ref_text><![CDATA[Warn, D. R. (1983). Lighting controls for synthetic images. In Proceedings of SIGGRAPH (pp. 13--21).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>90</ref_seq_no>
				<ref_text><![CDATA[Whitted, T. (1980). An improved illumination model for shaded display. Communications of the ACM, 23(6), 343--349.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>91</ref_seq_no>
				<ref_text><![CDATA[Williams, A., Barrus, S., Morley, R. K., & Shirley, P. (2005). An efficient and robust ray-box intersection algorithm. Journal of Graphics Tools, 10(1).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801126</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>92</ref_seq_no>
				<ref_text><![CDATA[Williams, L. (1983). Pyramidal parametrics. In Proceedings of SIGGRAPH (pp. 1--11).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>93</ref_seq_no>
				<ref_text><![CDATA[Williams, L. (1991). Shading in two dimensions. In Proceedings of Graphics Interface (pp. 143--151).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>554539</ref_obj_id>
				<ref_seq_no>94</ref_seq_no>
				<ref_text><![CDATA[Woo, M., Neider, J., Davis, T., & Shreiner, D. (1999). OpenGL programming guide (Third ed.). Reading, MA: Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807443</ref_obj_id>
				<ref_obj_pid>800249</ref_obj_pid>
				<ref_seq_no>95</ref_seq_no>
				<ref_text><![CDATA[Yessios, C. I. (1979). Computer drafting of stones, wood, plant and ground materials. In Proceedings of SIGGRAPH) (pp. 190-198).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Data Structures for Graphics There are a variety of data structures that seem to pop up repeatedly 
in graphics applications. This chapter talks about three basic and unrelated data structures that are 
among the most common and useful. There are many variants of these data structures, but the basic ideas 
behind them can be conveyed using an example of each. First the winged-edge data structure for storing 
tessellated geometric models is discussed (Baumgart, 1974). The winged-edge data structure is useful 
for managing models where the tessellation changes, such as in subdivision or simpli.cation routines. 
Next, the scene-graph data structure is presented. These are rapidly becoming well supported features 
of all new graphics APIs because they are so useful in managing objects and transformations. Finally, 
the tiled multidimensional array is presented. Originally developed to help paging performance, such 
structures are now crucial for memory locality on machines regardless of whether the array .ts in main 
memory. 12.1 Triangle Meshes One of the most common model representations is a polygonal mesh as discussed 
in Section 10.3. When such meshes are unchanging in the program, the simple structure described in that 
section is usually suf.cient. However, when the meshes are to be modi.ed, more complicated data representations 
are needed to ef.ciently 12. Data Structures for Graphics answer queries such as: given a triangle, 
what are the three adjacent triangles?  given an edge, which two triangles share it?  given a vertex, 
which faces share it?  given a vertex, which edges share it?  There are many data structures for triangle 
meshes, polygonal meshes, and polyg onal meshes with holes (see the notes at the end of the chapter 
for references). In many applications the meshes are very large, so an ef.cient representation can be 
crucial. The most straightforward, though bloated, implementation is to have three types: vertex, edge, 
and triangle. There are a variety of ways to divide the data among these types. While one might be tempted 
to just store all the relationships, this makes for variable-length data structures that really are not 
needed. For ex ample, a vertex can have an arbitrarily large number of edges incident to it. It is best, 
therefore, to hide the implementation behind a class interface. 12.2 Winged-Edge Data Structure We can 
use the class winged-edge data structure. This data structure makes edges the .rst-class citizen of the 
data structure. This data structure, a more ef.cient implementation, is illustrated in Figures 12.1 and 
12.2. 12.2. Winged-Edge Data Structure Note that the winged-edge data structure makes the desired queries 
in constant time. For example, a face can access one of its edges and follow the traversal pointers to 
.nd all of its edges. Those edges store the adjoining face. As with any data structure, the winged-edge 
data structure makes a variety of time/space trade-offs. For example, we could eliminate the prev references. 
When we need to know the previous edge, we could follow the successor edges in a circle until we get 
back to the original edge. This would save space, but it would make the computation of the previous edge 
take longer. This type of issue has led to a proliferation of mesh data structures (see the chapter notes 
for more information on those structures). 12. Data Structures for Graphics  12.3 Scene Graphs To motivate 
the scene-graph data structure, we will use the hinged pendulum shown in Figure 12.3. Consider how we 
would draw the top part of the pendulum: M1 = rotate(.) M2 = translate(p) M3 = M2M1 Apply M3 to all 
points in upper pendulum The bottom is more complicated, but we can take advantage of the fact that 
it is attached to the bottom of the upper pendulum at point b in the local coordinate system. First, 
we rotate the lower pendulum so that it is at an angle f relative to its initial position. Then, we move 
it so that its top hinge is at point b. Now it is at the appropriate position in the local coordinates 
of the upper pendulum, and it can then be moved along with that coordinate system. The composite transform 
for the lower pendulum is: Ma = rotate(f) Mb = translate(b) Mc = MbMa Md = M3Mc Apply Md to all points 
in lower pendulum Thus, we see that the lower pendulum not only lives in its own local coordinate system, 
but also that coordinate system itself is moved along with that of the upper pendulum. 12.3. Scene Graphs 
225 We can encode the pendulum in a data structure that makes management of these coordinate system issues 
easier, as shown in Figure 12.4. The appropriate matrix to apply to an object is just the product of 
all the matrices in the chain from the object to the root of the data structure. For example, consider 
the model of a ferry that has a car that can move freely on the deck of the ferry, and wheels that each 
move relative to the car as shown in Figure 12.5. As with the pendulum, each object should be transformed 
by the product of the matrices in the path from the root to the object: ferry transform using M0 car 
body transform using M0M1 left wheel transform using M0M1M2 left wheel transform using M0M1M3 An ef.cient 
implementation can be achieved using a matrix stack, a data structure supported by many APIs. A matrix 
stack is manipulated using push and pop operations that add and delete matrices from the right-hand 
side of a matrix product. For example, calling: push(M0) push(M1) push(M2) creates the active matrix 
M = M0M1M2. A subsequent call to pop() strips the last matrix added so that the active matrix becomes: 
M = M0M1. Combining the matrix stack with a recursive traversal of a scene graph gives us: function traverse(node) 
push(Mlocal) draw object using composite matrix from stack traverse(left child) traverse(right child) 
pop() There are many variations on scene graphs but all follow the basic idea above.   Figure 12.7. 
The memory layout for a tiled 2D array with Nx = 4 and Ny = 3 and two by two tiles. Note that padding 
on the top of the array is needed because Ny is not a multiple of the tile size two. 226 12. Data Structures 
for Graphics 12.4 Tiling Multidimensional Arrays Effectively utilizing the cache hierarchy is a crucial 
task in designing algorithms for modern architectures. Making sure that multidimensional arrays have 
data in a nice arrangement is accomplished by tiling, sometimes also called bricking.A traditional 2D 
array is stored as a 1D array together with an indexing mechanism; for example, an Nx by Ny array is 
stored in a 1D array of length NxNy and the 2D index (x, y) (which runs from (0, 0) to (Nx - 1,Ny - 1)) 
and maps it to the 1D index (running from 0 to NxNy - 1 using the formula index = x + Nxy. An example 
of how that memory lays out is shown in Figure 12.6. A problem with this layout is that although two 
adjacent array elements that are in the same row are next to each other in memory, two adjacent elements 
in the same column will be separated by Nx elements in memory. This can cause poor memory locality for 
large Nx. The standard solution to this is to use tiles to make memory locality for rows and columns 
more equal. An example is shown in Figure 12.7 where two by two tiles are used. The details of indexing 
such an array are discussed in the next section. A more complicated example with two levels of tiling 
on a 3D array are covered after that. A key question is what size to make the tiles. In practice, they 
should be similar to the memory-unit size on the machine. For example, on a machine with 128-byte cache 
lines, and using 16-bit data values, n is exactly 8. However, using .oat (32-bit) datasets, n is closer 
to 5. Because there are also coarser-sized memory units such as pages, hierarchical tiling with similar 
logic can be useful. 12.4.1 One-Level Tiling for 2D Arrays If we assume an Nx by Ny array decomposed 
into square n by n tiles (Figure 12.8), then the number of tiles required is Bx = Nx/n, By = Ny/n. 
Here, we assume that n divides Nx and Ny exactly. When this is not true, the array should be padded. 
For example, if Nx =15 and n =4, then Nx should be changed to 16. To work out a formula for indexing 
such an array, we .rst .nd the tile indices (bx,by) that give the row/column for the tiles (the tiles 
themselves form a 2D array): bx = x  n, by = y  n, 12.4. Tiling Multidimensional Arrays where  is 
integer division, e.g., 12  5=2. If we order the tiles along rows as shown in Figure 12.6, then the 
index of the .rst element of the tile (bx,by) is index = n 2(Bxby + bx). The memory in that tile is 
arranged like a traditional 2D array as shown in Fig ure 12.7. The partial offsets (x,y.) inside the 
tile are x = x mod n, y = y mod n, where mod is the remainder operator, e.g., 12mod5 = 2. Therefore, 
the offset inside the tile is offset = yn + x. Thus the full formula for .nding the 1D index element 
(x, y) in an Nx by Ny array with n by n tiles is index = n 2(Bxby + bx)+ yn + x, = n 2((Nx  n)(y  n)+ 
x  n)+(y mod n)n +(x mod n). This expression contains many integer multiplication, divide and modulus 
operations. On modern processors, these operations are extremely costly. For n that are powers of two, 
these operations can be converted to bitshifts and bitwise logical operations. However, as noted above, 
the ideal size is not always a power 12. Data Structures for Graphics of two. Some of the multiplications 
can be converted to shift/add operations, but the divide and modulus operations are more problematic. 
The indices could be computed incrementally, but this would require tracking counters, with numerous 
comparisons and poor branch prediction performance. However, there is a simple solution; note that the 
index expression can be written as index = Fx(x)+ Fy(y), where Fx(x)= n 2(x  n)+(x mod n), Fy(y)= n 
2(Nx  n)(y  n)+(y mod n)n.  We tabulate Fx and Fy, and use x and y to .nd the index into the data 
array. These tables will consist of Nx and Ny elements, respectively. The total size of the tables will 
.t in the primary data cache of the processor, even for very large data set sizes. 12.4.2 Example: Two-Level 
Tiling for 3D Arrays Effective TLB utilization is also becoming a crucial factor in algorithm perfor 
mance. The same technique can be used to improve TLB hit rates in a 3D array by creating m  m  m bricks 
of n  n  n cells. For example, a 40  20  19 volume could be decomposed into 4  2  2 macrobricks 
of 2  2  2 bricks of 5  5  5 cells. This corresponds to m =2 and n =5. Because 19 cannot be factored 
by mn =10, one level of padding is needed. Empirically useful sizes are m =5 for 16 bit datasets and 
m =6 for .oat datasets. The resulting index into the data array can be computed for any (x, y, z) triple 
with the expression 3 index =((x  n)  m)nm 3((Nz  n)  m)((Ny  n)  m) 3 +((y  n)  m)nm 3((Nz 
 n)  m) 33 +((z  n)  m)nm 32 +((x  n)mod m)nm 3 +((y  n)mod m)nm 3 +((z  n)mod m)n 2 +(x mod (n 
2))n +(y mod n)n +(z mod n), where Nx, Ny and Nz are the respective sizes of the dataset.  12.4. Tiling 
Multidimensional Arrays Note that, as in the simpler 2D one-level case, this expression can be written 
as index = Fx(x)+ Fy(y)+ Fz(z), where 3 Fx(x)=((x  n)  m)nm 3((Nz  n)  m)((Ny  n)  m) 32 +((x 
 n)mod m)nm 2 +(x mod n)n, 3 Fy(y)=((y  n)  m)nm 3((Nz  n)  m) 3 +((y  n)mod m)nm + +(y mod n)n, 
33 Fz(z)=((z  n)  m)nm 3 +((z  n)mod m)n +(z mod n).  Frequently Asked Questions Does tiling really 
make that much difference in performance? On some volume rendering applications, a two-level tiling strategy 
made as much as a factor-of-ten performance difference. When the array does not .t in main memory, it 
can effectively prevent thrashing in some applications such as image editing. How do I store the lists 
in a winged-edge structure? For most applications it is feasible to use arrays and indices for the references. 
However, if many delete operations are to be performed, then it is wise to use linked lists and pointers. 
 Notes The discussion of the winged-edge data structure is based on the course notes of Ching-Kuang Shene. 
There are smaller mesh data structures than wingededge. The trade-offs in using such structures is discussed 
in Directed Edges A Scalable Representation for Triangle Meshes (Campagna, Kobbelt, &#38; Seidel, 12. 
Data Structures for Graphics 1998) The tiled-array discussion is based on Interactive Ray Tracing for 
Volume Visualization (Parker et al., 1999). Exercises 1. What is the memory difference for a simple 
tetrahedron stored as four independent triangles and one stored in a winged-edge data structure? 2. 
Diagram a scene graph for a bicycle.  3. How many look-up tables are needed for a single-level tiling 
of an ndimensional array?  References 253 References Amanatides, J., &#38; Woo, A. (1987). A fast 
voxel traversal algorithm for ray tracing. In Proceedings of Eurographics (pp. 1 10). Appel, A. (1968). 
Some techniques for shading machine renderings of solids. In Proceedings of the AFIPS spring joint computing 
conference (p. 37-49). Association, I. S. (1985). IEEE standard for binary .oating-point arithmetic. 
IEEE Report (New York). (ANSI/IEEE Std 754-1985) Baumgart, B. (1974, October). Geometric modeling for 
computer vision (Tech. Rep. No. AIM-249). Seattle, WA: Stanford University AI Laboratory. Bayer, B. E. 
(1976). Color imaging array. (U.S. Patent 3,971,065) Beck, K., &#38; Andres, C. (2004). Extreme programming 
explained : Embrace change (Second ed.). Reading, MA: Addison-Wesley. Blinn, J. (1978). Simulation of 
wrinkled surfaces. In Proceedings of SIGGRAPH (pp. 286 292). Blinn, J. (1996). Jim blinn s corner. San 
Francisco, CA: Morgan Kaufmann. Blinn, J., &#38; Newell, M. (1978). Clipping using homogeneous coordinates. 
In Proceedings of SIGGRAPH (pp. 245 251). Blinn, J. F. (1976). Texture and re.ection in computer generated 
images. Communications of the ACM, 19(10), 542-547. Bresenham, J. E. (1965). Algorithm for computer 
control of a digital plotter. IBM Systems Journal, 4(1), 25 30. Campagna, S., Kobbelt, L., &#38; Seidel, 
H.-P. (1998). Directed edges a scalable representation for triangle meshes. Journal of Graphics Tools, 
3(4), 1 12. Catmull, E. (1975). Computer display of curved surfaces. In IEEE conference on computer graphics, 
pattern recognition and data structures (pp. 11 17). Cleary, J., Wyvill, B., Birtwistle, G., &#38; Vatti, 
R. (1983). A Parallel Ray Tracing Computer. In Proceedings of the association of simula users conference 
(p. 77-80). Cook, R. L., Carpenter, L., &#38; Catmull, E. (1987). The reyes image rendering architecture. 
In Proceedings of SIGGRAPH (pp. 95 102). Cook, R. L., Porter, T., &#38; Carpenter, L. (1984). Distributed 
ray tracing. In Proceedings of SIGGRAPH (p. 165-174). Crow, F. C. (1978). The use of grey scale for improved 
raster display of vectors and characters. In Proceedings of SIGGRAPH (pp. 1 5). Crowe, M. J. (1994). 
A history of vector analysis. Mineola, NY: Dover. Cyrus, M., &#38; Beck, J. (1978). Generalized two-and 
three-dimensional clipping. Computers and Graphics, 3(1), 23 28. DeRose, T. (1989, September). A coordinate-free 
approach to geometric programming (Tech. Rep. No. 89-09-16). Seattle, WA: Universit of Washington. 
254 13. Sampling Dobkin, D. P., &#38; Mitchell, D. P. (1993). Random edge discrepancy of supersampling 
patterns. In Proceedings of Graphics Interface (pp. 62 69). Dooley, D., &#38; Cohen, M. (1990). Automatic 
illustration of 3d geometric models: Lines. In Symposium on interactive 3D graphics (pp. 77 82). Doran, 
C., &#38; Lasenby, A. (2003). Geometric algebra for physicists. Cambridge: Cambridge University Press. 
Eberly, D. (2000). Game engine design. San Francisco, CA: Morgan Kaufmann. Farin, G., &#38; Hansford, 
D. (2004). Practical linear algebra: A geometry toolbox. Wellesley, MA: AK Peters. Fuchs, H., Kedem, 
Z. M., &#38; Naylor, B. F. (1980). On visible surface generation by a priori tree structures. In Proceedings 
of SIGGRAPH (pp. 124 133). Fujimoto, A., Tanaka, T., &#38; Iwata, K. (1986, April). Arts: Accelerated 
ray-tracing system. IEEE Computer Graphics &#38; Applications, 16 26. Glassner, A. (1984). Space subdivision 
for fast ray tracing. IEEE Computer Graphics and Applications, 4(10), 15 22. Glassner, A. (1988). Spacetime 
ray tracing for animation. IEEE Computer Graphics &#38; Applications, 8(2), 60 70. Glassner, A. (Ed.). 
(1989). An introduction to ray tracing. London: Academic Press. Goldman, R. (1985). Illicit expressions 
in vector algebra. ACM Transactions on Graphics, 4(3), 223 243. Goldsmith, J., &#38; Salmon, J. (1987, 
May). Automatic creation of object hierarchies for ray tracing. IEEE Computer Graphics &#38; Applications, 
14 20. Gooch, A., Gooch, B., Shirley, P., &#38; Cohen, E. (1998). A non-photorealistic lighting model 
for automatic technical illustration. In Proceedings of SIG-GRAPH (pp. 447 452). Gouraud, H. (1971). 
Continuous shading of curved surfaces. Communications of the ACM, 18(6), 623-629. Hammersley, J., &#38; 
Handscomb, D. (1964). Monte-carlo methods. Methuen, London. Hanson, A. J. (2005). Visualizing quaternions. 
San Francisco, CA: Morgan Kaufmann. Hausner, M. (1998). A vector space approach to geometry. Mineola, 
NY: Dover. Havran, V. (2000). Heuristic ray shooting algorithms. Unpublished doctoral dissertation, Czech 
Technical University in Prague. Hearn, D., &#38; Baker, M. P. (1986). Computer graphics. Englewood Cliffs, 
N.J.: Prentice-Hall. Heidrich, W., &#38; Seidel, H.-P. (1998). Ray-tracing procedural displacement shaders. 
In Graphics interface (pp. 8 16). Hoffmann, B. (1975). About vectors. Mineola, NY: Dover. Hughes, J. 
F., &#38; Moller, T. (1999). Building an orthonormal basis from a unit vector. Journal of Graphics Tools, 
4(4), 33 35. References 255 Jansen, F. W. (1986). Data structures for ray tracing. In Proceedings of 
the workshop on data structures for raster graphics (p. 57-73). Kalos, M., &#38; Whitlock, P. (1986). 
Monte carlo methods, basics. Wiley-Interscience. Kay, D. S., &#38; Greenberg, D. P. (1979). Transparency 
for computer synthesized images. In Proceedings of SIGGRAPH (pp. 158 164). Kernighan, B. W., &#38; Pike, 
R. (1999). The practice of programming. Reading, MA: Addison-Wesley. Kindlmann, G., Reinhard, E., &#38; 
Creem, S. (2002). Face-based luminance matching for perceptual colormap generation. In Proceedings of 
Visualization (pp. 299 306). Kirk, D., &#38; Arvo, J. (1988). The ray tracing kernel. In Proceedings 
of Ausgraph. Kollig, T., &#38; Keller, A. (2002). Ef.cient multidimensional sampling. Computer Graphics 
Forum, 21(3), 557 564. Lakos, J. (1996). Large-scale C++ software design. Reading, MA: Addison-Wesley. 
Liang, Y.-D., &#38; Barsky, B. A. (1984). A new concept and method for line clipping. ACM Transactions 
on Graphics, 3(1), 1 22. Meyers, S. (1995). More effective C++: 35 new ways to improve your programs 
and designs. Reading, MA: Addison-Wesley. Meyers, S. (1997). Effective C++: 50 speci.c ways to improve 
your programs and designs (Second ed.). Reading, MA: Addison-Wesley. Mitchell, D. P. (1996). Consequences 
of strati.ed sampling in graphics. In Proceedings of SIGGRAPH (pp. 277 280). M oller, T., &#38; Haines, 
E. (1999). Real-time rendering. Wellesley, MA: AK Peters. Moller, T., &#38; Haines, E. (2002). Real-time 
rendering (Second ed.). Wellesley, MA: AK Peters. M oller, T., &#38; Hughes, J. (1999). Ef.ciently building 
a matrix to rotate one vector to another. Journal of Graphics Tools, 4(4), 1 4. Muuss, M. J. (1995). 
Towards real-time ray-tracing of combinatorial solid geometric models. In Proceedings of BRL-CAD symposium. 
Paeth, A. W. (1990). A fast algorithm for general raster rotation. In Graphics gems (pp. 179 195). Parker, 
S., Martin, W., Sloan, P., Shirley, P., Smits, B., &#38; Hansen, C. (1999). Interactive ray tracing. 
In ACM symposium on interactive 3D graphics (pp. 119 126). Patterson, J., Hoggar, S., &#38; Logie, J. 
(1991). Inverse displacement mapping. Computer Graphics Forum, 10(2), 129 139. Peachey, D. (1985). Solid 
texturing of complex surfaces. In Proceedings of SIGGRAPH (pp. 279 286). Penna, M., &#38; Patterson, 
R. (1986). Projective geometry and its applications to computer graphics. Englewood Cliffs, NJ: Prentice 
Hall. 256 13. Sampling Perlin, K. (1985). An image synthesizer. In Proceedings of SIGGRAPH (pp. 287 296). 
Pharr, M., &#38; Hanrahan, P. (1996). Geometry caching for ray-tracing displacement maps. In Eurographics 
rendering workshop (pp. 31 40). Pharr, M., Kolb, C., Gershbein, R., &#38; Hanrahan, P. (1997). Rendering 
complex scenes with memory-coherent ray tracing. In Proceedings of SIGGRAPH (pp. 101 108). Phong, B.-T. 
(1975). Illumination for computer generated images. Communications of the ACM, 18(6), 311-317. Pineda, 
J. (1988). A parallel algorithm for polygon rasterization. In Proceedings of SIGGRAPH (pp. 17 20). Pitteway, 
M. L. V. (1967). Algorithm for drawing ellipses or hyperbolae with a digital plotter. Computer Journal, 
10(3), 282 289. Plauger, P. J. (1991). The standard C library. Englewood Cliffs, NJ: Prentice Hall. Porter, 
T., &#38; Duff, T. (1984). Compositing digital images. In Proceddings of SIGGRAPH (p. 253-259). Riesenfeld, 
R. F. (1981, January). Homogeneous coordinates and projective planes in computer graphics. IEEE Computer 
Graphics &#38; Applications, 1, 50 55. Roberts, L. (1965, May). Homogenous matrix representation and 
manipulation of n-dimensional constructs (Tech. Rep. No. MS-1505). Lexington, MA: MIT Lincoln Laboratory. 
Roth, S. (1982). Ray casting for modelling solids. Computer Graphics and Image Processing, 18(2), 109 
144. Rubin, S., &#38; Whitted, J. T. (1980). A 3-dimensional representation for fast rendering of complex 
scenes. In Proceedings of SIGGRAPH (pp. 110 116). Saito, T., &#38; Takahashi, T. (1990). Comprehensible 
rendering of 3-d shapes. In Proceedings of SIGGRAPH (pp. 197 206). Salomon, D. (1999). Computer graphics 
and geometric modeling. New York, NY: Springer Verlag. Segal, M., Korobkin, C., Widenfelt, R. van, Foran, 
J., &#38; Haeberli, P. E. (1992). Fast shadows and lighting effects using texture mapping. In Proceedings 
of SIGGRAPH (pp. 249 252). Smits, B., Shirley, P., &#38; Stark, M. M. (2000). Direct ray tracing of displacement 
mapped triangles. In Eurographics workshop on rendering (pp. 307 318). Snyder, J., &#38; Barr, A. (1987). 
Ray tracing complex models containing surface tessellations. In Proceedings of SIGGRAPH (pp. 119 128). 
Sobel, I., Stone, J., &#38; Messer, R. (1975). The monte carlo method. Chicago, IL: University of Chicago 
Press. Solomon, H. (1978). Geometric probability. Philadelphia, PA: SIAM Press. References 257 Strang, 
G. (1988). Linear algebra and its applications (third ed.). Florence, KY: Brooks Cole. Sutherland, I. 
E., Sproull, R. F., &#38; Schumacker, R. A. (1974). A characterization of ten hidden-surface algorithms. 
ACM Computing Surveys, 6(1), 1 55. Turkowski, K. (1990). Properties of surface-normal transformations. 
In Graphics gems (pp. 539 547). Van Aken, J., &#38; Novak, M. (1985). Curve-drawing algorithms for raster 
displays. ACM Transactions on Graphics, 4(2), 147 169. Veach, E., &#38; Guibas, L. J. (1997). Metropolis 
light transport. In Proceedings of SIGGRAPH (pp. 65 76). Wald, I., Slusallek, P., &#38; Benthin, C. (2001). 
Interactive distributed ray tracing of highly complex models. In Proceedings of the Eurographics workshop 
on rendering (pp. 277 288). Warn, D. R. (1983). Lighting controls for synthetic images. In Proceedings 
of SIGGRAPH (pp. 13 21). Whitted, T. (1980). An improved illumination model for shaded display. Communications 
of the ACM, 23(6), 343 349. Williams, A., Barrus, S., Morley, R. K., &#38; Shirley, P. (2005). An ef.cient 
and robust ray-box intersection algorithm. Journal of Graphics Tools, 10(1). Williams, L. (1983). Pyramidal 
parametrics. In Proceedings of SIGGRAPH (pp. 1 11). Williams, L. (1991). Shading in two dimensions. In 
Proceedings of Graphics Interface (pp. 143 151). Woo, M., Neider, J., Davis, T., &#38; Shreiner, D. (1999). 
OpenGL programming guide (Third ed.). Reading, MA: Addison-Wesley. Yessios, C. I. (1979). Computer drafting 
of stones, wood, plant and ground materials. In Proceedings of SIGGRAPH) (pp. 190 198). 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198743</article_id>
		<sort_key>4</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[An improved illumination model for shaded display]]></title>
		<page_from>4</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198743</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198743</url>
		<abstract>
			<par><![CDATA[To accurately render a two-dimensional image of a three-dimensional scene, global illumination information that affects the intensity of each pixel of the image must be known at the time the intensity is calculated. In a simplified form, this information is stored in a tree of "rays" extending from the viewer to the first surface encountered and from there to other surfaces and to the light sources. A visible surface algorithm creates this tree for each pixel of the display and passes it to the shader. The shader then traverses the tree to determine the intensity of the light received by the viewer. Consideration of all of these factors allows the shader to accurately simulate true reflection, shadows, and refraction, as well as the effects simulated by conventional shaders. Anti-aliasing is included as an integral part of the visibility calculations. Surfaces displayed include curved as well as polygonal surfaces.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[computer animation]]></kw>
			<kw><![CDATA[computer graphics]]></kw>
			<kw><![CDATA[raster displays]]></kw>
			<kw><![CDATA[shading]]></kw>
			<kw><![CDATA[visible surface algorithms]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P285628</person_id>
				<author_profile_id><![CDATA[81100586999]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Turner]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Whitted]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bell Laboratories, Holmdel, New Jersey]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Appel, A. Some techniques for shading machine renderings of solids. AFIPS 1968 Spring Joint Comptr. Conf., pp. 37--45.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807403</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Atherton, P., Weiler, K., and Greenberg, D. Polygon shadow generation. Proc. S1GGRAPH 1978, Atlanta, Ga., pp. 275--281.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F. Models of light reflection for computer synthesized pictures. Proc. SIGGRAPH 1977, San Jose, Calif., pp. 192--198.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F. Simulation of wrinkled surfaces. Proc. SIGGRAPH 1978, Atlanta, Ga., pp. 286--292.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360353</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F., and Newell, M. E. Texture and reflection in computer generated images. Comm. ACM 19, 10 (Oct. 1976), 542--547.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>810236</ref_obj_id>
				<ref_obj_pid>800179</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F., and Newell, M. E. The progression of realism in computer generated images. Proc. of the ACM Ann. Conf., 1977, pp. 444--448.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Bouknight, W. K., and Kelley, K. C. An algorithm for producing half-tone computer graphics presentations with shadows and movable light sources. AFIPS 1970 Spring Joint Comptr. Conf., pp. 1--10.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Bui-Tuong Phong. Illumination for computer generated images. Comm. ACM 18, 6 (June 1975), 311--317.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Catmull, E. A subdivision algorithm for computer display of curved surfaces. UTEC CSc-74-133, Comptr. Sci. Dept., Univ. of Utah, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Catmull, E., and Clark, J. Recursively generated B-spline surfaces on arbitrary topological meshes. Comptr. Aided Design 10, 6 (Nov. 1978), 350--355.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360354</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Clark, J. H. Hierarchical geometric models for visible surface algorithms. Comm. ACM 19, 10 (Oct. 1976), 547--554.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563901</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Crow, F. C. Shadow algorithms for computer graphics. Proc. SIGGRAPH 1977, San Jose, Calif., pp. 242--248.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>359869</ref_obj_id>
				<ref_obj_pid>359863</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Crow, F. C. The aliasing problem in computer-generated shaded images. Comm. ACM 20, 11 (Nov. 1977), 799--805.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Goldstein, R. A. and Nagel, R. 3-D visual simulation. Simulation (Jan. 1971), 25--31.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Jarvis, J. F., Judice, C. N., and Ninke, W. H. A survey of techniques for the display of continuous tone pictures on bilevel displays. Comptr. Graphics and Image Proc. 5 (1976), 13--40.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Kay, D. S. Transparency, refraction, and ray tracing for computer synthesized images. Masters thesis, Cornell Univ., Ithaca, N. Y., January 1979.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807438</ref_obj_id>
				<ref_obj_pid>800249</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Kay, D. S., and Greenberg, D. Transparency for computer synthesized images. Proc. SIGGRAPH 1979, Chicago, Ill., pp. 158--164.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569954</ref_obj_id>
				<ref_obj_pid>800193</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Newell, M. E., Newell, R. G., and Sancha, T. L. A solution to the hidden surface problem. Proc. ACM Ann. Conf., 1972, pp. 443--450.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Warnock, J. E. A hidden line algorithm for halftone picture representation. Tech. Rep. TR 4-15, Comptr. Sci. Dept., Univ. of Utah, 1969.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807402</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Williams, L. Casting curved shadows on curved surfaces. Proc. SIGGRAPH 1978, Atlanta, Ga., pp. 270--274.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Graphics and J.D. Foley Image Processing Editor An Improved Illumination Model for Shaded Display Turner 
Whitted Bell Laboratories Holmdel, New Jersey To accurately render a two-dimensional image of a three-dimensional 
scene, global illumination information that affects the intensity of each pixel of the image must be 
known at the time the intensity is calculated. In a simplified form, this information is stored in a 
tree of "rays" extending from the viewer to the first surface encountered and from there to other surfaces 
and to the light sources. A visible surface algorithm creates this tree for each pixel of the display 
and passes it to the shader. The shader then traverses the tree to determine the intensity of the light 
received by the viewer. Consideration of all of these factors allows the shader to accurately simulate 
true reflection, shadows, and refraction, as well as the effects simulated by conventional shaders. Anti-aliasing 
is included as an integral part of the visibility calculations. Surfaces displayed include curved as 
well as polygonal surfaces. Key Words and Phrases: computer graphics, computer animation, visible surface 
algorithms, shading, raster displays CR Category: 8.2 Introduction Since its beginnings, shaded computer 
graphics has progressed toward greater realism. Even the earliest vis- ible surface algorithms included 
shaders that simulated such effects as specular reflection [19], shadows [1, 7], and transparency [18]. 
The importance of illumination models is most vividly demonstrated by the realism produced with newly 
developed techniques [2, 4, 5, 16, 20]. Permission to copy without fee all or part of this material is 
granted provided that the copies are not made or distributed for direct commercial advantage, the ACM 
copyright notice and the title of the publication and its date appear, and notice is given that copying 
is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires 
a fee and/or specific permission. Author's address: Bell Laboratories, Holmdel, NJ 07733. O 1980 ACM 
0001-0782/80/0600-0343 $00.75. The role of the illumination model is to determine how much light is 
reflected to the viewer from a visible point on a surface as a function of light source direction and 
strength, viewer position, surface orientation, and surface properties. The shading calculations can 
be per- formed on three scales: microscopic, local, and global. Although the exact nature of reflection 
from surfaces is best explained in terms of microscopic interactions be- tween light rays and the surface 
[3], most shaders produce excellent results using aggregate local surface data. Un- fortunately, these 
models are usually limited in scope, i.e., they look only at light source and surface orienta- tions, 
while ignoring the overall setting in which the surface is placed. The reason that shaders tend to operate 
on local data is that traditional visible surface algorithms cannot provide the necessary global data. 
A shading model is presented here that uses global information to calculate intensities. Then, to support 
this shader, extensions to a ray tracing visible surface algo- rithmare presented. 1. Conventional Models 
\ The simplest visible surface algorithms use shaders based on Lambert's cosine law. The intensity of 
the reflected light is proportional to the dot product of the surface normal and the light source direction, 
simulating a perfect diffuser and yielding a reasonable looking approximation to a dull, matte surface. 
A more sophis- ticated model is the one devised by Bui-Tuong Phong [8]. Intensity from Phong's model 
is given by j=ls j=ls I= Ia + kd Z (N.Lj) + ks ~ (N'L)) n, (1) j=l j=l where I= the reflected intensity, 
L= reflection due to ambient light, kd = diffuse reflection constant, unit surface normal, the vector 
in the direction of the jth light source, ks the specular reflection coefficient, the vector in the direction 
halfway between the viewer and thejth light source, n ~--an exponent that depends on the glossiness of 
the surface. Phong's model assumes that each light source is located at a point infinitely distant from 
the objects in the scene. The model does not account for objects within a scene acting as light sources 
or for light reflected from object to object. As noted in [6], this drawback does not affect the realism 
of diffuse reflection components very much, but it seriously hurts the quality of specular reflections. 
A method developed by Blinn and Newell [5] partially solves the problem by modeling an object's environment 
and mapping it onto a sphere of infinite radius. The technique yields some of the most realistic computer 
Communications June 1980 of Volume 23 the ACM Number 6 generated pictures ever made, but its limitations 
preclude its use in the general case. In addition to the specular reflection, the simulation of shadows 
is one of the more desirable features of an illumination model. A point on a surface lies in shadow if 
it is visible to the viewer but not visible to the light source. Some methods [2, 20] invoke the visible 
surface algorithm twice, once for the light source and once for the viewer. Others [1, 7, 12] use a simplified 
calculation to determine whether the point is visible to the light source. Transmission of light through 
transparent objects has been simulated in algorithms that paint surfaces in re- verse depth order [18]. 
When painting a transparent surface, the background is partially overwritten, allowing previously painted 
portions of the image to show through. While the technique has produced some im-pressive pictures, it 
does not simulate refraction. Kay [171 has improved on this approach with a technique that yields a very 
realistic approximation to the effects of refraction. 2. Improved Model A simple model for reflection 
of light from perfectly smooth surfaces is provided by classical ray optics. As shown in Figure 1, the 
light intensity, I, passed to the viewer from a point on the surface consists primarily of the specular 
reflection, S, and transmission, T, compo- nents. These intensities represent light propagated along 
the V, R, and /5 directions, respectively. Since surfaces displayed are not always perfectly glossy, 
a term must be added to model the diffuse component as well. Ideally the diffuse reflection should contain 
components due to reflection of nearby objects as well as predefined light sources, but the computation 
required to model a distrib- uted light source is overwhelming. Instead, the diffuse term from (1) is 
retained in the new model. Then the new model is j=ls I = la + ka (N.Lj) + ksS +ktT, (2)j=l where S 
= the intensity of light incident from the/~ direction, kt = the transmission coefficient, T = the intensity 
of light from the/5 direction. The coefficients ks and kt are held constant for the model used to make 
pictures in this report, but for the best accuracy they should be functions that incorporate an approximation 
of the Fresnel reflection law (i.e., the coefficients should vary as a function of incidence angle in 
a manner that depends on the material's surface properties). In addition, these coefficients must be 
care- fully chosen to correspond to physically reasonable val- ues if realistic pictures are to be generated. 
The /~ direction is determined by the simple rule that the angle 344 Fig. 1. I I S\ SURFACE Ir ! T of 
reflection must equal the angle of incidence. Similarly, the /5 direction of transmitted light must obey 
Snell's law. Then,/~ and/5 are functions of N and P" given by I7 I V'NI' ~q= ~' + 22q, /5 = kr(2q + Y') 
-~7, where kr = (k~l g' 12 -I V' + ~712)-1< and kn = the index of refraction. Since these equations assume 
that V- N is less than zero, the intersection processor must adjust the sign of N so that it points to 
the side of the surface from which the intersecting ray is incident. It must likewise adjust the index 
of refraction to account for the sign change. If the denominator of the expression for k r is imaginary, 
T is assumed to be zero because of total internal reflection. By making ks smaller and ka larger, the 
surface can be made to look less glossy. However, the simple model will not spread the specular term 
as Phong's model does by reducing the specular exponent n. As pointed out in [3], the specular reflection 
from a roughened surface is produced by microscopic mirrorlike facets. The intensity of the specular 
reflection is proportional to the number of these microscopic facets whose normal vector is aligned with 
the mean surface normal value at the region being sampled. To generate the proper looking specular reflection, 
a random perturbation is added to the surface normal to simulate the randomly oriented microfacets. Communications 
June 1980 of Volume 23 the ACM Number 6  Fig. 2. the scene before it reaches the light source, the point 
of T 2 intersection represented by the node lies in shadow with respect to that light source. That light 
source's contri- bution to the diffuse reflection from the point is then attenuated. After the tree is 
created, the shader traverses the tree,  T/~SURFACE 1 Fig. 3. I S 2 s S  (A similar normal perturbation 
technique is used by Blinn [4] to model texture on curved surfaces.) For a glossy surface, this perturbation 
has a small variance; with greater variances the surface will begin to look less glossy. This same perturbation 
will cause a transparent object to look progressively more frosted as the variance is increased. While 
providing a good model for micro- scopic surface roughness, this scheme relies on sampled surface normals 
and will show the effects of aliasing for larger variances. Since this scheme also requires entirely 
too much additional computing, it is avoided whenever possible. For instance, in the case of specular 
reflections caused directly by a point light source, Phong's model is used at the point of reflection 
instead of the perturbation scheme. The simple model approximates the reflection from a single surface. 
In a scene of even moderate complexity light will often be reflected from several surfaces before reaching 
the viewer. For one such case, shown in Figure 2, the components of the light reaching the viewer from 
point A are represented by the tree in Figure 3. Creating this tree requires calculating the point of 
intersection of each component ray with the surfaces in the scene. The calculations require that the 
visible surface algorithm (described in the next section) be called recursively until all branches of 
the tree are terminated. For the case of surfaces aligned in such a way that a branch of the tree has 
infinite depth, the branch is truncated at the point where it exceeds the allotted storage. Degradation 
of the image from this truncation is not noticeable. In addition to rays in the /~ and /5 direction, 
rays corresponding to the j terms in (2) are associated with each node. If one of these rays intersects 
some surface in applying eq. (2) at each node to calculate intensity. The intensity at each node is then 
attenuated by a linear function of the distance between intersection points on the ray represented by 
the node's parent before it is used as an input to the intensity calculation of the parent. (Since one 
cannot always assume that all the surfaces are planar and all the light sources are point sources, square- 
law attenuation is not always appropriate. Instead of modeling each unique situation, linear attenuation 
with distance is used as an approximation.) 3. Visible Surface Processor Since illumination returned 
to the viewer is deter- mined by a tree of "rays," a ray tracing algorithm is ideally suited to this 
model. In an obvious approach to ray tracing, light rays emanating from a source are traced through their 
paths until they strike the viewer. Since only a few will reach the viewer, this approach is waste- ful. 
In a second approach suggested by Appel [1] and used successfully by MAGI [14], rays are traced in the 
opposite direction--from the viewer to the objects in the scene, as illustrated in Figure 4. Unlike previous 
ray tracing algorithms, the visibility calculations do not end when the nearest intersection of a ray 
with objects in the scene is found. Instead, each visible intersection of a ray with a surface produces 
more rays in the /~ direction, the /5 direction, and in the direction of each light source. The intersection 
process is repeated for each ray until none of the new rays intersects any object. Because of the nature 
of the illumination model, some traditional notions must be discarded. Since objects may be visible to 
the viewer through reflections in other objects, even though some other object lies between it and the 
viewer, the measure of visible complexity in an image is larger than for a conventionally generated image 
of the same scene. For the same reason, clipping and eliminating backfacing surface elements are not 
appli- cable with this algorithm. Because these normal prepro- cessor stages that simplify most visible 
surface algorithms cannot be used, a different approach is taken. Using a technique similar to one described 
by Clark [11], the object description includes a bounding volume for each item in the scene. If a ray 
does not intersect the bounding volume of an object, then the object can be eliminated from further processing 
for that ray. For simplicity of representation and ease of performing the intersection calculation, spheres 
are used as the bounding volumes. Communications June 1980 of Volume 23 the ACM Number 6  Since a sphere 
can serve as its own bounding volume, initial experiments with the shading processor used spheres as 
test objects. For nonspherical objects, addi- tional intersection processors must be specified whenever 
a ray does intersect the bounding sphere for that object. For polygonal surfaces the algorithm solves 
for the point of intersection of the ray and the plane of the polygon and then checks to see if the point 
is on the interior of the polygon. If the surface consists of bicubic patches, bounding spheres are generated 
for each patch. If the bounding sphere is pierced by the ray, then the patch is subdivided using a method 
described by Catmull and Clark [10], and bounding spheres are produced for each subpatch. The subdivision 
process is repeated until either no bounding spheres are intersected (i.e., the patch is not intersected 
by the ray) or the intersected bounding sphere is smaller than a predetermined minimum. This scheme was 
selected for simplicity rather than efficiency. The visible surface algorithm also contains the mech- 
anism to perform anti-aliasing. Since aliasing is the result of undersampling during the display process, 
the most straightforward cure is to low-pass filter the entire image before sampling for display [13]. 
A considerable amount of computing can be saved, however, if a more econom- ical approach is taken. Aliasing 
in computer generated images is most apparent to the viewer in three cases: (1) at regions of abrupt 
change in intensity such as the silhouette of a surface, (2) at locations where small objects fall between 
sampling points and disappear, and (3) whenever a sampled function (such as texture) is mapped onto the 
surface. The visible surface algorithm looks for these cases and performs the filtering function only 
in these regions. For this visible surface algorithm a pixel is defined in the manner described in [9] 
as the rectangular region whose corners are four sample points as shown in Figure 5(a). If the intensities 
calculated at the four points have nearly equal values and no small object lies in the region between 
them, the algorithm assumes that the average of the four values is a good approximation of the intensity 
over the entire region. If the intensity values are not nearly equal (Figure 5(b)), the algorithm subdi- 
vides the sample square and starts over again. This process runs recursively until the computer runs 
out of resolution or until an adequate amount of information about the detail within the sample square 
is recovered. The contribution of each single subregion is weighted by its area, and all such weighted 
intensities are summed to determine the intensity of the pixel. This approach amounts to performing a 
Warnock-type visibility process for each pixel [19]. In the limit it is equivalent to area sampling, 
yet it remains a point sampling technique. A better method, currently being investigated, considers volumes 
defined by each set of four corner rays and applies a containment test for each volume. To ensure that 
small objects are not lost, a minimum radius (based on distance from the viewer) is allowed for bounding 
spheres of objects. This minimum is chosen so Fig. 4. Fig. 4. OBJECT _ FOCAL POINT Fig. 5. SAMPLE 0 
(a) ,f 0 (b) that no matter how small the object, its bounding sphere will always be intersected by at 
least one ray. If a ray passes within a minimum radius of a bounding sphere but does not intersect the 
object, the algorithm will know to subdivide each of the four sample squares that share the ray until 
the missing object is found. Although Communications June 1980 of Volume 23 the ACM Number 6  adequate 
for rays that reach the viewer directly, this scheme will not always work for rays being reflected from 
curved surfaces. 4. Results A version of this algorithm has been programmed in C, running under UNIX 
~on both a PDP-11/45 and a VAX-11/780. To simplify the programming, all calcu- lations are performed 
in floating point (at a considerable speed penalty). The pictures are displayed at a resolution of 480 
by 640 pixels with 9 bits per pixel. Originally color pictures were photographed from the screen of a 
color CRT so that only three bits were available for each of the three primary colors. Ordered dither 
[15] was applied to the image data to produce 111 effective intensity levels per primary. For this report 
pictures are produced by a high-quality color hardcopy camera that exposes each color separately to provide 
eight bits of intensity per color. For the scenes shown in this paper, the image gen- eration times are 
Figure 6: 44 minutes, Figure 7: 74 minutes, Figure 8:122 minutes. All times given are for the VAX, which 
is nearly three times faster than the PDP-11/45 for this application. The image of Figure 6 shows three 
glossy objects with shadows and object-to-object reflections. The texturing is added using Blinn's wrinkling 
technique. Figure 7 illustrates the effect of refraction through a transparent object. The algorithm 
has also been used to produce a short animated sequence. The enhancements provided by this illumination 
model are more readily apparent in the animated sequence than in the still photographs. A breakdown of 
where the program spends its time for simple scenes is: Overhead-- 13 percent, Intersection--75 percent, 
Shading-- 12 percent. For more complex scenes the percentage of time required to compute the intersections 
of rays and surfaces in- creases to over 95 percent. Since the program makes almost no use of image coherence, 
these figures are actually quite promising. They indicate that a more efficient intersection processor 
will greatly improve the algorithm's performance. This distribution of processing times also suggests 
that a reasonable division of tasks between processors in a multiprocessor system is to have one or more 
processors dedicated to intersection calcu- lations with ray generation and shading operations per- formed 
by the host. J UNIX is a trademark of Bell Laboratories.  5. Summary This illumination model draws heavily 
on techniques derived previously by Phong [8] and Blinn [3-5], but it operates recursively to allow the 
use of global illumina- tion information. The approach used and the results achieved are similar to those 
presented by Kay [16]. While in many cases the model generates very real- istic effects, it leaves considerable 
room for improvement. Specifically, it does not provide for diffuse reflection from distributed light 
sources, nor does it gracefully handle specular reflections from less glossy surfaces. It is implemented 
through a visible surface algorithm that is very slow but which shows some promise of becoming more efficient. 
When better ways of using picture coher- ence to speed the display process are found, this algo- rithm 
may find use in the generation of realistic animated sequences. Received 12/78; revised 1/80; accepted 
2/80 References l. Appel, A. Some techniques for shading machine renderings of solids. AFIPS 1968 Spring 
Joint Comptr. Conf., pp. 37~15. 2. Atherton, P., Weiler, K., and Greenberg, D. Polygon shadow generation. 
Proc. S1GGRAPH 1978, Atlanta, Ga., pp. 275-281.  3. Blinn, J.F. Models of light reflection for computer 
synthesized pictures. Proc. SIGGRAPH 1977, San Jose, Calif., pp. 192-198.  4. Blinn, J.F. Simulation 
of wrinkled surfaces. Proc. SIGGRAPH 1978, Atlanta, Ga., pp. 286-292.  5. Blinn, J.F., and Newell, M.E. 
Texture and reflection in computer generated images. Comm. ACM 19, 10 (Oct. 1976), 542-547. 6. Blinn, 
J.F., and Newell, M.E. The progression of realism in computer generated images. Proc. of the ACM Ann. 
Conf., 1977, pp. 444~.48. 7. Bouknight, W.K., and Kelley, K.C. An algorithm for producing half-tone 
computer graphics presentations with shadows and movable light sources. AFIPS 1970 Spring Joint Comptr. 
Conf., pp. 1-10. 8. Bui-Tuong Phong. Illumination for computer generated images. Comm. ACM 18, 6 (June 
1975), 311-317. 9. Catmull, E. A subdivision algorithm for computer display of curved surfaces. UTEC 
CSc-74-133, Comptr. Sci. Dept., Univ. of Utah, 1974.  10. Catmull, E., and Clark, J. Recursively generated 
B-spline surfaces on arbitrary topological meshes. Comptr. Aided Design 10, 6 (Nov. 1978), 350-355. 
11. Clark, J.H. Hierarchical geometric models for visible surface algorithms. Comm. ACM 19, 10 (Oct. 
1976), 547-554.  12. Crow, F.C. Shadow algorithms for computer graphics. Proc. SIGGRAPH 1977, San Jose, 
Calif., pp. 242-248.  13. Crow, F.C. The aliasing problem in computer-generated shaded images. Comm. 
ACM 20, 11 (Nov. 1977), 799-805. 14. Goldstein, R.A. and Nagel, R. 3-D visual simulation. Simulation 
(Jan. 1971), 25-31. 15. Jarvis, J.F., Judice, C.N., and Ninke, W.H. A survey of techniques for the display 
of continuous tone pictures on bilevel displays. Comptr. Graphics and Image Proc. 5 (1976), 13M0.  16. 
Kay, D.S. Transparency, refraction, and ray tracing for computer synthesized images. Masters thesis, 
Cornell Univ., Ithaca, N.Y., January 1979. 17. Kay, D.S., and Greenberg, D. Transparency for computer 
synthesized images. Proc. SIGGRAPH 1979, Chicago, Ill., pp. 158-  164. 18. Newell, M.E., Newell, R.G., 
and Sancha, T.L. A solution to the hidden surface problem. Proc. ACM Ann. Conf., 1972, pp. 443M50. 19. 
Warnock, J.E. A hidden line algorithm for halftone picture representation. Tech. Rep. TR 4-15, Comptr. 
Sci. Dept., Univ. of Utah, 1969.  20. Williams, L. Casting curved shadows on curved surfaces. Proc. 
SIGGRAPH 1978, Atlanta, Ga., pp. 270-274.  Communications June 1980 of Volume 23 the ACM Number 6  
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198744</article_id>
		<sort_key>5</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[The RTRT core]]></title>
		<page_from>5</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198744</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198744</url>
		<abstract>
			<par><![CDATA[The overall design decisions of the RTRT/OpenRT framework are described in detail in [Wald04]. To summarize the most important points, we have chosen to only support triangles, to exploit SIMD extensions in a data-parallel way, to optimize for memory and caches, and to use BSP trees as an acceleration structure. In this chapter, we are now going to discuss the actual algorithms and implementation of these topics in more detail.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40031452</person_id>
				<author_profile_id><![CDATA[81100041422]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ingo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wald]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Saarland University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{AMD} Advanced Micro Devices. Software Optimization Guide for AMD Athlon(tm) 64 and AMD Opteron(tm) Processors. Available from http://www.amd.com/us-en/Processors/TechnicalResources/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>90867</ref_obj_id>
				<ref_obj_pid>90767</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{Badouel92} Didier Badouel. An Efficient Ray Polygon Intersection. In David Kirk, editor, Graphics Gems III, pages 390--393. Academic Press, 1992. ISBN: 0124096735.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{Carey97} Rikk Carey, Gavin Bell, and Chris Marrin. ISO/IEC 14772-1:1997 Virtual Reality Modelling Language (VRML97), April 1997. http://www.vrml.org/Specifications/VRML97.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{Erickson97} Jeff Erickson. Pluecker Coordinates. Ray Tracing News, 1997. http://www.acm.org/tog/resources/RTNews/html/-rtnv10n3.html#art11.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>94788</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{Glassner89} Andrew Glassner. An Introduction to Ray Tracing. Morgan Kaufmann, 1989. ISBN 0-12286-160-4.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>31469</ref_obj_id>
				<ref_obj_pid>31468</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{Goldsmith87} Jeffrey Goldsmith and John Salmon. Automatic Creation of Object Hierarchies for Ray Tracing. IEEE Computer Graphics and Applications, 7(5):14--20, May 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{Haines91} Eric Haines. Efficiency Improvements for Hierarchy Traversal in Ray Tracing. In James Arvo, editor, Graphics Gems II, pages 267--272. Academic Press, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{Havran97} Vlastimil Havran. Cache Sensitive Representation for the BSP Tree. In Compugraphics '97, pages 369--376. GRASP - Graphics Science Promotions & Publications, December 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{Havran99} Vlastimil Havran. Analysis of Cache Sensitive Representation for Binary Space Partitioning Trees. Informatica, 23(3):203--210, May 1999. ISSN: 0350-5596.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{Havran00} Vlastimil Havran, Jan Prikryl, and Werner Purgathofer. Statistical Comparison of Ray-Shooting Efficiency Schemes. Technical Report TR-186-2-00-14, Department of Computer Science, Czech Technical University; Vienna University of Technology, July 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{Havran01} Vlastimil Havran. Heuristic Ray Shooting Algorithms. PhD thesis, Faculty of Electrical Engineering, Czech Technical University in Prague, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{Hurley02} James T. Hurley, Alexander Kapustin, Alexander Reshetov, and Alexei Soupikov. Fast Ray Tracing for Modern General Purpose CPU. In Proceedings of Graphicon, 2002. Available from http://www.graphicon.ru/2002/papers.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{Intel} Intel Corp. Intel Computer Based Tutorial. http://developer.intel.com/vtune/cbts/cbts.htm.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{Keller98} Alexander Keller. Quasi-Monte Carlo Methods for Realistic Image Synthesis. PhD thesis, University of Kaiserslautern, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{MacDonald89} J. David MacDonald and Kellogg S. Booth. Heuristics for Ray Tracing using Space Subdivision. In Proceedings of Graphics Interface '89, pages 152--63, Toronto, Ontario, June 1989. Canadian Information Processing Society.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>87856</ref_obj_id>
				<ref_obj_pid>87851</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{MacDonald90} J. David MacDonald and Kellogg S. Booth. Heuristics for Ray Tracing using Space Subdivision. Visual Computer, 6(6):153--65, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[{M&#246;ller} Tomas M&#246;ller. Practical Analysis of Optimized Ray-Triangle Intersection. http://www.ce.chalmers.se/staff/-tomasm/raytri/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>272315</ref_obj_id>
				<ref_obj_pid>272313</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[{M&#246;ller97} Tomas M&#246;ller and Ben Trumbore. Fast, minimum storage ray triangle intersection. Journal of Graphics Tools, 2(1):21--28, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258791</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[{Pharr97} Matt Pharr, Craig Kolb, Reid Gershbein, and Pat Hanrahan. Rendering Complex Scenes with Memory-Coherent Ray Tracing. Computer Graphics, 31(Annual Conference Series):101--108, August 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>940410</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[{Shirley03} Peter Shirley and R. Keith Morley. Realistic Ray Tracing. A K Peters, Second edition, 2003. ISBN 1-56881-198-5.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[{Shoemake98} Ken Shoemake. Pluecker Coordinate Tutorial. Ray Tracing News, 1998. http://www.acm.org/tog/resources/RTNews/html/rtnv11n1.html#art3.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[{Subramanian90} K. R. Subramanian. A Search Structure based on K-d Trees for Efficient Ray Tracing. PhD thesis, The University of Texas at Austin, December 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[{Wald01} Ingo Wald, Philipp Slusallek, Carsten Benthin, and Markus Wagner. Interactive Rendering with Coherent Ray Tracing. Computer Graphics Forum, 20(3):153--164, 2001. (Proceedings of Eurographics).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[{Wald03} Ingo Wald, Timothy J. Purcell, J&#246;rg Schmittler, Carsten Benthin, and Philipp Slusallek. Realtime Ray Tracing and its use for Interactive Global Illumination. In Eurographics State of the Art Reports, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[{Wald04} Ingo Wald. Realtime Ray Tracing and Interactive Global Illumination. PhD thesis, Computer Graphics Group, Saarland University, 2004. Available at http://www.mpi-sb.mpg.de/~wald/PhD/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073211</ref_obj_id>
				<ref_obj_pid>1186822</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[{Woop05} Sven Woop, Joerg Schmittler, and Philipp Slusallek. RPU: A Programmable Ray Processing Unit for Realtime Ray Tracing. Proceedings of ACM SIGGRAPH, (to appear), 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Siggraph 2005 Course on Interactive Ray Tracing The RTRT Core Ingo Wald This is an excerpt from Realtime 
Ray Tracing and Interactive Global Illumination , PhD Thesis, Ingo Wald, Computer Graphics Group, Saarland 
University. Full Version available at http://www.mpi-sb.mpg.de/~wald/PhD Some argue that in the very 
long term, rendering may best be solved by some variant of ray tracing, in which huge numbers of rays 
sample the environment for the eye s view of each frame. And there will also be colonies on Mars, underwater 
cities, and personal jet packs. Tomas Moller and Eric Haines, Real-Time Rendering , 1st edition (page 
391) The overall design decisions of the RTRT/OpenRT framework are described in detail in [Wald04]. To 
summarize the most important points, we have chosen to only support triangles, to exploit SIMD extensions 
in a data-parallel way, to optimize for memory and caches, and to use BSP trees as an acceleration structure. 
In this chapter, we are now going to discuss the actual algorithms and implementation of these topics 
in more detail. Fast Triangle Intersection in RTRT Fast ray triangle intersection code has long been 
an active .eld of research in computer graphics and has lead to a large variety of algorithms, e.g. Moeller-Trumbore 
[Moller97, Moller], Glassner [Glassner89], Badouel [Badouel92], Pluecker [Erickson97, Shoemake98], 
and many others. The RTRT core uses a modi.ed version of the projection method (see below), which has 
been specially designed to run as fast as possible with single-ray C code, while still being well suited 
for SSE code. Essentially, the task of computing a ray-triangle intersection can be described as follows: 
Given a ray R(t)= O + tD; t . (0,tmax)1 (going from its origin O into direction D), and a triangle with 
vertices A, B and C, determine whether 1In practice, rays usually start at tmin = . in order to avoid 
self-intersection . 1 the ray has a valid hit-point H = R(thit) with the triangle, i.e. whether there 
exists a thit with tmin = thit = tmax and R(thit) is inside the triangle. In case of having found a valid 
hit point, many ray tracers require that the ray-triangle intersection routine also returns the barycentric 
coordinates (or local surface coordinates) of the hit-point for shading purposes. As these coordinates 
are often computed anyway in the process of determining the hitpoint, we follow this pattern. Note, 
however, that this is not the case for shadow rays, for which only the boolean yes/no decision is important, 
and which can be slightly optimized by not storing these coordinates. 1.1 Barycentric Coordinate Tests 
While there are many di.erent methods for computing ray-triangle intersections, many of them are based 
on computing the barycentric coordinates of the hitpoint and using those for determining whether there 
is a valid intersection or not2 (e.g. [Badouel92, Shirley03, Glassner89]). In fact, most ray-triangle 
intersection algorithms (including the one proposed here) follow this general pattern, and are often 
only variants and di.erent implementations of the same idea. In order to use barycentric coordinates 
for computing ray triangle intersections, one .st computes the signed distance tplane along the ray 
to the plane embedding the triangle. Given the geometric normal N =(B - A)  (C - A) = -(O-A).N and a 
triangle vertex A, this can be computed as tplane . The cal- D.N culated distance tplane is then tested 
for whether it lies in the interval in which the ray is actually looking for intersections. If not, no 
valid intersection can occur, and the triangle test returns no intersection . The triangle normal N is 
often computed on the .y . This minimizes storage requirements, but requires a costly vector product. 
If this so-called distance test has been passed, one has to check whether the ray actually pierces the 
triangle. To do this, the actual intersection point with the plane is computed as H = R(tplane)= O + 
tplaneD, and is then tested whether it actually lies inside the triangle. The barycentric coordinates 
of H can then be computed in several ways, e.g. by solving the system of equations H = aA+B +.C, or 
geometrically by considering the relative signed (!) areas of the triangles ABC, HBC, AHC and ABH. Once 
the barycentric coordinates a,  and . of H are known, one can determine whether H is inside the triangle 
by and checking whether the conditions 0 = a = 1, 0 =  = 1, 0 = . = 1 are ful.lled. Note that it is 
su.cient to check whether  = 0, . = 0 and  +. = 1, which follows from the properties of barycentric 
coordinates (a +  + . = 1). 2The barycentric coordinates of H are the values a,  and . for which aA 
+ B + .C = H, a +  + . = 1. If H is inside the triangle, both a, and . are positive. 1.2 Projection 
Method The projection method is an optimization of the barycentric coordinate test. It exploits the fact 
that projecting both triangle ABC and hit-point H into any other plane (except for the planes that are 
orthogonal to the plane ABC) does not change the barycentric coordinates of H. The computations for calculating 
the barycentric coordinates can then be optimized by projecting both triangle and hit-point H into one 
of the 2D coordinate planes (XY-, XZ-or YZ-plane), in which all further computations can be performed 
in 2D. For reasons of numerical stability, one should project into the plane in which the triangle has 
maximum projected area. This so-called projection dimension corresponds to the dimension in which the 
normal N has its maximum absolute component. After projection, all computations can be performed more 
e.ciently in 2D. For example, projecting into the XY plane (i.e. projection dimension is Z ) yields HI 
= aAI + BI + .CI, where AI,BI,CI and HI are the projected points of A, B, C, and H, respectively. Substituting 
a =1 -  - . and rearranging the terms yields (BI - AI)+ .(CI - AI)= HI - AI. det |bh| This can be solved 
(e.g. using the Horner scheme), yielding  = ,. = det |bc|det |hc| det |bc| , (where b = CI - AI, c = 
BI - AI and h = HI - AI). In 2D, this can be expressed quite e.ciently as bxhy - byhx hxcy - hycx  = 
,. = . (1) bxcy - bycx bxcy - bycx In pseudo-code, the projection method usually looks like the following: 
// calc edges and normal b = C-A; c = B-A; N = Cross(c,b); // distance test t_plane = -Dot((O-A),N) 
/ Dot(D,N); if (t_plane < Epsilon || t_plane > t_max) return NO_HIT; // determine projection dimensiondimensions 
if (|N.x| > |N.y|) if (|N.x| > |N.z|) k = 0; /* X */ else k=2; /* Z */ else if (|N.y| > |N.z|) k = 1; 
/* Y */ else k=2; /* Z */ u = (k+1) mod 3; v = (k+2) mod 3; // calc hitpoint H[u] = O[u] + t_plane * 
D[u]; H[v] = O[v] + t_plane * D[v]; beta = (b[u] * H[v] -b[v] * H[u]) / (b[u] * c[v] -b[v] * c[u]); 
if (beta < 0) return NO_HIT; gamma = (c[v] * H[u] -c[u] * H[v]) / (b[u] * c[v] -b[v] * c[u]); if (gamma 
< 0) return NO_HIT; if (beta+gamma > 1) return NO_HIT; return HIT(t_plane,beta,gamma); 1.3 Optimizing 
the Projection Method Taking a closer look at the execution pattern of the above mentioned projection 
method, it becomes obvious that for di.erent executions on the same triangle many values will be recomputed 
every time: For example, the edges and normal of a triangle will be recomputed for every intersection 
test with this triangle, and also the result of determining the projection case will always remain the 
same. These -and other -computations are thus redundant, and can be saved by precomputing and storing 
them. This saves the costly computations for the normal, and enables to avoid the branches for determining 
the projection case. Once the normal is known, the two secondary dimensions (u =(k + 1)mod 3 and v =(k+2)mod 
3) can then be determined by a simple table lookup (intmodulo[5] = {0, 1, 2, 0, 1}), without having to 
perform the two expensive modulo operations. Note that we do not have to store the full normal: If k 
is the projection dimension, N.k can never be zero. As such, we can divide the normal N by N.k, (A-O).N. 
A.N.-Ou.N. -Ov.N. -Ok.N. N uvk yielding NI = N.k . Then t == Du.N. -Dk.N. . D.N. +DvObviously .N. Nv 
uvk the values d = A.NI , NI = Nu and NI = are constant for each triangle and uNk vNk thus can be precomputed. 
By de.nition, NI is equal to one, and thus doesn t k have to be stored. Furthermore, knowing that NI 
= 1 saves two additional k multiplications. The same idea simplifying the computations and precomputing 
as many of the terms as possible can also be applied to the edges: Rearranging the terms for computing 
 and . yields 1  =(bxHy - bxAy - byHx + byAx)bxcy - bycx bx -by byAx - bxAy = Hy + Hx + bxcy - bycx 
bxcy - bycx bxcy - bycx = KyHy + KxHx + Kd. This equation now depends only on the projected coordinates 
Hx and Hy of the hit-point H (which can be calculated entirely from NI , O and D). After precomputing 
and storing the constants Ky, Kx, and K,d,  = Kb,nuHx + 3 Kb,nvHy + Kb,d can be computed quite e.ciently. 
Note that no other values have to be stored for computing . Obviously, the same procedure works for 
the second barycentric coordinate, .. The last one, a then does not require any further storage space, 
as a =1 -  - .. With these simpli.cations and precomputations, only very few operations have to be performed 
during runtime. In the worst case4, only 10 multiplies, 1 division, and 11 additions are needed for an 
intersection. If the ray fails already at the distance test, only 4 muls, 5 adds, and 1 division are 
needed. Neither geometric normal nor the edge vectors have to be stored or computed during intersection. 
 1.4 Cache-optimized Data Layout Obviously, preprocessing can save quite some amount of computations. 
However, as mentioned above this has to be done quite carefully: Due to the high cost of a cache miss, 
using additional memory for storing precomputed values carries the chance of actually costing more than 
the operation itself. On the other hand, careful data layout can even simplify the memory access patterns, 
and can help in prefetching and in reducing cache misses. Using the just mentioned simpli.cations, all 
data needed for a triangle intersection can be expressed in only 10 values: 3 .oats (d, N I ,N I ) for 
the scaled plane equation, 3 .oats each uv for the two 2D line equations in the u/v plane, and one int 
(actually only 2 bits) for storing the projection case k. Note that these 10 values comprise all the 
data required for the triangle test. In fact, with these precomputed values it is not even necessary 
any more to know the actual vertex positions of the triangle. Though these are still stored somewhere 
for potential shading purposes (resulting in an actual increase in total memory consumption), they do 
not have to be accessed at all during traversal and intersection. Since we know the access pattern of 
the intersection algorithm, we can even store the 10 values in the order in which they are accessed by 
the CPU to enable even better data access for the CPU. This leads to a very simple data layout for our 
triangle acceleration structure: struct TriAccel { // first 16 byte half cache line // plane: float n_u; 
//!< == normal.u / normal.k float n_v; //!< == normal.v / normal.k 3It is interesting to note that the 
same three values can also be derived and explained geometrically. In that case, Kb,nu,Kb,nv and Kb,d 
correspond to the line equation Lb(u, v)= Kb,nu.u + Kb,nv.v + Kb,d = 1 of side b = C' - A' (hence the 
name of the constants), properly scaled such that inserting the third vertex B' into the line equation 
yields Lb(B',B') = 0. xy 4Note that with a good BSP tree, this worst-case cost (a valid intersection) 
happens quite frequently, as a good BSP tree already avoids most unsuccessful intersection operations, 
see Table 5. Figure 1: The RTRT core organizes its geometry in the typical Vertex Array organization 
(also called Indexed Face Sets in VRML97 terms [Carey97]): Vertices are stored in arrays from where they 
are referenced by triangles. Each triangle is described by pointers (or IDs in our case) to its three 
vertices, plus an ID for specifying its shader. The di.erent vertex attributes (e.g. position, normal, 
texture coordinates etc) are stored in separate lists, thereby allowing to store only those data that 
have actually be speci.ed by the application. Additionally to this typical data layout, the RTRT core 
keeps a separate acceleration record for each triangle that stores all data required for an intersection 
in a preprocessed form. Thus, neither ID record nor vertex data is ever touched during traversal and 
intersection. Whereas typical intersection algorithm require to fetch data from four di.erent, non-cache-aligned 
memory locations (thereby having to chase the pointers in the ID record), RTRT fetches only this single 
acceleration data, which lends well to caching and prefetching. float n_d; //!< constant of plane equation 
int k; // projection dimension // second 16 byte half cache line // line equation for line ac float b_nu; 
float b_nv; float b_d; int pad; // pad to next cache line // third 16 byte half cache line // line equation 
for line ab float c_nu; float c_nv; float c_d; int pad; // pad to 48 bytes for cache alignment purposes 
}; Though this data layout actually uses more memory than other intersection algorithms operating directly 
on the vertices (like e.g. Moeller-Trumbore [Moller97]), it is likely to use the cache better (see Figure 
1): Operating directly on the vertices requires to .rst access a record that contains the vertex IDs, 
which require to access at least one cache line. Then accessing the vertices themselves again requires 
to touch three cache lines, except if the vertices are incidentally stored next to each other. If the 
index record and/or the vertices straddle cache line boundaries, another four cache lines might be required. 
In contrast to these up to 8 cache lines, the above structure can be guaranteed to use exactly two cache 
lines on 32 byte caches, and often only one cache access for 64 byte or 128 byte caches5 . Furthermore, 
having all data for the intersection test in one contiguous block also allows for e.cient prefetching. 
Having reached a leaf, prefetching the next triangle before intersecting the current one can guarantee 
that the next triangle is already in the cache until needed. Finally, having all required data values 
stored sequentially one after another ideally lends to a streaming-like SIMD implementation. However, 
the additional memory overhead can be problematic for extremely complex scenes for which both main memory 
and address space become quite a limiting factor. For these special cases, the RTRT kernel also contains 
an e.cient implementation of the Moeller-Trumbore algorithm [Moller97] (in both a single-ray C-code 
as well as in an SSE implementation), which can be used for these cases. 1.5 C Code Implementation for 
Single-Ray/Triangle Intersection Writing the code for the just derived intersection algorithm is straightforward, 
and can be expressed in only a few lines of code: // lookup table for the modulo operation ALIGN(ALIGN_CACHELINE) 
static const unsigned int modulo[] = {0,1,2,0,1}; inline void Intersect(TriAccel &#38;acc,Ray &#38;ray, 
Hit &#38;hit) { #define ku modulo[acc.k+1] #define ku modulo[acc.k+2] // don t prefetch here, assume 
data has already been prefetched // start high-latency division as early as possible const float nd = 
1./(ray.dir[acc.k] + acc.n_u * ray.dir[ku] + acc.n_v * ray.dir[kv]); const float f = (acc.n_d -ray.org[acc.k] 
-acc.n_u * ray.org[ku] -acc.n_v * ray.org[kv]) * nd; // check for valid distance. if (!(hit.dist > f 
&#38;&#38; f > EPSILON )) return; // compute hitpoint positions on uv plane const float hu = (ray.org[ku] 
+ f * ray.dir[ku]); 5Intel Pentium-III processors have 32 byte cache lines, whereas AMD Athlon-MPs have 
64 bytes, and Intel Pentium IV Xeons have 128 bytes per cache line. const float hv = (ray.org[kv] + f 
* ray.dir[kv]); // check first barycentric coordinate const float lambda = (hu * acc.b_nu + hv * acc.b_nv 
+ acc.b_d); if (lambda < 0.0f) return; // check second barycentric coordinate const float mue = (hu 
* acc.c_nu + hv * acc.c_nv + acc.c_d); if (mue < 0.0f) return; // check third barycentric coordinate 
if (lambda+mue > 1.0f) return; // have a valid hitpoint here. store it. hit.dist = f; hit.tri = triNum; 
hit.u = lambda; hit.v = mue; } Note that the costly modulo 3 operation has been replaced with a precomputed 
lookup table. The most costly operation in this triangle test is the division at the beginning, which 
in SSE code can be replaced by a faster reciprocal operation with Newton-Raphson iteration (see e.g. 
[Intel, AMD]). Also note that the actual implementation uses a C code macro for the intersection code, 
which (surprisingly) is even faster than an inline function as shown above. Instead of the many memory 
indirections into the origin and direction vectors it is also possible to do a switch-case statement 
based on acc.k at the beginning, and then use hard-coded o.set values. The speed di.erence between these 
two implementations is small. Depending on the actual CPU used (i.e. Athlon vs. Pentium-III vs. Pentium-IV), 
sometimes one versions is faster, and sometimes the other. 1.5.1 Single-Ray Intersection Performance 
The performance of this optimized implementation is given in Table 1, in which the single-ray C Code 
version of this triangle test is compared to a fairly optimized implementation of the standard Moeller-Trumbore 
triangle test [Moller97]. As can be seen, our proposed triangle test in practice is roughly twice as 
fast as the Moeller-Trumbore code.  1.6 SSE Implementation By design, the chosen algorithm and data 
layout naturally lend to SSE implementation. In fact, for our SSE triangle intersection we use exactly 
the same code and data structures as described above in the previous Section. The only major change is 
that instead of a single ray, we use a structure that stores four rays together in a SIMD-friendly way 
(see Figure 2): Opposed to the standard Table 1: Performance for the RTRT optimized projection (OP) triangle 
test algorithm as compared to the Moeller-Trumbore algorithm (MT) [Moller97], measured in CPU cycles 
on a single 2.5 GHz Pentium-IV notebook. The RTRT code is measured with the single ray C code implementation, 
not with the fast SIMD code described in Section 1.6. Note that these measurements have not been taken 
with synthetical ray distributions, but correspond to average case performance in typical scenes. The 
actual cost depends on the probability with which a ray exits at a certain test (e.g. distance test, 
any of the barycentric coordinate tests, or successful intersection) and as such varies from one scene 
to another, and also di.ers for shadow and standard rays (i.e. primary and secondary rays). For the RTRT 
OP triangle test, these numbers correspond to more than 35 million ray-triangle intersections. Also note 
that a 2.5GHz notebook CPU is not state of the art any more. CPU Cycles MT OP speedup primary rays 144 
172 69 74 2.1 2.3 shadow rays 127 144 68 73 1.9 2.0 way of storing such four rays as an array of four 
ray structures (the AoS organization), accessing such values e.ciently with SSE requires to reorganize 
such data into a SoA (structure of arrays) organization, i.e. .rst storing the four origin.x values, 
then the four origin.y values, etc. Using SSE intrinsics, implementing the above algorithm in SSE is 
almost straightforward. For example, the line const float hu = (ray.org[ku] + f * ray.dir[ku]); can easily 
be expressed as const sse_t hu = _mm_add_ps(ray4.org[ku], _mm_mul_ps(f,ray4.dir[ku])). Though converting 
the whole algorithm in that way is quite simple, the actual code is quite lengthy due to the low-level 
nature of the SSE operations, and as such is omitted here. 1.6.1 Overhead A potential source of overhead 
is that even though some rays may have terminated early, all four rays have to be intersected with a 
triangle. For coherent rays however this is unlikely. However, not all rays may have found a valid hit, 
so the hit information may only be updated for rays that actually found an intersection. To achieve this, 
information on which of the four rays is still active is kept in a bit-.eld, which can be used to mask 
out invalid rays in a conditional move instruction when storing the hit point information. Though this 
is simple to implement, it results in a considerable overhead, see Table 2: Whereas both shadow rays 
and standard rays undergo exactly the Figure 2: Array-of-structures (AoS) vs. structure-of-arrays (SoA) 
layout for our ray packets. Each ray consists of origin (R) and direction (D) vectors, as well as its 
maximum length (t). The same data layout has to be used for the hit point information. While the AoS 
layout is more natural, e.cient SIMD code requires the reorganization to the SIMD-friendly SoA layout. 
In order to achieve su.cient performance, this layout has to be used during all computations, i.e. already 
during ray generation. same .oating point computations until the hit/no hit information has been determined, 
standard rays require several masking operations in order to update the hit information only for those 
rays that have actually had a valid intersection. Shadow rays have to perform signi.cantly less of these 
masking operations, as only a single .ag has to be stored per ray, in contrast to triangle and instance 
ID, distance, and barycentric coordinates for normal rays. CPU Cycles C Code SSE 4:1 SSE 4:1 speedup 
rays per single ray per packet per ray second primary rays 69 74 101 107 25 27 2.70 2.76 92M 100M shadow 
rays 68 73 80 93 20 23 3.17 3.4 108M 125M Table 2: Cost (in CPU cycles) for our optimized ray-triangle 
test in a single ray C code implementation and in its data parallel 4:1 SSE implementation. As in Table 
1, these numbers correspond to average-case performance in typical scenes. On a 2.5 GHz Pentium IV CPU, 
20 27 cycles correspond to 108 125 million ray-triangle intersections per second. Note that the speedup 
is only calculated with respect to the single-ray C code implementation. Comparison to a C code Moeller-Trumbore 
implementation (see Table 1 would yield a speedup of more than 6. 1.6.2 Performance Results The overall 
results of our fast ray-triangle intersection code can be seen in Table 2: Whereas the C Code is already 
much faster than the Moeller-Trumbore Test (see Table 1), the SSE code achieves an additional, signi.cant 
speedup: On a 2.5 GHz Pentium-IV CPU, the SSE code for intersecting four rays with a single triangle 
requires 101 107 CPU cycles, depending on where the code exits. Amortizing this cost over all four rays 
results in only 25 27 cycles per intersection. Compared to the C code implementation of the RTRT OP 
algorithm, this results in a speedup of 2.7 2.8. Compared to the C code Moeller-Trumbore implementation 
in Table 1, a speedup of more than six can be observed. As discussed above, shadow rays have signi.cantly 
less overhead for storing the hit information, and as such are much faster: A shadow ray intersection 
costs only 80 93 cycles per packet, respectively 20 23 per ray. This once again shows that SSE is extremely 
e.cient for speeding up computations (the actual computations for shadow rays and primary rays are the 
same), but quickly su.ers from any non-computation overhead. All these measurements have been performed 
on a 2.5GHz Pentium-IV notebook CPU, on which these numbers correspond to 92 100 million ray triangle 
intersections for standard rays, and even 108 125 million intersections per second for shadow rays. 
The overall speedup compared to the single ray C code implementation is around 2.7 for primary and secondary 
rays, and 3.1 3.4 for shadow rays. This di.erence clearly shows the impact of the above-discussed overhead 
for updating the hit information for non shadow rays. Note that this masking overhead for storing the 
results might be partially hidden if more than four rays would be intersected in parallel. Generally, 
operating on larger packet sizes would allow for a more streaming-like approach, in which the latencies 
of certain operations could be hidden much better. Also note that the application of this data-parallel 
intersection algorithm is not limited to the RTRT core, but could also be used to accelerate other ray 
tracing-based rendering algorithms such as memory coherent ray tracing [Pharr97].  Fast kd-Tree Traversal 
Even before accelerating the triangle test, traversal of the acceleration structure was typically 2-3 
times as costly as ray-triangle intersection, as a ray tracer typically performs many more traversal 
steps than triangle intersections (see Table 5 for statistical traversal data in di.erent scenes6). Once 
the SSE triangle intersection code reduces the intersection cost by more than a factor of three, traversal 
is the limiting factor in our ray tracing engine. Furthermore, the SSE intersection procedure requires 
us to always have four rays available anyway. Therefore, we need an algorithm for e.ciently traversing 
four rays through an acceleration structure in parallel. As already discussed earlier on in this course, 
a wide variety of ray tracing acceleration schemes have been developed over the last two decades. For 
example, there are octrees, general BSP-trees, axis-aligned BSP-trees, uniform, non-uniform and hierarchical 
grids, ray classi.cation, bounding volume hierarchies, and several hybrids of several of these methods. 
As already discussed in [Wald04], we have chosen to use axis-aligned BSP trees (kd-trees) for the RTRT 
core. Their traversal code is quite simple, and can very well be implemented in a highly optimized form. 
Furthermore, BSP trees usually perform at 6Similar data hold for di.erent acceleration structures, see 
[Havran01]. least comparable to other techniques [Havran00, Havran01], and are well-known for their robustness 
and applicability for a wide range of scenes. However, our main reason for using a BSP tree in the RTRT 
core is the simplicity of the traversal code, which allows for e.ciently traversing packets of rays in 
parallel: Traversing a node is based on only two binary decisions, one for each child, which can e.ciently 
be done for several rays in parallel using SSE. If any ray needs traversal of a child, all rays will 
traverse it in parallel. This is in contrast to algorithms like octrees or hierarchical grids, where 
each of the rays might take a di.erent decision of which voxel to traverse next. Keeping track of these 
states is non-trivial and was judged to be too complicated to be implemented e.ciently. Bounding Volume 
Hierarchies have a traversal algorithm that comes close in simplicity to BSP trees, and could also be 
adapted to a SIMD-traversal method. However, BVHs do not partition space, but rather organize the hierarchy. 
This leads to di.erent parts of the hierarchy overlapping themselves, does not allow for e.ciently traversing 
the voxels in front-to-back order7 , and thus in practice makes BVHs ine.cient for complex scenes (for 
extensive statistical experiments, see [Havran00, Havran01]). Furthermore, algorithms for building BVHs 
that are well-suited for fast traversal are less well investigated than similar algorithms for BSP trees. 
2.1 Data Layout of a kd-Tree Node As mentioned above, the ratio of computation to the amount of accessed 
memory is very low for scene traversal. This requires us to carefully design the data structure for e.cient 
caching and prefetching. For a typical BSP node, one has to store A .ag specifying whether it is a leaf 
node or an inner node.  For leaf nodes, an item list , i.e. a list of integer IDs that specify the triangles 
in this leaf; consists of a pointer (or index) to the .rst item in the list, and of the number of items 
in the list.  For inner nodes, the addresses of the two children, the dimension of the splitting axis 
(i.e. x, y, or z), and the location of the split plane.  All these values can be stored in a very compact, 
uni.ed node layout of only 8 bytes: Obviously, a node can either be a leaf node or an inner node, so 
they can be stored in the same memory location (a union in C code) as long as there is at least one bit 
reserved for determining the kind of the node. For inner nodes, we need half the node for storing the 
.oat value that speci.es the split plane. Addressing the two children can be performed with a single 
pointer if children of a node are always stored next to each other. Furthermore, if all BSP nodes are 
stored in one contiguous array (with child nodes always 7It is possible to traverse BVHs in front-to-back 
order by keeping the yet-to-be-traversed parts of the hierarchy organized in a priority queue [Haines91]. 
This however makes each traversal step considerably more costly than a BSP traversal step stored after 
their parent nodes), this single pointer can be expressed as an o.set relative to the current node. As 
this o.set is positive, we can use its sign bit for storing the .ag that speci.es the type of node. Finally, 
having the nodes stored in an array guarantees that the o.set is a multiple of 8 (the node size), so 
its lower two bits can be safely used for storing the splitting axis. Leaf nodes can be expressed in 
quite the same way: The .ag that speci.es the node type has to remain in place, and the pointer to the 
start of the item list is stored just like the children pointer, as a relative o.set stored in bits 2..30. 
This leads to the following simple, compact structure: struct BSPLeaf { unsigned int flagDimAndOffset; 
// bits 0..1 : splitting dimension // bits 2..30 : offset bits // bit 31 (sign) : flag whether node is 
a leaf float splitCoordinate; }; struct BSPInner { unsigned int flagAndOffset; // bits 0..30 : offset 
to first son // bit 31 (sign) : flat whether node is a leaf } typedef union { BSPLeaf leaf; BSPInner 
inner; } BSPNode; Note that the exact order and arrangement of the bits has been very carefully designed: 
Each value can be extracted by exactly one bitwise and operation to mask out the other bits, and does 
not require any costly shift operations for shifting bits to their correct positions. #define ABSP_ISLEAF(n) 
(n->flag_k_ofs &#38; (unsigned int)(1<<31)) #define ABSP_DIMENSION(n) (n->flag_k_ofs &#38; 0x3) #define 
ABSP_OFFSET(n) (n->flag_k_ofs &#38; (0x7FFFFFFC)) As traversing a BSP node is by far the most common 
operation in a ray tracer, it has to be implemented with extreme care. For example, an older version 
of the RTRT kernel originally stored the dimension bits in the upper bits of the .ag word, from where 
they could be retrieved by a single shift operation. While this seems comparably cheap, due to this single 
shift operation (which is quite more costly than a bitwise and ) the old version was roughly 5 percent 
slower than the current version. The presented data layout allows for squeezing the whole BSP node description 
into 8 bytes per node, or 4 16 nodes per cache line8 . As we always store 8Assuming 32 bytes per cache 
line on a PentiumPro Architecture (Pentium-III), 64 bytes on an AMD Athlon MP, and 128 bytes on an Intel 
Pentium-IV Xeon. Note that the larger cache sizes on a Xeon CPU might bene.t from an improved node packing 
inside a cache line as discussed in [Havran97, Havran99, Havran01] both children of a node next to each 
other, both nodes are stored in the same cache line9, and are thus always and automatically fetched together. 
 Figure 3: All BSP nodes (inner nodes as well as leaf nodes) in RTRT are stored in one contiguous, cache-aligned 
array. Depending on cache line size, either 4, 8, or 16 nodes form one cache line. Both children of the 
same node are always stored next to each other, and thus land in the same cache line. As cache line size 
is a multiple of node size, node pairs will never overlap a cache line boundary. Both children can be 
addressed by the same pointer, which is stored as an o.set. As this o.set is always positive and divisible 
by four, we can squeeze both node type .ag (leaf or inner node) and split dimension (X,Y, or Z) in the 
sign bit and in the lower two bits, respectively. For leaves, pointers to the item lists (not shown) 
are stored exactly like pointers to nodes. Using the same pointer for both node types allows for reducing 
memory latencies and pipeline stalls by prefetching, as the next data (either a node or the list of triangles) 
can be prefetched before even processing the current node. Note that though prefetching requires SSE 
cache control operations, prefetching is also possible for the single-ray, non-SIMD traversal code. Similarly, 
the bene.ts of using this optimized node layout, i.e. reduced bandwidth and improved cache utilization, 
positively a.ect both the C-code as well as the SSE implementation. 2.2 Fast Single-Ray kd-Tree Traversal 
Before describing our algorithm for traversal of four rays in parallel, we .rst take a look at the traversal 
of a single ray: In each traversal step, we maintain the current ray segment [tnear,tfar], which is the 
parameter interval of the ray that actually intersects the current voxel. This ray segment is .rst initialized 
to [0, 8)10 , then clipped to the bounding box of the scene, and is updated incrementally during traversal11 
. For each traversed node, we calculate the distance d to the splitting plane de.ned by that node, and 
compare that distance to the current ray segment. 9In RTRT, all BSP node pairs are aligned to cache line 
boundaries: All nodes are stored in one consecutive, cache-aligned array, and the cache line size is 
a multiple of the node size. 10In practice, rather to [., tmax] 11Instead of clipping to the scene bounding 
box, it is also possible to not clip at all and rather use six additional BSP planes that represent the 
bounding box sides. This is typically slower in a software implementation, but can be useful for hardware 
implementations such as in the SaarCOR architecture Figure 4: The three traversal cases in a BSP tree: 
A ray segment is completely in front of the splitting plane (a), completely behind it (b), or intersects 
both sides (c). If the ray segment lies completely on one side of the splitting plane (i.e. d>= tfar 
or d<= tnear), we can cull the subtree on the other side and immediately proceed to the corresponding 
child voxel12 . If neither side can be culled, one computes the ray parameter at which the plane intersects, 
and traverses both sides in turn the .rst side with ray segment [tnear,d], and the second one with [d, 
tfar]. This actually leads to three di.erent traversal cases, as depicted in Figure 4. Basing the traversal 
entirely on the current ray segments allows for performing all computations in 1D: Only the actual ray 
parameters for start and end of the segment, as well as distance to the split plane have to be known. 
Neither the 3D coordinates of the actual entry, exit, or intersection points are required, nor is it 
necessary to track the current voxel s actual extent13 . Early ray termination: In the just described 
implementation, voxels are traversed in front-to-back order, which allows for early ray termination : 
If a valid hit point is found inside one voxel (i.e. thit <= tfar), traversal can be immediately terminated, 
as all further potential primitive intersections can only be be behind the already found hit point. This 
early ray termination is actually responsible for the occlusion culling feature of ray tracing, and can 
greatly 12Note that using <= and >= instead of < and > requires careful programming to correctly handle 
triangles that lie on the splitting plane. Also not that the exact implementation is quite sensitive 
to issues such as having rays parallel to the split plane, or rays actually lying inside the split plane. 
These special cases generate In.nity s and NaN s during traversal, which need special attention to handle 
correctly. 13This implies that the actual size of the voxel is not known at any time during traversal. 
Only the current ray segment i.e. the overlap between the ray and the voxel is known. enhance performance. 
Combined with a high-quality BSP tree (see Section 3), early ray termination can in many scenes lead 
to an average of less than two ray-triangle intersections per ray (see Table 5). 2.2.1 Recursive kd-Tree 
Traversal In its most common recursive form, the whole traversal algorithm can be expressed quite simply: 
void Traverse() { ( t_near,t_far ) = ( Epsilon, ray.t_max ); ( t_near,t_far ) = Clip(t_near,t_far); if 
(t_near > t_far) // ray misses bounding box of object return; RecTraverse( bspRoot, t_near, t_far ); 
} float RecTraverse(node,t_near,t_far) // returns distance to closest hit point { if (IsLeaf(node)) { 
IntersectAllTrianglesInLeaf(node); return ray.t_closest_hit; // t_closest_hit initialized to t_max before 
traversal } d = (node.split -ray.org[node.dim] / ray.dir[node.dim]; if (d <= t_near) { // case one, 
d <= t_near <= t_far -> cull front side return RecTraverse(BackSideSon(node),t_near,t_far); } else if 
(d >= t_far) { // case two, t_near <= t_far <= d -> cull back side return RecTraverse(FrontSideSon(node),t_near,t_far); 
 } else { // case three: traverse both sides in turn t_hit = RecTraverse(FrontSideSon(node),t_near,d); 
if (t_hit <= d) return t_hit; // early ray termination return RecTraverse(BackSideSon(node),d,t_far); 
 } } 2.2.2 Iterative kd-Tree Traversal Due to the reasons discussed in the previous chapter, a recursive 
solution is not the best choice for high performance. However, the algorithm can be easily reformulated 
in an iterative way (see e.g. [Keller98, Havran01]), which in pseudocode can be written up in only a 
few lines of code: void Traverse() { ( t_near, t_far ) = ( Epsilon, ray.t_max ); ( t_near, t_far ) = 
scene.boundingBox.ClipRaySegment(t_near, t_far); node = rootNode; if (t_near > t_far) // ray misses 
bounding box of object return; while (1) { while (!node.IsLeaf()) { // traverse til next leaf d = (node.split 
-ray.org[node.dim]) / ray.dir[node.dim]; if (d <= t_near) { // case one, d <= t_near <= t_far -> cull 
front side node = BackSideSon(node); } else if (d >= t_far) { // case two, t_near <= t_far <= d -> cull 
back side node = FrontSideSon(node); } else { // case three: traverse both sides in turn stack.push(BackSideSon(node),d,t_far); 
( node, t_far ) = ( FrontSideSon(node), d ); } } // have a leaf now IntersectAllTrianglesInLeaf(node); 
if (t_far <= ray.t_closesthit) return; // early ray termination if (stack is empty) return; // noting 
else to traverse any more... ( node, t_near, t_far ) = stack.pop(); } } Obviously, a realtime kernel 
requires a very high-performance implementation of this traversal code with many low-level optimizations. 
For example, this includes precomputation of the 1/ray.dir[dim] terms, an e.cient stack handling, e.cient 
calculation of FrontSideSon and NearSideSon , careful data layout, and especially e.cient handling, organization 
and ordering of the conditionals. Special emphasis has to be paid on handling all special cases like 
for example division by zero ray direction (leading to +/-In.nity and NaN values), numerical issues (especially 
during the comparisons), triangles lying in the splitting plane, .at voxels leading to zero-length ray 
segments, etc  in an e.cient though nevertheless correct manner. As the discussion of all these implementation 
details is quite involved, the actual low-level source code is omitted here.   2.3 SIMD Packet Traversal 
for kd-Trees As discussed before, e.cient use of the SSE instruction set during ray tracing requires 
to trace packets of several rays in parallel. The algorithm for tracing four di.erent rays is essentially 
the same as traversing a single one: All four rays are .rst initialized to (0,tmax) and clipped to the 
scene bounding box using fast SSE code. In each traversal step then, SSE operations are used to compute 
the four distances to the splitting plane and to compare these to the four respective ray segments, all 
in parallel. If all rays require traversal of the same child, traversal immediately proceeds with this 
child, without having to change any of the ray segments. Otherwise, we traverse both children, with the 
ray segments updated accordingly. As discussed in the previous section, e.cient ray tracing requires 
to traverse the voxel visited by a ray in front-to-back order. However, when tracing several rays at 
the same time in parallel, the correct traversal order for the packet might be ambiguous, as di.erent 
rays might demand a di.erent traversal order. In order to get a consistent traversal order for the whole 
packet, we only allow such rays into the same packet for which the traversal order can be guaranteed 
to match. This however is easy to guarantee for two common cases, as discussed in more detail below: 
First, rays starting at the same origin can be shown to never disagree on traversal order, whatever their 
direction is. Second, rays with the same direction signs in all dimensions will also have the same traversal 
order at any splitting plane. 2.3.1 Resolving Traversal Order Ambiguities: Same Origin vs. Same Principle 
Direction The .rst case already supports most of the rays in ray tracing, as all primary rays from a 
pinhole camera, as well as all shadow rays from point light sources fall under this category. However, 
the computations for determining the traversal order depend on the relation between actual origins of 
the rays and position of the splitting plane. As such, they have to be performed during each traversal 
step in the inner loop of the packet traversal code, and as such are quite costly. Furthermore, the operations 
for computing the respective updated ray segments get relatively complex for this alternative. The second 
alternative of only combining rays with matching direction signs on .rst sight appears more costly: First, 
each packet of rays has to be checked for matching signs, and rays with non-matching signs either have 
to split up or require special handling. However, these special cases happen only rarely for coherent 
rays, which typically have similar directions. Once it is clear that the rays have matching direction 
signs, the computations in the inner loop get very simple, and can be expressed quite e.ciently. In fact, 
all that is required in the inner loop of the traversal code is a simple XOR with the respective direction 
sign bit of the .rst ray. Similar arguments hold for the code computing the respective tnear/tfar values, 
which can be expressed quite a bit more e.ciently than for the case with common ray origin. As such, 
the RTRT kernel only supports packets with matching directions signs. Packets are automatically and quickly 
tested for complying to this rule, and non-complying rays are traced with the fast single-ray traversal 
code. 2.3.2 Implementation Issues After restricting the traversal code to packets with matching direction 
signs, the respective computations get quite simple. The plane distances for all four rays are computed 
with only one SSE mult and one SSE add , and compared to the four respective tnear and tfar values with 
SSE compare instructions14 . If either all ray segments lie in front of the plane, or are all behind 
the splitting plane (corresponding to cases a and b in Figure 4), the other side is culled, and no special 
operations have to be performed for the near/far values, nor for the traversal stack. In the case that 
both sides have to be traversed 15, the respective ray segments get updated to [tmin, min(d, tfar)] for 
the near side, respectively [max(d, tnear),tfar] for the far side. The min and max operations are required 
as not all ray segments may actually have overlapped the splitting plane. These ray segments may obviously 
not get longer than they have been before. Note that the near and far sides of a voxel (with respect 
to a given ray R) are determined by the order in which a directed in.nite line with the same direction 
as R would cross this line16. As such, near and far side are independent of both ray origin and actual 
BSP plane position, and can be determined once at the start of traversal by the direction signs alone. 
Deactivating invalid rays: Rays that get forced to traverse a subtree that they would not have traversed 
had they been traversed alone should obviously not in.uence any decisions in that subtree. This however 
can be achieved quite e.ciently: Using the SSE min/max for updating the respective ray segments operations 
as just described, it can be shown easily that rays entering an invalid subtree automatically get their 
ray segments updated to negative length (i.e. tnear >tfar), which can be used to determine which of the 
rays are still active in a subtree. In SSE, this generates hardly any overhead at all: A single SSE compare 
of tnear and tfar automatically generates a bit-mask that can be used to mask out any of the latter decision 
.ags in a single operation. This leads to the following pseudocode for SIMD packet-traversal: void IterativePacketTraverse(ray[4],hit[4]) 
{ ( t_near[i], t_far[i] ) = ( Epsilon, ray.t_max ); // i=0..3 in parallel 14Note that SSE comparisons 
are actually not conditionals, but rather generate bit masks that can be used for dependent moves 15Note 
that this case can also happen if neither ray wants to traverse both sides, as one ray might want to 
only traverse the left side, while an other one demands traversal of only the right side. 16The near 
side may not be confused with the .rst voxel visited by a ray, as the origin may actually lie on the 
far side. // t_near[i], t_far[i] are the near/far values for the i th ray ( t_near[i], t_far[i] ) = 
scene.boundingBox.ClipRaySegment(t_near[i], t_far[i]); node = rootNode; while (1) { while (!node.IsLeaf()) 
{ // traverse til next leaf d[i] = (node.split -ray[i].org[node.dim]) / ray[i].dir[node.dim]; active[i] 
= (t_near[i] < t_far[i]); if for all i=0..3 (d[i] <= t_near[i] || !active[i]) { // case one, d <= t_near 
<= t_far for all active rays // -> cull front side node = BackSideSon(node); } else if for all i=0..3 
(d[i] >= t_far[i] || !active[i]) { // case two, t_near <= t_far <= d for all active rays // -> cull back 
side node = FrontSideSon(node); } else { // case three: traverse both sides in turn // correctly update 
all near/far values // push all near/far values for entire packet stack.push(BackSideSon(node), max(d[i],t_near[i]),t_far[i]); 
( node, t_far[i] ) = ( FrontSideSon(node), min(d[i],t_near[i]) ); } } // have a leaf now IntersectAllTrianglesInLeaf(node); 
if for all i=0..3 (t_far[i] <= ray[i].t_closesthit) return; // early ray termination if (stack is empty) 
 return; // noting else to traverse any more... // restore all near/far values for entire packet ( node, 
t_near[i], t_far[i] ) = stack.pop(); } } Note that all x[i] statements are always executed for all four 
rays in parallel using a SIMD instruction. While this algorithm only operates on packets of 4 rays, the 
extension to larger packet sizes is straightforward. Note that the respective computations for properly 
computing the near/far values (including marking invalid ray segments) get quite a bit more involved 
for the alternative case in which the origin coincides but the directions di.er. The actual SSE implementation 
of this algorithm can be performed quite e.ciently. Obviously, the same iterative algorithm as in the 
single ray code can be used, and many of the single-ray optimizations (such as changing the divisions 
to multiplies with the precomputed inverse) can be performed as well. All mathematical computations in 
the inner loop consist of only one SSE multiply and one SSE add. As SSE does not easily work together 
with non-SSE conditionals, many of the conditionals can be expressed more e.ciently by SSE conditional 
moves (realized via SSE bit operations). Furthermore, all of the min/max operations for traversal case 
3 can be expressed with a single SEE instruction each.  2.4 Traversal Overhead Obviously, traversing 
packets of rays through the acceleration structure generates some overhead: Even if only a single ray 
requires traversal of a subtree or intersection with a triangle, the operation is always performed on 
all four rays. Our experiments have shown that this overhead is relatively small as long as the rays 
are coherent. Table 3 shows the overhead in additional BSP node traversals for di.erent packet sizes. 
As can be seen from this experiment, overhead is in the order of a few percent for 2  2 packets of rays, 
but goes up for larger packets. On the other hand, increasing screen resolution also increases coherence 
between primary rays. Most important is the fact that the e.ective memory bandwidth has been reduced 
essentially by a factor of four through the new SIMD traversal and intersection algorithms as triangles 
and BSP nodes need not be loaded separately for each ray. This e.ect is particularly important for ray 
traversal as the computation to bandwidth ratio in relatively low. Of course one could operate on even 
larger packets of rays to enhance the e.ect. However, our results show that we are running almost completely 
within the processor caches even with only four rays. We have therefore chosen not to use more rays per 
ray packet, as it would additionally increase the overhead due to redundant traversal and intersection 
computations, and would make the basic algorithm more complicated again17 . For the SaarCOR architecture 
however [Woop05], the same packet traversal principle is used with a signi.cantly larger number of rays 
per packet. 2  2 4  4 8  8 2562 10242 ERW6 1.4% 4.4% 11.8% 5.8% 1.4% O.ce 2.6% 8.2% 21.6% 10.4% 2.6% 
Conference. 3.2% 10.6% 28.2% 12.2% 3.2% Table 3: Overhead (measured in number of additional node traversals) 
of tracing entire packets of rays at an image resolution of 10242 in the .rst three columns: As expected, 
overhead increases with scene complexity (800, 34k, and 280k triangles, respectively) and packet size, 
but is tolerable for small packet sizes. The two columns on the right show the overhead for 2  2 packets 
at di.erent screen resolutions. 17Larger packets especially su.er from the limited number of registers 
in the ia32 architectures. Whereas most values for the single ray code can be kept in registers, larger 
packets require frequent load/store operations to save and restore certain values into the registers 
 Figure 5: Naive kd-tree vs. high-quality kd-tree in a simple scene consisting of a room with one chair 
and one light source. Center: The scene with a BSP tree as it would result from a typical naive BSP construction 
code that always splits the biggest dimension in the middle, until a maximum depth or a minimum number 
of triangles is reached. Right: The same scene with a high-quality BSP as it results if the planes are 
placed based a good cost prediction function. Obviously, the BSP with the cost function would be signi.cantly 
faster to traverse than the BSP with the naive plane placement. The e.ect of a good BSP tree can be even 
more pronounced in practical, more complex scenes.  High-Quality BSP Construction Except for e.cient 
traversal and intersection code as just described in Sections 1 and 2, the performance of a ray tracer 
using a kd-tree to a large degree depends on the algorithms with which the BSP tree has been built. Therefore, 
it is important to brie.y discuss how good BSP trees can be built (for a more indepth discussion of 
this topic, see e.g. [Havran01]). Once the kd-tree has been built i.e. the location and orientation 
of the BSP planes, and the decision when to stop subdivision have been .xed the number of traversal 
steps and triangle intersections for a given ray and traversal algorithm is predetermined. As such, 
building a BSP tree that better adapts to the scene complexity directly in.uences these two critical 
performance parameters. This can have a signi.cant impact on overall performance: For example, since 
its original publication in [Wald01], the RTRT core has been enhanced with a better BSP construction 
code which has roughly doubled its performance on top of the already very high performance as originally 
published. This speedup of two is entirely due to the improved BSP tree, and did not require any other 
changes to the core18 . When building BSP trees, the most common approach is to always split each voxel 
in the middle. In the most naive approach, the splitting dimension is cho 18Note that similar speedups 
apply for the SaarCOR architecture [Woop05]: As the Saar-COR architecture uses exactly the same data 
structures as the RTRT kernel (and in fact uses RTRT to generate the binary scene dumps it runs on), 
any speedups due to better BSPs translate similarly to better SaarCOR performance! sen in a round-robin 
fashion, and subdivision proceeds until either a maximum depth has been reached, or voxel contains less 
than a speci.ed number of triangles19 . However, it is common knowledge that the BSP tree for non-cube-like 
scenes can be improved by always splitting the box in the dimension where it has maximum extent20 . This 
can be explained by the fact that this approach produces the most cube-like voxels21 . However, it is 
also long known that putting the plane into the middle might not be a perfect position, either [Havran01]. 
Scene #triangles RR absolute pME erformPS ance SAH spePS edup ME/RR ERW6 ERW10 O.ce Theater Conference 
(sta) SodaHall (in) SodaHall (out) Cruiser PowerPlant (in) PowerPlant (out) 804 83,600 34,000 112,306 
282,801 2,247,879 2,247,879 3,637,101 12,748,510 12,748,510 4.33 1.30 2.50 1.30 2.18 2.50 2.62 1.67 0.51 
0.72 4.16 2.74 2.32 1.12 1.89 2.13 2.78 1.56 0.50 0.78 4.53 3.03 2.85 1.47 2.47 2.87 3.63 2.03 0.81 0.97 
8.18 5.51 4.31 2.43 4.17 3.46 4.08 3.01 1.26 1.44 80 % 81 % 51 % 65 % 69 % 20 % 12 % 48 % 56 % 48 % 89 
% 101 % 72 % 87 % 91 % 38 % 47 % 80 % 147 % 84 % Table 4: Relative performance of rendering with BSPs 
built by di.erent construction algorithms: Kaplan-BSP with round-robin subdivision (RR), Splitting the 
voxel in the dimension of maximum extent (ME), PlaneShifter , i.e. ME with shifting the plane to maximize 
empty voxels (PS), and a surface area heuristic (SAH). Numbers correspond to million primary rays per 
second with SSE code on a 2.2GHz Pentium-IV Xeon. Right two columns show the relative SAH speedup as 
compared to PS, ME and RR. As expected the SAH performs best. Except for Soda Hall, SAH usually performs 
50 80 percent faster than the best other method. Note that the e.ect in practice is even more pronounced: 
Whereas RR, ME and PS require extensive parameter tuning to achieve the result given in this table, the 
SAH performs reasonably well already with its default parameters. The respective scenes can be seen in 
Figure 7, some statistical data on the generated BSPs is given in Table 5. Many people assume that placing 
the split plane towards the object median (i.e. placing it such that both halves contain an equal number 
of triangles) would be a better choice. Though this appeals to intuition, it is actually a very bad 19In 
practice, 20 25 for maximum depth, and 2 3 for the triangles per leaf threshold are usually close to 
optimal values. 20Interestingly, though this is common knowledge , it is actually a misconception except 
for extremely non-cubic voxels, as can be seen in Table 4 (columns RR vs. ME ): For most scenes, splitting 
in the middle is actually slightly faster. 21For cube-like voxels, the ratio of voxel surface to voxel 
volume reaches its minimum. As the voxel surface in.uences the probability of a voxel to be hit by a 
ray[MacDonald89], a voxel of a given volume has the least chance of being traversed. choice. Splitting 
at the object median aims at building a balanced tree with equal depth of all leaves. Though this is 
optimal for binary search trees with equal access probabilities to each leaf node, it is not optimal 
for ray tracing with a kd-tree: First, the probability of accessing di.erent voxels is certainly not 
equally distributed, as larger voxels are more likely to be hit than small ones. Furthermore, traversing 
a kd-tree is actually not the same as a search in a binary search tree (in which traversal always proceeds 
from the root to the leaf in one straight line), but rather a range searching process in which several 
leaves have to be accessed, and in which traversal frequently goes up and down in the tree. As such, 
BSP trees should not be optimized towards having an equal number of traversal steps towards each leaf 
(i.e. balancing it), but should rather minimize the number of traversal steps for traversing a ray from 
one location to another. For this kind of traversal, BSP trees behave best if they have large voxels 
of empty space as close to the root node as possible, as large empty space allows for traversing a ray 
over a large distance at small cost. Splitting at the object median results in empty space being pushed 
far down the tree into many small voxels, and thus leads to many traversal steps and bad performance. 
Some other intuitive improvements to the split plane position lead to more successful heuristics. For 
example, if one of the half-voxels produced by a split is empty, the argument of empty space being bene.cial 
suggests that the split plane should be shifted as far into the non-empty half as possible. This reduces 
the probability of the ray having to traverse the non-empty leaf, signi.cantly improves the BSP quality, 
and is easy to implement. This heuristic can also be furtherly re.ned to yield even more improvements. 
Though the results of such intuitive approaches are quite limited in the range of 30 50 percent over 
the naive construction method (see Table 4) they are relatively easy to implement, and thus should always 
be preferred over the naive approach. However, these simple heuristics by far cannot match the BSP quality 
that can be generated with a well-designed cost function (see below). 3.1 Surface Area Heuristic (SAH) 
A more successful though unfortunately also quite more complicated approach is to optimize the positioning 
of the splitting plane via cost prediction functions in the spirit of Goldman and Salmon [Goldsmith87], 
MacDonald and Booth [MacDonald89, MacDonald90], and Subramanian [Subramanian90]. Such a cost prediction 
function uses certain assumptions for estimating how costly a split would be. This estimate can then 
be used to place the plane at the position of minimal cost. Furthermore, the cost function provides a 
much more e.ective termination criteria for the subdivision than the above-mentioned maximum depth and 
triangle threshold : Using a cost-estimate function, subdivision is simply terminated as soon as the 
estimated traversal cost for a leaf node is less than the cost for the split with minimum estimated cost. 
The most famous of these cost prediction functions is the surface area heuristic (SAH) as introduced 
by MacDonald and Booth [MacDonald89, MacDonald90]: The surface area heuristic assumes that rays are equally 
distributed in space, 24 and are not blocked by objects. Under these (somewhat unrealistic) assumptions, 
it is possible to calculate the probability with which a ray hitting a voxel also hits any of its sub-voxels. 
More speci.cally, having a voxel V that is partitioned into two voxels VL and VR, the probability of 
a ray traversing these two sub-voxels can be calculated as SA(VL) SA(VR) P (VL|V ) = and P (VR|V )= SA(V 
) SA(V ) where SA(V ) = 2(VwVd + VwVh + VdVh) is the surface area of voxel V (with Vw,Vh, and Vd being 
width, depth and height of the voxel, respectively). Once these respective probabilities are know, one 
can estimate the cost of a split: Assuming that a traversal step and a ray triangle intersection have 
an average cost of Ctrav and Cisec respectively, the average cost of splitting voxel V into VL and VR 
can be estimated as Costsplit(VL,NL,VR,NR)= Ctrav + Cisec(P (VL|V )NL + P (VR|V )NR) where NL and NR 
are the number of triangles in VL and VR, respectively. 3.1.1 Finding the best split positions This function 
is continuous except for the split plane positions at which the numbers NL and NR change (also see [Havran01]). 
These are exactly the positions where either a triangle side ends (i.e. at a vertex), or where a triangle 
side pierces the side of a voxel [Havran01, Hurley02]). These locations form the potential split positions 
, from which the position with the minimum cost is chosen. Unfortunately, checking all potential splits 
can be quite expensive, and requires a carefully designed algorithm to avoid quadratic complexity during 
each splitting step. Furthermore, .nding all potential splits can be quite costly and numerically unstable, 
especially for those potential splits that are computed by intersecting a triangle side with the voxel 
surface. Instead of performing these side-voxel intersections it is also possible to only consider each 
triangle s bounding box sides as potential split planes. This is much easier to implement, and still 
performs better than not using the SAH at all. However, perfect split positions usually achieve superior 
performance than only considering the bounding box sides. As such, the RTRT core uses perfect split positions, 
and uses a carefully designed implementation to avoid all potential numerical inaccuracies without sacri.cing 
performance. 3.1.2 Automatic termination criterion Using the above assumptions, one can estimate the 
minimum cost of traversing the split object. Similarly, one can estimate the cost of not splitting a 
voxel at all, as Costleaf (V )= NV  Cisec. Simply comparing these two values provides a very simple 
and e.cient termination criterion. Of course, it is still possible to combine the surface area heuristic 
with other heuristics. For example, it may make sense to still specify a maximum tree depth22, or to 
add heuristics for encouraging splits that produce empty space (see e.g. [Havran01]).  3.2 Post-Process 
Memory Optimizations The BSP construction process in the RTRT core actually is a two-stage process. While 
the optimized data layout described in the previous section is quite easy to use during traversal, it 
would be quite awkward to use while building the BSP. As such, we .rst build the BSP tree with a more 
easy-to-use node layout that uses twice as much memory and lots of pointers. Once the build-tree process 
is .nished, RTRT performs several optimizations on the BSP tree (see Figure 6): First, for some build-tree 
algorithms RTRT .rst iterates over the whole tree a second time, thereby undoing any splits that have 
not produced useful results (e.g. a node with two leaves containing the same item lists)23 . Then, this 
memory-unfriendly data layout is re-arranged to the more cachefriendly form as described above. Though 
this data reorganization is quite costly, it is much more convenient than having to program the whole 
BSP construction code directly on the optimized data layout. Figure 6: Post-process memory optimizations: 
After construction, splits that did not produce sensible results get collapsed (e.g. nodes G and H), 
and the item lists are stored in a compressed form by checking whether the same node list can already 
be found in the list array. Di.erent item lists can overlap the same memory regions without any problems, 
as the length of the list is stored in the BSP node anyway. After these collapse operations, the BSP 
is reformatted to the memory-compressed form as shown in Figure 3. Finally, it is possible to perform 
some minor optimizations during the data rearrangement, such as having similar item lists use the same 
memory space. For example, the item lists 12,13,17 and 13,17 can be stored in the same memory region 
if the pointer for the second lists points into the .rst list (see Figure 6). Though this can save some 
memory especially for deeply subdivided BSPs, the performance impact of these .nal optimizations is quite 
limited. 22Compared to Kaplan-BSPs, a maximum tree depth with the surface area heuristic is more likely 
to be in the range of 50 or more 23Obviously, this could also be done already during BSP construction. 
 ERW6 ERW10 O.ce (804 triangles) (83,600 triangles) 34,000 triangles)  Theater Conference Soda Hall 
(inside) (112,306 triangles) (282,801 triangles) (2,247,879 triangles) Soda Hall (outside) Cruiser Power 
Plant (outside) (2,247,879 triangles) (3,637,101 triangles) (12,748,510 triangles) Figure 7: The scenes 
used for the RTRT benchmarks in Table 6. Including simple SSE shading, these scenes run at 1.3 5.4 frames 
per second at full-screen (1024  1024) resolutions on a single 2.5GHz Pentium-IV notebook CPU. 3.3 
Results of di.erent BSP Construction Strategies In its current implementation, the surface area heuristic 
in typical scenes is roughly 50 100 percent faster than a typical Kaplan-type BSP (see Table 4), and 
is still up to 50 percent faster than the best non-SAH as implemented in RTRT by 2001 (as used in the 
original 2001 Coherent Ray Tracing paper [Wald01]). Though these results are impressive, the surface 
area heuristic also has several problems. First of all, it can be quite costly to generate, especially 
for complex scenes. Second, the SAH though being already very good is still not optimal24 . Following 
a greedy strategy for picking the split plane can lead to getting stuck in local minima. The same is 
actually true for the termination 24Computing the best BSP tree is known to be NP-complete [Havran01]. 
criterion: Very easily, it may happen that no split can be found with a cost less than the cost of making 
a leaf in which case a leaf will be generated even though a better con.guration might be found if another 
level of splits were considered (see e.g. Figure 8). This could be .xed by using a global optimization 
method, which however would probably be far too costly to generate. More importantly, the SAH is quite 
complicated to implement correctly, and is error-prone both to programming bugs as well as to numerical 
inaccuracies. Figure 8: With a greedy method for choosing the split plane, the surface area heuristic 
can get stuck in local minima. For example, no single split plane can be found that subdivides the left 
voxel in a way that would have a better cost function than creating a leaf (as each side would have as 
many triangles as the node itself). If however a non-optimal split were allowed in the center, the following 
split would .nd a con.guration that has less cost than the left one (center image). Right: The same argument 
can be repeated in.nitely, making automatic termination problematic if such splits are allowed. Note 
that this is a very common con.guration for practical scenes, as for example all walls of a room match 
this setting. Finally, the SAH requires the ray tracer to work exactly: For example, working on perfect 
split positions often leads to the generation of .at cells with zero width: All triangles that are orthogonal 
to a coordinate axis (such as walls) will eventually end up in a cell that exactly encloses them, and 
which thus will be .at25 . This can easily lead to numerical problems during traversal, as a ray traversing 
an empty cell actually has a zero-length overlap with this voxel, which may easily be over-seen by the 
traverser. Though this is not exactly a problem of the SAH, it may still lead to problems when using 
it. Obviously, the RTRT traversal code correctly handles this case. 25This case also has to be handled 
correctly during BSP construction: For example, when further subdividing a .at cell, the construction 
code has to take care when computing the side-voxel intersections. Scene (view) BSP generation strategy 
num. trav. steps number of traversed leaves (total) (empty) (full) Triangle-Isecs mailboxing yes no 
ERW6 Kaplan PS SAH 32.22 33.45 20.97 8.05 7.76 4.32 1.60 4.31 3.25 6.46 3.45 1.07 15.51 9.78 1.46 6.35 
5.83 1.45 ERW10 Kaplan PS SAH 51.14 54.15 32.35 9.88 9.70 5.35 1.66 6.65 4.27 8.22 3.05 1.07 17.31 7.50 
2.65 8.39 6.41 2.65 O.ce Kaplan PS SAH 58.80 60.04 35.09 12.76 12.10 6.53 7.47 10.64 5.37 5.29 1.46 1.15 
11.63 3.39 3.46 6.03 2.73 3.36 Theater Kaplan PS SAH 98.22 88.48 64.86 18.21 15.19 10.40 15.03 13.44 
9.13 3.19 1.74 1.28 12.52 5.21 3.79 7.96 4.07 3.68 Conference Kaplan PS SAH 68.10 68.91 38.32 14.25 13.61 
6.87 9.48 12.31 5.63 4.78 1.29 1.24 9.91 2.82 2.53 5.63 2.38 2.30 Soda Hall (inside) Kaplan PS SAH 61.96 
60.06 50.12 8.70 8.24 5.34 5.45 6.81 4.22 3.25 1.43 1.12 9.58 3.73 2.64 6.20 2.98 2.62 Soda Hall (outside) 
Kaplan PS SAH 99.92 73.16 62.70 17.10 11.56 9.136 14.29 10.38 8.09 2.81 1.17 1.04 8.04 2.89 1.78 5.52 
2.67 1.78 Cruiser Kaplan PS SAH 74.95 78.40 52.34 11.05 11.2 7.019 6.77 9.52 5.74 4.28 1.68 1.28 14.84 
5.31 2.73 11.15 4.08 2.57 PowerPlant (inside) Kaplan PS SAH 108.7 90.65 72.79 15.62 12.52 9.18 11.30 
10.73 7.93 4.33 1.79 1.25 105.22 41.25 5.82 81.73 35.12 5.69 PowerPlant (outside 2) ( overview ) Kaplan 
PS SAH 189.1 132.7 109.7 32.45 22.02 19.61 28.52 19.82 17.99 3.93 2.20 1.62 40.06 15.75 10.12 28.26 12.13 
9.79 Table 5: Impact of the di.erent BSP generation strategies on traversal parameters: This table shows 
(for di.erent scenes and views) the average number of BSP traversal steps per ray, average number of 
leaves encountered during traversal (empty vs. nonempty leaves), and number of ray-triangle intersections 
with and without mailboxing, respectively27 . Generation strategies measured include Kaplan , PlaneShifting 
, and Surface Area Heuristic see Table 4). For both Kaplan and PS, several parameter sets have been tested, 
the number given here corresponds to the parameter set that achieved best performance. Note that the 
exceptionally high number of triangles visited for the Kaplan BSP in the PowerPlant model results from 
the high memory consumption of the Kaplan BSP, which did not allow for deeper BSP trees in a 32-bit address 
space.  Current RTRT Performance As described in the previous section, the RTRT software ray tracing 
kernel builds the combination of highly optimized traversal and intersection routines, tracing packets 
of rays for e.cient SIMD support, and a special emphasis on caching and memory optimizations. Though 
the newest version of the RTRT core still uses the same ideas as discussed in its original publication 
[Wald01], the RTRT kernel since then has been signi.cantly improved and completely reimplemented to 
achieve signi.cantly higher performance [Wald03]. This increase in performance is due to a combination 
of several factors: Faster CPUs: Obviously, CPUs have become signi.cantly faster since 2001 (from around 
800MHz Pentium-III s to 3GHz Pentium-IV s today). While many other applications cannot fully bene.t from 
this increase in clock rate, the RTRT core has been designed to fully exploit the available CPU performance 
(e.g. by minimizing cache misses, pipeline stalls and branch mis-predictions), and as such bene.ts linearly 
from improved CPU performance. Though the performance increase of modern CPUs is obviously not an achievement 
of the RTRT core itself, it is due to its special design especially its emphasis on SIMD support and 
caching optimizations that have enabled the RTRT kernel to bene.t linearly from any increase in CPU 
performance. Better BSP Trees: The Coherent Ray Tracing paper cared mostly about the fast traversal of 
an existing BSP tree, and neglected the algorithms for building these BSPs. The new RTRT core uses an 
improved surface area heuristic (SAH) cost prediction function for generating optimized BSP tree (see 
Section 3), which result in up to twice the performance than with the BSP construction code as used in 
the original Coherent Ray Tracing system. Better Compilers: Modern compilers o.er increasingly powerful 
tools for writing better and faster code. For example, RTRT achieves roughly twice the performance when 
compiling its single-ray code (which is written in plain C/C++ ) with Intel s ICC (Version 7.1) compiler 
as compared to compiling it with the 2001 version of the GNU gcc compiler as used in the original system28 
. Comparing to most up-to-date code written in ICC intrinsics with the performance of the original 2001 
SSE code written in hand-coded assembler yields similar speedups. Better Implementations: The RTRT core 
algorithms cover only a few hundred lines of code, and are continuously being optimized. Since its original 
publication in 2001 [Wald01], the core code has been re-implemented several times, having resulted in 
a signi.cant increase in performance. 28The new gcc versions 3 and higher are supposed to o.er similarly 
increased performance over pre-3.0 gcc s. Preliminary tests with gcc 3.3.1 have been positive, but a 
thorough evalu ation has not yet been performed. CPU / scene #tris absolute performance (fps@1024x1024, 
1CPU) ray tracing shading SSE SSE SSE C none SSE C C ERW6 (static) 804 8.95 5.38 3.80 2.09 ERW6 (dynamic) 
804 4.00 3.05 2.57 1.33 O.ce (static) 34,000 4.68 3.45 2.86 1.39 O.ce (dynamic) 34,000 2.61 2.17 1.87 
0.88 ERW10 83,600 5.82 3.88 3.27 1.65 Theater 112,306 2.68 2.18 1.95 1.05 Conference (dynamic) 282,801 
3.17 2.50 1.98 1.01 Conference (static) 282,801 4.40 3.26 2.61 1.44 Soda Hall (in) 2,247,870 3.68 2.85 
2.46 1.19 Soda Hall (out) 2,247,870 4.47 3.28 3.19 1.78 Cruiser 3,637510 3.38 2.65 2.31 1.17 Power Plant 
(in) 12,748,510 1.43 1.27 1.19 0.53 Power Plant (out) 12,748,510 1.59 1.39 1.40 1.17 Table 6: RTRT core 
performance in million rays per second on a single 2.5GHz Pentium-IV notebook CPU at a resolution of 
1024  1024 pixels, in di.erent shading con.gurations: SSE/none corresponds to pure ray traversal and 
intersection performance without shading at all; SSE/SSE means SSE packet tracing with a hard-coded 
simple SSE shading model; SSE/C means SSE ray tracing with C-code shading (including SoA-to-AoS data 
re-packing overhead); and C/C means pure C-code single ray traversal and shading. Though ray tracing 
scales nicely with scene complexity, even simple shading can already cost more than a factor of two given 
current ray tracing performance! The above numbers directly correspond to the achievable frame rate on 
a single 2.5GHz Pentium-IV notebook CPU at full-screen resolution (1024  1024 pixels). The respective 
benchmarking scenes can be found in Figure 7. Taken together, these methods allow the current core to 
signi.cantly outperform the old system even when running the old code on an up-to-date CPU. Even when 
traversing single, incoherent rays (i.e. without using the SSE instruction set) the new kernel is slightly 
faster than the originally published SSE code tracing packets of rays. Exploiting the full performance 
of the newest SIMD code then achieves an additional performance improvement of 2 3 when shooting coherent 
rays (see Table 6). It is important to note that the RTRT kernel does not use any approximations to achieve 
this speedup. It still performs at least the operations of a traditional ray tracer. Considering only 
the pure traversal and intersection cost i.e. without shading and without support for dynamic scenes 
 the RTRT kernel achieves up to ~ 9 million rays per second on simple scenes, and still 1.4 4.4 million 
rays per second on as complex scenes as the soda hall and power plant scenes (with 1.5 and 12.5 million 
triangles, respectively). Casting only primary rays with relatively simple shading, this performance 
allows for computing several (1.3 5.4) full screen frames per second even on a single notebook with a 
typical 2.5GHz Pentium-IV CPU (see Table 6 and Figure 7). Using a state of the art dual-CPU PC, this 
level of ray tracing performance allows generate impressive frame-rates even on a single desktop machine. 
 Future Work As can be seen by the results mentioned in Table 6, it is clear that the biggest individual 
bottleneck and thus the biggest remaining problem to be solved is the cost for shading. As the cost 
for shading has traditionally been cheap compared to the cost for tracing a ray, this problem so far 
has not received much attention. With the current increase in ray tracing performance however even simple 
shading incurs a severe performance impact. As such, the biggest potential for future performance gains 
lies in .nding ways for faster shading. However, it is still unclear how this can be achieved. Apart 
from faster shading, we expect that even higher ray tracing performance can be achieved by exploiting 
even more coherence by using larger packets. Larger packets should allow for optimizations in which 
not all individual rays in a packet have to be considered in each traversal step. For example, two out 
of the three traversal cases could be accelerated by only looking at the corner rays of a packet29 . 
Similarly, the e.ciency of the SSE code could probably be increased by larger packets, as any setup cost 
(such as fetching triangle data) could be amortized over more rays. Though larger packets obviously su.er 
from decreased coherence, this may be o.set by the continuing trend towards higher image resolutions. 
Furthermore, it has to be investigated how the ideas that have proven so successful in accelerating ray 
tracing for polygonal scenes could also be employed for other kind of ray tracing primitives, such as 
volumetric objects, isosurfaces, or parameteric patches. Finally, it has to be investigated how much 
it is possible to further improve the quality of the BSP trees. While the average number of triangles 
hit by a ray is close to the optimum (see Table 5), it may still be possible to further reduce the number 
of traversal steps. References [AMD] Advanced Micro Devices. Software Optimization Guide for AMD Athlon(tm) 
64 and AMD Opteron(tm) 29For primary rays, it is obvious to de.ne the corner rays for a packet. For secondary 
rays, the corner rays could be de.ned by the corners of an imaginary shaft bounding the rays. Processors. 
Available from http://www.amd.com/usen/Processors/TechnicalResources/. [Badouel92] Didier Badouel. An 
E.cient Ray Polygon Intersection. In David Kirk, editor, Graphics Gems III, pages 390 393. Academic 
Press, 1992. ISBN: 0124096735. [Carey97] Rikk Carey, Gavin Bell, and Chris Marrin. ISO/IEC 147721:1997 
Virtual Reality Modelling Language (VRML97), April 1997. http://www.vrml.org/Speci.cations/VRML97. [Erickson97] 
Je. Erickson. Pluecker Coordinates. Ray Tracing News, 1997. http://www.acm.org/tog/resources/RTNews/html/rtnv10n3.html#art11. 
[Glassner89] Andrew Glassner. An Introduction to Ray Tracing. Morgan Kaufmann, 1989. ISBN 0-12286-160-4. 
[Goldsmith87] Je.rey Goldsmith and John Salmon. Automatic Creation of Object Hierarchies for Ray Tracing. 
IEEE Computer Graphics and Applications, 7(5):14 20, May 1987. [Haines91] Eric Haines. E.ciency Improvements 
for Hierarchy Traversal in Ray Tracing. In James Arvo, editor, Graphics Gems II, pages 267 272. Academic 
Press, 1991. [Havran97] Vlastimil Havran. Cache Sensitive Representation for the BSP Tree. In Compugraphics 
97, pages 369 376. GRASP Graphics Science Promotions &#38; Publications, December 1997. [Havran99] 
Vlastimil Havran. Analysis of Cache Sensitive Representation for Binary Space Partitioning Trees. Informatica, 
23(3):203 210, May 1999. ISSN: 0350-5596. [Havran00] Vlastimil Havran, Jan Prikryl, and Werner Purgathofer. 
Statistical Comparison of Ray-Shooting E.ciency Schemes. Technical Report TR-186-2-00-14, Department 
of Computer Science, Czech Technical University; Vienna University of Technology, July 2000. [Havran01] 
Vlastimil Havran. Heuristic Ray Shooting Algorithms. PhD thesis, Faculty of Electrical Engineering, Czech 
Technical University in Prague, 2001. [Hurley02] James T. Hurley, Alexander Kapustin, Alexander Reshetov, 
and Alexei Soupikov. Fast Ray Tracing for Modern General Purpose CPU. In Proceedings of Graphicon, 2002. 
Available from http://www.graphicon.ru/2002/papers.html. 33 [Intel] Intel Corp. Intel Computer Based 
Tutorial. http://developer.intel.com/vtune/cbts/cbts.htm. [Keller98] Alexander Keller. Quasi-Monte Carlo 
Methods for Realistic Image Synthesis. PhD thesis, University of Kaiserslautern, 1998. [MacDonald89] 
J. David MacDonald and Kellogg S. Booth. Heuristics for Ray Tracing using Space Subdivision. In Proceedings 
of Graphics Interface 89, pages 152 63, Toronto, Ontario, June 1989. Canadian Information Processing 
Society. [MacDonald90] J. David MacDonald and Kellogg S. Booth. Heuristics for Ray Tracing using Space 
Subdivision. Visual Computer, 6(6):153 65, 1990. [Moller] Tomas Moller. Practical Analysis of Optimized 
Ray-Triangle Intersection. http://www.ce.chalmers.se/sta./tomasm/raytri/. [Moller97] Tomas Moller 
and Ben Trumbore. Fast, minimum storage ray triangle intersection. Journal of Graphics Tools, 2(1):21 
28, 1997. [Pharr97] Matt Pharr, Craig Kolb, Reid Gershbein, and Pat Hanrahan. Rendering Complex Scenes 
with Memory-Coherent Ray Tracing. Computer Graphics, 31(Annual Conference Series):101 108, August 1997. 
[Shirley03] Peter Shirley and R. Keith Morley. Realistic Ray Tracing. A K Peters, Second edition, 2003. 
ISBN 1-56881-198-5. [Shoemake98] Ken Shoemake. Pluecker Coordinate Tutorial. Ray Tracing News, 1998. 
http://www.acm.org/tog/resources/RTNews/ html/rtnv11n1.html#art3. [Subramanian90] K. R. Subramanian. 
A Search Structure based on K-d Trees for E.cient Ray Tracing. PhD thesis, The University of Texas at 
Austin, December 1990. [Wald01] Ingo Wald, Philipp Slusallek, Carsten Benthin, and Markus Wagner. Interactive 
Rendering with Coherent Ray Tracing. Computer Graphics Forum, 20(3):153 164, 2001. (Proceedings of Eurographics). 
[Wald03] Ingo Wald, Timothy J. Purcell, Jorg Schmittler, Carsten Benthin, and Philipp Slusallek. Realtime 
Ray Tracing and its use for Interactive Global Illumination. In Eurographics State of the Art Reports, 
2003. 34 [Wald04] Ingo Wald. Realtime Ray Tracing and Interactive Global Illumination. PhD thesis, Computer 
Graphics Group, Saarland University, 2004. Available at http://www.mpisb.mpg.de/~wald/PhD/. [Woop05] 
Sven Woop, Joerg Schmittler, and Philipp Slusallek. RPU: A Programmable Ray Processing Unit for Realtime 
Ray Tracing. Proceedings of ACM SIGGRAPH, (to appear), 2005.  
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198745</article_id>
		<sort_key>6</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Efficiency issues for ray tracing]]></title>
		<page_from>6</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198745</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198745</url>
		<abstract>
			<par><![CDATA[Ray casting is the bottleneck of many rendering algorithms. Although much work has been done on making ray casting more efficient, most published work is high level. This paper discusses efficiency at a slightly lower level, presenting optimizations for bounding volume hierarchies that many people use but are rarely described in the literature. A set of guidelines for optimization are presented that avoid some of the common pitfalls. Finally, the effects of the optimizations are shown for a set of models.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP31044610</person_id>
				<author_profile_id><![CDATA[81408593457]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Brian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Smits]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Arnaldi, B., Priol, T., and Bouatouch, K. A new space subdivision method for ray tracing CSG modelled scenes. The Visual Computer 3, 2 (Aug. 1987), 98--108.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>539147</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bentley, J. L. Writing Efficient Programs. Prentice-Hall, Englewood Cliffs, NT, 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>59935</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bentley, J. L. Programming Pearls (reprinted with corrections). Addison-Wesley, Reading, MA, USA, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>13044</ref_obj_id>
				<ref_obj_pid>13043</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Fujimoto, A., Tanaka, T., and Iwata, K. Arts: Accelerated ray-tracing system. IEEE Computer Graphics and Applications (Apr. 1986), 16--26.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>94788</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Glassner, A., Ed. An Introduction to Ray Tracing. Academic Press, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>31469</ref_obj_id>
				<ref_obj_pid>31468</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Goldsmith, J., and Salmon, J. Automatic creation of object hierarchies for ray tracing. IEEE Computer Graphics and Applications 7, 5 (May 1987), 14--20.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Haines, E. Efficiency improvements for hierarchy traversal. In Graphics Gems II, J. Arvo, Ed. Academic Press, San Diego, 1991, pp. 267--273.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15916</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kay, T. L., and Kajiya, J. T. Ray tracing complex scenes. In Computer Graphics (SIGGRAPH '86 Proceedings) (Aug. 1986), D. C. Evans and R. J. Athay, Eds., vol. 20, pp. 269--278.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>129057</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Knuth, D. E. Literate Programming. CSLI Lecture Notes Number 27. Stanford University Center for the Study of Language and Information, Stanford, CA, USA, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807479</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Rubin, S. M., and Whitted, T. A 3-dimensional representation for fast rendering of complex scenes. Computer Graphics 14, 3 (July 1980), 110--116.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>90874</ref_obj_id>
				<ref_obj_pid>90767</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Woo, A. Fast ray-box intersection. In Graphics Gems, A. S. Glassner, Ed. Academic Press, San Diego, 1990, pp. 395--396.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Ef.ciency Issues for Ray Tracing Brian Smits University of Utah February 19, 1999 Abstract Ray casting 
is the bottleneck of many rendering algorithms. Although much work has been done on making ray casting 
more ef.cient, most published work is high level. This paper discusses ef.ciency at a slightly lower 
level, presenting optimizations for bounding volume hierarchies that many people use but are rarely described 
in the literature. A set of guidelines for optimization are presented that avoid some of the common pitfalls. 
Finally, the effects of the optimizations are shown for a set of models. Introduction Many realistic 
rendering systems rely on ray casting algorithms for some part of their computation. Often, the ray casting 
takes most of the time in the system, and signi.cant effort is usually spent on making it more ef.cient. 
Much work has been done and published on acceleration strategies and ef.cient algorithms for ray casting, 
the main ideas of which are summarized in Glassner [5]. In addition, many people have developed optimizations 
for making these algorithms even faster. Much of this work remains unpublished and part of oral history. 
This paper is an attempt to write down some of these techniques and some higher level guidelines to follow 
when trying to speed up ray casting algorithms. I learned most of the lessons in here the hard way, either 
by making the mistakes myself, or by tracking them down in other systems. Many of the observations in 
here were con.rmed by others. This paper will discuss some mid-level optimization issues for bounding 
volume hierarchies. The ray casting algorithm uses the hierarchy to determine if the ray intersects 
an object. An intersection involves computing the distance to the intersection and the intersection point 
as well as which object was hit. Sometimes it includes computing surface normal and texture coordinates. 
The information computed during an intersection is sometimes called the hit information. In ray tracing 
based renderers, rays from the eye are called primary rays. Re.ected and transmitted rays are known as 
secondary rays. Together, these rays are called intersection rays. Rays from hits to lights to determine 
shadowing are called shadow rays. bes@cs.utah.edu 2 Principles of Optimization Optimization can be a 
seductive activity leading to endless tweaks and changes of code. The most important part of optimization 
is knowing when not to do it. Two common cases are: .Code or system is not run frequently. .Code is 
a small fraction of overall time.  In other words, code should only be optimized if it will make a signi.cant 
effect on the .nal system and the .nal system will be used frequently enough to justify the programmer 
s time and the chance of breaking something. It helps to have a set of principles to follow in order 
to guide the process of optimization. The set I use is: .Make it work before you make it fast. .Pro.le 
everything you do. .Complexity is bad. .Preprocessing is good. .Compute only what you need. 2.1 Make 
it Work Before You Make it Fast Code should be made correct before it is made fast [2]. As stated repeatedly 
by Knuth [9] Premature optimization is the root of all evil . Obviously, slow correct code is more useful 
than fast broken code. There is an additional reason for the rule, though. If you create a working, unoptimized 
version .rst, you can use that as a benchmark to check your optimizations against. This is very important. 
Putting the optimizations in early means you can never be completely sure if they are actually speeding 
up the code. You don t want to .nd out months or years later that your code could be sped up by removing 
all those clever optimizations. 2.2 Pro.le Everything You Do It is important to .nd out what the bottleneck 
is before trying to remove it. This is best done by pro.ling the code before making changes [3]. The 
best pro.lers give time per line of code as well as per function. They also tell you how many times different 
routines are called. Typically what this will tell you is that most of the time is spent intersecting 
bounding boxes, something that seems to be universally true. It also can tell you how many bounding boxes 
and primitives are checked. Like many algorithms, the speed will vary based on the input. Obviously large 
data sets tend to take more time than small ones, but the structure of the models you use for benchmarking 
is also important. Ideally you use a set of models that are characteristic of the types of models you 
expect to use. Pro.ling is especially critical for low-level optimizations. Intuition is often very wrong 
about what changes will make the code faster and which ones the compiler was already doing for you. Compilers 
are good at rearranging nearby instructions. They are bad at knowing that the value you are continually 
reading through three levels of indirection is constant. Keeping things clean and local makes a big difference. 
This paper makes almost no attempt to deal with this level of optimization. 2.3 Complexity is Bad Complexity 
in the intersection algorithm causes problems in many ways. The more complex your code becomes, the more 
likely it is to behave unexpectedly on new data sets. Additionally, complexity usually means branching, 
which is signi.cantly slower than similar code with few branches. If you are checking the state of something 
in order to get out of doing work, it is important that the amount of work is signi.cant and that you 
actually get out of doing the work often enough to justify the checks. This is the argument against the 
caches used in Section 4.4. 2.4 Preprocessing is Good In many of the situations where ray casting is 
used, it is very common to cast hundreds of millions of rays. This usually takes a much longer time than 
it took to build the ray tracing data structures. A large percentage increase in the time it takes to 
build the data structures may provide a signi.cant win even if the percentage decrease in the ray casting 
time of each ray is much smaller. Ideally you increase the complexity and sophistication of the hierarchy 
building stage in order to reduce the complexity and number of intersections computed during the ray 
traversal stage. This principle motivates Section 4.3. 2.5 Compute Only What You Need There are many 
different algorithms for many of the components of ray casting. Often there are different algorithms 
because different information is needed out of them. Much of the following discussion will be based on 
the principle of determining the minimum amount of information needed and then computing or using that 
and nothing more. Often this results in a faster algorithm. Examples of this will be shown in Sections 
4.1 and 4.2.  3 Overview of Bounding Volume Hierarchies A bounding volume hierarchy is simply a tree 
of bounding volumes. The bounding volume at a given node encloses the bounding volumes of its children. 
The bounding volume of a leaf encloses a primitive. If a ray misses the bounding volume of a particular 
node, then the ray will miss all of its children, and the children can be skipped. The ray casting algorithm 
traverses this hierarchy, usually in depth .rst order, and determines if the ray intersects an object. 
BoundingVolume BuildHierarchy(bvList, start, end, axis) if(end -start == 0) // only a single bv in list 
so return it. return bvList[start] BoundingVolume parent foreach bv in bvList expand parent to enclose 
bv sort bvList along axis axis = next axis parent.AddChild(BuildHierarchy(bvList, start, (start + end) 
/ 2, axis) parent.AddChild(BuildHierarchy(bvList, 1 + (start + end) / 2, end, axis) return parent Figure 
1: Building a bounding volume hierarchy recursively. There are several ways of building bounding volume 
hierarchies [6, 10]. The simplest way to build them is to take a list of bounding volumes containing 
the primitives and sort along an axis[8]. Split the list in half, put a bounding box around each half, 
and then recurse, cycling through the axes as you recurse. This is expressed in pseudocode in Figure 
1. This method can be modi.ed in many ways to produce better hierarchies. A better way to build the hierarchy 
is to try to minimize the cost functions described by Goldsmith and Salmon [6]. 4 Optimizations for 
Bounding Volume Hierarchies 4.1 Bounding Box Intersections Intersecting rays with bounding volumes usually 
accounts for most of the time spent casting rays. This makes bounding volume intersection tests an ideal 
candidate for optimization. The .rst issue is what sort of bounding volumes to use. Most of the environments 
I work with are architectural and have many axis-aligned planar surfaces. This makes axis-aligned bounding 
boxes ideal. Spheres tend not to work very well for this type of environment. There are many ways to 
represent and intersect an axis-aligned bounding box. I have seen bounding box code that computed the 
intersection point of the ray with the box. If there was an intersection point, the ray hits the box, 
and if not, the ray misses. There are optimizations that can be made to this approach, such as making 
sure you only check faces that are oriented towards the ray, and taking advantage of the fact that the 
planes are axis aligned [11]. Still, the approach is too slow. The .rst hint of this is that the algorithm 
computes an intersection point. We don t care about that, we just want a yes or no answer. Kay [8] represented 
bounding volumes as the intersection of a set of slabs (parallel planes). A slab is stored as a direction,, 
and an interval, , representing the minimum and maximum value in that direction, effectively as two 
plane equations. The set of slab directions is .xed in advance. In my experience, this approach is most 
effective when there are three, axis aligned, slab directions. This is just another way of storing a 
bounding box, we store minimum and maximum values bool RaySlabsIntersection(ray, bbox) Interval inside 
= ray.Range() for i in (0,1,2) inside = Intersection(inside,(slab[i].Range()-ray.Origin[i])/ray.Direction[i]) 
if(inside.IsEmpty()) return false return true Figure 2: Pseudocode for intersecting a ray with a box 
represented as axis aligned slabs. along each axis. Given this representation, we can intersect a bounding 
box fairly ef.ciently. We show this in pseudocode in Figure 2. This code isn t as simple as it looks 
due to the comparisons of the IsEmpty and Intersection functions and the need to reverse the min and 
max values of the interval when dividing by a negative number, but it is still much faster than computing 
the intersection point with the box. One important thing to notice about this representation and this 
intersection code is that it gives the right answer when the ray direction is 0 for a particular component. 
In this case the ray is parallel to the planes of the slab. The divide by zero gives either I nbayzsnbagaI 
epayz epaga I nbayz epaga or when the ray is outside the slab and when the ray is inside. This saves 
additional checks on the ray direction.  4.2 Intersection Rays versus Shadow Rays It is important to 
know what kind of information you need from the ray casting algorithm in order to keep from doing more 
work than necessary. There are three commonly used ray casting queries: closest hit, any hit, and all 
hits. Closest hit is used to determine the .rst object in a given direction. This query is usually used 
for primary, re.ected, and transmitted rays. Any hit is used for visibility tests between two points. 
This is done when checking to see if a point is lit directly by a light and for visibility estimation 
in radiosity algorithms. The object hit is not needed, only the existence of a hit. All hits is used 
for evaluating CSG models directly. The CSG operations are performed on the list of intervals returned 
from the all hits intersection routine. For ef.ciency reasons it is important to keep these queries separate. 
This can be seen by looking at what happens when using the most general query, all hits, to implement 
the others. Any hit will simply check to see if the list of intersections is empty. Clearly we computed 
more than we needed in this case. Closest hit will sort the list and return the closest intersection. 
It may seem as if the same or more work is needed for this query, however this is usually not the case. 
With most ray tracing ef.ciency schemes, once an intersection is found, parts of the environment beyond 
the intersection point can be ignored. Finding intersections usually speeds up the rest of the traversal. 
Also, the list of hit data does not need to be maintained. Shadow (any hit) rays are usually the most 
common type of rays cast, often accounting for more than 90 percent of all rays. Because of this, it 
is worth considering how to make them faster than other types of rays. Shadow rays need not compute any 
Figure 3: Three different representations for a tree. (a) Children pointers. (b) Left child, right sibling, 
parent pointers. (c) Array in depth-.rst order with skip pointers. of the commonly needed intersection 
information, such as intersection point, surface normal, uv coordinates, or exact object hit. Additionally, 
the traversal of the ef.ciency structure can be terminated immediately once an intersection is guaranteed. 
A special shadow routine taking these factors into account can make a signi.cant difference in ef.ciency. 
The difference between shadow rays and intersection rays determined which acceleration scheme I use. 
I have tried both grids [4] and bounding volume hierarchies. In my experience (based on models I typically 
render) grids are a little faster on intersection rays (closest hit) and slower for shadow rays (any 
hit). Grids sort the environment spatially, which is good for .nding the closest intersection. The bounding 
volume hierarchies built by trying to minimize Goldsmith and Salmon s cost function [6] tend to keep 
larger primitives near the root, which is good for shadow rays. It is still unknown as to which acceleration 
scheme is better, and it is almost certainly based on the model. 4.3 Traversal Code Casting a ray against 
a bounding volume hierarchy requires traversing the hierarchy. If a ray hits a bounding volume, then 
the ray is checked against the children of the bounding volume. If the bounding volume is a leaf, then 
it has an object inside it, and the object is checked. This is done in depth-.rst order. Once bounding 
volume intersection tests are as fast as they can be, the next place for improvement is the traversal 
of the hierarchy. Traversal code for shadow rays will be used in the following discussion. In 1991, Haines[7] 
published some techniques for better traversals. Several of these techniques used extra knowledge to 
mark bounding boxes as automatically hit and to change the order of traversal. In my experience these 
methods do not speed up the ray tracer and greatly increase the complexity of the code. This difference 
in experience may be due to changes in architecture over the last 8 years that make branches and memory 
accesses instead of .oating point the bottleneck. It may also be due to faster bounding box tests. I 
have found that the best way to make the traversal fast is to make it as minimal as possible. The simplest 
traversal code is to use recursion to traverse the tree in depth-.rst order. Figure 3(a) shows a hierarchy 
of bounding boxes. Depth .rst traversal means that bounding box A is tested, then box B, then the boxes 
with primitives D, E, and F. The idea is to .nd an intersection as soon as possible by traveling down 
into the tree. The TreeShadowTraversal(ray, bvNode) while(true) // termination occurs when bvNode GetParent() 
is NULL if(bvNode Intersect(ray)) if(bvNode HasPrimitive()) if(bvNode Primitive().Intersect(ray)) return 
true else bvNode = bvNode GetLeftChild() continue while(true) if(bvNode GetRightSibling() != NULL) bvNode 
= bvNode GetRightSibling() break bvNode = bvNode GetParent() if(bvNode == NULL) return false Figure 
4: Traversal of bounding volume tree using left child, right sibling, parent structure. biggest problem 
with this is the function call overhead. The compiler maintains much more state information than we need 
here. We can eliminate much of this overhead by changing our representation of the tree. A representation 
that works well is to store the left-most child, the right sibling, and the parent for each node, as 
in Figure 3. Using this representation we can get rid of the recursion by following the appropriate pointers. 
If the ray intersects the bounding box, we get to its children by following the left-most child link. 
If the ray misses, we get to the next node by following the right sibling link. If the right sibling 
is empty, we move up until either there is a right sibling, or we get back up to the root, as shown in 
pseudocode in Figure 4. This tree traversal also does too much work. Notice that when the traversal is 
at a leaf or when the ray misses a bounding volume, we compute the next node. The next node is always 
the same, there is no reason to be computing it for each traversal. We can pre-compute the node we go 
to when we skip this subtree and store this skip node in each node. This step eliminates all computation 
of traversal related data from the traversal. There are still intersection computations, but no extra 
computation for determining where to go. This is expressed in pseudocode in Figure 5 The .nal optimization 
is the recognition that we only need to do depth-.rst traversals on the tree once it is built. This 
observation lets us store the tree in an array in depth-.rst order as in Figure 3. If the bounding volume 
is intersected, the next node to try is the next node in the array. If the bounding volume is missed, 
the next node can be found through the skip mechanism. We have effectively thrown out all the information 
we don t need out of the tree, although it is still possible to reconstruct it. The traversal code can 
be seen in Figure 6. The array traversal approach works signi.cantly better than the previous one, and 
has a couple subtle advantages. The .rst is better memory usage. In addition to the SkipTreeShadowTraversal(ray, 
bvNode) while(bvNode != NULL) if(bvNode Intersect(ray)) if(bvNode HasPrimitive()) if(bvNode Primitive().Intersect(ray)) 
return true bvNode = bvNode SkipNode() else bvNode = bvNode GetLeftChild() else bvNode = bvNode SkipNode() 
 return false Figure 5: Traversal of bounding volume tree using left child, and skip pointers. ArrayShadowTraversal(ray, 
bvNode) stopNode = bvNode GetSkipNode() while(bvNode .stopNode) if(bvNode Intersect(ray)) if(bvNode HasPrimitive()) 
if(bvNode Primitive().Intersect(ray)) return true bvNode++ else bvNode = bvNode GetSkipNode() return 
false Figure 6: Traversal of bounding volume tree stored as an array in depth-.rst order. bounding volume, 
this method requires only a pointer to a primitive and a pointer to the skip node. This is very minimal. 
Since the nodes are arranged in the order they will be accessed in, there is more memory coherency for 
large environments. The second advantage is that this method requires copying data from the original 
tree into an array. Since the original tree is going to be thrown out, it can be augmented with extra 
information. Depending upon how the tree is created, this extra information can more than double the 
cost of each node. Now there is no penalty for this information. Storing the extra information can reduce 
the time to build the tree and more importantly can result in better trees. The fastest bounding volume 
test is the one you don t have to do.  4.4 Caching Objects One common optimization is the use of caches 
for the object most recently hit. This optimization and variations on it were discussed by Haines[7]. 
The idea is that the next ray cast will be similar to the current ray, so keep the intersected object 
around and check it .rst the next time. To the extent that this is true, caches can provide a bene.t, 
however rays often differ wildly. Also, cache effectiveness decreases as the size of the primitives get 
smaller. The realism of many types of models is increased by replacing single surfaces with many surfaces. 
Now caches will remain valid for a shorter amount of time. There are two different types of caches, those 
for intersection (closest hit) rays and those for shadow (any hit) rays. If caches are used for intersection 
rays, the ray will still need to be checked against the environment to see if another object is closer. 
Usually the ray will again be checked against whatever object is in the cache. Mailboxes [1] can eliminate 
this second check (by marking each tested object with a unique ray id and then checking the id before 
testing the primitive). Mailboxes, however, create problems when making a parallel version of the code. 
Depending on the environment and the average number of possible hits per ray, the cache may reduce the 
amount of the environment that must be checked by shortening the ray length. In my experience, the cost 
of maintaining the cache and the double intersection against an object in it more than outweighs the 
bene.t of having a cache. If your primitives are very expensive and your environments are dense, the 
bene.t of reducing the length of the ray early may outweigh the costs, but it is worth checking carefully. 
Evaluating the bene.t of caches for shadow rays is more complicated. In cases where there is a single 
light, there tends to be a speedup as long as the cache remains full much of the time and the objects 
in it stay there for a long enough time. In cases where there are multiple lights we often lose shadow 
ray coherence because the lights are in different regions of the environment. Now each shadow ray is 
signi.cantly different from the previous one. A solution for this is to have a different cache for each 
light. For both types of caches, we have ignored what happens for re.ected and transmitted rays. These 
rays are spatially very different from primary rays and from each other. Each additional bounce makes 
the problem much worse. If rays are allowed to bounceE n a times, there are 2 d +l different nodes in 
the ray tree. In order for caching to be useful, a separate cache needs to be associated with each node. 
For shadow rays, that means a separate cache for each light at each node This can increase the complexity 
of the code signi.cantly. Another option is to store a cache for each light on each object (or collection 
of objects) in the environment as discussed by Haines[7]. Note that caching only helps when there is 
an object in the cache. If most shadow rays won t hit anything (due to the model or the type of algorithm 
using the shadow tests) then the cache is less likely to be bene.cial. In my experience, shadow caching 
wasn t a signi.cant enough gain, so I opted for simplicity of code and removed it, although after generating 
the data for the result section I am considering putting it back in for certain situations. Others have 
found that caches are still bene.cial.  Results Now we look at the cumulative effects for shadow rays 
of the three main optimizations described in the paper. First we speed up bounding box tests. Next we 
speed up the traversal using the different methods from Section 4.3. We then treat shadow rays differently 
from intersection rays and lastly we add a shadow cache. In all of the Table 1: Results of the different 
experiments described in the text on different environments. Times rounded to the nearest second. 1 
2 3 4 5 6 7 8 theater 64 36 30 21 22 11 10 6 lab 79 41 32 22 20 12 12 7 10,000 small 415 223 191 142 
110 48 50 27 10,000 mid 392 185 154 103 81 77 79 65 10,000 big 381 179 152 104 82 79 77 69 100,000 small 
995 620 550 449 351 62 63 33 100,000 mid 932 473 424 324 230 146 148 89 100,000 big 1024 508 442 332 
240 210 212 156 300,000 mid 1093 597 536 421 312 120 121 64 experiments 1,000,000 rays are generated 
by choosing random pairs of points from within a bounding box 20% larger than the bounding box of the 
environment. In the last experiment, 500,000 rays are generated, each generated ray is cast twice, resulting 
in 1,000,000 rays being cast overall. The .rst two test cases are real environments, the rest are composed 
of randomly oriented and positioned unit right triangles. The number gives the number of triangles. Small, 
mid, and big refer to the space the triangles .ll. Small environments are 20 units cubed, mid are 100 
units cubed, and big are 200 units cubed. The theater model has 46502 polygons. The science center model 
has 4045 polygons. The code was run on an SGI O2 with a 180 MHz R5000 using the SGI compiler with full 
optimization turned on1. No shading or other computation was done and time to build the hierarchies was 
not included. The experiments reported in Table 1 are explained in more detail below: 1. Bounding box 
test computes intersection point, traversal uses recursion, and shadow rays are treated as intersection 
rays. 2. Bounding box test replaced by slab version from Section 4.1. 3. Recursive traversal replaced 
by iterative traversal using left child, right sibling, and parent pointers as in Section 4.3. 4. Skip 
pointer used to speed up traversal as in Section 4.3. 5. Tree traversal replaced by array traversal 
as in Section 4.3. 6. Intersection rays replaced by shadow rays as in Section 4.2. 7. Shadow caching 
used as in Section 4.4. 8. Shadow caching used, but each ray checked twice before generating a new ray. 
The same number of checks were performed.  1-Ofast=ip32 5k The .rst thing to notice is that real models 
require much less work than random polygons. This is because the polygons are distributed very unevenly 
and vary greatly in size. The theater has a lot more open space and even more variation in polygon size 
than the lab, resulting in many inexpensive rays and a faster average time. In spite of this, the results 
show very similar trends for all models. In the .rst 5 experiments we haven t used any model-speci.c 
knowledge, we have just reduced the amount of work done. Special shadow rays and caching are more model 
speci.c. Shadow rays are more effective when there are many intersections along the ray and are almost 
the same when there is zero or one intersection. Shadow caching is based on ray coherence and the likelihood 
of having an intersection. In experiment 7 there is an unrealistically low amount of coherence (none). 
In experiment 8 we guaranteed that there would be signi.cant coherence by casting each ray twice. 6 Conclusions 
The optimization of ray casting code is a double-edged sword. With careful pro.ling it can result in 
signi.cant speedups. It can also lead to code that is slower and more complicated. The optimizations 
presented here are probably fairly independent of the computer architecture. There are plenty of signi.cant 
lower level optimizations that can be made which may be completely dependent upon the speci.c platform. 
If you plan on porting your code to other architectures, or even keeping your code for long enough that 
the architecture changes under you, these sorts of optimizations should be made with care. Eventually 
you get to a point where further optimization makes no signi.cant difference. At this point you have 
no choice but to go back and try to create better trees requiring fewer primitive and bounding box tests, 
or to look at entirely different acceleration strategies. Over time, the biggest wins come from better 
algorithms, not better code tuning. The results presented here should be viewed as a case study. They 
describe some of what has worked for me on the types of models I use. They may not be appropriate for 
the types of models you use. 7 Acknowledgments Thanks to Peter Shirley, Jim Arvo, and Eric Haines for 
many long discussions on ray tracing. Thanks to Peter and Eric for encouraging me to write up these experiences, 
and to both of them and Bill Martin for helpful comments on the paper. This work was partially funded 
by Honda and NSF grant ACI-97-20192.  References [1] ARNALDI, B., PRIOL, T., AND BOUATOUCH, K. A new 
space subdivision method for ray tracing CSG modelled scenes. The Visual Computer 3, 2 (Aug. 1987), 98 
108. [2] BENTLEY, J. L. Writing Ef.cient Programs. Prentice-Hall, Englewood Cliffs, NJ, 1982. [3] BENTLEY, 
J. L. Programming Pearls (reprinted with corrections). Addison-Wesley, Reading, MA, USA, 1989. [4] FUJIMOTO, 
A., TANAKA, T., AND IWATA, K. Arts: Accelerated ray-tracing system. IEEE Computer Graphics and Applications 
(Apr. 1986), 16 26. [5] GLASSNER, A., Ed. An Introduction to Ray Tracing. Academic Press, 1989. [6] GOLDSMITH, 
J., AND SALMON, J. Automatic creation of object hierarchies for ray tracing. IEEE Computer Graphics and 
Applications 7, 5 (May 1987), 14 20. [7] HAINES, E. Ef.ciency improvements for hierarchy traversal. In 
Graphics Gems II, J. Arvo, Ed. Academic Press, San Diego, 1991, pp. 267 273. [8] KAY, T. L., AND KAJIYA, 
J. T. Ray tracing complex scenes. In Computer Graphics (SIGGRAPH 86 Proceedings) (Aug. 1986), D. C. Evans 
and R. J. Athay, Eds., vol. 20, pp. 269 278. [9] KNUTH, D. E. Literate Programming. CSLI Lecture Notes 
Number 27. Stanford University Center for the Study of Language and Information, Stanford, CA, USA, 
1992. [10] RUBIN, S. M., AND WHITTED, T. A 3-dimensional representation for fast rendering of complex 
scenes. Computer Graphics 14, 3 (July 1980), 110 116. [11] WOO, A. Fast ray-box intersection. In Graphics 
Gems, A. S. Glassner, Ed. Academic Press, San Diego, 1990, pp. 395 396. 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198746</article_id>
		<sort_key>7</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Fast, minimum storage ray/triangle intersection]]></title>
		<page_from>7</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198746</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198746</url>
		<abstract>
			<par><![CDATA[We present a clean algorithm for determining whether a ray intersects a triangle. The algorithm translates the origin of the ray and then changes the base of that vector which yields a vector (<i>t u v</i>)<sup><i>T</i></sup>, where <i>t</i> is the distance to the plane in which the triangle lies and (<i>u, v</i>) represents the coordinates inside the triangle.One advantage of this method is that the plane equation need not be computed on the fly nor be stored, which can amount to significant memory savings for triangle meshes. As we found our method to be comparable in speed to previous methods, we believe it is the fastest ray/triangle intersection routine for triangles which do not have precomputed plane equations.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[base transformation]]></kw>
			<kw><![CDATA[intersection]]></kw>
			<kw><![CDATA[ray tracing]]></kw>
			<kw><![CDATA[ray/triangle-intersection]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP31025774</person_id>
				<author_profile_id><![CDATA[81100071413]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[M&#246;ller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chalmers University of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P28702</person_id>
				<author_profile_id><![CDATA[81100244169]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ben]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Trumbore]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{Arenberg88} Jeff Arenberg, Re: Ray/Triangle Intersection with Barycentric Coordinates, in Ray Tracing News, edited by Eric Haines, Vol. 1, No. 11, November 4, 1988, http://www.acm.org/tog/resources/RTNews/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>90867</ref_obj_id>
				<ref_obj_pid>90767</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{Badouel90} Didier Badouel, An Efficient Ray-Polygon Intersection, in Graphics Gems, edited by Andrew S. Glassner, Academic Press Inc., 1990, pp. 390--393.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>180899</ref_obj_id>
				<ref_obj_pid>180895</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{Haines94} Eric Haines, Point in Polygon Strategies, in Graphics Gems IV, edited by Paul S. Heckbert, AP Professional, 1994, pp. 24--46.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{Patel96} Edward Patel, personal communication, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{Shirley96} Peter Shirley, personal communication, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198747</article_id>
		<sort_key>8</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Fast 3D triangle-box overlap testing]]></title>
		<page_from>8</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198747</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198747</url>
		<abstract>
			<par><![CDATA[A fast routine for testing whether a triangle and a box are overlapping in three dimensions is presented. The test is derived using the separating axis theorem, whereafter the test is simplified and the code is optimized for speed. We show that this approach is 2.3 vs. 3.8 (PC vs. Sun) times faster than previous routines for this. It can be used for faster collision detection and faster voxelization in interactive ray tracers. The code is available online.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P339062</person_id>
				<author_profile_id><![CDATA[81100093806]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Akenine-M&#246;ller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chalmers University of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1214590</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Eberly, David, 3D Game Engine Design: A Practical Approach to Real-Time Computer Graphics, Morgan Kaufmann Publishers Inc., San Francisco, 2000. http://www.magic-software.com/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Graphics Gems III Errata Listing, http://www.graphicsgems.org/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237244</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Gottschalk, S., M. C. Lin, and D. Manocha, "OBBTree: A Hierarchical Structure for Rapid Interference Detection," Computer Graphics (SIGGRAPH '96 Proceedings), pp. 171--180, August, 1996. http://www.cs.unc.edu/~geom/OBB/OBBT.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Green, D. and D. Hatch, "Fast Polygon-Cube Intersection Testing," in Alan Paeth, ed., Graphics Gems V, AP Professional, Boston, pp. 375--379, 1995. http://www.graphicsgems.org/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Haines, Eric, and John Wallace, "Shaft Culling for Efficient Ray-Traced Radiosity," in P. Brunet and F. W. Jansen, eds., Photorealistic Rendering in Computer Graphics (Proceedings of the Second Eurographics Workshop on Rendering), Springer-Verlag, New York, pp. 122--138, 1994. http://www.acm.org/tog/editors/erich/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M&#246;ller, Tomas, and Eric Haines, Real-Time Rendering, AK Peters Ltd., Natick, MA, 1999. http://www.realtimerendering.com/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Terdiman, Pierre, Personal communication, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>130785</ref_obj_id>
				<ref_obj_pid>130745</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Voorhies, Douglas, "Triangle-Cube Intersection," in David Kirk, ed., Graphics Gems III, AP Professional, Boston, pp. 236--239, 1992. http://www.graphicsgems.org/]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Fast 3D Triangle-Box Overlap Testing Tomas Akenine-Moller* Department of Computer Engineering, Chalmers 
University of Technology March 2001, updated June 2001 Abstract A fast routine for testing whether a 
triangle and a box are overlapping in three dimensions is presented. The test is derived using the separating 
axis theorem, whereafter the test is simpli.ed and the code is optimized for speed. We show that this 
approach is 2.3 vs. 3.8 (PC vs. Sun) times faster than previous routines for this. It can be used for 
faster collision detection and faster voxelization in interactive ray tracers. The code is available 
online. 1 Introduction Testing whether a triangle overlaps a box is an important routine to have in a 
graphics programmer s toolbox. For example, the test can be used to voxelize triangle meshes in ray tracers, 
and it can be used in collision detection algorithms that are based on boxes [3]. Gottschalk et al s 
collision detection framework only used OBB/OBB tests and triangle-triangle tests. However, it has been 
noted that both memory and speed can be gained [7] by not having an OBB around each triangle, and instead 
test a triangle against an OBB. Previously, Voorhies has presented code for testing a triangle against 
a unit cube centered at the origin [8]. His test tries to eliminate work by doing some simple acceptance/rejection 
tests early on, and then testing each triangle edge for intersection with the cube faces. Finally, he 
checks whether the interior of the triangle is penetrated by the cube. Green and Hatch [4] improve on 
the e.ciency of Voorhies work and generalize it to handle arbitrary polygons as well. They also use fast 
acceptance/rejectance tests, but recast the testing of an edge against the cube into testing a point 
against a skewed rhombic dodecahedron, which is more robust. Finally, they test whether one diagonal 
of the cube intersect the polygon, which further improves the e.ciency. *Previously known as Tomas Moller. 
 2 Derivation and Optimization Our test is derived from the separating axis theorem (SAT) [1, 3, 6]. 
The theorem states that two convex polyhedra, A and B, are disjoint if they can be separated along either 
an axis parallel to a normal of a face of either A or B, or along an axis formed from the cross product 
of an edge from A with and edge from B. We focus on testing an axis-aligned bounding box (AABB), de.ned 
by a center c, and a vector of half lengths, h, against a triangle .u0u1u2. To simplify the tests, we 
.rst move the triangle so that the box is centered around the origin, i.e., vi = ui - c, i E{0, 1, 2}. 
To test against an oriented box, we would .rst rotate the triangle vertices by the inverse box transform, 
then use the presented test. Based on SAT, we test the following 13 axes: Figure 1: Notation used for 
the triangle-box overlap test. To the left the inital position of the box and the triangle is shown, 
while at the right, the box and the triangle has been translated so that the box center coincides with 
the origin. 1. [3 tests] e0 = (1, 0, 0), e1 = (0, 1, 0), e2 = (0, 0, 1) (the normals of the AABB). Test 
the AABB against the minimal AABB around the triangle. 2. [1 test] n, the normal of .. We use a fast 
plane/AABB overlap test [5, 6], which only tests the two diagonal vertices, whose direction is most closely 
aligned to the normal of the triangle. 3. [9 tests] aij = ei  fj , i, j E{0, 1, 2}, where f0 = v1 - 
v0, f1 = v2 - v1, and f2 = v0 - v2. These tests are very similar and we will only show the derivation 
of the case where i = 0 and j = 0 (see below).  If all tests pass, i.e., there is no separating axis, 
then the triangle overlaps the box. Also, as soon as a separating axis is found the the algorithm terminates 
and returns no overlap . Next, we derive one of the nine tests, where i = 0 and j = 0, in bullet 3 above. 
This means that a00 = e0  f0 = (0, -f0z ,f0y ). So, now we need to project the triangle vertices onto 
a00 (hereafter called a): p0 = a  v0 = (0, -f0z ,f0y )  v0 = v0z v1y - v0y v1z p1 = a  v1 = (0, -f0z 
,f0y )  v1 = v0z v1y - v0y v1z = p0 (1) p2 = a  v2 = (0, -f0z ,f0y )  v2 =(v1y - v0y )v2z - (v1z - 
v0z )v2y Normally, we would have had to .nd min(p0,p1,p2) and max(p0,p1,p2), but fortunately p0 = p1, 
which simplify the computations a lot. Now we only need to .nd min(p0,p2) and max(p0,p2), which is signi.cantly 
faster because conditional statements are expensive on modern CPUs. After the projection of the triangle 
onto a, we need to project the box onto a as well. We compute a radius , called r, of the box projected 
on a as r = hx|ax| + hy |ay | + hz |az | = hy |ay | + hz |az | (2) where the last step comes from that 
ax = 0 for this particular axis. Then this axis test becomes: if( min(p0,p2) >r or max(p0,p2) < -r) return 
false; (3) Now, if all these 13 tests pass, then the triangle overlaps the box. 3 Performance Evaluation 
To evaluate performance, we used the same test as Voorhies [8], i.e., we randomly select the triangle 
vertices inside a 4  4  4 cube centered around the origin and the AABB is the unit cube: from (-0.5, 
-0.5, -0.5) to (0.5, 0.5, 0.5). To get accurate timings we randomly selected 100, 000 triangles and tested 
these in a sequence 100 times. We veri.ed that our code generated the same result as Green and Hatch 
[4], and compared runtimes (we did not test against Voorhies code since that was found to be incorrect 
[2]). On a Sun Sparc Ultra 10 at 333 MHz, the presented code was 3.8 times faster on average in this 
test1 . On a Linux PC with a 1333 MHz AMD Athlon, the speed up was found to be 2.32 . Also, the best 
order to perform the tests on the Sun was found to be: 3, 1, and .nally 2 (the most expensive). On the 
PC, the order did not matter signi.cantly. Note that Green and Hatch s code handles the more general 
case of testing a general polygon against a cube, while we only test a triangle against a cube, and hence 
we can expect some degradation in performance due to this. The only place, where there is a robustness 
issue, is when the normal of the triangle is computed; n = f0  f1. If the triangle has an area close 
to zero, then the normal calculation is not robust, and our code does not solve that problem. However, 
in most applications thin long triangles are best avoided. We have used the code for fast voxelization 
in a ray tracer, and it has been used in a 3D engine [7]. 1 Our code was compiled using gcc, and Green 
and Hatch s code was compiled using Sun s cc, because the runtimes were best for the di.erent routines 
like that. 2 Compiled with gcc -O9 -fomit-frame-pointer -funroll-loops -march=athlon. 4 Acknowledgement 
Thanks to Pierre Terdiman for suggesting di.erent ways to optimize the code, and for trying the code 
in his game engine. Thanks to Peter Rundberg for letting me use his PC for timings. Code is available 
at: http://www.acm.org/jgt/AkenineMoller01/  References [1] Eberly, David, 3D Game Engine Design: A 
Practical Approach to Real-Time Computer Graphics, Morgan Kaufmann Publishers Inc., San Francisco, 2000. 
http://www.magic-software.com/ [2] Graphics Gems III Errata Listing, http://www.graphicsgems.org/ [3] 
Gottschalk, S., M.C. Lin, and D. Manocha, OBBTree: A Hierarchical Structure for Rapid Interference Detection, 
Computer Graphics (SIG-GRAPH 96 Proceedings), pp. 171 180, August, 1996. http://www.cs.unc. edu/~geom/OBB/OBBT.html 
[4] Green, D. and D. Hatch, Fast Polygon-Cube Intersection Testing, in Alan Paeth, ed., Graphics Gems 
V, AP Professional, Boston, pp. 375 379, 1995. http://www.graphicsgems.org/ [5] Haines, Eric, and John 
Wallace, Shaft Culling for E.cient Ray-Traced Radiosity, in P. Brunet and F.W. Jansen, eds., Photorealistic 
Rendering in Computer Graphics (Proceedings of the Second Eurographics Workshop on Rendering), Springer-Verlag, 
New York, pp. 122 138, 1994. http://www. acm.org/tog/editors/erich/ [6] Moller, Tomas, and Eric Haines, 
Real-Time Rendering, AK Peters Ltd., Natick, MA, 1999. http://www.realtimerendering.com/ [7] Terdiman, 
Pierre, Personal communication, 2001. [8] Voorhies, Douglas, Triangle-Cube Intersection, in David Kirk, 
ed., Graphics Gems III, AP Professional, Boston, pp. 236 239, 1992. http://www. graphicsgems.org/ 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198748</article_id>
		<sort_key>9</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[An efficient and robust ray-box intersection algorithm]]></title>
		<page_from>9</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198748</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198748</url>
		<abstract>
			<par><![CDATA[The computational bottleneck in a ray tracer using bounding volume hierarchies is often the ray intersection routine with axis-aligned bounding boxes. We describe a version of this routine that uses IEEE numerical properties to ensure that those tests are both robust and efficient. Sample source code is available online.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P837793</person_id>
				<author_profile_id><![CDATA[81322509940]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Amy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Williams]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P837822</person_id>
				<author_profile_id><![CDATA[81322488418]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Steve]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Barrus]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P636044</person_id>
				<author_profile_id><![CDATA[81100540261]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[Keith]]></middle_name>
				<last_name><![CDATA[Morley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39043298</person_id>
				<author_profile_id><![CDATA[81100449948]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shirley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{IEEE 85} IEEE Standards Association. "IEEE Standard for Binary Floating-Point Arithmetic." IEEE Report (New York), ANSI/IEEE Std 754-1985, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>515330</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{Shirley 02} Peter Shirley. Fundamentals of Computer Graphics. Wellesley, MA: A K Peters, Ltd., 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>781210</ref_obj_id>
				<ref_obj_pid>781209</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{Smits 98} Brian Smits. "Efficiency Issues for Ray Tracing." journal of graphics tools 3:2 (1998), 1--14.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{Smits 02} Brian Smits. "Efficient Bounding Box Intersection." Ray Tracing News 15:1 (2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Amy Williams, University of Utah, Computer Science Department, 50 Central Campus Drive, Salt Lake City, UT 84112 (amy@mit.edu)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Steve Barrus, University of Utah, Computer Science Department, 50 Central Campus Drive, Salt Lake City, UT 84112 (email address)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[R. Keith Morley, University of Utah, Computer Science Department, 50 Central Campus Drive, Salt Lake City, UT 84112 (email address)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Peter Shirley, University of Utah, Computer Science Department, 50 Central Campus Drive, Salt Lake City, UT 84112 (shirley@cs.utah.edu)]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Vol. 10, No. 1: 55 60 An Ef.cient and Robust Ray-Box Intersection Algorithm Amy Williams, Steve Barrus, 
R. Keith Morley, and Peter Shirley University of Utah Abstract. The computational bottleneck in a ray 
tracer using bounding volume hierarchies is often the ray intersection routine with axis-aligned bounding 
boxes. We describe a version of this routine that uses IEEE numerical properties to ensure that those 
tests are both robust and e.cient. Sample source code is available online. 1. Introduction Naive implementations 
of ray-box intersection algorithms can have numerical problems for rays that have slopes near zero along 
any axis. Smits [Smits 98] pointed out that properties given in the IEEE .oating point standard [IEEE 
85] can be used to avoid explicit tests for these values, but did not provide the implementation details. 
The following is an implementation of Smits algorithm. It expects a box with ordered corners min and 
max,a ray r, and a valid intersection interval of (t0, t1) to be given. We assume that the Vector3 and 
Ray classes are implemented; their usages below should be obvious. class Box { public: Box(const Vector3 
&#38;min, const Vector3 &#38;max) { assert(min < max); bounds[0] = min; bounds[1] = max; } &#38;#169; 
A K Peters, Ltd. 55 1086-7651/04 $0.50 per page journal of grpahics tools bool intersect(const Ray &#38;, 
float t0, float t1) const; Vector3 bounds[2]; }; // Smits method bool Box::intersect(const Ray &#38;r, 
float t0, float t1) const { float tmin, tmax, tymin, tymax, tzmin, tzmax; if (r.direction.x() >= 0) { 
tmin = (bounds[0].x() -r.origin.x()) / r.direction.x(); tmax = (bounds[1].x() -r.origin.x()) / r.direction.x(); 
} else { tmin = (bounds[1].x() -r.origin.x()) / r.direction.x(); tmax = (bounds[0].x() -r.origin.x()) 
/ r.direction.x(); } if (r.direction.y() >= 0) { tymin = (bounds[0].y() -r.origin.y()) / r.direction.y(); 
tymax = (bounds[1].y() -r.origin.y()) / r.direction.y(); } else { tymin = (bounds[1].y() -r.origin.y()) 
/ r.direction.y(); tymax = (bounds[0].y() -r.origin.y()) / r.direction.y(); } if ( (tmin > tymax) || 
(tymin > tmax) ) return false; if (tymin > tmin) tmin = tymin; if (tymax < tmax) tmax = tymax; if (r.direction.z() 
>= 0) { tzmin = (bounds[0].z() -r.origin.z()) / r.direction.z(); tzmax = (bounds[1].z() -r.origin.z()) 
/ r.direction.z(); } else { tzmin = (bounds[1].z() -r.origin.z()) / r.direction.z(); tzmax = (bounds[0].z() 
-r.origin.z()) / r.direction.z(); } if ( (tmin > tzmax) || (tzmin > tmax) ) return false; if (tzmin > 
tmin) tmin = tzmin; if (tzmax < tmax) tmax = tzmax; return ( (tmin < t1) &#38;&#38; (tmax > t0) ); } 
Note that the reason we check the sign of each component direction is to ensure that the intervals produced 
are ordered (i.e., so that tmin <= tmax is true). This property is assumed throughout the code, and allows 
us to reason about whether the computed intervals overlap. Note also that since IEEE arithmetic guarantees 
that a positive number divided by zero is +8 and a negative number divided by zero is -8, the code works 
for vertical and horizontal lines (see [Shirley 02] for a detailed discussion). 2. Improved Code The 
code from the previous section works correctly for almost all values, but there is a problem if r.direction.x() 
== -0.0 In this case, the .rst if statement will be true (-0 == 0 is true in IEEE .oating point), and 
instead of the resulting interval being (-8, +8), it will be the degenerate (+8, -8). The same problem 
appears when either r.direction.y() or r.direction.z() are -0.0. When such a degenerate interval is obtained, 
the function will return false. The algorithm therefore fails to detect a valid intersection in this 
situation. While this scenario may seem unlikely, negative zeroes can arise in practice, and indeed have 
in our applications, which is how we discovered this problem. Note how easy it is to generate a negative 
zero: float u = -2.0; float v = 0.0; float w = u*v; // w is now negative zero Many implementations of 
ray-box intersection replace the two divides in each if clause with a single divide and two multiplies: 
divx = 1 / r.direction.x(); tmin = (bounds[0].x() -r.origin.x()) * divx; tmax = (bounds[1].x() -r.origin.x()) 
* divx; This is done because the two multiplies are usually faster than the single divide they replace, 
but it also allows a way out of the negative zero problem. divx captures the sign of r.direction.x() 
even when it is zero: 1 / 0.0 = +8 and 1 / -0.0 = -8. The updated algorithm for the x component (y and 
z are analogous) is: // Improved method for x component divx = 1 / r.direction.x(); if (divx >= 0) { 
tmin = (bounds[0].x() -r.origin.x()) * divx; tmax = (bounds[1].x() -r.origin.x()) * divx; } journal of 
grpahics tools else { tmin = (bounds[1].x() -r.origin.x()) * divx; tmax = (bounds[0].x() -r.origin.x()) 
* divx; } Note that it is important to test the sign of divx rather than r.direction.x() in order for 
-0.0 to be properly detected. This does result in an e.ciency penalty on some systems because the evaluation 
of the if statement must wait for the result of the divide. Nonetheless, to ensure the correctness of 
the ray-box test in all cases, this penalty must be accepted. The code with a test on divx was .rst presented 
by Smits [Smits 02]; although he did not explicitly state its advantage for handling zeroes, he was probably 
aware of it because the associated e.ciency penalty makes it otherwise unattractive. 3. Optimizing for 
Multiple Box Tests Rays are often tested against numerous boxes in a ray tracer, e.g., when traversing 
a bounding volume hierarchy. The above algorithm can be optimized by precomputing values that remain 
constant in each test. Rather than computing divx = 1 / r.direction.x() each time a ray is intersected 
with a box, the ray data structure can compute and store this and other pertinent values. Storing the 
inverse of each component of the ray direction as well as the boolean value associated with the tests 
(such as divx >= 0) provides signi.cant speed improvements. The new code is fairly simple: class Ray 
{ public: Ray(Vector3 &#38;o, Vector3 &#38;d) { origin = o; direction = d; inv_direction = Vector3(1/d.x(), 
1/d.y(), 1/d.z()); sign[0] = (inv_direction.x() < 0); sign[1] = (inv_direction.y() < 0); sign[2] = (inv_direction.z() 
< 0); } Vector3 origin; Vector3 direction; Vector3 inv_direction; int sign[3]; }; // Optimized method 
bool Box::intersect(const Ray &#38;r, float t0, float t1) const { float tmin, tmax, tymin, tymax, tzmin, 
tzmax; tmin = (bounds[r.sign[0]].x() -r.origin.x()) * r.inv_direction.x(); tmax = (bounds[1-r.sign[0]].x() 
-r.origin.x())  * r.inv_direction.x(); tymin = (bounds[r.sign[1]].y() -r.origin.y())  * r.inv_direction.y(); 
tymax = (bounds[1-r.sign[1]].y() -r.origin.y())  * r.inv_direction.y(); if ( (tmin > tymax) || (tymin 
> tmax) ) return false; if (tymin > tmin) tmin = tymin; if (tymax < tmax)  tmax = tymax; tzmin = (bounds[r.sign[2]].z() 
-r.origin.z())  * r.inv_direction.z(); tzmax = (bounds[1-r.sign[2]].z() -r.origin.z())  * r.inv_direction.z(); 
if ( (tmin > tzmax) || (tzmin > tmax) ) return false; if (tzmin > tmin) tmin = tzmin; if (tzmax < tmax) 
tmax = tzmax;  return ( (tmin < t1) &#38;&#38; (tmax > t0) ); } We ran tests to ensure that the multibox 
optimization did not incur a decrease in e.ciency for the case in which a single box or shallow bounding 
volume hierarchy is intersected. Our results show that the optimized method is indeed faster for both 
cases. While the runtimes are dependent on processor type and scene content, we found these timings to 
be typical for most scene complexities and architectures. Scene Smits Improved Optimized method method 
method Single box -1e8 rays 77.78s 71.39s 66.82s 1e6 triangles in BVH -1e8 rays 1027.43s 961.23 739.21s 
 Table 1. journal of grpahics tools In both the single-box and BVH tests approximately half of the rays 
.red hit the test object while the other half were near misses. The tests were performed on a Pentium4 
1800 MHz processor. Acknowledgments. We would like to acknowledge Brandon Mans.eld, Steve Parker, and 
Erik Reinhard for providing test code. John McCorquodale also provided some useful information about 
the speed of .oat-point multiplies and divides. Brian Smits advocacy for BVH intersection methods and 
care with IEEE properties gave us the initial impetus for this work. The anonymous reviewer of the article 
provided very helpful comments, and pointed out that the divides could be performed once for a full 
hierarchy. This work was partially supported by NSF grant 03-06151. Web Information: Sample C++ source 
code for the optimized method described above is available online at http://www.acm.org/jgt/WilliamsEtAl05. 
References [IEEE 85] IEEE Standards Association. IEEE Standard for Binary Floating-Point Arithmetic. 
IEEE Report (New York), ANSI/IEEE Std 754-1985, 1985. [Shirley 02] Peter Shirley. Fundamentals of Computer 
Graphics. Wellesley, MA: A K Peters, Ltd., 2002. [Smits 98] Brian Smits. E.ciency Issues for Ray Tracing. 
journal of graphics tools 3:2 (1998), 1 14. [Smits 02] Brian Smits. E.cient Bounding Box Intersection. 
Ray Tracing News 15:1 (2002). Amy Williams, University of Utah, Computer Science Department, 50 Central 
Campus Drive, Salt Lake City, UT 84112 (amy@mit.edu) Steve Barrus, University of Utah, Computer Science 
Department, 50 Central Campus Drive, Salt Lake City, UT 84112 (email address) R. Keith Morley, University 
of Utah, Computer Science Department, 50 Central Campus Drive, Salt Lake City, UT 84112 (email address) 
Peter Shirley, University of Utah, Computer Science Department, 50 Central Campus Drive, Salt Lake City, 
UT 84112 (shirley@cs.utah.edu) Received October 29, 2002; accepted November 6, 2002. 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198749</article_id>
		<sort_key>10</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Notes on efficient ray tracing]]></title>
		<page_from>10</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198749</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198749</url>
		<abstract>
			<par><![CDATA[There are many ways to make your ray tracer faster. If you're writing an interactive ray tracer, you've got to turn to your bottlenecks in your code and make them scream. You're probably spending the majority of your time computing ray-scene intersections (in some applications, ray-scene intersection may not be the bottleneck, for example Perlin noise is commonly a performance bottleneck for applications that use it heavily). To speed up ray-scene intersections, you use acceleration structures, but how do you get that extra factor of two in performance? This document is some informal notes on experience we've had at Utah on this topic. I do not include citations here. For the sources of these techniques see the bibliography for the chapters from the second edition of <i>Fundamentals of Computer Graphics</i> included in these notes. Several papers discussing these techniques are also included in these notes.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40031357</person_id>
				<author_profile_id><![CDATA[81322489114]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Solomon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Boulos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Notes on ef.cient ray tracing Solomon Boulos University of Utah There are many waystomake yourray tracerfaster.Ifyou 
re writingan interactiveray tracer,you vegot to turn to your bottlenecks in your code and make them scream. 
You re probably spending the majority of your time computing ray-scene intersections (in some applications, 
ray-scene intersection may not be the bottleneck, for example Perlin noise is commonly a performance 
bottleneck for applications that use it heavily).Tospeedup ray-scene intersections,youuse acceleration 
structures,buthowdoyougetthatextra factor of two in performance? This document is some informal notes 
on experience we ve had at Utah on this topic. Ido not include citations here. For the sources of these 
techniques see the bibliographyfor the chapters from the second edition of Fundamentals of Computer Graphics 
included in these notes. Several papers discussing these techniques are also included in these notes. 
Icovertwodifferent classesof acceleration structuresand whatyou candotomake themevenfaster: bounding 
volume hierarchies (BVHs) and uniform grids (UGs). We do not have as much experience with BSP trees and 
interested readers should see the work from the University of Saarland group for BSP tree implementation 
techniques. I ll show code, and discuss the trade-offs involved between each choice. The codeexamplesfromtheBVH 
sectionareslightly modi.edversionsofcodefrom Realistic Ray Tracing, 2nd Edition. That original code is 
available at http://www.cs.utah.edu/ shirley/galileo/. Bounding volume hierarchies ABVHis conceptually 
simple. It sa treeof boundingvolumes, wherea boundingvolumeis usuallyan axis aligned bounding box that 
encloses all the surfaces you ve got underneath it in the tree. An example of a simple BVH class in C++ 
looks like this: class BVH : public Surface { public: // Constructors and such here BBox bbox; Surface* 
left; Surface* right; }; Asyoucansee,wehavea boundingboxforournodeand pointerstoourtwo children.TobuildaBVH,you 
choose some way to split up a list of primitives into two separate lists and put them into the left and 
right children as you see .t while making sure that your bounding box surrounds all the primitives. In 
C++ you get something like this: BVH::BVH(Surface** surfaces, int num_surfaces, int axis) { if (num_surfaces 
== 1) { *this = BVH(surfaces[0], surfaces[0], axis); return; } if (num_surfaces == 2) { *this = BVH(surfaces[0], 
surfaces[1], axis); return; } // surround all the objects in the list bbox = surround(surfaces, num_surfaces); 
Vector3 pivot = (bbox.max() + bbox.min()) / 2.0; // split up the primitives and tell me where the end 
of the left node is int mid_point = qsplit(surfaces, num_surfaces, pivot[axis], axis); // create a new 
bounding volume int next_axis = (axis + 1) % 3; left = buildBranch(surfaces, mid_point, next_axis); right 
= buildBranch(&#38;surfaces[mid_point], num_surfaces -mid_point, next_axis); } This constructor takesa 
listof Surface pointers and an axis, and producesa BVH.You include the axis parameter so you can switch 
which axis you split the primitives along. The qsplit function called here is similartothewaya standard 
qsortworks,except thatweonlyhavetomove objectsto one sideofa splitting plane(thepivotpoint).Again,thechoiceof 
constructionalgorithmisentirelyuptoyouandthe performance ofyourBVH depends stronglyuponit,butitisanopen 
questionastohowyoumightbuildan optimalBVH (or at least something that performs really well for a variety 
of situations). buildBranch is essentially a copy-and-paste from this default constructor except you 
can return something other than a BVH pointer for those .rst cases (e.g. return surfaces[0] if there 
is only one object). One of the nicest things about the BVH is how simple it is to intersect with a ray: 
bool BVH::hit(Ray &#38;r, HitRecord&#38; rec, Context&#38; context) { if ( !(bbox.rayIntersect(r, r.tmin, 
r.tmax))) return false; bool isahit1 = left->hit(r, rec, context); bool isahit2 = right->hit(r, rec, 
context); return (isahit1 || isahit2); } From this code we can see that we .rst test a ray against our 
bounding volume. If we don thit the bounding volume, we immediately returnfalse. If wedo hit the boundingvolume 
we recurse. You mayhave just realizedwe re abouttodoalotof boundingbox intersection tests. Currently,the 
best methodIknowof asks fora little bitofextra storagein yourRay classbutgivesa substantial improvementin 
performance (Williams et al. 2005). There is also a recent JGT submission discussing a Ray-box test using 
Plucker coordinates,but wehave not implemented this algorithm ourselves. So those are the basics of 
BVH. How do we make it better? Assuming you think your construction is rock solid,but you just wish the 
traversal werefaster, the .rst question is probably whyleft before right, whynotrightbeforeleft? Thisisaverygoodquestion.Infact,ifyouswitch 
betweenleftandrightyou ll even notice a difference for some scenes. What if we could choose the side 
based on something we know about the ray? Since we were already using theWilliams bounding box test, 
which required us to store bitwise values that determined whether or not we are going in the positive 
or negative x,y and z directions, we use this to our advantage. The BVH node changes slightly: class 
BVH : public Surface { public: // Constructors and such here BBox bbox; Surface* child[2]; int split_axis; 
}; and the hit function changes similarly: bool BVH::hit(Ray &#38;r, HitRecord&#38; rec, Context&#38; 
context) { if ( !(bbox.rayIntersect(r, r.tmin, r.tmax))) return false; bool isahit1 = child[r.posneg[(split_axis*2)]]->hit(r, 
rec, context); bool isahit2 = child[r.posneg[(split_axis*2)+1]]->hit(r, rec, context); return (isahit1 
|| isahit2); } Here r.posneg storesa0iftherayismovingtotherightin that axisanda1otherwise.In ourexperience 
this modi.cation gives a non-trivial performance bene.t over either static choice (left then right or 
right then left). Alternatively, if we switch the order of traversal, we perform worse than either of 
the static choices. It should be noted that this modi.cation is essentially an algorithmic change in 
traversal. You re trying to .nd the earliest intersection in a scene, so this algorithm chooses the node 
that would be in your way . If you re going to the right, it .rst checks the left node, and if you re 
going left it .rst checks the right node. Other researchers have tried other things like reordering the 
nodes in depth .rst search order to obtain higher memory coherence (Smits 1998). There have been other 
discussions of how to choose a splitting axis, but the most commonly used scheme is that shown here: 
to start with some axis and cycle through the axes in order. More discussion about these issues can be 
found in the Ray Tracing News (http://www.acm.org/tog/resources/RTNews/html/rtn index.html#spatial). 
 Uniform grids TheUGis also conceptually simple.Take your listof objects,buildabigbox around them then 
cutitup into smaller boxes. When a rayhits your grid, you iteratively traverse your grid using a 3D-DDAalgorithm 
(Woo 87). Grid traversal has been covered in great detail, and the basic thing to remember to do is to 
avoid recomputing anything you don t need to during the inner most loop. Grid construction has also been 
discussedbymanyresearchersandthebest resourceforanyofthisistheraytracingnews.Onceyou vegot a basic grid 
implementation, the question is how to make itfaster. First, if you re adding adding geometry to grid 
cells because their bounding boxes overlap, you re paying a high price without a good reason. Most likely,yourlargescenehasatleastsomenumberoftrianglesinit.Anexcellentcodefor 
box-triangleoverlap is onTomasAkenine-M oller swebsite.Itisfasterandmorestablethanprevious methodsandverysimple 
toaddtoyourcodelibrary.Istrongly recommendthatanyobjectyouareinsertingintoyourgridistestedto make sureit 
actuallyoverlaps your grid cell. This simple changegavea 15-17% boostin performance fora simple scene 
with the Stanfordbunny. Other Box-object tests alsoexist, anda listof them canbe found on the Real-Time 
Rendering website (http://www.realtimerendering.com/int). Most grid implementations have some sort of 
way they store their grid data, for example a 3D array of lists of pointers. In a similar manner to the 
common Matrix-Matrix multiply optimization, you get very different results based on how you traverse 
this data due to the memory layout. If for example, you had a 3D array such as this: Surface* data[nx][ny][nz]; 
youwould payvery little costin memory penalties for traversingin thez direction,butavery large cost for 
traversing in the x direction (and this only gets worse as your memory requirements increase). In ray 
tracing, and more soin path tracing, rays are bouncingin all sortsof directions.You could de.nitely layout 
your memoryfora particularviewifyouwantedto,but doing thisfor eachviewis incredibly costly(and could 
almost certainly never be done interactively). Instead, it is better to arrange your data in a bricked 
fashion so that you never pay a huge cost in stride for anydirection you travel. You won t necessarily 
do as wellforthe rays thatwouldhave beenat ideal cost,butyouwon tdo nearlyas poorlyforthe rays that would 
have had the worst cost possible. Again,alotof improvement can alsobegainedatthe algorithmiclevel.Ifwe 
instead usea hierarchy of uniform grids (unfortunately there is no standard term for this in the literature) 
we can reduce the size of the object listsin each cell. Automatically generatingagridto perform wellis 
essentially black magic,but without any explanation of how to do it, you can achieve up to 40% improvements 
in run time from simply buildinganew uniformgridwheneveracellistoodensely populated.Forexample,ifyoubuildagridby 
havinga3Darrayoflistsofobject pointers,youcoulddoapassoverthegridafteryou vebuiltitandcheck for lists 
that are say longer than 16 elements. In anysuch cell, you could take that list of objects and turn it 
into a new grid. This would be a particularly simple implementation, and seems to work pretty well in 
practice. Another improvement involves maximizing cache coherence. For example, if you allocate a pointer 
for each object as you insert it into the grid, you will cause a large amount of fragmentation within 
your grid. If instead in a .rst pass you created a grid holding the number of objects that overlap a 
cell (instead of pointers to the objects that will eventually go there) and then allocated a big chunk 
of memory you can removethepenaltyof fragmentation(youthenloopoveryourgridagainplugginginvaluesforthe 
pointers). This technique may also reduce your construction time despite the twopasses due to the reduction 
in memory allocation calls (system calls always cost a fortune). Grids vs BVHs So the question now is 
which one to use? Or should you use a BSP? The short answer is that it depends. The long answer involves 
explaining what it depends on. The correct answer is that nobody really knows. But I ll give the long 
answer. There are a few different issues that warrant some (mostly high-level) discussion, including 
very large scenes, object distribution and material properties.We ll talk about eachof these issuesin 
turn, and remember that for the most part this discussion assumes that each of your acceleration structures 
is implemented equally well (which may or may not be true in practice as people have very different mileage 
for each data structure). Large scenes Large scenesarethosewhicharesimplynotpossibleina32-bitaddressspace.AsceneincludingtheDavid 
model from Stanford (the model .le alone is 1.1GB) would be a good example. In the 64-bit address space 
pointersarenow8byteslongtoallowyouto addressallthat memory.Theimpactforyouisthatyourdata structures may 
now suddenly require twice as much storage. Instead of using pointers we can store a list of objects 
that we wish to access and index into them using an appropriately sized integer value. For example, as 
long as you have less than 232 objects in your scene, you can getaway witha simple4byte unsigned integer. 
In the general case, you only need n-bit indices, where n is such that 2n is greater than the number 
of objects you need to index. Unless memory was really tight, I drecommend sticking with the simple integer. 
This brings up a common technique whenever you have lots and lots of instances of a data structure: make 
it smaller. For example, a common representation for a KD-Tree node would contain two pointers to child 
nodes, an integer for the split axis and a .oating point position of the splitting plane. This leads 
to at leasta24byte structureona 64-bit machine. IngoWaldhas demonstrateda moreef.cient representation 
requiringonly8bytesofstorage.Thisimprovescachelinereuseandgreatlyreducesmemory requirements, and his 
representation does so without a loss in accuracy. Object distribution So let s say you have a big list 
of primitives (spheres, polygons, etc), what kind of an acceleration structure shouldyouput them into?I.nd 
this questionisbestansweredby lookingat each data structure separately and then comparing them afterwards. 
ABVHisidealforsparse scenes.WhenyoubuildaBVH,youhavetheabilitytogrouptheobjectsinto two separate clusters 
that may be separated by large portions of space. Also, if the bounding boxes of your node s children 
(the left and right children s bounding boxes) don t overlap you can get an instant stopping criteria. 
For example, assume that you have a ray entering from the right and some objects clustered as shown in 
Figure 1. If you were to test the right box .rst, you d .nd the .rst intersection and produce a shorter 
ray, which would no longer hit the left box. This exit early condition is not possible if the boxes overlapalot 
becauseeventhe clippedray will stillhitthe other box.So oneofthe biggest weaknessesof the BVH is when 
you have geometry with strong overlap. What does this mean to you? For a dense mesh, such as the Stanford 
Buddha, your BVH may not perform as well as it would for a scene composed with the same number of non-overlapping 
primitives. Thisdoesn tmeanitwon tperformprettywell,butthere s de.nitelyroomforimprovement.Thetakehome 
message:BVHsarevery naturalforsparse scenes,sinceyoucantakeadvantageofearlyexitsbutmaybe you should use 
something else for dense regions of your scene. In contrasttotheBVH,the UniformGridismeantfordensedata.Whenyoubuilda 
uniformgrid,you usually dice up the overall bounding box into equally sized cells, which means that for 
a sparse scene, you have a lot of empty cells, which you ll still end up checking when you go along intersecting 
(although you stillmoveprettyquicklythroughthem).Wastingtimemovingthroughemptycells,andworseyet spending 
anyamountof storage onempty cellsisa problem for uniform grids.Toavoid this problem, you can make cells 
biggerso thatyoujumpovermore empty space more quickly,but thenyouhave some cells with lots of primitives 
inside of them. This problem is commonly referred to as the teapot in the stadium problem , where you 
have a high resolution version of the Utah teapot in the center of a large low resolution stadium. This 
scenewouldhaveaverylarge boundingbox,butto obtaina suitablegrid resolutionforthe teapotyou might have 
to use very small cells. Figure1:Aray coming from the right should test the right subtree .rst. The 
common solution for this is not to put things into anyacceleration structure blindly. Most likely, you 
have a high level understanding that your teapot is an object on its own and could make a uniform grid 
out of this object and then place the teapot-grid into a BVH in combination with the stadium (thus taking 
advantage of the sparse structure of the stadium). How do you do this automatically? There have been 
lots of papers,but this is largely an unanswered question. One of the largest barriers to answering the 
question is that there isn t a suitable set of test scenes to test the performance of acceleration structures. 
The SPD sceneshavebeenusefulasaaraytracing benchmark,butarenolonger representativeofthetypesof scenes 
you would want to render in a modern rendering system. The take home message: gridsworkvery well for 
dense data such as meshes andvolumes,but you pay a price for traversing and storing the empty cells. 
There has not been much work in adaptive resolution grid structuresinraytracing(althoughtherewerea handful 
between1987and1997),butthebasicideainvolves automatically isolating dense regions of space and putting 
them into a structure and then placing the result into a coarser representation (or a different structure 
entirely, such as a BVH). Ray casting versus ray tracing This is not a commonly discussed problem with 
these different acceleration structures, but in practice is incredibly important. For example, some acceleration 
structure papers have only considered ray casting (sending primary rays from the observer towards the 
scene) which involves no secondary bounces. This usually means that all rays are starting well outside 
the acceleration structure and arevery coherent (traveling in the same direction and likely to touch 
adjacent memory). A more interesting situation occurs when we consider rays that start on or inside the 
acceleration structure. The two data structures we ve discussed above perform quite differently for what 
I ll call a starting cost. For example, for a uniform grid, you can determine in constant time the grid 
cell you are in when you start a ray inside the grid. For a BVH, you usually provide a ray to the top 
level node and traverse down the hierarchy, despite thefact that you might know you re inside the acceleration 
structure already. As you consider larger and larger scenes, the height of the hierarchycontinues to 
grow and suddenly the log n traversal starting cost becomes larger and larger. This applies to all hierarchical 
data structures. This basic problem leads to an optimization present in some interactive ray tracers: 
if you don t allow objects to be placed inside your dielectrics, you can avoid a scene intersection test 
for transmitted rays and only perform a test against the dielectric object. This is an interesting optimization 
because it offers a huge performance bene.tforlarge scenes containing dielectrics(imagineaglasscoffeetableinacomplexscene). 
Anopen questionwouldbehowtotakeadvantageofthis property automatically, without requiringthe user to tell 
you that nothing is inside the space you re interested in testing. This problem comes up anytime you 
haveraysenteringthemodel,butagainasImentionedthesameissueistruewhenyou resendingsecondary raysfromoffofthemodelaswell.Itwouldbe 
interestingtoseemore researchondata structuresthatmight be able to take advantage of these situations. 
For the most part the uniform grid already achieves this due to its negligible (constant time) startup 
cost, so the simplest solution might be to investigate how to create adaptive resolution hierarchical 
grids, so that you can avoid the empty cells. Summary We ve discussed two of the most common data structures 
for accelerating ray-scene queries. Hopefully some of the basic optimizations such as memory layout( 
data bricking, compact data structures )and algorithmic optimizations(earlyexits, precomputed results)came 
across clearly as theycan greatly improve the performance of your renderer. Therearealotofother solutionsoutthere,butatUtahwe 
vefoundtheadvicegivenheretobefairly useful in practice. All of the techniques apply to parallel code 
as well, and we haven t spent any time considering optimizations that only work on a single processor 
(e.g. mailboxing). For the most part, the basic rules of optimization always hold: optimize the portions 
of the code that show up in pro.ling, always consider improving your algorithm and gettingit rightis 
more important than makingitfast. 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198750</article_id>
		<sort_key>11</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Parallel & distributed processing]]></title>
		<page_from>11</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198750</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198750</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40024383</person_id>
				<author_profile_id><![CDATA[81100159926]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Philipp]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Slusallek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Saarland University, Saarbr&#252;cken, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39043298</person_id>
				<author_profile_id><![CDATA[81100449948]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shirley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35035889</person_id>
				<author_profile_id><![CDATA[81547494456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mark]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Texas at Austin, Austin, TX]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39031627</person_id>
				<author_profile_id><![CDATA[81100189931]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Gordon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stoll]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Intel Corporation, Santa Clara, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40030613</person_id>
				<author_profile_id><![CDATA[81100041422]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Ingo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wald]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Max-Planck-Institut f&#252;r Informatik, Saarbr&#252;cken, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
  P r o m i s e s a n d C h a l l e n g e s  Characteristics Independence of every ray tree  Serial 
dependency between generations of rays  Often dependency between child rays due to shader  Significant 
coherence between adjacent rays  Geometry can be cached rays cannot  Coherence generally diminishes 
with generation  Single shared (mostly) read-only scene data base  P a r a l l e l i s m  Task versus 
Data Parallelism (I) Data parallelism: task follows data  Distribute scene among processors, migrate 
tasks (rays)  Seems suitable for massive scenes   Drawbacks  Large bandwidth due to many rays (difficult 
to cache)  Hotspots at camera, lights, and other locations   P a r a l l e l i s m  Task versus 
Data Parallelism (II) Task parallelism: data follows tasks Distribute pixel (tiles) among processors 
 Load data on demand, cache locally  Cache size accumulates among processors  Should assign similar 
tasks to same processor (coherence) Within frame and between frames  Dynamic load balancing is simple, 
but conflicts with coherence  C o m m u n i c a t i o n  Shared Memory versus Message Passing Conceptually 
highly similar  Separate memories with fast interconnect network  Both need low latency, high bandwidth 
networks  Often special HW support for SHM (cache coherence)   Shared memory: User-space illusion 
through OS  Convenient and efficient cache: No explicit programming  Fully transparent but can introduce 
long thread stalls on miss   Ideal: SHM with OS support under user control   H a r d w a r e O p 
t i o n s  Shared-Memory Computer High scalability with fast &#38; low latency networks  Single virtual 
address space &#38; lot s of RAM  Single admin domain  Future computers will use shared memory  Today: 
8 sockets * dual core 16 CPU + 64 GB  Heavy multi core designs with fast &#38; high bw interconnects 
 May become all we need (at some point : )   H a r d w a r e O p t i o n s  Cell processor No 
caches but low latency DMA messages  Globally shared memory with high bandwidth  256 KB Local Store 
: manually managed cache  128x 4-vector registers: keep many packets in-flight  #packets allow for 
hiding DMA latency (hopefully)  Similar to PC cluster, but at different level/granularity  C a c h 
i n g  Caching and Working Sets: (Level I) Sharing between adjacent (groups of) rays  Even small caches 
work extremely well SaarCOR I: 4 KB cache . >98% hit rate (2x2 traversal) less for lists and triangles 
 Larger tiles reduce coherence  Diminishing return on bandwidth due to reduced coherence  Increased 
working set requires larger caches   C a c h i n g  Caching and Working Sets: (Level II) Sharing 
between frames  Size of working set (with paging) #rays * avg(#pages per ray) * sizeof(page) * (1 avg(sharing)) 
 Little sharing at leaf nodes of large scenes  Only changed and new data must be send  Can significantly 
reduce bandwidth  Might even use procedural approach   C a c h i n g  Caching and Working Sets: 
(Level III) Out-of-core rendering (loading from disk, e.g. Boeing)  In renderer and/or application 
(with feedback)  Similar characteristics to L-II  But latency in the order of frame times  Must use 
pre fetching of data to avoid artifacts   C a c h i n g  Caching and Working Sets: (Summary) Caching 
generally works very well  RT has surprising amount of coherence  Across all levels of hierarchy  
 Reduces required bandwidth  May fail occasionally . high peak bandwidth  Completely incoherent rays 
(no sharing)  Sudden changes of working set (e.g. fast movements)   L o a d B a l a n c i n g  Load 
Balancing of Tasks (packets of rays) Centrally assign tasks to processors on demand  Goal: Keep processors 
busy at all times  Size of tasks: Overhead versus granularity  Overhead through network bandwidth &#38; 
processing  Small granularity: Allows better distribution of load  Large granularity: Not enough tasks 
for large cluster  Typical on PC Cluster: 32x32 to 16x16 ( 4 packets queued)   Keeps queue filled 
with 1 ms latency and 4 Mrays/s L o a d B a l a n c i n g  Fairness Usually not an issue: Enough tasks 
to distribute  640x480/32x32 300 tasks per frame  At 30 processors: can tolerate 10:1 imbalance (a 
lot !)   End of frame synchronization  Big worry in offline rendering: Must balance each frame  Not 
an issue in online rendering: stream computing Start assigning tasks from next frame to idle processors 
 Even higher imbalance can be handled   S e n d O p e n R T C o m m a n d s F r a m e n r t S w a 
p - B u f f e r s Send OpenRT Commands Frame n+1 rtSwap-Buffers Send OpenRT Commands Frame n+2  S c 
e n e U p d a t e s  Synchronization for Scene Update May need to update scene between frames  Must 
adhere to temporal consistency All packets in old frame must be finished, no new started yet  Approach 
(Copy &#38; Update)  Separate receiver thread updates scene  Changed objects are copied before applying 
changes  At end of frame: pointers are updated fast pointer copy   N e t w o r k i n g  Bandwidth 
requirements From master:  Scene updates (it depends )  2D tile coordinates (tiny)  Enough bandwidth 
to add other data (e.g. AR background)   To master:  RBG data: (3 byte per pixel: >3MB * N fps)  
Could use low latency compression (MJPEG, H 263, )    H y b r i d D i s t r i b u t i o n M o d e 
l   Cluster of SHM machines  SHM: Better caching and sharing of scene data  Single link many parallel 
threads  Reduced bandwidth requirements with large cache   Several processes on SHM machine  One 
link per process . increased bandwidth  SHM leads to frame sync between threads (!)  Better scalability 
with shared memory mapping   S u m m a r y a n d L i m i t a t i o n s  Ideally scalable due independent 
rays  Limited only by bandwidth to data Scene updates, cache misses, pixel data  Reduced bandwidth 
through caching  Needs good task scheduling &#38; load balancing  Generally work very well  . OK on 
computer scale, translate to chip scale 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198751</article_id>
		<sort_key>12</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Interactive ray tracing]]></title>
		<page_from>12</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198751</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198751</url>
		<abstract>
			<par><![CDATA[We examine a rendering system that interactively ray traces an image on a conventional multiprocessor. The implementation is "brute force" in that it explicitly traces rays through every screen pixel, yet pays careful attention to system resources for acceleration. The design of the system is described, along with issues related to material models, lighting and shadows, and frameless rendering. The system is demonstrated for several different types of input scenes.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[parallel systems]]></kw>
			<kw><![CDATA[ray tracing]]></kw>
			<kw><![CDATA[shading models]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP39030761</person_id>
				<author_profile_id><![CDATA[81350577009]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Parker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31041741</person_id>
				<author_profile_id><![CDATA[81406598481]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Martin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40031399</person_id>
				<author_profile_id><![CDATA[81100524617]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Peter-Pike]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Sloan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39043298</person_id>
				<author_profile_id><![CDATA[81100449948]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shirley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31044610</person_id>
				<author_profile_id><![CDATA[81408593457]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Brian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Smits]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14162477</person_id>
				<author_profile_id><![CDATA[81100464350]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Charles]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hansen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>808589</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Amanatides. Ray tracing with cones. Computer Graphics, pages 129--135, July 1984. ACM Siggraph '84 Conference Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>888993</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Kavita Bala, Julie Dorsey, and Seth Teller. Bounded-error interactive ray tracing. Technical Report LCS TR-748, MIT Computer Graphics Group, March 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192195</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Gary Bishop, Henry Fuchs, Leonard McMillan, and Ellen J. Scher Zagier. Frameless rendering: Double buffering considered harmful. Computer Graphics, 28(3):175--176, July 1994. ACM Siggraph '94 Conference Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>154731</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Michael E Cohen and John R. Wallace. Radiosity and Realistic Image Synthesis. Academic Press, Boston, MA, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Robert L. Cook, Thomas Porter, and Loren Carpenter. Distributed ray bating. Computer Graphics, 18(4):165--174, July 1984. ACM Siggraph '84 Conference Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>806819</ref_obj_id>
				<ref_obj_pid>965161</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Robert L. Cook and Kennneth E. Torrance. A reflectance model for computer graphics. Computer Graphics, 15(3):307--316, August 1981. ACM Siggraph '81 Conference Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>833838</ref_obj_id>
				<ref_obj_pid>832271</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Robert A. Cross. Interactive realism for visualization using ray tracing. In Proceedings Visualization '95, pages 19--25, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>182470</ref_obj_id>
				<ref_obj_pid>182466</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[David A. Ellsworth. A new algorithm for interactive graphics on multicomputers. IEEE Computer Graphics and Applications, 14(4), July 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Bernd Fr&#246;hlich. Ray Tracing mit Strahlenb&#252;ndeln (Ray Tracing with Bundles of Rays). PhD thesis, Technical University of Braunschweig, Germany, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>13044</ref_obj_id>
				<ref_obj_pid>13043</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Akira Fujimoto, Takayo Tanaka, and Kansei Iwata. Arts: Accelerated ray-tracing system. IEEE Computer Graphics & Applications, pages 16--26, April 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>94788</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Andrew S. Glassner, editor. An Introduction to Roy Tracing. Academic Press, San Diego, CA, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280950</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Amy Gooch, Brace Gooch, Peter Shirley, and Elaine Cohen. A non-photorealistic lighting model for automatic technical illustration. In SIGGRAPH 98 Conference Proceedings, pages 447--452, July 1998. ISBN 0-89791-999-8.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618511</ref_obj_id>
				<ref_obj_pid>616051</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Gene Greger, Peter Shirley, Philip M. Hubbard, and Donald P. Greenberg. The irradiance volume. IEEE Computer Graphics & Applications, 18(2):32--43, March-April 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>63450</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Roy Hall. Illumination and Color in Computer Generated Imagery. Springer-Verlag, New York, N.Y., 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808588</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Paul S. Heckbert and Pat Hanrahan. Beam tracing polygonal objects. In Computer Graphics (SIGGRAPH '84 Proceedings), volume 18, pages 119--127, July 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801287</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[James T. Kajiya. Ray tracing parametric patches. In SIGGRAPH '82, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15916</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Timothy L. Kay and James T. Kajiya. Ray tracing complex scenes. Computer Graphics, 20(4):269--278, August 1986. ACM Siggraph '86 Conference Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[M. J. Keates and R. J. Hubbold. Accelerated ray tracing on the KRS1 virtual shared-memory parallel computer. Technical Report UMCS-94-2-2, Computer Science Department, University of Manchester, February 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[D. Kersten, D. C. Knill, Mamassian P, and I. B&#252;lthoff. Illusory motion from shadows. Nature, 379:31, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Michael J. Muuss. Rt and remrt - shared memory parllel and network distributed ray-tracing programs. In USENIX: Proceedings of the Fourth Computer Graphics Workshop, October 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Michael J. Muuss. Towards real-time ray-tracing of combinatorial solid geometric models. In Proceedings of BRL-CAD Symposium, June 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280929</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Eyal Ofek and Ari Rappoport. Interactive reflections on curved objects. In SIGGRAPH 98 Conference Proceedings, pages 333--342, July 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>288266</ref_obj_id>
				<ref_obj_pid>288216</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Steven Parker, Peter Shirley, Yarden Livnat, Charles Hansen, and Peter-Pike Sloan. Interactive ray tracing for isosurface rendering. In Proceedings Visualization '98, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Steven Parker, Peter Shirley, and Brian Smits. Single sample soft shadows. Technical Report UUCS-98-019, Computer Science Department, University of Utah, October 1998. http://www.cs.utah.edu/~bes/papers/coneShadow.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37435</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[William T. Reeves, David H. Salesin, and Robert L. Cook. Rendering antialiased shadows with depth maps. Computer Graphics, 21(4):283--292, July 1987. ACM Siggraph '87 Conference Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[E. Reinhard, A. G. Chalmers, and F. W. Jansen. Overview of parallel photorealistic graphics. In Eurographics '98, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>260843</ref_obj_id>
				<ref_obj_pid>260832</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Erik Reinhard and Frederik W. Jansen. Rendering large scenes using parallel ray tracing. Parallel Computing, 23(7), July 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Christophe Schlick. A customizable reflectance model for everyday rendering. In Proceedings of the Fourth Eurographics Workshop on Rendering, pages 73--84, June 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>18559</ref_obj_id>
				<ref_obj_pid>18548</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Thomas W. Sederberg and Scott R. Parry. Comparison of three curve intersection algorithms. Computer-aided Design, 18(1), January/February 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>826423</ref_obj_id>
				<ref_obj_pid>826026</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Peter Shirley, Helen Ho, Brian Smits, and Eric Lafortune. A practitioners' assessment of light reflection models. In Pacific Graphics, pages 40--49, October 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Peter Shirley, Kelvin Sung, and William Brown. A ray tracing framework for global illumination systems. In Proceedings of Graphics Interface '91, pages 117--128, June 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>182461</ref_obj_id>
				<ref_obj_pid>182452</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[J. S. Singh, A. Gupta, and M. Levoy. Parallel visualization algorithms: Performance and architectural implications. IEEE Computer, 27(7), July 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614404</ref_obj_id>
				<ref_obj_pid>614271</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Wolfgang St&#252;rzlinger. Ray-tracing triangular trimmed free-form surfaces. IEEE Transactions on Visualization and Computer Graphics, 4(3), July-September 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>260841</ref_obj_id>
				<ref_obj_pid>260832</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[H. J. Yoon, S. Eun, and J. W. Cho. Image parallel ray tracing using static load balancing and data prefetching. Parallel Computing, 23(7), July 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Ellen Scher Zagier. Frameless antialiasing. Technical Report TR95-026, UNC-CS, May 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Ellen Scher Zagier. Defining and refining frameless rendering. Technical Report TR97-008, UNC-CS, July 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Interactive Ray Tracing Steven Parker William Martin Peter-Pike J. Sloan Peter Shirley Brian Smits 
Charles Hansen University of Utah,  Abstract We examine a rendering system that interactively ray traces 
an image on a conventional multiprocessor. The implementation is brute force in that it explicitly traces 
rays through every screen pixel, yet pays careful attention to system resources for acceleration. The 
design of the system is described, along with issues related to material models, lighting and shadows, 
and frameless rendering. The system is demonstrated for several different types of input scenes. CR Categories: 
1.3.0 [Computer Graphics]: General; 1.3.6 [Computer Graphics]: Methodology and Techniques. Figure 1: 
The ray tracing system discussed in this paper explicitly Keywords: Ray tracing, parallel systems, shading 
models traces all rays on a pool of processors for a viewpoint interactively selected by the viewer: 
1 INTRODUCTION Interactive rendering systems provide a powerful way to convey information, especially 
for complex environments. Until recently the only interactive rendering algorithms were hardware-accelerated 
polygonal renderers. This approach has limitations due to both the algorithms used and the tight coupling 
to the hardware. Softwareonly implementations are more easily modified and extended which enables experimentation 
with various rendering and interaction options. This paper describes our explorations of an interactive 
ray tracing system designed for current multiprocessor machines. This system was initially developed 
to examine ray tracing s performance on a modem architecture. We were surprised at just how responsive 
the resulting system turned out to be. Although the system takes careful advantage of system resources, 
it is essentially a brute force implementation (Figure 1). We intentionally take the simple path wherever 
feasible at each step believing that neither limiting assumptions nor complex algorithms are needed for 
performance. The ray tracing system is interactive in part because it runs on a Figure 2: A portion 
of a 600 by 400 pixel image from our systemhigh-end machine (SGI Origin 2000) with fast frame buffer, 
CPU running at approximately fifteen frames per second.set, and interconnect. The key advantages of ray 
tracing are: . ray tracing scales well on tens to hundreds of processors; The first item allows our implementation 
to be interactive, the sec ray tracing s frame rendering time is sub-linear in the number ond allows 
this interactivity to extend to relatively large (e.g. gigaof primitives for static scenes; byte) scenes, 
and the third allows the familiar ray traced look with shadows and specular reflection (Figure 2). . 
ray tracing allows a wide range of primitives and user pro-In the paper we stress the issues in ray tracing 
that change when grammable shading effects. we move from the static to the interactive case. These include 
achieving performance in synchronous or asynchronous (frameless) fashions (Section 2), and modifications 
to traditional Whitted-style lighting/shadowing model to improve appearance and performance (Section 
3). We also discuss a few areas that might benefit from interactive ray tracing and show some of the 
environments we used in Section 4. We compare our work to the other work in parallel ray tracing in 
Section 5. We do not compare our work to the many object space methods available for simulating shadows 
and non-diffuse effects (e.g. Ofek and Rappoport [22]) which we believe comprise a different family 
of techniques. Our interactive implementation of ray tracing isosurfaces in trilinear volumes is described 
elsewhere [23].     Figure 7: The directional quantities associated with Equation 1. Metal. Metal 
has a reflectance that varies with incident angle [6]. We are currently ignoring this effect, and other 
effects of real metal, Dielectric. Dielectrics, such as glass and water, have reflectances that depend 
on viewing angle. These reflectances are modeled by the Fresnel Equations, which for the unpolarized 
case can be approximated by a polynomial developed by Schlick [28]: and is determined by conservation 
of energy: The internal attenuation of intensity  is the standard exponential decay with distance 
according to extinction coefficient  I(t) = To approximate the specular reflection of an area light 
source we add a Phong term to dielectrics as well.  Polished. We use the coupled model presented in 
[30]. This model allows the to vary with incident angle, and allows the diffuse appearance to decrease 
with angle. As originally presented, it is a BRDF, but it is modified here to be appropriate for a clamped 
RGB lighting model with an ambient component: where the first term assumes the ambient component arises 
from directionally uniform illumination. 3.1.1 Ambient Lighting The ambient term  in Equation 1 is 
a crude approximation used in conventional ray tracers to avoid computing an indirect lighting term. 
It is not meant to be physically accurate, but instead to illuminate those areas that are not directly 
lit by the luminaires. Given this, its main failing is that the uniform intensity causes diffuse objects 
to appear flat when the surface faces away from the light source. One way to avoid this is to put a fill-light 
at the eye point, but we feel this is distracting for a moving viewpoint. An alternative is to allow 
the ambient coefficient to vary with position and orientation:  This can be a simple heuristic, or based 
on radiosity solutions [13]. Our motivation for using a more sophisticated ambient term is to allow 
shading variation on surfaces that are not directly lit without the computational cost of adding additional 
lights. This can be accomplished by assuming the ambient term arises due to illumination from a background 
divided evenly between two intensities A and (Figure 8). The angle  will vary from zero to radians. 
For = 0 the surface will only see A so the ambient term will be A. As increases the ambient term will 
 Figure 8: A surface is illuminated by a hemisphere with colors A and B. gradually change to (A + at 
 = and finally change to B as the surface fully faces the bottom hemisphere. Nusselt s analog [4] allows 
us to derive the full relationship: Either the user can set A and B algorithmically or by hand. We set 
ours by hand, but some heuristics can aid in selection. If we envision the hemisphere-pair as approximating 
indirect lighting of an object in a room, then the walls opposite the light are well illuminated and 
bright. So the hemisphere can be roughly aligned to the light source, with the hemisphere in the direction 
of the light source darker than the one pointing away from the light source. As advocated by Gooch et 
al. [12], we can accent the shape using a cool-towarm color shift by making sure the light source is 
yellow (warm) and the hemisphere facing away from the light is blue (cool). Our ambient approximation 
is shown in Figure 9 and is not measurably slower than a constant ambient component for non-trivial mmodels. 
 Figure 9: Left: simple ambient approximation. Right: directionally varying ambient approximation.  
3.2 Shadows One of the limitations of ray tracing is the hard edges computed for shadows. In addition 
to aesthetic reasons, there is evidence that soft edged shadows aid in accurate spatial perception [19]. 
Ray tracing methods that produce accurate soft shadows such as ray tracing with cones [l] or probabilistic 
ray tracing [5] stress accurate soft shadows, but dramatically increase computation time relative to 
hard shadow computation. In this section we examine how to compute soft-edged shadows approximately so 
that interactivity can be maintained.  One option to improve performance is to do explicit multisampling 
of the light with a beam made up of a small number of rays [15]. Since the number of rays is small, there 
will be visual artifacts but interactive performance will be possible (Figure 10). To speed up this 
computation we can precompute the rays in the beam if we assume the luminaire is far away, and we can 
vectorize the intersection computation against each geometric primitive. This is similar to traversing 
efficiency structures using bundles rather than single rays [9]. Although this optimization gives us 
a factor of two performance over the unvectorized version, it is still too slow for many shadow rays. 
An alternative to computing accurate soft shadows is to soften the edges of hard shadows. This is essentially 
the technique used in depth buffer algorithms [25] where the binary shadow raster can be filtered. However 
we want to simulate the change in penumbra width we see in real shadows. Such an effect requires more 
sophisticated filtering. This means shadow penumbra width should behave in a believable way, starting 
at zero at the occluder and increasing linearly with distance from the occluder. It is hard for observers 
to tell the difference between shadows cast by differently shaped lights. For this reason we assume spherical 
lights. We do a rough calculation at each illuminated point of what fraction  of the light is visible, 
and attenuate the unshadowed illumination by  Thus our goal is to estimate   in efficiently and to 
visually plausible results.  Rather than creating a correct shadow created by an area source, the algorithm 
creates a shadow of a object from a point source (Figure 11). The penumbra is the shadow of the semiopaque 
(outer) object that is not also shadowed by the opaque (inner) object. The transparency of the outer 
object increases from no transparency at the inner object to full transparency at the boundary of the 
outer object. For an isolated object, we can use inner and outer offsets of the real object to achieve 
believable results. We also need to make the intensity gradient in the penumbra natural. This can be 
achieved by computing the shadowing variable  beginning at  0 on the penumbra/umbra boundary (the 
surface of the inner object) and increasing non-linearly with distance to  = 1 on the outer boundary 
of the penumbra (the surface of the outer object). The above approach will give an approximate soft shadow. 
The size of the penumbra is based on the size of the offsets used to create the inner and outer objects. 
In order to have the penumbra width change plausibly, the offsets need to change based on the distance 
along the shadow ray and the size of the light source, as illustrated in Figure 12. This requires modifying 
the intersection tests for shadow rays. The details of this approach, including solutions to light leaking 
between two objects and the intersection tests and bounding box construction for polygons and spheres 
with varying offsets are discussed in more depth by Parker et al. [24]. The results are shown in Figure 
13.  3.3 Spline Surfaces In most traditional rendering systems NURBS are tessellated, often outside 
the graphics API in order to have more control over the accuracy. This can lead to an explosion in the 
amount of data that needs to be stored and then sent down the rendering pipeline. Ray tracing does not 
have this limitation. Intersection tests with NURBS have been done in several ways (e.g., [16, 29, 33]. 
Our approach computes an estimate to the intersection point and then uses a brute force approach to 
compute the actual intersection point. Surface parameter spaces are subdivided to a user-specified depth, 
and the quadtree that results is used to construct an inn-a-surface bounding volume hierarchy. Axisaligned 
bounding volumes are used to preserve consistency with the overall infrastructure. Bounding volume hierarchies 
are built bottom up. It is important to note that this will result in tighter volumes than top down construction 
(since the subdivided control meshes converge to the surface).   Intersections with the leaf nodes 
of the bounding volume tree are computed using Broyden s method. This is a pseudo-Newton solver which 
approximates the value of the Jacobian. It converges more slowly than Newton, but requires fewer function 
evaluations. The initial guess is given by the average of the boundary parameter values of the patch 
in question. Patches are allowed to overlap by a small percentage of their parametric domains, thereby 
lessening the chance of cracks. Usually fewer than three iterations of the root finder are required to 
converge to a suitably refined surface. The cost of storage is one copy of the original control mesh, 
and for each leaf node in the intra-surface bounding volume hierarchy, four doubles denoting the parametric 
interval it covers. In addition, we require each processor to reserve a scratch area so that the spline 
basis functions can be computed without needing to lock the data. The cost of this storage is where 
 and are the maximum control mesh dimensions over all surfaces in the scene. ates large models is scientific 
visualization. In Figure 15 we show a visualization of a stress simulation. Each node in the simulation 
is represented by a sphere. There are 35 million spheres in this model. Unlike conventional rendering 
systems, the high depth complexity has very little effect on the rendering times. Another area that 
can create complex models is architectural design. The model in Figure 16 contains roughly 75,000 polygons 
and a spline teapot. An area we would like to explore is the use of interactive ray tracing for walk 
throughs of globally illuminated static environments, where the illumination information has been computed 
in advance by such techniques as radiosity or density estimation. Usually specular and transparent effects 
are missing from such walk throughs. In addition, we should be able to easily allow higher order reconstruction 
of the solution. Also, we could greatly reduce polygon count if radiance lookup evaluates the mesh instead 
of representing each mesh element as a separate polygon.   4 RESULTS The final rendering system is 
interactive on relatively few (8) processors, and approaches real time for complex environments on 64 
or more processors. It runs well on a variety of models from different application areas. Its flexibility 
allows several different display modes, all of which are applicable to the various models. Ray tracing 
is ideal for showing dynamic effects such as specular highlights and shadows. Dynamic objects are more 
difficult to incorporate into a ray tracer than into a z-buffer algorithm as current acceleration schemes 
are not dynamic [11]. Our current workaround is to keep dynamic objects outside the acceleration scheme 
and check them individually for each ray. Obviously this only works for limited numbers of dynamic objects. 
In Figure 2 we show a static image from a set of bouncing balls using the soft shadow approximation. 
Computer-aided design usually uses both curved surfaces and non-diffuse objects, such as a windshield 
made from glass. Ray tracing can render curved surfaces directly, making it ideal for spline models. 
The ability to calculate accurate reflections across the surface make is possible to evaluate the smoothness 
and curvature of the models for aesthetic purposes. A sample of a directly ray traced spline primitives 
is shown in Figure 14. We have run on several models containing 20-2000 individual patches with runtimes 
ranging from 1-20 fps at 512 by 512 pixels on 60 processors. Ray tracing time is sub-linear with respect 
to model size. This allows us to interact with very large models. One area that cre- spheres. This image 
at 512 by 512 pixels runs approximately 15 frames per second on 60 CPUs.  5 RELATED WORK Ray tracing 
has long been a focus for acceleration through parallel techniques. There are two general parallel methods 
which are used for such acceleration: demand scheduling and data parallel. Demand driven scheduling 
refers to distributing tasks upon demand. Data parallel methods partition the data and assign tasks to 
the processors which contain the required data. Hybrid methods combine these two paradigms generally 
by partitioning the tasks into those requiring a small amount of data and those requiring a large amount. 
Since shared memory processors with large amounts of memory have only recently been commercially available, 
most parallel ray tracing research has focused on distributed memory architectures. For shared memory 
parallel computers, demand driven scheduling methods tend to lead to the best performance [26]. Our implementation 
is based on demand driven scheduling where the task granularity is rendering an 32 by 4 pixel tile. 
In this section, we provide a comparison with several related parallel ray tracing implementations. 
A more thorough general review is provided by Reinhard and Jansen [26]. Muuss and researchers from ARL 
have experimented with parallel and distributed ray tracing for over a decade [20, 21]. In their recent 
work, they describe a parallel and distributed real-time ray tracer running on a cluster of SGI Power 
Challenge machines [21]. One of the differences between BRL s effort and ours is the geometric primitives 
used. Their geometry is defined by through a CSG modeler, BRL-CAD. Additionally, we leverage the tight 
coupling of the graphics hardware on the SGI Origin while their system uses an image decomposition scheme 
combined with a network attached framebuffer. Muuss points out that synchronization, particularly at 
the frame level, is critical for real-time ray tracing [21]. Our research indicates that synchronization 
within a frame is also critical as noted by our dynamic load balancing scheme. Although not reported 
in the literature, ARL s current effort seems to have a comparable framerate as ours (Muuss, personal 
communication at SIGGRAPH98).  Keates and Hubbold use a distributed shared memory architecture, the 
KSRl, to implement a demand driven ray tracer which renders a simple scene is slightly over 1.8 seconds 
for 256 processors [18]. Their implementation is similar to ours in that they use the brute force technique 
of parallelizing over rays. However, their work differs in the granularity of work distribution, the 
method used for load balancing, and results based upon architecture. Their implementation split the screen 
into regions and divided the work among the CPUs. It is not clear how large the regions were but one 
is lead to believe the regions are larger than the 32 pixel regions used in our implementation. They 
report problems with load balancing and synchronization. They address these by a two level hierarchy 
for screen space subdivision similar to Ellsworth [8]. Our system uses a different strategy for load 
balancing of decreasing granularity of assigned work which empirically yields better results. This also 
assists in synchronization which is why this issue has not been a problem for us. Singh et al. reported 
on using the Stanford DASH distributed shared memory machine for ray tracing [32]. Their implementation 
used an image decomposition scheme which subdivided the image among the available processors. Within 
a processor, the sub-image a further subdivided into 8 by 8 pixel tiles. As in our system, their implementation 
noted the advantage of data cache reuse for object intersection test. Their work differed from ours in 
the load balancing scheme. They used task stealing rather than demand driven scheduling. We find that 
the simpler approach of using a task queue with good dynamic load balancing provides excellent results 
without the complexity of performing task stealing. The fetch and op hardware in the Origin architecture 
allows the task queue to per form well even on a large number of processors. Yoon et al. use an image 
partitioning scheme which statically load balances the tasks by interleaving pixels and distributing 
among nodes the scene data while replicating the spatial hierarchy on each node [34]. Their work attempts 
to prefetch data for each ray task. Their work differs from ours in two major respects: load balancing 
and machine architecture. Our implementation effectively exploits dynamic load balancing through the 
heuristic of decreasing task size while Yoon et al. employ static load balancing through pixel assignment. 
Since their work focuses on a distributed memory architecture, they need to explicitly address data distribution 
while our implementation exploits the CC-NUMA distributed shared memory. Reinhard and Jansen use a hybrid 
scheduling method for parallel ray tracing [27]. Their implementation divides the ray tracing task into 
those tasks which require limited amounts of data and those that require more substantial amounts of 
data. Since their spatial subdivision hierarchy, but not the leaf nodes, is replicated on each processor, 
tasks using these are demand scheduled whereas tracing rays through the objects within the leaf nodes 
is performed in a data parallel fashion. Their method makes novel use of this combined scheduling scheme 
which provides better performance on distributed memory parallel computers. Since our method exploits 
the distributed shared memory architecture, we can achieve very good performance with only demand scheduling. 
Bala et al. describe a bounded error method for ray tracing [2]. For each object surface, their method 
uses a 4D linetree to store a collection of interpolants representing the radiance from that surface. 
If available, these interpolants are reprojected when the user s viewpoint changes. If not, the system 
intersects the ray with the scene checking for a valid interpolant at the intersection point. If one 
is found, the radiance for that pixel is interpolated. Otherwise, using that linetree cell, an attempt 
is made to build an interpolant. If this is within an error predicate, it is used otherwise the linetree 
cell is subdivided and the system falls back to shading using a standard ray tracing technique. The acceleration 
is based upon the utilization of previously shaded samples bounded by an error predicate rather than 
fully tracing every ray. Our system is brute-force and traces every ray in parallel. Bala s method is 
oriented toward a more informed and less parallel strategy, and is currently not interactive. Moving 
objects would pose a problem for the linetree based system whereas they can be handled in our implementation. 
Using reprojection techniques might further accelerate our system.  6 CONCLUSION Interactive ray tracing 
is a viable approach with high end parallel machines. As parallel architectures become more efficient 
and cheaper this approach could have much more widespread application. Ray tracing presents a new set 
of display options and tradeoffs for interactive display, such as soft shadows, frameless rendering, 
more sophisticated lighting, and different shading models. The software implementation allows us to 
easily explore these options and to evaluate their impact for an interactive display. We believe the 
following possibilities are worth investigating: . How should antialiasing be handled? . How do we handle 
complex dynamic environments? How do we ensure predictable performance for simulation applications? 
 What should the API be for an interactive ray tracer?  . How could an inexpensive architecture be 
built to do interactive ray tracing?   Figure D: A model with splines, glass, image textures, and 
procedu ral solid textures. At 512 by 512 pixels this image is generated at approximately 4 frames per 
second on 60 CPUs.  
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198752</article_id>
		<sort_key>13</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[Supporting animation and interaction]]></title>
		<page_from>13</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198752</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198752</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40031782</person_id>
				<author_profile_id><![CDATA[81100041422]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ingo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wald]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MPII Saarbruecken]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
  T h e N e e d f o r D y n a m i c S c e n e s   Part I: How to achieve maximum performance ?  Fast 
ray surface intersection  CPU Friendly implementation  AND: High quality acceleration data structures 
(ADS).   Problem: Building ADS takes time Up to minutes for realistically complex models (1MTri) 
 For Walkthrough applications: Not a problem Build once (preprocess), reuse in following frames  BUT: 
Can t change geometry  T h e N e e d f o r D y n a m i c S c e n e s   Static Geometry: Already many 
practical applications Design reviews, massive engineering models, architecture, lighting/reflection 
simulation  But: Not applicable to dynamic scenes  Games (the main driving force of 3D graphics!) 
  Can t do even simple editing (switching variants, moving parts, )   Future scenario: RTRT as mainstream 
3D graphics ?  MUST offer ability to interact with model If only for games  K i n d s o f D y n a m 
i c S c e n e s  Need to differentiate between different kinds of dynamics Hierarchical Animation 
 Typical application: Scene graphs  Unstructured Motion Typical application: Simulations, skinning, 
explosions,  Timestepped Animation One one out of k discrete poses per frame (game characters)  Mostly 
hierarchical: Skeleton + skinning  . Totally different scenarios . There is no best solution to ray 
tracing dynamic scenes  R a y T r a c i n g D y n a m i c S c e n e s F i r s t a p p r o a c h e s 
  Alternative 1: Handle dynamic objects separately  Already used in 98/99 [Parker]  Keep dynamic 
objects out of ADS, intersect separately  Only works for very few dynamic objects   Alternative 2: 
Rebuild ADS every frame  (Super )linear in #objects  Only applicable to tiny scenes  Note: This might 
change for future HW   R a y T r a c i n g D y n a m i c S c e n e s F i r s t a p p r o a c h e s 
  Alternative 3: Progressively build ADS Motivation: Often only parts of scene visible Might only 
need small part of ADS  Build hierarchical ADS lazily and progressively E.g., split node only once 
ray reaches that node  Problem:  Even initial split (for kd tree) already O(N) . Too costly already 
 Not really used in practice   R a y T r a c i n g D y n a m i c S c e n e s F i r s t a p p r o a 
c h e s  Alternative 4: Update ADS for dynamic objects Problem 1: How to avoid degeneration of ADS 
?  Problem 2: How to efficiently update ADS ?  Kd trees: Quite problematic  Original cost estimates 
(SAH) wrong/useless after geom. changes  Updating often not (easily) possible  E.g., can t move root 
split: would need to rebuild all sibling nodes  Similar for other hierarchical ADS   But: works reasonably 
well for grids [Reinhard01]  R e i n h a r d s A p p r o a c h : D y n a m i c a l l y u p d a t e 
v i r t u a l G r i d   Basic Idea: Use (regular) grid, update dynamically  Efficient updates: Maintain 
different grid resolutions Large primitives on coarse levels, small primitives on fine levels .Each 
prim. covers few cells: remove/add/move primitive in O(1)  Avoiding degeneracy: Grid wraps around  
Objects moving out of right side re enter on left side No rebuild required even if scene s bounds changes 
  Same for rays (slightly different traversal)  Still: Rebuild from scratch every few frames...  
  R e i n h a r d s A p p r o a c h : D y n a m i c a l l y u p d a t e v i r t u a l G r i d   Results: 
Works well for many scenes In particular: Completely unstructured motion  But: Only works for grid-like 
ADS  Traversal performance relatively low  Problematic for large scenes with varying primitive distribution 
 Does not easily generalize to more efficient ADS   Plus: quite problematic for hierarchical animation 
 E.g., slight rotation of scene costs O(N) update D y n a m i c S c e n e s i n O p e n R T  Main 
observations: Prefer kd trees for high performance and complex scenes  Problematic for update/rebuild 
operations  But: interactive rebuild possible for few dynamic objects   Update/rebuild approaches 
problematic for hierarchical animation (small change triggers complete rebuild)  Most practical scenes 
use (mostly) hierarchical animation  Scene changes often localized  In particular: Unstructured motion 
often very localized (e.g., explosion in complete game level...  D y n a m i c S c e n e s i n O p e 
n R T H i e r a r c h i c a l S c e n e O r g a n i z a t i o n  OpenRT approach [PGV 2003]: Application 
groups geometry into objects  Wrt same properties concerning dynamic updates Similar to building display 
lists  Each object has its own acceleration structure   Objects can be re-used in subsequent frames 
 No rebuild necessary  Application can redefine object(s) any time  .Unstructured motion: just redefine 
object every frame D y n a m i c S c e n e s i n O p e n R T H i e r a r c h i c a l S c e n e O r g 
a n i z a t i o n   Objects are instantiated into the scene  Each instance has a transformation attached 
to it Hierarchical Animation: Inversely transform rays instead of objects .Can keep object itself static 
.Only need to update instance transformation  Instances are organized in additional hierarchy level 
 With its own acceleration structure (kd tree of instances)  Only this has to be rebuilt every frame 
 Use highly optimized rebuild algorithm   Also SAH, but: much simpler (only boxes of objects), highly 
optimized, D y n a m i c S c e n e s i n O p e n R T H i e r a r c h i c a l S c e n e O r g a n i z 
a t i o n  Special Case: Timestepped Animation Can be realized quite simply  Build one object for 
every timestep All kd trees built in advance  Hide all but current timestep s instance Simply switch 
instance per frame, no rebuild at all.  Sufficient for many game like applications   Extension to 
(simple) skinning possible  No details here (not yet published)  D y n a m i c S c e n e s i n O p 
e n R T U n s t r u c t u r e d M o t i o n  Support for unstructured motion  Build special object 
for dynamic triangles  Rebuild (only) this object ever frame  Rebuild tolerable for few ( 1k 10k) objects 
 Use cheap, low quality kd trees for these objects Trade object s traversal performance for construction 
time  Can have multiple dynamic object s    Problem: Parallelization framework  Need to send each 
dynamic triangle to each client Huge bandwidth required for many clients and dyn. triangles  R e s u 
l t s : M u l t i p l e I n s t a n t i a t i o n  Side Effect: Multiple Instantiation is for free ! 
 Different instances simply share same geometry  Example: Sunflowers (26,000 instances, 1 billion 
triangles)   R e s u l t s : U n s t r u c t u r e d M o t i o n  Unstructured Motion: Possible, 
but costly  Rebuild for <10,000 instances: Tolerable, but costly  Main bottleneck: Network bandwidth 
 Need to transfer each updated triangle to each client in turn  Not worked on since 02/03: Few practical 
applications   R e s u l t s : P r a c t i c a l A p p l i c a t i o n s  Totally sufficient for 
typical VR applications (simple editing and variant switching)  Note: Cost only depends on #instance, 
not on #triangles  UNC Powerplant (12.5 MTri), single PC G a m e E x a m p l e 1 : Q u a k e 3 / R 
T ( J o e r g S c h m i t t l e r , D a n i e l P o h l )  Quake3 bots/scenes, self written game engine 
 Fully ray traced (using OpenRT API)  Dynamic bots, monsters: timestepped animation  Plus: Lots of 
small moving objects, missiles, cartridges,    
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198753</article_id>
		<sort_key>14</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Handling dynamic scenes]]></title>
		<page_from>14</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198753</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198753</url>
		<abstract>
			<par><![CDATA[Even though ray tracing is a relatively old and well-understood technique, its use for interactive applications is still in its infancy. Several issues of interactive applications are all but fully solved. Especially the handling of dynamic scenes in an interactive context so far has received few attention by ray tracing researchers. Ray tracing research so far almost exclusively concentrated on accelerating the process of creating a <i>single</i> image, which could take from minutes to hours. Most of these approaches relied on doing extensive preprocessing by building up complex data structures to accelerate the process of tracing a ray.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40031465</person_id>
				<author_profile_id><![CDATA[81100041422]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ingo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wald]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Saarland University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{Amanatides87} John Amanatides and Andrew Woo. A Fast Voxel Traversal Algorithm for Ray Tracing. In Eurographics '87, pages 3--10. 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{Carey97} Rikk Carey, Gavin Bell, and Chris Marrin. ISO/IEC 14772-1:1997 Virtual Reality Modelling Language (VRML97), April 1997. http://www.vrml.org/Specifications/VRML97.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1081419</ref_obj_id>
				<ref_obj_pid>1081407</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{DeMarle03} David E. DeMarle, Steve Parker, Mark Hartner, Christiaan Gribble, and Charles Hansen. Distributed Interactive Ray Tracing for Large Volume Visualization. In Proceedings of the IEEE Symposium on Parallel and Large-Data Visualization and Graphics (PVG), pages 87--94, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1010373</ref_obj_id>
				<ref_obj_pid>1009389</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{Dietrich04} Andreas Dietrich, Ingo Wald, Markus Wagner, and Slusallek. VRML Scene Graphs on an Interactive Ray Tracing Engine. In Proceedings of IEEE VR 2004, pages 109--116, March 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617407</ref_obj_id>
				<ref_obj_pid>615999</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{Glassner88} Andrew Glassner. Spacetime Ray Tracing for Animation. IEEE Computer Graphics and Applications, 8(2):60--70, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{Gr&#246;ller91} Eduard Gr&#246;ller and Werner Purgathofer. Using temporal and spatial coherence for accelerating the calculation of animation sequences. In Proceedings of Eurographics '91, pages 103--113. Elsevier Science Publishers, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{Haines87} Eric A. Haines. A Proposal for Standard Graphics Environments. IEEE Computer Graphics and Applications, 7(11):3--5, November 1987. Available from http://www.acm.org/pubs/tog/resources/SPD/overview.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{Haines91} Eric Haines. Efficiency Improvements for Hierarchy Traversal in Ray Tracing. In James Arvo, editor, Graphics Gems II, pages 267--272. Academic Press, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{Havran01} Vlastimil Havran. Heuristic Ray Shooting Algorithms. PhD thesis, Faculty of Electrical Engineering, Czech Technical University in Prague, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{Intel02} Intel Corp. Intel Pentium III Streaming SIMD Extensions. http://developer.intel.com/vtune/cbts/simd.htm, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15916</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{Kay86} Timothy L. Kay and James T. Kajiya. Ray Tracing Complex Scenes. Computer Graphics (Proceedings of SIGGRAPH 86), 20(4):269--278, June 1986. Held in Dallas, Texas.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{Kirk91} David Kirk and James Arvo. Improved Ray Tagging For Voxel-Based Ray Tracing. In James Arvo, editor, Graphics Gems II, pages 264--266. Academic Press, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{Lext00} Jonas Lext, Ulf Assarsson, and Tomas M&#246;ller. BART: A Benchmark for Animated Ray Tracing. Technical report, Department of Computer Engineering, Chalmers University of Technology, G&#246;teborg, Sweden, May 2000. Available at http://www.ce.chalmers.se/BART/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{Lext01} Jonas Lext and Tomas Akenine-M&#246;ller. Towards Rapid Reconstruction for Animated Ray Tracing. In Eurographics 2001 - Short Presentations, pages 311--318, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{OpenSG01} OpenSG-Forum. http://www.opensg.org, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{OSG} OpenSceneGraph. http://www.openscenegraph.org.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300537</ref_obj_id>
				<ref_obj_pid>300523</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[{Parker99} Steven Parker, Peter Shirley, Yarden Livnat, Charles Hansen, and Peter-Pike Sloan. Interactive Ray Tracing. In Proceedings of Interactive 3D Graphics, pages 119--126, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732126</ref_obj_id>
				<ref_obj_pid>647652</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[{Reinhard00} Erik Reinhard, Brian Smits, and Chuck Hansen. Dynamic Acceleration Structures for Interactive Ray Tracing. In Proceedings of the Eurographics Workshop on Rendering, pages 299--306, Brno, Czech Republic, June 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807479</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[{Rubin80} Steve M. Rubin and Turner Whitted. A Three-Dimensional Representation for Fast Rendering of Complex Scenes. Computer Graphics, 14(3):110--116, July 1980.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569051</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[{Schmittler02} J&#246;rg Schmittler, Ingo Wald, and Philipp Slusallek. SaarCOR - A Hardware Architecture for Ray Tracing. In Proceedings of the ACM SIGGRAPH/Eurographics Conference on Graphics Hardware, pages 27--36, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732298</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[{Wald01} Ingo Wald, Philipp Slusallek, and Carsten Benthin. Interactive Distributed Ray Tracing of Highly Complex Models. In Steven J. Gortler and Karol Myszkowski, editors, Rendering Techniques, Proceedings of the 12th Eurographics Workshop on Rendering Techniques, London, UK, June 25-27, 2001, pages 274--285. Springer, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[{Wald02a} Ingo Wald, Carsten Benthin, and Philipp Slusallek. OpenRT - A Flexible and Scalable Rendering Engine for Interactive 3D Graphics. Technical report, Saarland University, 2002. Available at http://graphics.cs.uni-sb.de/Publications.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>581899</ref_obj_id>
				<ref_obj_pid>581896</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[{Wald02b} Ingo Wald, Thomas Kollig, Carsten Benthin, Alexander Keller, and Philipp Slusallek. Interactive Global Illumination using Fast Ray Tracing. Rendering Techniques, pages 15--24, 2002. (Proceedings of the 13th Eurographics Workshop on Rendering).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[{Wald03} Ingo Wald, Timothy J. Purcell, J&#246;rg Schmittler, Carsten Benthin, and Philipp Slusallek. Realtime Ray Tracing and its use for Interactive Global Illumination. In Eurographics State of the Art Reports, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[{Wald04} Ingo Wald. Realtime Ray Tracing and Interactive Global Illumination. PhD thesis, Computer Graphics Group, Saarland University, 2004. Available at http://www.mpi-sb.mpg.de/~wald/PhD/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[{Wernecke94} Josie Wernecke. The Inventor Mentor. Addison-Wesley, 1994. ISBN 0-20162-495-8.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Siggraph 2005 Course on Interactive Ray Tracing Handling Dynamic Scenes Ingo Wald This is an excerpt 
from Realtime Ray Tracing and Interactive Global Illumination , PhD Thesis, Ingo Wald, Computer Graphics 
Group, Saarland University. Full Version available at http://www.mpi-sb.mpg.de/~wald/PhD The time spent 
constructing the hierarchy tree should more than pay for itself in time saved rendering the image Timothy 
L. Kay, James T. Kajiya Ray Tracing Complex Scenes [Kay86] (in 1986!) Even though ray tracing is a relatively 
old and well-understood technique, its use for interactive applications is still in its infancy. Several 
issues of interactive applications are all but fully solved. Especially the handling of dynamic scenes 
in an interactive context so far has received few attention by ray tracing researchers. Ray tracing research 
so far almost exclusively concentrated on accelerating the process of creating a single image, which 
could take from minutes to hours. Most of these approaches relied on doing extensive preprocessing by 
building up complex data structures to accelerate the process of tracing a ray. Before realtime ray tracing, 
the time used for building an index structure such as kd-trees was insigni.cant compared to the long 
rendering times, as this preprocessing was then amortized over the remainder of a frame. Thus preprocessing 
times of several seconds to a few minutes could easily be tolerated in order to build a high-quality 
acceleration structure for an o.ine renderer. As long as the scene remains static, the same trick also 
worked for interactive ray tracing systems as described before the acceleration structure was built 
once in an o.ine preprocessing step, and was then reused for all the remaining frames1 . In dynamic scenes, 
however, this trick no longer works, as each new frame requires a new acceleration structure. Building 
this data structure for every 1Even though the scene itself has to remain static in this approach, it 
is still possible to arbitrarily change camera, material properties, shaders, and light source con.gurations 
in a scene. frame then becomes a bottleneck, as this preprocessing alone would often exceed the total 
time available per frame in an interactive setting. Even worse, this preprocessing phase cannot easily 
be parallelized: Though tracing the rays can be parallelized trivially once each client has access to 
scene and acceleration structure, the operations for building the acceleration structure have to be performed 
on each client, thereby incurring a non-parallelizable cost factor. As a result, any time spent on dynamic 
updates becomes extremely costly especially for parallel (distributed) interactive ray tracing systems2. 
This poses a major problem for ray tracing dynamic scenes, as virtually all of todays interactive ray 
tracing (e.g. [Wald01, Parker99, DeMarle03, Wald03]) systems have to rely on massive parallelization 
to achieve interactive frame rates. Therefore, it is not surprising that all of those systems have in 
common that they mainly concentrate on the actual ray tracing phase and do not target dynamic scenes. 
Without methods for interactively modifying the scene, however, interactive ray tracing will forever 
be limited to simple walk-throughs of static environments, and can therefore hardly be termed truly interactive, 
as long as real interaction between the user and the environment is not impossible. In order to be truly 
interactive, ray tracing must be able to e.ciently support dynamic environments. As such, e.cient handling 
of dynamic scenes is probably one of the biggest challenges for realtime ray tracing. 1 Previous Work 
Some methods have been proposed for the case where prede.ned animation paths are known in advance (e.g. 
[Glassner88, Groller91]). These however are not applicable to our target setting of totally dynamic, 
unpredictable changes to the scene in which the motion of objects is not known in advance. Little research 
is available for such truly interactive settings. This research will be reviewed below. First of all, 
excellent work on ray tracing in dynamic environments has recently been performed by Lext et al. with 
the BART project [Lext00], in which they provide an excellent analysis and classi.cation of the problems 
arising in dynamic scenes. Based on this analysis, they proposed a representative set of test scenes 
(see Figure 1) that have been designed to stress the di.erent aspects of ray tracing dynamic scenes. 
Thus, the BART benchmark provides an excellent tool for evaluating and analyzing a dynamic ray tracing 
engine. For future research on dynamic ray tracing, the BART benchmark suite might well play the same 
role that Eric Haines SPD Database [Haines87] played for o.ine rendering. In their analysis, Lext et 
al. have classi.ed the behavior of dynamic scenes into two inherently di.erent classes: Hierarchical 
motion, and unstructured mo 2As an example, consider a system that spends only 5% of its time on dynamic 
scene updates. Parallelizing this system on 19 CPUs ( 1 - 1) results in each node spending half 5% its 
time on scene updates, and in a speedup of only 10 for 19 CPUs (i.e. a utlization of only 10 ~ 50%)! 
19 Figure 1: Some example screen-shots from the BART benchmark: (a) robots , where 10 robots (each consisting 
of 16 independently moving body parts) are walking through a city model; (b) kitchen , in which a small 
toy car is driving through a highly specular kitchen scene; and (c) museum , where a certain amount of 
re.ective triangles is animated incoherently to form several di.erent shapes. The number of triangles 
in the museum scene can be con.gured from a few hundred to some hundred thousand triangles. tion. In 
hierarchical motion, the animation is described by having the primitives in a scene organized into several 
groups that are transformed hierarchically. While di.erent groups may move independently of all other 
groups, all primitives in the same group are always subject to the same, usually a.ne, transformation3 
. The other class is unstructured motion, where each triangle moves without relation to all others. For 
example, the robots scene in Figure 1a is a good example of hierarchical motion, as there is no dynamic 
behavior except for hierarchical translation and rotation of the di.erent robots body parts. In contrast 
to this, the museum scene (Figure 1c) features many incoherently moving triangles, and as such is a good 
example for unstructured motion. For a closer explanation of the di.erent kinds of motion, see the BART 
paper [Lext00]. Though the BART paper provides an excellent analysis of dynamic ray tracing, it did 
not attempt to propose any practical algorithms or solutions to the problems. So far, few people have 
worked on this topic. In a .rst step, Parker et al. [Parker99] kept moving primitives out of the acceleration 
structure and checked them individually for every ray. This of course is only feasible for a small number 
of moving primitives. Another approach would be to e.ciently update the acceleration structure whenever 
objects move. Because objects can occupy a large number of cells in an acceleration structure this may 
require costly updates to large parts of the structure for each moving primitive (especially for large 
primitives, which tend to overlap many cells). To overcome this problem, Reinhard et al. [Reinhard00] 
proposed a dynamic acceleration structure based on a hierarchical grid. In order to quickly insert and 
delete objects independently of their size, larger objects are kept in coarser levels of the hierarchy. 
With this approach, objects always cover approximately a constant number of cells, thus updating the 
acceleration struc 3A.ne transformation are not limited to translation and rotation only, but also include 
e.g. shearing or scaling. ture can be performed in constant time. However, their method resulted in a 
rather high overhead, and also required their data structure to be rebuilt once in a while to avoid degeneration. 
Furthermore, their method mainly concentrated on unstructured motion, and is not well suited for hierarchical 
animation. Recently, Lext et al. [Lext01] proposed a way for quickly reconstructing an acceleration structure 
in a hierarchically animated scene by transforming the rays to the local object coordinate systems instead 
of transforming the objects and rebuilding their acceleration structures. Though their basic idea is 
similar to the way that our method handles hierarchical animation, to our knowledge their method so far 
has never been applied in an interactive context. 2 A Hierarchical Approach to Handling Dynamic Scenes 
Essentially, our approach to handling dynamic scenes is motivated by the same observations as Lext et 
al. [Lext01] of how dynamic scenes typically behave: Usually large parts of a scene remain static over 
long periods of time. Other parts of the same scene undergo well-structured transformations such as rigid 
body motion or a.ne transformations. Yet other parts are changed in a totally unstructured way. All these 
kinds of motion are fundamentally di.erent. Even worse, many scenes actually contain a mix of all these 
di.erent kinds of motion. It is unlikely that a single method can handle all these kinds of motion equally 
well. Because of this, we prefer an approach in which the di.erent kinds of motion are handled with di.erent, 
specialized algorithms that are then combined into a common architecture. To do this, geometric primitives 
are organized in separate objects according to their dynamic properties. Each of the three kinds of objects 
 static, hierarchically animated, and those with unstructured motion is thus treated di.erently: Static 
objects will be handled as before, hierarchically animated objects are handled by transforming rays rather 
than the object, and objects with unstructured motion are handled by specially optimized algorithms for 
quickly rebuilding the a.ected parts of the data structure. Each object has its own acceleration structure 
and can be updated independently of the rest of the scene. These independent objects are then combined 
in a hierarchical way by organizing them in an additional top-level acceleration structure that accelerates 
ray traversal between the objects in a scene (see Figure 2). 2.1 Building the Hierarchy To enable this 
scheme, all triangles that are subject to the same set of transformations (e.g. all the triangles forming 
the head of the animated robot in Figure 3) must be grouped by the application into the same object. 
Note that we explicitly do not attempt to perform this grouping automatically. Instead, this grouping 
has to be performed by the application that drives the ray tracer. Though this somewhat shifts the problem 
to the application, the Figure 2: Two-level hierarchy as used in our approach: A top-level BSP contains 
references to instances, which contain a transformation and a reference to an object. Objects in turn 
consist of geometry and a local BSP tree. Multiple instances can refer to the same object with di.erent 
transformations.  Figure 3: Grouping of triangles into objects for hierarchical animation. Triangles 
subject to the same hierarchical transformations are grouped into the same object. (a) Snapshot from 
the BART robots scene, (b) Same snapshot, with color-coded objects. Triangles with the same color belong 
to the same object. application itself has the information about the motion of every part of the scene 
in its internal scene-graph, and can typically perform this classi.cation without major e.ort. In fact, 
most applications already do this for OpenGL rendering, as the same grouping of objects is required for 
e.ciently using OpenGL display lists (also see the discussion of the accompanying document on OpenRT). 
However, the actual grouping of objects into objects has a higher in.uence on rendering performance than 
for OpenGL display lists. As such, it is important to perform this grouping with extreme care in order 
to achieve good performance. In the following, we will shortly describe how these di.erent kinds of objects 
are treated, and how the top-level index structure is built and traversed. Figure 4: Snapshots of an 
interactive session in which complex parts of the 12.5 million triangle UNC power plant model are being 
moved interactively with our method: a) the original powerplant, b) moving the powerplant and the construction 
side apart, and c) moving part of the internal structure (the cool and warm water pipes, totalling a 
few million triangles!) out of the main structure).  3 Static and Hierarchical Motion For static objects, 
ray traversal works as before by just traversing the ray with our usual, fast traversal algorithm. For 
hierarchically transformed objects, we do not actually transform the geometry of the object itself, 
but rather store this transformation with the object, and inversely transform the rays that require intersection 
with this object4 . For both static objects and for those with hierarchical motion, the local BSP tree 
must only be built once directly after object de.nition. Thus, the time for building these objects is 
not an issue, thereby allowing for the use of sophisticated and slow algorithms for building high-quality 
acceleration structures for these objects. Obviously the transformation slightly increases the per-ray 
cost. However, this transformation has to be performed only once for each dynamic object visited by a 
ray, and is as such tolerable. This increased per-ray cost then totally removes the reconstruction cost 
for hierarchically animated objects, as all that is required for transforming the object is to update 
its transformation matrix. This is especially important as this kind of motion is usually the most common 
form in practical scenes. Furthermore, not having to rebuild any BSP trees make the update-cost for hierarchically 
transformed objects independent of object size. As such, this way of handling hierarchical animation 
can be used very e.ciently even in extremely complex scenes. For example, Figure 4 shows how a complex 
part of the 12.5 million triangle UNC power plant is being moved in an interactive session. 3.1 Instantiation 
Being able to handle objects that are subject to a transformation, the presented approach as a side e.ect 
also allows for instantiation , i.e. using multiple in 4Note that this way of handling is similar to 
the approach of Lext et al. [Lext01]. stances of the same object: Parts of a scene (e.g. one of the sun.owers 
in Figure 5) can re-used several times in the same scene by creating several instances of this object. 
An instance then consists only of two properties: a reference to the original model, and a transformation 
matrix that the instanced object is subject to. Thus, even highly complex scenes can be stored with a 
small memory footprint, which in turn allows for e.ciently rendering even massively complex scenes at 
interactive rates. As an example, Figure 5 shows a slight modi.cation of Oliver Deussen s Sun.owers scene, 
which consists of several large trees with millions of triangles each, plus 28,000 instances of 10 di.erent 
sun.ower models with roughly 36,000 triangles each. While only one kind of tree and 10 kinds of sun.owers 
have to actually be stored, in total roughly one billion triangles are potentially visible. By changing 
the transformation matrices of the instances, each object can be manipulated interactively while the 
scene renders at about 7 fps on 24 dual processor PCs at video resolution (see Table 4). Note that this 
performance can be achieved even tough a large number of rays needs to be cast in this scene: The leaves 
of both sun.owers and trees are modeled with transparency textures, which results in many rays for computing 
transparency and semi-transparent shadows. Figure 5: Instantiation: The Sun.owers scene consists of 
roughly 28,000 instances of 10 di.erent kinds of sun.owers with 36,000 triangles each together with 
several multi-million-triangle trees. The whole scene consists of roughly one billion triangles. The 
center image shows a closeup of the highly detailed shadows cast by the sun onto the leaves. All leaves 
contain textures with transparency which increase the number of rays needed for rendering a frame. The 
whole scene renders at roughly 7 fps on 24 dual PCs at video resolution. All objects including the sun 
can be manipulated interactively.  Fast Handling of Unstructured Motion While this simple trick of transforming 
rays instead of triangles elegantly avoids any reconstruction cost for hierarchical motion, it does not 
work for unstructured motion, as there the acceleration structure potentially has to be rebuilt for 
every frame. Even so, if triangles under unstructured motion are kept in a separate object, the BSP reconstruction 
cost can be localized to only those triangles that have actually been transformed. The local acceleration 
structures of such objects are discarded and rebuilt from the transformed triangles whenever necessary. 
Even though this process is costly, it is only required for objects with unstructured motion and does 
not a.ect any of the other objects. Obviously, only those objects have to be rebuilt whose primitives 
have actually be modi.ed in the respective frame. Furthermore, it is possible to perform this reconstruction 
of dynamic objects lazily on demand, i.e. only once a ray actually demands intersection with that updated 
object. As such, the occlusion-culling feature of ray tracing also applies to the reconstruction of dynamic 
objects, as occluded objects do not have to be rebuilt. The algorithms for creating highly optimized 
BSP trees may require several seconds even for moderately complex objects. Thus, they are not applicable 
to unstructured motion, for which the object BSP has to be rebuilt every frame (and thus in fractions 
of a second). For these cases we trade traversal performance for construction speed by using less expensive, 
simple heuristics for BSP plane placement, which allows for a high-performance implementation of the 
construction process. 4.1 Using less costly BSP Construction Parameters Furthermore, we use less expensive 
quality parameters for the BSP plane placement heuristics. For example, a particularly important cost 
factor for BSP tree construction is the subdivision criterion of the BSP. As described in the accompanying 
document on the RTRT core, this criterion typically consist of a maximum tree depth and a target number 
of triangles per leaf cell. Subdivision continues on cells with more than the target number of triangles 
up to the maximum depth. Typical criteria specify 2 or 3 triangles per cell and usually result in fast 
traversal times but also in deeper BSPs, which are more costly to create. Particularly costly are degenerate 
cases, in which subdivision can not reduce the number of triangles per cell, for example if too many 
primitives occupy the same point in space, e.g. at vertices with a valence higher than the maximum numbers 
of triangles. In order to avoid such excessive subdivisions in degenerate regions, we modi.ed the subdivision 
criterion (for unstructured object BSPs): The deeper the subdivision, the more triangles will be tolerated 
per cell. We currently increase the tolerance threshold by a constant factor for each level of subdivision. 
Thus, we generally obtain signi.cantly lower BSP trees and larger leaf cells than for static objects. 
Though this of course slows down the traversal of rays hitting such objects, this slowdown is usually 
more than made up by the signi.cantly shorter construction time. Furthermore often only few rays hit 
such objects with unstructured motion and are a.ected by this slowdown, so using a slower BSP tree for 
those rays is tolerable. With the described compromises on BSP construction, unstructured motion for 
moderate-sized objects can be supported by rebuilding the respective object BSP every frame.  Fast Top-Level 
BSP Construction As mentioned before, all kinds of objects static, hierarchically animated, and those 
with with unstructured motion are hierarchically combined in an additional top-level acceleration structure. 
For this top-level structure, we also use a kd-tree, and as such can use exactly the same algorithms 
for traversing this top-level tree than for the object BSPs, except that visiting a voxel now requires 
to intersect objects rather than triangles. While traversing this top-level BSP thus requires only minor 
changes to the original implementation, this is not the case for the construction algorithm. A scene 
can easily contain hundreds or thousands of instances (see Figures 6 and 5), and a straight-forward approach 
would be too costly for interactive use. On the other hand, the top-level BSP is traversed by every ray, 
and thus few compromises on BSP quality can be made for the top-level BSP. Fortunately, the task of building 
the top-level BSP is simpler than for object BSPs: Object BSPs require costly triangle-in-cell computations, 
careful placement of the splitting plane, and handling of degenerate cases. The top-level BSP however 
only contains instances represented by an axis-aligned bounding box (AABB) of its transformed object5 
. Considering only the AABBs, optimized placement of the splitting plane becomes much easier, and any 
degenerate cases can be avoided. For splitting a cell, we follow several observations: 1. It is usually 
bene.cial to subdivide a cell in the dimension of its maximum extent, as this usually yields the most 
well-formed cells [Havran01]. 2. Placement of the BSP plane only makes sense at the boundary of objects 
contained within the current cell. This is due to the fact that the costfunction can be maximal only 
at such boundaries [Havran01]. 3. It can been shown that the optimal position for the splitting plane 
lies between the cells geometric center and the object median [Havran01]  Following these observations, 
the BSP tree can be built such that it is both suited for fast traversal by optimized plane placement, 
and can still be built quickly and e.ciently: For each subdivision step, we try to .nd a splitting plane 
in the dimension of maximum extent (observation 1). As potential splitting planes, only the AABB borders 
will be considered (observation 2). To .nd a good splitting plane, we .rst split the cell in the middle, 
and decide which side contains more objects, i.e. which one contains the object median. From this side, 
we choose the object boundary closest to the center of the cell. Thus, the splitting plane lies in-between 
cell center and object median, which is generally a good choice (observation 3). 5While the object itself 
already has an axis-aligned bounding box, this AABB is not necessarily axis-aligned any more when subject 
to a transformation. As such, we conservatively build the AABB of the instance by building a new instance 
AABB out of the transformed vertices of the objects AABB. While this somewhat overestimates the actual 
instance bounds, it is much less costly than computing the correct AABB by transforming all vertices. 
As each subdivision step removes at least one potential splitting plane, termination of the subdivision 
can be guaranteed without further termination criteria. Degenerate cases for overlapping objects cannot 
happen, as only AABB boundaries are considered, and not the overlapping space itself. Choosing the splitting 
plane in the described way also yields relatively small and well-balanced BSP trees. Thus, we get a top-level 
BSP that can be traversed reasonable quickly, while still o.ering a fast and e.cient construction algorithm. 
BuildTree(instances,voxel) for d = x,y,z in order of maximum extent P= {i.mind, i.maxd|i . instances} 
if (IP I = 0) continue; c = center of voxel if (more instances on left side of c than on right) p = max({p 
. P |p<c}) else p = min({p . P |p>= c}) Split Cell (instances,cell) in d at p into (leftvox,leftinst),(rightvox,rightinst) 
l = BuildTree(leftinst,leftvox); r = BuildTree(rightinst,rightvox); return InnerNode(d,p,l,r); end for 
# no valid splitting plane found return Leaf(instances) 5.1 High-Quality Top-level BSPs Instead of this 
simpli.ed BSP construction algorithm, it is also possible to use a surface area heuristic for the top-level 
BSP tree. The main problem with this approach is the question how to best estimate the cost for intersecting 
the object. As the respective object BSPs contain only triangles, the cost for each half voxel created 
by a split can be safely estimated to be mostly linear in the number of triangles on each side. For the 
top-level BSP however, each side contains objects of di.erent size, for which the cost is hard to estimate. 
However, the bigger problem with a surface area heuristic for the top-level BSP tree is its relatively 
high construction cost. While this may be neglectable for a few dozen objects, it currently becomes too 
expensive for a few hundred instances. As such, using an SAH would only make sense for a small number 
of instances as long as no fast implementations of an SAH tree builder are available. Though RTRT/OpenRT 
has an implementation of both SAH and the above mentioned algorithm, by default we use the simple and 
fast-to-build version as described above.  6 Fast Traversal Once both the top-level BSP tree and all 
the object BSPs are built, each ray .rst starts traversing this top level structure. As soon as a voxel 
is found, the ray is intersected with the objects in the leaf by simply traversing the respective objects 
local acceleration structures. Once all BSPs are built, within both toplevel BSP and within each object 
traversal is identical to traditional ray tracing in a static environment. Consequently, we use exactly 
the same algorithms and data structures for building and traversing that acceleration structure as for 
the static case [Wald04]. For the top-level BSP, the only di.erence is that each leaf cell of the top-level 
BSP tree contains a list of instance IDs instead of triangle IDs. Only minor changes have been required 
to implement this modi.ed traversal code. As with the original implementation, a ray is .rst clipped 
to the scene bounding box and is then traversed iteratively through the top-level BSP tree. As soon 
as it encounters a leaf cell, it sequentially intersects the ray with all instances in this cell: For 
each instance, the ray is .rst transformed to the local coordinate system of the object, then clipped 
to the correct AABB of the object, and .nally traversed through its acceleration structure. 6.1 Mailboxing 
Typically, the bounding volumes of di.erent instances will overlap. In order to avoid having to intersect 
a ray with the same object multiple times, mailboxing [Amanatides87, Kirk91, Havran01] is very important 
to use for the top-level BSP tree. While the bene.t of mailboxing for the triangle for an object BSP 
is rather small, the high cost of intersecting the same object several times clearly justi.es the use 
of mailboxing for the top-level BSP. 6.2 SSE Traversal As our traversal and intersection algorithms 
do not require normalized ray directions, transforming a ray is relatively cheap, as no costly re-normalization 
of the transformed rays is necessary. The ray-matrix multiplications themselves can very e.ciently be 
done using SSE [Intel02]. Of course, our method also works with the fast SSE packet traversal code described 
in [Wald04].  7 Experiments and Results The described framework is rather straightforward to implement 
and use as long as a shared-memory system (e.g. a dual-CPU PC) is available. However, the situation of 
dynamic ray tracing gets much more problematic for non-shared memory systems, as such systems often contain 
many non-scalable cost factors, such as communicating scene updates to the client, or having to rebuild 
parts of the hierarchy on every client. As the described framework has been especially designed for performing 
well on loosely coupled (i.e. non-shared memory) clusters of workstations, it is of major importance 
to investigate the scalability of our method. To allow for representative results, we have chosen to 
use a wide range of experiments and test scenes. Therefore, we have chosen to use the BART benchmark 
scenes [Lext00], which represent a wide variety of stress factors for ray tracing of dynamic scenes. 
Additionally, we use several of the scenes that we encountered in practical applications [Wald02b], 
and a few custom-made scenes for stress-testing. Snapshots of these test scenes can be found in Figure 
6. Figure 6: Several example frames from some of our dynamic scenes. a.) BART robots contains roughly 
100,000 triangles in 161 moving objects, b.) BART kitchen , c.) BART museum with unstructured motion 
of several thousand triangles. Note how the entire museum re.ects in these triangles. d.) The terrain 
scene uses up to 661 instances of 2 trees, would contain several million triangles without instantiation, 
and also calculates detailed shadows. e.) The o.ce scene in a typical ray tracing con.guration, demonstrating 
that the method works fully automatically and completely transparently to the shader. f.) O.ce with interactive 
global illumination. All of the following experiments have been performed on a cluster of dual AMD AthlonMP 
1800+ machines with a FastEthernet (100Mbit) network connection. The network is fully switched with 
a single GigaBit uplink to a dual AthlonMP 1700+ server. The application is running on the server and 
is totally unaware of the distributed rendering happening inside the rendering engine. It manages the 
geometry in a scene graph, and transparently controls rendering via calls to the OpenRT API [Wald04]. 
While the application itself may internally use a scene-graph with multiple nested hierarchy levels, 
the OpenRT library internally .attens this multi-level scene graph to the two-level organization as described 
above (see Figure 2). In the following experiments, all examples are rendered at video resolution Figure 
7: Two snapshots from the BART kitchen. a.) OpenGL-like ray casting at > 26 fps on 32 CPUs. b.) full-featured 
ray tracing with shadows and 3 levels of re.ections, at > 7 fps on 32 CPUs. of 640 480 pixels. Ray 
tracing is performed with costly programmable shaders featuring shadows, re.ections and texturing. 7.1 
BART Kitchen The kitchen scene contains hierarchical animation of 110.000 triangles organized in 5 objects. 
It requires negligible network bandwidth and BSP construction overhead. Overlap of bounding boxes may 
results in a certain overhead, which is hard to measure exactly but is de.nitely not a major cost factor6 
. The main cost of this scene is due to the need for tracing many rays to evaluate shadows from 6 point 
lights. There is also a high degree of re.ectivity on many objects. Due to fast camera motion and highly 
curved objects (see Figure 7), these rays are rather incoherent. However, these aspects are completely 
independent of the dynamic nature of the scene and are handled e.ciently by our system. We achieve interactive 
frame rates even for the large amount of rays to be shot. A re.ection depth of 3 results in a total of 
3.867.661 rays/frame. At a measured rate of 912.000 rays traced per second and CPU in this scene, this 
translates to a frame rate of 7.55 fps on 32 CPUs. As can be seen in Table 1, scalability is almost linear 
 using twice as many CPUs results in roughly twice the frame rate. CPUs 2 4 8 16 32 OpenGL-like 3.2 6.4 
12.8 25.6 > 26 Ray Tracing 0.47 0.94 1.88 3.77 7.55 Table 1: Scalability in the kitchen scene in frames/sec. 
6Note that the robot, museum, kitchen, and terrain scenes are only available in a dynamic version, and 
can thus not be compared to a static version. 7.2 BART Robots The robots scene features a game-like 
setting with 16 animated robots moving through a city. The scene consists of 161 objects: 16 robots with 
10 animated body parts each, plus one object for the surrounding city. All dynamic motion is hierarchical 
with no unstructured motion at all. Therefore, the BSP trees for all objects have to be built only once, 
and only the top-level BSP have to be rebuilt for every frame. Using the algorithms described above, 
rebuilding the top-level BSP is very e.cient and takes less than one millisecond. Furthermore, updating 
the transformation matrices requires only a small network bandwidth of roughly 20 kb/frame for each 
client. CPUs 2 4 8 16 32 OpenGL-like 2.8 5.55 10.8 21 > 26 Ray Tracing 0.54 1.07 2.15 4.3 8.6 Table 
2: Scalability in the robots scene in frames/sec. With such a small transmission and reconstruction overhead, 
we again achieve almost-linear scalability (see Table 2) and high rendering performance. Using 32 CPUs, 
we achieve a frame rate of 8 frames per second. Again, the high cost of this scene is due to the large 
number of re.ection and shadow rays. Using a simple OpenGL-like shader (see Figure 8) results in frame 
rates of more than 26 frames per second. 7.3 BART Museum The museum has been designed mainly for testing 
unstructured motion and is the only BART scene featuring non-hierarchical motion. In the center of the 
museum, several triangles are animated on prede.ned animation paths to form di.erently shaped objects. 
The number of triangles undergoing unstructured motion can be con.gured to 64, 256, 1k, 4k, 16k, or 64k. 
Even though the complete animation paths are speci.ed in the BART scene graph, we do not make use of 
this information. User controlled movement of the triangles i.e. without knowledge of future positions 
 would create the same results. This scene also requires the computation of shadows from two point lights 
as well as large amounts of re.ection rays. All of the moving triangles are re.ective and incoherently 
sample the whole environment (see Figure 9). As the dynamic behavior of a scene is completely transparent 
to the shaders, integrating all these e.ects does not require any additional e.ort except for the cost 
for tracing the rays. As expected, unstructured motion gets costly for many triangles. Building the BSP 
tree for the complex version of 64k triangles already requires more than one second (see Table 3). Note, 
however, that our current algorithms for building object BSPs still leave plenty of room for further 
optimizations. Figure 8: BART robots: 16 robots consisting of 161 objects rendered interactively. a.) 
Ray casting at > 26 fps on 32 CPUs. b.) Full ray tracing at > 8 fps at 32 CPUs. Figure 9: Unstructured 
motion in the BART museum: Up to 64,000 triangles are moving incoherently through the museum. Note how 
the triangles re.ect the entire environment. Furthermore, the reconstruction time is strongly a.ected 
by the distribution of triangles in space: In the beginning of the animation, all triangles are equally 
and almost-randomly distributed. This is the worst case for BSPs, which are best at handling uneven distributions, 
and construction is consequently costly. Furthermore, the randomly distributed triangles form many singularities 
when intersecting themselves, which is extremely bad for typical BSP trees. During the animation, the 
triangles organize themselves to form a single surface. At this stage, reconstruction time is much faster. 
Note that the numbers given in Table 3 are taken at the beginning of the animation, and are thus worst-case 
results. num tris 64 256 1k 4k 16k 64k reconst.time 1ms 2ms 8ms 34ms 0.1s > 1s bandwidth/client 6.4k 
25.6k 102k 409k 1.6M 6.5M Table 3: Unstructured motion in di.erent con.gurations of the museum scene. 
Rows specify reconstruction time for the top-level BSP, and data sent to each client for updating the 
triangle positions. 7.3.1 Network Bottleneck Apart from raw reconstruction cost, signi.cant network bandwidth 
is required for sending all triangles to every client. Since we use reliable unicast (TCP/IP) for network 
transport, using 4096 triangles and 16 clients (32 CPUs), requires to transfer roughly 6.5 Mb (16 clients 
 408kb, see Table 3) for every frame. Though in theory this does not yet totally saturate the network, 
the network load is not equally distributed over time: Network bandwidth is especially high at the beginning 
of each frame, when all the scene updates have to be communicated to the clients. During this time, 
the network is already completely saturated when sending 16k triangles to the clients, implying that 
the performance of the server is already signi.cantly a.ected during this time. Consequently, we can 
no longer scale linearly any more when dynamically updating more than a few thousand triangles (see Table 
4). 7.3.2 Geometry Shaders Note that this problem would be signi.cantly reduced on a shared-memory platform, 
or even with the availability of a reliable hardware multicast. On a cluster con.guration, the update 
problem could probably also be solved by using geometry shaders that can generate the triangles directly 
on the clients. Though this can only be used for a limited set of applications, it would already allow 
for many important and interesting applications. So far however this approach has not yet been su.ciently 
investigated. Due to the discussed problems high communication cost for the scene updates and high 
reconstruction cost for the dynamic object s BSP the museum scene is the most problematic of all the 
scenes encountered so far. Even so, with all these e.ects unstructured motion, shadows, and highly incoherent 
re.ections in the animated triangles the museum can still be rendered interactively: Using 8 clients, 
we achieve 4.8 fps for 1024 triangles, and still 4.2 fps for 4096 triangles in video resolution (see 
Table 4). Again, the frame rate is dominated by the cost for shadows and re.ections. Using an OpenGL-like 
shader without these e.ects allows to render the scene at 19 frames per second on 8 clients.  7.4 Outdoor 
Terrain The terrain scene has been specially designed to stress scalability with a large number of instances 
and triangles. It contains 661 instances of 2 di.erent trees, Table 4: Scalability of our method in the 
di.erent test scenes (BART robots, BART kitchen, Outdoor Terrain, and BART museum with 1k, 4k, and 16k 
dynamic triangles). * means that the servers network connection is completely saturated in our network 
con.guration, and thus no higher performance can be achieved. The numbers in the left half of the table 
correspond to pure OpenGL like shading, the right half is for full ray tracing including shadows and 
re.ections. As can clearly be seen, for scenes with hierarchical animation scalability is almost linear 
up to the maximum network bandwidth for the .nal pixel data. With an increasing amount of unstructured 
motion (museum 1k 16k), the required network bandwidth for sending the changed triangles to the clients 
soon becomes a bottleneck. In that case, adding more CPUs even reduces performance, as data has to be 
sent to even more clients. An overview of these scenes can be found in Figure 6 num CPUs with GL1 2 -like 
shading 4 8 with full ray trac16 1 2 4 ing 8 16 robots kitchen terrain museum: w/ 1k w/ 4k w/ 16k 2.8 
5.55 3.2 6.4 1.3 2.5 2.7 5.4 2.5 4.5 1.6 2.4 10.8 12.8 4.8 10.2 7.5 1.7 21 25.6 8 19.5 4.5 1 26* 0.54 
1.07 2.15 26* 0.47 0.94 1.88 15 0.9 1.77 3.39 26* 0.6 1.2 2.4 2.5 0.55 1.1 2.2 0.5 0.45 0.9 1.65 4.3 
3.77 6.5 4.8 4.2 0.98 8.6 7.55 12 9.3 2.5 0.53 which correspond to more than 10 million triangles after 
instantiation. A point light source creates highly detailed shadows from the leaves (see Figure 6). All 
trees can be moved around interactively, both in groups or individually. The large number of instances 
results in construction times for the top-level BSP of up to 4 ms per frame. This cost together with 
the transmission cost for updating all 661 instance matrices on all clients limits the scalability for 
a large number of instances and clients (see Table 4).  Discussion The above scenes have been chosen 
to stress di.erent aspects of our dynamic ray tracing engine. Together with the terrain experiment, our 
test scenes contain a strong variation of parameters from 5 to 661 instances, from a few thousand to 
several million triangles, from simple shading to lots of shadows and re.ections, and from hierarchical 
animation to unstructured motion of thousands of triangles (for an overview, see Figure 6). Taken together, 
these experiments allow for a detailed analysis of our method. 8.1 Transformation Cost For mainly hierarchical 
animation, the core idea of our method was to trade the cost for rebuilding the acceleration structure 
for the cost to transform the rays to the local coordinate system of each object. This implies that every 
ray intersecting an object has to be transformed via matrix-vector multiplications for both ray origin 
and direction (for every object encountered), potentially resulting in several matrix operations per 
ray. With a ray tracing performance of up to several million rays per second [Wald04], this can amount 
to many million matrix-vector multiplications per frame! For example, the terrain and robots scenes at 
640 480 pixels require 1.6 and 1 million matrix operations, respectively (see Figure 5). Furthermore, 
more transformations are often required during shading, e.g. by transforming the shading normal or for 
calculating procedural noise in the local coordinate system. o.ce terrain robots objects 9 661 161 matrix 
ops 480k 1.6M 1M Table 5: Number of matrix-vector multiplies for our benchmark scenes (resolution 640x480). 
A matrix operation can be performed in only 23 cycles even in plain C code, which is negligible compared 
to traversal cost. However, the cost for these transformations in practice is quite tolerable: Even for 
a straight-forward C-code implementation, a matrix-vector operation costs only 23 cycles on an AMD AthlonMP 
CPU, which is rather small compared to the cost for tracing a ray (which is in the order of several hundred 
to a few thousand cycles). Note that the matrix-vector multiplies are ideally suited for fast SSE implementation. 
This reduces this cost even further, and makes the transformation overhead almost negligible. 8.2 Unstructured 
Motion As could be expected, the museum scene has shown that unstructured motion remains costly for ray 
tracing. A moderate number of a few thousand independently moving triangles can easily be supported, 
but larger numbers still lead to high reconstruction times for the respective objects (see Table 3). 
As such, our method is still not suitable for scenes with strong unstructured motion. To support such 
scenes, algorithms for faster reconstruction of dynamic objects have to be developed. Note that our 
method could also be combined with Reinhard s approach [Reinhard00] by using his method only for the 
unstructured objects. Even then, lots of unstructured motion would still create a performance problem 
due to the need to send all triangle updates to the clients. This is not a limitation of our speci.c 
method, but would be similar for any algorithm in a distributed environment. 8.3 Bounding Volume Overlap 
One of the stress cases identi.ed in [Lext00] was Bounding Volume Overlap. In fact, this does create 
some overhead, as in the overlap area of two objects, these two objects have to be intersected sequentially 
by each ray. As a result, a successful intersection found during traversal of the .rst object may later-on 
be invalidated by a closer one in the other object. In fact, this partially disables early ray termination 
and thus negatively a.ects the occlusion culling feature of ray tracing7 . Though it is easy to construct 
scenarios where bounding volume overlap would lead to excessive overhead, it is rarely signi.cant in 
practice. In fact, bounding volume overlap does happen in all our test cases, but has never shown to 
pose a major performance problem. In fact, overlapping objects are exactly what happens all the time 
in bounding volume hierarchies (BVHs) [Rubin80, Kay86, Haines91], which have also proven to work rather 
well in practice. 8.4 Teapot-in-a-Stadium Problem The teapot-in-a-stadium problem is handled very well 
by out method: BSPs automatically adapt to varying object density in a scene [Havran01]. This is true 
for both object and top-level BSPs. In fact, our method can even increase performance for such cases: 
If the teapot is contained in a separate object, the shape of the stadium BSP is usually much better, 
as there is no need any more for several BSP subdivisions to tightly enclose the teapot. 7Note that for 
shadow rays, .nding intersections in the wrong order is not a problem, as any valid intersection is su.cient 
to determine occlusion of a ray. Even so, Bounding Volume Overlap may still lead to the situation that 
the object containing an occluder will be traversed rather late during traversal of the toplevel structure. 
 8.5 Over-Estimation of Object Bounds Building the top-level BSP requires an estimate of the bounding 
box of each instance in world coordinates. As transforming each individual vertex would be too costly, 
we conservatively estimate these bounds based on the transformed bounding box of the original object. 
This somewhat over-estimates the correct bounds and thus results in some overhead: During top-level BSP 
traversal, a ray may be intersected with an object that it would not have intersected otherwise. However, 
this overhead is restricted to only transforming and clipping the ray: After transformation to the local 
coordinate system, such a ray is .rst clipped against the correct bounding box, and can thus be immediately 
discarded without further traversal. 8.6 Scalability with the Number of Instances Apart from unstructured 
motion, the main cost of our method results from the need to recompute the top-level BSP tree. As such, 
a large number of instances is expensive, as can be seen in the terrain scene. Thus, the number of instances 
should be minimized in order to achieve optimal performance. Usually, it is better to use a small number 
of large objects instead of many small ones. For example, all static triangles in a scene should best 
be stored in a single object, instead of using multiple objects. This is completely di.erent to approaches 
commonly used in OpenGL, in which many, small display lists are used. Thus, some amount of manual adjustment 
and optimization may be required when porting applications from OpenGL to OpenRT. Even so, even the thousand 
complex instances can be rendered interactively, and top-level reconstruction has not yet proven a real 
limitation in any practical application. For moderate numbers of objects, top-level reconstruction is 
virtually negligible. On the other hand, supporting instantiation (i.e. using exactly the same object 
multiple times in the same frame) is a valuable feature of our method, as this allows for rendering complex 
environments very e.ciently: With instantiation, memory is required for storing only one copy of each 
object to be instantiated, plus the top-level BSP, allowing to render even many million triangles with 
a small memory footprint (see Figures 5 and 10). For triangle rasterization, all triangles would still 
need to be handled individually by the graphics hardware even when using display lists. 8.7 Scalability 
in a Distributed Environment As can be seen by the experiments in Section 7, we achieve rather good scalability 
even for many clients except for scenes that require to update a lot of information on all clients, i.e. 
for a high degree of unstructured motion (where every moving triangle has to be transmitted), and for 
a large number of instances. In the terrain scene, using 16 clients would require to send 676 Kb8 per 
frame simply for updating the 661 transformation matrices on the clients. Though this data can be sent 
in a compressed form, load balancing and client/server communication further adds to the network bandwidth. 
Without broadcast/multicast functionality on the network, the server bandwidth increases linearly with 
the number of clients. For many clients and lots of updated data, this creates a bandwidth bottleneck 
on the server, and severely limits the scalability (see Table 4). In fact, performance could even drop 
when adding many more CPUs, as each new client increases the network load. In principle, the same is 
true for unstructured motion, where sending several thousand triangles to each client also creates a 
bandwidth bottleneck. On the other hand, both problems are not speci.c to our method, but will apply 
similarly to any method running on such a distributed hardware architecture. 8.8 Total Overhead In order 
to estimate the total overhead of our method, we have compared several scenes in both a static and dynamic 
con.guration. As there are no static equivalents for the BART benchmarks, we have taken several of our 
static test scenes, and have modi.ed them in a way that they can be rendered in both a static con.guration 
with all triangles in a single, static BSP tree, as well as in a dynamic con.guration, where triangles 
are grouped into di.erent objects that can then be moved dynamically. For simple scenes, the total overhead 
is relatively high9, compared to the small cost of rendering a static version of these scenes, and even 
reaches up to a factor of two in total rendering time. For more realistic scene sizes, however, the relative 
overhead is signi.cantly less, and in practice is often in the range of 20 to 30 percent, sometimes even 
less. This is very fortunate, as the overhead is worst for simple scenes in which absolute performance 
is highest anyway, and is relatively small for more costly scenes in which a high overhead would hurt 
most. Furthermore, most practical applications use rather complex scenes, and thus have a small overhead. 
As such, we believe this overhead to be a reasonable price for the added .exibility gained through supporting 
dynamic scenes.  9 Conclusions The presented method is a simple and practical approach to handling dynamic 
scenes in an interactive distributed ray tracing engine. It can handle a large variety of dynamic scenes, 
including all the BART benchmark scenes (see Figure 6). It imposes no limitations on the kind of rays 
to be shot, and as such 8661 instances16 clients(4  4) .oats 9Note that total overhead includes all 
the previously mentioned sources of overhead, e.g. including toplevel reconstruction, bounding volume 
overlap, traversal cost, multiple traversal setup cost, etc. allows for all the usual ray-tracing features 
like shadows, re.ections, and even global illumination [Wald04]. For unstructured motion, the proposed 
method still incurs a high reconstruction cost per frame, that makes it infeasible for a large number 
of incoherently moving triangles. For a moderate amount of unstructured motion however (in the order 
of a few thousand incoherently moving triangles), it is well applicable and results in frame rates of 
several frames per second at video resolution. For mostly hierarchical animation our method is highly 
e.cient and achieves interactive performance even for highly complex models with hundreds of instances, 
and with millions of triangles per object [Wald02a]. This is especially furtunate since many of todays 
scene graph libraries (especially in VR/AR and other industrial applications) mostly use only this kind 
of animation. The proposed technique forms a core part of the RTRT/OpenRT core, and has been used exclusively 
in all of the published applications of this system that all use this technique). Though it is certainly 
possible to construct cases in which the proposed method breaks down, so far is has been successfully 
able to handle all the dynamic scenes that have been encountered in practical applications of RTRT/OpenRT. 
In conclusion, the proposed method of handling dynamic scenes is still limited but nonetheless already 
good enough for a large class of applications. Furthermore, the support for dynamic scenes in ray tracing 
is likely to improve signi.cantly in the near future as more researchers start looking at this problem. 
Still, there remains a vast potential for future research in this area. 10 Future Work At the moment, 
the main remaining scalability bottleneck lies in communicating all scene updates to all clients, making 
the total bandwidth linear in the number of clients. Thus, future work will investigate to use network 
broadcast/multicast to communicate the scene updates. As almost all of the updated data is the same for 
every client, this should e.ectively remove the server bottleneck. Furthermore, the above-mentioned 
concept of geometry shaders seems to be an interesting option for reducing the scene update bandwidth. 
On the clients, the main bottleneck is the cost for reconstructing objects under unstructured motion. 
This could be improved by designing specialized algorithms for cases where motion is spatially limited 
in some form, such as for skinning, prede.ned animations, or for key-frame interpolation. For the top-level 
BSP, it could be highly bene.cial to investigate the use of cost functions. This especially includes 
.nding ways of building such highquality BSPs in a fast and e.cient manner. Apart from these technical 
issues, it is also important to investigate how existing applications can be mapped to our method, e.g. 
by evaluating how a scene graph library such as OpenInventor [Wernecke94], OpenSG [OpenSG01], OpenSceneGraph 
[OSG] or VRML [Carey97] can be e.ciently implemented on top of our system. Preliminary results seem promising 
[Dietrich04]. Finally, it is an obvious next step to integrate this techniques into a hardware ray tracing 
architecture such as the SaarCOR architecture [Schmittler02]. As such an architecture avoids most of 
the distribution problems we have in our PC cluster, such a mapping should be highly successful. First 
results are encouraging. References [Amanatides87] John Amanatides and Andrew Woo. A Fast Voxel Traversal 
Algorithm for Ray Tracing. In Eurographics 87, pages 3 10. 1987. [Carey97] Rikk Carey, Gavin Bell, and 
Chris Marrin. ISO/IEC 147721:1997 Virtual Reality Modelling Language (VRML97), April 1997. http://www.vrml.org/Speci.cations/VRML97. 
[DeMarle03] David E. DeMarle, Steve Parker, Mark Hartner, Christiaan Gribble, and Charles Hansen. Distributed 
Interactive Ray Tracing for Large Volume Visualization. In Proceedings of the IEEE Symposium on Parallel 
and Large-Data Visualization and Graphics (PVG), pages 87 94, 2003. [Dietrich04] Andreas Dietrich, Ingo 
Wald, Markus Wagner, and Philipp Slusallek. VRML Scene Graphs on an Interactive Ray Tracing Engine. 
In Proceedings of IEEE VR 2004, pages 109 116, March 2004. [Glassner88] Andrew Glassner. Spacetime Ray 
Tracing for Animation. IEEE Computer Graphics and Applications, 8(2):60 70, 1988. [Groller91] Eduard 
Groller and Werner Purgathofer. Using temporal and spatial coherence for accelerating the calculation 
of animation sequences. In Proceedings of Eurographics 91, pages 103 113. Elsevier Science Publishers, 
1991. [Haines87] Eric A. Haines. A Proposal for Standard Graphics Environments. IEEE Computer Graphics 
and Applications, 7(11):3 5, November 1987. Available from http://www.acm.org/pubs/tog/resources/SPD/overview.html. 
[Haines91] Eric Haines. E.ciency Improvements for Hierarchy Traversal in Ray Tracing. In James Arvo, 
editor, Graphics Gems II, pages 267 272. Academic Press, 1991. [Havran01] Vlastimil Havran. Heuristic 
Ray Shooting Algorithms. PhD thesis, Faculty of Electrical Engineering, Czech Technical University in 
Prague, 2001. [Intel02] Intel Corp. Intel Pentium III Streaming SIMD Extensions. http://developer.intel.com/vtune/cbts/simd.htm, 
2002. [Kay86] Timothy L. Kay and James T. Kajiya. Ray Tracing Complex Scenes. Computer Graphics (Proceedings 
of SIGGRAPH 86), 20(4):269 278, June 1986. Held in Dallas, Texas. [Kirk91] David Kirk and James Arvo. 
Improved Ray Tagging For Voxel-Based Ray Tracing. In James Arvo, editor, Graphics Gems II, pages 264 
266. Academic Press, 1991. [Lext00] Jonas Lext, Ulf Assarsson, and Tomas Moller. BART: A Benchmark for 
Animated Ray Tracing. Technical report, Department of Computer Engineering, Chalmers University of Technology, 
Goteborg, Sweden, May 2000. Available at http://www.ce.chalmers.se/BART/. [Lext01] Jonas Lext and Tomas 
Akenine-Moller. Towards Rapid Reconstruction for Animated Ray Tracing. In Eurographics 2001 Short 
Presentations, pages 311 318, 2001. [OpenSG01] OpenSG-Forum. http://www.opensg.org, 2001. [OSG] OpenSceneGraph. 
http://www.openscenegraph.org. [Parker99] Steven Parker, Peter Shirley, Yarden Livnat, Charles Hansen, 
and Peter-Pike Sloan. Interactive Ray Tracing. In Proceedings of Interactive 3D Graphics, pages 119 126, 
1999. [Reinhard00] Erik Reinhard, Brian Smits, and Chuck Hansen. Dynamic Acceleration Structures for 
Interactive Ray Tracing. In Proceedings of the Eurographics Workshop on Rendering, pages 299 306, Brno, 
Czech Republic, June 2000. [Rubin80] Steve M. Rubin and Turner Whitted. A Three-Dimensional Representation 
for Fast Rendering of Complex Scenes. Computer Graphics, 14(3):110 116, July 1980. [Schmittler02] Jorg 
Schmittler, Ingo Wald, and Philipp Slusallek. SaarCOR A Hardware Architecture for Ray Tracing. In Proceedings 
of the ACM SIGGRAPH/Eurographics Conference on Graphics Hardware, pages 27 36, 2002. [Wald01] Ingo Wald, 
Philipp Slusallek, and Carsten Benthin. Interactive Distributed Ray Tracing of Highly Complex Models. 
In Steven J. Gortler and Karol Myszkowski, editors, Rendering Techniques, Proceedings of the 12th Eurographics 
Workshop on Rendering Techniques, London, UK, June 25-27, 2001, pages 274 285. Springer, 2001. 24 [Wald02a] 
Ingo Wald, Carsten Benthin, and Philipp Slusallek. OpenRT -A Flexible and Scalable Rendering Engine for 
Interactive 3D Graphics. Technical report, Saarland University, 2002. Available at http://graphics.cs.uni-sb.de/Publications. 
[Wald02b] Ingo Wald, Thomas Kollig, Carsten Benthin, Alexander Keller, and Philipp Slusallek. Interactive 
Global Illumination using Fast Ray Tracing. Rendering Techniques, pages 15 24, 2002. (Proceedings of 
the 13th Eurographics Workshop on Rendering). [Wald03] Ingo Wald, Timothy J. Purcell, Jorg Schmittler, 
Carsten Benthin, and Philipp Slusallek. Realtime Ray Tracing and its use for Interactive Global Illumination. 
In Eurographics State of the Art Reports, 2003. [Wald04] Ingo Wald. Realtime Ray Tracing and Interactive 
Global Illumination. PhD thesis, Computer Graphics Group, Saarland University, 2004. Available at http://www.mpisb.mpg.de/~wald/PhD/. 
[Wernecke94] Josie Wernecke. The Inventor Mentor. Addison-Wesley, 1994. ISBN 0-20162-495-8.  
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198754</article_id>
		<sort_key>15</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Interactive ray tracing for volume visualization]]></title>
		<page_from>15</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198754</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198754</url>
		<abstract>
			<par><![CDATA[We present a brute-force ray tracing system for interactive volume visualization. The system runs on a conventional (distributed) shared-memory multiprocessor machine. For each pixel we trace a ray through a volume to compute the color for that pixel. Although this method has high intrinsic computational cost, its simplicity and scalability make it ideal for large datasets on current high-end parallel systems. To gain efficiency several optimizations are used including a volume bricking scheme and a shallow data hierarchy. These optimizations are used in three separate visualization algorithms: isosurfacing of rectilinear data, isosurfacing of unstructured data, and maximum-intensity projection on rectilinear data. The system runs interactively (i.e., several frames per second) on an SGI Reality Monster. The graphics capabilities of the Reality Monster are used only for display of the final color image.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[isosurface]]></kw>
			<kw><![CDATA[maximum-intensity projection]]></kw>
			<kw><![CDATA[ray tracing]]></kw>
			<kw><![CDATA[visualization]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39030761</person_id>
				<author_profile_id><![CDATA[81350577009]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Parker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP37032339</person_id>
				<author_profile_id><![CDATA[81406594963]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Parker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15032967</person_id>
				<author_profile_id><![CDATA[81100468934]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yarden]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Livnat]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P225694</person_id>
				<author_profile_id><![CDATA[81100524617]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Peter-Pike]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sloan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14162477</person_id>
				<author_profile_id><![CDATA[81100464350]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Charles]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hansen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39043298</person_id>
				<author_profile_id><![CDATA[81100449948]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shirley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>288266</ref_obj_id>
				<ref_obj_pid>288216</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Steven Parker, Peter Shirley, Yarden Livnat, Charles Hansen, and Peter-Pike Sloan, "Interactive ray tracing for isosurface rendering," in Proceedings of Visualization '98, October 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300537</ref_obj_id>
				<ref_obj_pid>300523</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Steven Parker, William Martin, Peter-Pike Sloan, Peter Shirley, Brian Smits, and Charles Hansen, "Interactive ray tracing," in Symposium on Interactive 3D Graphics, April 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[James T. Kajiya, "An overview and comparison of rendering methods," A Consumer's and Developer's Guide to Image Synthesis, pp. 259--263, 1988, ACM Siggraph '88 Course 12 Notes.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>44652</ref_obj_id>
				<ref_obj_pid>44650</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Mark Levoy, "Display of surfaces from volume data," IEEE Computer Graphics & Applications, vol. 8, no. 3, pp. 29--37, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378476</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Paolo Sabella, "A rendering algorithm for visualizing 3d scalar fields," Computer Graphics, vol. 22, no. 4, pp. 51--58, July 1988, ACM Siggraph '88 Conference Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378482</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Craig Upson and Micheal Keeler, "V-buffer: Visible volume rendering," Computer Graphics, vol. 22, no. 4, pp. 59--64, July 1988, ACM Siggraph '88 Conference Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[E. Reinhard, A. G. Chalmers, and F. W. Jansen, "Overview of parallel photo-realistic graphics," in Eurographics '98, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>532835</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Arie Kaufman, Volume Visualization, IEEE CS Press, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>197949</ref_obj_id>
				<ref_obj_pid>197938</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Lisa Sobierajski and Arie Kaufman, "Volumetric Ray Tracing," 1994 Workshop on Volume Visualization, pp. 11--18, Oct. 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617354</ref_obj_id>
				<ref_obj_pid>182466</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[K. L. Ma, J. S. Painter, C. D. Hansen, and M. F. Krogh, "Parallel Volume Rendering using Binary-Swap Compositing," IEEE Comput. Graphics and Appl., vol. 14, no. 4, pp. 59--68, July 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Michael J. Muuss, "Rt and remrt - shared memory parllel and network distributed ray-tracing programs," in USENIX: Proceedings of the Fourth Computer Graphics Workshop, October 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>147138</ref_obj_id>
				<ref_obj_pid>147130</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Guy V&#233;zina, Peter A. Fletcher, and Philip K. Robertson, "Volume Rendering on the MasPar MP-1," in 1992 Workshop on volume Visualization, 1992, pp. 3--8, Boston, October 19-20.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>147142</ref_obj_id>
				<ref_obj_pid>147130</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[P. Schr&#246;der and Gordon Stoll, "Data Parallel Volume Rendering as Line Drawing," in 1992 Workshop on volume Visualization, 1992, pp. 25--31, Boston, October 19-20.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Michael J. Muuss, "Towards real-time ray-tracing of combinatorial solid geometric models," in Proceedings of BRL-CAD Symposium, June 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Scott Whitman, "A Survey of Parallel Algorithms for Graphics and Visualization," in High Performance Computing for Computer Graphics and Visualization, 1995, pp. 3--22, Swansea, July 3-4.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[B. Wyvill G. Wyvill, C. McPheeters, "Data structures for soft objects," The Visual Computer, vol. 2, pp. 227--234, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[William E. Lorensen and Harvey E. Cline, "Marching cubes: A high resolution 3d surface construction algorithm," Computer Graphics, vol. 21, no. 4, pp. 163--169, July 1987, ACM Siggraph '87 Conference Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Chyi-Cheng Lin and Yu-Tai Ching, "An efficient volume-rendering algorithm with an analytic approach," The Visual Computer, vol. 12, no. 10, pp. 515--526, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>951109</ref_obj_id>
				<ref_obj_pid>951087</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Stephen Marschner and Richard Lobb, "An evaluation of reconstruction filters for volume rendering," in Proceedings of Visualization '94, October 1994, pp. 100--107.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>951123</ref_obj_id>
				<ref_obj_pid>951087</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Milos Sramek, "Fast surface rendering from raster data by voxel traversal using chessboard distance," in Proceedings of Visualization '94, October 1994, pp. 188--195.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Georgios Sakas, Marcus Grimm, and Alexandros Savopoulos, "Optimized maximum intensity projection (MIP)," in Eurographics Rendering Workshop 1995. Eurographics, June 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378484</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Robert A. Drebin, Loren Carpenter, and Pat Hanrahan, "Volume rendering," Computer Graphics, vol. 22, no. 4, pp. 65--74, July 1988, ACM Siggraph '88 Conference Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>99310</ref_obj_id>
				<ref_obj_pid>99307</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Don Speray and Steve Kennon, "Volume probes: Interactive data exploration on arbitrary grids," in Computer Graphics (San Diego Workshop on Volume Visualization), 1990, pp. 5--12.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[John Amanatides and Andrew Woo, "A fast voxel traversal algorithm for ray tracing," in Eurographics '87, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>13044</ref_obj_id>
				<ref_obj_pid>13043</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Akira Fujimoto, Takayu Tanaka, and Kansei Iwata, "Arts: Accelerated ray-tracing system," IEEE Computer Graphics & Applications, pp. 16--26, April 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>147155</ref_obj_id>
				<ref_obj_pid>147130</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[John Danskin and Pat Hanrahan, "Fast algorithms for volume ray tracing," 1992 Workshop on Volume Visualization, pp. 91--98, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>78965</ref_obj_id>
				<ref_obj_pid>78964</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Marc Levoy, "Efficient ray tracing of volume data," ACM Transactions on Graphics, vol. 9, no. 3, pp. 245--261, July 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>99321</ref_obj_id>
				<ref_obj_pid>99308</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[J. Wilhelms and A. Van Gelder, "Octrees for faster isosurface generation," in Computer Graphics (San Diego Workshop on Volume Visualization), Nov. 1990, pp. 57--62.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>130882</ref_obj_id>
				<ref_obj_pid>130881</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[J. Wilhelms and A. Van Gelder, "Octrees for faster isosurface generation," ACM Transactions on Graphics, vol. 11, no. 3, pp. 201--227, July 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>99318</ref_obj_id>
				<ref_obj_pid>99308</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Jane Wilhelms and Judy Challinger, "Direct volume rendering of curvilinear volumes," in Computer Graphics (San Diego Workshop on Volume Visualization), Nov. 1990, pp. 41--47.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>99316</ref_obj_id>
				<ref_obj_pid>99307</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[M. Garrity, "Ray Tracing Irregular Volume Data," in 1990 Workshop on Volume Visualization, 1990, pp. 35--40, San Diego.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>236228</ref_obj_id>
				<ref_obj_pid>236226</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Cl&#225;udio Silva, Joseph S. B. Mitchell, and Arie E. Kaufman, "Fast rendering of irregular grids," in 1996 Volume Visualization Symposium. IEEE, Oct. 1996, pp. 15--22, ISBN 0-89791-741-3.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[C. E. Prakash and S. Manohar, "Volume rendering of unstructured grids-a voxelization approach," Computers & Graphics, vol. 19, no. 5, pp. 711--726, Sept. 1995, ISSN 0097-8493.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>267068</ref_obj_id>
				<ref_obj_pid>266989</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Michael B. Cox and David Ellsworth, "Application-controlled demand paging for Out-of-Core visualization," in Proceedings of Visualization '97, October 1997, pp. 235--244.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>94794</ref_obj_id>
				<ref_obj_pid>94788</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[James Arvo and David Kirk, "A survey of ray tracing acceleration techniques," in An Introduction to Ray Tracing, Andrew S. Glassner, Ed. Academic Press, San Diego, CA, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[David Jevans and Brian Wyvill, "Adaptive voxel subdivision for ray tracing," in Proceedings of Graphics Interface '89, June 1989, pp. 164--172.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618406</ref_obj_id>
				<ref_obj_pid>616044</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Kryzsztof S. Klimansezewski and Thomas W Sederberg, "Faster ray tracing using adaptive grids," IEEE Computer Graphics & Applications, vol. 17, no. 1, pp. 42--51, Jan.-Feb. 1997, ISSN 0272-1716.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Al Globus, "Octree optimization," Tech. Rep. RNR-90-011, NASA Ames Research Center, July 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>949621</ref_obj_id>
				<ref_obj_pid>949607</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Greg Nielson and Bernd Hamann, "The asymptotic decider: Resolving the ambiguity in marching cubes," in Proceedings of Visualization '91, October 1991, pp. 83--91.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[National Library of Medicine (U.S.) Board of Regents, "Electronic imaging: Report of the board of regents, u.s. department of health and human services, public health service, national institutes of health," NIH Publication 90-2197, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Bill Lorensen, "Marching through the visible woman," http://www.crd.ge.com/cgi-bin/vw.pl, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614330</ref_obj_id>
				<ref_obj_pid>614261</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Y Livnat, H. Shen, and C. R. Johnson, "A near optimal isosurface extraction algorithm using the span space," IEEE Trans. Vis. Comp. Graphics, vol. 2, no. 1, pp. 73--84, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614407</ref_obj_id>
				<ref_obj_pid>614271</ref_obj_pid>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[M. L. Brady, K. K. Jung, H. T. Nguyen, and T. PQ. Nguyen, "Interactive Volume Navigation," IEEE Transactions on Visualization and Computer Graphics, vol. 4, no. 3, pp. 243--256, July 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>90877</ref_obj_id>
				<ref_obj_pid>90767</ref_obj_pid>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Jochen Schwarze, "Cubic and quartic roots," in Graphics Gems, Andrew Glassner, Ed., pp. 404--407. Academic Press, San Diego, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Interactive Ray Tracing for Volume Visualization Steven Parker, Michael Parker, Yarden Livnat, Peter-Pike 
Sloan, Charles Hansen, Peter Shirley Abstract We present a brute-force ray tracing system for interactive 
volume visualization. The system runs on a conventional (distributed) shared-memory multiprocessor machine. 
For each pixel we trace a ray through a volume to compute the color for that pixel. Although this method 
has high intrinsic computational cost, its simplicity and scalability make it ideal for large datasets 
on current high-end parallel systems. To gain ef.ciency several optimizations are used including a volume 
bricking scheme and a shallow data hierarchy. These optimizations are used in three separate visualization 
algorithms: isosurfacing of rectilinear data, isosurfacing of unstructured data, and maximum-intensity 
projection on rectilinear data. The system runs interactively (i.e., several frames per second) on an 
SGI Reality Monster. The graphics capabilities of the Reality Monster are used only for display of the 
.nal color image. Keywords Ray tracing, visualization, isosurface, maximum-intensity projection. I. INTRODUCTION 
Many applications generate scalar .elds p(x;y;z)which can be visualized by a variety of methods. These 
.elds are often de.ned by a set of point samples and an interpolation rule. The point samples are typically 
in either a rectilinear grid, a curvilinear grid, or an unstructured grid (simplical complex). The two 
main visualization techniques used on such .elds are to display isosurfaces where p(x;y;z)piso,and direct 
volume rendering, where there is some type of opacity/emission integration along the line of sight. 
The key difference between these techniques is that isosurfacing displays actual surfaces, while direct 
volume rendering displays some function of all the values seen along a ray throughout the pixel. Ideally, 
the display parameters for each technique are interactively controlled by the user. In this paper we 
present interactive volume visualization schemes that use ray tracing as their basic computation method. 
The basic ray-volume traversal method used in this paper is shown in Fig. 1. This framework allows us 
to implement volume visualization methods that .nd exactly one value along a ray. Two such methods described 
in this paper are isosurfacing and maximum-intensity projection. Maximum-intensity projection is a direct 
volume rendering technique where the opacity is a function of the maximum intensity seen along a ray. 
The isosurfacing of rectilinear grids has appeared previously [1], while the isosurfacing of unstructured 
grids and the maximum-intensity projection are described for the .rst time in this paper. More general 
forms of direct volume rendering are not discussed in this paper. The methods are implemented in a parallel 
ray tracing system that runs on an SGI Reality Monster, which is a conventional (distributed) shared-memory 
multiprocessor machine. The only graphics hardware that is used is the high-speed framebuffer. This overall 
system is described in a previous paper [2]. Conventional wisdom holds that ray tracing is too slow 
to be competitive with hardware z-buffers. However, when rendering a suf.ciently large dataset, ray 
tracing should be competitive be screen eye value is searched for along part of ray that is inside the 
volume  Fig. 1. A ray traverses a volume looking for a speci.c or maximum value. No explicit surface 
or volume is computed. cause its low time complexity ultimately overcomes its large time constant [3]. 
This crossover will happen sooner on a multiple CPU computer because of ray tracing s high degree of 
intrinsic parallelism. The same arguments apply to the volume traversal problem. In Section II we review 
previous work, describe several volume visualization techniques, and give an overview of the parallel 
ray tracing code that provides the backbone of our system. Section III describes the data organizational 
optimizations that allow us to achieve interactivity. In Section IV we describe our memory optimizations 
for various types of volume visualization. In Section V we show our methods applied to several datasets. 
We discuss the implications of our results in Section VI, and point to some future directions in Section 
VII. Some material that is not research-oriented but is helpful for implementors is presented in the 
appendices. II. BACKGROUND Ray tracing has been used for volume visualization in many works (e.g., [4], 
[5], [6]). Typically, the ray tracing of a pixel is a kernel operation that could take place within any 
conventional ray tracing system. In this section we review how ray tracers are used in visualization, 
and how they are implemented ef.ciently at a systems level. A. Ef.cient Ray Tracing It is well understood 
that ray tracing is accelerated through two main techniques [7]: accelerating or eliminating ray/voxel 
intersection tests and parallelization. Acceleration is usually accomplished by a combination of spatial 
subdivision and early ray termination [4], [8], [9]. Ray tracing for volume visualization naturally lends 
itself towards parallel implementations [10], [11]. The computation for each pixel is independent of 
all other pixels, and the data structures used for casting rays are usually read-only. These proper 
ties have resulted in many parallel implementations. A variety Computer Science Department, University 
of Utah, Salt Lake City, UT 84112. E-mail: [sparker jmap jylivnat jppsloan jhansen jshirley 1@cs.utah.edu. 
of techniques have been used to make such systems parallel, and many successful systems have been built 
(e.g., [10], [12], [13], [14]). These techniques are surveyed by Whitman [15]. B. Methods of Volume Visualization 
There are several ways that scalar volumes can be made into images. The most popular simple volume visualization 
techniques that are not based on cutting planes are isosurfacing, maximum-intensity projection and direct 
volume rendering. In isosurfacing, a surface is displayed that is the locus of points where the scalar 
.eld equals a certain value. There are several methods for computing images of such surfaces including 
constructive approaches such as marching cubes [16], [17] and ray tracing [18], [19], [20]. In maximum-intensity 
projection (MIP) each value in the scalar .eld is associated with an intensity and the maximum intensity 
seen through a pixel is projected onto that pixel [21]. This is a winner-takes-all algorithm, and thus 
looks more like a search algorithm than a traditional volume color/opacity accumulation algorithm. More 
traditional direct volume rendering algorithms accumulate color and opacity along a line of sight [8], 
[4], [5], [6], [22]. This requires more intrinsic computation than MIP, and we will not deal with it 
in this paper. C. Traversals of Volume Data Traversal algorithms for volume data are usually customized 
to the details of the volume data characteristics. The three most common types [23] of volume data used 
in applications are shown in Figure 2. To traverse a line through rectilinear data some type of incremental 
traversal is used (e.g., [24], [25]). Because there are many cells, a hierarchy can be used that skips 
uninteresting parameter intervals, which increases performance [26], [27], [28], [29]. For curvilinear 
volumes, the ray can be intersected against a polygonal approximation to the boundary, and then a more 
complex cell-to-cell traversal can be used [30]. For unstructured volumes a similar technique can be 
used [31], [32]. Once the ray is intersected with a volume, it can be tracked from cell-to-cell using 
the connectivity information present in the mesh. Another possibility for both curvilinear and unstructured 
grids is to resample to a rectilinear grid [33], although resampling artifacts and data explosion are 
both issues. III. TRAVERSAL OPTIMIZATIONS Our system organizes the data into a shallow rectilinear hierarchy 
for ray tracing. For unstructured or curvilinear grids, a rectilinear hierarchy is imposed over the data 
domain. Within a given level of the hierarchy we use the incremental method described by Amanatides and 
Woo [24]. A. Memory Bricking The .rst optimization is to improve data locality by organizing the volume 
into bricks that are analogous to the use of image tiles in image-processing software and other volume 
rendering programs [21], [34] (Figure 3). Our use of lookup tables is particularly similar to that of 
Sakas et al. [21].  Fig. 2. The three most common types of point-sampled volume data. Effectively utilizing 
the cache hierarchy is a crucial task in designing algorithms for modern architectures. Bricking or 3D 
tiling has been a popular method for increasing locality for ray cast volume rendering. The dataset is 
reordered into nxnxn cells which then .ll the entire volume. On a machine with 128 byte cache lines, 
and using 16 bit data values, nis exactly 4. However, using .oat (32 bit) datasets, nis closer to 3. 
Effective translation lookaside buffer (TLB) utilization is also becoming a crucial factor in algorithm 
performance. The same technique can be used to improve TLB hit rates by creating mx mxmbricks of nxnxncells. 
For example, a 40x20x19 volume could be decomposed into 4x2x2macrobricks of 2x2x2bricks of 5x5x5cells. 
This corresponds to m2 and n5. Because 19 cannot be factored by mn10, one level of padding is needed. 
We use m5for 16 bit datasets, and m6for 32 bit datasets. The resulting offset qinto the data array can 
be computed for any x;y;ztriple with the expression: q=((x+n)+m)n 3 m 3((N+n)+m)((N+n)+m)+ zy ((y+n)+m)n 
3 m 3((Nz+n)+m)+ ((z+n)+m)n 3 m 3+ ((x+n)modm)n 3 m 2+ ((y+n)modm)n 3 m+ ((z+n)modm)n 3+ (xmodnxn)n 2+ 
(ymodn)xn+ (zmodn) where Nx, Nyand Nzare the respective sizes of the dataset. This expression contains 
many integer multiplication, divide and modulus operations. On modern processors, these operations are 
extremely costly (32+ cycles for the MIPS R10000). Where nand mare powers of two, these operations can 
be converted to bitshifts and bitwise logical operations. However, the ideal size is rarely a power 
of two thus, a method that addresses arbitrary sizes is needed. Some of the multiplications can be converted 
to shift/add operations, but the divide and modulus operations are more problematic. The indices could 
be computed incrementally, but this would require tracking 9 counters, with numerous comparisons and 
poor branch prediction performance. Note that this expression can be written as: qFx(x)+Fy(y)+Fz(z) 
where Fx(x)=((x+n)+m)n 3 m 3((Nz+n)+m)((Ny+n)+m)+ ((x+n)modm)n 3 m 2+ (xmodnxn)n 2 F(y)=((y+n)+m)n 3 
m 3((N+n)+m)+ yz ((y+n)modm)n 3 m+ (ymodn)xn Fz(z)=((z+n)+m)n 3 m 3+ ((z+n)modm)n 3+ (zmodn) We tabulate 
Fx, Fy,and Fzand use x, y,and zrespectively to .nd three offsets in the array. These three values are 
summed to compute the index into the data array. These tables will consist of Nx, Ny,and Nzelements 
respectively. The total sizes of the tables will .t in the primary data cache of the processor even for 
very large data set sizes. Using this technique, we note that one could produce mappings which are much 
more complex than the two level bricking described here, although it is not at all obvious which of these 
mappings would achieve the highest cache utilization. For many algorithms, each iteration through the 
loop examines the eight corners of a cell. In order to .nd these eight values, we need to only lookup 
Fx(x), Fx(x+1), Fy(y), Fy(y+1), Fz(z),and Fz(z+1). This consists of six index table lookups for each 
eight data value lookups. B. Multilevel Grid The other basic optimization we use is a multi-level spatial 
hierarchy to accelerate the traversal of empty cells as is shown in Figure 4. Cells are grouped divided 
into equal portions, and then a macrocell is created which contains the minimum and maximum data value 
for its children cells. This is a common variant of standard ray-grid techniques [35] and is especially 
similar to previous multi-level grids [36], [37]. The use of minimum/maximum caching has been shown 
to be useful [28], [29], [38]. The ray-isosurface traversal algorithm examines the min and max at each 
macrocell before deciding whether to recursively examine a deeper level or to proceed to the next cell. 
The p typical complexity of this search will be O(3n)for a three level hierarchy [36]. While the worst 
case complexity is still O(n), it is dif.cult to imagine an isosurface occurring in practice approaching 
this worst case. Using a deeper hierarchy can theoretically reduce the average case complexity slightly, 
but also dramatically increases the storage cost of intermediate levels. We have experimented with modifying 
the number of levels in the hierarchy and empirically determined that a tri-level hierarchy (one top-level 
cell, two intermediate macrocell levels, and the data cells) is highly ef.cient. This optimum may be 
data dependent and is modi.able at program startup. Using a tri-level hierarchy, the storage overhead 
is negligible ( 0:5% of the data size). The cell sizes used in the hierarchy are independent of the brick 
sizes used for cache locality in the .rst optimization.  Fig. 3. Cells can be organized into tiles or 
bricks in memory to improve locality. The numbers in the .rst brick represent layout in memory. Neither 
the number of atomic voxels nor the number of bricks need be a power of two.  Fig. 4. With a two-level 
hierarchy, rays can skip empty space by traversing larger cells. A three-level hierarchy is used for 
most of the examples in this paper. Macrocells can be indexed with the same approach as used for memory 
bricking of the data values. However, in this case there will be three table lookups for each macrocell. 
This, combined with the signi.cantly smaller memory footprint of the macrocells made the effect of bricking 
the macrocells negligible. IV. ALGORITHMS This section describes three types of volume visualization 
that use ray tracing: . isosurfacing on rectilinear grids . isosurfacing on unstructured meshes . maximum-intensity 
projection on rectilinear grids The .rst two require an operation of the form: .nd a speci.c scaler value 
along a ray. The third asks: what is the maximum value along a ray. All of these are searches that can 
bene.t from the hierarchical data representations described in the previous section. A. Rectilinear Isosurfacing 
Our algorithm has three phases: traversing a ray through cells which do not contain an isosurface, analytically 
computing the isosurface when intersecting a voxel containing the isosurface, shading the resulting intersection 
point. This process is repeated for each pixel on the screen. A bene.t is that adding incremental features 
to the rendering has only incremental cost. For example, if one is visualizing multiple isosurfaces 
with some of them Fig. 5. The ray traverses each cell (left), and when a cell is encountered that has 
an isosurface in it (right), an analytic ray-isosurface intersection computa tion is performed. rendered 
transparently, the correct compositing order is guaranteed since we traverse the volume in a front-to-back 
order along the rays. Additional shading techniques, such as shadows and specular re.ection, can easily 
be incorporated for enhanced visual cues. Another bene.t is the ability to exploit texture maps which 
are much larger than physical texture memory which is currently available up to 64 MBytes. However, newer 
architectures that use main memory for textures eliminate this issue. For a regular volume, there is 
a one-to-one correspondence with the cells forming bricks and the voxels. This leads to a large branching 
factor for the shallow hierarchy which we have empirically found to yield the best results. If we assume 
a regular volume with even grid point spacing arranged in a rectilinear array, then ray-isosurface intersection 
is straightforward. Analogous simple schemes exist for intersection of tetrahedral cells as described 
below. To .nd an intersection (Figure 5), the ray ~a+t~traverses bcells in the volume checking each cell 
to see if its data range bounds an isovalue. If it does, an analytic computation is performed to solve 
for the ray parameter tat the intersection with the isosurface: p(xa+txb;ya+tyb;za 0: +tzb),piso When 
approximating pwith a trilinear interpolation between discrete grid points, this equation will expand 
to a cubic polynomial in t. This cubic can then be solved in closed form to .nd the intersections of 
the ray with the isosurface in that cell. We use the closed form solution for convenience since its stability 
and ef.ciency have not proven to be major issues for the data we have used in our tests. Only the roots 
of the polynomial which are contained in the cell are examined. There may be multiple roots, corresponding 
to multiple intersection points. In this case, the smallest t(closest to the eye) is used. There may 
also be no roots of the polynomial, in which case the ray misses the isosurface in the cell. The details 
of this intersection computation are given in Appendix A. Note that using trilinear interpolation directly 
will produce more complex isosurfaces than is possible with a marching cubes algorithm. An example of 
this is shown in Figure 6 which illustrates case 4 from Lorensen and Cline s paper [17]. Techniques such 
as the Asymptotic Decider [39] could disambiguate such cases but they would still miss the correct topology 
due to the isosurface interpolation scheme.  Fig. 6. Left: The isosurface from the marching cubes algorithm. 
Right: The isosurface resulting the true cubic behavior inside the cell.  Fig. 7. For a given leaf cell 
in the rectilinear grid, indices to the shaded elements of the unstructured mesh are stored. B. Unstructured 
Isosurfacing For unstructured meshes, the same memory hierarchy is used as is used in the rectilinear 
case. However, we can control the resolution of the cell size at the .nest level. We chose a resolution 
which uses approximately the same number of leaf nodes as there are tetrahedral elements. At the leaf 
nodes a list of references to overlapping tetrahedra is stored (Figure 7). For ef.ciency, we store 
these lists as integer indices into an array of all tetrahedra. Rays traverse the cell hierarchy in a 
manner identical to the rectilinear case. However, when a cell is detected that might contain an isosurface 
for the current isovalue, each of the tetrahedra in that cell are tested for intersection. No connectivity 
information is used for the tetrahedra; instead they are treated as independent items, just as in a traditional 
surface-based ray tracer. The isosurface for a tetrahedron is computed implicitly using barycentric 
coordinates. The intersection of the parameterized ray and the isoplane is computed directly, using 
the implicit equations for the plane and the parametric equation for the ray. The intersection point 
is checked to see if it is still within the bounds of the tetrahedron by making sure the barycentric 
coordinates are all positive. Details of this intersection code are described in Appendix B. C. Maximum-Intensity 
Projection The maximum-intensity projection (MIP) algorithm seeks the largest data value that intersects 
a particular ray. It utilizes the same shallow spatial hierarchy described above for isosurface extraction. 
In addition, a priority queue is used to track the cells or macrocells with the maximal values. For each 
ray, the priority queue is .rst initialized with single top level macrocell. The maximum data value 
for the dataset is used as the priority value for this entry in the priority queue. The algorithm repeatedly 
pulls the largest entry from the priority queue and breaks it into smaller (lower level) macrocells. 
Each of these cells are inserted into the priority queue with the precomputed maximum data value for 
that region of space. When the lowest-level cells are pulled from the priority queue, the algorithm traverses 
the segment of the ray which intersects the macrocell. Bilinear interpolation is used at the intersection 
of the ray with cell faces since these are the extremal values of the ray-cell intersection in a linear 
interpolation scheme. For each data cell face which intersects the ray, a bilinear interpolation of 
the data values is computed, and the maximum of these values in stored again in the priority queue. 
Finally, when one of these data maximums appears at the head of the priority queue, the algorithm has 
found the maximum data value for the entire ray. To reduce the average length of the priority queue, 
the algorithm performs a single trilinear interpolation of the data at one point to establish a lower-bound 
for the maximum value of the ray. Macrocells and datacells which do not exceed this lower-bound are not 
entered into the priority queue. To obtain this value, we perform the trilinear interpolation using the 
tcorresponding to the maximum value from whatever previous ray a particular processor has computed. 
Typically, this will be a value within the same block of pixels and exploits image-space coherence. If 
not, it still provides a bound on the maximum along the ray. If this tvalue is unavailable (due to program 
startup, or a ray missing the data volume), we choose the midpoint of the ray segment which intersects 
the data volume. This is a simple heuristic which improves the performance for many datasets. Similar 
to the isosurface extraction algorithm, the MIP algorithm uses the 3D bricking memory layout for ef.cient 
cache utilization when traversing the data values. Since each processor will be using a different priority 
queue as it processes each ray, an ef.cient implementation of a priority queue which does not perform 
dynamic memory allocation is essential for performance of the algorithm. V. RESULTS We applied ray tracing 
isosurface extraction to interactively visualize the Visible Woman dataset. The Visible Woman dataset 
is available through the National Library of Medicine as part of its Visible Human Project [40]. We used 
the computed tomography (CT) data which was acquired in 1mm slices with varying in-slice resolution. 
This rectilinear data is composed of 1734 slices of 512x512 images at 16 bits. The complete dataset is 
910 MBytes. Rather than down-sample the data with a loss of resolution, we utilize the full resolution 
data in our experiments. As previously described, our algorithm has three phases: traversing a ray through 
cells which do not contain an isosurface, analytically computing the isosurface when intersecting a voxel 
containing the isosurface, and shading the resulting intersection point. Figure 8 shows a ray tracing 
for two isosurface values. Figure 9 illustrates how shadows can improves the accuracy of our TABLE 
I DATA FROM RAY TRACING THE VISIBLE WOMAN.THE FRAMES-PER-SECOND (FPS) GIVES THE OBSERVED RANGE FOR THE 
INTERACTIVELY GENERATED VIEWPOINTS ON 64 CPUS.  Isosurface Traversal Intersec. Shading FPS Skin (p600:5) 
55% 22% 23% 7-15 Bone (p1224:5) 66% 21% 13% 6-15 TABLE II SCALABILITY RESULTS FOR RAY TRACING THE BONE 
ISOSURFACE IN THE VISIBLE HUMAN. A 512X512 IMAGE WAS GENERATED USING A SINGLE VIEW OF THE BONE ISOSURFACE. 
 View 1 View 2 # cpus FPS speedup FPS speedup 1 0.18 1.0 0.39 1.0 2 0.36 2.0 0.79 2.0 4 0.72 4.0 1.58 
4.1 8 1.44 8.0 3.16 8.1 12 2.17 12.1 4.73 12.1 16 2.89 16.1 6.31 16.2 24 4.33 24.1 9.47 24.3 32 5.55 
30.8 11.34 29.1 48 8.50 47.2 16.96 43.5 64 10.40 57.8 22.14 56.8 96 16.10 89.4 33.34 85.5 128 20.49 113.8 
39.98 102.5  geometric perception. Figure 10 shows a transparent skin isosurface over a bone isosurface. 
Table I shows the percentages of time spent in each of these phases, as obtained through the cycle hardware 
counter in Silicon Graphics Speedshop1. As can be seen, we achieve about 10 frames per second (FPS) interactive 
rates while rendering the full, nearly 1 GByte, dataset. Table II shows the scalability of the algorithm 
from 1 to 128 processors. View 2 uses a zoomed out viewpoint with approximately 75% pixel coverage whereas 
view 1 has nearly 100% pixel coverage. We chose to examine both cases since view 2 achieves higher frame 
rates. The higher frame rates cause less parallel ef.ciency due to synchronization and load balancing. 
Of course, maximum interaction is obtained with 128 processors, but reasonable interaction can be achieved 
with fewer processors. If a smaller number of processors were available, one could reduce the image 
size in order to restore the interactive rates. Ef.ciencies are 91% and 80% for view 1 and 2 respectively 
on 128 processors. The reduced ef.ciency with larger numbers of processors (.64) can be explained by 
load imbalances and the time required to synchronize processors at the required frame rate. The ef.ciencies 
would be higher for a larger image. Table III shows the improvements which were obtained 1Speedshop 
is the vendor provided performance analysis environment for the SGI IRIX operating system. TABLE III 
TIMES IN SECONDS FOR OPTIMIZATIONS FOR RAY TRACING THE VISIBLE HUMAN. A 512X512 IMAGE WAS GENERATED ON 
16 PROCESSORS USING A SINGLE VIEW OF AN ISOSURFACE. View Initial Bricking Hierarchy+Bricking skin: front 
1.41 1.27 0.53 bone: front 2.35 2.07 0.52 bone: close 3.61 3.52 0.76 bone: from feet 26.1 5.8 0.62 TABLE 
IV FRAMERATES VARYING SHADOW AND TEXTURE FOR THE VISIBLE MALE DATASET ON 64 CPUS (FPS). no shadows, 
no texture 15.9 shadows, no texture 8.7 no shadows, texture 12.6 shadows, texture 7.5 through the data 
bricking and spatial hierarchy optimizations. Using a ray tracing architecture, it is simple to map each 
isosurface with an arbitrary texture map. The Visible Man dataset includes both CT data and photographic 
data. Using a texture mapping technique during the rendering phase allows us to add realism to the resultant 
isosurface. The photographic cross section data which was acquired in 0.33mm slices, and can be registered 
with the CT data. This combined data cab be used as a texture mapped model to add realism to the resulting 
isosurface. The size of the photographic dataset is approximately 13 GBytes which clearly is too large 
to .t into texture memory. When using texture mapping hardware it is up to the user to implement intelligent 
texture memory management. This makes achieving effective texture performance non-trivial. In our implementation, 
we down-sampled this texture by a factor of 0.6 in two of the dimensions so that it occupied only 5.1 
GBytes. The framerates for this volume with and without shadows and texture are shown in Table IV. A 
sample image is shown in Figure 11. We can achieve interactive rates when applying the full resolution 
photographic cross sections to the full resolution CT data. We know of no other work which achieves these 
rates. Figure 12 shows an isosurface from an unstructured mesh made up of 1.08 million elements which 
contains adaptively re.ned tetrahedral elements. The heart and lungs shown are polygonal meshes that 
serve as landmarks. The rendering times for this data, rendered without the polygonal landmarks at 512 
by 512 pixel resolution, is shown in Table V. As would be expected, the FPS is lower than the structured 
data but the method scales well. We make the number of lowest-level cells proportional to the number 
of tetrahedral elements, and the bottleneck is the intersection with individual tetrahedral elements. 
This dataset composed of adaptively re.ned tetrahedral with volume differences of two orders of magnitude. 
Figure 13 shows a maximum-intensity projection of the Visible Female dataset. This dataset runs in approximately 
0.5 to 2 FPS on 16 processors. Using the use last t optimization saves  TABLE V DATA FROM RAY TRACING 
UNSTRUCTURED GRIDS AT 512X512 PIXELS ON 1 TO 126 PROCESSORS.THE ADAPTIVELY REFINED DATASET IS FROM A 
BIOELECTRIC FIELD PROBLEM. # cpus FPS speedup 1 0.108 1 2 0.21 1.97 3 0.32 2.95 4 0.42 3.91 6 0.63 5.86 
8 0.84 7.78 12 1.25 11.56 16 1.64 15.20 24 2.44 22.58 32 3.21 29.68 48 4.76 44.07 64 6.46 59.81 96 9.05 
83.80 124 11.13 103.06 approximately 15% of runtime. Generating such a frame rate using conventional 
graphics hardware would require approximately a 1.8 GPixel/second pixel .ll rate and 900 Mbytes of texture 
memory. VI. DISCUSSION We contrast applying our algorithm to explicitly extracting polygonal isosurfaces 
from the Visible Woman data set. For the skin isosurface we generated 18,068,534 polygons. For the bone 
isosurface we generated 12,922,628 polygons. These numbers are consistent with those reported by Lorensen 
given that he was using a cropped version of the volume [41]. With this number of polygons, it would 
be challenging to achieve interactive rendering rates on conventional high-end graphics hardware. Our 
method can render a ray-traced isosurface of this data at roughly ten frames per second using a 512 by 
512 image on 64 processors. Table VI shows the extraction time for the bone isosurface using both NOISE 
[42] and marching cubes [17]. Note that because we are using static load balancing, these numbers would 
improve with a dynamic load balancing scheme. However, this would still not allow interactive modi.cation 
of the isovalue while displaying the isosurface. Although using a downsampled or simpli.ed detail volume 
would allow interaction at the cost of some detail. Simpli.ed, precomputed isosurfaces could also yield 
interaction, but storage and precomputation time would be signi.cant. Triangle stripping could improve 
display rates by up to a factor of three because isosurface meshes are usually transform bound. Note 
that we gain ef.ciency for both the extraction and rendering components by not explicitly extracting 
the geometry. Our algorithm is therefore not well-suited for applications that will use the geometry 
for non-graphics purposes. The interactivity of our system allows exploration of both the data by interactively 
changing the isovalue or viewpoint. For example, one could view the entire skeleton and interactively 
zoom in and modify the isovalue to examine the detail in the  TABLE VI EXPLICIT BONE ISOSURFACE EXTRACTION 
TIMES IN SECONDS. # cpus NOISE build NOISE extract Marching cubes 1 4838 110 627 2 2109 81 324 4 1006 
56 171 8 885 31 93 16 437 24 49 32 118 14 26 64 59 12 24 toes all at about ten FPS. The variation in 
framerate is shown in Fig. 14. Brady et al. [43] describe a system which allows, on a Pentium workstation 
with accelerated graphics, interactive navigation through the Visible Human data set. Their technique 
is two-fold: 1) combine frustum culling with intelligent paging from disk of the volume data, and 2) 
utilize a two-phase perspective volume rendering method which exploits coherence in adjacent frames. 
Their work differs from ours in that they are using incremental direct volume rendering while we are 
exploiting isosurface or MIP rendering. This is evidenced by their incremental rendering times of about 
2 seconds per frame for a 480x480 image. A full (non-incremental) rendering is nearly 20 seconds using 
their technique. For a single CPU, our isosurface rendering time is several seconds per frame (see Table 
II) depending on viewpoint. While it is dif.cult to directly compare these techniques due to their differing 
application focus, our method allows for the entire data set to reside within the view frustum without 
severe performance penalties since we are exploiting parallelism. The architecture of the parallel machine 
plays an important role in the success of this technique. Since any processor can randomly access the 
entire dataset, the dataset must be available to each processor. Nonetheless, there is fairly high locality 
in the dataset for any particular processor. As a result, a shared memory or distributed shared memory 
machine, such as the SGI Origin 2000, is ideally suited for this application. The load balancing mechanism 
also requires a .ne-grained low-latency communication mechanism for synchronizing work assignments and 
returning completed image tiles. With an attached In.nite Reality graphics engine, we can display images 
at high frame rates without network bottlenecks. We feel that implementing a similar technique on a 
distributed memory machine would be extraordinarily challenging, and would probably not achieve the 
same rates without duplicating the dataset on each processor. VII. FUTURE WORK AND CONCLUSIONS Since 
all computation is performed in software, there are many avenues which deserve exploration. Ray tracers 
have a relatively clean software architecture, in which techniques can be added without interfering with 
existing techniques, without re-unrolling large loops, and without complicated state management as are 
characteristic of a typical polygon renderer. We believe the following possibilities are worth investigating: 
. 011 (x0,y1,z1) (0,1,1) . 111 (x1,y1,z1) . 001 (x0,y0,z1) (1,1,1) (0,0,1) . 010 (x0,y1,z0) (0,1,0) 
z y . 110. 000 (x1,y1,z0) (x0,y0,z0) (1,1,0) (0,0,0) x Fig. 15. The geometry for a cell. The bottom 
coordinates are the (u;v;w) values for the intermediate point. . Exploration of other hierarchical methods 
in addition to the multilevel hierarchy described above. . Combination with other scalar and vector visualization 
tools, such as cutting planes, surface maps, streamlines, etc. . Using higher-order interpolants. Although 
numerical root .nding would be necessary, the images might look better [19]. Since the intersection routine 
is not the bottleneck the degradation in performance might be reasonable. We have shown that ray tracing 
can be a practical alternative to explicit isosurface extraction for very large datasets. As data sets 
get larger, and as general purpose processing hardware becomes more powerful, we expect this to become 
a very attractive method for visualizing large scale scalar data both in terms of speed and rendering 
accuracy. VIII. ACKNOWLEDGMENTS Thanks to Matthew Bane and Michelle Miller for comments on the paper. 
Thanks to Chris Johnson for providing the open collaborative research environment that allowed this work 
to happen. Special thanks to Steve Modica and Robert Cummins at SGI for crucial bug .xes in support code. 
This work was supported by the SGI Visual Supercomputing Center, the Utah State Centers of Excellence, 
the Department of Energy and the National Science Foundation. Special thanks to Jamie Painter and the 
Advanced Computing Laboratory at Los Alamos National Laboratory for access to a 128 processor machine 
for .nal benchmarks. Ruth Klepfer provide assistance in obtaining the various unstructured data sets. 
APPENDIX I. RAY-ISOSURFACE INTERSECTION FOR TRILINEAR BOXES This appendix expands on some details of 
the intersection of a ray and a trilinear surface. It is not new research, but is helpful for implementors. 
A rectilinear volume is composed of a three dimensional array of point samples that are aligned to the 
Cartesian axes and are equally spaced in a given dimension. A single cell from such a volume is shown 
in Figure 15. Other cells can be generated by exchanging indices (i;j;k)for the zeros and ones in the 
.gure. (x1, y1) (1, 1) u1 (0, 0)  v0 v1 (x0, y0) (0, 0) u0 (1, 1) Fig. 16. Various coordinate systems 
used for interpolation and intersection. The density at a point within the cell is found using trilinear 
interpolation: p(u;v;w)(1,u)(1,v)(1,w)p000+(1) (1,u)(1,v)(w)p001+ (1,u)(v)(1,w)p010+ (u)(1,v)(1,w)p100+ 
(u)(1,v)(w)p101+ (1,u)(v)(w)p011+ (u)(v)(1,w)p110+ (u)(v)(w)p111 where x,x0 u (2) x1,x0 y,y0 v y1,y0 
z,z0 w z1,z0 Note that x1,x 1,u (3) x1,x0 y1,y 1,v y1,y0 z1,z 1,w z1,z0 If we rede.ne u01,uand u1u, and 
similar de.nitions for v0;v;w;w1,thenweget: 10 X puivjwkpijk i;j;k=0;1 For a given point (x;y;z)in the 
cell, the surface normal is given by the gradient with respect to (x;y;z): @p@p@p~~ Nrp;; @x@y@z ~ So 
the normal vector of (Nx;NY;Nz)rpis X (,1)i+1 vjwkNx pijk x1,x0 i;j;k=0;1 X (,1)j+1 uiwkNy pijk y1,y0 
i;j;k=0;1 X (,1)k+1 uivjNz pijk z1,z0 i;j;k=0;1 Lin and Ching [18] described a method for intersecting 
a ray with a trilinear cell. We derive a similar result that is more tailored to our implementation. 
~ See .gure 16. Given a ray p~~a+tb, the intersection with the isosurface occurs where p(~p) We can 
convert this piso. ~ ray into coordinates de.ned by (u0;v0;w0): p~0 ~a0+tb0and ~~ a third ray de.ned 
by p~1 ~a1+tb1. These rays p~0 ~a0+tb0 ~ and ~p1 ~a1+tb1are now used for the intersection computation. 
These two rays are in the two coordinate systems (Figure 16): ~a0and ~b0 (u a 0;v a 0;w a 0) (u b 0;v 
b 0;w b 0) x1,xa x1,x0 ; y1,ya y1,y0 ; z1,za z1,z0 ; xb x1,x0 ; yb y1,y0 ; zb z1,z0 : ~ These equations 
are different because ~a0is a location and b0is ~ a direction. The equations are similar for ~a1and b1: 
 xa,x0ya,y0za,z0 aaa ~a1(u1;v1;w1) ;;; x1,x0y1,y0z1,z0 and ,xb ,yb ,zb bbb ~(u;v;w) ;;: b1111 x1,x0y1,y0z1,z0 
 Note that tis the same for all three rays. This point can be found by traversing the cells and doing 
a brute-force algebraic solution for t. The intersection with the isosurface p(p~)piso occurs where: 
 X,n,n,n ababab u+tuv+tvw+twpijk piso iiiiiii;j;k=0;1 This can be simpli.ed to a cubic polynomial in 
t: At3+Bt2+Ct+D0 where X bbb Auiviwipijk i;j;k=0;1 X,n abbbabbba Buv+uw+u iiwiiviiiviwipijk i;j;k=0;1 
X,n baaabaaab Cuw+uv+uvw iviiiiwiiiipijk i;j;k=0;1 X aaa D,piso + uiviwipijk i;j;k=0;1 The solution 
to a cubic polynomial is discussed the article by Schwarze [44]. We used his code (available on the web 
in several Graphics Gems archive sites) with two modi.cations: special cases for quadratic or linear 
solutions (his code assumes Ais non-zero), and the EQN EPS parameter was set to 1.e-30 which provided 
for maximum stability for large coef.cients. . 3 (x3,y3,z3) (0,0,0,1) . 2 (x2,y2,z2) . 0 (0,0,1,0) 
(x0,y0,z0) (1,0,0,0) . 1 (x1,y1,z1) (0,1,0,0) p0 Fig. 18. The barycentric coordinate a0is the scaled 
distance dlD. The dis tances are dand Dare signed distances to the plane containing the triangu lar 
face opposite p0. II. RAY-ISOSURFACE INTERSECTION FOR BARYCENTRIC TETRAHEDRA This appendix is geared 
toward implementors and discusses the details of intersecting a ray with a barycentric tetrahedral isosurface. 
An unstructured mesh is composed of three dimensional point samples arranged into a simplex of tetrahedra. 
A single cell from such a volume is shown in Figure 17, where the four vertices are pi(xi;yi;zi). The 
density at a point within the cell is found using barycentric interpolation: p( 0;1;2;3) 0p0+ 1p1+ 2p2+ 
3p3; where 0+ 1+ 2+ 31: Similar equations apply to points in terms of the vertices. For points inside 
the tetrahedron, all barycentric coordinates are positive. One way to compute barycentric coordinates 
is to measure the distance from the plane that de.nes each face (Figure 18). This is accomplished by 
choosing a plane equation f0(p)0 such that f0(p0)1. Such equations for all four plane-faces of the tetrahedron 
allow us to compute barycentric coordinates of a point pdirectly: i(p) fi(p). If we take the ray p(t) 
a +t ~b, then we get an equation for the density along the ray: 3 X p(t) fi(a+t~b)pi: i=0 11 If we 
solve for p(t)piso, then we get a linear equation in t, so solution is straightforward. If the resulting 
barycentric coordinates of p(t)are all positive, the point is in the tetrahedron, and it is accepted. 
Finding the normal is just a matter of taking the gradient: 3 X ~~ rp(p) pirfi(p): i=0 Because fiis 
just a plane equation of the form ~ni.(p,qi) ~ where qiis a constant point, the normal vector Nis simply 
3 X ~ Npi ~ni: i=0 This is a constant for the cell, but we do not precompute it since it would require 
extra memory accesses. REFERENCES [1] Steven Parker, Peter Shirley, Yarden Livnat, Charles Hansen, and 
Peter-Pike Sloan, Interactive ray tracing for isosurface rendering, in Proceedings of Visualization 
98, October 1998. [2] Steven Parker, William Martin, Peter-Pike Sloan, Peter Shirley, Brian Smits, and 
Charles Hansen, Interactive ray tracing, in Symposium on Interactive 3D Graphics, April 1999. [3] James 
T. Kajiya, An overview and comparison of rendering methods, A Consumer s and Developer s Guide to Image 
Synthesis, pp. 259 263, 1988, ACM Siggraph 88 Course 12 Notes. [4] Mark Levoy, Display of surfaces from 
volume data, IEEE Computer Graphics &#38; Applications, vol. 8, no. 3, pp. 29 37, 1988. [5] Paolo Sabella, 
A rendering algorithm for visualizing 3d scalar .elds, Computer Graphics, vol. 22, no. 4, pp. 51 58, 
July 1988, ACM Siggraph 88 Conference Proceedings. [6] Craig Upson and Micheal Keeler, V-buffer: Visible 
volume rendering, Computer Graphics, vol. 22, no. 4, pp. 59 64, July 1988, ACM Siggraph 88 Conference 
Proceedings. [7] E. Reinhard, A.G. Chalmers, and F.W. Jansen, Overview of parallel photo-realistic graphics, 
in Eurographics 98, 1998. [8] Arie Kaufman, Volume Visualization, IEEE CS Press, 1991. [9] Lisa Sobierajski 
and Arie Kaufman, Volumetric Ray Tracing, 1994 Workshop on Volume Visualization, pp. 11 18, Oct. 1994. 
[10] K.L. Ma, J.S. Painter, C.D. Hansen, and M.F. Krogh, Parallel Volume Rendering using Binary-Swap 
Compositing, IEEE Comput. Graphics and Appl., vol. 14, no. 4, pp. 59 68, July 1993. [11] Michael J. Muuss, 
Rt and remrt -shared memory parllel and network distributed ray-tracing programs, in USENIX: Proceedings 
of the Fourth Computer Graphics Workshop, October 1987. [12] Guy Vezina, Peter A. Fletcher, and Philip 
K. Robertson, Volume Rendering on the MasPar MP-1, in 1992 Workshop on volume Visualization, 1992, pp. 
3 8, Boston, October 19-20. [13] P. Schroder and Gordon Stoll, Data Parallel Volume Rendering as Line 
Drawing, in 1992 Workshop on volume Visualization, 1992, pp. 25 31, Boston, October 19-20. [14] Michael 
J. Muuss, Towards real-time ray-tracing of combinatorial solid geometric models, in Proceedings of BRL-CAD 
Symposium, June 1995. [15] Scott Whitman, A Survey of Parallel Algorithms for Graphics and Visualization, 
in High Performance Computing for Computer Graphics and Visualization, 1995, pp. 3 22, Swansea, July 
3 4. [16] B. Wyvill G. Wyvill, C. McPheeters, Data structures for soft objects, The Visual Computer, 
vol. 2, pp. 227 234, 1986. [17] William E. Lorensen and Harvey E. Cline, Marching cubes: A high resolution 
3d surface construction algorithm, Computer Graphics, vol. 21, no. 4, pp. 163 169, July 1987, ACM Siggraph 
87 Conference Proceedings. [18] Chyi-Cheng Lin and Yu-Tai Ching, An ef.cient volume-rendering algorithm 
with an analytic approach, The Visual Computer, vol. 12, no. 10, pp. 515 526, 1996. [19] Stephen Marschner 
and Richard Lobb, An evaluation of reconstruction .lters for volume rendering, in Proceedings of Visualization 
94, October 1994, pp. 100 107. [20] Milos Sramek, Fast surface rendering from raster data by voxel traversal 
using chessboard distance, in Proceedings of Visualization 94, October 1994, pp. 188 195. [21] Georgios 
Sakas, Marcus Grimm, and Alexandros Savopoulos, Optimized maximum intensity projection (MIP), in Eurographics 
Rendering Workshop 1995. Eurographics, June 1995. [22] Robert A. Drebin, Loren Carpenter, and Pat Hanrahan, 
Volume rendering, Computer Graphics, vol. 22, no. 4, pp. 65 74, July 1988, ACM Siggraph 88 Conference 
Proceedings. [23] Don Speray and Steve Kennon, Volume probes: Interactive data exploration on arbitrary 
grids, in Computer Graphics (San Diego Workshop on Volume Visualization), 1990, pp. 5 12. [24] John Amanatides 
and Andrew Woo, A fast voxel traversal algorithm for ray tracing, in Eurographics 87, 1987. [25] Akira 
Fujimoto, Takayu Tanaka, and Kansei Iwata, Arts: Accelerated ray-tracing system, IEEE Computer Graphics 
&#38; Applications, pp. 16 26, April 1986. [26] John Danskin and Pat Hanrahan, Fast algorithms for volume 
ray tracing, 1992 Workshop on Volume Visualization, pp. 91 98, 1992. [27] Marc Levoy, Ef.cient ray tracing 
of volume data, ACM Transactions on Graphics, vol. 9, no. 3, pp. 245 261, July 1990. [28] J. Wilhelms 
and A. Van Gelder, Octrees for faster isosurface generation, in Computer Graphics (San Diego Workshop 
on Volume Visualization), Nov. 1990, pp. 57 62. [29] J. Wilhelms and A. Van Gelder, Octrees for faster 
isosurface generation, ACM Transactions on Graphics, vol. 11, no. 3, pp. 201 227, July 1992. [30] Jane 
Wilhelms and Judy Challinger, Direct volume rendering of curvilinear volumes, in Computer Graphics (San 
Diego Workshop on Volume Visualization), Nov. 1990, pp. 41 47. [31] M. Garrity, Ray Tracing Irregular 
Volume Data, in 1990 Workshop on Volume Visualization, 1990, pp. 35 40, San Diego. [32] Claudio Silva, 
Joseph S. B. Mitchell, and Arie E. Kaufman, Fast rendering of irregular grids, in 1996 Volume Visualization 
Symposium. IEEE, Oct. 1996, pp. 15 22, ISBN 0-89791-741-3. [33] C. E. Prakash and S. Manohar, Volume 
rendering of unstructured grids a voxelization approach, Computers &#38; Graphics, vol. 19, no. 5, pp. 
711 726, Sept. 1995, ISSN 0097-8493. [34] Michael B. Cox and David Ellsworth, Application-controlled 
demand paging for Out-of-Core visualization, in Proceedings of Visualization 97, October 1997, pp. 235 
244. [35] James Arvo and David Kirk, A survey of ray tracing acceleration techniques, in An Introduction 
to Ray Tracing, Andrew S. Glassner, Ed. Academic Press, San Diego, CA, 1989. [36] David Jevans and Brian 
Wyvill, Adaptive voxel subdivision for ray tracing, in Proceedings of Graphics Interface 89, June 1989, 
pp. 164 172. [37] Kryzsztof S. Klimansezewski and Thomas W. Sederberg, Faster ray tracing using adaptive 
grids, IEEE Computer Graphics &#38; Applications,vol. 17, no. 1, pp. 42 51, Jan.-Feb. 1997, ISSN 0272-1716. 
[38] Al Globus, Octree optimization, Tech. Rep. RNR-90-011, NASA Ames Research Center, July 1990. [39] 
Greg Nielson and Bernd Hamann, The asymptotic decider: Resolving the ambiguity in marching cubes, in 
Proceedings of Visualization 91, October 1991, pp. 83 91. [40] National Library of Medicine (U.S.) Board 
of Regents, Electronic imaging: Report of the board of regents. u.s. department of health and human 
services, public health service, national institutes of health, NIH Publication 90-2197, 1990. [41] 
Bill Lorensen, Marching through the visible woman, http://www.crd.ge.com/cgi-bin/vw.pl, 1997. [42] Y 
Livnat, H. Shen, and C. R. Johnson, A near optimal isosurface extraction algorithm using the span space, 
IEEE Trans. Vis. Comp. Graphics, vol. 2, no. 1, pp. 73 84, 1996. [43] M.L. Brady, K.K. Jung, H.T. Nguyen, 
and T.PQ. Nguyen, Interactive Volume Navigation, IEEE Transactions on Visualization and Computer Graphics, 
vol. 4, no. 3, pp. 243 256, July 1998. [44] Jochen Schwarze, Cubic and quartic roots, in Graphics Gems, 
Andrew Glassner, Ed., pp. 404 407. Academic Press, San Diego, 1990. Steven Parker is a research scientist 
in the Department of Computer Science at the University of Utah. His research focuses on problem solving 
environments, which tie together scienti.c computing, scienti.c visualization, and computer graphics. 
He is the principal architect of the SCIRun Software System, which formed the core of his Ph.D. dissertation. 
He was a recipient of the Computational Science Graduate Fellowship from the Department of Energy. He 
received a B.S. in Electrical Engineering from the University of Oklahoma in 1992. Michael Parker Michael 
Parker is a Ph.D. student in Computer Science at the University of Utah. He is interested in Computer 
Architecture and VLSI Design. He has recently concluded his work on a project to reduce communication 
latency and overhead in clusters of workstations. He is currently involved in the architecture of an 
adaptable memory controller. His dissertation deals with reducing I/O and communication overhead and 
latency. He received a B.S. in Electrical Engineering from the University of Oklahoma in 1995. Yarden 
Livnat is a Research Associate at the Department of Computer Science at the University of Utah. working 
with the Scienti.c Computing and Imaging Research Group. Yarden received a B.Sc. in computer science 
in 1982 from Ben Gurion University Israel and an M.Sc. cum laude in computer science from the Hebrew 
University, Israel in 1991. He will receive his Ph.D from the University of Utah in 1999. His research 
interests include computational geometry, scienti.c computation and visualization and computer generated 
holograms. Peter-Pike Sloan has recently joined the Graphics Research group at Microsoft as a Research 
SDE. He previously was a student at the University of Utah and worked in the Scienti.c Computing and 
Imaging group for Chris Johnson. He has also previously worked on a 3D Painting product at Parametric 
Technology in Salt Lake City. His interests span the spectrum of computer graphics, and most recently 
has been working/dabbling in the areas of interactive techniques, image-based rendering, surface parameterizations, 
and non-photorealistic rendering. Charles Hansen is an Associate Professor of Computer Science at the 
University of Utah. From 1989 to 1997, he was a Research Associate Professor of Computer Science at Utah. 
From 1989 to 1997, he was a Technical Staff Member in the Advanced Computing Laboratory (ACL) located 
at Los Alamos National Laboratory where he formed and directed the visualization efforts in the ACL. 
His research interests include large-scale scienti.c visualization, massively parallel processing, parallel 
computer graphics algorithms, 3D shape representation, and computer vision. He received a B.S. in Computer 
Science from Memphis State University in 1981 and a Ph.D. in Computer Science from the University of 
Utah in 1987. He was a Bourse de Chateaubriand PostDoc Fellow at INRIA, in 1987 and 1988. Peter Shirley 
is an Assistant Professor of Computer Science at the University of Utah. From 1994 to 1996 he was a Visiting 
Assistant Professor at the Cornell Program of Computer Graphics. From 1990 to 1994 he was an Assistant 
Professor of Computer Science at Indiana University. His research interests include visualization, realistic 
rendering, and application of visual perception research in computer graphics. He received a B.A. in 
Physics from Reed College in 1984 and a Ph.D. in Computer Science from the University of Illinois at 
Urbana/Champaign in 1991.  
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198755</article_id>
		<sort_key>16</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[Rendering massive models]]></title>
		<page_from>16</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198755</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198755</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40024383</person_id>
				<author_profile_id><![CDATA[81100159926]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Philipp]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Slusallek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Saarland University, Saarbr&#252;cken, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39043298</person_id>
				<author_profile_id><![CDATA[81100449948]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shirley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35035889</person_id>
				<author_profile_id><![CDATA[81547494456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mark]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Texas at Austin, Austin, TX]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39031627</person_id>
				<author_profile_id><![CDATA[81100189931]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Gordon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stoll]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Intel Corporation, Santa Clara, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40030613</person_id>
				<author_profile_id><![CDATA[81100041422]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Ingo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wald]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Max-Planck-Institut f&#252;r Informatik, Saarbr&#252;cken, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
    P r e v i o u s W o r k S h a r e d M e m o r y C o m p u t e r  Parker et al. (U. Utah, 1999) 
 Large shared memory machine  All distribution issues hidden by OS Caching &#38; demand loading  Simply 
works   P r e v i o u s W o r k M e m o r y C o h e r e n t R T ( 1 9 9 7 )  Accumulates rays in 
voxel grid Loads required geometry on demand into cache  Forwards rays to neighboring voxels &#38; 
reorder  Supports incoherent rays (path tracing)  Requires 1/10th the memory  P r e v i o u s W o 
r k D a t a P a r a l l e l R a y T r a c i n g   Spatial Subdivided Geometry  Distribute subsets 
of geometry to clients  Forward rays between clients as necessary  Leads to bad load balancing &#38; 
high bandwidth   Random Geometry Distribution (Kilauea)  Rays are replicated to all clients and traced 
in parallel  Wasted computation: no occlusion culling   B r i c k B a s e d A p p r o a c h   Observations: 
 Reordering has high cost (managing lists of rays)  Working sets usually fits in memory   Approach 
 Cache geometry in bricks (sub trees of kd tree)  2 level kd tree: leafs in top tree point to cache 
lines (bricks)  Each brick is separate file (gets memory mapped)   Load data on demand across network 
 Reorder computation by multi threading    B r i c k B a s e d A p p r o a c h  Algorithm [Wald 
2001] Normal ray packet traversal through top tree  At leaf node check cache status (1 flag)  Cache 
miss:  Put ray packet in hold queue  Schedule demand load operation (asynchronous)  Fetch new ray 
packet from run queue   Fetcher thread:   Load brick, move ray packet to run queue B r i c k B a 
s e d A p p r o a c h  Discussion  Works best for coherent rays &#38; small working set  Reorder 
only when necessary  Cache reuse: Second chance Mark all nodes for eviction, evict when not used after 
a while  Must be able to load data within one frame   Results  Powerplant: 12.5 MTri, several GB 
on disk (2001!) Rendered on 5 7 PCs w/ 200 400MB geometry cache  O u t - O f - C o r e R a y T r a 
c i n g   Data Management is the issue  Test: Runs perfectly fine on SunFire w/ 96GB RAM  But target 
PCs have less than 2 GB RAM   Observations:  Changes in working set are large  Cannot be loaded 
during rendering a frame  Want to reuse as much as possible   Async. Loading, caching, streaming, 
preprocessing, O u t - O f - C o r e R a y T r a c i n g  New approach  Detect (and avoid) potential 
page faults by MMU  Keep track of what data is currently in memory   Difference to Brick approach 
 Work on OS pages, not on voxel files Uniform caching domain (all data is handled in same way)^^  
Do not reorder rays (latency too large)   Instead: Kill off ray &#38; replace by proxy information 
      S u m m a r y   Ray tracing based MMR  Powerful yet relatively simple approach  Boeing: 
350 MTris on single PC @ 2-3 fps  Outdoor scenes with billions of triangles and global environment lighting 
  But: Still a lot to do  Models are getting bigger (3-5x for Boeing 787)  Still many unsolved problems 
   O p e n I s s u e s  Efficient geometric anti-aliasing  More triangles more detail/pixel aliasing 
 LOD versus super-sampling versus   Efficient multi-resolution approach Better proxies for missing 
data  Better parallelization  Data dependent assignment of tiles to clients  
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198756</article_id>
		<sort_key>17</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[An interactive out-of-core rendering framework for visualizing massively complex models]]></title>
		<page_from>17</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198756</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198756</url>
		<abstract>
			<par><![CDATA[With the tremendous advances in both hardware capabilities and rendering algorithms, rendering performance is steadily increasing. Even consumer graphics hardware can render many million triangles per second. However, scene complexity seems to be rising even faster than rendering performance, with no end to even more complex models in sight.In this paper, we are targeting the interactive visualization of the "Boeing 777" model, a highly complex model of 350 million individual triangles, which - due to its sheer size and complex internal structure - simply cannot be handled satisfactorily by today's techniques. To render this model, we use a combination of real-time ray tracing, a low-level out of core caching and demand loading strategy, and a hierarchical, hybrid volumetric/lightfield-like approximation scheme for representing not-yet-loaded geometry. With this approach, we are able to render the full 777 model at several frames per second even on a single commodity desktop PC.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[complex models]]></kw>
			<kw><![CDATA[distributed computing]]></kw>
			<kw><![CDATA[out-of-core rendering]]></kw>
			<kw><![CDATA[ray tracing]]></kw>
			<kw><![CDATA[real-time rendering]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP40031744</person_id>
				<author_profile_id><![CDATA[81100041422]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ingo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wald]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MPI Informatik, Saarbr cken, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40024006</person_id>
				<author_profile_id><![CDATA[81100128205]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Andreas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dietrich]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Saarland University, Saarbr cken, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40024383</person_id>
				<author_profile_id><![CDATA[81100159926]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Philipp]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Slusallek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Saarland University, Saarbr cken, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>300554</ref_obj_id>
				<ref_obj_pid>300523</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{ACW 99} Aliaga D. G., Cohen J., Wilson A., Baker E., Zhang H., Erikson C., Hoff III K. E., Hudson T., St&#252;rzlinger W., Bastos R., Whitton M. C. Brooks Jr. F. P., Manocha D.: MMR: An Interactive Massive Model Rendering System using Geometric and Image-Based Acceleration. In ACM Symposium on Interactive 3D Graphics (1999), pp. 199 206.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{AMD03} AMD: AMD Opteron Processor Model 8 Data Sheet. http://www.amd.com/us-en/Processors, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>862735</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{BC02} Bovet D. P., Cesati M.: Understanding the Linux Kernel (2nd Edition). O'Reilly & Associates, 2002. ISBN 0-59600-213-0.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{BMH99} Bartz D., Meissner M., H&#252;ttner T.: OpenGL assisted Occlusion Culling for Large Polygonal Models. Computer and Graphics 23, 3 (1999), 667 679.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>581922</ref_obj_id>
				<ref_obj_pid>581896</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{BSGM02} Baxter III W. V., Sud A., Govindaraju N. K., Manocha D.: Gigawalk: Interactive Walkthrough of Complex Environments. In Rendering Techniques 2002 (Proceedings of the 13th Eurographics Workshop on Rendering) (2002), pp. 203 214.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882318</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{BWG03} Bala K., Walter B., Greenberg D.: Combining Edges and Points for Interactive High-Quality Rendering. ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH) (2003), 631--640.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>581903</ref_obj_id>
				<ref_obj_pid>581896</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{CH02} Coconu L., Hege H.-C.: Hardware-Accelerated Point-Based Rendering of Complex Scenes. In Proceedings of the 13th Eurographics Workshop on Rendering (2002), Eurographics Association, pp. 43 52.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1081409</ref_obj_id>
				<ref_obj_pid>1081407</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{CKS03} Correa W., Koslowski J. T., Silva C.: Visibility-Based Prefetching for Interactive Out-Of-Core Rendering. In Proceedings of Parallel Graphics and Visualization (PGV) (2003), pp. 1 8.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{CMS98} Cignioni P., Montani C., Scopignio R.: A Comparison of Mesh Simplification Algorithms. Computers and Graphics 22, 1 (1998), 37 54.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2386119</ref_obj_id>
				<ref_obj_pid>2386103</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{DGP04} DeMarle D. E., Gribble C., Parker S.: Memory-Savvy Distributed Interactive Ray Tracing. In Eurographics Symposium on Parallel Graphics and Visualization (2004). To appear.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1081419</ref_obj_id>
				<ref_obj_pid>1081407</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{DPH 03} DeMarle D. E., Parker S., Hartner M., Gribble C., Hansen C.: Distributed Interactive Ray Tracing for Large Volume Visualization. In Proceedings of the IEEE Symposium on Parallel and Large-Data Visualization and Graphics (PVG) (2003), pp. 87 94.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166147</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{GKM93} Greene N., Kass M., Miller G.: Hierarchical Z-Buffer Visibility. In Computer Graphics (Proceedings of ACM SIGGRAPH) (August 1993), pp. 231 238.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882299</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{GLY 03} Govindaraju N. K., Lloyd B., Yoon S.-E., Sud A., Manocha D.: Interactive Shadow Generation in Complex Environments. ACM Transaction on Graphics (Proceedings of ACM SIGGRAPH) 22, 3 (2003), 501 510.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{Hav99} Havran V.: Analysis of Cache Sensitive Representation for Binary Space Partitioning Trees. Informatica 23, 3 (May 1999), 203 210. ISSN: 0350-5596.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{Hav01} Havran V.: Heuristic Ray Shooting Algorithms. PhD thesis, Faculty of Electrical Engineering, Czech Technical University in Prague, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{Int02} Intel Corp.: Intel Pentium III Streaming SIMD Extensions. http://developer.intel.com, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237199</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[{LH96} Levoy M., Hanrahan P.: Light field rendering. In Proceedings of the 23rd Annual Conference on Computer Graphics and Interactive Techniques (ACM SIGGRAPH) (1996), pp. 31 42.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>130653</ref_obj_id>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[{Nie92} Niederreiter H.: Random Number Generation and Quasi-Monte Carlo Methods. Society for Industrial and Applied Mathematics, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258791</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[{PKGH97} Pharr M., Kolb C., Gershbein R., Hanrahan P.: Rendering Complex Scenes with Memory-Coherent Ray Tracing. Computer Graphics 31, Annual Conference Series (Aug. 1997), 101 108.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344936</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[{PZvBG00} Pfister H., Zwicker M., van Baar J., Gross M.: Surfels: Surface elements as rendering primitives. In Proc. of ACM SIGGRAPH (2000), pp. 335 342.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344940</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[{RL00} Rusinkiewicz S., Levoy M.: QSplat: A Multiresolution Point Rendering System for Large Meshes. In Proc. of ACM SIGGRAPH (2000), pp. 343 352.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[{SDB97} Sillion F., Drettakis G., Bedelet B.: Efficient Imposter manipulation for Real-Time Visualization of Urban Scenery. Computer Graphics Forum, 16, 3 (1997), 207 218. (Proceeding of Eurographics).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[{Wal04} WALD I.: Realtime Ray Tracing and Interactive Global Illumination. PhD thesis, Computer Graphics Group, Saarland University, 2004. Available at http://www.mpi-sb.mpg.de/~wald/PhD/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383819</ref_obj_id>
				<ref_obj_pid>2383815</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[{WDP99} Walter B., Drettakis G., Parker S.: Interactive Rendering using the Render Cache. In Rendering Techniques 1999 (Proceedings of Eurographics Workshop on Rendering) (1999).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383299</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[{WFP 01} Wand M., Fischer M., Peter I., auf der Heide F. M., Strasser W.: The Randomized z-Buffer Algorithm: Interactive Rendering of Highly Complex Scenes. In Proc of ACM SIGGRAPH (2001), pp. 361 370.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>337722</ref_obj_id>
				<ref_obj_pid>337680</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[{WS99} Ward G., Simmons M.: The Holodeck Ray Cache: An Interactive Rendering System for Global Illumination in Nondiffuse Environments. ACM Transactions on Graphics 18, 4 (Oct. 1999), 361 398.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732298</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[{WSB01} Wald I., Slusallek P., Benthin C.: Interactive Distributed Ray Tracing of Highly Complex Models. In Rendering Techniques (2001), pp. 274 285. (Proceedings of Eurographics Workshop on Rendering).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[{WSBW01} Wald I., Slusallek P., Benthin C., Wagner M.: Interactive Rendering with Coherent Ray Tracing. Computer Graphics Forum 20, 3 (2001), 153 164. (Proceedings of Eurographics).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>760610</ref_obj_id>
				<ref_obj_pid>647652</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[{WWS00} Wonka P., Wimmer M., Schmalstieg D.: Visibility Preprocessing with Occluder Fusion for Urban Walkthroughs. In Rendering Techniques (2000), pp. 71 82. (Proceedings of Eurographics Workshop on Rendering).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258781</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[{ZMHH97} Zhang H., Manocha D., Hudson T., Hoff III K. E.: Visibility Culling using Hierarchical Occlusion Maps. Computer Graphics 31, Annual Conference Series (1997), 77 88.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Eurographics Symposium on Rendering (2004) H. W. Jensen, A. Keller (Editors) An Interactive Out-of-Core 
Rendering Framework for Visualizing Massively Complex Models Ingo Wald , Andreas Dietrich , and Phlipp 
Slusallek MPI Informatik, Saarbrcken, Germany, Saarland University, Saarbrcken, Germany wald@mpi-sb.mpg.de 
{dietrich,slusallek}@cs.uni-sb.de Figure 1: The Boeing 777 model containing 350 million triangles. a.) 
Overview over the entire model, including shadows. b.) Zoom into the engine, showing intricately interweaved, 
complex geometry. c.) The same as b.), but zooming in even closer. All of the individual parts of the 
entire plane are modeled at this level of complexity. d.) The cockpit, including shadows. Using our out-of-core 
visualization scheme, all of these frames can be rendered interactively at 3 7 frames per second on a 
single desktop PC. Abstract With the tremendous advances in both hardware capabilities and rendering 
algorithms, rendering performance is steadily increasing. Even consumer graphics hardware can render 
many million triangles per second. However, scene complexity seems to be rising even faster than rendering 
performance, with no end to even more complex models in sight. In this paper, we are targeting the interactive 
visualization of the Boeing 777 model, a highly complex model of 350 million individual triangles, which 
 due to its sheer size and complex internal structure simply cannot be handled satisfactorily by today 
s techniques. To render this model, we use a combination of real-time ray tracing, a low-level out of 
core caching and demand loading strategy, and a hierarchical, hybrid volumetric/light.eld-like approximation 
scheme for representing not-yet-loaded geometry. With this approach, we are able to render the full 777 
model at several frames per second even on a single commodity desktop PC. Keywords: Real-time rendering, 
out-of-core rendering, complex models, distributed computing, ray tracing Categories and Subject Descriptors 
(according to ACM CCS): I.3.7 [Computer Graphics]: Ray tracing I.6.3 [Simulation and Modeling]: Applications 
I.3.2 [Computer Graphics]: Distributed/network graphics 1. Introduction For many years now, the performance 
of commodity CPUs has increased at a rate of a factor of two roughly every 18 months. At least in the 
last few years, the performance of graphics hardware has grown even faster, having led to commodity 
graphics hardware that can render up to several million triangles per second. In addition to this free 
increase in rendering performance, we also see a steady improvement in rendering algorithms. With all 
this taken together, the model complexity that is affordable at interactive rates is constantly and rapidly 
increasing. &#38;#169; The Eurographics Association 2004. Unfortunately, the complexity of practical 
models seems to be rising even faster: First of all, users of modeling systems (and game designers as 
well) tend to immediately spend every grain of increased performance into even more detail, i.e. into 
more triangles. Additionally, virtual prototyping is becoming increasingly important and hardwired into 
the design process. Traditionally, virtual reality has been but loosely coupled to the actual design 
process, and has merely visualized semi-manually prepared (i.e. simpli.ed) versions of the CAD models. 
With VR getting increasingly involved into the production pro  Figure 2: Some example closeups of the 
777, to show the high geometric complexity, small degree of occlusion, and complex topological structure 
of the model, which make it complicated for most simpli.cation/approximation-based approaches. a.) Zoom 
onto a small object of roughly one cubic foot in size, showing each individual nut and bolt modeled with 
hundreds of badly-shaped triangles. Multiple surfaces with different materials overlap themselves, as 
can be seen e.g. on the mixed white/blue-patched structure. Due to the randomly jittered vertex positions 
(introduced to prevent data theft), such structures self-intersect with each other randomly. b.) The 
same view from a few meters away. The left image corresponds to the red rectangle in the middle. c.) 
&#38; d.) The same for a view into the engine. Note how much detail is visible in that view, and how 
the many pipes and cables are intricately interweaved. The low degree of occlusion is also demonstrated 
in Figure 3. cess, there is a growing need to render models directly out of the database , i.e. without 
any model preparation and simpli.cation. Such CAD datasets, however, can be quite complex. Furthermore, 
the increased use of collaborative engineering for large-scale industrial projects leads to models consisting 
of hundreds and thousands of individual parts (potentially created by different suppliers), each of 
which modeled at whatever complexity and accuracy has been affordable for that individual part. In practice, 
this often means that each individual nut and bolt of a model (also see Figures 1 3) is represented in 
full geometric detail. Taken together, these developments lead to a growth in model complexity that seems 
to be at least as fast as the growth in hardware resources. An end to these developments currently is 
not foreseeable. In this paper, we are targeting the interactive visualization of the Boeing 777 model, 
a model consisting of roughly 350 million individual triangles, i.e. without using instantiation to 
generate this triangle count. Just the raw input data of that model ships in compressed form on a total 
of eleven CDs. After unpacking and storing each triangle as a triple of three .oats without any additional 
acceleration data, the model is 12 GByte in size, and requires several minutes just for reading it from 
disk. For this kind of model complexity, generating frame rates of several frames per second is quite 
challenging for contemporary massive model rendering approaches. 1.1. Outline In the remainder of this 
paper, we will .rst discuss relevant related work regarding rendering complex models in Section 2, and 
will particularly discuss their problems in handling a model of the size, topological structure, and 
complexity of the 777. Based on this discussion, we will then develop and describe our new approach 
to such models: After giving an overview of our system in Section 3, we will then describe the caching 
and demand loading subsystem in Section 4, and our hierarchical approximation scheme for not-yet-loaded 
geometry in Section 5. Section 6 then summarizes some results of using our framework for rendering the 
full 777 model on a single dual-1.8 GHz AMD Opteron desktop PC with 6 GB RAM. Finally, Section 7 concludes 
and ends with an outlook on future work.  2. Previous Work Due to the practical and industrial importance 
of rendering complex datasets, there exists a vast suite of different approaches to this problem. However, 
many of these techniques perform well only for speci.c kinds of models, but prove problematic for others. 
Brute-Force Rendering. Obviously, a model of the size of the 777 cannot be handled by a pure brute-force 
approach. In theory, the most up-to-date graphics hardware (e.g. an NVIDIA Quadro FX 4000) features a 
theoretical peak performance of 133 million shaded and lit triangles per second, and could thus raster 
the full model in only a few seconds. Unfortunately, the practical performance usually is much lower, 
in particular for models that do not .t into graphics card memory. Thus, typical approaches to rendering 
complex datasets rely on reducing the number of triangles to be sent to the graphics card. Culling Techniques. 
Typical approaches like view-frustum culling are quite limited for a model of as high a depth complexity 
as the 777. Depth complexity can only be handled by taking occlusion into account. At least for 2D or 
2 12 D scenes (e.g. urban walkthroughs), occlusion can be conservatively precomputed quite well [WWS00]. 
In three dimensions, in particular with as few occlusion as in the 777 (see Figures 2 and 3), visibility 
preprocessing is quite problematic [ACW* 99]. Instead of precomputing visibility, the alternative is 
to use a hierarchical visibility culling mechanism, e.g. the hierarchical z-buffer [GKM93], possibly 
implemented via OpenGL occlusion queries [BMH99]. However, neither of these approaches has been designed 
for handling gigabytesized models that do not even .t into main memory. Recently, Correa et al. [CKS03] 
have proposed a visibilitybased out-of-core rendering framework that can also cope with models larger 
than memory. However, even if visibilitybased approaches would achieve perfect culling, for many views 
the low degree of occlusion in the 777 still results in millions of potentially visible triangles. To 
handle this case, the randomized z-buffer algorithm [WFP* 01] randomly selects one triangle out of the 
many triangles that project onto a pixel. This, however, works only for scenes in which it does not actually 
matter which of the triangles is chosen, e.g. for picking one of the thousands of leaves of a tree. For 
the 777 the exact ordering and mutual occlusion of even very close-by triangles is quite important. For 
example, in order to avoid the small yellow pipes shining through the green hull to which they are attached. 
Finally, like all the previously mentioned techniques, the randomized z-buffer is not designed for handling 
models that do not even .t into memory. Model Simpli.cation. As pure visibility culling even theoretically 
is not enough, many approaches try to reduce the model by some form of mesh simpli.cation, e.g. via 
edge contraction, vertex removal, or remeshing (see e.g. [CMS98]), often requiring some form of wellbehaving 
geometry. Typically, these methods perform best for highly tessellated surfaces that are otherwise relatively 
smooth, .at, and topologically simple. In the 777 the triangles actually form many detailed, loosely 
connected though interweaving parts of complex topological structure, such as mazes of tubes, pipes, 
and cables (see Figures 2 and 3). Such kinds of geometry are very hard to simplify effectively in a robust 
manner. Moreover, each part of the 777 comes in a soup of unconnected triangles, without any connectivity 
information, often forming self-intersecting and overlapping surfaces (see Figure 3: In comparison to 
most other massive models, the 777 has a much lower degree of occlusion. a.) Zoom onto the front part 
of the model, where the rays penetrate deeply into the model. b.) Closeup of the geometry that can be 
seen through the ribs of the plane. &#38;#169; The Eurographics Association 2004. Figure 2a) with different 
material properties. Even worse, the vertex positions have been slightly jittered to prevent public spreading 
of the sensitive original CAD data. Thus, overlapping surfaces are not perfectly aligned, but rather 
randomly intersect each other multiple times. For such kinds of input data, most geometrically based 
algorithms are likely to fail. As each individual technique usually has a weak point, the UNC s MMR/Gigawalk 
system [ACW* 99, BSGM02, GLY* 03] is based on a combination of different techniques, combining mesh 
simpli.cation, visibility preprocessing, impostors [SDB97], textured depth meshes, and hierarchical occlusion 
maps [ZMHH97]. However, as just discussed each of these individual parts is problematic in the 777. This 
raises the question whether a combination of these techniques can still succeed in each technique masking 
the shortcomings of the other. Image-based and Point-based Approaches. In addition to these traditional 
methods, researchers have also looked into image-based and point-based approaches. For example, the 
Holodeck [WS99], Render Cache [WDP99], and Edge-and-Point-Image [BWG03] progressively sample the model 
asynchronously to displaying it, and interactively reconstruct the image from these sparse samples. 
In principle, both approaches might be applicable to the 777. However, the rays traced by these systems 
are likely to cause signi.cant paging, resulting in prohibitively long times for generating enough 
image samples. This is likely to result in severe subsampling, and in strong visual artifacts. As yet 
another alternative, researchers have proposed to represent models using point samples (see e.g. [CH02, 
PZvBG00]). Though this decouples geometric complexity from display complexity, the sparse number of samples 
often limits the detail that is present in the reconstructed image. To avoid this problem, QSplat [RL00] 
employs a hierarchical scheme in which the entire mesh is represented by at least one sample per triangle. 
However, its hierarchical approximation scheme assumes that nearby triangles can, if seen from a distance, 
be well approximated by a disk-shaped splat with .ltered color and normal information. Like mesh simpli.cation, 
this works only for relatively smooth and topologically simple surfaces, and is likely to fail for the 
geometrical structure of the 777 as described above. Interactive Ray Tracing. Finally, complex models 
can also be visualized using interactive ray tracing. Due to its logarithmic dependence on scene complexity, 
ray tracing can easily handle even highly complex scenes of several million triangles at full detail. 
For example, the OpenRT realtime ray tracing system [Wal04] has been shown to interactively render 
the one billion triangle Sun.owers scene even including shadows, semi-transparent leaves, and moving 
geometry. However, this has only been possible through instantiation, i.e. by reusing the same kind of 
sun.ower several thousand times, therefore being able to keep the entire model in main memory. For the 
777 model, we simply cannot store the entire dataset which occupies 30 40 GByte including acceleration 
structures in main memory. Once the operating system starts to generate the inevitable page faults the 
ray tracer would run idle while waiting for data, and could not maintain interactivity. In order to 
solve that problem, Pharr et al. [PKGH97] have proposed a caching and reordering scheme that reorders 
the rays in a way that minimizes disk I/O. Though this allows for ef.ciently ray tracing models that 
are much larger than main memory, the approach is not easily applicable to interactive rendering. A 
simpli.ed version of this scheme has also been used by Wald et al. [WSB01]. They have proposed to suspend 
rays that would cause a page fault and load the required data asynchronously over the network while tracing 
other rays in the meantime. The stalled rays then get resumed once the data is available. Though that 
approach worked well for the target model (the 12.5 million triangle UNC Power Plant), it fails in interactively 
rendering a model as complex as the 777: The proposed suspend/resume approach can hide the loading latency 
only within the duration of one frame. In the 777, however, even a small camera change often triggers 
thousands of disk read requests that simply cannot be ful.lled within a single frame. Though prefetching 
(in the sense of e.g. [CKS03]) would help, it can hide loading latencies only to a limited degree. Furthermore, 
their demand loading scheme was based on splitting the model into voxels of several thousand triangles, 
which were then loaded and discarded as required. This caching granularity is far too large for our purposes, 
as each individual ray may cause loading another of these voxels. Additionally, this method is prone 
to memory fragmentation, and carries a certain overhead for managing the data (also see the discussion 
in [DGP04]).  3. An Out-of-Core Framework for Interactively Rendering Massively Complex Models As shown 
by the discussion in the previous section, contemporary techniques to handle massive models cannot easily 
cope with a model of the size, structure, and complexity of the 777. Thus, a new approach had to be taken. 
Since ray tracing can in principle handle such massive amounts of geometry, in a .rst experiment we ported 
the OpenRT ray tracer to a shared-memory architecture, and experimented with rendering the 777 on 16 
UltraSPARC III CPUs in a SUN Sun Fire 11K with 180 GB RAM. This allowed for storing the model including 
pre-built BSP data into the RAM disk, making it possible to load the entire scene within a few seconds, 
and to interactively inspect it at several frames per second, even including shadows. With these successful 
experiments, we started designing an architecture that could deliver similar performance even on a commodity 
PC. In order to be able to at least address the entire model, we decided to build on AMD s 64-bit Opteron 
CPUs [AMD03], which have recently become available in commodity desktop systems. Compared to e.g. the 
Intel Itanium CPU, the Opteron also supports the IA32 SSE Instruction set [Int02], and thus can exploit 
also those traversal and intersection routines of OpenRT that have been speci.cally optimized towards 
SSE [WSBW01, Wal04]. This support for using SSE instructions together with a nominally higher clock 
rate allow the Opteron to easily outpace the UltraSPARC III. Instead of having to use many CPUs in a 
Sun Fire, we can achieve similar performance on a single dual-CPU Opteron PC. Unfortunately, having a 
64-bit address space allows for addressing the entire model, but cannot help the fact that we still are 
not able to keep it entirely in memory. We therefore decided to follow the approach of Wald et al. [WSB01], 
and use a combination of manual memory management and demand loading in order to detect and avoid page 
faults due to access to out-of-core memory. As discussed in the previous section, however, their approach 
had several shortcomings with respect to a 777-class model, mainly with respect to the design and implementation 
of the memory management scheme. Most importantly, their system has mainly been designed for hiding 
the scene access latency by suspending and resuming rays, which we have argued cannot work successfully 
for the 777. As a consequence, our framework builds on two pillars: First, on a new memory management 
scheme that has been redesigned from scratch. It avoids the fragmentation, caching granularity, and I/O 
problems of the original approach, and is thus much better suited for a 777-class model. Second, our 
approach does not even try to hide scene access latency, but instead kills off potentially page-faulting 
rays, which are then being replaced by shading information from so-called proxies . This is achieved 
by ef.ciently determining in advance accesses to parts of the BSP that may potentially lead to a page 
fault. Proxies are a pre-computed coarse yet appropriate approximate representation for the respective 
subtree. This proxy mechanism is similar to a hierarchical level-of-detail representation intermixed 
with the spatial index structure, and will be described in more detail in Section 5.  4. Memory Management 
As just motivated, a memory management scheme based on manually managing individual sub-parts of several 
thousand triangles is inappropriate for the 777 due to memory fragmentation, much too coarse cache granularity, 
and thus bad memory ef.ciency and high I/O cost. In contrast to this, the Linux/UNIX memory mapping facilities 
(mmap() [BC02]) provide a convenient way of addressing and demand loading memory on a per-page basis. 
In particular, it realizes c a uni.ed cache, i.e. it does not matter which data is contained in which 
physical page, and it never pages in any data (e.g. shading information) that might not be required. 
Leaving the memory management (MM) to the operating system greatly simpli.es the design, and improves 
the ef.ciency of the implementation: For example, manual memory management requires to take special 
care in order to avoid race conditions where one thread accesses data that is just being freed by another 
thread. If not avoided by costly synchronization via mutexes, such race conditions usually lead to program 
crashes. If a similar race condition happens in our OS-based MM scheme, the worst that can happen is 
a page fault, as the pointer to the not available memory region is still considered valid. Additionally, 
working on real pointers minimizes the address lookup overhead, as this is done automatically by the 
processor s hardware MMU, and do not cost precious CPU time (also see [DPH* 03]). Finally, using this 
scheme is quite simple: All one has to do to implement this scheme is to precompute all static data structures 
(e.g. BSP index structures etc.), store them on disk in binary form, and map them into the address space 
via mmap(). This preprocessing is done in an out-of-core approach similar to [WSB01]. 4.1. Detecting 
and Avoiding Page Faults Though an OS-based MM system has many advantages over manual caching, it also 
has a major drawback in that we lose control over what data is loaded into or discarded from memory 
at what time. Although data is automatically paged in on demand upon accessing it, the resulting page 
fault stalls the rendering thread until the data is available. To retain control over the caching process 
we implemented a hybrid memory management system, which uses the operating system to perform demand 
paging, but which detects and avoids potential page faults before they occur, and which manually steers 
page loading and eviction. In order to avoid page faults, we have to detect whether or not memory referenced 
by a pointer is actually in core memory. Though Linux for this purpose offers the mincore() function, 
performing an OS call on each memory access obviously is not affordable. When taking a closer look at 
the Linux memory mapping implementation, however, there are several important observations to be made: 
First, after having once loaded a page, it will stay in memory at least for a limited amount of time. 
Second, pages in memory will not be paged out as long as there is some unused memory available. Thus, 
as long as we know that there is some memory left, we can mark once-accessed pages, and can be (almost) 
sure that the respective page will still be in memory later on. Obviously, this only works as long as 
we do not try to page in more data than .ts into physical memory. Fortunately, this can be easily guaranteed: 
By using the Linux madvise() &#38;#169; The Eurographics Association 2004. call, we can force the kernel 
to free pages of our choice, thereby guaranteeing that some free memory is available at any time, and 
that no pages become unavailable without us knowing it. Of course, this assumes that no other processes 
start using up our memory. 4.2. The Tile Table In order to mark pages as either available or missing, 
we have to store at least one bit per page. Keeping an entry for each potential 4 KB page in a 64-bit 
address space would require 252 entries and is not affordable. Instead, one could use a hierarchical 
scheme as used by the processor s MMU, which however would be quite costly to access. We therefore group 
several pages into one tile and keep our tiles organized in a hash table of tile addresses. If the hash 
table is large enough to minimize hash collisions, hashing is quite ef.cient, and can be implemented 
with a few bit operations on the address pointer. Furthermore, a hash table is quite memory ef.cient: 
For hashing 128 GB RAM of 4 KB sized tiles (one page per tile) we only need 32M entries. Using a larger 
cache granularity of 16 KB or 64 KB, this reduces even more to 8M and 2M entries, respectively. If the 
size of the tile table is a power of two, all addressing and hashing operation can be performed ef.ciently 
by simple binary ands and shifts. Each tile table entry contains a 64-bit pointer with the virtual 
base address of the tile for detecting hashing collisions. The lower 12 16 bits of this entry are always 
zero, and can thus be used for other purposes, i.e. for marking whether the page is available (bit 0), 
and whether it has recently been referenced (bit 1). Thus, in order to check if a page is in memory, 
we simply have to .nd its entry in the tile table (one shift operation), validate there is no hash collision 
(one and), check bit 0 for availability (one more and), and, if required, set bit 1 (one or) to mark 
an access.  4.3. Tile Fetching In case we found a tile that is not marked as available, we cancel the 
respective ray and schedule the tile s address for asynchronous loading by putting it into a request 
queue. Once a tile is scheduled to be fetched, it will eventually be loaded by an asynchronous fetcher 
thread. In an in.nite loop, this thread in each iteration takes one request from the request queue, reads 
in the page via madvise(), and then marks the tile as available. Though reading the page obviously stalls 
the fetcher thread, the ray tracing threads are not affected at all, and remain busy. Note that we run 
several (4 8) fetcher threads in parallel, thereby allowing the OS to schedule multiple parallel disk 
requests as it deems appropriate. Fetch Prioritization. Missing data leads to cancellation of rays, 
so missing data that cancels many rays should be  overview engine wheels cockpit cabin Figure 4: Reference 
views for our experiments. From left to right: Overview over the whole model, a view into the engine, 
zoom onto the front wheels, the cockpit, and one of the main cabins. Using a single dual-CPU AMD Opteron 
1.8 GHz PC, these respective views can be rendered at 4.1, 2.9, 7.1, 3.1, and 3.2 frames per second at 
video resolution (640  480). fetched faster than data affecting only a single ray. Counting the actual 
accesses to a tile, however, is too costly, as it would require to coordinate the different write accesses 
to the shared counter. Instead, we observe that the number of affected rays is proportional to the size 
of the BSP voxel they are about to enter, and inversely proportional to its distance to the camera. 
We use this value for prioritizing fetch requests. To avoid searching for the most important requests, 
we map the priority to 8 discrete values, and keep one request queue for each of them. The fetchers 
then always take the .rst entry out of the queue with highest priority. This mapping is performed linearly, 
relative to the minimum and maximum priorities of the previous frame.  4.4. Tile Eviction As mentioned 
before, the tile fetcher can only fetch new tiles if some unused memory is available. Otherwise, the 
OS pages out tiles without us even noticing it (i.e. they are still being marked available). We therefore 
use the madvise() function to discard mapped pages from main memory. This obviously should be done only 
for pages that are likely not needed any longer. As a full least recently used strategy would be too 
expensive, we follow the same strategy as the Linux kernel swapper, and use a second chance strategy. 
The tile evictor slowly but continuously cycles through the tile table and resets the tile s referenced 
bit to zero (the page is still marked as present!). If the tile is still needed, this bit will soon be 
re-set by a rendering thread. If, however, the evictor visits a tile a second time with the R-bit still 
zero, it evicts the tile and marks it as missing. Similar to the Linux kernel swapper, tile eviction 
only starts once memory gets scarce, currently at a memory utilization of .80%. 4.5. Minimizing MM Overhead 
While the just described memory management is an integral part of our system, we have to keep its performance 
impact to an absolute minimum. In particular, we have to minimize the number of semaphore synchronization 
operations, which otherwise tend to block the rendering threads. Apart from the time consumed by the 
asynchronous fetcher and evictor threads, the main ray tracing threads have to constantly check each 
memory access for availability of the data. To minimize this overhead, we .rst check each pointer dereference 
for whether it crosses a tile boundary (with respect to the previous access). This can be done quite 
ef.ciently by simple bit operations, already reduces most of the tile table lookups, and does not require 
any costly semaphore operations. Even in the case that we have to access the tile table, we can often 
get away without having to perform locking operations: If the tile is marked as available, or is marked 
as already being fetched, we can immediately return. Though this can result in a race condition e.g. 
the evictor might evict the tile at exactly this moment this event is extremely improbable. Even if 
it occurs, in the worst case it can lead to either a single, improbable page fault, or to scheduling 
a tile twice for being loaded. Both cases are well tolerable even in the rare event that they occur. 
As such, there are only two cases where a ray tracing thread has to use a mutex. Once it adds a previously 
unvisited tile to the tile table, and every time it has to add a tile to the request queue. Both cases 
happen but relatively rarely. We also have to lock a mutex every time the tile fetcher or tile evictor 
want to modify the tile table or request queues. These threads, however, are not performance critical. 
  5. Geometry Proxies Using our MM scheme, we can ef.ciently detect and avoid any page fault of the 
ray tracing threads, and thus maintain interactivity and high performance at all times. Unfortunately 
cache misses are detected but shortly before the data is actually required. Thus, the ray that caused 
this page fault obviously cannot be traversed any further. As already discussed in Section 2, only suspending 
that ray until the data has been fetched will not work for a model of the 777 s complexity, as we simply 
cannot load thousands of tiles within a single frame. Hence, we have no other way but to accept the fact 
that there eventually will be pixels in a frame for which we cannot completely trace the necessary ray(s). 
Therefore, we have to decide on what color to assign to such pixels. Obviously, coloring these pixels 
in a .xed color (like red in Figure 5) results in large parts of the image being unrecognizable. c  
Figure 5: Approximation quality during startup time. Left: Immediately after startup. Right: after loading 
for a few seconds. Even then only a fraction of the model has been loaded. Top row: Without proxy information, 
by just marking canceled rays in red. Bottom row: Using our geometry proxies. While the proxy quality 
after startup is quite coarse, it suf.ces to navigate the model. As can be seen, without the proxies 
almost no pixel contains sensible information. Eventually all data will be loaded, with no artifacts 
left at all. Also note that the positive in.uence of the proxies can hardly be shown in a still image, 
and becomes fully apparent only while interactively navigating the model. Alternatively one could .ll 
in such a pixels color from the nearest valid sample, interpolate its color from several surrounding 
pixels, or even do sophisticated sparse sample reconstruction as done in e.g. the Render Cache [WDP99]. 
This approach however is quite problematic too: First, it requires costly (and badly parallelizable) 
post-.ltering of the rendered image, which is too costly for full-screen resolutions. More importantly 
however, even a slight change of camera position can result in large fractions of the image becoming 
invalid (see Figure 5): Though most of the required nodes in the upper BSP levels will be in memory, 
many of the subpixel-sized leaf voxels will not yet be available, and will result in killing off many 
pixels, even after the rays could be traced almost up to he .nal hitpoint. 5.1. Proxies for Missing 
Data For a cache miss however there are several important observation to be made: First, a cache miss 
can only be caused by a ray that wishes to traverse a speci.c subtree of the BSP that is not yet in memory. 
Such a subtree no matter how many nodes or triangles it contains is always a volume enclosed in an 
axis-aligned box. Furthermore, walkthrough applications tend to not change the view drastically, and 
similar views will touch similar data, particularly in the upper levels of the BSP tree. As such, going 
from one view to the next most of the upper-level BSP nodes will already be in mem &#38;#169; The Eurographics 
Association 2004. ory, and only small subtrees close to the leaves are likely to be missing. These subtrees 
fortunately are quite small, and, when projected, often smaller than a pixel. For such small voxels it 
often does not matter which triangle exactly is hit by the ray, as long as there is some kind of proxy 
that mimics the subtrees appearance. As a result, we have chosen to compute such a proxy for each potentially 
missing subtree. Note that this scheme is inherently hierarchical, as each proxy represents a subtree 
that in turn contains other subtrees and proxies. Moreover, this hierarchical approximation is tightly 
coupled to the BSP tree, and thus adapts well to the geometry. Number of Proxies. Before discussing how 
exactly we are going to represent our proxies, we .rst have to evaluate how many of them we actually 
need (in order to estimate the amount of memory we can spend on them), and how to ef.ciently .nd the 
proxies. As we want to use our proxies for hiding the visual impact of a cache miss, we obviously need 
a proxy for each potentially occurring cache miss. As already discussed above, cache misses can only 
happen when following pointers from a parent node to its children that are located in a different tile. 
Instead of building a proxy for each child, we only build a proxy for the parent node. More importantly, 
we change our BSP memory organization such that the number of pointers across tiles is minimized: Instead 
of storing BSP nodes in depth-.rst order [Wal04], we now use a scheme where we always .ll cache-tile 
sized memory regions in breadth-.rst order [Hav99], thereby combining nodes forming small subtrees 
in the same tile. Apart from having fewer tile-crossing pointers, this has the positive and visually 
notable side effect that the proxy distribution is more symmetric: In depth.rst order, the parents 
tile is usually .lled up with nodes of the left child s subtree, almost always yielding a potentially 
faulting pointer for the right son. This insymmetry results is visually displeasing images while not 
all data is loaded. granularity 16KB 64KB BSP number memory number memory deep 15.6M 1.2GB 4.3M 344MB 
shallow 833K 66MB 383K 30MB Table 1: Number of proxies with respect to cache granularity, and for two 
different BSP tree parameters. The deeper BSP generates somewhat faster performance (see Table 3), but 
requires more memory and many more proxies. For our experiments, we typically use the shallow BSP with 
16 KB tiles, resulting in less than 70 MB of proxy memory. However, using only 80 bytes per proxy (see 
below), even the deep BSPs are affordable when using 64 KB tiles, using 344 MB out of 6 GB RAM. Note 
that the deep BSPs are a worst-case con.guration. Obviously, the exact parameters with which the BSP 
was built in.uences the number of proxies. Deeper BSPs tend to achieve higher performance (see Table 
3), but unfortunately also have more potentially page-faulting subtrees (see Table 1). Note that we 
can also in.uence the number of proxies by adjusting the caching granularity, as we can also perform 
our caching on e.g. 16 KB or 64 KB tiles. A larger cache granularity results in less tiles, in less pointers 
crossing tile borders, and thus in less proxies (see Table 1). Due to their lower memory consumption, 
by default, we use the shallow BSPs with a cache granularity of 16 KB, resulting in roughly 1.1 million 
proxies for the 777 model.  5.2. Hybrid Volumetric/Light.eld-like Proxies As proxies, we have chosen 
a light.eld-like approach: As just argued, each proxy represents a volumetric subpart of the model, that 
will be viewed only from the outside, but from different directions. Thus, we only need to generate some 
meaningful shading information for each potentially incoming ray. This representation of discretized 
rays in fact is similar to a light.eld [LH96], except that we do not store readily shaded illumination 
samples in our proxy, but rather pre-.ltered shading information. In particular, we store the averaged 
material information (currently only a single diffuse 5+6+5 bit RGB value) and the averaged normal (discretized 
into 16 bits). As mentioned above such a proxy will usually be subpixel-sized, we ignore the spatial 
distribution of the incoming ray on the proxy s surface, and rather only consider its direction. To this 
end, we triangulate the sphere of potentially incoming directions around the proxy, and precompute average 
normal and material value for each vertex of this discretized sphere of directions. In case a canceled 
ray must use such a proxy, we then simply .nd the three nearest discretized directions with respect 
to the rays direction (i.e. the spherical triangle that contains this direction), compute the ray direction 
s barycentric coordinates with respect to its neighboring directions, and then interpolate the shading 
information from the data stored at these neighboring directions. As discretized directions, we currently 
use the triangulation given by once subdividing the Octahedron given by the +X,-X,+Y,-Y,+Z, and -Z axes, 
which results in 18 discretized directions: 6 directions along the major axes, and 12 directions halfway 
in-between two adjoining axes (i.e. (1,1,0),(1,0,1),...). This discretization has been chosen very carefully, 
as it allows for .nding the three nearest directions quite ef.ciently: The direction s three signs specify 
the octant of the spheres which has only 4 triangles. The coordinate with the maximum value then .xes 
the main axis, and leaves but two potential triangles, the one adjoining the axis, and the center triangle 
of the octant. By computing the four dot products between the ray and these triangles four vertices, 
the nearest three vertices and their barycentric coordinates can be easily and ef.ciently determined. 
The main problem with this approach is that averaging the normal tends to result in a normal that points 
more into the direction of the viewer than each individual normal. For example, looking symmetrically 
onto the edge of a box shows two sides facing the viewer in a 45-degree angle, but averaging the normals 
results in the averaged normal pointing towards the viewer. This effect leads to over-estimation of the 
cosine between normal and viewing direction and thus in overly bright proxies. By only considering directional 
information, a proxy will for each individual direction look like a simple, colored box. This obviously 
leads to artifacts if a proxy covers many pixels. As these proxies are fetched with higher priority 
such large blocks however appear rarely, and disappear quickly. For proxies of small projected size our 
representation is suf.cient and very compact. Alternatively, one could use a method in which this purely 
directional scheme is only used for small proxies, and proxies higher up in the BSP also get some positional 
information. So far however this scheme was not deemed necessary, and thus has not been implemented. 
 5.3. Discretization, Generation, and Reconstruction Though we have just argued that the actual hitpoint 
is not important as long as we have a solid approximation, it is important to note that occlusion has 
to be taken into account. Most proxies contain a signi.cant number of triangles, potentially with different 
materials and orientation. It often happens that a proxy contains e.g. lots of yellow cables being hidden 
behind a green metal part. In that case, just randomly picking a triangle is not appropriate, as it 
would lead to the proxy getting yellowish. We therefore compute the directional information by sampling 
the proxy with ray tracing. Rays are traced from the outside onto the object, and only triangles actually 
visible from that respective direction will contribute to the proxy s appearance in that direction. Each 
proxy is sampled by a certain number ( 10K) of random rays, whose hit information is stored within the 
proxy. To increase uniformity of the rays, we use Halton sequences [Nie92] for generating the rays. 
 5.4. Memory Overhead and Reconstruction Quality For obvious reasons, we can spend only a small amount 
of memory for our proxies: We want to use the proxies to hide page faults, and thus currently need all 
proxies in physical memory. Otherwise, we would only replace paging for BSP nodes by paging for proxies. 
On the other hand, we still need a signi.cant portion of main memory for our geometry cache, and cannot 
waste it on proxies. As mentioned above, we use a discretization of 18 directions for each proxy. At 
two 16-bit values per direction, each proxy consumes 72 bytes, plus a .oat for specifying its surface 
area (for prioritized loading), plus a 32-bit unique ID c specifying to which BSP subtree it belongs. 
In total, this requires a mere 80 bytes per proxy, or 66 344 megabytes for our two example con.gurations 
(shallow 16 KB, deep 64 KB). Addressing of Proxies. In case of a cache miss, we have to ef.ciently .nd 
the corresponding proxy. As we can t add any pointer to the respective BSP node at least not without 
changing the entire BSP structure of the ray tracer we simply use the parents address as a unique identi.er 
for the proxy, and use this address to index into an STL- map to .nd the proxy. Thus, we can implement 
our MM scheme without interfering at all with OpenRT s internal data structures, and can use the same 
data structures and algorithms as without our memory management unit (MMU). Note that we only build proxies 
only for BSP subtrees, and not for faulting triangles or shading data. For such page faults, we simply 
use the last proxy encountered during traversal, which represents the subtree that this faulting triangle 
is located in.  6. Results Once all the individual parts of our system are now together, we can start 
evaluating its performance. As target hardware platform, we have chosen a dual-processor 1.8 GHz AMD 
Opteron 246 system with 6 GB RAM, running SuSE 9.0 Linux with kernel 2.4.25. Though the machine is equipped 
with an NVIDIA graphics card, this card is only used for displaying the .nal image, and otherwise remains 
unused. For storing the model, the system uses a standard Western Digital WD2500JB IDE disk with a nominal 
throughput of roughly 50 55 MB/s. All of these parts are commodity PC parts, and the whole system costs 
is less than $5000. 6.1. Preprocessing As mentioned before, all preprocessing i.e. model splitting, 
BSP construction, and proxy computation is performed out of core. For this preprocessing, by default 
we stop subdividing at 2 4 million triangles per voxels. At this size the individual blocks conveniently 
.t into memory for BSP construction. BSPs that are built in core can be built with advanced BSP generation 
schemes using cost prediction functions [Hav01, Wal04], which results in higher rendering performance 
than for the typical split-in-the-middle strategy adopted while splitting the model. Depending on the 
actual BSP parameters, we need around 30 40 GB on disk for the preprocessed model. Preprocessing including 
unpacking, conversion, splitting, BSP generation, and proxy computation takes in the order of one day 
on a single PC, depending on the actual parameter values. Most of this time however is spent in BSP 
generation and proxy computation, which can be trivially parallelized by simply having N machines working 
on every Nth voxel &#38;#169; The Eurographics Association 2004. each. This allows for performing the 
entire preprocessing in less than a night. For example, in the course of writing this paper we have performed 
this preprocessing several times a day in order to experiment with different parameters. 6.2. Proxy 
Memory Overhead and Cache Con.guration From these experiments, we have picked two different con.gurations 
that represent a range of typical values. For one setting, we have chosen high-quality BSP trees of up 
to 60 levels of depth for each voxel generated during out-of-core preprocessing. This obviously results 
in many BSP nodes, roughly 40 GB on disk, and many proxies (see Table 1). In the other experiments, we 
have used rather shallow BSP trees, which use only 30 GB of disk space, and much less proxies. As mentioned 
before, we use a cache granularity of 64 KB for the deep BSPs, and 16 KB for the shallow BSPs, resulting 
in 66 MB and 344 MB for the proxies, respectively. With 6 GB of physical RAM, we can con.gure our cache 
size at 4 5 GB, with plenty of RAM left for the OS and for OpenRT runtime data. At this cache size, large 
parts of the model .t into the cache. In particular, each individual view .ts into cache, and the proxies 
only have to bridge the loading latencies when changing views.  6.3. Demand Loading Time and Approximation 
Quality After a complete restart of the entire system, our framework starts by parsing the list of voxel 
.les, creates the yet-empty containers for the voxels, and builds a top-level BSP for these voxels. All 
this takes at most a few seconds. It then reads in all the proxies, which takes several seconds to a 
few minutes, depending on the actual proxies data size. Once all proxies are read, the ray tracer immediately 
starts shooting rays, and uses the proxies while the data is being fetched asynchronously. Depending 
on how much data is required for loading the working set of a frame, it can take in the order of up to 
several minutes until all data is loaded. Some views require up to more than a gigabyte of data, which 
simply cannot be loaded from disk within a few seconds. The memory footprint and loading time for our 
reference views (see Figure 4) are given in Table 2. As a worst-case example, we have taken the overview 
viewpoint, in which the entire airplane is seen from a viewpoint with minimal occlusion and in which 
the rays travel deeply into all parts of the model . This view requires more than 2 gigabytes of data, 
and can take minutes to page in. While the approximation is rather coarse immediately after startup 
(see Figure 5), the structure of the model is already well recognizable after having loaded only a few 
percent of the data. Though this quality is far from perfect, it is totally suf.cient for navigating 
through the model while it is being loaded and re.ned simultaneously. Additionally, when zooming onto 
a speci.c part the data is usually fetched quite fast, and shows the part in full detail after only a 
few frames. Once a signi.cant portion of the model has been loaded, most of the geometry needed for 
rendering is already present in the cache. In particular, most of the upper levels of the BSP are already 
in the cache, and potential cache misses will typically affect only a few pixels. In that case, the proxies 
can do a good job at masking these isolated missing pixels. As our proxies were never designed to provide 
a high-quality hierarchical approximation, they ful.ll their planned task of providing solid feedback 
for interactive navigation. BSP/View overview engine wheels cockpit cabin deep 2,300 145 40 122 254 shallow 
2,150 215 36 105 236 Table 2: Memory footprint (in MB) for our reference views. As expected, some views 
require up to hundreds of megabytes. Particularly the intentionally chosen worst-case overview requires 
more than 2 GB, which can take minutes to load completely. Note however that we do not have to wait 
until all data is loaded, but can already navigate the proxy-approximation from the very .rst second. 
 6.4. Performance Overhead Obviously, our demand loading scheme will not come for free. Through aggressively 
minimizing the tile table lookups and mutex locks (see Section 4.5), we have reduced the overhead of 
our MM scheme to the bare minimum. Even so, a certain overhead remains. In particular, testing if a pointer 
crosses a tile boundary though it costs only a few bit tests has to be performed for each memory access 
even in the ray tracers inner traversal loop, and thus affects performance. Tile table access is less 
common, but unfortunately more costly, and thus affects performance, too. To determine the total overhead 
of our system, we have measured the frame rate for our reference views (see Figure 4), once using the 
standard OpenRT ray tracer without our MM scheme, and once with the MMU turned on. This experiment can 
be performed only for static views, as even small camera movements lead to long paging stalls if the 
MMU is turned off. To enable a fair comparison, for the MMU version we have measured the frame rate after 
all tiles have been paged in. This in fact is the worst-case scenario as rays have to be traversed quite 
deeply, and have to perform many checks and locks. Once some pixels get killed off i.e. during startup 
or when accessing previously invisible parts of the scene frame rate is rather higher than lower. As 
can be seen from Table 3, the total overhead for our example views consistently is in the range of 25% 
for the shallow BSPs, and 20% for the deep BSPs, respectively. Note that this includes the entire overhead, 
including pointer checking, tile lookups, threading, tile fetching, mutexes, etc. As our MM scheme enables 
us to navigate .uently without any paging stalls, we believe this overhead to be quite tolerable. BSP/View 
overview engine wheels cockpit cabin shallow BSPs w/o MMU 2.7 2.4 5.3 2.0 2.1 w/ MMU 1.9 1.8 4.0 1.5 
1.6 overhead 26% 25% 24% 25% 23% deep BSPs w/o MMU 4.9 3.6 9.0 4.0 4.0 w/ MMU 4.1 2.9 7.1 3.1 3.2 overhead 
16% 19% 21% 22% 20% Table 3: Total overhead of our memory management scheme for different views (see 
Figure 4), and for BSPs built with different cost parameters, measured in frames per second. As can 
be seen, total overhead is in the range of 25% for the shallow BSPs, and only 20% for the higher-performing 
deeper BSPs.  6.5. Overall System Performance With this small performance overhead, the ray tracer is 
quite ef.cient at rendering the model. As can be seen from Table 4, using a single dual-Opteron PC we 
achieve interactive frame rates of 3 7 fps at video resolution of 640  480 pixels. Even at full-screen 
resolution of 1280  1024, we still maintain frame rates of 1 2 fps. Such high resolutions are particularly 
important for getting a feeling of the relative orientation of the highly detailed geometry. While the 
just mentioned frame rates do not include antialiasing, supersampling can still be added progressively 
as soon as the camera stops moving. Also note that this performance data again corresponds to all data 
being present in the geometry cache. Upon cache misses and use of proxies, frame rates are even higher, 
as the rays perform less traversal steps. Thus, we can maintain these interactive frame rates at all 
times while navigating freely in and around the model. Resolution overview engine wheels cockpit cabin 
shallow BSPs 640x480 1.9 1.8 4.0 1.5 1.6 1280x1024 0.7 0.6 1.3 0.5 0.5 deep BSPs 640x480 4.1 2.9 7.1 
3.1 3.2 1280x1024 1.3 0.9 2.3 1.0 1.0 Table 4: System performance in frames per second on a single dual-1.8 
GHz Opteron, using our two con.gurations. c  6.6. Shading and Shadows In the course of the paper, we 
have only concentrated on the memory management scheme and proxy mechanism, and so far have neglected 
secondary rays and shading at all. Of course, using a ray tracer allows for also computing shadows and 
re.ections. Without sensible material data (which is not included in the 777 model), and in particular 
with the randomly jittered vertex positions (and therefore randomly jittered normals) however computing 
re.ections simply does not make much sense. Shadow effects can be added quite easily. While the performance 
and caching impact of shadows so far have shown to be surprisingly low, an exact discussion of these 
effects is beyond the scope of this paper. Nonetheless, adding shadows in practice is relatively simple. 
For example, Figure 6 shows some images that have been computed with shadows from a .ashlight-like light 
source that is attached relative to the viewer. Figure 6: Using a ray tracer, adding shadows to the 
model is (almost) trivial. As expected, shadows signi.cantly improve the impression of shape and depth 
(compare to Figure 4). This is particularly the case during interaction. As expected, shadows add an 
important visual cue to the image, and signi.cantly improve the impression of shape and depth, which 
can best be seen by comparing Figures 4 and 6. This improved sense of depth is particularly apparent 
once the shadows move with the light during interaction.  7. Conclusions In this paper, we have presented 
a framework that allows for interactively ray tracing gigabyte-sized models consisting of hundreds of 
millions of individual triangles on a single desktop PC. This is achieved using a combination of real-time 
ray tracing, an out-of-core demand-loading and memory management scheme for handling the massive amounts 
of geometry, and a hybrid volumetric/light.eld-like approximation scheme for representing not-yet-loaded 
geometry. By detecting and canceling potentially page-faulting rays, &#38;#169; The Eurographics Association 
2004. we can avoid system paging, and maintain high frame rates of several frames a second, even while 
.ying into or around our example airplane model. The visual impact of killing off rays is reduced by 
approximating the missing geometry using a light.eld-like approach. For not too drastic camera changes, 
the proxies can well hide the visual artifacts otherwise caused by the canceled rays. For large camera 
movements however, or when entering a previously occluded part of the model, the proxy structure becomes 
visible in form of blocky artifacts in the image. These artifacts then are similar to other approaches 
like Holodeck, Render Cache, point-based methods, or even MPEG/JPEG-compression. Using the surfacebased 
loading prioritization however these artifacts disappear quite quickly. Furthermore, the quality is 
still suf.cient for interactively navigating the model. Using our approach, we achieve frame rates of 
3 7 frames per second at 640 480 pixels, or still 1 2 frames per second at full-screen resolution of 
1280  1024 pixels, even on a single dual-CPU desktop PC. 7.1. Future Work As next steps, we will investigate 
ways to further improve the visual appearance of our proxies, potentially by including positional information 
at least for large voxels. More importantly, we are planning to make this technology available to industrial 
end-users, which means that we have to target real-time frame rates at full-screen resolutions. Eventually, 
this will require using more than only two CPUs. Fortunately, quad-CPU systems are already available, 
and eight-way systems have been announced. Additionally, it seems interesting to parallelize and distribute 
the current system over a cluster of cheap dual-CPU PCs. Preliminary result already look promising. Once 
the computational power is available, we also plan on evaluating how high-quality shadows, re.ections, 
and in particular interactive lighting simulation can be achieved in models of this complexity.  Acknowledgements 
We would like to express our thanks to Boeing Corp. for graciously providing this model, and to our 
system administration team for getting the prototype Opteron to run so quickly. Source 3D data provided 
by and used with permission of the Boeing Company.  References [ACW 99]ALIAGA D. G., COHEN J., WILSON 
A., BAKER E., ZHANG H., ERIKSON C., HOFF III K. E., HUDSON T., STRZLINGER W., BASTOS R., WHITTON M. 
C., BROOKS JR. F. P., MANOCHA D.: MMR: An Interactive Massive Model Rendering System using Geometric 
and Image-Based Acceleration. In ACM Symposium on Interactive 3D Graphics (1999), pp. 199 206. [AMD03] 
AMD: AMD Opteron Processor Model 8 Data Sheet. http://www.amd.com/us-en/Processors, 2003. [BC02] BOVET 
D. P., CESATI M.: Understanding the Linux Kernel (2nd Edition). O Reilly &#38; Associates, 2002. ISBN 
0-59600-213-0. [BMH99] BARTZ D., MEISSNER M., HTTNER T.: OpenGL assisted Occlusion Culling for Large 
Polygonal Models. Computer and Graphics 23, 3 (1999), 667 679. [BSGM02]BAXTER III W. V., SUD A., GOVINDARAJU 
N. K., MANOCHA D.: Gigawalk: Interactive Walkthrough of Complex Environments. In Rendering Techniques 
2002 (Proceedings of the 13th Eurographics Workshop on Rendering) (2002), pp. 203 214. [BWG03] BALA 
K., WALTER B., GREENBERG D.: Combining Edges and Points for Interactive High-Quality Rendering. ACM 
Transactions on Graphics (Proceedings of ACM SIGGRAPH) (2003), 631 640. [CH02] COCONU L., HEGE H.-C.: 
Hardware-Accelerated Point-Based Rendering of Complex Scenes. In Proceedings of the 13th Eurographics 
Workshop on Rendering (2002), Eurographics Association, pp. 43 52. [CKS03] CORREA W., KOSLOWSKI J. T., 
SILVA C.: Visibility-Based Prefetching for Interactive Out-Of-Core Rendering. In Proceedings of Parallel 
Graphics and Visualization (PGV) (2003), pp. 1 8. [CMS98] CIGNIONI P., MONTANI C., SCOPIGNIO R.: A Comparison 
of Mesh Simpli.cation Algorithms. Computers and Graphics 22, 1 (1998), 37 54. [DGP04] DEMARLE D. E., 
GRIBBLE C., PARKER S.: Memory-Savvy Distributed Interactive Ray Tracing. In Eurographics Symposium on 
Parallel Graphics and Visualization (2004). To appear. [DPH 03] DEMARLE D. E., PARKER S., HARTNER M., 
GRIB-BLE C., HANSEN C.: Distributed Interactive Ray Tracing for Large Volume Visualization. In Proceedings 
of the IEEE Symposium on Parallel and Large-Data Visualization and Graphics (PVG) (2003), pp. 87 94. 
[GKM93] GREENE N., KASS M., MILLER G.: Hierarchical Z-Buffer Visibility. In Computer Graphics (Proceedings 
of ACM SIGGRAPH) (August 1993), pp. 231 238. [GLY 03] GOVINDARAJU N. K., LLOYD B., YOON S.-E., SUD A., 
MANOCHA D.: Interactive Shadow Generation in Complex Environments. ACM Transaction on Graphics (Proceedings 
of ACM SIGGRAPH) 22, 3 (2003), 501 510. [Hav99] HAVRAN V.: Analysis of Cache Sensitive Representation 
for Binary Space Partitioning Trees. Informatica 23, 3 (May 1999), 203 210. ISSN: 0350-5596. [Hav01] 
HAVRAN V.: Heuristic Ray Shooting Algorithms. PhD thesis, Faculty of Electrical Engineering, Czech Technical 
University in Prague, 2001. [Int02] INTEL CORP.: Intel Pentium III Streaming SIMD Extensions. http://developer.intel.com, 
2002. [LH96] LEVOY M., HANRAHAN P.: Light .eld rendering. In Proceedings of the 23rd Annual Conference 
on Computer Graphics and Interactive Techniques (ACM SIG-GRAPH) (1996), pp. 31 42. [Nie92] NIEDERREITER 
H.: Random Number Generation and Quasi-Monte Carlo Methods. Society for Industrial and Applied Mathematics, 
1992. [PKGH97] PHARR M., KOLB C., GERSHBEIN R., HANRAHAN P.: Rendering Complex Scenes with Memory-Coherent 
Ray Tracing. Computer Graphics 31, Annual Conference Series (Aug. 1997), 101 108. [PZvBG00]PFISTER H., 
ZWICKER M., VAN BAAR J., GROSS M.: Surfels: Surface elements as rendering primitives. In Proc. of ACM 
SIGGRAPH (2000), pp. 335 342. [RL00] RUSINKIEWICZ S., LEVOY M.: QSplat: A Multiresolution Point Rendering 
System for Large Meshes. In Proc. of ACM SIGGRAPH (2000), pp. 343 352. [SDB97] SILLION F., DRETTAKIS 
G., BEDELET B.: Ef.cient Imposter manipulation for Real-Time Visualization of Urban Scenery. Computer 
Graphics Forum, 16,3 (1997), 207 218. (Proceeding of Eurographics). [Wal04] WALD I.: Realtime Ray Tracing 
and Interactive Global Illumination. PhD thesis, Computer Graphics Group, Saarland University, 2004. 
Available at http://www.mpisb.mpg.de/.wald/PhD/. [WDP99] WALTER B., DRETTAKIS G., PARKER S.: Interactive 
Rendering using the Render Cache. In Rendering Techniques 1999 (Proceedings of Eurographics Workshop 
on Rendering) (1999). [WFP 01] WAND M., FISCHER M., PETER I., AUF DER HEIDE F. M., STRASSER W.: The Randomized 
z-Buffer Algorithm: Interactive Rendering of Highly Complex Scenes. In Proc of ACM SIGGRAPH (2001), 
pp. 361 370. [WS99] WARD G., SIMMONS M.: The Holodeck Ray Cache: An Interactive Rendering System for 
Global Illumination in Nondiffuse Environments. ACM Transactions on Graphics 18, 4 (Oct. 1999), 361 
398. [WSB01] WALD I., SLUSALLEK P., BENTHIN C.: Interactive Distributed Ray Tracing of Highly Complex 
Models. In Rendering Techniques (2001), pp. 274 285. (Proceedings of Eurographics Workshop on Rendering). 
[WSBW01]WALD I., SLUSALLEK P., BENTHIN C., WAGNER M.: Interactive Rendering with Coherent Ray Tracing. 
Computer Graphics Forum 20, 3 (2001), 153 164. (Proceedings of Eurographics). [WWS00] WONKA P., WIMMER 
M., SCHMALSTIEG D.: Visibility Preprocessing with Occluder Fusion for Urban Walkthroughs. In Rendering 
Techniques (2000), pp. 71 82. (Proceedings of Eurographics Workshop on Rendering). [ZMHH97]ZHANG H., 
MANOCHA D., HUDSON T., HOFF III K. E.: Visibility Culling using Hierarchical Occlusion Maps. Computer 
Graphics 31, Annual Conference Series (1997), 77 88. c  
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198757</article_id>
		<sort_key>18</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[Custom hardware support for realtime ray tracing]]></title>
		<page_from>18</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198757</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198757</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40024383</person_id>
				<author_profile_id><![CDATA[81100159926]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Philipp]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Slusallek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Saarland University, Saarbr&#252;cken, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39043298</person_id>
				<author_profile_id><![CDATA[81100449948]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shirley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35035889</person_id>
				<author_profile_id><![CDATA[81547494456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mark]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Texas at Austin, Austin, TX]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39031627</person_id>
				<author_profile_id><![CDATA[81100189931]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Gordon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stoll]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Intel Corporation, Santa Clara, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40030613</person_id>
				<author_profile_id><![CDATA[81100041422]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Ingo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wald]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Max-Planck-Institut f&#252;r Informatik, Saarbr&#252;cken, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
  R a y T r a c i n g o n C P U s  Characteristics  Commodity, well understood HW  High FP performance, 
yet still too slow  Limited parallelism, bulky clusters  Poor silicon usage (e.g. cache)   Outlook 
 Multi-core designs are coming  Will still take too long    R a y T r a c i n g C h a r a c t e 
r i s t i c s : k d - T r e e T r a v e r s a l  Traversal Processing 50 80 k D steps per ray @ 10 
instructions/step . many instructions . many clock cycles  Serial dependency . low pipeline efficiency, 
stalls, latency  Limited but flexible control flow and memory access  . Custom HW unit One clock tick 
per traversal step (fully pipelined)  Up to 100:1 improvement  R a y T r a c i n g C h a r a c t e 
r i s t i c s : I n t e r s e c t i o n  Intersection computation Triggered by traversal at every leaf 
node Called with: ray and address of geometry  Option 1: Custom hardware [SaarCOR 05]  Option 2: Software 
on programmable processor  Can be implemented efficiently  Enables arbitrary programmable primitives 
  . Do not use costly dedicated hardware R a y T r a c i n g C h a r a c t e r i s t i c s : S h a 
d i n g  Shading computation Triggered by finished ray traversal Called with: ray, hit point, shader 
id, address of parameters  Characteristics:  General purpose computation, many 3-/4-vectors  Needs 
support for efficient texture and memory access  Needs support for arbitrary recursive tracing rays 
  E.g. support dependent ray tracing . Main feature of ray tracing: Do not put limits on it R a y T 
r a c i n g C h a r a c t e r i s t i c s : C o h e r e n c e  Ray coherence Neighboring primary rays 
 Traverse highly similar kd node in same order  Often hit same geometric primitives  Often execute 
the same shader, access same textures,   Similar for shadow rays to one light source  Often (but not 
always) applies for secondary rays  . HW should take advantage of this coherence   R P U D e s i g 
n  . ShaderProcessingUnits(SPU) . CustomRayTraversalUnit(TPU)  . Multi-Threading -IncreasesusageofHWresources 
-Hideslatencydueto -Memoryaccess -Instructiondependencies -Longtraversaloperations -SeparatethreadpoolforSPU&#38; 
TPU -Softwarescheduling(compiler) -Nooverheadforswitchingthreads -Increasesresources(mainlyregisterfile) 
 R P U D e s i g n  . ShaderProcessingUnits(SPU) . CustomRayTraversalUnit(TPU) . Multi-Threading 
 . Chunking -SIMDexecution(SPUs &#38; TPUs) -Takesadvantageofcoherence -Reduceshardwarecomplexity -Cancombineofmemoryrequests 
-Reducesexternalbandwidth -Mustallowforincoherence -Chunksmaysplitatconditionals -Inactivesub-chunkputonstack 
-Maskedexecution -Worstcase:serialcomputation R P U D e s i g n  . ShaderProcessingUnits(SPU) . CustomRayTraversalUnit(TPU) 
 . Multi-Threading . Chunking . MailboxProcessing (MPU) . Perthreadcachingmechanism . Avoidsmultipleprocessing 
ofsamekd-treeentry(e.g.triangle)  . 10xperformanceforsomescenes   R P U A r c h i t e c t u r e  
Fast RPUChip1 Chip PCI/AGP/PCI-X Inter-INTERFACE Connect Thread DMA-IF Generator RPU1 RPU2 RPUN DDR-RAM1 
SPUR4-CACHE SPU SPUSPUSPU R4-CACHE SPU R/W SPUSPU R/W (...) MEM-IF (...) VMU SPUT-CACHE SPU SPUSPUSPU 
T-CACHE SPU READONLY TPU DDR-RAMN TPUREADONLY L-CACHE READONLY L-CACHE MPUMPU READONLY      R P 
U P r o g r a m m i n g M o d e l TPU/ MPU TPU/ MPU Top LevelGeometry TPU/ TPU/ ObjectIntersector MPU 
MPU Intersector Light Source Shader shadow rays secondary rays primary ray Light Source Shader Lighting 
Shader Surface/ BRDF Shader Primary Ray Shader R P U P r o g r a m m i n g M o d e l  Threads are 
started for each pixel  Registers initialized from an input stream  TPU/ 2D Hilbert curve generator 
sampling the screen MPU  Memory stream for multi pass  Shader computes ray TPU/ MPU Top Level Geometry 
TPU/ TPU/ Object Intersector MPU MPU Intersector Light Source Shader shadow rays secondary rays primary 
ray Light Source Shader Lighting Shader Surface/ BRDF Shader Primary Ray Shader R P U P r o g r a 
m m i n g M o d e l Light Source Shader shadow rays secondary rays primary ray Light Source Shader 
 shadow rays secondary rays primary ray Light Source Shader Lighting Shader Surface/ BRDF Shader 
 Primary Ray Shader Light Source Shader Lighting Shader Surface/ BRDF Shader Primary Ray Shader 
 Threads are started  Registers initialized from an input stream  2D Hilbert curve generator sampling 
the screen  Memory stream for multi pass   Top LevelGeometry TPU/ ObjectIntersector MPU Intersector 
TPU/ MPU TPU/ MPU TPU/ MPU R P U P r o g r a m m i n g M o d e l Shooting Primary Rays Ray traversal 
performed on the TPU  Started in top level kd tree TPU/ MPU  Intersector transforms ray into local 
coordinate system  TPU/ MPU top level kd tree Top LevelGeometry TPU/ TPU/ ObjectIntersector MPU MPU 
Intersector R P U P r o g r a m m i n g M o d e l TPU/ MPU TPU/ MPU top level kd tree Top LevelGeometry 
TPU/ TPU/ ObjectIntersector MPU MPU Intersector R P U P r o g r a m m i n g M o d e l TPU/ MPU TPU/ 
MPU top level kd tree Top LevelGeometry TPU/ TPU/ ObjectIntersector MPU MPU Intersector Light Source 
Shader shadow rays secondary rays primary ray Light Source Shader shadow rays secondary rays primary 
ray Light Source Shader Lighting Shader Surface/ BRDF Shader Primary Ray Shader Light Source Shader 
 Lighting Shader Surface/ BRDF Shader Primary Ray Shader    DDR-RAM 1 (...) DDR-RAM N  S c a 
l a b i l i t y Larger Chunk Size Less ray coherence  More data is accessed  Increased cache bandwidth 
 Larger caches  S c a l a b i l i t y Larger Chunk Size RPU RPU Multiple RPUs on a Chip RAM RAM Limited 
by RPU RPU VLSI technology  Memory bandwidth  FPGA prototype versus current GPUs Floating point 
units 50x  Memory bandwidth 100x  Clock rate 7x  S c a l a b i l i t y RPU board Larger Chunk Size 
RAM RAM RPU CHIP RAM RAM RPU CHIP Multiple RPUs on a Chip  Multiple chips on a board  Fast interconnect 
for data exchange  Cache sizes accumulate  Managed through virtual memory [Schmittler 2003]  Limited 
through external bandwidth due to scene changes   S c a l a b i l i t y RPU board RPU board RPU board 
RPU board Larger Chunk Size RAM RAM RPU CHIP RAM RAM RPU CHIP RAM RAM RPU CHIP RAM RAM RPU CHIP RAM RAM 
RPU CHIP RAM RAM RPU CHIP Multiple RPUs on a Chip RAM RAM RPU CHIP RAM RAM RPU CHIP Multiple chips on 
a board  Multiple boards in a PC  Similar to today s PC clusters in a much smaller form factor   
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198758</article_id>
		<sort_key>19</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[Real-time rendering systems in 2010]]></title>
		<page_from>19</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198758</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198758</url>
		<abstract>
			<par><![CDATA[We present a case for future real-time rendering systems that support non-physically-correct global illumination techniques by using ray tracing visibility algorithms, by integrating scene management with rendering, and by executing on general-purpose single-chip parallel hardware (CMP's). We explain why this system design is desireable and why it is feasible. We also discuss some of the research questions that must be addressed before such a system can become practical.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP39035744</person_id>
				<author_profile_id><![CDATA[81100279370]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Mark]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Texas at Austin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P68425</person_id>
				<author_profile_id><![CDATA[81100584372]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fussell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Texas at Austin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Adiletta, M., Rosenbluth, M., Bernstein, D., Wolrich, G., and Wilkinson, H. 2002. The next generation of Intel IXP network processors. Intel technology journal 6, 3 (Aug.).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166131</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Akeley, K. 1993. RealityEngine graphics. In SIGGRAPH 93, 109--116.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>255132</ref_obj_id>
				<ref_obj_pid>255129</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Alverson, R., Callahan, D., Cummings, D., Koblenz, B., Porterfield, A., and Smith, B. 1990. The tera computer system. SIGARCH Comput. Archit. News 18, 3, 1--6.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[(AMERICAN NATIONAL STANDARDS INSTITUTE), A. 1988. programmer's hierarchical interactive graphics system (PHIGS) functional description. Tech. rep., ANSI.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Ar, S., Montag, G., and Tal, A. 2002. Deferred, self-organizing bsp trees. In Eurographics 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882364</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Bolz, J., Farmer, I., Grinspun, E., and Schroder, P. 2003. Sparse matrix solvers on the gpu: conjugate gradients and multigrid. In SIGGRAPH 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>876468</ref_obj_id>
				<ref_obj_pid>874076</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Ca&#351;caval, C., nos, J. G. C., Ceze, L., Denneau, M., Gupta, M., Lieber, D., Moreira, J. E., Strauss, K., and Jr, H. S. W. 2002. Evaluation of a multithreaded architecture for cellular computing. In Proceedings of the Eighth International Symposium on High-Performance Computer Architecture (HPCA'02), IEEE Computer Society, 311--322.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Christensen, P. H., Laur, D. M., Fong, J., Wooten, W. L., and Batali, D. 2003. Ray differentials and multiresolution geometry caching for distribution ray tracing in complex scenes. In Eurographics 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37414</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Cook, R. L., Carpenter, L., and Catmull, E. 1987. The REYES image rendering architecture. SIGGRAPH 87 21, 4 (July), 95--102.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>988498</ref_obj_id>
				<ref_obj_pid>988497</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Graphics standards planning committee. 1979. Status report of the graphics standards planning committee. Computer graphics 13, 3 (Aug.).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>643327</ref_obj_id>
				<ref_obj_pid>643323</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Gritz, L., and Hahn, J. K. 1996. BMRT: A global illumination implementation of the RenderMan standard. Journal of Graphics Tools 1, 3, 29--47.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97911</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hanrahan, P., and Lawson, J. 1990. A language for shading and lighting calculations. In SIGGRAPH 90, 289--298.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>861856</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hennessy, J. L., Patterson, D. A., and Goldberg, D. 2003. Computer Architecture: A Quantitative Approach, 3rd ed. Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1066491</ref_obj_id>
				<ref_obj_pid>1066486</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Hughes, C. J., and Adve, S. V. 2005. Memory-side prefetching for linked data structures for processor-in-memory systems. Journal of Parallel and Distributed Computing 65, 4 (Apr.), 448--463.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Hurley, Kapustin, Reshetov, and Soupikov. 2002. Fast ray tracing for modern general purpose CPU. In Graphicon 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Hurley, J., 2005, Mar. Personal Communication.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>285321</ref_obj_id>
				<ref_obj_pid>285305</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Igehy, H., Eldridge, M., and Proudfoot, K. 1998. Prefetching in a texture cache architecture. In Proc. of 1998 Eurographics/SIGGRAPH workshop on graphics hardware.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1095889</ref_obj_id>
				<ref_obj_pid>1095878</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Johnson, G. S., Lee, J., Burns, C. A., and Mark, W. R. 2005. The irregular z-buffer. ACM Transactions on Graphics (to appear).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Kapasi, U. J., Dally, W. J., Rixner, S., Owens, J. D., and Khailany, B. 2002. The Imagine stream processor. In Proc. of IEEE Conf. on Computer Design, 295--302.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>772258</ref_obj_id>
				<ref_obj_pid>772249</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Kato, T. 2002. The "Kilauea" massively parallel ray tracer. In Practical Parallel Rendering, A K Peters, A. Chalmers, T. Davis, and E. Reinhard, Eds.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>279399</ref_obj_id>
				<ref_obj_pid>279358</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Keckler, S. W., Dally, W. J., Maskit, D., Carter, N. P., Chang, A., and Lee, W. S. 1998. Exploiting fine-grain thread level parallelism on the MIT multi-alu processor. In ISCA 1998, 306--317.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258769</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Keller, A. 1997. Instant radiosity. In SIGGRAPH '97: Proceedings of the 24th annual conference on Computer graphics and interactive techniques, ACM Press/Addison-Wesley Publishing Co., New York, NY, USA, 49--56.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Kowalczyk, A., Adler, V., Amir, C., Chiu, F., Chng, C. P., Lange, W. J. D., Ge, Y., Ghosh, S., Hoang, T. C., Huang, B., Kant, S., Kao, Y. S., Khieu, C., Kumar, S., Lee, L., Lieber-mensch, A., Liu, X., Malur, N. G., Martin, A. A., Ngo, H., Oh, S.-H., Orginos, I., Shih, L., Sur, B., Tremblay, M., Tzeng, A., Vo, D., Zambare, S., and Zong, J. 2001. The first majc microprocessor: A dual cpu system-on-a-chip. IEEE Journal of Solid-State Circuits 36, 11 (Nov.), 1609--1616.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Krewell, K. 2003. Sun weaves multithreaded future. Available online at http://www.sun.com/processors/throughput/MDR_Reprint.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Lander, J. 1998. Skin them bones: game programming for the web generation. Game Developer Magazine (May), 11--16.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Lext, J., and Akenine-Moller, T. 2001. Towards rapid reconstruction for animated ray tracing. In Eurographics 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383274</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Lindholm, E., Kilgard, M. J., and Moreton, H. 2001. A user-programmable vertex engine. In SIGGRAPH 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>339673</ref_obj_id>
				<ref_obj_pid>339647</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Mai, K., Paaske, T., Jayasena, N., Ho, R., Dally, W. J., and Horowitz, M. 2000. Smart memories: A modular reconfigurable architecture. In ISCA 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882362</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Mark, W. R., Glanville, S., Akeley, K., and Kilgard, M. J. 2003. Cg: A system for programming graphics hardware in a C-like language. In SIGGRAPH 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Moyer, B., 2004. Ambient occlusion: It's better than a kick to the head. WWW page visited December 2004, http://www-viz.tamu.edu/students/bmoyer/617/ambocc/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[NVIDIA Corp. 2003. NV_fragment_program. In NVIDIA OpenGL Extension Specifications. Jan.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[NVIDIA Corp. 2004. NVIDIA GPU programming guide, v2.2.1, Nov.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300537</ref_obj_id>
				<ref_obj_pid>300523</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Parker, S., Martin, W., Sloan, P.-P. J., Shirley, P., Smits, B., and Hansen, C. 1999. Interactive ray tracing. In Symposium on interactive 3D graphics.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614435</ref_obj_id>
				<ref_obj_pid>614275</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Parker, S., Parker, M., Livnat, Y., Sloan, P.-P., Hansen, C., and Shirley, P. 1999. Interactive ray tracing for volume visualization. IEEE Transactions on Visualization and Computer Graphics 5, 3, 238--250.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Pham, D., S. Asano, Bolliger, M., Day, M., Hofstee, H., Johns, C., Kahle, J., Kameyama, A., Keaty, J., Masubuchi2, Y., Riley1, M., Shippy1, D., Stasiak1, D., M. Wang, J. Warnock, S. Weitzel, D. Wendel, T. Yamazaki, and K. Yazawa. 2005. The design and implementation of a first-generation cell processor. In Proceedings of 2005 IEEE Intl. Solid-State Circuits Conf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>275462</ref_obj_id>
				<ref_obj_pid>275458</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Pharr, M., and Hanrahan, P. 1996. Geometry caching for ray-tracing displacement maps. In 1996 Eurographics workshop on rendering.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258791</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Pharr, M., Kolb, C., Gershbein, R., and Hanrahan, P. 1997. Rendering complex scenes with memory-coherent raytracing. In SIGGRAPH 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566640</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Purcell, T. J., Buck, I., Mark, W. R., and Hanrahan, P. 2002. Ray tracing on programmable graphics hardware. In SIGGRAPH 2002, 703--712.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732126</ref_obj_id>
				<ref_obj_pid>647652</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Reinhard, E., Smits, B., and Hansen, C. 2000. Dynamic acceleration structures for interactive ray tracing. In Proceedings of the 11th Eurographics Workshop on Rendering, Eurographics Association, 299--306.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192262</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Rohlf, J., and Helman, J. 1994. IRIS performer: A high performance multiprocessing toolkit for real-time 3D graphics. In SIGGRAPH 94, 381--394.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956548</ref_obj_id>
				<ref_obj_pid>956417</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Sankaralingam, K., Keckler, S. W., Mark, W. R., and Burger, D. 2003. Universal mechanisms for data-parallel architectures. In Proceedings of the 36th Annual International Symposium on Microarchitecture.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>859667</ref_obj_id>
				<ref_obj_pid>859618</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Sankaralingam, K., Nagarajan, R., Liu, H., Kim, C., Huh, J., Burger, D., Keckler, S. W., and Moore, C. R. 2003. Exploiting ilp, tlp, and dlp with the polymorphous trips architecture. In Proc. of the 30th Annual Intl. Symp. on Computer Architecture (ISCA).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1006238</ref_obj_id>
				<ref_obj_pid>1006209</ref_obj_pid>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Sasanka, R., Adve, S. V., Chen, Y.-K., and Debes, E. 2004. The energy efficiency of cmp vs. smt for multimedia workloads. In ICS '04: Proceedings of the 18th annual international conference on Supercomputing, ACM Press, New York, NY, USA, 196--206.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1058143</ref_obj_id>
				<ref_obj_pid>1058129</ref_obj_pid>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Schmittler, J., Woop, S., Wagner, D., Paul, W. J., and Slusallek, P. 2004. Realtime ray tracing of dynamic scenes on an fpga chip. In Graphics Hardware 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Segal, M., and Akeley, K. 2002. The OpenGL Graphics System: A Specification (Version 1.4). OpenGL Architecture Review Board. Editor: Jon Leech.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566612</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Sloan, P.-P., Kautz, J., and Snyder, J. 2002. Precomputed radiance transfer for real-time rendering in dynamic, low-frequency lighting environments. In SIGGRAPH '02: Proceedings of the 29th annual conference on Computer graphics and interactive techniques, ACM Press, New York, NY, USA, 527--536.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1006733</ref_obj_id>
				<ref_obj_pid>998680</ref_obj_pid>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Taylor, M. B., Lee, W., Miller, J., Wentzlaff, D., Bratt, I., Greenwald, B., Hoffmann, H., Johnson, P., Kim, J., Psota, J., Saraf, A., Shnidman, N., Strumpen, V., Frank, M., Amarasinghe, S., and Agarwal, A. 2004. Evaluation of the raw microprocessor: An exposed-wire-delay architecture for ilp and streams. In ISCA 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>774894</ref_obj_id>
				<ref_obj_pid>774861</ref_obj_pid>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[Thompson, C. J., Hahn, S., and Oskin, M. 2002. Using modern graphics architectures for general-purpose computing: a framework and analysis. In Intl. symposium on computer architecture.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1081418</ref_obj_id>
				<ref_obj_pid>1081407</ref_obj_pid>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[Wald, I., Benthin, C., and Slusallek, P. 2003. Distributed interactive ray tracing of dynamic scenes. In Proc. IEEE symp. on parallel and large-data visualization and graphics.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>50</ref_seq_no>
				<ref_text><![CDATA[Wald, I., Purcell, T. J., Schmittler, J., Benthin, C., and Slusallek, P. 2003. Realtime ray tracing and its use for global illumination. In Eurographics 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>51</ref_seq_no>
				<ref_text><![CDATA[Wald, I., Purcell, T. J., Schmittler, J., Benthin, C., and Slusallek, P. 2003. Realtime ray tracing and its use for interactive global illumination. In State of the Art Reports, EUROGRAPHICS 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>500844</ref_obj_id>
				<ref_seq_no>52</ref_seq_no>
				<ref_text><![CDATA[Wan Jensen, H. 2001. Realistic image synthesis using photon mapping. AK Peters.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>53</ref_seq_no>
				<ref_text><![CDATA[Whitted, T. 1980. An improved illumination model for shaded display. Communications of the ACM 23, 6 (June), 343--349.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Real-Time Rendering Systems in 2010 William R. Mark * Donald Fussell Department of Computer Sciences 
The University of Texas at Austin Abstract We present a case for future real-time rendering systems that 
support non-physically-correct global illumination techniques by using ray tracing visibility algorithms, 
by integrating scene management with rendering, and by executing on general-purpose single-chip parallel 
hardware (CMP s). We explain why this system design is desireable and why it is feasible. We also discuss 
some of the research questions that must be addressed before such a system can become practical. CR 
Categories: I.3.1 [Computer Graphics]: Hardware Architecture [I.3.2]: Computer Graphics Graphics Systems 
1 Introduction For many years, real-time graphics systems have used the traditional Z-buffer pipeline 
model, which is limited to local illumination computations. With appropriate modi.cations, this pipeline 
can support some restrictive global illumination techniques, but doing so is awkward and often inef.cient. 
A different strategy is possible VLSI technology has now progressed to the point where we are on the 
verge of having suf.cient raw computational capability to use more general global illumination techniques. 
But there is no consensus yet about how future graphics systems supporting global illumination should 
be organized. If we look a few years into the future, several major questions become evident: What rendering 
algorithms are most appropriate for this new era? What architectures should we build to support these 
algorithms? And what overall system organization should tie together the application, rendering algorithms, 
and hardware? We believe that these questions have not yet been answered satisfactorily. The purpose 
of this paper is to argue that these questions are closely coupled and that addressing them will require 
simultaneous investigation of software algorithms and hardware architectures. We also propose a set of 
algorithmic and architectural approaches that we believe present one promising avenue of investigation. 
Our hope is that this paper will stimulate discussion in the research community and help to inspire 
the combined software and hardware research that we believe is critical to forward progress. The application-level 
goal that drives our investigation is support for real-time global illumination for dynamic scenes. 
We place greater emphasis on non-physically-correct global illumination techniques than on fully physically-based 
techniques, since non-physically-correct techniques represent an intermediate step between today s local 
illumination models and eventual use of 100% physically-based techniques. Most global illumination techniques 
require a more general visibility-computation capability than that provided by today s Z buffer. We present 
an algorithmic approach organized around ray tracing visibility algorithms that ef.ciently supports dynamic 
scenes by integrating scene management with rendering. But this tighter integration requires that the 
graphics hardware directly support model management as well as rendering. At the hardware level, we 
advocate a very .exible architecture: a multi-core, multi-threaded, MIMD architecture with coherent access 
to a single address space. This architecture ef.ciently supports application-speci.c scene management 
code as well as the creation and traversal of dynamic, irregular data structures. 1.1 Background The 
Z-buffer 3D graphics pipeline has been widely used for more than 20 years. As VLSI technology has advanced, 
this system organization has progressed down the cost curve from multimillion dollar .ight simulators, 
through high-end graphics workstations made by companies such as SGI (e.g. [Akeley 1993]), down to singlechip 
GPUs made by companies such as NVIDIA and ATI. For most of this history, Z-buffer graphics hardware was 
con.gurable but not programmable. However, over the past four years, we have seen the introduction of 
user-accessible programmability at both the vertex [Lindholm et al. 2001] and fragment [NVIDIA Corp. 
2003] stages of the pipeline. The vertex programmability merely exposed a programmable engine that had 
already existed in various forms for many years, but the fragment programmability exposed fundamentally 
new hardware functionality. Its introduction was driven by the realization that beyond a certain point, 
the best way to use additional VLSI transistors to improve image quality is to increase the quality 
of each pixel rather than increasing the number of pixels or increasing the geometric detail. Fragment 
programmability enabled commodity real-time systems [Mark et al. 2003] to support programmable shading 
capabilities inspired by those of Renderman [Hanrahan and Lawson 1990]. However, this programmability 
has proven to be suf.ciently .exible that researchers have begun to think of graphics processors as 
general-purpose stream processors [Kapasi et al. 2002], capable of supporting a variety of non-shading 
computations [Purcell et al. 2002; Thompson et al. 2002; Bolz et al. 2003]. But at the current time, 
most of these other uses of the GPU are not yet fully practical. The reason is that the current GPU 
programming model has limitations that limit performance on general-purpose computations to much less 
than peak performance. We expect that this situation will change with time, but not as rapidly as many 
researchers are expecting. Thus, the primary economic force driving GPU design is still real-time rendering, 
which leads us to the following question: What rendering requirements should drive the future evolution 
of graphics hardware? Another way of asking this question is, what additional capabilities could best 
be put to good use by applications? Of course, it only makes sense to consider capabilities that have 
the potential to be cost effective in the time frame of interest.  2 Application needs *e-mail: billmark@cs.utexas.edu 
We believe that there is still unmet application demand for higher e-mail: fussell@cs.utexas.edu .delity 
real-time imagery. For example, most observers would agree that the images produced by batch-rendering 
systems are noticeably superior to those produced by interactive graphics systems, and that they would 
like to see these higher-quality images produced by real-time systems. Some of the demand for improved 
image quality in real-time graphics can be met by adding support for object-space shading like that used 
in batch rendering systems such as REYES [Cook et al. 1987]. In particular, REYES provides better temporal 
and spatial anti-alising than the screen-space shading used in current real-time graphics systems. However, 
much of the current difference between batch rendering and real-time rendering results from the poor 
modeling of global illumination effects in real-time rendering systems as compared to batch rendering 
systems. We are already seeing demand for realistic global illumination with the current focus on the 
special case of real-time hard shadow generation. REYES and similar systems do not support global illumination 
computations in any general sense. Some observers argue that REYES and similar algorithms can be used 
to fake a wide variety global illumination effects, as demonstrated by their use for over 10 years for 
movie rendering. However, interactive graphics applications are fundamentally different from batch movie 
rendering because the viewpoints and scene con.gurations are not known a-priori by the programmers and 
artists. Most of the techniques used to fake global illumination with REYES-like systems rely on viewpoint-dependent 
hand tuning and thus are not appropriate for use in real-time graphics. 2.1 Use ray tracing visibility 
Almost all algorithms that model global illumination effects without the use of extensive hand-tuning 
rely on global visibility computations. Examples include radiosity, ray tracing [Whitted 1980], photon 
mapping [Wann Jensen 2001], approximation of far-.eld illumination using spherical basis functions, etc. 
Thus, we believe that robust support for global illumination requires support for global visibility 
computations, and speci.cally for ray tracing visibility. Recent work shows that raw computational capability 
has now advanced to the point where it is reasonable to consider using ray tracing visibility in real-time 
graphics systems. Over the past several years, several groups have built near-real-time ray tracing 
systems with steadily improving price/performance ratios. Most of these systems run on standard CPUs 
(e.g. [Parker et al. 1999a; Parker et al. 1999b; Hurley et al. 2002; Wald et al. 2003b], but one runs 
on a specialized ray tracing architecture implemented with an FPGA [Schmittler et al. 2004], and another 
uses the fragment processors of mainstream GPUs [Purcell et al. 2002]. The system with the best price/performance 
ratio [Hurley 2005] runs on a desktop PC with frame rates over 30 frames/sec for eye+shadow rays on complex 
scenes. Its raw performance has been quoted at over 100M Ray segments/sec. A recent review article [Wald 
et al. 2003c] provides an excellent overview of recent developments in this area. 2.2 Use non-physically-correct 
global illumination Experience has proven [Gritz and Hahn 1996; Kato 2002] that ray tracing algorithms 
and variants such as photon mapping provide the most robust and general solution to the global illumination 
problem. However, we do not expect 2010-era real-time game applications to rely primarily on physically 
correct global illumination. Instead, we expect that these applications will use the point-to-point visibility 
queries enabled by a ray tracing visibility framework to implement various non-physically correct approximations 
to global illumination. For example, we expect techniques such as ambient occlusion [Moyer 2004], instant 
radiosity [Keller 1997], and variations of precomputed radiance transfer [Sloan et al. 2002] to be used. 
For most of its history, computer graphics has relied heavily on phenomenological or quasi-physical 
approximations to illumination computation, and we do not expect that situation to change immediately. 
In fact, we expect that new phenomenological approximation techniques will be developed that leverage 
the capabilities of a ray tracing visibility engine. 2.3 Dynamic scenes are the challenge Most interactive 
applications, particularly those in the economically important gaming market, use dynamic scenes. These 
scenes include geometrically complex objects that move, and, more signi.cantly, deform. Unfortunately, 
there has been very little effort devoted to raytracing for dynamic scenes, and in particular for deformable 
objects. Deformable objects such as the skinned characters [Lander 1998] used in QuakeIII and Doom present 
a signi.cant challenge. The deformable nature of these characters is not well supported by any existing 
method for ray tracing. In particular, the simple approach of pre-building an acceleration data structure 
for the object and repositioning that object within the scene [Lext and Akenine-Moller 2001; Wald et 
al. 2003a] does not work for objects in which many polygons deform every frame. We believe that any practical 
real-time raytracing system must support moving and deformable objects with reasonable performance. 
 3 Integrate scene management with rendering To ray trace dynamic scenes in real time we must reassess 
the crucial role of acceleration structures in making the ray tracing process ef.cient. The highest 
performance ray tracers use a space partitioning acceleration structure such as an octree or BSP tree, 
but the scene data is not originally stored in this form. Instead, the space partitioning data structure 
is constructed from data stored in a scene graph represented as a hierarchy of (potentially overlapping) 
bounding volumes. A simple approach is to begin the computation of each frame by rebuilding an acceleration 
data structure of the type used in batch ray tracing. The problem with this approach is that the cost 
of rebuilding the acceleration structure may exceed the ray tracing cost itself. This problem is particularly 
serious if the scene has very high depth complexity, forcing the system to perform work for objects that 
are not hit by any rays. Even if we only rebuild those portions of the acceleration structure containing 
moving objects [Reinhard et al. 2000] the system may be performing much unnecessary work. For dynamic 
scenes it becomes apparent that minimizing the rebuild cost may be as important as minimizing the traversal 
cost, since the minimization of the total cost is the overriding criterion. The most promising approach 
is to use lazy evaluation techniques to build the acceleration structure (building on and extending 
work by Ar et al. [Ar et al. 2002]). When a ray enters a previously untouched portion of the space partitioning 
data structure, the system puts the ray traversal on hold; then constructs that portion of the space 
partitioning data structure from the scene graph; and .nally lets ray traversal resume through the newly 
created geometry. However, this approach requires a close interaction between the acceleration data structure 
and the scene graph used to model the world at the application level. We believe that this recognition 
is the key to designing an effective system organization for real time dynamic ray tracing. Consider 
a system in which scene management is tightly integrated with rendering (Figure 1). Such a system does 
not necessarily eliminate the need to store geometry using two different organizations hierarchical 
scene graph and space partitioning but such a system can tightly control which data is converted into 
the space partitioning form and when it is stored in this form. In particular, Today s Proposed System 
Architecture System Architecture CPU GPU CPU PPU/GPU and ray tracing   Rendering OpenGL/Direct3D renderer 
 Algorithms Hardware   Figure 1: We propose that scene management be tightly integrated with rendering 
and that both be executed on the .exible parallel hardware. We refer to this .exible parallel hardware 
as a PPU (parallel processing unit). the system can insure that only visible or nearly-visible surfaces 
are stored in space partitioning form. Requiring the rendering system to integrate scene management with 
rendering is a major change from today s systems, so it is reasonable to ask why it is possible to separate 
scene management from rendering in a Z-buffer system but not in a ray tracer. In a simple Z-buffer system, 
visibility computations are performed in object order, so that each polygon in the scene is touched once 
and only once each frame by the visibility algorithm. Thus, for the purpose of the visibility computation, 
there is no need to store more than one polygon in local memory at a time. Of course the geometry must 
be stored somewhere in the system, but this can be done by the application or scene graph in any manner 
that is desired, with the geometry streamed across the immediate mode interface to the Z-buffer system. 
Commonly, the geometry is stored in a hierarchical data structure for the application to animate and 
otherwise modify. Typically, ray tracing algorithms are ray order algorithms, in which the basic visibility 
algorithm can touch one polygon, then touch a second polygon, and eventually return to the .rst polygon. 
This type of algorithm requires direct access to the geometric database describing the scene. However, 
the geometric database need not be stored in the same format as the scene graph that is manipulated by 
the application. By transferring data lazily between the two data structures, we can minimize the cost 
of maintaining two different data structures. 3.1 Additional improvements If ray traversal is managed 
so that most rays touching a particular portion of space are processed simultaneously [Pharr et al. 1997], 
then the system has the option of treating geometry represented in space-partitioning form as disposable. 
That is, when a particular volume of space is visited by a batch of rays, .rst the system creates an 
acceleration structure in on-chip memory for the geometry residing in that volume of space, then performs 
ray/triangle intersection tests, then discards the acceleration structure. The acceleration structure 
for that volume of space can be recreated later from the scene graph if it happens to be needed again. 
Several other optimizations become convenient in this framework. If the system stores scene graph data 
using higher-order representations such as subdivision surfaces, these representations may be tesselated 
into triangles as the system creates the spatial acceleration structure. The data explosion that occurs 
during this step can be con.ned to on-chip memory, just as it is for a Z-buffer pipeline that includes 
a tesselation processor. Pharr and Hanrahan describe a variant of approach for displacement surfaces 
[Pharr and Hanrahan 1996]. An additional advantage of tight integration of scene management with rendering 
is that the system can automatically adapt the LOD of geometry to local ray density, even instantiating 
the same geometry at two different levels of detail, as is often needed when different types of rays 
(eye and re.ected, for example) intersect the same geometry. A recent paper from Pixar [Christensen et 
al. 2003] has clearly demonstrated the value of using ray differentials to manage geometric level of 
detail in a raytracer.  4 Is a uni.ed system organization practical? We recognize that proposing to 
tightly couple scene management with rendering .ies in the face of conventional wisdom about graphics 
system design. Current systems, following the lead of Iris GL and OpenGL [Segal and Akeley 2002], are 
characterized by the separation of scene management from rendering, mediated by a carefully-designed 
immediate mode rendering interface (Figure 1). Why do we have this interface? Because experience has 
shown that it is not possible to build an ef.cient, fully general-purpose scene manager. Attempts to 
standardize systems of this type, such as CORE [Graphics standards planning committee 1979] and PHIGS 
[(american national standards institute) 1988], failed largely because of their attempt to integrate 
support for modeling and rendering using an API framework. So why do we think we can do better? Because 
experience has also shown that it is possible to build reusable scene managers specialized for particular 
application domains. The most prominent examples are Performer [Rohlf and Helman 1994] which is specialized 
for visual simulation and id software s widely licensed game engines, which are specialized for .rst-person-shooter 
games. However, these systems do not use a standard API framework either the engine is either highly 
con.gurable through internal hooks (Performer) or it can be directly modi.ed in source code form (id 
s game engines). We conclude that it is probably not possible to build a fully generic scene engine behind 
an API, but that it is possible to build specialized engines that implement performance critical tasks 
and can be adapted for particular applications. Thus, if one is willing to allow a scene manager to 
be implemented in user code (i.e. not embedded in unprogrammable hardware, or behind a onesize-.ts-all 
interface), then it is perfectly possible to build a highperformance scene manager. If this scene manager 
can run on the same hardware that supports the rendering, then we believe that the scene manager can 
include rendering code, and thus provide the integrated renderer / scene manager that we propose. This 
approach is analogous to the programmable shaders in today s hardware, but carried much farther.  5 
Parallel architecture supporting late binding To ef.ciently support the ray tracing system we have described, 
the hardware architecture and corresponding parallel programming model must be very .exible and allow 
most control and data binding decisions to be deferred until run time. For example, a highlyspecialized 
architecture, a SIMD architecture, or a streaming architecture would not be appropriate for this workload. 
Several factors drive this need for generality: Application-dependent scene management: The architecture 
cannot be designed for particular scene management code.  Irregular data structures: The scene graph 
and acceleration data structures are irregular, requiring pointer-chasing or its equivalent.  Dynamic 
data structures: The irregular data structures must be built and modi.ed with high performance, as well 
as being traversed with high performance.  Data dependent control .ow: Adaptive tesselation, ray tracing, 
and other tasks use highly data-dependent control .ow.  Data locality: Many of the data structures exhibit 
temporal locality in their access patterns, but the exact form of the locality is not known at compile 
time due to the irregular nature of the data structures.  We take as a starting point that our target 
architecture provides explicit parallelism, which provides better power ef.ciency than a single mainstream 
high-ILP CPU [Sasanka et al. 2004]. 5.1 MIMD control .ow We advocate a MIMD programming model because 
it supports data parallel execution of computation kernels that use data-dependent conditionals and looping. 
Support for MIMD control .ow is critical for ef.ciently creating and traversing adaptive spatial data 
structures such as k-d trees, as well as for executing short data-dependent loops such as those used 
in vertex skinning and anisotropic texture .ltering [Sankaralingam et al. 2003a]. MIMD computation also 
supports general task level parallelism, i.e. it allows multiple distinct kernels to run concurrently. 
A primary example of the need for this is to allow closely coupled scene graph management and rendering 
tasks to run concurrently, particularly when these tasks are not individually suf.ciently parallelizable 
to be able to occupy the entire machine. Current graphics hardware (e.g. NVIDIA 6800 with shader model 
3.0) supports a more restrictive SPMD (single-program, multiple data) programming model in which MIMD-style 
control .ow is supported, but all fragment or vertex processors must be running the same program. However, 
the hardware implementation of the control .ow is closer to a SIMD implementation, so that code with 
divergent branching behavior is inef.cient [Nvidia Corp. 2004]. Even if future architectures use a MIMD 
organization as we advocate, that does not preclude support for simpler programming models as well. 
Most other parallel programming models (e.g. various variants of stream programming ) can be described 
as restricted subsets of the one we have outlined and thus can be supported by the same hardware. For 
tasks that can tolerate these limitations, the restricted programming models are often easier to use 
and typically encourage the programmer to express the task in a form that will perform well. For example, 
the stream programming model forbids the code within one kernel from directly communicating with the 
code within another kernel, thereby eliminating the potential for many types of concurrency and performance 
bugs. Recent industry designs seem to endorse our view that MIMD architectures are a better choice than 
SIMD architectures for generalpurpose single-chip parallel computation. Sun s Niagara [Krewell 2003] 
and IBM/STI s CELL [Pham et al. 2005] are both fully MIMD. The most advanced graphics processors (e.g. 
GeForce 6800) currently have a MIMD programing model (actually SPMD) implemented as a MIMD execution 
model in the vertex processor and a SIMD execution model in the fragment processor. We expect future 
architectures to gradually move towards a MIMD implementation, although maintaining current fragment 
ordering semantics in a MIMD machine presents some challenges. Several interesting research architectures 
that use a highly-parallel MIMD organization are IBM s Cyclops [Cascaval et al. 2002] (not yet built), 
Stanford s Smart Memories [Mai et al. 2000] (not yet built), MIT s RAW [Taylor et al. 2004] (already 
built), and the MIT M-Machine [Keckler et al. 1998] (already built) which demonstrated some promising 
approaches for supporting .ne-grained MIMD parallelism. Note that although all of the architectures 
mentioned above are MIMD in their overall organization, many of them support 4-wide SIMD instructions 
within each core. These short-vector SIMD instructions are an ef.cient mechanism for exploiting what 
is really just a particularly common form of instruction-level parallelism found in graphics and scienti.c 
code. Even in machines that are designed to exploit MIMD thread-level parallelism, it is still worthwhile 
to support such low-cost forms of instruction level parallelism, since exploiting such parallelism improves 
performance without requiring an increase in on-chip storage such as would be required by support for 
additional threads.  5.2 Hardware caches and global address space For processors built using modern 
VLSI technology it is desirable to include a multi-level memory hierarchy on chip, since for workloads 
with temporal memory-access locality this strategy provides a favorable combination of low power consumption, 
low average memory-access latency, and high load/store bandwidth [Kapasi et al. 2002]. There are a variety 
of mechanisms by which a programming model can provide access to high-speed on-chip memory. The two most 
popular mechanisms are a hardware-managed cache and a software-managed scratchpad memory. The difference 
between these two approaches is fundamental. For a cache, the decision as to which elements of data should 
be stored on chip is automatically made by the hardware at run-time, with the decision typically made 
at a .ne granularity (e.g. blocks of 32 bytes). With a softwaremanaged scratchpad memory, the decision 
as to which data should be stored on chip is made either at compile time or made explicitly by software 
at runtime, usually at a coarser granularity. In applications with highly regular memory access patterns, 
such as classical DSP applications, a software-managed memory is the right choice. Software-managed memories 
carry less hardware overhead, allow static scheduling of the entire machine (particularly important for 
SIMD architectures), and provide the user and compiler with better performance guarantees than a hardware-managed 
cache. In contrast, applications that manipulate adaptive data structures such as k-d trees, BSP trees, 
or short variable-length lists cannot easily manage memory at compile time. The application writer and 
compiler may know that there will be signi.cant spatial and temporal locality of the memory accesses, 
but they do not know exactly what form this locality will take for any particular data set. For these 
applications, the binding of particular data elements to the on-chip memory is best performed at a .ne 
spatial granularity. This approach is exactly that used by conventional hardware-managed caches. Since 
we believe that the construction, modi.cation, and use of adaptive spatial data structures will be a 
performance-critical part of future real-time 3D graphics applications, we believe that future hardware 
architectures should support hardware-managed caches or at a minimum must include hardware primitives 
from which equivalent behavior can be ef.ciently implemented in software. One important advantage of 
an architecture with traditional hardware-managed caches especially if cache-coherency is supported 
 is that the architecture can provide the illusion of a single large memory, in which the storage hierarchy 
is simply an automatic hardware-supported performance optimization. In practice, parallel software must 
be heavily tuned to achieve good performance from such an architecture, but this performance tuning 
can be done incrementally. In contrast, software-managed memories are usually exposed to the programmer 
and/or compiler as a series of architecturally visible capacity cliffs , which must be painfully overcome 
even in the earliest software prototypes. The recently announced CELL architecture [Pham et al. 2005], 
is an interesting hybrid between the traditional cache strategy and scratchpad strategy. CELL s parallel 
cores (called SPE s) have a local scratchpad memory, but the DMA transfers between this scratchpad and 
main memory are coherent within a single global address space. The dif.culty of managing a scratchpad 
memory is mitigated by the fact that the scratchpad is unusually large (256 KB per core). For a programmer, 
is is qualitatively easier to manage this L2-sized scratchpad than it is to manage a more traditional 
L1-sized scratchpad. Nevertheless, we believe that it will prove to be challenging to ef.ciently implement 
some irregular-datastructure algorithms on CELL. Even the strategy of using software to mimic traditional 
cache behavior is unlikely to perform well on CELL, due to the long branch mis-predict penalty and lack 
of hardware-supported multithreading. However, we believe that adding minimalist multithreading capability 
to the CELL SPE architecture would substantially improve this situation at relatively low cost, and 
we hope that this capability will be considered for future versions of CELL.  5.3 Hardware support for 
multithreading A major problem encountered by most modern architectures is that the latency for moving 
data between the processing chip and offchip DRAM memory can be 100 or more cycles. To maintain high 
ALU utilization, the machine must perform other work while such requests are outstanding. With a hardware-managed 
cache, the problem is particularly severe, because the compiler and hardware do not know in advance whether 
a particular load or store will miss the cache(s). Thus, every access to the uni.ed address space potentially 
incurs a 100 cycle delay, whereas in a machine with a scratchpad, only the explicit accesses to off-chip 
memory can incur this delay. Fortunately, highly parallel computations such as those in 3D graphics normally 
have other work (i.e. other threads) that can be processed during an off-chip memory access. There are 
two strategies for switching to other thread(s), which we will now describe. The .rst strategy is to 
assume that every memory access misses the cache. This approach is followed by classical texture caching 
systems [Igehy et al. 1998], by the specialized SaarCOR raytracing architecture [Schmittler et al. 2004], 
and by cacheless multithreaded architectures like Tera [Alverson et al. 1990]. The ALU switches to other 
thread(s) (e.g. another fragment or vertex) for the required number of cycles, regardless of whether 
or not the memory request actually missed the cache. Unfortunately, this strategy requires that the 
number of active threads per ALU be approximately equal to the off-chip memory latency. The memory needed 
to store the working set for these threads can easily dominate the die area of the parallel processor, 
particularly when one considers the datacache or scratchpad-memory footprint of each thread as well 
as its registers. The second strategy is to switch to another thread only if the data access actually 
misses the cache. This approach is the one used by modern multithreaded machines such as Niagara [Krewell 
2003], Cyclops [Cascaval et al. 2002], and MAJC [Kowalczyk et al. 2001]. The advantage of this second 
approach is that fewer threads are required, particularly if cache misses are infrequent. Thus we consider 
this strategy to be the better one, at least if the machine is already a MIMD machine. However, it is 
worth noting that this strategy may not perform well if the memory accesses by different threads are 
highly correlated, leading to situations where all threads stall at the same time waiting for the same 
cache line. For example, this situation can occur for texture map lookups in a fragment shader. In some 
cases careful use of prefetching can mitigate this problem, but it is not yet clear if this strategy 
would be effective for texture mapping. There is an unfortunate tension between the goal of maximizing 
overlap of the working sets of different threads (which in turn reduces the per-thread SRAM requirements) 
and minimizing the temporal correlation between cache misses of different threads (which in turn allows 
a reduction in the ratio of threads-per-ALU). We expect that managing this tradeoff will be a major 
focus of future performance-optimization efforts for both hardware and software in single-chip parallel 
systems. One advantage of SIMD control .ow that is often under-appreciated is that SIMD execution provides 
implicit but very tight inter-thread synchronization that facilitates reasoning about and management 
of this tradeoff. Managing this tradeoff in MIMD systems can require that .ne-grained interthread synchronization 
be used for this purpose as well as for the traditional purpose of managing the more obvious control 
and data dependencies in the parallel computation.  5.4 Parallelism Summary The various design decisions 
for a parallel machine are closely coupled to each other. For example, the decision to use a hardwaremanaged 
L1 cache in each core is at odds with a decision to use SIMD control. Broadly speaking, there appear 
to be two reasonable points in the design space, which can be referred to as static and dynamic . Static 
machines such as Imagine bind and schedule most .ne-grain resources at compile time ALUs, on-chip memory, 
off-chip memory accesses, etc. The static strategy can use compile-time information about the program, 
but cannot not use much if any information about data-dependent behavior. In contrast, dynamic machines 
such as Niagara [Krewell 2003], Cyclops [Cascaval et al. 2002] and the Intel IXP network processor [Adiletta 
et al. 2002] bind and schedule most resources at run time with hardware assistance. The dynamic-binding 
strategy uses both program information and runtime information derived from the data being processed. 
For tasks in which the runtime information can signi.cantly improve the quality of resource binding 
and scheduling, we believe that the dynamic approach will provide superior performance and will also 
be easier to program. However, for problems that can be effectively scheduled at compile time, there 
is no bene.t to the dynamic approach, and the hardware support needed for it reduces the performance/price 
ratio of the hardware. Thus, the decision as to what type of machine to build should rest largely on 
anticipated application characteristics. We have argued that future real-time 3D graphics algorithms 
will use adaptive data structures, and thus that future architectures targeted to support these algorithms 
should use dynamic binding and scheduling. The close coupling we .nd here between the choice of software 
algorithms and the choice of hardware architectures is one of the reasons that we are advocating that 
algorithmic and hardware questions be investigated in tandem. As with most such design-space tradeoffs, 
hybrid strategies exist. For example CELL has MIMD control .ow, seemingly placing it in the dynamic 
category, but its high branch-mispredict penalty coupled with lack of multithreading somewhat penalize 
highly dynamic algorithms, as does CELL s choice of scratchpad memory rather than cache for local storage. 
A useful perspective on the general static-vs-dynamic tradeoff can be found in the architectural taxonomy 
found at the end of [Taylor et al. 2004].  5.5 CPU and parallel processor on the same die Experience 
teaches us that very few problems are perfectly parallelizable. Historically, Cray s vector machines 
outperformed their competitors because they had superior performance for scalars and short vectors [Hennessy 
et al. 2003]. 3-D graphics is no exception to this general rule modern graphics hardware has serialization 
points, although these potential bottlenecks are normally not user programmable. For this reason, we 
believe that future graphics algorithms will split their work between an array of parallel processors 
optimized for high, power-ef.cient throughput on parallel code and at least one CPU-like processor optimized 
for maximum performance on a single thread. We believe that these two core types will be implemented 
with different sets of transistors, rather than by recon.guring a single underlying substrate [Sankaralingam 
et al. 2003b; Taylor et al. 2004; Mai et al. 2000]. The reason is that a welldesigned throughput-optimized 
processor differs from a singlethread-optimized processor in almost every respect, including the physical 
design of the individual transistors. The .exibility gained from a single recon.gurable substrate is 
likely to be more than offset by the cost of the necessary compromises. To facilitate the low-latency, 
high-bandwith transfer of work between the throughput-optimized and single-thread-optimized processing 
cores, they must be integrated on a single die. Network processors [Adiletta et al. 2002] and CELL use 
this organization already, and we believe that in the long term these technical bene.ts as well as market 
trends towards cost reduction make such integration inevitable for graphics processors. 5.6 More than 
one kind of throughput-optimized core? One important but open question is whether future chipmultiprocessors 
should have just one kind of throughput-optimized core, or two or more varieties of such cores. For example, 
it would be reasonable to build an architecture which has one set of cores that can only write to memory 
via stream outputs (like today s GPU fragment processors), and a second set of cores supporting cachecoherent 
memory writes and reads. The .rst set of cores would have higher peak performance, but would be restricted 
to a narrower class of computations than the second set of cores. Other kinds of cores may also be useful. 
For example, current graphics chips include a simple con.gurable hardware unit (the raster-operation 
unit) located next to each of several memory controllers. We have shown that adding additional capabilities 
to this unit enables it to ef.ciently assist the task of building linked lists [Johnson et al. 2005]. 
Others have shown that such near-memory processing can be useful for traversing linked lists [Hughes 
and Adve 2005]. Finally, if a single-chip parallel architecture is expected to be heavily used for one 
particular task such as 3D rendering, it may be advantageous to include highly-specialized cores optimized 
for particular tasks such as texture .ltering (included in today s GPU s) or ray/triangle intersection 
testing. Most of these decisions must be made based on detailed cost/bene.t analysis of both the workload 
and the hardware implementation, but there is one broad issue that will impact all such decisions. 
It is possible that future power budgets will prohibit architectures from using all of their transistors 
at once. This constraint would favor heterogeneous specialization of the architecture s processing units, 
a point that was .rst brought to our attention by Mark Horowitz.  6 Conclusion We have argued that 
the next frontier in improved real-time image quality is to simulate global illumination effects for 
dynamic scenes. We claim that ray tracing will be the visibility algorithm of choice, but that it will 
initially be used to support non-physicallycorrect global illumination techniques. We believe that a 
ray tracing system that ef.ciently supports dynamic scenes will need to integrate scene management with 
rendering. Since scene management code is somewhat application speci.c, this tight integration implies 
that the parallel architecture used to accelerate rendering must also be capable of executing application-speci.c 
scene management code. In turn, this requires that the parallel architecture support a general-purpose 
parallel programming model, with inter-thread communication, synchronization, and perhaps cache-coherent 
memory operations. The programming model supported by today s GPUs lacks most of these capabilities, 
and in particular it does not provide adequate support for creating and modifying adaptive data structures. 
We believe the most promising hardware architecture to support this programming model is a MIMD multithreaded 
machine with cache-coherent shared memory. However, this conjecture remains unproven, and many questions 
remain about the details of such an architecture as well as its price/performance ratio. To date we have 
not built either the software or the hardware necessary to con.rm our hypothesis. What we have presented 
is a set of informed opinions backed by reasonable arguments and some initial results from architecture 
and algorithm simulations [Johnson et al. 2005]. Our purpose in presenting these opinions is two-fold. 
First, we think the ideas are suf.ciently interesting that they will stimulate useful discussion within 
the research community. Second, we hope to persuade the research community that the particular approach 
we have outlined is suf.ciently promising to be worthy of detailed investigation.  7 Acknowledgements 
Gordon Stoll has contributed substantially to our thinking about real-time ray tracing systems and in 
particular is responsible for the insight that ray casting visiblity is likely to be used initially to 
support non-physically-correct techniques such as ambient occlusion rather than to support physically-correct 
techniques such as photon mapping. Kurt Akeley is responsible for the insight that scene-graph rendering 
interfaces can be successful if they are tailored to suf.ciently narrow application domains. Our research 
group and collaborators Greg Johnson, Paul Navratil, Calvin Lin, Chris Burns, Juhyun Lee, Karthikeyan 
Sankaralingam, Doug Burger, Steve Keckler, the Stanford Smart Memories group, Alex Joly, Ikrima Elhassan, 
David Whiteford, Chris Lundberg, Chendi Zhang and Peter Djeu have been build ing systems and gathering 
results that have in.uenced our thinking about both rendering algorithms and parallel architectures. 
We thank Microsoft, Intel, NVIDIA, and the University of Texas for supporting this research.  References 
ADILETTA, M., ROSENBLUTH, M., BERNSTEIN, D., WOLRICH, G., AND WILKINSON, H. 2002. The next generation 
of Intel IXP network processors. Intel technology journal 6, 3 (Aug.). AKELEY, K. 1993. RealityEngine 
graphics. In SIGGRAPH 93, 109 116. ALVERSON, R., CALLAHAN, D., CUMMINGS, D., KOBLENZ, B., PORTERFIELD, 
A., AND SMITH, B. 1990. The tera computer system. SIGARCH Comput. Archit. News 18, 3, 1 6. (AMERICAN 
NATIONAL STANDARDS INSTITUTE), A. 1988. programmer s hierarchical interactive graphics system (PHIGS) 
functional description. Tech. rep., ANSI. AR, S., MONTAG, G., AND TAL, A. 2002. Deferred, self-organizing 
bsp trees. In Eurographics 2002. BOLZ, J., FARMER, I., GRINSPUN, E., AND SCHRODER, P. 2003. Sparse matrix 
solvers on the gpu: conjugate gradients and multigrid. In SIG-GRAPH 2003. CASCAVAL, C., NOS, J.G.C., 
CEZE, L., DENNEAU, M., GUPTA, M., LIEBER, D., MOREIRA, J. E., STRAUSS, K., AND JR,H. S. W. 2002. Evaluation 
of a multithreaded architecture for cellular computing. In Proceedings of the Eighth International Symposium 
on High-Performance Computer Architecture (HPCA 02), IEEE Computer Society, 311 322. CHRISTENSEN, P. 
H., LAUR, D. M., FONG, J., WOOTEN, W. L., AND BATALI, D. 2003. Ray differentials and multiresolution 
geometry caching for distribution ray tracing in complex scenes. In Eurographics 2003. COOK, R. L., 
CARPENTER, L., AND CATMULL, E. 1987. The REYES image rendering architecture. SIGGRAPH 87 21, 4 (July), 
95 102. GRAPHICS STANDARDS PLANNING COMMITTEE. 1979. Status report of the graphics standards planning 
committee. Computer graphics 13,3 (Aug.). GRITZ, L., AND HAHN, J. K. 1996. BMRT: A global illumination 
implementation of the RenderMan standard. Journal of Graphics Tools 1,3, 29 47. HANRAHAN,P., AND LAWSON, 
J. 1990. A language for shading and lighting calculations. In SIGGRAPH 90, 289 298. HENNESSY, J. L., 
PATTERSON, D. A., AND GOLDBERG, D. 2003. Computer Architecture: A Quantitative Approach, 3rd ed. Morgan 
Kaufmann. HUGHES, C. J., AND ADVE, S. V. 2005. Memory-side prefetching for linked data structures for 
processor-in-memory systems. Journal of Parallel and Distributed Computing 65, 4 (Apr.), 448 463. HURLEY,KAPUSTIN,RESHETOV, 
AND SOUPIKOV. 2002. Fast ray tracing for modern general purpose CPU. In Graphicon 2002. HURLEY, J., 2005, 
Mar. Personal Communication. IGEHY, H., ELDRIDGE, M., AND PROUDFOOT, K. 1998. Prefetching in a texture 
cache architecture. In Proc. of 1998 Eurographics/SIGGRAPH workshop on graphics hardware. JOHNSON, G. 
S., LEE, J., BURNS, C. A., AND MARK, W. R. 2005. The irregular z-buffer. ACM Transactions on Graphics 
(to appear). KAPASI, U. J., DALLY, W. J., RIXNER, S., OWENS, J. D., AND KHAILANY, B. 2002. The Imagine 
stream processor. In Proc. of IEEE Conf. on Computer Design, 295 302. KATO, T. 2002. The Kilauea massively 
parallel ray tracer. In Practical Parallel Rendering, A K Peters, A. Chalmers, T. Davis, and E. Reinhard, 
Eds. 7 KECKLER,S.W., DALLY, W. J., MASKIT,D.,,CARTER,N.P., CHANG, A., AND LEE, W. S. 1998. Exploiting 
.ne-grain thread level parallelism on the MIT multi-alu processor. In ISCA 1998, 306 317. KELLER, A. 
1997. Instant radiosity. In SIGGRAPH 97: Proceedings of the 24th annual conference on Computer graphics 
and interactive techniques, ACM Press/Addison-Wesley Publishing Co., New York, NY, USA, 49 56. KOWALCZYK, 
A., ADLER,V., AMIR, C., CHIU,F., CHNG,C. P., LANGE, W. J. D., GE,Y., GHOSH, S., HOANG, T. C., HUANG, 
B., KANT, S., KAO, Y. S., KHIEU, C., KUMAR, S., LEE, L., LIEBER-MENSCH, A., LIU, X., MALUR, N. G., MARTIN, 
A. A., NGO, H., OH, S.-H., ORGINOS, I., SHIH, L., SUR, B., TREMBLAY, M., TZENG, A., VO, D., ZAMBARE, 
S., AND ZONG, J. 2001. The .rst majc microprocessor: A dual cpu system-on-a-chip. IEEE Journal of Solid-State 
Circuits 36, 11 (Nov.), 1609 1616. KREWELL, K. 2003. Sun weaves multithreaded future. Available online 
at http://www.sun.com/processors/throughput/MDR_Reprint.pdf. LANDER, J. 1998. Skin them bones: game programming 
for the web generation. Game Developer Magazine (May), 11 16. LEXT, J., AND AKENINE-MOLLER, T. 2001. 
Towards rapid reconstruction for animated ray tracing. In Eurographics 2001. LINDHOLM, E., KILGARD, M. 
J., AND MORETON, H. 2001. A userprogrammable vertex engine. In SIGGRAPH 2001. MAI, K., PAASKE,T., JAYASENA, 
N., HO, R., DALLY, W. J., AND HOROWITZ, M. 2000. Smart memories: A modular recon.gurable architecture. 
In ISCA 2000. MARK, W. R., GLANVILLE, S., AKELEY, K., AND KILGARD,M. J. 2003. Cg: A system for programming 
graphics hardware in a C-like language. In SIGGRAPH 2003. MOYER, B., 2004. Ambient occlusion: It s better 
than a kick to the head. WWW page visited December 2004, http://wwwviz.tamu.edu/students/bmoyer/617/ambocc/. 
NVIDIA CORP. 2003. NV_fragment_program. In NVIDIA OpenGL Extension Speci.cations. Jan. NVIDIA CORP. 
2004. NVIDIA GPU programming guide, v2.2.1,Nov. PARKER, S., MARTIN,W., SLOAN, P.-P. J., SHIRLEY,P., SMITS, 
B., AND HANSEN, C. 1999. Interactive ray tracing. In Symposium on interactive 3D graphics. PARKER, S., 
PARKER, M., LIVNAT,Y., SLOAN, P.-P., HANSEN, C., AND SHIRLEY, P. 1999. Interactive ray tracing for volume 
visualization. IEEE Transactions on Visualization and Computer Graphics 5, 3, 238 250. PHAM, D., S.ASANO,BOLLIGER, 
M., DAY, M., HOFSTEE, H., JOHNS, C., KAHLE, J., KAMEYAMA, A., KEATY, J., MASUBUCHI2, Y., RI-LEY1, M., 
SHIPPY1, D., STASIAK1, D., M.WANG, J.WARNOCK, S.WEITZEL, D.WENDEL,T.YAMAZAKI, AND K.YAZAWA. 2005. The 
design and implementation of a .rst-generation cell processor. In Proceedings of 2005 IEEE Intl. Solid-State 
Circuits Conf. PHARR, M., AND HANRAHAN, P. 1996. Geometry caching for ray-tracing displacement maps. 
In 1996 Eurographics workshop on rendering. PHARR, M., KOLB, C., GERSHBEIN, R., AND HANRAHAN, P. 1997. 
Rendering complex scenes with memory-coherent raytracing. In SIGGRAPH 1997. PURCELL, T. J., BUCK, I., 
MARK, W. R., AND HANRAHAN, P. 2002. Ray tracing on programmable graphics hardware. In SIGGRAPH 2002, 
703 712. REINHARD, E., SMITS, B., AND HANSEN, C. 2000. Dynamic acceleration structures for interactive 
ray tracing. In Proceedings of the 11th Eurographics Workshop on Rendering, Eurographics Association, 
299 306. ROHLF, J., AND HELMAN, J. 1994. IRIS performer: A high performance multiprocessing toolkit for 
real time 3D graphics. In SIGGRAPH 94, 381 394. SANKARALINGAM, K., KECKLER,S.W., MARK, W. R., AND BURGER, 
D. 2003. Universal mechanisms for data-parallel architectures. In Proceedings of the 36th Annual International 
Symposium on Microarchitecture. SANKARALINGAM, K., NAGARAJAN, R., LIU, H., KIM, C., HUH, J., BURGER, 
D., KECKLER,S.W., AND MOORE, C. R. 2003. Exploiting ilp,tlp, and dlp with the polymorphous trips architecture. 
In Proc. of the 30th Annual Intl. Symp. on Computer Architecture (ISCA). SASANKA, R., ADVE,S. V., CHEN, 
Y.-K., AND DEBES, E. 2004. The energy ef.ciency of cmp vs. smt for multimedia workloads. In ICS 04: Proceedings 
of the 18th annual international conference on Supercomputing, ACM Press, New York, NY, USA, 196 206. 
SCHMITTLER, J., WOOP, S., WAGNER, D., PAUL, W. J., AND SLUSALLEK, P. 2004. Realtime ray tracing of dynamic 
scenes on an fpga chip. In Graphics Hardware 2004. SEGAL, M., AND AKELEY, K. 2002. The OpenGL Graphics 
System: A Speci.cation (Version 1.4). OpenGL Architecture Review Board. Editor: Jon Leech. SLOAN, P.-P., 
KAUTZ, J., AND SNYDER, J. 2002. Precomputed radiance transfer for real-time rendering in dynamic, low-frequency 
lighting environments. In SIGGRAPH 02: Proceedings of the 29th annual conference on Computer graphics 
and interactive techniques, ACM Press, New York, NY, USA, 527 536. TAYLOR, M. B., LEE,W., MILLER, J., 
WENTZLAFF, D., BRATT, I., GREENWALD, B., HOFFMANN, H., JOHNSON,P., KIM, J., PSOTA, J., SARAF, A., SHNIDMAN, 
N., STRUMPEN,V., FRANK, M., AMARAS-INGHE, S., AND AGARWAL, A. 2004. Evaluation of the raw microprocessor: 
An exposed-wire-delay architecture for ilp and streams. In ISCA 2004. THOMPSON, C. J., HAHN, S., AND 
OSKIN, M. 2002. Using modern graphics architectures for general-purpose computing: a framework and analysis. 
In Intl. symposium on computer architecture. WALD, I., BENTHIN, C., AND SLUSALLEK, P. 2003. Distributed 
interactive ray tracing of dynamic scenes. In Proc. IEEE symp. on parallel and large-data visualization 
and graphics. WALD, I., PURCELL, T. J., SCHMITTLER, J., BENTHIN, C., AND SLUSALLEK, P. 2003. Realtime 
ray tracing and its use for global illumination. In Eurographics 2003. WALD, I., PURCELL, T. J., SCHMITTLER, 
J., BENTHIN, C., AND SLUSALLEK, P. 2003. Realtime ray tracing and its use for interactive global illumination. 
In State of the Art Reports, EUROGRAPHICS 2003. WANN JENSEN, H. 2001. Realistic image synthesis using 
photon mapping. AK Peters. WHITTED, T. 1980. An improved illumination model for shaded display. Communications 
of the ACM 23, 6 (June), 343 349.  
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198759</article_id>
		<sort_key>20</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[Programming with OpenRT]]></title>
		<page_from>20</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198759</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198759</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP24038507</person_id>
				<author_profile_id><![CDATA[81322509130]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Igno]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wald]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MPII Saarbruecken]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
  U s i n g R e a l t i m e R a y T r a c i n g : P r o g r a m m i n g w i t h O p e n R T  The OpenRT 
API  Architecture and Design Guidelines  Brief API overview   Writing OpenRT Applications Brief 
tutorial  Performance optimizations  Tips &#38; Tricks  O p e n R T A P I M o t i v a t i o n  Part 
I-III: Have discussed technical issues of realtime ray tracing  Fast ray traversal and intersection 
 Handling dynamic scenes  Hardware  Applications   Together: Form a complete rendering engine 
 O p e n R T A P I M o t i v a t i o n  How to make that technology available to the user(s) ? .Need 
an API  Lack of common API one of the historical problems of RT !  Hundreds of known/published improvements 
(better algorithms, optimizations, tricks, )  But: usually each only implemented in one software package 
 Not directly available to others, slow spreading of technology  Result: Many, many different ray tracers 
out there Test: Who in this room has not yet written at least one ray tracer ?  but most use only tiny 
part of known optimizations/technology   Test: Who in this room has implemented a (working) SAH ? O 
p e n R T A P I M o t i v a t i o n  (Standardized) APIs are crucial for new technologies Allow to 
build a common user base .Knowledge base of how to use the technology  Allows users to abstract from 
underlying technology Can become productive without having to understand all details  Allows technicians 
to continually improve the technology  If hidden behind API, user won t even see any changes  Technical 
improvements directly reach the users   If similar to exiting/known APIs, yield steep learning curve 
 . Need to define a (quasi )standard API for RTRT O p e n R T A P I M o t i v a t i o n  Problem: What 
is a good API for realtime ray tracing Existing ray tracing APIs: Inherently offline (POVRay, RenderMan, 
)  Existing realtime APIs:  Not designed to support advantages/demands of ray tracing  Historically 
all designed for rasterization   Need to build our own O p e n R T A P I D e s i g n G o a l s  As 
powerful as RenderMan etc. Offer all features of ray tracing (shaders, complex geometry, )  As similar 
to OpenGL as possible:  Except where it doesn t make sense  Allows for easy migration of existing OpenGL 
knowledge  Be as low level as possible Flexibility   Optimally support existing RTRT implementations 
 Suitable for parallelization, handling dynamic scenes,  But: Hide technological aspects (distribution) 
where possible   Users just don t (want to) care about distribution, different kd trees, O p e n R 
T A P I D e s i g n G o a l s  Fundamental design decision: Differentiate between application API and 
shader API  RenderMan-like for shader writers C++ framework, shader classes, recursive ray tracing 
 OpenGL like for application programmers  Just load and use shaders like e.g., display lists  Describing 
geometry etc. like with OpenGL   O p e n R T C o r e A p p l i c a t i o n A P I : V e r y m u c h 
l i k e O p e n G L  Geometry: Almost exactly like OpenGL Vertices: rtVertex3f( ), rtNormal3f( ), 
rtColor3f( ),  Triangles: rtBegin(RT TRIANGLES/RT POLYGON/ ); rtEnd();  Typical OpenGL transformation 
operations available rtPushMatrix(), rtRotatef( ), rtLoadMatrixf( ),  But: No Immediate-mode rendering 
 Rather: Geometry objects O p e n R T C o r e A p p l i c a t i o n A P I : V e r y m u c h l i k e 
O p e n G L  Geometry objects Define/use like OpenGL display lists rtGenObjects( ), rtNewObject( 
), rtEndObject( )  Each object gets its own ADS ADS built once on object definition (invisible to user) 
 Objects lateron instantiated : rtInstantiate( )  Like calling a display list  Instance generated 
with current transformation stack  Support framework for dynamic scenes (see Part II)  Difference to 
OpenGL: MUST use objects  T h e O p e n R T A P I : D e f i n i n g G e o m e t r y  A simple example: 
Trivial for any OpenGL programmer int objID; rtGenObjects(&#38;objID,1); rtNewObject(objID,RT_COMPILE); 
rtPushMatrix(); rtTranslatef(1,0,0); rtBindShader(shaderID); rtBegin(RT_TRIANGLES); rtVertex3f( .); rtNormal3f( 
); rtEnd(); rtPopMatrix(); rtEndObject(); O p e n R T C o r e A p p l i c a t i o n A P I : V e r y 
m u c h l i k e O p e n G L  Apart from Geometry Texture objects Exactly like OpenGL Shaders access 
via tex.ID  Shader objects  All appearance related operations done via shaders! Camera shaders, light 
shaders, surface shaders, environment,  No explicit handling of lights or materials any more  NO rtMaterialf, 
rtLightf, etc.  Well-known helper functions  rtPerspective( ), rtLookAt( ), rtSwapBuffers( ), rtFlush( 
) O p e n R T C o r e A p p l i c a t i o n A P I : L o a d i n g a n d U s i n g s h a d e r s  Similar 
to Stanford Prog.Shading API Dynamically loaded from DLLs/.so s: rtGenShaders(), rtNewShader(), rtBindShader() 
 Each triangle has one shader ID of shader associated shader ID that was bound during triangle definition 
 App/shader communication:  Shader classes export parameters (by name)  App requests handle to specific 
shader s parameter int diffuseHandle rtParameterHandle( diffuseColor );  then writes to it   rtParameter3fv(diffuseHandle,&#38;red); 
 O p e n R T S S h a d e r A P I  Shader API: Very much like RenderMan  Plug-n-play shader framework 
 Surface shaders, light shaders, environment shaders,  Realized via C++ classes: RTShader, RTLight, 
  C-style API functions (rtFindShadingNormal(), )  Can trace arbitrary individual rays (rtsTrace( 
))   No more details here, see following talk on Writing OpenRT shaders  O p e n R T A P I : R e 
s u l t s   Powerful: Lots of existing applications  Including industrial VR software  All realized 
exclusively via the API   Distribution framework completely hidden  Application often doesn t know 
at all if it s running standalone or distributed  Programmer doesn t have to care  Except: performance 
(see below)  Except: file names (might be different on clients!)   O p e n R T A P I : R e s u l 
t s   Experience: Easily adopted by new users  In particular, if they already know OpenGL  Most particular 
problem: Different semantics  Usually quickly accepted/used to   Easy to use and learn: Very impressive 
results by students   Difference between shader/application API works well  Can write shaders completely 
independent of application  Can share shaders amond different applications  But: App needs to be aware 
of shaders parameters   U s i n g R e a l t i m e R a y T r a c i n g : P r o g r a m m i n g w i t 
h O p e n R T  A brief tutorial  Initializing  Defining geometry  Loading and using shaders  Rendering 
a frame  Animating the scene   Performance optimizations  Tips &#38; Tricks  W r i t i n g O p e 
n R T a p p l i c a t i o n s I n i t i a l i z a t i o n  First and foremost, call rtInit directly 
after main() int main(int ac, char **av) { rtInit(&#38;ac,av); Specify frame buffer to use rtSetFrameBuffer() 
, No details here, see tutorials  Usually way: Render into texture, display via OpenGL E.g., via QT 
s QGLImage  GLUT style helper library (RTUT) available  Easy to use, ideal for first tests W r i t 
i n g O p e n R T a p p l i c a t i o n s D e f i n i n g G e o m e t r y  Will only cover triangular 
geometry here Other primitive types supported via plugins  Basic way of defining geometry  Define 
objects as geometry containers  Add primitives to an objects  Can use usual ModelView transformations 
like OGL  Later on, instantiate object with associated transform   W r i t i n g O p e n R T a p p 
l i c a t i o n s D e f i n i n g G e o m e t r y  A simple example: Trivial for any OpenGL programmer 
int objID; rtGenObjects(&#38;objID,1); rtNewObject(objID,RT_COMPILE); rtPushMatrix(); rtTranslatef(1,0,0); 
rtBindShader(shaderID); rtBegin(RT_TRIANGLES); rtVertex3f( .); rtNormal3f( ); rtEnd(); rtPopMatrix(); 
rtEndObject(); W r i t i n g O p e n R T a p p l i c a t i o n s L o a d i n g a n d u s i n g s h a 
d e r s  Loading a shader consists of five steps Loading the shader class  Declaring handles to its 
parameters  Creating an instance of that shader  Parameterizing it  Using shader references during 
geometry definition   W r i t i n g O p e n R T a p p l i c a t i o n s L o a d i n g a n d u s i n 
g s h a d e r s  Using a shader during primitive definition Simply bind the shader ID before issuing 
primitive rtBindShader(simpleID); rtBegin(RT TRIANGLES); rtEnd();  Note: Shaders have side effects 
(intentionally)  Changing shader parameter affects all triangles with given shader even after primitive 
definition Shader editing does NOT require re definition of primitives W r i t i n g O p e n R T a p 
p l i c a t i o n s U s i n g l i g h t s h a d e r s  Lights in OpenRT No explicit light calls (like 
rtLight( )) ALL realized via light shaders  Using light shaders  Generate just like surface shaders 
 Need to know light shader parameters E.g., PointLight shader: position , intensity , atten ,  Typical 
light shaders (point,spot,directional) already included   Once generated, call rtUseLight(RT_GLOBAL,lightID) 
  W r i t i n g O p e n R T a p p l i c a t i o n s R e n d e r i n g a f r a m e  Once all geometry/lights/etc 
are set up: Render Frame  Calling rtSwapBuffers() renders currently specified scene to given frame buffer. 
 Note: In the distributed variant, rtSwapBuffers() has one frame latency: rtSwapBuffers always returns 
previous frame !  Once frame is rendered: Display via e.g. OpenGL  W r i t i n g O p e n R T a p p 
l i c a t i o n s A n i m a t i n g t h e s c e n e  Animating lights, shaders, camera, trivial Just 
change it s respective shader parameters rtBindLight(lightID); rtParameter3f(LIGHT POSITION,newPosition); 
  Animating geometry: Re instantiate object(s) with new transformation matrix See previous talk on 
Handling Dynamic Scenes  Simplest (most typical) way:  Delete all instances every frame (rtDeleteInstances()) 
 Retraverse Scenegraph   Instantiate all objects with updated transformation matrix W r i t i n g 
O p e n R T a p p l i c a t i o n s A n i m a t i n g t h e s c e n e  More advanced way of doing that: 
Change transformation of only a single instance: rtLoadMatrixf(&#38;newTransformation); rtSetInstanceXfm(instID); 
Much more efficient, but often harder to implement Keyframe animation: Build one object for every timestep. 
Then, per frame: rtDeleteInstance(instID); rtLoadMatrixf(&#38;currentTransform); instID rtInstantiate(objID[currentTimeStep]); 
P e r f o r m a n c e o p t i m i z a t i o n s  Key to good performance: Minimize state changes Reason: 
All state changes have to be transferred across network to clients VERY costly  Minimize number of objects/instances 
 Core performance best for few, large objects Good kd trees can t help if geometry is not in same object! 
 Use lightweight applications  Don t spend 90% of time in GUI and scene graph trav.! P e r f o r m 
a n c e o p t i m i z a t i o n s  Minimizing state changes: Don t delete/re-instantiate all instances 
per frame Rather: selectively update only changed instances  Don t re-issue data that has not changed 
 Shader parameters, lights positions,  Often need to track current state in application  Remember: 
If not explcitly changed, everything is still available in next frame   Shaders, objects, shader parameters, 
P e r f o r m a n c e o p t i m i z a t i o n s  Minimize number of objects Typical scene graph problem: 
Lots of small nodes Don t generate a new object for every 10 triangles !  Generally: Put all primitives 
in same object, except if they are to to be moved differently  Need to combine small sub-graphs to 
one object  Often coding effort for existing scene graphs  but VERY important   T i p s &#38; T r 
i c k s  Some typical tips&#38;tricks when using OpenRT: Progressive Supersampling OpenRT also supports 
accumulation buffer concept  During motion: use plain rtSwapBuffers()  At camera standstill: Use rtAccum( 
) to accumulate images computed with different pixel samples  Result: Fast rendering during interaction 
 But: Aliasing quickly disappears after end of interaction  Can do similar for smooth shadows, glossyness, 
  T i p s &#38; T r i c k s  Using binary object dumps OpenRT supports binary dumps of complete objects 
 Including kd trees and geometry  Next time app starts, just load/map the binary objects Much faster 
startup times, no need to build kd trees  In particular, can mmap the binaries  No need to even load 
the data into application  Can copy binaries to client s local disks, map from there No need to send 
full geometry every frame!   T i p s &#38; T r i c k s  Subsampling during motion If your machine/cluster 
is too slow:  Let OpenRT render at reduced resolution during motion  Use OpenGL to zoom image to fullscreen 
blurry, but faster   During camera standstill, switch to fullscreen ray tracing  Similar to progressive 
supersampling 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198760</article_id>
		<sort_key>21</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[The OpenRT-API]]></title>
		<page_from>21</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198760</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198760</url>
		<abstract>
			<par><![CDATA[In the preceding course sections, all the basic constituents of a complete realtime ray tracing engine have been described: A highly efficient ray tracing kernel for modern CPUs, its efficient parallelization, and a simple yet efficient framework for handling dynamic scenes.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40031461</person_id>
				<author_profile_id><![CDATA[81100041422]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ingo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wald]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Saarland University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>617574</ref_obj_id>
				<ref_obj_pid>616012</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{Apodaca90} A. Apodaca and M. Mantle. RenderMan: Pursuing the Future of Graphics. IEEE Computer Graphics & Applications, 10(4):44--49, July 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>555371</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{Apodaka00} Anthony Apodaka and Larry Gritz. Advanced RenderMan: Creating CGI for Motion Pictures. Morgan Kaufmann, 2000. ISBN: 1558606181.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{Bekaert01} Philippe Bekaert. Extensible Scene Graph Manager, August 2001. http://www.cs.kuleuven.ac.be/~graphics/XRML/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{Benthin03} Carsten Benthin, Ingo Wald, and Philipp Slusallek. A Scalable Approach to Interactive Global Illumination. Computer Graphics Forum, 22(3):621--630, 2003. (Proceedings of Eurographics).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37414</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{Cook87} Robert L. Cook, Loren Carpenter, and Edwin Catmull. The REYES Image Rendering Architecture. Computer Graphics (Proceedings of ACM SIGGRAPH 1987), pages 95--102, July 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{Dietrich03} Andreas Dietrich, Ingo Wald, Carsten Benthin, and Philipp Slusallek. The OpenRT Application Programming Interface - Towards A Common API for Interactive Ray Tracing. In Proceedings of the 2003 OpenSG Symposium, pages 23--31, Darmstadt, Germany, 2003. Eurographics Association.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1010373</ref_obj_id>
				<ref_obj_pid>1009389</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{Dietrich04} Andreas Dietrich, Ingo Wald, Markus Wagner, and Philipp Slusallek. VRML Scene Graphs on an Interactive Ray Tracing Engine. In Proceedings of IEEE VR 2004, pages 109--116, March 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{DirectX} Microsoft DirectX 8.0. http://www.microsoft.com/windows/directx/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>862247</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{Fernando03} Randima Fernando and Mark J. Kilgard. The Cg Tutorial - The Definitive Guide to Programmable Real-Time Graphics. Addison-Wesley, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>643327</ref_obj_id>
				<ref_obj_pid>643323</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{Gritz96} Larry Gritz and James K. Hahn. BMRT: A Global Illumination Implementation of the RenderMan Standard. Journal of Graphics Tools, 1(3): 29--47, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97911</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{Hanrahan90} Pat Hanrahan and Jim Lawson. A language for shading and lighting calculations. Computer Graphics (Proceedings of ACM SIGGRAPH), 24(4):289--298, August 1990. ISBN: 0-201-50933-4.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566639</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{Humphreys02} Greg Humphreys, Mike Houston, Ren Ng, Sean Ahern, Randall Frank, Peter Kirchner, and James T. Klosowski. Chromium: A Stream Processing Framework for Interactive Graphics on Clusters of Workstations. ACM Transactions on Graphics (Proceedings of SIGGRAPH 2002), 21(3):693--702, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{Kessenich02} John Kessenich, Dave Baldwin, and Randi Rost. The OpenGL Shading Language, Version 1.051, February 2002. Available from http://www.3dlabs.com/support/developer/ogl2/-downloads/ShaderSpecV1.051.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{Mark01} William Mark. Shading System Immediate-Mode API, v2.1. In SIGGRAPH 2001 Course 24 Notes - Real-Time Shading, August 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882362</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{Mark03} William R. Mark, R. Steven Glanville, Kurt Akeley, and Mark J. Kilgard. Cg: A System for Programming Graphics Hardware in a C-like Language. ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH), 22(3):896--907, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{Neider93} Jackie Neider, Tom Davis, and Mason Woo. OpenGL Programming Guide. Addison-Wesley, 1993. ISBN 020163-2748.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[{OpenSG01} OpenSG-Forum. http://www.opensg.org, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[{OSG} OpenSceneGraph. http://www.openscenegraph.org.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[{Pixar89} Pixar. The RenderMan Interface. San Rafael, September 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383275</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[{Proudfoot01} Kekoa Proudfoot, William Mark, Svetoslav Tzvetkov, and Pat Hanrahan. A Real-Time Procedural Shading System for Programmable Graphics Hardware. In Proceedings of ACM SIGGRAPH, pages 159--170, August 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566640</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[{Purcell02} Timothy J. Purcell, Ian Buck, William R. Mark, and Pat Hanrahan. Ray Tracing on Programmable Graphics Hardware. ACM Transactions on Graphics, 21(3):703--712, 2002. (Proceedings of SIGGRAPH 2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192262</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[{Rohlf94} John Rohlf and James Helman. IRIS Performer: A High Performance Multiprocessing Toolkit for Real-Time 3D Graphics. Computer Graphics, 28(Annual Conference Series):381--394, July 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[{Slusallek95} Philipp Slusallek, Thomas Pflaum, and Hans-Peter Seidel. Using Procedural RenderMan Shaders for Global Illumination. In Computer Graphics Forum (Proc. of Eurographics '95, pages 311--324, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[{Upstill90} Steve Upstill. The RenderMan Companion. Addison-Wesley, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[{Wagner02} Markus Wagner. Development of a Ray-Tracing-Based VRML Browser and Editor. Master's thesis, Computer Graphics Group, Saarland University, Saarbr&#252;cken, Germany, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[{Wald} Ingo Wald and Tim Dahmen. OpenRT User Manual. Computer Graphics Group, Saarland University. http://www.openrt.de.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[{Wald02} Ingo Wald, Carsten Benthin, and Philipp Slusallek. OpenRT - A Flexible and Scalable Rendering Engine for Interactive 3D Graphics. Technical report, Saarland University, 2002. Available at http://graphics.cs.uni-sb.de/Publications.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[{Wald03} Ingo Wald, Timothy J. Purcell, J&#246;rg Schmittler, Carsten Benthin, and Philipp Slusallek. Realtime Ray Tracing and its use for Interactive Global Illumination. In Eurographics State of the Art Reports, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[{Wald04} Ingo Wald. Realtime Ray Tracing and Interactive Global Illumination. PhD thesis, Computer Graphics Group, Saarland University, 2004. Available at http://www.mpi-sb.mpg.de/~wald/PhD/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[{Wernecke94} Josie Wernecke. The Inventor Mentor. Addison-Wesley, 1994. ISBN 0-20162-495-8.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073211</ref_obj_id>
				<ref_obj_pid>1186822</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[{Woop05} Sven Woop, Joerg Schmittler, and Philipp Slusallek. RPU: A Programmable Ray Processing Unit for Realtime Ray Tracing. Proceedings of ACM SIGGRAPH, (to appear), 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Siggraph 2005 Course on Interactive Ray Tracing The OpenRT API Ingo Wald This is an excerpt from Realtime 
Ray Tracing and Interactive Global Illumination , PhD Thesis, Ingo Wald, Computer Graphics Group, Saarland 
University. Full Version available at http://www.mpi-sb.mpg.de/~wald/PhD In the preceding course sections, 
all the basic constituents of a complete realtime ray tracing engine have been described: A highly e.cient 
ray tracing kernel for modern CPUs, its e.cient parallelization, and a simple yet e.cient framework for 
handling dynamic scenes. Once these building blocks have successfully been merged, essentially all the 
technical requirements for realtime ray tracing are ful.lled. However, a key issue for reaching the scenario 
of realtime ray tracing on everybody s desktop is widespread application support, which requires a standardized 
and commonly accepted API. Roughly speaking, having a powerful new technology is one thing, having a 
good means of making the power of this technology available to the average end user is a totally di.erent 
story. For hardware rasterization, this role of a powerful and widely accepted API has been taken by 
OpenGL [Neider93]1 , which today is used by almost any graphics application, and which is well-known 
to virtually any graphics developer. Ideally, one could simply adopt OpenGL for ray tracing, in which 
case any existing OpenGL application could transparently render its images using ray tracing. Thus, 
one could (in theory) write an OpenGL wrapper library in the spirit of WireGL/Chromium [Humphreys02], 
that would perform the state tracking, would extract a ray-tracing suitable scene description from that, 
and would then call the ray tracer. The extended capabilities of ray tracing namely shaders and global 
e.ects could then be made available to the graphics programmer via the use of the well-known OpenGL 
extension mechanism (i.e. by o.ering a GL ARB RAYTRACE extension). Unfortunately, this is but a mere 
theoretical option. as OpenGL and similar graphics APIs are too closely related to the rasterization 
pipeline. These APIs clearly re.ect the stream of graphics commands that is fed to the rasterization 
pipeline, and as such also closely re.ect the capabilities and limitations of the rasterization approach. 
In contrast to OpenGL, RenderMan [Pixar89, Apodaca90, Hanrahan90, Upstill90, Apodaka00] o.ers a more 
suitable highlevel API that also supports ray tracing. However, these APIs o.er almost no 1And, more 
recently, also by DirectX and Direct3D [DirectX]. support for interactive applications, and are thus 
not well suited for driving interactive applications. Another option would be the use of an existing 
high-level scene graph library such as Performer, OpenInventor, OpenSG, OpenSceneGraph, or others [Rohlf94, 
Wernecke94, OpenSG01, OSG] for driving the ray tracer. This would already enable many new applications 
and would already reach a large number of potential users. However, the level of abstraction of such 
high-level scene graphs is too high for a generic ray tracing API, often is too application speci.c, 
and is unnecessarily restrictive. Being a low-level API, OpenGL allowed for all the non-intended uses 
(e.g. multipass rendering) while still allowing for layering higher-level APIs on top of it. In order 
not to unneccessarily restrict the potential uses of the API, it seems appropriate to follow this approach 
and design the API to be as low-level and .exible as possible. This allows for performing all the tasks 
that it is mainly thought for today, while still being .exible enough to adapt to potentially changing 
demands in the future. As discussed above, none of the commonly available graphics APIs could be easily 
adopted for our ray tracing engine without unnecessary restrictions of its functionality. As such, we 
have decided to design a new API explicitly for realtime ray tracing. Ideally, such an API for realtime 
ray tracing should not only be an API speci.c to a certain implementation (i.e. the RTRT kernel), but 
should be both general and powerful enough to support the upcoming trend towards more widespread use 
of realtime ray tracing in general. Thus, we have designed our API with the following guidelines in mind: 
 The API should be as low-level as possible in order to be able to layer higher-level scene graph APIs 
on top of it.  It should be syntactically and semantically as similar to an existing, widely used graphics 
API as possible, in order to facilitate porting of existing applications and for leveraging programmers 
experiences. Being the most commonly adopted graphics API, we have chosen OpenGL as a parent API to our 
new API, and have thus called it OpenRT .  It should be as powerful and .exible as RenderMan for writing 
shaders in order not to restrict the kinds of shading functionality that can be realized through this 
API.  The OpenRT API [Wald02, Wald03, Dietrich03] has been designed explicitly with these key observations 
in mind. While OpenRT so far has been implemented only on top of the previously mentioned RTRT kernel, 
it is not speci.c to this system. For example, the entire cluster infrastructure of the RTRT system has 
been completely abstracted from, and is not re.ected in the API. Already today, two di.erent implementations 
of this API are available, a distributed cluster version and a stand-alone shared-memory version (although 
both actually build on the same RTRT core). In the near future, it is planned to also use this OpenRT 
API for driving the SaarCOR architecture [Woop05]. 1 General Design of OpenRT As brie.y mentioned above, 
one problem in designing OpenRT was choosing the right parent API to inherit ideas from: While it is 
generally a good idea to stay close to popular APIs allowing to draw from a wide range of experienced 
people there is the open question what API exactly to inherit from. On one side, OpenGL is the favorite 
API for writing interactive applications it is very powerful, many people are experienced in OpenGL, 
and there is a huge amount of documentation and practical applications using OpenGL. On the other hand, 
OpenGL does not really .t a ray tracing engine: For example, it is mostly an immediate-mode API, and 
does not have any support for specifying shaders or for handling secondary e.ects (re.ections, refraction) 
in a sensible manner. In contrast to OpenGL, there are many APIs (like RenderMan2, POV-Ray, etc.) that 
allow for taking advantage of all the bene.ts of ray tracing, but which are usually not applicable to 
interactive settings. On the other hand, writing shaders and writing applications are usually two fundamentally 
di.erent (though inter-playing) parts that can be realized with di.erent APIs. As such, it is possible 
to take the best of both worlds, by using a RenderMan like API for writing shaders, and an OpenGL like 
API for writing the application. With this in mind, OpenRT has not been designed as one single graphics 
API, but actually consists of two mostly independent parts: One part is concerned with application programming, 
i.e. specifying geometric primitives, handling transformations and user input, handling textures, loading 
and communicating with shaders (but not writing them!), etc. This part of the API has been designed to 
be as close to OpenGL as possible. The second part of OpenRT describes how shaders are written essentially 
describing a shading language which has inherited much functionality from the RenderMan language, though 
it is not yet as .exible as full RenderMan. 1.1 Shader API Application API Communication All that is 
required to use this concept of having two separate parts of the same API is a minimal interface between 
these two subsystems. In OpenRT, this interface is realized via shader parameters (see below): Shaders 
are written independently from the application, and are stored in shared library .les. Each shader exports 
a description of its shader parameters which control its shading calculations (e.g. the surface material 
properties to be implemented by this shader) but otherwise performs all its computations independently 
from the application. The application API then o.ers calls for loading these shaders, for binding them 
to geometry, for acquiring handles to their parameters, and for writing data to their parameters. For 
a closer description of this process, see below. 2RenderMan was originally not designed to be a ray tracing 
API, but mainly to drive the REYES [Cook87] architecture. However, its .exibility and powerful shading 
language allow for also using it for ray tracing and global illumination, see e.g. [Gritz96, Slusallek95]. 
Having a clear abstraction layer between application interface and shading language it is also possible 
to exchange any of these two parts without a.ecting the other. For example, it would be possible to use 
di.erent shading languages like e.g. Cg [Mark03, Fernando03], OpenGL 2.0 Shading language [Kessenich02], 
or RenderMan [Upstill90, Apodaca90, Apodaka00] for writing the shaders, while still using the same application 
interface. Instead of adopting another API as a parent API, it would also have been possible to create 
a completely new, independent API from scratch. Such approaches however tend to reinvent the wheel, 
and often have problems getting widely accepted (and used) by the users.  2 Application Programming 
Interface As just described the application programming part of OpenRT has been designed to be as close 
to OpenGL as possible. As a rule of thumb, OpenRT o.ers the same calls as OpenGL wherever possible (albeit 
using rt as a pre.x instead of gl ), and only uses di.erent calls where a concept of ray tracing has 
no meaningful match in OpenGL (or vice versa). In particular any calls for specifying geometry (i.e. 
vertices or primitives), transformations, and textures have identical syntax and semantics as OpenGL. 
This simpli.es porting of applications where large parts of the OpenGL code can be reused without changes. 
2.1 Semantical Di.erences Note however that OpenRT is not compatible with OpenGL. In fact, the general 
rule often has been to use the same syntax where possible but not supporting all semantical details that 
do not easily .t a ray tracer. In practice that means that there are several concepts in which OpenRT 
can be used just as a typical user would use OpenGL, even though the actual semantics slightly di.er. 
For example, the viewpoint in OpenGL is usually speci.ed via calls to gluLookAt and gluPerspective. While 
OpenRT o.ers exactly the same functions with the same parameters (consequently called rtLookAt and rtPerspective) 
that also specify the camera position, OpenRT does not exactly follow the OpenGL semantics of having 
these functions change a perspective transform which in OpenGL could also be used for other applications, 
e.g. projective textures. Supporting these semantical details in OpenRT does not make much sense, as 
a ray tracer uses the much more general and .exible concept of a camera shader instead of a perspective 
transformation. Though there are actually several of such low-level semantical di.erences, most are actually 
not very important for practical applications, as they usually appear only for concepts in which the 
ray tracer o.ers a more general concept (such as a freely programmable camera shader) anyway. In fact, 
many users of OpenRT take quite a while to discover the .rst of these di.erences at all. While these 
semantical di.erences obviously make porting more complicated, the two main goals of making OpenRT similar 
to OpenGL are not successfully realized with this approach: First, to the average user, OpenRT appears 
quite similar to OpenGL, and thus is easy to learn, understand, and accept as a new API. Second, none 
of the .exibility, features and functionality of ray tracing have to be sacri.ced in order to be comply 
to OpenGL features that simply don t match. 2.2 Geometry, Objects and Instances The main issue with 
using OpenGL for ray tracing is the fact that no information is available about the changes between successive 
frames. In OpenGL, even unchanged display lists can be rendered di.erently in successive frames due to 
global state changes in-between the frames3 . This however does not map to a ray tracing engine, which 
needs information on which parts of a scene did or did not change since the last frame in order to achieve 
interactive performance (see accompanying document on Handling Dynamic Scenes ). Therefore, instead of 
display lists OpenRT o.ers objects (see Figure 1). Objects encapsulate geometry together with references 
to shaders and their attributes. In contrast to display lists, objects may not have any side e.ects and 
as such changing the de.nition of one object can never a.ect the shape or appearance of any other object. 
On the other hand, global side e.ects are still possible (and usually bene.cial) for the appearance of 
an object: As the primitives only store references to shaders, changing a shader at any later time will 
immediately change the appearance of all the primitives that this shader is bound to4 . Objects are de.ned 
using an rtNewObject(id)/rtEndObject() pair. Each object is assigned a unique ID that is used to instantiate 
it later by a call to rtInstantiateObject(ID). Note how this is (intentionally) very similar to OpenGL 
s way of handling display lists (i.e. glNewList(id),glEndList() and glCallList(id)). Essentially, an 
instance consists of a reference to an object, together with a transformation matrix that this object 
is subject to (see Figure 1). Therefore, reinstantiating an object with a di.erent transformation will 
change the position of the object in the scene (also see the accompanying document on Handling Dynamic 
Scenes ). In order to support unstructured motion, each object can be rede.ned at any time by calling 
rtNewObject with the same object ID. Note that here too, global side e.ects can take place once an object 
is changed: Rede.ning an object automatically changes all the instances that have instantiated the rede.ned 
3Actually, this feature of changing the e.ects of a display list by global state changes often even happens 
in the same frame. 4In OpenRT, the shape of the object (i.e. its triangles and vertices) is captured 
in the kd-tree, and will not be a.ected by any global state changes lateron. The appearance of the object 
if described by its references to the respective shaders (and, of course, by the global light sources 
shaders), and thus can change lateron by changing these respective shaders (see Figure 1. Even though 
this allows for side e.ects, it is conceptually slightly di.erent from side e.ects through global state 
changes in OpenGL. Figure 1: In the RTRT/OpenRT system, all geometry is encapsulated in objects. Each 
object (the grey block) contains the vertices, triangle description records, as well as their local acceleration 
structure. Each triangle contains references to its three vertices, as well as to its globally de.ned 
shader. In fact, each of these objects corresponds exactly to the RTRT Kernel data structures as described 
earlier in this course. In order to take e.ect, objects are instantiated, where each instance consists 
of an object ID and a transformation that this object is subject to (which corresponds to our method 
for handling dynamic scenes, as described in the accompanying document on Handling Dynamic Scenes ). 
The entire scene then consists of the list of objects, the list of shaders, and the list of instances. 
Objects, shaders, and instances reference themselves by ID only, thereby allowing for dynamic and fully 
automatic side e.ects when changing any of these records. object. Note that this API functionality perfectly 
matches the requirements of the previously proposed method to handle dynamic scenes. Here again, the 
detailed semantics of OpenGL display lists and OpenRT objects/instances are slightly di.erent. For example, 
certain special features (such as the above-mentioned global state changes) are not supported by OpenRT 
objects. However, the way that the average user uses a display list (i.e. for encapsulating a certain 
part of a scene graph for faster rendering) corresponds exactly to what an OpenRT object is being used 
for. As such, most users will hardly see the di.erence at all. 2.3 Shading, Shaders and Lighting In 
order not to be limited by the .xed re.ectance model of standard OpenGL, OpenRT does not o.er or emulate 
the OpenGL shading model at all, but rather supports programmable shaders similar to RenderMan [Pixar89]. 
Shaders provide a .exible plug-in mechanism that allows for modifying almost any functionality in a 
ray tracer, e.g. the appearance of objects, the behavior of light sources, the way that primary rays 
are generated, how radiance values are mapped to pixel values, or what the environment looks like. In 
its current version, OpenRT supports all these kinds of programmability by o.ering support for surface 
, light , camera , pixel , and environment shaders, respectively. In terms of the API, shaders are named 
objects that receive parameters and can then be referenced lateron by name or ID, e.g. in order to attach 
( bind ) a surface shader to geometry. The syntax and functionality are essentially the same as the 
functionality to specify texture objects in OpenGL: A set of shader IDs is allocated by rtGenShaders(), 
and a shader with a certain ID is then loaded by rtNewShader(ID). lateron, a previously de.ned shader 
can be activated at any time by rtBindShader(ID), e.g. in order to assign to some geometric primitives. 
Binding shaders to geometry works similarly to how materials properties are assigned in OpenGL: The 
application just binds a certain shader, at which stage all primitives issues after this call get this 
respective shader assigned to them. Once the primitive is issues, the ID of the shader bound to the respective 
triangle is stored with the respective triangle. As changing individual triangles is only possible by 
rede.ning the respective object containing that triangle, this shader-primitive binding can not be changed 
any more without rede.ning the object and re-issueing the primitives with a di.erently bound shader. 
Note however that the triangles actually store only references to their respective shader (in fact, the 
ID of the shader). As such, changing the shader associated to these triangles itself (i.e. loading a 
new shader with the same ID as the original one) thus allows for changing the appearance of the respective 
triangle or object without having to touch any triangle or object at all. 2.3.1 Parameter Binding For 
communicating with the applications, shaders export parameters , each parameter having a symbolic name 
(e.g. di.use ). The application can then register a handle to a speci.c shader parameter (rtParameterHandle()), 
and can write to that parameter with a generic rtParameter() call. Note that the syntax and semantics 
for de.ning and accessing shader parameters is almost exactly the same as proposed in the Stanford shader 
API [Proudfoot01, Mark01]. A shader can specify its parameters to reside in di.erent scopes , i.e. a 
shader can be speci.ed to be stored per vertex, per triangle, per object, or per scene. For example, 
a Phong shader would most likely want to have its material parameters stored per shader, whereas a radiosity 
viewer might want to store certain radiosity values in the vertices5 . These di.erent ways to specify 
parameters allow for optimizing shaders and minimize storage requirements. Using a parameter binding 
by name allows for a very .exible way of having an application communicate with many di.erent kinds of 
shaders. For example, if a VRML viewer [Dietrich04]) follows the convention to always assign the di.use 
component of its VRML material to the di.use parameter of a shader, all that di.erent shaders have to 
do to get access to the applications material model is to implement and export the respective shaders. 
In this example, the same di.use parameter value can be used for both a simple .at shader as well as 
for a shader implementing interactive global illumination. Neither application nor shader have to know 
anything else about each other except that they follow this convention6 . Overhead due to binding by 
name is not an issue: Once the handle to the parameter has been acquired by the application, the assignment 
itself does not have to consider any symbolic names any more. 2.3.2 Lighting The same argument given 
for materials is actually true for lighting: The OpenGL lighting model simply is too limited for a ray 
tracer to be useful. As such, all lighting calculations are implemented via programmable light source 
shaders (see below). For convenience and compatibility, the OpenRT library comes equipped with default 
implementations for all the typical OpenGL (or VRML) light source types like point lights, spot lights, 
directional lights, or ambient lights. Even so, loading these shaders is di.erent from specifying a light 
source in OpenGL (via glLight()), and requires special handling when porting applications.  2.4 A Simple 
Example Obviously, this thesis can not give a complete description of the full OpenRT API with all its 
details. However, for readers being familiar with both OpenGL and with the concepts of a ray tracer, 
the following simple example should give a good overview of how OpenRT is used in practical applications 
7 . // EightCubes.c: // Simple OpenRT example showing // eight rotating color cubes #include <rtut/rtut.h> 
// include GLUT-replacement 5Obviously, it could do this also by storing them in the triangles vertex 
colors 6If the application tries to assign a value to a parameter that a shader never actually exported, 
this invalid assignment will be detected and ignored. This can be very useful for many applications: 
For example, a typical VRML application [Dietrich04] might simply assign the typical VRML material properties 
to each shader (writing to parameters named di.useColor , specularColor , etc.). If the shader writer 
wants to have access to the VRML materials di.useColor , it simply has to export a parameter with that 
name. 7The example given below uses a slightly outdated version of the OpenRT API (pre-1.0). In the most 
up-to-date version (currently 1.0R2), the example would look slightly di.erent. #include <openrt/rt.h> 
// include OpenRT header files RTint createColorCubeObject() { // Create an object for our // vertex-colored 
cube // Step1: Define the *class* of a vertex color shader int cid = rtGenShaderClasses(1); //allocate 
one slot for a shader class rtNewShaderClass(cid, VertexColor , libVertexColor.so ); // load shader class 
 VertexColor from a shared library // Step2: Create one instance of that shader class int sid = rtGenShaders(1); 
// allocate one slot for a shader instance rtNewShader(sid); // creates an instance of the // currently 
bound shader class ... // Step3: Define the object RTint objId = rtGenObjects(1); rtNewObject(objId, 
RT_COMPILE); // Step3a: Bind the shader rtBindShader(sid); // Step3b: Specify transforms rtMatrixMode(RT_MODELVIEW); 
rtPushMatrix(); rtLoadIdentity(); // scale the cube to [-1,1]^3 rtTranslatef(-1, -1, -1); rtScalef(2, 
2, 2); // first cube side // Step3c: Issue geometry rtBegin(RT_POLYGON); rtColor3f(0, 0, 0); rtVertex3f(0, 
0, 0); rtColor3f(0, 1, 0); rtVertex3f(0, 1, 0); rtColor3f(1, 1, 0); rtVertex3f(1, 1, 0); rtColor3f(1, 
0, 0); rtVertex3f(1, 0, 0); rtEnd(); // other cube sides ... rtPopMatrix(); rtEndObject(); // finish 
building the object return objId; // return object s ID to the caller } int main(int argc, char *argv[]) 
{ // Init, open window, etc. // virtually exactly the same as any GLUT program rtutInit(&#38;argc, argv); 
rtutInitWindowSize(640, 480); rtutCreateWindow("Simple OpenRT Example"); // set Camera rtPerspective(65, 
1, 1, 100000); rtLookAt(2,4,3, 0,0,0, 0,0,1); // generate object *once* objId = createColorCubeObject(); 
for (int rot = 0; ; rot++) { // instantiate object eight times, // re-instantitate object for every 
frame // with different transformation rtDeleteAllInstances(); for (int i=0; i<8; i++) { int dx = (i&#38;1)?-1:1; 
int dy = (i&#38;2)?-1:1; int dz = (i&#38;4)?-1:1; // position individual objects rtLoadIdentity(); rtTranslatef(dx,dy,dz); 
rtRotatef(4*rot*dx,dz,dy,dx); rtScalef(.5,.5,.5); rtInstantiateObject(objId); } // start rendering and 
display the image // frame buffer automatically handled by RTUT rtutSwapBuffers(); } return 0; } After 
opening a window, the main function .rst generates a vertex-colored RGB cube with a shader that just 
displays the interpolated vertex color. The cube is generated by .rst loading the VertexColor shader 
class from its shared library .le, creating a single instance of it, and de.ning an object containing 
the geometry for the sides of the triangle. After the object has been completed, the for -loop creates 
eight rotating instances of this cube by re-instantiating each of the eight instances with a di.erent 
transformation in subsequent frames. In fact, this simple example already features most of the important 
features of OpenRT: Specifying objects and instantiating them, issuing geometry, loading shaders, animating 
the objects, specifying the camera, and opening and using a window8 . Being similar to OpenGL, this example 
should be easy to understand and extend by any slightly experienced OpenGL programmer. Of course, this 
is but a very simple example, and real programs will be considerably more complex. For example, a real 
program also has to load textures, specify light shaders, assign shader parameters, aso. Still, using 
advanced ray tracing effects in OpenRT is signi.cantly simpler than generating the same e.ect in an 
OpenGL program: For example, rendering a scene once with global illumination e.ects and once without 
only requires to load a di.erent shader e.g. changing the shader name in rtNewShaderClass from VertexColor 
to InstantGlobalIllumination [Wald04, Benthin03] without having to touch any other code in the program. 
 2.5 Semantical Di.erences to OpenGL As already mentioned before, there are several issues on which OpenRT 
semantically di.ers from OpenGL. 2.5.1 Retained Mode and Late Binding For example, OpenRT di.ers from 
the semantics of OpenGL when binding references. OpenGL stores parameters on its state stack and binds 
references immediately when geometry is speci.ed. This is natural for immediate-mode rendering, but does 
not easily .t a ray tracer. OpenRT instead extends the notion of identi.able objects embedding state, 
similar to OpenGL texture objects. However, this binding is performed only during rendering once the 
frame is fully de.ned. This approach signi.cantly simpli.es the reuse of unchanged geometric objects 
across frames, thus getting rid of the need to rede.ne such unchanged objects every frame. On the other 
hand this means that any changes to an objects or shader de.ned in a previous frame might also a.ect 
the appearance of geometry de.ned earlier. For example, changing a shader parameter will automatically 
change the appearance of all triangles that this shader is bound to, even if those triangles have been 
speci.ed in an earlier frame. Similarly, rede.ning a geometric object will automatically and instantly 
change the shape of all instances of that object, even if those have been de.ned in a previous frame. 
Though this sounds obvious, it can lead to somewhat unexpected results for people being used to OpenGL. 
For example, the code sequence 8Though the example uses RTUT (a GLUT) replacement, it is not required 
to use this interface. It is also possible to directly get access to the ray tracers frame bu.er, and 
to display this e.g. via OpenGL rtGenNewShaderClass( Diffuse , libDiffuse.so ); RTint diffuse = rtParameterHandle( 
diffuse ); rtParameter3f(diffuse, 1.f,0.f,0.f); <triangle A> rtParameter3f(diffuse, 0.f,1.f,0.f); <triangle 
B> rtSwapBuffers(); // render frame will actually result in two triangle that are both green9, which 
is not what an OpenGL-experienced programmer would expect. Thus, these semantics are natural for a ray 
tracer but require careful attention during porting of existing OpenGL applications. More research is 
still required to better resolve the contradicting requirements of rasterization and ray tracing in this 
area. 2.5.2 Unsupported GL Functionality Finally, some OpenGL functions are meaningless in a 3D ray 
tracing context and consequently are not supported in OpenRT. For instance, point and line drawing operations 
are not (currently) supported, and e.ects like stipple bits and .ll modes , as well as 2D frame bu.er 
operations make little sense for a ray tracing engine either. Similarly, fragment operations, fragment 
tests, and blending modes are no longer useful and can be better implemented using surface and pixel 
shaders if necessary. Traditionally ray tracing writes only a single fragment to each pixel in the frame 
bu.er after a complete ray tree has been evaluated. Thus the usual ordering semantics of OpenGL and its 
blending operations that are based on the submission order of primitives are no longer meaningful, either. 
However the lack of this functionality so far has not been a problem for any of the applications already 
written on top of OpenRT: While these unsupported operations are very important for triangle rasterization, 
their main use is for multi-pass rendering. With the powerful shader concept o.ered by OpenRT, multipass-rendering 
is not neccessary any more, so this functionality so far has not been missed yet. 2.5.3 Frame Bu.er 
Handling Instead of writing the pixels to a hardware frame-bu.er OpenRT renders into an application-supplied 
memory region as a frame bu.er. This, however, is only due to the current hardware setup which uses a 
software implementation. For more dedicated ray tracing hardware, this is likely to change. For example, 
an OpenRT application on top of the SaarCOR architecture [Woop05] would most likely have the option to 
use a hardware frame bu.er with direct VGA output 9Both triangles share the same shader. Until the two 
triangles are actually rendered during rtSwapBuffers, that shaders di.use parameter has been set to green. 
Whether or not that parameter has had a di.erent value when specifying triangle A does not make a di.erence. 
instead of always transferring the rendered pixel values back to the application for display. The above 
described late binding 10 also results in up to one frame of additional latency compared to OpenGL. 
The rasterization hardware can already start rendering as soon as the .rst geometric primitive is received 
by the renderer, and renders each primitive directly once it is speci.ed (except for some bu.ering in 
the driver). Once all primitives have been sent to the graphics card, the resulting image as such is 
already .nished. In contrast to this, the ray tracer has to wait for the full scene to be completely 
.nished before it can actually start tracing any rays.  3 OpenRTS Shader Programming Interface As motivated 
in the introduction of this chapter, the shader API in OpenRT (called OpenRTS ) has intentionally been 
designed to be mostly independent of the core API for writing applications. In order to allow for all 
the typical ray tracing e.ects that users are already used to, this API is as similar to RenderMan as 
possible. 3.1 Shader Structure Overview The base class of all shaders in OpenRT is the OpenRT Plug-in 
, i.e. an entity that can be loaded dynamically from a .le, and which o.ers functionality for registering 
itself and exporting its parameters11 . Once a parameter has been exported, the application can lateron 
bind a handle to this parameter, and can assign values to it (see the above OpenRT example). Apart from 
registration and parameter export, all RTPlugins are equipped with an Init and NewFrame method that can 
be overwritten by its subclasses. All other shader types i.e. surface, light, camera and pixel shaders, 
and the rendering object (see below) are derived from this base class, and as such can all be parameterized 
by the application. 3.1.1 Surface Shaders The most common shader types in OpenRT obviously are surface 
shaders. Surface shaders have a virtual Shade function that is expected to return the color of the ray 
it got passed. For the shading operations, the surface shader has access to an extensive API for accessing 
scene data (e.g. vertex positions, normals, or texture coordinates) and for querying data concerning 
the ray and hit point (such as the shading normal, the ray origin and direction, the transformation 
that the hit object is subject to, etc). To di.erentiate these shader 10Sometimes also called frame semantics 
to stress its di.erence from immediate mode semantics 11For convenience, we only speak about C++ classes 
for specifying shaders. Though OpenRT in principle also allows for writing pure C-code shaders, C++ classes 
are actually more natural for implementing a shader concept and as such are usually preferred. API functions 
from those of the core OpenRT API, all these functions (except class methods) start with the pre.x rts 
. 3.1.2 Accessing Light Sources In order to access light sources, a surface shader can query a list 
of light shaders over which it can iterate. The surface shader can then call back to each light shader 
(via rtsIlluminate(...)) to ask it for an illumination sample , or light sample . A light sample consists 
of all 3 values required for doing the lighting calculations in the surface shader: The direction towards 
the light, its distance (possibly in.nite), and the intensity with which it in.uences the hit position. 
Once a light shader has returned its light sample, this sample forms a complete shadow ray description 
with origin, direction, and maximum distance. This shadow ray description can then (but does not have 
to) be used by the surface shader to compute shadows by calling rtsOccluded(...) with this light sample, 
which in turn uses the ray tracing core to cast a shadow ray. If semi-transparent occluders are used, 
the surface shader can also use rtsTransparentShadows() instead of rtsOccluded, which will iterate over 
all the potential occluders along the shadow ray to compute the attenuated contribution of the light 
source. 3.1.3 Casting Secondary Rays Except for casting shadow rays via rtsOccluded() (or via rtsTransparent-Shadows() 
for computing transparent shadows), further secondary rays can also be shot via rtsTrace. This rtsTrace 
shoots an arbitrarily speci.ed ray, determines the hit point, calls the respective shader at that hit 
point, and returns the color computed by that shader. In case the ray did not hit any objects, rtsTrace 
automatically calls the environment shader for computing the color of that ray. While rtsTrace already 
allows for all kinds of rays to be generated and shot, OpenRT o.ers several convenience functions for 
the most often used kinds of secondary rays, like e.g. rtsReflectionRay(), rtsRefractionRay(), rtsTransparencyRay(), 
etc. 3.1.4 Light Shaders Similarly to the Shade function of the surface shaders, light shaders have 
a virtual Illuminate method that can be overridden to write new kinds of light shaders. As described 
above, OpenRT already comes equipped with the most common light source shaders like point, spot, and 
directional lights. For global illumination purposes, OpenRT also contains a few area light source shaders. 
As the surface shader expects illuminate to return a single light sample, these area light shaders take 
a list of pseudo-random numbers that they got passed from the surface shader to create a light sample. 
If a surface sample needs multiple samples from the same light source, it has to call rtsIlluminate several 
times with di.erent random numbers. 3.1.5 Camera Shader Camera shaders work in a similar way as surface 
and light shaders: Each camera shader has a single virtual function for initializing and returning a 
primary ray through the pixel, which will then be cast into the scene via rtsTrace(). 3.1.6 Environment 
Shader Environment shaders are automatically called for all rays traced via rtsTrace that did not hit 
an object. In fact, an environment shader is a shader like any other (i.e. with a Shade() function), 
except that it does not make any sense to query any hit point information within the shading code. 3.1.7 
The Rendering Object Concept Whereas all the surface, light, camera, and environment shaders are typical 
shader types in any programmable shader concept, OpenRT additionally o.ers the concept of a rendering 
object . A rendering object is responsible for actually computing pixel values, and as such enables 
the user to completely change the way that the ray tracer works. Typically, a rendering object will call 
a camera shader to generate a primary ray through each pixel, will call rtsTrace, and will let the respective 
surface shaders do the rest. For special applications however, the rendering object can skip this .exible 
though costly shader concept, and can perform the rendering in a more hardcoded way, e.g. by directly 
using the fast RTRT packet tracing code with a hard-coded shading model. Similarly, many global illumination 
algorithms do not easily .t the above surface shader concept12, but can be quite e.ciently implemented 
as a rendering object. As such, rendering objects greatly extend the range of applications that can be 
realized with OpenRT. However, rendering objects are an advanced concept of OpenRT, and should be used 
with extreme care.  3.2 A Simple Shader Example Obviously, the above explanation is but a very brief 
sketch of the OpenRT shader concept. The complete description of the shader API is beyond the scope of 
this thesis. More information on OpenRT and OpenRT shading can also be found in the respective OpenRT 
manuals and tutorials (see e.g. [Wald]). As for the previously described application part of the OpenRT 
API, how the OpenRT Shader API is actually used in practice can best be described 12For example, the 
above shader concept expects a shader to compute the color of a ray, whereas many global illumination 
algorithms require evaluation of a BRDF with given incoming and outgoing directions (such as bidirectional 
path tracing), or sampling of a BRDF (e.g. for photon shooting or generation of light-and eye-paths). 
with a simple example. As such, the following example implements some simple (though typical) OpenRT 
shaders, one light shader and one surface shader. The surface shader implements a simple di.use shader, 
parameterized by a di.use color and an ambient term). The light shader implements a typical point light 
source consisting of position and intensity, and with a hard-coded quadratic intensity fallo.. 3.2.1 
Simple Di.use Shader class SimpleDiffuse : public RTShader { RTVec3f diffuse; RTVec3f ambient; RTvoid 
Register() { // register parameters rtDeclareParameter("diffuse", PER_SHADER, offsetof(diffuse),sizeof(diffuse)); 
rtDeclareParameter("ambient", PER_SHADER, offsetof(ambient),sizeof(ambient)); } RTvoid Shade(RTState 
*state) { RTVec3f color = ambient; // init with ambient color RTVec3f P; // surface hit position RTVec3f 
N; // normal rtsGetHitPosition(state,P); rtsFindShadingNormal(state,N);// interpolate normal, make // 
sure it faces toward the viewer RTState shadow = *state; // init shadow ray state RTenum *light; RTint 
lights; lights = rtsGlobalLights(&#38;light); for (int i=0;i<lights;i++) { // iterate over all light 
sources rtsIlluminate(light[i],P,&#38;shadow,NULL); if (rtsOccluded(&#38;shadow)) continue; // test for 
shadows Vec3f L; // light direction Vec3f I; // light intensity rtsGetRayDirection(&#38;shadow,L); rtsGetRayColor(&#38;shadow,I); 
RTfloat cosine = N * L; // dot product I *= diffuse; // component-wise mult. color += (cosine * I); 
} rtsReturnColor(state,color); } }; rtsDeclareShader(SimpleDiffuse, SimpleDiffuse); 3.2.2 Simple PointLight 
Shader class SimplePointLight : public RTLight { RTVec3f position; RTVec3f intensity; RTvoid Register() 
{ rtDeclareParameter("position", offsetof(position),sizeof(position)); rtDeclareParameter("intensity", 
offsetof(intensity),sizeof(intensity)); } RTvoid Illuminate(RTState *state) { RTVec3f P; // surface 
hit point rtsGetRayOrigin(state,P); RTVec3f L = position -P; // direction towards light RTfloat distance 
= Lenght(L); Normalize(L); RTVecf3 I = intensity * 1./(distance * distance); // quadratic distance attenuation 
 rtsSetRayDirection(state,L); rtsSetRayMaxDistance(state,length -Epsilon); rtsReturnColor(state,I); 
} }; rtsDeclareShader(SimplePointLight, SimplePointLight);  Taking it all together Having now described 
all the di.erent parts of the API, it is important to brie.y summarize how these di.erent parts actually 
play together. To do this, we will brie.y go step by step through the process of rendering a frame: 
1. First, the application speci.es the scene itself, i.e. it loads and parameterizes shaders, speci.es 
objects and instances, issues geometry, sets the frame bu.er, etc. All the time, the OpenRT implementation 
makes sure that all these calls get executed on all rendering clients, be it the local CPU, remote cluster 
clients, or a hardware architecture. 2. Once the scene is speci.ed, the application calls rtSwapBuffers 
to tell the ray tracer that any scene updates are .nished and that it should render a frame. 3. Upon 
rtSwapBuffers the OpenRT library calls the user-programmable rendering object to actually perform the 
rendering computations. In a single-CPU or shared-memory version, the rendering object will simply render 
a complete frame. In the distributed cluster version, the ray tracer will automatically perform the load 
distribution, load balancing, and communication between the clients and the server. As such, it will 
automatically request each client s respective rendering object to render one or more tiles. 4. The 
rendering object iterates over all the pixels in its frame (respectively tile), and calls the user-programmable 
camera shader to generate a primary ray through that tile. 5. Once a valid primary ray has been generated, 
the rendering object tells OpenRT to trace this ray and compute its color. To do this, OpenRT uses the 
RTRT kernel to trace the ray and .nd a hit point. 6. If no valid hit could be found, OpenRT automatically 
calls the (userprogrammable) environment shader to shade the ray. If a hit was found, OpenRT determines 
the respective surface shader and calls its Shade method. 7. The (user-programmable) surface shader 
uses the shader API to call back to the library while performing its shading computations, e.g. by asking 
OpenRT for the list of active lights, or for the shading normal of the hit point. This also includes 
asking OpenRT for a light sample from a given light shader. OpenRT will then look up that light shader, 
and call its respectiveIlluminate function. 8. The light shader generates this light sample (probably 
with some additional calls into the shader API), and returns this via OpenRT to the surface shader. 
 9. Having processed all light samples, the surface shader may tell OpenRT to shoot some additional secondary 
rays, for which stages 5 9 are recursively repeated13 . 10. Once the entire shading tree has been processed, 
the rendering object has the color of the hit point as determined by the surface shader. It may now do 
some .nal operations on this ray (in the spirit of a pixel  13Obviously, the secondary rays can be shot 
at any time, not only at the end of the shader routine. shader ), e.g. for performing tone mapping. Once 
this is done, it writes the pixel to the frame bu.er. Again, in the distributed version all these pixels 
that have been computed on di.erent machines get automatically communicated back to the server (where 
they can be again manipulated by a user-programmable routine). 11. Once all pixels have been computed, 
the OpenRT library returns the frame bu.er to the application, and returns from the rtSwapBuffers call. 
 12. The application can now display the frame bu.er, and can start over by starting to specify the next 
frame.  Though this is in fact exactly the same ray tracing pipeline that any decent ray tracer uses 
as well, two things are important to note: .rst, the modularity and programmability of this framework, 
and second, the hardware abstraction model used in OpenRT. 4.1 Modularity and Programmability First of 
all, taking a closer look at the above topics makes clear that OpenRT is a highly .exible API in which 
almost all parts are user programmable and can be arbitrarily replaced. Surface, light, environment and 
camera shaders, the rendering mode, and to a certain degree even the parallelization can be changed by 
the user. The OpenRT library in fact provides only the basic infrastructure such as abstracting from 
the distributed architecture, automatic handling of all parallelization and communication, scene management 
etc and nicely glues the di.erent user-programmable parts together. Last but not least, the OpenRT library 
also drives the ray tracing kernel and makes it available to all the respective subsystems. Of course, 
for all these user-programmable parts (such as generating the tiles in the rendering object, generating 
primary rays, or assembling the pixels to the .nal image) there are optimized default routines. Most 
users will never make contact with any of these advanced issues, and will concentrate on writing surface 
and/or light source shaders. 4.2 Hardware Abstraction Model The second important issue to mention is 
how this design carefully abstracts from the underlying hardware. For example, the shader-application 
communication works entirely over the shader parameter concept, and never assumes any direct communication 
between shaders and application. As such, the shaders can either be located on the same machine as the 
application, or could run on another, remote machine that does not even know about the application. It 
would just as well possible that the shaders themselves are not software C++ classes at all, but might 
reside directly on a ray tracing hardware architecture such as SaarCOR. Similarly, the shader API (i.e. 
the API used by the shader programmer) is strictly kept apart from the main OpenRT application API. As 
such, the same application program could be used even if the shader API changes. For example, the SaarCOR 
architecture [Woop05] obviously will not use the same C/C++ shader API that is currently used on the 
CPU14 .  Conclusions and Future Work In summary, OpenRT is a simple yet highly .exible API for realtime 
ray tracing. It is simple to use and .exible enough to support all typical ray tracing e.ects though 
a RenderMan like shading API and a highly modular user-programmable plug-in concept. While the application 
API is not actually semantically 100% compatible to OpenGL, the syntax and semantics for typical programs 
are still very similar. Thus, novice OpenRT users with (some) previous OpenGL experience so far found 
OpenRT easy to learn and use. In fact, many concepts (e.g. shaders) appeared easier and more natural 
to these users. Because of this, OpenRT so far has shown to be well accepted by current users. However, 
highly experienced OpenGL users (which tend to know and use all the subtle details of OpenGL) sometimes 
found it hard to understand that certain concepts are di.erent (e.g. that a rtLookAt call does not have 
any side e.ects on the matrix stack that could then be exploited for projective textures). Though some 
open questions remain, OpenRT has already been used for several practical projects, and so far has been 
very successful for those projects. In particular, it is already being using in real-world industrial 
project, and so far has been very successful. For really widespread use, however, still some more work 
has to be invested: First, it would be desirable if more di.erent implementations of the OpenRT API would 
be available, e.g. on the SaarCOR architecture, on a GPU-based implementation (e.g. [Purcell02]), or 
on an open source ray tracer. Furthermore, it has to be evaluated whether and how the remaining di.erences 
between OpenGL and OpenRT could be bridged. Eventually, it would be a highly interesting option to somehow 
combine OpenGL and OpenRT, e.g. by making OpenRT to be an OpenGL extension. Due to fundamentally di.erent 
semantics as discussed above, it yet unclear if this is possible at all, let alone in which way. An even 
more important issue to work on is an e.cient shading API that supports coherent packets of rays. As 
described in earlier on, the full performance of the RTRT core can only be unleashed if SIMD packet 
traversal with e.cient SIMD shading can be used. In its current form, however, the OpenRT shader API 
actually supports only the shading and tracing of single rays. For those having the actual RTRT sources, 
it is still possible to use both packet 14Though it is still imaginable to use the same shading language 
for both the software and the hardware implementation, e.g. by using di.erent shading language compilers 
(with the same syntax) for the di.erent platforms. traversal code and OpenRT API at the same (e.g. by 
performing the packet traversal code inside a rendering object), but a clean external API does not exist. 
As it is not yet even clear how such packet shading could be e.ciently performed at all, it seemed premature 
to already discuss its API issues. Finally, probably the biggest challenge for the success of OpenRT 
is to create new, powerful interactive applications. This also implies making it available to a much 
wider range of users to actually build these applications. Though all our experiences with OpenRT so 
far have been highly encouraging, only once many di.erent kinds of users will actually use if for solving 
their everyday practical rendering problems will it be possible to objectively evaluate the real potential 
and the limitations of this API. As most applications in fact operate on a much higher level of abstraction 
 usually working on scene graphs rather than directly on the API level making OpenRT available to a 
wider range of users also implies to investigate how scene graphs can be e.ciently mapped to the new 
API. Preliminary work has already investigated how a VRML-based scene graph (the XRML engine [Bekaert01]) 
can be mapped to OpenRT [Wagner02, Dietrich04]. However, an even deeper investigation of this problem 
has yet to be performed. References [Apodaca90] A. Apodaca and M. Mantle. RenderMan: Pursuing the Future 
of Graphics. IEEE Computer Graphics &#38; Applications, 10(4):44 49, July 1990. [Apodaka00] Anthony Apodaka 
and Larry Gritz. Advanced RenderMan: Creating CGI for Motion Pictures. Morgan Kaufmann, 2000. ISBN: 
1558606181. [Bekaert01] Philippe Bekaert. Extensible Scene Graph Manager, August 2001. http://www.cs.kuleuven.ac.be/~graphics/XRML/. 
[Benthin03] Carsten Benthin, Ingo Wald, and Philipp Slusallek. A Scalable Approach to Interactive Global 
Illumination. Computer Graphics Forum, 22(3):621 630, 2003. (Proceedings of Eurographics). [Cook87] 
Robert L. Cook, Loren Carpenter, and Edwin Catmull. The REYES Image Rendering Architecture. Computer 
Graphics (Proceedings of ACM SIGGRAPH 1987), pages 95 102, July 1987. [Dietrich03] Andreas Dietrich, 
Ingo Wald, Carsten Benthin, and Philipp Slusallek. The OpenRT Application Programming Interface Towards 
A Common API for Interactive Ray Tracing. In Proceedings of the 2003 OpenSG Symposium, pages 23 31, 
Darmstadt, Germany, 2003. Eurographics Association. [Dietrich04] Andreas Dietrich, Ingo Wald, Markus 
Wagner, and Philipp Slusallek. VRML Scene Graphs on an Interactive Ray Tracing Engine. In Proceedings 
of IEEE VR 2004, pages 109 116, March 2004. [DirectX] Microsoft DirectX 8.0. http://www.microsoft.com/windows/directx/. 
[Fernando03] Randima Fernando and Mark J. Kilgard. The Cg Tutorial The De.nitive Guide to Programmable 
Real-Time Graphics. Addison-Wesley, 2003. [Gritz96] Larry Gritz and James K. Hahn. BMRT: A Global Illumination 
Implementation of the RenderMan Standard. Journal of Graphics Tools, 1(3):29 47, 1996. [Hanrahan90] Pat 
Hanrahan and Jim Lawson. A language for shading and lighting calculations. Computer Graphics (Proceedings 
of ACM SIGGRAPH), 24(4):289 298, August 1990. ISBN: 0-201-509334. [Humphreys02] Greg Humphreys, Mike 
Houston, Ren Ng, Sean Ahern, Randall Frank, Peter Kirchner, and James T. Klosowski. Chromium: A Stream 
Processing Framework for Interactive Graphics on Clusters of Workstations. ACM Transactions on Graphics 
(Proceedings of SIGGRAPH 2002), 21(3):693 702, July 2002. [Kessenich02] John Kessenich, Dave Baldwin, 
and Randi Rost. The OpenGL Shading Language, Version 1.051, February 2002. Available from http://www.3dlabs.com/support/developer/ogl2/downloads/ShaderSpecV1.051.pdf. 
[Mark01] William Mark. Shading System Immediate-Mode API, v2.1. In SIGGRAPH 2001 Course 24 Notes Real-Time 
Shading, August 2001. [Mark03] William R. Mark, R. Steven Glanville, Kurt Akeley, and Mark J. Kilgard. 
Cg: A System for Programming Graphics Hardware in a C-like Language. ACM Transactions on Graphics (Proceedings 
of ACM SIGGRAPH), 22(3):896 907, 2003. [Neider93] Jackie Neider, Tom Davis, and Mason Woo. OpenGL Programming 
Guide. Addison-Wesley, 1993. ISBN 020163-2748. [OpenSG01] OpenSG-Forum. http://www.opensg.org, 2001. 
[OSG] OpenSceneGraph. http://www.openscenegraph.org. [Pixar89] Pixar. The RenderMan Interface. San Rafael, 
September 1989. [Proudfoot01] Kekoa Proudfoot, William Mark, Svetoslav Tzvetkov, and Pat Hanrahan. A 
Real-Time Procedural Shading System for Programmable Graphics Hardware. In Proceedings of ACM SIG-GRAPH, 
pages 159 170, August 2001. [Purcell02] Timothy J. Purcell, Ian Buck, William R. Mark, and Pat Hanrahan. 
Ray Tracing on Programmable Graphics Hardware. ACM Transactions on Graphics, 21(3):703 712, 2002. (Proceedings 
of SIGGRAPH 2002). [Rohlf94] John Rohlf and James Helman. IRIS Performer: A High Performance Multiprocessing 
Toolkit for Real-Time 3D Graphics. Computer Graphics, 28(Annual Conference Series):381 394, July 1994. 
[Slusallek95] Philipp Slusallek, Thomas P.aum, and Hans-Peter Seidel. Using Procedural RenderMan Shaders 
for Global Illumination. In Computer Graphics Forum (Proc. of Eurographics 95, pages 311 324, 1995. [Upstill90] 
Steve Upstill. 1990. The RenderMan Companion. Addison-Wesley, [Wagner02] Markus Wagner. Development of 
a Ray-Tracing-Based VRML Browser and Editor. Master s thesis, Computer Graphics Group, Saarland University, 
Saarbrucken, Germany, 2002. [Wald] Ingo Wald and Tim Dahmen. OpenRT User Manual. Computer Graphics Group, 
Saarland University. http://www.openrt.de. [Wald02] Ingo Wald, Carsten Benthin, and Philipp Slusallek. 
OpenRT -A Flexible and Scalable Rendering Engine for Interactive 3D Graphics. Technical report, Saarland 
University, 2002. Available at http://graphics.cs.uni-sb.de/Publications. [Wald03] Ingo Wald, Timothy 
J. Purcell, Jorg Schmittler, Carsten Benthin, and Philipp Slusallek. Realtime Ray Tracing and its use 
for Interactive Global Illumination. In Eurographics State of the Art Reports, 2003. [Wald04] Ingo Wald. 
Realtime Ray Tracing and Interactive Global Illumination. PhD thesis, Computer Graphics Group, Saarland 
University, 2004. Available at http://www.mpisb.mpg.de/~wald/PhD/. [Wernecke94] Josie Wernecke. The 
Inventor Mentor. Addison-Wesley, 1994. ISBN 0-20162-495-8. [Woop05] Sven Woop, Joerg Schmittler, and 
Philipp Slusallek. RPU: A Programmable Ray Processing Unit for Realtime Ray Tracing. Proceedings of ACM 
SIGGRAPH, (to appear), 2005. 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198761</article_id>
		<sort_key>22</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[Writing OpenRT shaders]]></title>
		<page_from>22</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198761</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198761</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP24038535</person_id>
				<author_profile_id><![CDATA[81322509130]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Igno]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wald]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MPII Saarbruecken]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
  W r i t i n g O p e n R T S h a d e r s   Basics  The Shader Framework  The Ray State Concept 
  Base classes: RTShader, RTLightShader,   A Simple Example  Declaring the shader  Writing its shader 
function   Advanced Shading Issues  I m p o r t a n t N o t e   The following information is explicitly 
meant for you to play around and gather your own experiences with OpenRT The best way to learn it is 
to play with it  The easiest way to writing your own shaders is  Go to www.openrt.de/Sig05  Download 
and install your noncommercial copy of OpenRT Using the access information provided to you  Follow 
the shader tutorial there to write your own shader(s)  Test your scene using the inView front end  
 Please: Direct all questions to the specified mailing list   W r i t i n g O p e n R T S h a d e 
r s   Basics  The Shader Framework  The Ray State Concept  Base classes: RTShader, RTLightShader, 
  A Simple Example  Declaring the shader  Writing its shader function   Advanced Shading Issues 
  B a s i c s : T h e S h a d e r F r a m e w o r k  Important: OpenRT is NOT a monolithic system Instead: 
Much functionality in special modules/plugins .OpenRT consists of different layers Ray Tracing core 
(define geometry, shoot indiv. rays)  The shader framework Surface, light, and camera shaders, rendering 
object,  Extended shader packages  For implementing special functionality  E.g., default shaders, 
RTX, instant global illumination,    S h a d e r F r a m e w o r k G e n e r a l   OpenRT core: 
pure C interface OpenRTS shader framework: C++  Shader plugins compiled to/loaded from .so s/DLLs 
Automatically done by OpenRT upon rtShaderClass( )  All classes in shader framework derived from RTPlugin 
 Encapsulates infrastructure to  register itself and parameters to the OpenRT system  dynamically 
load from shared libraries  work within OpenRT s parallelization framework  S h a d e r F r a m e 
w o r k R T P l u g i n b a s e c l a s s  The RTPlugin base class class RTPlugin { virtual void NewFrame(); 
virtual void Init(); virtual void Register(); };  Init(): Initialize self directly upon loading  NewFrame(): 
Called once per frame Allows for doing per frame precomputations  Register(): Register shader parameters 
to OpenRT  Shader parameters: See part I on programming OpenRT  Register via rtsDeclareParameter( ) 
(see example lateron)   S h a d e r F r a m e w o r k T h e R e n d e r i n g O b j e c t   Basic 
ingredient is the Rendering Object  Main functionality: Render complete frame  Standalone implementation 
::RenderFrame( )  Distributed implementation ::RenderTile( )   Typical realization:  Generate initial 
ray state  Call camera shader for each pixel  Shoot the ray, and call respective surface shader (or 
environment shader)    Note: There can be only one rendering object active at any time   All other 
shaders called only indirectly  S h a d e r F r a m e w o r k T h e R e n d e r i n g O b j e c t 
  Don t need to know details on rendering object Can usually use existing rendering object Concentrate 
on writing surface/light shaders  Note: Rendering objects can do MUCH more  Can basically do anything 
within the rendering object Frameless rendering, render cache, rasterization, adaptive sampling, frame 
post processing (tonemapping, filtering),  But: no details here    S h a d e r F r a m e w o r k 
C a m e r a S h a d e r s  Camera shader Purpose: Compute primary ray class RTCameraShader : public 
RTPlugin { virtual void InitPrimaryRay(RTstate state); };  Typical use: Straightforward Simply sets 
origin, direction, and maxdist of state  Default PerspectiveCamera available.  Advanced camera shader 
examples  Fisheye camera, Stereo camera, Depth of field,  S h a d e r F r a m e w o r k S u r f a c 
e S h a d e r s   Purpose: Given a ray (state), compute it s color  Realization: RTShader class  
class RTLight : public RTPlugin { virtual void Shade(RTstate state); };  Surface shader computes color 
of the given ray Including shooting secondary rays, calling light shaders, etc.  and returns color 
via rtsReturnColor(state,color);  Writing a new shader: Derive from RTShader, overwrite Shade() function 
 S u r f a c e S h a d e r s S h a d i n g a r a y   Can use arbitrary C/C++ code  Helper classes 
available (Vector, Matrix, )  Use rts functions to operate on given state  rtsFindShadingNormal(),rtsGetHitDistance(),rtsGetShader(), 
 Lighting: Query incident light onto the hitpoint  By calling rtsIlluminate(lightID,state,ptr)  Surface 
shader can pass additional data to light shader (ptr)   rtsIlluminate() returns light samples for given 
hitpoint  Consisting of direction, distance, and incident radiance Can check shadow/visibility of light 
via rtsOccluded(state) S h a d e r F r a m e w o r k L i g h t S h a d e r s   Purpose: Deliver light 
samples to surface shaders  On rtsIlluminate , OpenRT calls respective light shader  Light shader: 
Derived from RTLightShader  class RTLight : public RTPlugin { virtual void Illuminate(RTstate state, 
void *ptr); };  RTLight::Illuminate(state,ptr) Compute light sample, return in state  Typical pre 
defined light shaders available  RTPointLight, RTSpotLight, RTDirectionalLight,  S h a d e r F r a 
m e w o r k E n v i r o n m e n t S h a d e r s  Environment shader Purpose: Shade rays that didn t 
hit anything class RTEnvironmentShader : public RTPlugin { virtual void Shade(RTstate state); };  Called 
automatically by rtsTrace if no hit was found  Default environment shader already included  Simply 
returns color from an (HDR) environment map A S i m p l e E x a m p l e   So far: Have discussed concepts 
on abstract level.  Now: Give practical examples  Steps to perform to implement a shader 1. Derive 
a new shader class from RTShader 2. Declare, init, and export its shader parameters 3. Implement its 
Shade() function 4. Compile it to a shared library   E x a m p l e 1 : S i m p l e H e a d l i g 
h t s h a d e r  Very simple shading model: C = (I_amb + (1-I_amb)*(N.D))*Rd Rd: diffuse surface color 
(three floats) I amb: ambient intensity N: surface normal (shading normal) D: Ray direction  E x a m 
p l e 1 : S i m p l e H e a d l i g h t s h a d e r  Step 1: Declaring the shader class // include 
base header files #include OpenRTS/RTS++.hxx #include OpenRTS/RTShader.hxx struct RTSimple : public 
RTShader { float ambient; R3 diffuseColor; void Init() { ambient .3; diffuseColor .5; }; }; // declare 
under the shader class name Simple rtDeclareShader(RTSimple,Simple); E x a m p l e 1 : S i m p l e 
H e a d l i g h t s h a d e r  Step 2: Declaring the shader s parameters void RTSimple::Register() 
{ rtDeclareParameter( diffuseColor , PER SHADER, memberoffset(diffuseColor), sizeof(diffuseColor)); 
rtDeclareParameter( ambient , PER SHADER, memberoffset(ambient), sizeof(ambient)); } E x a m p l e 1 
: S i m p l e H e a d l i g h t s h a d e r  Step 3: Implementing the Shade() function void RTSimple::Shade(RTstate 
state) { R3 C,D,N; // query ray s direction and hit s normal rtsGetRayDirection(state,D); Normalize(D); 
// might not be necessary rtsFindShadingNormal(state,N); //compute ray s color C (ambient + (1 ambient)*(N*D)) 
* diffuseColor;  // return color to calling shader (via state) rtsReturnColor(state,C); }; E x a m 
p l e 1 : S i m p l e H e a d l i g h t s h a d e r  Step 4: Compile to a shared library Save to 
Simple.cxx  Compile as shared library  Intel ICC8.1 icc Simple.cxx o libSimple.so shared rdynamic O3 
I < >  GCC (3.4.2 and higher) g++ Simple.cxx o libSimple.so shared fPIC O3 I < >  Make sure to pass 
the correct include directories   MAKE SURE THE .SO IS IN YOUR LIBRARY PATH!  Note: Closely follow 
www.openrt.de/SIG05  Information will be continually updated E x a m p l e 1 : S i m p l e H e a d 
l i g h t s h a d e r  (Step 5: Declare shader to frontend application) Only if you re not using 
your own frontend  For inView: Create SimpleShaderInfo.wrl #VRML97 utf8 ORTShaderInfo {  name Simple 
file libSimple.so options [ color diffuseColor .5 .5 .5 ] } (see inView documentation for details)  
Done: Use the shader in your application ./inView SimpleShaderInfo.wrl test.wrl shader Simple E x a m 
p l e 2 : A t y p i c a l P h o n g S h a d e r   Previous example was very simple  Now: Add lights 
and shadows  First: Declare SimplePhong class as before  Declare diffuseColor , specularColor , exponent 
, etc  Will only consider the Shade() function   E x a m p l e 2 : A t y p i c a l P h o n g S h a 
d e r  The shade function: virtual void Shade(RTstate state) { // initialize C ambientColor; rtsFindHitPosition(state,hitPos); 
rtsFindShadingNormal(state,normal); // create new state for light samples RTState lightSample; rtsInitState(state,&#38;lightSample); 
 // query light sources: RTvoid **light; int lights rtsGlobalLights(&#38;light);  E x a m p l e 2 : 
A t y p i c a l P h o n g S h a d e r  Now, iterate over light sources: for (int i 0;i<lights;i++) 
{ rtsSetRayOrigin(&#38;lightSample,hitPos) bool ok rtsIlluminate(&#38;lightSample,light[i],NULL); if 
(!ok) // maybe light points away from hitpoint continue; // <MARK>  // Query light sample direction 
and radiance R3 L,I; rtsGetColor(&#38;lightSample,I); rtsGetRayDirection(&#38;lightSample,L); // do the 
actual shading C + diffuseColor * (N * L) + .. E x a m p l e 2 : A t y p i c a l P h o n g S h a d e 
r  Adding ray traced shadows Extremely simple: Just replace <MARK> with // Check for shadow if (rtsOccluded(&#38;lightSample)) 
continue;  That s all there is to do Adding reflections/refraction: As simple as C + rtsTrace(secondaryRayState); 
(with correctly set secondary ray)  P e r f o r m a n c e C o n s i d e r a t i o n s  First of all: 
Shading is COSTLY Often more costly than tracing the rays .Take care to write optimized shader code 
!!! The fastest ray tracing core can t help shading cost Minimize shading overhead Minimize number of 
rays shot P e r f o r m a n c e C o n s i d e r a t i o n s M i n i m i z i n g # o f r a y s s h o 
t  Tracing rays is fast, but cost is linear in #rays CHECK before you trace a ray Don t trace shadow 
rays to lights that won t be used, anyway (e.g., light on wrong side, light too far away, )  Don t calculate 
shadows on a black (or transparent) surface   For more complex shaders (glass, transparency)  Tracking 
ray s pixel contribution can avoid explosion of ray tree (already done in RTX shader package)  But: 
tracking itself is costly    P e r f o r m a n c e C o n s i d e r a t i o n s M i n i m i z i n 
g S h a d i n g O v e r h e a d   Avoid all operations that don t have to be done  I.e., don t use 
C + max(0,N*L) * PhongShade(N,L)  But rather if (N*L > 0.f) C +   Take care of small optimizations 
as well:  Float vs. double, use cosf/sqrtf, not cos/sqrt  Always write float constants as 1.0f (not 
just 1 ) etc  Use inline s and const s for helper functions  Compile with optimization ( O3 at least) 
and without debug options  For VERY compute intensive shaders: Use SIMD   Finally: Profile, optimize, 
test, profile, optimize, test,  S h a d i n g i n O p e n R T S u m m a r y   Have described overall 
OpenRT architecture  Shader framework  Interoperation of different shader types   Have described 
complete workflow for writing OpenRT shaders (based on simple example)  Have briefly discussed performance 
issues Entirely sufficient for writing your own shaders  S h a d i n g i n O p e n R T S u m m a r 
y  The best way to really understand how it works: Have a look at the shader tutorials http://www.openrt.de/SIG05 
 Write your own shaders  PLAY with it !  
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198762</article_id>
		<sort_key>23</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[Realtime ray tracing for current and future games]]></title>
		<page_from>23</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198762</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198762</url>
		<abstract>
			<par><![CDATA[Recently, realtime ray tracing has been developed to the point where it is becoming a possible alternative to the current rasterization approach for interactive 3D graphics. With the availability of a first prototype graphics board purely based on ray tracing, we have all the ingredients for a new generation of 3D graphics technology that could have significant consequences for computer gaming. However, hardly any research has been looking at how games could benefit from ray tracing.In this paper we describe our experience with two games: The adaption of a well known ego-shooter to a ray tracing engine and the development of a new game especially designed to exploit the features of ray tracing. We discuss how existing features of games can be implemented in a ray tracing context and what new effects and improvements are enabled by using ray tracing. Both projects show how ray tracing allows for highly realistic images while it greatly simplifies content creation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P384462</person_id>
				<author_profile_id><![CDATA[81100134343]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J&#246;rg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schmittler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P837799</person_id>
				<author_profile_id><![CDATA[81322503299]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pohl]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P385085</person_id>
				<author_profile_id><![CDATA[81100538817]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Tim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dahmen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P837797</person_id>
				<author_profile_id><![CDATA[81322508910]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Christian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vogelgesang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40024383</person_id>
				<author_profile_id><![CDATA[81100159926]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Philipp]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Slusallek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Saarland University, Saarbr&#252;cken, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{BWS03} Benthin, C, Wald, I., und Slusallek, P.: A Scalable Approach to Interactive Global Illumination. Computer Graphics Forum. 22(3):621--630. 2003. (Proceedings of Eurographics).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{DWBS03} Dietrich, A., Wald, I., Benthin, C, und Slusallek, P.: The OpenRT Application Programming Interface - Towards A Common API for Interactive Ray Tracing. In: Proceedings of the 2003 OpenSG Symposium. S. 23--31. Darmstadt, Germany. 2003. Eurographics Association.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383549</ref_obj_id>
				<ref_obj_pid>2383533</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{GWS04} G&#252;nther, J., Wald, I., und Slusallek, P.: Realtime caustics using distributed photon mapping. In: To appear in Proceedings of Eurographics Symposium on Rendering. 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{SLS03} Schmittler, J., Leidinger, A., und Slusallek, P.: A Virtual Memory Architecture for Real-Time Ray Tracing Hardware. Computer and Graphics, Volume 27, Graphics Hardware. S. 693--699. 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1058143</ref_obj_id>
				<ref_obj_pid>1058129</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{SWWS04} Schmittler, J., Woop, S., Wagner, D., und Slusallek, P.: Realtime Ray Tracing of Dynamic Scenes on an FPGA Chip. In: To appear in Proceedings of the ACM SIGGRAPH/Eurographics Conference on Graphics Hardware. 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{Wa04} Wald, I.: Realtime Ray Tracing and Interactive Global Illumination. PhD thesis. Computer Graphics Group, Saarland University. 2004. Available at http://www.mpi-sb.mpg.de/~wald/PhD/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1081418</ref_obj_id>
				<ref_obj_pid>1081407</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{WBS03} Wald, I., Benthin, C, und Slusallek, P.: Distributed Interactive Ray Tracing of Dynamic Scenes. In: Proceedings of the IEEE Symposium on Parallel and Large-Data Visualization and Graphics (PVG). 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383545</ref_obj_id>
				<ref_obj_pid>2383533</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{WDS04} Wald, I., Dietrich, A., und Slusallek, P.: An interactive out-of-core rendering framework forvisualizing massively complex models. In: To appear in Proceedings of Eurographics Symposium on Rendering. 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Realtime Ray Tracing for Current and Future Games Jorg Schmittler, Daniel Pohl, Tim Dahmen, Christian 
Vogelgesang, and Philipp Slusallek {schmittler,sidapohl,mor.el,chrvog,slusallek}@graphics.cs.uni-sb.de 
Abstract: Recently, realtime ray tracing has been developed to the point where it is becoming a possible 
alternative to the current rasterization approach for interactive 3D graphics. With the availability 
of a .rst prototype graphics board purely based on ray tracing, we have all the ingredients for a new 
generation of 3D graphics technology that could have signi.cant consequences for computer gaming. However, 
hardly any research has been looking at how games could bene.t from ray tracing. In this paper we describe 
our experience with two games: The adaption of a well known ego-shooter to a ray tracing engine and the 
development of a new game especially designed to exploit the features of ray tracing. We discuss how 
existing features of games can be implemented in a ray tracing context and what new effects and improvements 
are enabled by using ray tracing. Both projects show how ray tracing allows for highly realistic images 
while it greatly simpli.es content creation. 1 Introduction Ray tracing is a well-known method to achieve 
high quality and physically-correct images, but only recently its performance was improved to the point 
that it can now also be used for interactive 3D graphics for highly complex and dynamic scenes including 
global illumination [Wa04, WDS04, WBS03, BWS03, GWS04]. While the above systems still rely on distributed 
computing to achieve realtime performance, a .rst prototype of a purely ray tracing based graphics chip 
[SWWS04] shows that ef.cient hardware implementations are indeed possible and provide many advantages 
over rasterization This encourages the research on possible effects of ray tracing technology for computer 
games. In this paper we describe our experiences with two games which use ray tracing for rendering and 
the physics engine. 2 Computer Games Based on Ray Tracing Ray tracing and rasterization technology are 
basically two different algorithms to solve the same problem: the visibility calculation. While rasterization 
uses a set of potential visible triangles which are rendered sequentially into the Z-buffer, ray tracing 
starts at the virtual camera and for every pixel shoots rays into the scene. Since rays are terminated 
as soon as they hit an object, the visibility calculation is highly ef.cient and fully output sensitive. 
As shading is performed after visibility calculation, you only pay for what you see. While ray tracing 
has access to the entire scene database and only reads what it needs to, current rasterization technology 
operates on a stream of independent triangles sent by the application. Therefore it cannot ef.ciently 
and accurately render global effects such as shadows, re.ections, and indirect illumination on demand, 
i.e. after .nding out that these effects are actually visible. Every effect has to be split into several 
render passes by the application and relies on tricks and approximations (e.g. shadow and re.ection maps) 
which are inaccurate and break down in many situations (e.g. multiple re.ections). In contrast ray tracing 
trivially supports global effects by shooting on demand additional rays for shadows, re.ections, and 
refractions. This output sensitivity allows for ef.ciently rendering even highly complex scenes. For 
every pixel this recursive approach automatically combines all visible shading effect correctly without 
involving the application or the need for separate rendering passes. Even memory management of the graphics 
card s memory is handled automatically by the ray tracer [SLS03]. Basic shading computations are the 
same as for rasterization. Thus, the same shaders (e.g. for texture .ltering and calculation of light 
intensities) and image .lters (e.g. for antialiasing) can be used. However, ray tracing allows to adaptively 
shoot new rays as required. While both techniques can eventually achieve similar results, this requires 
complex and costly operation by both the graphics hardware and the application. In contrast ray tracing 
handles most effects automatically and internally. This greatly simpli.es content creation for games, 
which is increasingly becoming a limiting factor for the gaming industry. 2.1 Traditional Ego Shooter 
We started our research with adapting the existing, well-known ego-shooter Quake 3: Arena by Id-Software 
to use ray tracing for rendering. We concentrated our efforts on adapting shading effects and general 
game management because most otherwise dif.cult rendering effects (e.g. shadows and re.ections) were 
automatically handled by the ray tracer. The game engine was written from scratch and supports player 
and bot movement including shooting and jumping, collision detection, and many special effects like 
jumppads and teleporters. The main development was done by a single student in less than six months. 
The game engine interfaces with the ray tracer through the OpenRT-API [DWBS03], which is very close to 
the OpenGL. OpenRT manages all ray tracing events fully transparent to the application, making it unaware 
of the underlying ray tracing implementation, which may run on a single computer, a cluster of PCs, or 
a dedicated ray tracing hardware. Figure 1 shows several example images from the game with many shading 
effects. The engine supports all of the standard effects of traditional computer games like dynamic 
placement of (blood) splats, texture animation and blending, volumetric fog, and pre-computed light 
maps (if desired). Figure 1: Screen shots of the ray traced version of Quake 3: Arena. Screen shots 
of live game play. While most images are taken from the PC-cluster-based version, the right-most image 
was rendered on the hardware prototype (1024x768, 32bit). All images were rendered at fully interactive 
rates of 5-20 fps. Some of the effects supported by ray tracing: a portal providing a view into distant 
places, light effects in the power-up, and correct re.ections in the ammo-box and on some spheres. More 
ray tracing speci.c effects like dynamic lighting including shadows and physicallycorrect re.ections 
and refractions are trivially supported by simply specifying the corresponding material attributes. 
This also holds for camera portals and surveillance cameras, which are automatically rendered correctly 
by default even if they recursively see each other. Since ray tracing is output sensitive there is no 
need for any level-of-detail mechanism to reduce scene complexity. This allows for highly crowded scenes 
with many players, monsters, and complex trees in a forest. Furthermore as ray tracing ef.ciently supports 
multiple instantiations, even crowded scenes have negligible memory requirements and scene complexity 
has only a minimal impact on performance. In summary, we were able to support all the traditional effects 
of Quake 3 while most effects were signi.cantly simpler to implement. Looking at newer engines such as 
Unreal 3, we still see no effects that could not be supported easily by ray tracing. 2.2 Novel Game 
Design for Ray Tracing Ray tracing offers new ways to design a game which led us to the development of 
Oasen game. Oasen operates in a fully open space on a huge world consisting of several islands and includes 
day time simulation with changing sky and light situations (see Figure 2). The player takes the role 
of a salesman on a .ying carpet visiting different places, buying and selling goods while .ghting off 
other players or bots. While ray tracing is basically a method for visibility calculation, we were also 
able to use it for the physics engine, acoustics, and collision detection. Similar to a radar system 
it uses rays to determine the distance to nearby objects. By reusing the existing fast ray tracer on 
the original geometry we avoided having to build special algorithms and data structures for those tasks. 
No level-of-detail mechanisms, clipping-planes, or fog have been used to reduce scene complexity, since 
ray tracing ef.ciently handles huge amounts of geometry and objects automatically. This avoids any artifacts 
such as popping and results in smooth .ights. Huge numbers of light sources are ef.ciently handled by 
exploiting the restricted range of illumination of each light and organizing them in a spatial index 
structure. For each pixel we can then ef.ciently locate light sources that contribute to its illumination, 
allowing physically-correct illumination at very low costs even in the presents of hundreds of visible 
light sources. Figure 2: Screen shots of the ray tracing based game Oasen. Typical life screen shots 
showing correct shadows, nicely rendered water including caustic-effects, and volumetric clouds. The 
two left-most images show the inherent scene management capability of ray-tracing: vegetation and buildings 
add 40-times triangles over the basic landscape geometry while the performance drops by less than 10% 
 without the use of any level-of-detail or clipping techniques.  3 Conclusion In this paper we brie.y 
summarized the experience we gained from implementing two games using a ray tracing based game engine. 
We have been able to easily port all of the exiting rendering effects to ray tracing, where their implementation 
has been much simpler and more ef.cient. Furthermore ray tracing adds many novel aspects that help designing 
more realistic and compelling game contents. Any shading effect can be approximated with rasterization, 
but every combination of shaders requires special support and complex programming for both the application 
and shaders. In contrast, ray tracing automatically handles all shader interaction allowing for plugand-play 
use of arbitrary shading effects. As a result, content creation is greatly simpli.ed and game designers 
can again concentrate on the content and game experience instead of working around the many limitations 
of current technology. Furthermore ray tracing offers new ways to design the physics engine including 
collision detection and acoustics. The main limitation of ray tracing has been its still limited support 
for dynamic scenes [WBS03], but ongoing research will soon remove this constraint. Even though LOD mechanisms 
were not needed for supporting complex scenes, new approaches are required to ef.ciently handle resulting 
geometric aliasing. The highly realistic and physically-correct images together with a greatly simpli.ed 
rendering engine make ray tracing an interesting technology for future computer games. Today, the system 
requirements for ray tracing based games seem to be very high as a cluster of PCs forming a virtual CPU 
with 30 GHz is required to render the images present here at interactive rates (5-20 fps for 640x480 
pixels). But future hardware will allow to have even higher performance on a single PC board similar 
to today s graphics cards [SWWS04]. This encourages further research on ray tracing and computer games. 
More details and videos are available at http://graphics.cs.uni-sb.de/RTGames/ Literatur [BWS03] Benthin, 
C., Wald, I., und Slusallek, P.: A Scalable Approach to Interactive Global Illumination. Computer Graphics 
Forum. 22(3):621 630. 2003. (Proceedings of Eurographics). [DWBS03] Dietrich, A., Wald, I., Benthin, 
C., und Slusallek, P.: The OpenRT Application Programming Interface Towards A Common API for Interactive 
Ray Tracing. In: Proceedings of the 2003 OpenSG Symposium. S. 23 31. Darmstadt, Germany. 2003. Eurographics 
Association. [GWS04] GRealtime caustics using distributed photon unther, J., Wald, I., und Slusallek, 
P.: mapping. In: To appear in Proceedings of Eurographics Symposium on Rendering. 2004. [SLS03] Schmittler, 
J., Leidinger, A., und Slusallek, P.: A Virtual Memory Architecture for Real-Time Ray Tracing Hardware. 
Computer and Graphics, Volume 27, Graphics Hardware. S. 693 699. 2003. [SWWS04] Schmittler, J., Woop, 
S., Wagner, D., und Slusallek, P.: Realtime Ray Tracing of Dynamic Scenes on an FPGA Chip. In: To appear 
in Proceedings of the ACM SIGGRAPH/Eurographics Conference on Graphics Hardware. 2004. [Wa04] Wald, 
I.: Realtime Ray Tracing and Interactive Global Illumination. PhD thesis. Computer Graphics Group, Saarland 
University. 2004. Available at http://www.mpisb.mpg.de/~wald/PhD/. [WBS03] Wald, I., Benthin, C., und 
Slusallek, P.: Distributed Interactive Ray Tracing of Dynamic Scenes. In: Proceedings of the IEEE Symposium 
on Parallel and Large-Data Visualization and Graphics (PVG). 2003. [WDS04] Wald, I., Dietrich, A., und 
Slusallek, P.: An interactive out-of-core rendering framework forvisualizing massively complex models. 
In: To appear in Proceedings of Eurographics Symposium on Rendering. 2004. 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198763</article_id>
		<sort_key>24</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[Adaptive frameless rendering]]></title>
		<page_from>24</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198763</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198763</url>
		<abstract>
			<par><![CDATA[We propose an adaptive form of frameless rendering with the potential to dramatically increase rendering speed over conventional interactive rendering approaches. Without the rigid sampling patterns of framed renderers, sampling and reconstruction can adapt with very fine granularity to spatio-temporal color change. A sampler uses closed-loop feedback to guide sampling toward edges or motion in the image. Temporally deep buffers store all the samples created over a short time interval for use in reconstruction and as sampler feedback. GPU-based reconstruction responds both to sampling density and space-time color gradients. Where the displayed scene is static, spatial color change dominates and older samples are given significant weight in reconstruction, resulting in sharper and eventually antialiased images. Where the scene is dynamic, more recent samples are emphasized, resulting in less sharp but more up-to-date images. We also use sample reprojection to improve reconstruction and guide sampling toward occlusion edges, undersampled regions, and specular highlights. In simulation our frameless renderer requires an order of magnitude fewer samples than traditional rendering of similar visual quality (as measured by RMS error), while introducing overhead amounting to 15% of computation time.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Raytracing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Virtual reality</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010374</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Ray tracing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P437427</person_id>
				<author_profile_id><![CDATA[81100598236]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Abhinav]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dayal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Northwestern University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24011637</person_id>
				<author_profile_id><![CDATA[81100188094]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Cliff]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Woolley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Virginia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39040047</person_id>
				<author_profile_id><![CDATA[81100375996]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Benjamin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Watson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Northwestern University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14056692</person_id>
				<author_profile_id><![CDATA[81100131290]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Luebke]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Virginia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>336417</ref_obj_id>
				<ref_obj_pid>336414</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{BDT99} Bala, K., Dorsey, J., Teller, S. 1999. Radiance interpolants for accelerated bounded-error ray tracing. ACM Trans. Graph, 18, 3, 213--256.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882318</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{BWG03} Bala, K., Walter, B., Greenberg, D. P. 2003. Combining edges and points for interactive high-quality rendering. ACM Trans. Graph., 22, 3, 631--640 (Proc. ACM SIGGRAPH).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15889</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{BFGS86} Bergman, L., Fuchs, H., Grant, E., Spach, E. 1986. Image rendering by adaptive refinement. Proc. ACM SIGGRAPH, 29--37.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192195</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{BFMS94} Bishop, G., Fuchs, H., McMillan, H., Scher Zagier, E. J. 1994. Frameless rendering: double buffering considered harmful. Proc. ACM SIGGRAPH, 175--176.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569052</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{CHH02} Carr, N. A., Hall, J. D., Hart, J. C. 2002. The ray engine. Proc. ACM SIGGRAPH/Eurographics Graphics Hardware, 37--46.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882431</ref_obj_id>
				<ref_obj_pid>882404</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{CT03} Choudhury, P., Tumblin, J. 2003. The trilateral filter for high contrast images and meshes. Proc. Eurographics Workshop on Rendering, 186--196.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566574</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{DD02} Durand, F., Dorsey, J. 2002. Fast bilateral filtering for the display of high-dynamic-range images. ACM Trans. Graphics, 21, 3, 257--266 (Proc. ACM SIGGRAPH).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>523382</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{DTB97} Dutton, K., Thompson, S., Barrachlough, B. 1997. The Art of Control Engineering, 1st ed. Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>527570</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{G95} Glassner, A. 1995. Principles of Digital Image Synthesis, 1st ed. Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882421</ref_obj_id>
				<ref_obj_pid>882404</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{HDM03} Havran, V., Damez, C., Myszkowski, K. 2003. An efficient spatio-temporal architecture for animation rendering. Proc. Eurographics Symposium on Rendering, 106--117.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>500844</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{J01} Jensen, H. W. 2001. Realistic Image Synthesis Using Photon Mapping. AK Peters.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{LAM00} Lext, J., Assarsson, U., Moeller, T. 2000. Bart: A benchmark for animated ray tracing. Tech. Rpt. 00-14, Dept. Computer Engineering, Chalmers Univ. Tech. http://www.ce.chalmers.se/BART.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>863276</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{LRC*02} Luebke, D., Reddy, M., Cohen, J. D., Varshney, A., Watson, B., Huebner, R. 2002. Level of Detail for 3D Graphics, 1st ed. Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37410</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{M87} Mitchell, D. P. 1987. Generating antialiased images at low sampling densities. Proc. ACM SIGGRAPH, 65--72.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>182469</ref_obj_id>
				<ref_obj_pid>182466</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{MCEF94} Molnar, S., Cox, M., Ellsworth, D., Fuchs, H. 1994. A sorting classification of parallel rendering. IEEE Computer Graphics and Applications, 14, 4, 23--32.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199407</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{OCMB95} Olano, M., Cohen, J., Mine, M., Bishop, G. 1995. Combatting rendering latency. Proc. ACM Interactive 3D Graphics, 19--24.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74362</ref_obj_id>
				<ref_obj_pid>74333</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[{PS89} Painter, J., Sloan, K. 1989. Antialiased ray tracing by adaptive progressive refinement. Proc. ACM SIGGRAPH, 281--288.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300537</ref_obj_id>
				<ref_obj_pid>300523</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[{PMS*99} Parker, S., Martin, W., Sloan, P.-P.J., Shirley, P., Smits, B., Hansen, C. 1999. Interactive ray tracing. Proc. ACM Interactive 3D Graphics, 119--126.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258791</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[{PKGH97} Pharr, M., Kolb, C., Gershbein, R., Hanrahan, P. 1997. Rendering Complex Scenes with memory-coherent ray tracing. Proc. ACM SIGGRAPH, 101--108.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566640</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[{PBMH02} Purcell, T. J., Buck, I., Mark, W. R., Hanrahan, P. 2002. Ray tracing on programmable graphics hardware. ACM Trans. Graphics, 21, 3, 703--712 (Proc. ACM SIGGRAPH).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192192</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[{RP94} Regan, M. J. P., Pose, R. 1994. Priority rendering with a virtual reality address recalculation pipeline. Proc. ACM SIGGRAPH, 155--162.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732132</ref_obj_id>
				<ref_obj_pid>647652</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[{SS00} Simmons, M., S&#233;quin, C. 2000. Tapestry: A dynamic mesh-based display representation for interactive rendering. Proc. Eurographics Workshop on Rendering, 329--340.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>888662</ref_obj_id>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[{TA98} Teller, S., Alex, J. 1998. Frustum Casting for Progressive, Interactive Rendering. Massachusetts Institute of Technology Technical Report LCS TR-740. Available at http://graphics.csail.mit.edu/pubs/MIT-LCS-TR-740.ps.gz]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566613</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[{TPWG02} Tole, P., Pellacini, F., Walter, B., Greenberg, D. P. 2002. Interactive global illumination in dynamic scenes. ACM Trans. Graphics, 21, 3, 537--546 (Proc. ACM SIGGRAPH).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237274</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[{TK96} Torborg, J., Kajiya, J. 1996. Talisman: Commodity Reality Graphics for the PC. Proc. ACM SIGGRAPH, 353--363.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[{WBDS03} Wald, I., Benthin, C., Dietrich, A., Slusallek, P. 2003. Interactive distributed ray tracing on commodity PC clusters---state of the art and practical applications. Lecture Notes on Computer Science, 2790, 499--508 (Proc. EuroPar).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[{WBWS01} Wald, I., Benthin, C., Wagner, M., Slusallek, P. 2001. Interactive rendering with coherent ray tracing. Computer Graphics Forum, 20, 153--164 (Proc. Eurographics).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[{WPS*03} Wald, I., Purcell, T. J., Schmittler, J., Benthin, C., Slusallek, P. 2003. Realtime ray tracing and its use for interactive global illumination. Eurographics State of the Art Reports.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732298</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[{WSB01} Wald, I., Slusallek, P., Benthin, C. 2001. Interactive distributed ray tracing of highly complex models. Proc. Eurographics Workshop on Rendering, 277--288.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>581901</ref_obj_id>
				<ref_obj_pid>581896</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[{WDG02} Walter, B., Drettakis, G., Greenberg, D. P. 2002. Enhancing and optimizing the render cache. Proc. Eurographics Workshop on Rendering, 37--42.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383819</ref_obj_id>
				<ref_obj_pid>2383815</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[{WDP99} Walter, B., Drettakis, G., Parker S. 1999. Interactive rendering using render cache. Proc. Eurographics Workshop on Rendering, 19--30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>337722</ref_obj_id>
				<ref_obj_pid>337680</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[{WS99} Ward, G., Simmons, M. 1999. The Holodeck Ray Cache: An Interactive Rendering System for Global Illumination in Nondiffuse Environments, ACM Trans. Graph. 18, 4, 361--398.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>641509</ref_obj_id>
				<ref_obj_pid>641480</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[{WLWD03} Woolley, C., Luebke, D., Watson, B. A., Dayal, A. 2003. Interruptible rendering. Proc. ACM Interactive 3D Graphics, 143--151.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Computer Science Department Technical Report NWU-CS-05-07 April 26, 2005 Adaptive Frameless Rendering 
1212 Abhinav Dayal, Cliff Woolley, Benjamin Watsonand David Luebke 1Northwestern University, 2University 
of Virginia Abstract We propose an adaptive form of frameless rendering with the potential to dramatically 
increase rendering speed over conventional interactive rendering approaches. Without the rigid sampling 
patterns of framed renderers, sampling and reconstruction can adapt with very fine granularity to spatio-temporal 
color change. A sampler uses closed-loop feedback to guide sampling toward edges or motion in the image. 
Temporally deep buffers store all the samples created over a short time interval for use in reconstruction 
and as sampler feedback. GPU-based reconstruction responds both to sampling density and space-time color 
gradients. Where the displayed scene is static, spatial color change dominates and older samples are 
given significant weight in reconstruction, resulting in sharper and eventually antialiased images. Where 
the scene is dynamic, more recent samples are emphasized, resulting in less sharp but more up-to-date 
images. We also use sample reprojection to improve reconstruction and guide sampling toward occlusion 
edges, undersampled regions, and specular highlights. In simulation our frameless renderer requires 
an order of magnitude fewer samples than traditional rendering of similar visual quality (as measured 
by RMS error), while introducing overhead amounting to 15% of computation time. Keywords: I.3.3 [Computer 
Graphics]: Picture-Image Generation Display algorithms; I.3.7 [Computer Graphics]: Three-Dimensional 
Graphics And Realism Raytracing; Virtual reality.   Adaptive Frameless Rendering Abhinav Dayal1, Cliff 
Woolley2, Benjamin Watson1 and David Luebke2 1Northwestern University, 2University of Virginia Abstract 
 We propose an adaptive form of frameless rendering with the potential to dramatically increase rendering 
speed over conventional interactive rendering approaches. Without the rigid sampling patterns of framed 
renderers, sampling and reconstruction can adapt with very fine granularity to spatio-temporal color 
change. A sampler uses closed-loop feedback to guide sampling toward edges or motion in the image. Temporally 
deep buffers store all the samples created over a short time interval for use in reconstruction and 
as sampler feedback. GPU-based reconstruction responds both to sampling density and space-time color 
gradients. Where the displayed scene is static, spatial color change dominates and older samples are 
given significant weight in reconstruction, resulting in sharper and eventually antialiased images. 
Where the scene is dynamic, more recent samples are emphasized, resulting in less sharp but more up-to-date 
images. We also use sample reprojection to improve reconstruction and guide sampling toward occlusion 
edges, undersampled regions, and specular highlights. In simulation our frameless renderer requires an 
order of magnitude fewer samples than traditional rendering of similar visual quality (as measured by 
RMS error), while introducing overhead amounting to 15% of computation time. Categories and Subject Descriptors: 
I.3.3 [Computer Graphics]: Picture-Image Generation Display algorithms; I.3.7 [Computer Graphics]: Three-Dimensional 
Graphics And Realism Raytracing; Virtual reality 1. Improving Interactive Rendering In recent years a 
number of traditionally offline rendering algorithms have become interactive or nearly so. The introduction 
of programmable high-precision graphics processors (GPUs) has drastically expanded the range of algorithms 
that can be employed in real-time graphics; meanwhile, the steady progress of Moore s Law has made techniques 
such as ray tracing, long considered a slow algorithm suited only for offline realistic rendering, feasible 
in real-time rendering settings [WDB*03]. These trends are related; indeed, some of the most promising 
interactive global illumination research performs algorithms such as ray tracing and photon mapping directly 
on the GPU [PBMH02]. Future hardware should provide even better support for these algorithms, bringing 
us closer to the day when ray-based algorithms are an accepted and powerful component of every interactive 
rendering system. What makes interactive ray tracing attractive? Researchers in the area have commented 
on ray tracing s ability to model physically accurate global illumination phenomena, its easy applicability 
to different shaders and primitives, and its output-sensitive running time, which is only weakly dependent 
on scene complexity [WPS*03]. We focus on another unique capability: selective sampling of the image 
plane. By design, depth-buffered rasterization must generate an entire image at a given time, but ray-tracing 
can focus rendering with very fine granularity. This ability enables a new approach to rendering that 
is both more interactive and more accurate. The topic of sampling in ray tracing may seem nearly ex- 
 Figure 1: Adaptive frameless rendering improves upon frameless rendering [BFMS94] (left) with adaptive 
sampling and reconstruction (right). Resulting imagery has similar visual quality to a framed renderer 
but is produced using an order of magnitude fewer samples per second. A. Dayal, C. Woolley, B. Watson 
&#38; D. Luebke / Adaptive Frameless Rendering hausted, but almost all previous work has focused on spatial 
sampling, or where to sample in the image plane. In an interactive setting, the question of temporal 
sampling, or when to sample with respect to user input, becomes equally important. Temporal sampling 
in traditional graphics is bound to the frame: an image is begun in the back buffer incorporating the 
latest user input, but by the time the frame is swapped to the front buffer for display, the image reflects 
stale input. To mitigate this, interactive rendering systems increase the frame rate by reducing the 
complexity of the scene, trading off fidelity for performance. In this paper we investigate novel sampling 
schemes for managing the fidelity-performance tradeoff. Our approach has two important implications. 
First, we advocate adaptive temporal sampling, analogous to the adaptive spatial sampling long employed 
in progressive ray tracing [BFGS86; M87; PS89]. Just as spatially adaptive renderers display detail 
where it is most important, temporally adaptive sampling displays detail when it is most important. Second, 
we advocate frameless rendering [BFMS94], in which samples are located freely in space-time rather than 
placed at regular temporal intervals forming frames, and with images reconstructed from a sampled space-time 
volume, rather than a coherent temporal slice. Frameless rendering decouples spatial and temporal sampling, 
enabling adaptive spatial and temporal sampling. Our prototype adaptive frameless renderer consists of 
four primary subsystems. An adaptive sampler directs rendering to image regions undergoing significant 
change (in space and/or time). The sampler produces a stream of samples scattered across space-time; 
recent samples are collected and stored in two temporally deep buffers. One of these buffers provides 
feedback to the sampler, while the other serves as input to an adaptive reconstructor, which repeatedly 
reconstructs the samples in its deep buffer into an image for display, adapting the reconstruction 
filters to local sampling density and color gradients. Where the displayed scene is static, spatial color 
change dominates and older samples are given significant weight in reconstruction, resulting in sharper 
images. Where the scene is dynamic, only more recent samples are emphasized, resulting in a less sharp 
but correctly up-to-date image. We describe an interactive system built on these principles, and show 
in simulation that this system achieves superior rendering accuracy and responsiveness. We compare our 
system s imagery to the imagery that would be displayed by a hypothetical zero-delay, antialiased renderer 
using RMS error. Our system outperforms not only frameless sampling (Figure 1), but also equals the 
performance of a framed renderer sampling 10 times more quickly. 2. Related work Bishop et al. s frameless 
rendering [BFMS94] replaces the coherent, simultaneous, double-buffered update of all pixels with samples 
distributed stochastically in space, each representing the most current input when the sample was taken. 
Pixels in a frameless image therefore represent many moments in time. Resulting images are more up-to-date 
than double-buffered frames, but temporal incoherence causes visual artifacts in dynamic scenes. Inspired 
by frameless rendering, other researchers examined the loosening of framed sampling constraints. The 
just in time pixels scheme [OCMB95] takes a new temporal sample for each scanline. The address recalculation 
pipeline [RP94] sorts objects into several layered frame buffers refreshed at different rates. The Talisman 
system [TK96] renders portions of the 3D scene at different rates. Ward and Simmons [WS99] and Bala et 
al. [BDT99] store and reuse previously rendered rays. In work that is particularly relevant here, several 
researchers have studied sample reprojection, which reuses samples from previous frames by repositioning 
them to reflect the current viewpoint. Walter et al. s Render Cache [WDP99; WDG02] reconstructs these 
temporally incoherent samples using depth comparisons and filtering that span small pixel neighborhoods. 
New samples are guided toward regions that have not been recently sampled, are sparsely sampled, or contain 
temporal color discontinuities. Simmons and Squin [SS00] use a hardware interpolated 2.5D mesh to cache 
and reconstruct the samples, and guide new samples toward spatial color and depth discontinuities. Tol 
et al. s Shading Cache [TPWG02] stores samples in the 3D scene itself, performing reconstruction by rendering 
that scene in hardware. Sampling is biased toward spatial color discontinuities and toward specular 
and moving objects. Havran et al. [HDM03] calculate the temporal intervals over which a given sample 
will remain visible in an offline animation and reproject that sample during the interval. Shading is 
recalculated for reprojected samples in every frame. Although the images they produce combine samples 
created at many different moments, all of these systems sample time at regular intervals. Woolley et 
al. [WLWD03] describe a fully framed but temporally adaptive sampling scheme called interruptible rendering. 
The approach adaptively controls frame rate to minimize simultaneously the error created by reduced rendering 
fidelity and by reduced rendering performance. A progressive renderer refines a frame in the back buffer 
until the error created by unrepresented input exceeds the error caused by coarse rendering. At that 
point, the front and back buffers are swapped and rendering begins again into the back buffer using the 
most recent input. Coarse, high frame-rate display results when input is changing rapidly, and finely 
detailed, low frame rate display when input is static. Many advances in high-speed ray tracing have been 
made recently. These include clever software techniques to im- Technical Report NWU-CS-05-07, Northwstern 
University A. Dayal, C. Woolley, B. Watson &#38; D. Luebke / Adaptive Frameless Rendering Figure 2: 
A reconstructed image and an overlay showing the tiling used by the sampler at that moment in time. Note 
the finer tilings over object edges and occlusions. prove memory locality [PKGH97; TA98; WBWS01], as 
well as advances in hardware that enable interactive ray tracers on supercomputers [PMS*99], on PC clusters 
[WSB01; WBDS03], on the SIMD instruction sets of modern CPUs [WBWS01], and on graphics hardware [PBMH02; 
CHH02]. Wald et al. provide a good summary of the state of the art [WPS*03]. These advances will soon 
allow a very finegrained and selective space-time sampling, in real time. This real-time, selective 
sampling enables a new adaptive form of frameless rendering that incorporates techniques from adaptive 
renderers, reprojecting renderers, non-uniform reconstruction [M87], and GPU programming. The resulting 
system outperforms framed and traditional frameless renderers and offers the following advantages over 
reprojecting renderers: Improved sampling response. Rather being clustered at each frame time, samples 
reflect the most up-to-date input available at the moment they are created. Further, closedloop control 
guides samples toward not only spatial but temporal color discontinuities at various scales. These elements 
combine to reduce rendering latency. Improved reconstruction. Rather than being non-adaptive or hardware-interpolated, 
reconstruction is adaptive over both space and time, responding to local space-time color gradients. 
This drastically improves image quality, eliminating the temporal incoherence in traditional frameless 
imagery without requiring framed sampling and its increased latency, and permitting antialiasing in 
static image regions. Moreover this reconstruction is already interactive and implemented on existing 
GPU hardware. 3. Adaptive frameless sampling Previous importance sampling techniques [BFGS86; G95; M87; 
PS89] are spatially adaptive, focusing on regions where color changes across space. Our renderer is both 
spatially and temporally adaptive, focusing also on regions where color changes over time (Figure 2). 
Adaptive bias is added to sampling with the use of a spatial hierarchy of image-space tiles. However, 
while previous methods operated in the static con fill deep buffers non-adaptively loop choose a tile 
to render and a pixel within it find last location sampled in pixel complete a crosshair of samples at 
last location update deep buffers and tile statistics repeat 5 times choose a tile crosshair and reproject 
it reevaluate tile gradients in crosshair check visibility of crosshair center sample if occluded then 
create new crosshair at same location update deep buffers and tile statistics end repeat choose a different 
pixel in tile to sample create sample, update last location sampled in pixel update deep buffers and 
tile statistics if one display time elapsed then send reconstructor view and tile information if another 
chunk of crosshairs has been completed then adjust tiling end loop Figure 3: Pseudocode for the main 
loop in the sampler. text of a single frame, we operate in a dynamic frameless context. This has several 
implications. First, rather than operating on a frame buffer, we send samples to two temporally deep 
buffers that collect samples scattered across space-time (one buffer for the sampler, one for the reconstructor). 
Our tiles therefore partition a space-time volume using planes parallel to the temporal axis. We call 
each resulting subvolume a block. Second, as in framed schemes, color variation within each tile guides 
rendering bias, but variation represents change over not just space but also time. Moreover, variation 
does not monotonically decrease as the renderer increases the number of tiles, but rather constantly 
changes in response to user interaction and animation. Therefore the hierarchy is also constantly changing, 
with tiles continuously merged and split in response to dynamic changes in the contents of the deep 
buffer. The sampler s deep buffer provides it with important feedback. This deep buffer is a 3D array 
sized to match the number of image pixels in two dimensions, and a shallow buffer depth b in the third, 
temporal dimension (we use b = 4). Buffer entries at each pixel location form a queue, with new samples 
inserted into the front causing the removal of the sample in the back if the queue is full. Each sample 
is also sent to the reconstructor s buffer as soon as it arrives in the sampler s buffer, and is described 
by its color, position in world space, age, and a view-independent velocity vector. In addition to filling 
the reconstructor s deep buffer, the sampler sends the reconstructor regular updates describing the current 
view and tiling. This information is sent to the reconstructor 60 times per second, and includes each 
tile s image coordinates as well as the average temporal and spatial color gradients in the tile s 
block. We implement our sampler s tiling hierarchy using a K-D tree. Given a target number of tiles, 
the tree is managed to A. Dayal, C. Woolley, B. Watson &#38; D. Luebke / Adaptive Frameless Rendering 
m o d e l ,  Figure 4: Adaptive frameless sampling as closed loop control. Samples from the ray tracer 
(plant) are sent to an error tracker, which adjusts the tiling or error map. The adaptive sampler (compensator) 
then selects one location to render in a tile. Constantly changing user input (disturbance) makes it 
very difficult to track and limit error. ensure that the amount of color variation in each tile s block 
is roughly equal: the tile with the most color variation is split and the two tiles with the least summed 
variation are merged, until all tiles have roughly equal variation. We calculate variation across all 
of a tile s samples using the equation vtile S = 1/n i (Li Lm)2, where Li is a sample s luminance and 
Lm the mean luminance in the tile. We ensure prompt response to changes in scene content by weighting 
samples in the variance calculation using a function that declines exponentially as sample age increases. 
As a result, small tiles are located over dynamic or finely detailed buffer regions, while large tiles 
emerge over static or coarsely detailed regions (Figure 2). The tiling is updated after a chunk of c 
new samples has been generated (we set c = 150). Sampling now becomes a biased probabilistic process 
(Figure 3). Since the current time is not fixed as it would be in a framed renderer, we cannot just 
iteratively sample the tile with the most variation in doing so, we would overlook newly emerging motion 
and detail. At the same time, we cannot leave rendering unbiased and unimproved. Our solution is to 
select each tile with equal probability and select the sampled location within the tile using a uniform 
distribution. Because tiles vary in size, sampling is biased towards those regions of the image which 
exhibit high spatial and/or temporal variance. Because all tiles are sampled, we remain sensitive to 
newly emerging motion and detail. This sampler thus constitutes a closed-loop control system [DTB97], 
capable of adapting to user input with great flexibility (Figure 4). In control theory, the plant is 
the process being directed by the compensator, which must adapt to external disturbance. Output from 
the plant becomes input for the compensator, closing the feedback loop. In a classic adaptive framed 
sampler, the compensator chooses the rendered location, the ray tracer is the plant that must be controlled, 
and disturbance is provided by the scene as viewed at the time being rendered. Our frameless sampler 
faces a more difficult challenge: view and scene state may change after each sample. Figure 5: Error 
derivatives (left) and the tile gradients (right) Gx, Gy, and Gt (shown here as red, green, and blue, 
respectively) in a scene corresponding to Figure 2. To meet this challenge, we apply two control engineering 
techniques. We first use a PD controller, in which control responds not only in proportion to error itself 
(P), but also to its derivative (D). In our sampler, error is color variation, and by biasing sampling 
toward variation, we are already responding in proportion to it. By responding to error s derivative, 
we bias sampling toward regions in which variation is changing such as the edge of the moving table in 
Figure 2, compensating for delay in our control system. We accomplish this by tracking variation change 
d and adding it to normalized variation p to form a new summed control error e in the tile: e = kp + 
(1-k)d, where s vtile p = |tiles| . j vj is the temporally weighted color variance in the tile block 
vtile normalized by the sum of these variances over all tiles scaled by the tile size s, d is the absolute 
difference between p s current value and its value u updates of the tile ago (we use u = 4) divided by 
the time between those updates, and k in the range [0,1] is the weight applied to the proportional term. 
The left image in Figure 5 visualizes d for each tile by mapping high d values to brighter colors. Our 
prototype adaptive sampler will be less effective when the rendered scene is more dynamic, changing the 
desired image (or target signal in control theory) more rapidly. In such cases, fixed delays in response 
will make control increasingly ineffective. To address this problem we apply another control engineering 
technique: adjusting gain. We implement this by restricting or increasing the ability of the sampler 
to adapt to deep buffer content. Specifically, we adjust the number of tiles onscreen so that color change 
over space and time are roughly equal in all tiles by ensuring that dC/ds S = i dC/dt T, where dC/ds 
and dC/dt are spatial and temporal color gradients averaged over the entire image (Figure 5), S is the 
average width of the tiles, T the average age of the samples in each tile, and i is a constant adjusting 
the relative importance of temporal and spatial change in control. By solving for S we can derive the 
appropriate number of tiles. A. Dayal, C. Woolley, B. Watson &#38; D. Luebke / Adaptive Frameless Rendering 
We find current spatial gradients by sampling five tightly clustered image locations (xy, x1y and xy1) 
in a crosshair pattern each time we add samples to the deep buffers, and averaging the horizontal and 
vertical absolute differences. To find a temporal gradient, we find the absolute difference between 
the center xy sample and a sample made at the same location the last time we visited the same pixel region, 
and divide by the time elapsed since that previous sample was made. We then produce and store a sample 
at a new location in the pixel region for pairing with the next crosshair made in the pixel region. This 
set of six samples forms a single entry in the xy queue of the sampler s deep buffer (they are not grouped 
when sent to the reconstructor s deep buffer). To determine average tile gradients, we reduce the weight 
of each sample gradient as a function of time using the same exponential scheme used to track color variation. 
To permit antialiasing, we center sample crosshairs at random spatial locations. However when the scene 
is particularly dynamic and spatial sampling density is decreased, sharp edges may appear to shimmer 
in reconstructed imagery. Although adaptive reconstruction reduces these artifacts, we eliminate them 
by randomizing crosshair location only when the scene is locally static and temporal gradients approach 
zero. 4. Interactive space-time reconstruction Frameless sampling strategies demand a rethinking of the 
traditional computer graphics concept of an image , since at any given moment the samples in an image 
plane represent many different moments in time. The original frameless work [BFMS94] simply displayed 
the most recent sample at every pixel. This traditional reconstruction results in a noisy image that 
appears to sparkle when the scene is dynamic (see Figure 1). In contrast, we convolve the frameless samples 
in the reconstructor s temporally deep buffer with space-time filters to continuously reconstruct images 
for display. This is similar to the classic computer graphics problem of reconstruction of an image from 
non-uniform samples [M87], but with a temporal element: since older samples may represent stale data, 
they are treated with less confidence and contribute less to nearby pixels than more recent samples. 
The resulting images greatly improve over traditional reconstruction (see again Figure 1). 4.1. Choosing 
a filter The key question is what shape and size filter to use. A temporally narrow, spatially broad 
filter (i.e. a filter which falls off rapidly in time but gradually in space) will give very little weight 
to relatively old samples, emphasizing the newest samples and leading to a blurry but very current image. 
Such a filter provides low-latency response to changes and should be used when the underlying image is 
changing rapidly. A temporally broad, spatially narrow filter will give nearly as much weight to relatively 
old samples as to recent samples; such a filter accumulates the results of many samples and leads to 
a finely detailed, antialiased image when the underlying scene is changing slowly. However, often different 
regions of an image change at different rates, as for example in a stationary view in which an object 
is moving across a static background. A scene such as this demands spatially adaptive reconstruction, 
in which the filter extent varies across the image. What should guide this process? We use local sampling 
density (Figure 7) and space-time gradient information (Figure 5) to guide filter size. The reconstructor 
maintains an estimate of local sampling density across the image, based on the overall sampling rate 
and on the tiling used to guide sampling. We size our filter support which can be interpreted as a space-time 
volume as if we were reconstructing a regular sampling with this local sampling density, and while preserving 
the total volume of the filter, perturb the spatial and temporal filter extents according to local gradient 
information. A large spatial gradient implies an edge, which should be resolved with a narrow filter 
to avoid blurring across that edge. Similarly, a large temporal gradient implies a temporal edge such 
as an occlusion event, which should be resolved with a narrow filter to avoid including stale samples 
from before the event. This is equivalent to an implicit robust estimator; rather than searching for 
edges explicitly, we rely on the gradient to allow us to size the filter such that the expected contribution 
of samples past those edges is small. Thus, given a local sampling rate Rl, expressed in samples per 
pixel per second, we define VS as the expected space-time volume occupied by a single sample: 1 VS = 
. Rl The units of VS are pixel-seconds per sample (note that the product of pixel areas and seconds is 
a volume). We then construct a filter at this location with space-time support proportional to this 
volume. For simplicity we restrict the filter shape to be axis-aligned to the spatial x and y and the 
temporal t dimensions. The filter extents ex, ey, and et are chosen to span equal expected color change 
in each dimension, determined by our estimates of the gradients Gx, Gy, and Gt and the total volume 
constraint Vs: eG = eG = eG xx yytt V = eee . S xyz Thus the filter extents are given by VGG VGG VGG 
S yt SxyS xt e = 3,e = 3,e = 3. x 2 y 2 t 2 GGG x yt What function to use for the filter kernel remains 
an open question. According to signal theory, a regularly sampled, band limited function should be reconstructed 
with a sinc function, but our deep buffer is far from regularly sampled A. Dayal, C. Woolley, B. Watson 
&#38; D. Luebke / Adaptive Frameless Rendering (a) (b) (c) (d) Figure 6: Adaptive reconstruction illustrated 
in one moment of a scene with a moving view and car, sampled using our adaptive frameless techniques. 
In (a), traditional frameless reconstruction leaves many artifacts of the view motion in the image. In 
(b), adaptive reconstruction rejects many of the outdated samples, eliminating artifacts and clarifying 
edges. (c) shows the improvements possible by reprojecting samples as in [WDP99], even without adaptive 
reconstruction. When reprojection is combined with adaptive reconstruction as in (d), the car s motion 
and view-dependent reflections in the floor are clarified. and the underlying signal (an image of a three-dimensional 
scene) contains high-frequency discontinuities such as occlusion boundaries. We have experimented with 
a range of filters. Box and tent filters have poor bandpass properties but are extremely cheap to evaluate. 
A gaussian filter looks better but also requires more computation. The Mitchell-Netravali filter [M87] 
is considered among the best filters for nonuniform sampling, but is still more costly and requires 
more precision than is provided by our 16-bit GPU implementation. We have also experimented with a simple 
inverse exponential filter, which has the nice temporal property that the relative contribution of two 
samples does not change as both grow older; however, the bandpass properties of this filter are less 
than ideal. We are currently using a gaussian filter. 4.2. Scatter versus gather We can consider reconstruction 
a gather process which loops over the pixels, looks for samples in the neighborhood of each pixel, and 
evaluates the contribution of those samples to that pixel. Alternatively, we can cast reconstruction 
as a scatter process which loops over the samples, projects each onto the image plane, and evaluates 
its contribution to all pixels within some footprint. We have experimented with both approaches. We 
implemented the reconstructor initially as a gather process directly on the sampler s deep buffer. At 
display time the reconstructor looped over the pixels, then adjusted the filter size and extents at each 
pixel using gradient and local sample density as described above. The reconstructor gathered samples 
outwards from each pixel in space and time until the maximum possible incremental contribution of additional 
samples would be less than some threshold . The final e color at that pixel was computed as the normalized 
weighted average of sample colors. This process proved expensive in practice our unoptimized simulator 
required reconstruction times of several hundred ms for small (256  256) image sizes. It was also unclear 
how to efficiently implement hardware sample reprojection We have therefore moved to a scatter-based 
implementation that stores the N most recent samples produced by the sampler across the entire image; 
the value of N is typically at least 4 the desired image resolution. This store is a distinct deep buffer 
for the reconstructor that organizes the samples as a single temporally ordered queue rather than a spatial 
array of crosshairs. At reconstruction time, the system splats each of these samples onto the image plane 
and evaluates the sample s affect on every pixel within the splat extent by computing the distance from 
the sample to the pixel center and weighting the sample s color contribution according to the local filter 
function. These accumulated contributions are then divided by the accumulated weight at each pixel to 
produce the final image (Figure 6). We implement this scatter approach on the GPU, achieving real-time 
or near real-time performance and improving on the speed of our CPU-based gather implementation by almost 
two orders of magnitude. The GPU treats the samples in the deep buffer as vertices in a vertex array, 
and uses an OpenGL vertex program to project them onto the screen as splats (i.e., large GL_POINTS primitives). 
A fragment program runs at each pixel covered by a sample splat, finding the distance to the sample and 
computing the local filter shape by accessing tile information local filter extent, precomputed from 
sample density and Gx,Gy,Gt gradients stored in a texture. This texture is periodically updated by rasterizing 
the latest tiling (provided by the sampler) as a set of rectangles into an offscreen buffer. To reduce 
overdraw while still providing broad filter support in sparsely sampled regions, the vertex program rendering 
the samples adaptively adjusts point size. Section 5.2 describes this process in more detail. The reconstructor 
uses several features of recent graphics hardware, including floating-point textures with blend support, 
multiple render targets, vertex texture fetch, dynamic branching in vertex programs, and separate blend 
functions A. Dayal, C. Woolley, B. Watson &#38; D. Luebke / Adaptive Frameless Rendering for color and 
alpha. The results presented in this paper were obtained on a NVIDIA GeForce 6800 Ultra. In general, 
reconstruction occurs at 20 Hz rates when keeping a visually sufficient number of samples N (N=400K). 
This is remarkable considering that our use of the hardware differs greatly from the rendering task 
the hardware was designed to support. 5. Reprojection Our adaptive frameless sampling and reconstruction 
techniques operate entirely in 2D image space and do not rely on information about sample depth or the 
3D structure of the scene. However, because camera location and sample depth are easily available from 
our ray-tracing renderer, we also incorporate sample reprojection [WDP99; WDG02; BDT99; WS99] into our 
algorithms. During sampling, reprojection can help the sampler find and focus on image regions undergoing 
disocclusion, occlusion, view-dependent lighting changes, or view-independent motion. During reconstruction, 
sample reprojection extends the effective lifetime of a sample by allowing older samples to contribute 
usefully to imagery even after significant camera or object motion. This section describes our strategies 
for using reprojection with our sampler and reconstructor.   5.1. Reprojection in the sampler It is 
not necessary to reproject every sample at fixed intervals, and indeed this would not be desirable since 
it would introduce periodicity into our frameless sampler. Instead, we reproject a small number of 
recent samples as we generate each new sample. When updates of tiling statistics (e.g. variation, gradients) 
are included, reprojecting a sample takes roughly 1/35th the mean time required to generate a new sample. 
We therefore reproject a small number (currently 5) of a tile s crosshairs each time the sampler visits 
a tile. In this way the same useful rendering bias that guides generation of new samples determines which 
samples are reprojected, focusing reprojections on important image areas. Within each tile, we choose 
the corresponding pixels to reproject randomly and relocate the crosshairs from the front of each pixel 
s queue in the deep buffer. We apply both motion and viewing transformations to the samples in the crosshair. 
Despite being updated in some sense, reprojected samples continue to age normally and do not receive 
increased weight in variance and gradient calculations. On a local per-tile basis, every sample is treated 
similarly, and its age remains a good indicator of its utility. We determine a crosshair s new location 
in the buffer solely by its relocated center sample, and insert the crosshair sample at the back of its 
new queue, updating source and destination tile statistics if necessary. When updating tile gradients, 
spatial gradients for the crosshair are recalculated using the new spatial locations of the crosshair 
samples (after reprojection, they are no longer sepa- Technical Report NWU-CS-05-07, Northwstern University 
 Figure 7: A sample density map (left) used by the reconstructor to determine the expected local sample 
volume Vs, and occlusion detection (right) used direct sampling. rated by one pixel length). We recalculate 
the crosshair temporal gradients by finding the absolute difference between the reprojected center sample 
and the newest sample in that pixel region, and dividing this difference by the age of this newest sample. 
Reprojection of a crosshair continues until it ages so much that it no longer affects tile variance and 
gradients, or until it is pushed out of its queue in the deep buffer by a newly arriving crosshair. Regions 
containing disocclusions will be undersampled as samples reproject to other image locations. We bias 
sampling toward these disocclusions with a new undersampling meas ure utile: |tiles | . m. (whb - | 
buffer tiles | . . j=1 . utile = 1- min .1, .. sb - | tile | .. Here the number of empty samples in a 
tile must be m times greater than the mean number of empty samples in all tiles to affect sampling. |buffer| 
and |tile| are the number of samples in the deep buffer and the current tile s block, while whb is the 
number of samples the deep buffer can hold (with image size wh). Regions undergoing occlusion will contain 
samples from multiple surfaces at differing view depths, leading to uncertainty about image content. 
To resolve this uncertainty, we increase sampling in occluded regions. We detect occlusions by casting 
rays from the eye to each reprojected sample. If the sample is no longer visible from the eye, we add 
a new sample at the occluded image location. We also increase sampling density in the occluded region 
by increasing error in tiles experiencing occlusion with an occlusion term otile = |O|/sb, where |O| 
is the number of occluded samples in a tile s block, tracked by our occlusion test. Figure 7 shows the 
occlusions that affect sampling. Proportional error p for the sampler then becomes: . v tile u tile 
o tile . w +. +(1 -. -.) p = s... |tiles ||tiles ||tiles | .. .. j vj . j uj . j oj . .... ith , ,and 
(+ )allin[0,1]. A. Dayal, C. Woolley, B. Watson &#38; D. Luebke / Adaptive Frameless Rendering 5.2. 
Reprojection in the reconstructor Unlike the sampler, the reconstructor operates in a framed context: 
to display an image on existing hardware, it scans out a traditional image (i.e., a uniform grid of pixels) 
at the regular intervals of the display refresh. Since each sample in the reconstructor s deep buffer 
stores the 3D hit point of the primary ray that generated that sample, reprojecting and reconstructing 
each of our renderer s images reduces to rendering the vertex array in the deep buffer with the current 
camera and projection matrices bound. Figure 6 shows the results of using reprojection in reconstruction. 
Reprojection sometimes generates regions of low sample density, for example at disocclusions and near 
the leading edge of the screen during camera rotation. In such regions, the filter support for the few 
samples present must be quite large, requiring the reconstructor to rasterize samples with large splats. 
Rather than rasterizing all samples using large splats, we avoid overdraw with an adaptive point size 
scheme. All samples are accumulated into a coverage map during rendering that tracks the number and average 
splat size of all samples rendered to each pixel. To size splats, the sample vertex program binds the 
previous image s coverage map as a texture, computes the projected coordinates of the sample, and uses 
the coverage information at those coordinates to calculate the splat size at which the sample will be 
rasterized. Sample splats in a region are sized according to the average point size used in that region 
during reconstruction of the previous image, but point sizes in undersampled regions (defined currently 
as fewer than 4 samples affecting a pixel) are multiplied by 4 to grow rapidly, while point sizes in 
oversampled regions (more than 32 samples reaching a pixel) are multiplied by 0.7 to shrink gradually. 
6. Evaluation Using the gold standard validation described in [WLWD03], we find that our adaptive frameless 
renderer consistently outperforms other renderers that have the same sampling rates. Gold standard validation 
uses as its standard an ideal renderer I capable of rendering antialiased imagery in zero time. To perform 
comparisons to this standard, we create n ideal images Ij (j in [1,n]) at 60 Hz for a certain animation 
A using a simulated ideal renderer. We then create n more images Rj for animation A using an actual interactive 
renderer R. We next compare each image pair (Ij,Rj) using an image comparison metric comp. Here we use 
root-mean-squared error (RMS). We report the results of our gold standard evaluation in Table 1, which 
compares several rendering methods producing 256x256 images using various sampling rates. Two framed 
renderings either maximize Hz at the cost of spatial resolution (lo-res), or spatial resolution at the 
cost of Hz (hi-res). Render Method Animation/Sampling rate Interactive Bart Toycar 100k 400k 800k 400k 
800k 400k 800k Framed: lo-res 92.7 71.8 60.9 112 100 47 42.8 Framed: hi-res 110 72.6 60.4 127 112 43.8 
38.9 Traditional Frameless 80.8 48.8 39.3 92.3 74.8 35.3 32.5 Adaptive 34.4 24.1 23.6 50.1 51.9 20.4 
18.5 hi-res 60Hz 28 28 28 30.7 30.7 29.4 29.4 Table 1: Summary error analysis using the techniques of 
Figure 8, with some additional sampling rates. The traditional frameless rendering simply displays the 
newest sample at a given pixel. The adaptive frameless renderings use our system to produce the imagery. 
The hi-res 60Hz is a framed renderer that uses a sampling rate 10 times higher than other renderers to 
produce full resolution imagery at 60Hz. (The difference between the ideal renderer and this hires 60Hz 
renderer is that the latter suffers from doublebuffering delay and does not use anti-aliasing). Rendering 
methods were tested in 3 different animations, all using the publicly available BART testbed [LAM00]: 
the viewpoint animation in the testbed itself (BART); a fixed viewpoint close-up of a moving car (toycar), 
and a recording of user viewpoint interaction (interactive). Adaptive frameless rendering is the clear 
winner, with lower RMS error than all techniques using the same sampling rate and comparable error to 
the hi-res 60Hz rendering, which uses sampling rates 40, 10 and 5 times faster than the 100K, 400K and 
800K adaptive frameless renderings. Figure 8 offers a more detailed view that confirms this impression. 
The graphs here show frame-by-frame RMS error comparisons between several of these rendering techniques 
and the ideal rendering. Note the sawtooth pattern produced by the low-sampling rate hi-res renderer, 
due to double buffering error. In the interactive animation, the periodic increases in error correspond 
to periods of viewpoint change. Once more, adaptive frameless rendering has lower RMS error than all 
rendering techniques using equivalent sampling rates, and comparable error to the much more densely sampled 
hi res 60Hz renderer. The top right graph also depicts the advantage of using reprojection in the sampler. 
RMS error is considerably higher if reprojection is not used. 7. Discussion and future work Frameless 
rendering and selective sampling have been criticized for sacrificing spatial coherence and thus memory 
locality, which can reduce sampling speed. We plan to experiment with increases in the number of samples 
we generate each time we visit a tile, increasing spatial coherence at the cost of slightly less adaptive 
sampling overall. However, exploiting spatial coherence has its limits: ultimately, it will limit our 
ability to take advantage of temporal coherence and force us to sample more often. Traditional renderers 
must sample every single pixel dozens of times each second; as displays grow in size and resolution, 
this ceaseless sampling 9 A. Dayal, C. Woolley, B. Watson &#38; D. Luebke / Adaptive Frameless Rendering 
Interactive Animation 100k samples/sec Interactive Animation 400k samples/sec 200 180 400k Full Res 400k 
60Hz 180 160 traditional frameless Full Res 60Hz 160 adaptive no reprojections 140 adaptive 140 120 120 
 RMS error RMS error RMS error RMS error 100 80 80 60 60 40 40 20 20 0 0 0 200 400 600 800 1000 1200 
0 200 400 600 800 1000 1200 1400 1600 1800 #Frame Frame# Bart Animation 400k samples/sec Toycar Animation 
400k samples/sec 250 70 60 200 50 150 40 30 20 50 10 0 0 0 200 400 600 800 1000 1200 0 50 100 150 200 
Frame# #Frames Figure 8: An error analysis of rendering techniques for several animation sequences created 
using 100K or 400K samples/sec. Graphs show frame-by-frame RMS error between each technique s images 
and the ideal image that would be displayed by a hypothetical zero-delay, antialiased renderer at the 
same moment in time. Resolution is 256x256 pixels at 60 Hz. becomes wasteful of computation, power, and 
heat. With this work, we hope to shift the emphasis of interactive ray tracing research from spatial 
to temporal coherence, and from bruteforce to selective sampling. Good filter design for the adaptive 
space-time reconstruction of frameless sample streams remains an open problem. We have begun investigating 
the edge-preserving concepts of bilateral and trilateral filtering [DD02; CT03], which perform nonlinear 
filtering by weighting samples according to their difference in luminance as well as their distance in 
space. However, extending these approaches to include a third temporal dimension and to operate on a 
non-uniformly distributed samples presents a significant challenge. A related possibility is to exploit 
a priori information about the underlying model or animation, as do Bala et al. [BWG03]. We believe this 
work has great potential, and will continue this research in several longer-term directions. Extending 
our temporally adaptive methods to more sophisticated global illumination algorithms is one obvious avenue. 
With its ability to selectively alter sampling and reconstruction across both space and time, our adaptive 
frameless renderer is an ideal platform for experimenting with perceptually driven rendering in interactive 
settings [LRC02]. We are studying the possibility of extremely high resolution ( gigapixel ) display 
hardware fed streams of frameless samples, with adaptive reconstruction performed in the display itself. 
This might be one solution to the immense bandwidth challenge posed by such displays. Such a rendering 
configuration would also enable a truly asynchronous parallelism in graphics, since renderers would 
no longer have to combine their samples into a single frame [MCEF94]. For this reason we are particularly 
interested in implementing these algorithms in graphics hardware. 8. Conclusion In conclusion, we advocate 
a revival of frameless rendering, based on temporally adaptive sampling and reconstruction, and enabled 
by recent advances in interactive ray tracing. This approach improves traditional framed and frameless 
rendering by focusing sampling on regions of spatial and temporal change, and with adaptive reconstruction 
that emphasizes new samples when scene content is changing quickly and incorporates older samples when 
the scene is static. In testing, our prototype system displays greater accuracy than framed and frameless 
rendering schemes at comparable sampling rates, and comparable accuracy to a framed A. Dayal, C. Woolley, 
B. Watson &#38; D. Luebke / Adaptive Frameless Rendering renderer sampling 10 times more quickly. Based 
on these results, we believe that a temporally adaptive frameless approach shows great promise for future 
rendering algorithms and hardware. 9. Acknowledgements We would like to thank Edward Colgate and Kevin 
Lynch (Department of Mechanical Engineering, Northwestern University) for their fruitful discussions 
on control systems and the Saarland University Graphics Group for providing us with the OpenRT ray tracer. 
This work was supported in part by the NSF grants 0092973, 0093172, 0112937, and 0130869. The 3D model 
(kitchen) is the courtesy of the BART (A Benchmark for Animated Ray Tracing) project at Chalmers University 
of Technology, Sweden. 10. References [BDT99] BALA, K., DORSEY, J., TELLER, S. 1999. Radiance interpolants 
for accelerated bounded-error ray tracing. ACM Trans. Graph, 18, 3, 213-256. [BWG03] BALA, K., WALTER, 
B., GREENBERG, D.P. 2003. Combining edges and points for interactive high-quality rendering. ACM Trans. 
Graph., 22, 3, 631 640 (Proc. ACM SIGGRAPH). [BFGS86] BERGMAN, L., FUCHS, H., GRANT, E., SPACH, E. 1986. 
Image rendering by adaptive refinement. Proc. ACM SIGGRAPH, 29 37. [BFMS94] BISHOP, G., FUCHS, H., MCMILLAN, 
H., SCHER ZAGIER, E.J. 1994. Frameless rendering: double buffering considered harmful. Proc. ACM SIGGRAPH, 
175 176. [CHH02] CARR, N.A., HALL, J.D., HART, J.C. 2002. The ray engine. Proc. ACM SIGGRAPH/Eurographics 
Graphics Hardware, 37 46. [CT03] CHOUDHURY, P., TUMBLIN, J. 2003. The trilateral filter for high contrast 
images and meshes. Proc. Eurographics Workshop on Rendering, 186 196. [DD02] DURAND, F., DORSEY, J. 
2002. Fast bilateral filtering for the display of high-dynamic-range images. ACM Trans. Graphics, 21, 
3, 257 266 (Proc. ACM SIGGRAPH). [DTB97] DUTTON, K., THOMPSON, S., BARRACHLOUGH, B. 1997. The Art of 
Control Engineering, 1st ed. Addison-Wesley. [G95] GLASSNER, A. 1995. Principles of Digital Image Synthesis, 
1st ed. Morgan Kaufmann. [HDM03] HAVRAN, V., DAMEZ, C., MYSZKOWSKI, K. 2003. An efficient spatio-temporal 
architecture for animation rendering. Proc. Eurographics Symposium on Rendering, 106-117. [J01] JENSEN, 
H.W. 2001. Realistic Image Synthesis Using Photon Mapping. AK Peters. [LAM00] LEXT, J., ASSARSSON, U., 
MOELLER, T. 2000. Bart: A benchmark for animated ray tracing. Tech. Rpt. 00-14, Dept. Computer Engineering, 
Chalmers Univ. Tech. http://www.ce.chalmers.se/BART. [LRC*02] LUEBKE, D., REDDY, M., COHEN, J.D., VARSHNEY, 
A., WATSON, B., HUEBNER, R. 2002. Level of Detail for 3D Graphics, 1st ed. Morgan Kaufmann. [M87] MITCHELL, 
D.P. 1987. Generating antialiased images at low sampling densities. Proc. ACM SIGGRAPH, 65 72. [MCEF94] 
MOLNAR, S., COX, M., ELLSWORTH, D., FUCHS, H. 1994. A sorting classification of parallel rendering. IEEE 
Computer Graphics and Applications, 14, 4, 23 32. [OCMB95] OLANO, M., COHEN, J., MINE, M., BISHOP, G. 
1995. Combatting rendering latency. Proc. ACM Interactive 3D Graphics, 19 24. [PS89] PAINTER, J., SLOAN, 
K. 1989. Antialiased ray tracing by adaptive progressive refinement. Proc. ACM SIGGRAPH, 281 288. [PMS*99] 
PARKER, S., MARTIN, W., SLOAN, P.-P.J., SHIRLEY, P., SMITS, B., HANSEN, C. 1999. Interactive ray tracing. 
Proc. ACM Interactive 3D Graphics, 119 126. [PKGH97] PHARR, M., KOLB, C., GERSHBEIN, R., HANRAHAN, P. 
1997. Rendering Complex Scenes with memorycoherent ray tracing. Proc. ACM SIGGRAPH, 101 108. [PBMH02] 
PURCELL, T.J., BUCK, I., MARK, W.R., HANRAHAN, P. 2002. Ray tracing on programmable graphics hardware. 
ACM Trans. Graphics, 21, 3, 703 712 (Proc. ACM SIGGRAPH). [RP94] REGAN, M.J.P., POSE, R. 1994. Priority 
rendering with a virtual reality address recalculation pipeline. Proc. ACM SIGGRAPH, 155 162. [SS00] 
SIMMONS, M., SQUIN, C. 2000. Tapestry: A dynamic mesh-based display representation for interactive rendering. 
Proc. Eurographics Workshop on Rendering, 329 340. [TA98] TELLER, S., ALEX, J. 1998. Frustum Casting 
for Progressive, Interactive Rendering. Massachusetts Institute of Technology Technical Report LCS TR-740. 
Available at http://graphics.csail.mit.edu/pubs/MIT-LCS-TR-740.ps.gz [TPWG02] TOLE, P., PELLACINI, F., 
WALTER, B., GREENBERG, D.P. 2002. Interactive global illumination in dynamic scenes. ACM Trans. Graphics, 
21, 3, 537 546 (Proc. ACM SIGGRAPH). [TK96] TORBORG, J., KAJIYA, J. 1996. Talisman: Commodity Reality 
Graphics for the PC. Proc. ACM SIGGRAPH, 353-363. [WBDS03] WALD, I., BENTHIN, C., DIETRICH, A., SLUSALLEK, 
P. 2003. Interactive distributed ray tracing on commodity PC clusters state of the art and practical 
applications. Lecture Notes on Computer Science, 2790, 499 508 (Proc. EuroPar). [WBWS01] WALD, I., BENTHIN, 
C., WAGNER, M., SLUSALLEK, P. 2001. Interactive rendering with coherent ray tracing. Computer Graphics 
Forum, 20, 153 164 (Proc. Eurographics). [WPS*03] WALD, I., PURCELL, T.J., SCHMITTLER, J., BENTHIN, 
C., SLUSALLEK, P. 2003. Realtime ray tracing and its use for interactive global illumination. Eurographics 
State of the Art Reports. [WSB01] WALD, I., SLUSALLEK, P., BENTHIN, C. 2001. Interactive distributed 
ray tracing of highly complex models. Proc. Eurographics Workshop on Rendering, 277 288. [WDG02] WALTER, 
B., DRETTAKIS, G., GREENBERG, D.P. 2002. Enhancing and optimizing the render cache. Proc. Eurographics 
Workshop on Rendering, 37 42. [WDP99] WALTER, B., DRETTAKIS, G., PARKER S. 1999. Interactive rendering 
using render cache. Proc. Eurographics Workshop on Rendering, 19 30. [WS99] WARD, G., SIMMONS, M. 1999. 
The Holodeck Ray Cache: An Interactive Rendering System for Global Illumination in Nondiffuse Environments, 
ACM Trans. Graph. 18, 4, 361-398. [WLWD03] WOOLLEY, C., LUEBKE, D., WATSON, B.A., DAYAL, A. 2003. Interruptible 
rendering. Proc. ACM Interactive 3D Graphics, 143 151.   
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
	<section>
		<section_id>1198764</section_id>
		<sort_key>39</sort_key>
		<section_seq_no>39</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[GPGPU: general-purpose computation on graphics hardware]]></section_title>
		<section_page_from>39</section_page_from>
		<chair_editor>
			<ch_ed>
				<person_id>PP39060444</person_id>
				<author_profile_id><![CDATA[81100116782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Harris]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
			<ch_ed>
				<person_id>PP14056692</person_id>
				<author_profile_id><![CDATA[81100131290]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Luebke]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Editor]]></role>
				<email_address><![CDATA[]]></email_address>
			</ch_ed>
		</chair_editor>
	<article_rec>
		<article_id>1198765</article_id>
		<sort_key>4</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Introduction]]></title>
		<page_from>4</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198765</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198765</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14056692</person_id>
				<author_profile_id><![CDATA[81100131290]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Luebke]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Virginia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Course Intr oduction  The GPU on commodity video cards has evolved into an extremely flexible and 
powerful processor  Programmability  Precision Power   This course will address how to harness that 
power for general-purpose computation   Motivation: Computati o nal Power  GPUs are fast  3 GHz Pentium4: 
6 GFLOPS, 6 GB/sec peak  GeForceFX 6800: 53 GFLOPs, 34 GB/sec peak   GPUs are getting faster, faster 
 CPUs: ~1.5 annual growth ~60 per decade  GPUs: >2.0 annual growth >1000 per decade   Courtesy 
Kurt Akeley, Ian Buck &#38; Tim Purcell, GPU Gems (see course notes) Motivation: Computati o nal Power 
An Aside: C o mputation a l Power multiplies per second Why are GPUs getting faster so fast? Arithmetic 
intensity: the specialized nature of GPUs makes it easier to use additional transistors for computation 
not cache  Economics: multi-billion dollar video game market is a pressure cooker that drives innovation 
444   GFLOPS July 01 Jan 02 July 02 Jan 03 July 03 Jan 04  Courtesy Ian Buck  Motivation: The Poten 
t ial of GPGPU  Modern GPUs are deeply programmable  Programmable pixel, vertex, video engines  Solidifying 
high-level language support   Modern GPUs support high precision  32 bit floating point throughout 
the pipeline  High enough for many (not all) applications   In short: The power and flexibility of 
GPUs makes them an attractive platform for general-purpose computation  Example applications range from 
in-game physics simulation to conventional computational science  Goal: make the inexpensive power of 
the GPU available to developers as a sort of computational coprocessor   The Problem: Difficult To 
Use Course go a l s  GPUs designed for &#38; driven by video games  Programming model unusual  Programming 
idioms tied to computer graphics  Programming environment tightly constrained   Underlying architectures 
are:  Inherently parallel  Rapidly evolving (even in basic feature set!)  Largely secret   Can t 
simply port CPU code!  A detailed introduction to general-purpose computing on graphics hardware  
We emphasize:  Core computational building blocks  Strategies and tools for programming GPUs  Tips 
&#38; tricks, perils &#38; pitfalls of GPU programming   Case studies to bring it all together   
Why a SIGGRAPH Cour se? Course Prerequisites Why SIGGRAPH, not (say) Supercomputing? Many graphics 
applications can benefit from GPGPU  Hot topic examples: shadows, level sets, fluids  Keeping computation 
on-card!   Many graphics applications strive for visual plausibility rather than rigorous scientific 
realism  Better tolerate GPU limitations in precision, memory  Well suited as GPGPU early adopters 
  GPGPU programming still requires expertise of SIGGRAPH audience  We assume  Familiarity with interactive 
graphics and computer graphics hardware  Ideally, some experience programming vertex and pixel shaders 
  Target audience  Researchers interested in GPGPU  Graphics and games developers interested in incorporating 
these techniques into their applications  Attendees wishing a survey of this exciting field 555   
 Course Topics: Details  GPU building blocks  Languages and tools  Effective GPU programming  GPGPU 
case studies   GPU building blocks  Linear algebra  Sorting and searching  Geometric Computing 
  Languages and tools  High-level languages  Debugging tools    Course Topics: Details Speakers 
 Effective GPU programming  Efficient data-parallel programming  GPU memory resources &#38; data layout 
approaches  GPU computation strategies &#38; tricks  Data structures   Case studies in GPGPU Programming 
 Databases and data mining operations on GPUs Particles &#38; grids on GPUs  Adaptive shadow maps 
&#38; octree textures on GPUs   In order of appearance: David Luebke, University of Virginia  Mark 
Harris, NVIDIA  Jens Krger, TU-Munich  Tim Purcell, NVIDIA  Naga Govindaraju, University of North 
Carolina  Ian Buck, NVIDIA  Cliff Woolley, University of Virginia  Aaron Lefohn, University of California 
Davis   Schedule 8:30 Introduction Welcome, overview, the graphics pipeline GPU Building Blocks 8:50 
Computational concepts: CPUGPU Streaming, resources, CPU-GPU analogies, branching 9:10 Linear algebra 
Representations, operations, example algorithms 9:50 Sorting &#38; Searching Bitonic sort, Binary &#38; 
k-nearest neighbor search  Schedule Luebke Harris Krger Purcell 10:30 Geometric computation Govindaraju 
Visibility, collision &#38; proximity, reliable computation Languages and Tools Buck 11:00 High-level 
languages Cg/HLSL/GLslang, Sh, Brook Purcell 11:30 Debugging tools imdebug, DirectX/OpenGL shader IDEs, 
ShadeSmith 666  Schedule Effective GPGPU Programming Case Studies 11:50 GPU program optimization Computational 
frequency, profiling, load balancing Woolley 1:45 12:15 Lunch break GPU memory models Memory objects, 
layout of data structures, FBOs Lefohn Buck 2:15 GPU computation strategies &#38; tricks Precision, performance, 
scatter, branching Lefohn 2:55 GPU data structures High-level data structures  Govindaraju 3:45 Databases 
&#38; data mining on GPUs Queries, aggregation, mining frequencies &#38; quantiles Krger 4:15 Particles 
&#38; grids on GPUs PBO/VBO &#38; framebuffer objects (FBO) Lefohn 4:45 Applications of adaptive data 
structures Adaptive shadow maps, octree textures Harris Conclusion 5:15 GPGPU: the year in review GP 
U Fundamentals: The Graphi cs P i p eli n e  A simplified graphics pipeline Note that pipe widths vary 
 Many caches, FIFOs, and so on not shown   GPU Fundamentals: The Modern Gr aphi cs Pipe l ine  Programmable 
vertex Programmable pixel processor! processor!   GPU Pipel i ne: Ra st e r iz e Rasterizer Convert 
geometric rep. (vertex) to image rep. (fragment) Fragment = image fragment Pixel + associated data: 
color, depth, stencil, etc.  Interpolate per-vertex quantities across pixels  Fragment processors 
(multiple in parallel) Compute a color for each pixel  Optionally read colors from textures (images) 
  Coming Up  Next: Mapping computational concepts to the GPU  Also coming up:  Core building blocks 
for GPGPU computing  Memory layout, data structures, and algorithms  Detailed advice on writing high 
performance GPGPU code  Lots of examples 888   
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198766</article_id>
		<sort_key>9</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Streaming architectures and technology trends]]></title>
		<page_from>9</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198766</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198766</url>
		<abstract>
			<par><![CDATA[Modern technology allows the designers of today's processors to incorporate enormous computation resources into their latest chips. The challenge for these architects is to translate the increase in capability to an increase in performance. The last decade of graphics processor development shows that GPU designers have succeeded spectacularly at this task. In this chapter, we analyze the technology and architectural trends that motivate the way GPUs are built today and what we might expect in the future.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35036235</person_id>
				<author_profile_id><![CDATA[81100458295]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Owens]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Davis]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>289927</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Dally, William J., and John W. Poulton. 1998. Digital Systems Engineering. Cambridge University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[ITRS. 2003. International Technology Roadmap for Semiconductors. http://public.itrs.net]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>939856</ref_obj_id>
				<ref_obj_pid>939824</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Kapasi, Ujval J., Scott Rixner, William J. Dally, Brucek Khailany, Jung Ho Ahn, Peter Mattson, and John D. Owens. 2003. "Programmable Stream Processors." IEEE Computer, pp. 54--62.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Moore, Gordon. 1965. "Cramming More Components onto Integrated Circuits." Electronics 38(8). More information is available at http://www.intel.com/research/silicon/mooreslaw.htm]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Owens, John D. 2002. "Computer Graphics on a Stream Architecture." Ph.D. Thesis, Stanford University, November 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1022596</ref_obj_id>
				<ref_obj_pid>1022594</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Patterson, David A. 2004. "Latency Lags Bandwidth." Communications of the ACM 47(10), pp. 71--75.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Excerpted from GPU Gems 2 Copyright 2005 by NVIDIA Corporation 999 Excerpted from GPU Gems 2 Copyright 
2005 by NVIDIA Corporation 101010 This part of the book aims to provide a gentle introduction to the 
world of generalpurpose computation on graphics processing units, or GPGPU, as it has come to be known. 
The text is intended to be understandable to programmers with no graphics experience, as well as to those 
who have been programming graphics for years but have little knowledge of parallel computing for other 
applications. Since the publication of GPU Gems, GPGPU has grown from something of a curiosity to a 
well-respected active new area of graphics and systems research. Why would you want to go to the trouble 
of converting your computational problems to run on the GPU? There are two reasons: price and performance. 
Economics and the rise of video games as mass-market entertainment have driven down prices to the point 
where you can now buy a graphics processor capable of several hundred billion floating-point operations 
per second for just a few hundred dollars. The GPU is not well suited to all types of problems, but there 
are many examples of applications that have achieved significant speedups from using graphics hardware. 
The applications that achieve the best performance are typically those with high arithmetic intensity 
; that is, those with a large ratio of mathematical operations to memory accesses. These applications 
range all the way from audio processing and physics simulation to bioinformatics and computational finance. 
Anybody with any exposure to modern computing cannot fail to notice the rapid pace of technological change 
in our industry. The first chapter in this part, Chapter 29, Streaming Architectures and Technology Trends, 
by John Owens of the University of California, Davis, sets the stage for the chapters to come by describing 
the trends in semiconductor design and manufacturing that are driving the evolution of both the CPU 
and the GPU. One of the important factors driving these changes is the memory gap the fact that computation 
speeds are increasing at a much faster rate than memory access speeds. This chapter also introduces the 
streaming computational model, which is a reasonably close match to the characteristics of modern GPU 
hardware. By using this style of programming, application programmers can take advantage of the GPU 
s massive computation and memory bandwidth resources, and the resulting programs can achieve large performance 
gains over equivalent CPU implementations. 453 PART IV GENERAL-PURPOSE COMPUTATION ON GPUS: A PRIMER 
Excerpted from GPU Gems 2 Copyright 2005 by NVIDIA Corporation 111111 Chapter 30, The GeForce 6 Series 
GPU Architecture, by Emmett Kilgariff and Randima Fernando of NVIDIA, describes in detail the design 
of a current stateof-the-art graphics processor, the GeForce 6800. Cowritten by one of the lead architects 
of the chip, this chapter includes many low-level details of the hardware that are not available anywhere 
else. This information is invaluable for anyone writing high-performance GPU applications. The remainder 
of this part of the book then moves on to several tutorial-style chapters that explain the details of 
how to solve general-purpose problems using the GPU. Chapter 31, Mapping Computational Concepts to GPUs, 
by Mark Harris of NVIDIA, discusses the issues involved with converting computational problems to run 
efficiently on the parallel hardware of the GPU. The GPU is actually made up of several programmable 
processors plus a selection of fixed-function hardware, and this chapter describes how to make the best 
use of these resources. Chapter 32, Taking the Plunge into GPU Computing, by Ian Buck of Stanford University, 
provides more details on the differences between the CPU and the GPU in terms of memory bandwidth, floating-point 
number representation, and memory access models. As Ian mentions in his introduction, the GPU was not 
really designed for general-purpose computation, and getting it to operate efficiently requires some 
care. One of the most difficult areas of GPU programming is general-purpose data structures. Data structures 
such as lists and trees that are routinely used by CPU programmers are not trivial to implement on the 
GPU. The GPU doesn t allow arbitrary memory access and mainly operates on four-vectors designed to represent 
positions and colors. Particularly difficult are sparse data structures that do not have a regular layout 
in memory and where the size of the structure may vary from element to element. Chapter 33, Implementing 
Efficient Parallel Data Structures on GPUs, by Aaron Lefohn of the University of California, Davis; Joe 
Kniss of the University of Utah; and John Owens gives an overview of the stream programming model and 
goes on to explain the details of implementing data structures such as multidimensional arrays and sparse 
data structures on the GPU. 454 PART IV GENERAL-PURPOSE COMPUTATION ON GPUS: A PRIMER Excerpted from 
GPU Gems 2 Copyright 2005 by NVIDIA Corporation 121212 Traditionally, GPUs have not been very good at 
executing code with branches. Because they are parallel machines, they achieve best performance when 
the the same operation can be applied to every data element. Chapter 34, GPU Flow-Control Idioms, by 
Mark Harris and Ian Buck, explains different ways in which flow-control structures such as loops and 
if statements can be efficiently implemented on the GPU. This includes using the depth-test and z-culling 
capabilities of modern GPUs, as well as the branching instructions available in the latest versions 
of the pixel shader hardware. Cliff Woolley of the University of Virginia has spent many hours writing 
GPGPU applications, and (like many of our other authors) he has published several papers based on his 
research. In Chapter 35, GPU Program Optimization, he passes on his experience on the best ways to optimize 
GPU code, and how to avoid the common mistakes made by novice GPU programmers. It is often said that 
premature optimization is the root of all evil, but it has to be done at some point. On the CPU, it is 
easy to write programs that have variable amounts of output per input data element. Unfortunately, this 
is much more difficult on a parallel machine like the GPU. Chapter 36, Stream Reduction Operations for 
GPGPU Applications, by Daniel Horn of Stanford University, illustrates several ways in which the GPU 
can be programmed to perform filtering operations that remove elements from a data stream in order to 
generate variable amounts of output. He demonstrates how this technique can be used to efficiently implement 
collision detection and subdivision surfaces. Only time will tell what the final division of labor between 
the CPU, the GPU, and other processors in the PC ecosystem will be. One thing is sure: the realities 
of semiconductor design and the memory gap mean that data-parallel programming is here to stay. By learning 
how to express your problems in this style today, you can ensure that your code will continue to execute 
at the maximum possible speed on all future hardware. Simon Green, NVIDIA Corporation 455 PART IV GENERAL-PURPOSE 
COMPUTATION ON GPUS: A PRIMER Excerpted from GPU Gems 2 Copyright 2005 by NVIDIA Corporation 131313 
Excerpted from GPU Gems 2 Copyright 2005 by NVIDIA Corporation 141414 Chapter 29 Streaming Architectures 
and Technology Trends John Owens University of California, Davis Modern technology allows the designers 
of today s processors to incorporate enormous computation resources into their latest chips. The challenge 
for these architects is to translate the increase in capability to an increase in performance. The last 
decade of graphics processor development shows that GPU designers have succeeded spectacularly at this 
task. In this chapter, we analyze the technology and architectural trends that motivate the way GPUs 
are built today and what we might expect in the future. 29.1 Technology Trends As computer users, we 
have become accustomed to each new generation of computer hardware running faster, with more capabilities 
and often a lower price than the last. This remarkable pace of development is made possible by continued 
advances in the underlying technologies, allowing more processing power to be placed on each chip. Each 
year in the International Technology Roadmap for Semiconductors (ITRS), the semiconductor industry forecasts 
how a number of chip metrics of interest, such as the size of transistors, the number of transistors 
per chip, and overall power consumption, will change in the coming years (ITRS 2003). These projections 
have an enormous impact on the companies that make chips and chip-making equipment, as well as the designers 
of next-generation chips. In this section we explain some of the trends we can expect in the future, 
as well as what they will mean for the development of nextgeneration graphics processors. 29.1 Technology 
Trends 457 Excerpted from GPU Gems 2 Copyright 2005 by NVIDIA Corporation 151515  29.1.1 Core Technology 
Trends Today s processors are constructed from millions of connected switching devices called transistors. 
As process technologies advance, these transistors, and the connections between them, can be fabricated 
in a smaller area. In 1965, Gordon Moore noted that the number of transistors that could be economically 
fabricated on a single processor die was doubling every year (Moore 1965). Moore projected that such 
an increase was likely to continue in the future. This oft-quoted prediction, termed Moore s Law, today 
means that each year, approximately 50 percent more components can be placed on a single die.1 In the 
forty years since Moore made his prediction, the number of transistors per die has gone from fifty (in 
1965) to hundreds of millions (in 2005), and we can expect this rate of growth to continue for at least 
the next decade. New chip generations not only increase the number of transistors, they also decrease 
transistor size. Because of their smaller size, these transistors can operate faster than their predecessors, 
allowing the chip to run faster overall. Historically, transistor speeds have increased by 15 percent 
per year (Dally and Poulton 1998). In modern processors, a global signal called a clock synchronizes 
computation that occurs throughout the processor, and so processor users see the increase in transistor 
speed reflected in a faster clock. Together, the increase in transistor count and clock speed combine 
to increase the capability of a processor at 71 percent per year. This yearly increase in capability 
means that each year, we can expect 71 percent more computation on a chip compared to the year before. 
Semiconductor computer memory, which uses slightly different fabrication methods than processor logic, 
also benefits from similar advances in fabrication technology. The ITRS forecasts that commodity dynamic 
random-access memory (DRAM) will continue to double in capacity every three years. DRAM performance 
can be measured in two ways: by bandwidth, which measures the amount of data it can transfer each second, 
and by latency, which measures the length of time between the time data is requested and the time it 
is returned. DRAM performance does not increase as quickly as processor capability. DRAM bandwidth increases 
by 25 percent each year (ITRS 2003, Tables 4c, 4d), and DRAM latency improves by only 5 percent per year. 
 29.1.2 Consequences In general, most of the trends just described are positive ones: with each new generation 
of fabrication technology, processor capability, memory bandwidth, and memory latency 1. Though references 
to Moore s Law in the popular press often refer to performance increases, Moore s actual prediction referred 
only to the number of devices that could fit on a single die. 458 Chapter 29 Streaming Architectures 
and Technology Trends Excerpted from GPU Gems 2 Copyright 2005 by NVIDIA Corporation 161616 all improve. 
For example, the yearly capability increase has led to an enormous degree of integration on a single 
die. Fifteen years ago, designers were only just beginning to integrate floating-point arithmetic units 
onto a processor die; today, such a unit occupies less than a square millimeter of die area, and hundreds 
can be placed onto the same die. However, the most important consequences of these technology trends 
are the differences between them. When one metric changes at a different rate than another, it requires 
rethinking the assumptions behind processor and system design. We can identify three major issues that 
will help drive GPU architectures of the future: compute versus communicate, latency versus bandwidth, 
and power. Compute vs. Communicate As both clock speeds and chip sizes increase, the amount of time it 
takes for a signal to travel across an entire chip, measured in clock cycles, is also increasing. On 
today s fastest processors, sending a signal from one side of a chip to another typically requires multiple 
clock cycles, and this amount of time increases with each new process generation. We can characterize 
this trend as an increase in the cost of communication when compared to the cost of computation. As a 
consequence, designers of the future will increasingly use computation via cheap transistors to replace 
the need for expensive communication. Another likely impact will be an increase in the amount of computation 
available per word of memory bandwidth. As an example, let us compare NVIDIA s last three flagship GPUs 
(2002 s GeForce FX 5800, 2003 s GeForce FX 5950, and 2004 s GeForce 6800) in measured peak programmable 
floating-point performance against peak off-chip bandwidth to memory. The GeForce FX 5800 could sustain 
2 floating-point operations for every word of off-chip bandwidth, while the GeForce FX 5950 could sustain 
2.66 operations, and the GeForce 6800 could sustain nearly 6. We expect this trend to continue in future 
chip generations. Figure 29-1 shows historical data for observed floating-point operations per second 
and available memory bandwidth for a series of GPU architectures. Latency vs. Bandwidth The gap between 
the trends of bandwidth and latency will also be an important driver of future architectures. Because 
latency will continue to improve more slowly than bandwidth (Patterson 2004), designers must implement 
solutions that can tolerate larger and larger amounts of latency by continuing to do useful work while 
waiting for data to return from operations that take a long time. 29.1 Technology Trends 459 Excerpted 
from GPU Gems 2 Copyright 2005 by NVIDIA Corporation 171717  The number of observed floating-point operations 
per second on the GeForce FX 5800, 5950, and the GeForce 6800 has been growing at a rapid pace, while 
off-chip memory bandwidth has been increasing much more slowly. (Data courtesy of Ian Buck, Stanford 
University) Power Although smaller transistors require less power than larger ones, the number of transistors 
on a single processor die is rising faster than the amount at which power per transistor is falling. 
Consequently, each generation of processors requires more power: the ITRS estimates that the maximum 
power allowed for 2004 chips with a heat sink is 158 watts and will gradually rise to a ceiling of 198 
watts by 2008. This power constraint will be one of the primary limitations of future processors; the 
future figure of merit may no longer be the number of operations per second but instead the number of 
operations per second per watt. Figure 29-2 summarizes the forecasted change in capability, DRAM bandwidth, 
DRAM latency, and power over the next decade. 460 Chapter 29 Streaming Architectures and Technology Trends 
Excerpted from GPU Gems 2 Copyright 2005 by NVIDIA Corporation 181818   29.2 Keys to High-Performance 
Computing In the previous section, we have seen that modern technology allows each new generation of 
hardware a substantial increase in capability. Effectively utilizing this wealth of computational resources 
requires addressing two important goals. First, we must organize our computational resources to allow 
high performance on our applications of interest. Simply providing large amounts of computation is not 
sufficient, however; efficient management of communication is necessary to feed the computation resources 
on the chip. In this section we describe techniques that allow us to achieve efficient computation and 
efficient communication, and we discuss why modern microprocessors (CPUs) are a poor match for these 
goals. 29.2.1 Methods for Efficient Computation In Section 29.1 we saw that it is now possible to place 
hundreds to thousands of computation units on a single die. The keys to making the best use of transistors 
for computation are to maximize the hardware devoted to computation, to allow multiple computation units 
to operate at the same time through parallelism, and to ensure that each computation unit operates at 
maximum efficiency. 461 29.2 Keys to High-Performance Computing Excerpted from GPU Gems 2 Copyright 2005 
by NVIDIA Corporation 191919 Though modern technologies allow us a large number of transistors on each 
die, our resources are not infinite. Our use of transistors can be broadly divided into three categories: 
control, the hardware used to direct the computation; datapath, the hardware used to perform the computation; 
and storage, the hardware used to store data. If our goal is to maximize performance, we must make hardware 
and software decisions that allow us to maximize the transistors in the datapath that are devoted to 
performing computation. Within the datapath, we can allow simultaneous operations at the same time. This 
technique is termed parallelism. We can envision several ways to exploit parallelism and permit simultaneous 
execution. Complex tasks such as graphics processing are typically composed of several sequential tasks. 
When running these applications, we may be able to run several of these tasks on different data at the 
same time (task parallelism). Within a stage, if we are running a task on several data elements, we may 
be able to exploit data parallelism in evaluating them at the same time. And within the complex evaluation 
of a single data element, we may be able to evaluate several simple operations at the same time (instruction 
parallelism). To effectively use hundreds of computation units, we may take advantage of any or all of 
these types of parallelism. Within each of the tasks, we could make each of our arithmetic units fully 
programmable and thus able to perform any task. However, we can gain more efficiency from our transistors 
by taking advantage of specialization. If a specific arithmetic unit performs only one kind of computation, 
that unit can be specialized to that computation with a considerable gain in efficiency. For example, 
triangle rasterization, in which a screenspace triangle is transformed into the fragments that cover 
that triangle, realizes an enormous efficiency benefit when the rasterization task is implemented in 
special-purpose hardware instead of programmable hardware.  29.2.2 Methods for Efficient Communication 
As we saw in Section 29.1.2, off-chip bandwidth is growing more slowly than on-chip arithmetic capability, 
so high-performance processors must minimize off-chip communication. The easiest way to reduce this 
cost is to eliminate it: modern processors attempt to keep as much required data communication on-chip 
as possible, requiring off-chip communication only to fetch or store truly global data. Another common 
way to mitigate the increasing cost of communication is through caching: a copy of recently used data 
memory is stored on-chip, removing the need for a fetch from off-chip if that data is needed again. Such 
data caching will be more com 462 Chapter 29 Streaming Architectures and Technology Trends Excerpted 
from GPU Gems 2 Copyright 2005 by NVIDIA Corporation 202020 mon in future architectures, extending to 
local caches or user-controlled memories that relieve the need for on-chip communication. These caches 
effectively trade transistors in the form of cache memory for bandwidth. Another powerful technique is 
compression; only the compressed form of data is transmitted and stored off-chip. Compression also trades 
transistors (compression and decompression hardware) and computation (the compression/decompression operation) 
for off-chip bandwidth. 29.2.3 Contrast to CPUs Today s high-performance microprocessors target general-purpose 
applications with different goals from a computer graphics pipeline. In general, these general-purpose 
programs have less parallelism, more complex control requirements, and lower performance goals than 
the rendering pipeline. Consequently, the design goals we enumerated previously are not those addressed 
by CPUs, and CPUs have made different design choices that result in a poor mapping to the graphics pipeline 
and many other applications with similar attributes. CPU programming models are generally serial ones 
that do not adequately expose data parallelism in their applications. CPU hardware reflects this programming 
model: in the common case, CPUs process one piece of data at a time and do not exploit data parallelism. 
They do an admirable job of taking advantage of instruction parallelism, and recent CPU additions to 
the instruction set such as Intel s SSE and the PowerPC s AltiVec allow some data parallel execution, 
but the degree of parallelism exploited by a CPU is much less than that of a GPU. One reason parallel 
hardware is less prevalent in CPU datapaths is the designers decision to devote more transistors to 
control hardware. CPU programs have more complex control requirements than GPU programs, so a large fraction 
of a CPU s transistors and wires implements complex control functionality such as branch prediction and 
out-oforder execution. Consequently, only a modest fraction of a CPU s die is devoted to computation. 
Because CPUs target general-purpose programs, they do not contain specialized hardware for particular 
functions. GPUs, however, can implement special-purpose hardware for particular tasks, which is far more 
efficient than a general-purpose programmable solution could ever provide. Finally, CPU memory systems 
are optimized for minimum latency rather than the maximum throughput targeted by GPU memory systems. 
Lacking parallelism, CPU programs must return memory references as quickly as possible to continue to 
make 463 29.2 Keys to High-Performance Computing Excerpted from GPU Gems 2 Copyright 2005 by NVIDIA Corporation 
212121 progress. Consequently, CPU memory systems contain several levels of cache memory (making up 
a substantial fraction of the chip s transistors) to minimize this latency. However, caches are ineffective 
for many types of data, including graphics inputs and data that is accessed only once. For the graphics 
pipeline, maximizing throughput for all elements rather than minimizing latency for each element results 
in better utilization of the memory system and a higher-performance implementation overall.  29.3 Stream 
Computation In the previous section, we have seen that building high-performance processors today requires 
both efficient computation and efficient communication. Part of the reason that CPUs are poorly suited 
to many of these high-performance applications is their serial programming model, which does not expose 
the parallelism and communication patterns in the application. In this section, we describe the stream 
programming model, which structures programs in a way that allows high efficiency in computation and 
communication (Kapasi et al. 2003). This programming model is the basis for programming GPUs today. 
29.3.1 The Stream Programming Model In the stream programming model, all data is represented as a stream, 
which we define as an ordered set of data of the same data type. That data type can be simple (a stream 
of integers or floating-point numbers) or complex (a stream of points or triangles or transformation 
matrices). While a stream can be any length, we will see that operations on streams are most efficient 
if streams are long (hundreds or more elements in a stream). Allowed operations on streams include copying 
them, deriving substreams from them, indexing into them with a separate index stream, and performing 
computation on them with kernels. A kernel operates on entire streams, taking one or more streams as 
inputs and producing one or more streams as outputs. The defining characteristic of a kernel is that 
it operates on entire streams of elements as opposed to individual elements. The most typical use of 
a kernel is to evaluate a function on each element of an input stream (a map operation); for example, 
a transformation kernel may project each element of a stream of points into a different coordinate system. 
Other desirable kernel operations include expansions (in which more than one output element is produced 
for each input element), reductions (in which more than one element is combined into a single output 
element), or filters (in which a subset of input elements are output). 464 Chapter 29 Streaming Architectures 
and Technology Trends Excerpted from GPU Gems 2 Copyright 2005 by NVIDIA Corporation 222222 Kernel outputs 
are functions only of their kernel inputs, and within a kernel, computations on one stream element are 
never dependent on computations on another element. These restrictions have two major advantages. First, 
the data required for kernel execution is completely known when the kernel is written (or compiled). 
Kernels can thus be highly efficient when their input elements and their intermediate computed data are 
stored locally or are carefully controlled global references. Second, requiring independence of computation 
on separate stream elements within a single kernel allows mapping what appears to be a serial kernel 
calculation onto data-parallel hardware. In the stream programming model, applications are constructed 
by chaining multiple kernels together. For instance, implementing the graphics pipeline in the stream 
programming model involves writing a vertex program kernel, a triangle assembly kernel, a clipping kernel, 
and so on, and then connecting the output from one kernel into the input of the next kernel. Figure 29-3 
shows how the entire graphics pipeline maps onto the stream model. This model makes the communication 
between kernels explicit, taking advantage of the data locality between kernels inherent in the graphics 
pipeline. The graphics pipeline is a good match for the stream model for several reasons. The graphics 
pipeline is traditionally structured as stages of computation connected by data flow between the stages. 
This structure is analogous to the stream and kernel abstractions of the stream programming model. Data 
flow between stages in the graphics pipeline is highly localized, with data produced by a stage immediately 
consumed by the next stage; in the stream programming model, streams passed between kernels exhibit similar 
behavior. And the computation involved in each stage of the pipeline is typically uniform across different 
primitives, allowing these stages to be easily mapped to kernels. The stream formulation of the graphics 
pipeline expresses all data as streams (indicated by arrows) and all computation as kernels (indicated 
by blue boxes). Both user-programmable and nonprogrammable stages in the graphics pipeline can be expressed 
as kernels. 465 29.3 Stream Computation Excerpted from GPU Gems 2 Copyright 2005 by NVIDIA Corporation 
232323 Efficient Computation The stream model enables efficient computation in several ways. Most important, 
streams expose parallelism in the application. Because kernels operate on entire streams, stream elements 
can be processed in parallel using data-parallel hardware. Long streams with many elements allow this 
data-level parallelism to be highly efficient. Within the processing of a single element, we can exploit 
instruction-level parallelism. And because applications are constructed from multiple kernels, multiple 
kernels can be deeply pipelined and processed in parallel, using task-level parallelism. Dividing the 
application of interest into kernels allows a hardware implementation to specialize hardware for one 
or more kernels execution. Special-purpose hardware, with its superior efficiency over programmable hardware, 
can thus be used appropriately in this programming model. Finally, allowing only simple control flow 
in kernel execution (such as the data-parallel evaluation of a function on each input element) permits 
hardware implementations to devote most of their transistors to datapath hardware rather than control 
hardware. Efficient Communication Efficient communication is also one of the primary goals of the stream 
programming model. First, off-chip (global) communication is more efficient when entire streams, rather 
than individual elements, are transferred to or from memory, because the fixed cost of initiating a transfer 
can be amortized over an entire stream rather than a single element. Next, structuring applications as 
chains of kernels allows the intermediate results between kernels to be kept on-chip and not transferred 
to and from memory. Efficient kernels attempt to keep their inputs and their intermediate computed data 
local within kernel execution units; therefore, data references within kernel execution do not go off-chip 
or across a chip to a data cache, as would typically happen in a CPU. And finally, deep pipelining of 
execution allows hardware implementations to continue to do useful work while waiting for data to return 
from global memories. This high degree of latency tolerance allows hardware implementations to optimize 
for throughput rather than latency.  29.3.2 Building a Stream Processor The stream programming model 
structures programs in a way that both exposes parallelism and permits efficient communication. Expressing 
programs in the stream model is only half the solution, however. High-performance graphics hardware must 
effec 466 Chapter 29 Streaming Architectures and Technology Trends Excerpted from GPU Gems 2 Copyright 
2005 by NVIDIA Corporation 242424 tively exploit the high arithmetic performance and the efficient computation 
exposed by the stream model. How do we structure a hardware implementation of a GPU to ensure the highest 
overall performance? The first step to building a high-performance GPU is to map kernels in the graphics 
pipeline to independent functional units on a single chip. Each kernel is thus implemented on a separate 
area of the chip in an organization known as task parallel, which permits not only task-level parallelism 
(because all kernels can be run simultaneously) but also hardware specialization of each functional unit 
to the given kernel. The taskparallel organization also allows efficient communication between kernels: 
because the functional units implementing neighboring kernels in the graphics pipeline are adjacent on 
the chip, they can communicate effectively without requiring global memory access. Within each stage 
of the graphics pipeline that maps to a processing unit on the chip, GPUs exploit the independence of 
each stream element by processing multiple data elements in parallel. The combination of task-level and 
data-level parallelism allows GPUs to profitably use dozens of functional units simultaneously. Inputs 
to the graphics pipeline must be processed by each kernel in sequence. Consequently, it may take thousands 
of cycles to complete the processing of a single element. If a high-latency memory reference is required 
in processing any given element, the processing unit can simply work on other elements while the data 
is being fetched. The deep pipelines of modern GPUs, then, effectively tolerate high-latency operations. 
For many years, the kernels that make up the graphics pipeline were implemented in graphics hardware 
as fixed-function units that offered little to no user programmability. In 2000, for the first time, 
GPUs allowed users the opportunity to program individual kernels in the graphics pipeline. Today s GPUs 
feature high-performance data-parallel processors that implement two kernels in the graphics pipeline: 
a vertex program that allows users to run a program on each vertex that passes through the pipeline, 
and a fragment program that allows users to run a program on each fragment. Both of these stages permit 
single-precision floating-point computation. Although these additions were primarily intended to provide 
users with more flexible shading and lighting calculations, their ability to sustain high computation 
rates on user-specified programs with sufficient precision to address general-purpose computing problems 
has effectively made them programmable stream processors that is, processors that are attractive for 
a much wider variety of applications than simply the graphics pipeline. 467 29.3 Stream Computation Excerpted 
from GPU Gems 2 Copyright 2005 by NVIDIA Corporation 252525   29.4 The Future and Challenges The migration 
of GPUs into programmable stream processors reflects the culmination of several historical trends. The 
first trend is the ability to concentrate large amounts of computation on a single processor die. Equally 
important has been the ability and talent of GPU designers in effectively using these computation resources. 
The economies of scale that are associated with building tens of millions of processors per year have 
allowed the cost of a GPU to fall enough to make a GPU a standard part of today s desktop computer. And 
the addition of reasonably high-precision programmability to the pipeline has completed the transition 
from a hard-wired, special-purpose processor to a powerful programmable processor that can address a 
wide variety of tasks. What, then, can we expect from future GPU development? 29.4.1 Challenge: Technology 
Trends Each new generation of hardware will present a challenge to GPU vendors: How can they effectively 
use additional hardware resources to increase performance and functionality? New transistors will be 
devoted to increased performance, in large part through greater amounts of parallelism, and to new functionality 
in the pipeline. We will also see these architectures evolve with changes in technology. As we described 
in Section 29.1.2, future architectures will increasingly use transistors to replace the need for communication. 
We can expect more aggressive caching techniques that not only alleviate off-chip communication but also 
mitigate the need for some onchip communication. We will also see computation increasingly replace communication 
when appropriate. For example, the use of texture memory as a lookup table may be replaced by calculating 
the values in that lookup table dynamically. And instead of sending data to a distant on-chip computation 
resource and then sending the result back, we may simply replicate the resource and compute our result 
locally. In the trade-off between communicate and recompute/cache, we will increasingly choose the latter. 
The increasing cost of communication will also influence the microarchitecture of future chips. Designers 
must now explicitly plan for the time required to send data across a chip; even local communication times 
are becoming significant in a timing budget. 29.4.2 Challenge: Power Management Ideas for how to use 
future GPU transistors must be tempered by the realities of their costs. Power management has become 
a critical piece of today s GPU designs as each 468 Chapter 29 Streaming Architectures and Technology 
Trends Excerpted from GPU Gems 2 Copyright 2005 by NVIDIA Corporation 262626 generation of hardware 
has increased its power demand. The future may hold more aggressive dynamic power management targeted 
at individual stages; increasing amounts of custom or power-aware design for power-hungry parts of the 
GPU; and more sophisticated cooling management for high-end GPUs. Technology trends indicate that the 
power demand will only continue to rise with future chip generations, so continued work in this area 
will remain an important challenge. 29.4.3 Challenge: Supporting More Programmability and Functionality 
While the current generation of graphics hardware features substantially more programmability than previous 
generations, the general programmability of GPUs is still far from ideal. One step toward addressing 
this trend is to improve the functionality and flexibility within the two current programmable units 
(vertex and fragment). It is likely that we will see their instruction sets converge and add functionality, 
and that their control flow capabilities will become more general as well. We may even see programmable 
hardware shared between these two stages in an effort to better utilize these resources. GPU architects 
will have to be mindful, however, that such improvements not affect the GPU s performance on its core 
tasks. Another option will be expanding programmability to different units. Geometric primitives particularly 
benefit from programmability, so we may soon see programmable processing on surfaces, triangles, and 
pixels. As GPU vendors support more general pipelines and more complex and varied shader computation, 
many researchers have used the GPU to address tasks outside the bounds of the graphics pipeline. This 
book contains examples of many of these efforts; the general-purpose computation on GPUs (GPGPU) community 
has successfully addressed problems in visual simulation, image processing, numerical methods, and databases 
with graphics hardware. We can expect that these efforts will grow in the future as GPUs continue to 
increase in performance and functionality. Historically, we have seen GPUs subsume functionality previously 
belonging to the CPU. Early consumer-level graphics hardware could not perform geometry processing on 
the graphics processor; it was only five years ago that the entire graphics pipeline could be fabricated 
on a single chip. Though since that time the primary increase in GPU functionality has been directed 
toward programmability within the graphics pipeline, we should not expect that GPU vendors have halted 
their efforts to identify more functions to integrate onto the GPU. In particular, today s games often 
require large amounts of computation in physics and artificial intelligence computations. Such computation 
may be attractive for future GPUs. 469 29.4 The Future and Challenges Excerpted from GPU Gems 2 Copyright 
2005 by NVIDIA Corporation 272727 29.4.4 Challenge: GPU Functionality Subsumed by CPU (or Vice Versa)? 
We can be confident that CPU vendors will not stand still as GPUs incorporate more processing power and 
more capability onto their future chips. The ever-increasing number of transistors with each process 
generation may eventually lead to conflict between CPU and GPU manufacturers. Is the core of future 
computer systems the CPU, one that may eventually incorporate GPU or stream functionality on the CPU 
itself? Or will future systems contain a GPU at their heart with CPU functionality incorporated into 
the GPU? Such weighty questions will challenge the next generation of processor architects as we look 
toward an exciting future.  29.5 References Dally, William J., and John W. Poulton. 1998. Digital Systems 
Engineering. Cambridge University Press. ITRS. 2003. International Technology Roadmap for Semiconductors. 
http://public.itrs.net Kapasi, Ujval J., Scott Rixner, William J. Dally, Brucek Khailany, Jung Ho Ahn, 
Peter Mattson, and John D. Owens. 2003. Programmable Stream Processors. IEEE Computer, pp. 54 62. Moore, 
Gordon. 1965. Cramming More Components onto Integrated Circuits. Electronics 38(8). More information 
is available at http://www.intel.com/research/silicon/mooreslaw.htm Owens, John D. 2002. Computer Graphics 
on a Stream Architecture. Ph.D. Thesis, Stanford University, November 2002. Patterson, David A. 2004. 
Latency Lags Bandwidth. Communications of the ACM 47(10), pp. 71 75. 470 Chapter 29 Streaming Architectures 
and Technology Trends Excerpted from GPU Gems 2 Copyright 2005 by NVIDIA Corporation 282828  
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198767</article_id>
		<sort_key>29</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[The GeForce 6 series GPU architecture]]></title>
		<page_from>29</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198767</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198767</url>
		<abstract>
			<par><![CDATA[The previous chapter described how GPU architecture has changed as a result of computational and communications trends in microprocessing. This chapter describes the architecture of the GeForce 6 Series GPUs from NVIDIA, which owe their formidable computational power to their ability to take advantage of these trends. Most notably, we focus on the GeForce 6800 (NVIDIA's flagship GPU at the time of writing, shown in Figure 30-1), which delivers hundreds of gigaflops of single-precision floating-point computation, as compared to approximately 12 gigaflops for current high-end CPUs. In this chapter---and throughout the book---reference to GeForce 6 Series GPUs should be read to include the latest Quadro FX GPUs supporting Shader Model 3.0, which provide a superset of the functionality offered by the GeForce 6 Series. We start with a general overview of where the GPU fits into the overall computer system, and then we describe the architecture along with details of specific features and performance characteristics.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P837801</person_id>
				<author_profile_id><![CDATA[81322498423]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Emmett]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kilgariff]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NVIDIA Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24031269</person_id>
				<author_profile_id><![CDATA[81100444337]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Randima]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fernando]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NVIDIA Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Chapter 30 The GeForce 6 Series GPU Architecture Emmett Kilgariff NVIDIA Corporation Randima Fernando 
 NVIDIA Corporation The previous chapter described how GPU architecture has changed as a result of computational 
and communications trends in microprocessing. This chapter describes the architecture of the GeForce 
6 Series GPUs from NVIDIA, which owe their formidable computational power to their ability to take advantage 
of these trends. Most notably, we focus on the GeForce 6800 (NVIDIA s flagship GPU at the time of writing, 
shown in Figure 30-1), which delivers hundreds of gigaflops of single-precision floating-point computation, 
as compared to approximately 12 gigaflops for current high-end CPUs. In this chapter and throughout the 
book references to GeForce 6 Series GPUs should be read to include the latest Quadro FX GPUs supporting 
Shader Model 3.0, which provide a superset of the functionality offered by the GeForce 6 Series. We start 
with a general overview of where the GPU fits into the overall computer system, and then we describe 
the architecture along with details of specific features and performance characteristics. 30.1 How the 
GPU Fits into the Overall Computer System The CPU in a modern computer system communicates with the GPU 
through a graphics connector such as a PCI Express or AGP slot on the motherboard. Because the graphics 
connector is responsible for transferring all command, texture, and vertex data from the CPU to the GPU, 
the bus technology has evolved alongside GPUs over the past few years. The original AGP slot ran at 66 
MHz and was 32 bits wide, giving a transfer rate of 264 MB/sec. AGP 2, 4, and 8 followed, each doubling 
the available 30.1 How the GPU Fits into the Overall Computer System 471 292929  bandwidth, until finally 
the PCI Express standard was introduced in 2004, with a maximum theoretical bandwidth of 4 GB/sec simultaneously 
available to and from the GPU. (Your mileage may vary; currently available motherboard chipsets fall 
somewhat below this limit around 3.2 GB/sec or less.) It is important to note the vast differences between 
the GPU s memory interface bandwidth and bandwidth in other parts of the system, as shown in Table 30-1. 
Table 30-1. Available Memory Bandwidth in Different Parts of the Computer System Component Bandwidth 
GPU Memory Interface 35 GB/sec PCI Express Bus (16) 8 GB/sec CPU Memory Interface 6.4 GB/sec (800 MHz 
Front-Side Bus) Table 30-1 reiterates some of the points made in the preceding chapter: there is a vast 
amount of bandwidth available internally on the GPU. Algorithms that run on the GPU can therefore take 
advantage of this bandwidth to achieve dramatic performance improvements. 30.2 Overall System Architecture 
The next two subsections go into detail about the architecture of the GeForce 6 Series GPUs. Section 
30.2.1 describes the architecture in terms of its graphics capabilities. Section 30.2.2 describes the 
architecture with respect to the general computational capabilities that it provides. See Figure 30-2 
for an illustration of the system architecture. 30.2.1 Functional Block Diagram for Graphics Operations 
Figure 30-3 illustrates the major blocks in the GeForce 6 Series architecture. In this section, we take 
a trip through the graphics pipeline, starting with input arriving from the CPU and finishing with pixels 
being drawn to the frame buffer. 30.2 Overall System Architecture 473 313131  First, commands, textures, 
and vertex data are received from the host CPU through shared buffers in system memory or local frame-buffer 
memory. A command stream is written by the CPU, which initializes and modifies state, sends rendering 
commands, and references the texture and vertex data. Commands are parsed, and a vertex fetch unit is 
used to read the vertices referenced by the rendering commands. The commands, vertices, and state changes 
flow downstream, where they are used by subsequent pipeline stages. The vertex processors (sometimes 
called vertex shaders ), shown in Figure 30-4, allow for a program to be applied to each vertex in the 
object, performing transformations, skinning, and any other per-vertex operation the user specifies. 
For the first time, a 323232 GPU the GeForce 6 Series allows vertex programs to fetch texture data. All 
operations are done in 32-bit floating-point (fp32) precision per component. The GeForce 6 Series architecture 
supports scalable vertex-processing horsepower, allowing the same architecture to service multiple price/performance 
points. In other words, high-end models may have six vertex units, while low-end models may have two. 
 Because vertex processors can perform texture accesses, the vertex engines are connected to the texture 
cache, which is shared with the fragment processors. In addition, there is a vertex cache that stores 
vertex data both before and after the vertex processor, reducing fetch and computation requirements. 
This means that if a vertex index occurs twice in a draw call (for example, in a triangle strip), the 
entire vertex program doesn t have to be rerun for the second instance of the vertex the cached result 
is used instead. Vertices are then grouped into primitives, which are points, lines, or triangles. The 
Cull/Clip/Setup blocks perform per-primitive operations, removing primitives that aren t visible at all, 
clipping primitives that intersect the view frustum, and performing edge and plane equation setup on 
the data in preparation for rasterization. 475333333 30.2 Overall System Architecture The rasterization 
block calculates which pixels (or samples, if multisampling is enabled) are covered by each primitive, 
and it uses the z-cull block to quickly discard pixels (or samples) that are occluded by objects with 
a nearer depth value. Think of a fragment as a candidate pixel : that is, it will pass through the fragment 
processor and several tests, and if it gets through all of them, it will end up carrying depth and color 
information to a pixel on the frame buffer (or render target). Figure 30-5 illustrates the fragment processor 
(sometimes called a pixel shader ) and texel pipeline. The texture and fragment-processing units operate 
in concert to apply a shader program to each fragment independently. The GeForce 6 Series architecture 
supports a scalable amount of fragment-processing horsepower. Another popular way to say this is that 
GPUs in the GeForce 6 Series can have a varying number of fragment pipelines (or pixel pipelines ). Similar 
to the vertex processor, texture data is cached onchip to reduce bandwidth requirements and improve 
performance. The texture and fragment-processing unit operates on squares of four pixels (called quads) 
at a time, allowing for direct computation of derivatives for calculating texture level of detail. Furthermore, 
the fragment processor works on groups of hundreds of pixels at a time in single-instruction, multiple-data 
(SIMD) fashion (with each fragment processor engine working on one fragment concurrently), hiding the 
latency of texture fetch from the computational performance of the fragment processor.  The fragment 
processor uses the texture unit to fetch data from memory, optionally filtering the data before returning 
it to the fragment processor. The texture unit supports many source data formats (see Section 30.3.3, 
Supported Data Storage Formats ). Data can be filtered using bilinear, trilinear, or anisotropic filtering. 
All data is returned to the fragment processor in fp32 or fp16 format. A texture can be viewed as a 2D 
or 3D array of data that can be read by the texture unit at arbitrary locations and filtered to reconstruct 
a continuous function. The GeForce 6 Series supports filtering of fp16 textures in hardware. The fragment 
processor has two fp32 shader units per pipeline, and fragments are routed through both shader units 
and the branch processor before recirculating through the entire pipeline to execute the next series 
of instructions. This rerouting happens once for each core clock cycle. Furthermore, the first fp32 shader 
can be used for perspective correction of texture coordinates when needed (by dividing by w), or for 
general-purpose multiply operations. In general, it is possible to perform eight or more math operations 
in the pixel shader during each clock cycle, or four math operations if a texture fetch occurs in the 
first shader unit. On the final pass through the pixel shader pipeline, the fog unit can be used to blend 
fog in fixed-point precision with no performance penalty. Fog blending happens often in conventional 
graphics applications and uses the following function: out = FogColor * fogFraction + SrcColor * (1 - 
fogFraction) This function can be made fast and small using fixed-precision math, but in general IEEE 
floating point, it requires two full multiply-adds to do effectively. Because fixed point is efficient 
and sufficient for fog, it exists in a separate small unit at the end of the shader. This is a good example 
of the trade-offs in providing flexible programmable hardware while still offering maximum performance 
for legacy applications. Fragments leave the fragment-processing unit in the order that they are rasterized 
and are sent to the z-compare and blend units, which perform depth testing (z comparison and update), 
stencil operations, alpha blending, and the final color write to the target surface (an off-screen render 
target or the frame buffer). The memory system is partitioned into up to four independent memory partitions, 
each with its own dynamic random-access memories (DRAMs). GPUs use standard DRAM modules rather than 
custom RAM technologies to take advantage of market economies and thereby reduce cost. Having smaller, 
independent memory partitions allows the memory subsystem to operate efficiently regardless of whether 
large or small blocks of data are transferred. All rendered surfaces are stored in the DRAMs, while textures 
and input data can be stored in the DRAMs or in system memory. The four 477353535 30.2 Overall System 
Architecture independent memory partitions give the GPU a wide (256 bits), flexible memory subsystem, 
allowing for streaming of relatively small (32-byte) memory accesses at near the 35 GB/sec physical limit. 
 30.2.2 Functional Block Diagram for Non-Graphics Operations As graphics hardware becomes more and more 
programmable, applications unrelated to the standard polygon pipeline (as described in the preceding 
section) are starting to present themselves as candidates for execution on GPUs. Figure 30-6 shows a 
simplified view of the GeForce 6 Series architecture, when used as a graphics pipeline. It contains a 
programmable vertex engine, a programmable fragment engine, a texture load/filter engine, and a depth-compare/blending 
data write engine. In this alternative view, a GPU can be seen as a large amount of programmable floatingpoint 
horsepower and memory bandwidth that can be exploited for compute-intensive applications completely unrelated 
to computer graphics. Figure 30-7 shows another way to view the GeForce 6 Series architecture. When used 
for non-graphics applications, it can be viewed as two programmable blocks that run serially: the vertex 
processor and the fragment processor, both with support for fp32 operands and intermediate values. Both 
use the texture unit as a random-access data fetch unit and access data at a phenomenal 35 GB/sec (550 
MHz DDR memory clock  256 bits per clock cycle  2 transfers per clock cycle). In addition, both the 
vertex and the fragment processor are highly computationally capable. (Performance details follow in 
Section 30.4.)  The vertex processor operates on data, passing it directly to the fragment processor, 
or by using the rasterizer to expand the data into interpolated values. At this point, each triangle 
(or point) from the vertex processor has become one or more fragments. Before a fragment reaches the 
fragment processor, the z-cull unit compares the pixel s depth with the values that already exist in 
the depth buffer. If the pixel s depth is greater, the pixel will not be visible, and there is no point 
shading that fragment, so the fragment processor isn t even executed. (This optimization happens only 
if it s clear that the fragment processor isn t going to modify the fragment s depth.) Thinking in a 
general-purpose sense, this early culling feature makes it possible to quickly decide to skip work on 
specific fragments based on a scalar test. Chapter 34 of this book, GPU Flow-Control Idioms, explains 
how to take advantage of this feature to efficiently predicate work for general-purpose computations. 
After the fragment processor runs on a potential pixel (still a fragment because it has not yet reached 
the frame buffer), the fragment must pass a number of tests in order to move farther down the pipeline. 
(There may also be more than one fragment that comes out of the fragment processor if multiple render 
targets [MRTs] are being used. Up to four MRTs can be used to write out large amounts of data up to 16 
scalar floating-point values at a time, for example plus depth.) First, the scissor test rejects the 
fragment if it lies outside a specified subrectangle of the frame buffer. Although the popular graphics 
APIs define scissoring at this location in the pipeline, it is more efficient to perform the scissor 
test in the rasterizer. Scissoring in x and y actually happens in the rasterizer, before fragment processing, 
and z scissoring happens 479373737 30.2 Overall System Architecture during z-cull. This avoids all 
fragment processor work on scissored (rejected) pixels. Scissoring is rarely useful for general-purpose 
computation because general-purpose programmers typically draw rectangles to perform computations in 
the first place. Next, the fragment s depth is compared with the depth in the frame buffer. If the depth 
test passes, the fragment moves on in the pipeline. Optionally, the depth value in the frame buffer can 
be replaced at this stage. After this, the fragment can optionally test and modify what is known as the 
stencil buffer, which stores an integer value per pixel. The stencil buffer was originally intended to 
allow programmers to mask off certain pixels (for example, to restrict drawing to a cockpit s windshield), 
but it has found other uses as a way to count values by incrementing or decrementing the existing value. 
This feature is used for stencil shadow volumes, for example. If the fragment passes the depth and stencil 
tests, it can then optionally modify the contents of the frame buffer using the blend function. A blend 
function can be described as out = src * srcOp + dst * dstOp where source is the fragment color flowing 
down the pipeline; dst is the color value in the frame buffer; and srcOp and dstOp can be specified to 
be constants, source color components, or destination color components. Full blend functionality is supported 
for all pixel formats up to fp164. However, fp32 frame buffers don t support blending only updating 
the buffer is allowed. Finally, a feature called occlusion query makes it possible to quickly determine 
if any of the fragments that would be rendered in a particular computation would cause results to be 
written to the frame buffer. (Recall that fragments that do not pass the z-test don t have any effect 
on the values in the frame buffer.) Traditionally, the occlusion query test is used to allow graphics 
applications to avoid making draw calls for occluded objects, but it is useful for GPGPU applications 
as well. For instance, if the depth test is used to determine which outputs need to be updated in a sparse 
array, updating depth can be used to indicate when a given output has converged and no further work is 
needed. In this case, occlusion query can be used to tell when all output calculations are done. See 
Chapter 34 of this book, GPU Flow-Control Idioms, for further information about this idea. 383838  
 30.3 GPU Features This section covers both fixed-function features and Shader Model 3.0 support (described 
in detail later) in GeForce 6 Series GPUs. As we describe the various pieces, we focus on the many new 
features that are meant to make applications shine (in terms of both visual quality and performance) 
on GeForce 6 Series GPUs. 30.3.1 Fixed-Function Features Geometry Instancing With Shader Model 3.0, the 
capability for sending multiple batches of geometry with one Direct3D call has been added, greatly reducing 
driver overhead in these cases. The hardware feature that enables instancing is vertex stream frequency 
the ability to read vertex attributes at a frequency less than once every output vertex, or to loop over 
a subset of vertices multiple times. Instancing is most useful when the same object is drawn multiple 
times with different positions, for example, when rendering an army of soldiers or a field of grass. 
Early Culling/Clipping GeForce 6 Series GPUs are able to cull nonvisible primitives before shading at 
a high rate and clip partially visible primitives at full speed. Previous NVIDIA products would cull 
nonvisible primitives at primitive-setup rates, and clip all partially visible primitives at full speed. 
Rasterization Like previous NVIDIA products, GeForce 6 Series GPUs are capable of rendering the following 
objects: . Point sprites . Aliased and antialiased lines . Aliased and antialiased triangles  Multisample 
antialiasing is also supported, allowing accurate antialiased polygon rendering. Multisample antialiasing 
supports all rasterization primitives. Multisampling is supported in previous NVIDIA products, though 
the 4 multisample pattern was improved for GeForce 6 Series GPUs. 481393939 30.3 GPU Features Z-Cull 
NVIDIA GPUs since GeForce3 have technology, called z-cull, that allows hidden surface removal at speeds 
much faster than conventional rendering. The GeForce 6 Series z-cull unit is the third generation of 
this technology, which has increased efficiency for a wider range of cases. Also, in cases where stencil 
is not being updated, early stencil reject can be employed to remove rendering early when stencil test 
(based on equals comparison) fails. Occlusion Query Occlusion query is the ability to collect statistics 
on how many fragments passed or failed the depth test and to report the result back to the host CPU. 
Occlusion query can be used either while rendering objects or with color and z-write masks turned off, 
returning depth test status for the objects that would have been rendered, without modifying the contents 
of the frame buffer. This feature has been available since the GeForce3 was introduced. Texturing Like 
previous GPUs, GeForce 6 Series GPUs support bilinear, trilinear, and anisotropic filtering on 2D and 
cube-map textures of various formats. Three-dimensional textures support bilinear, trilinear, and quad-linear 
filtering, with and without mipmapping. Here are the new texturing features on GeForce 6 Series GPUs: 
. Support for all texture types (2D, cube map, 3D) with fp162, fp164, fp321, fp322, and fp324 formats 
 . Support for all filtering modes on fp162 and fp164 texture formats . Extended support for non-power-of-two 
textures to match support for power-of-two textures, specifically:  Mipmapping  Wrapping and clamping 
 Cube map and 3D textures  Shadow Buffer Support NVIDIA GPUs support shadow buffering directly. The 
application first renders the scene from the light source into a separate z-buffer. Then during the lighting 
phase, it fetches the shadow buffer as a projective texture and performs z-compares of the shadow buffer 
data against a value corresponding to the distance from the light. If the 404040 distance passes the 
test, it s in light; if not, it s in shadow. NVIDIA GPUs have dedicated transistors to perform four 
z-compares per pixel (on four neighboring z-values) per clock, and to perform bilinear filtering of the 
pass/fail data. This more advanced variation of percentage-closer filtering saves many shader instructions 
compared to GPUs that don t have direct shadow buffer support. High-Dynamic-Range Blending Using fp16 
Surfaces, Texture Filtering, and Blending GeForce 6 Series GPUs allow for fp164 (four components, each 
represented by a 16-bit float) filtered textures in the pixel shaders; they also allow performing all 
alphablending operations on fp164 filtered surfaces. This permits intermediate rendered buffers at 
a much higher precision and range, enabling high-dynamic-range rendering, motion blur, and many other 
effects. In addition, it is possible to specify a separate blending function for color and alpha values. 
(The lowest-end member of the GeForce 6 Series family, the GeForce 6200 TC, does not support floating-point 
blending or floating-point texture filtering because of its lower memory bandwidth, as well as to save 
area on the chip.) 30.3.2 Shader Model 3.0 Programming Model Along with the fixed-function features listed 
previously, the capabilities of the vertex and the fragment processors have been enhanced in GeForce 
6 Series GPUs. With Shader Model 3.0, the programming models for vertex and fragment processors are converging: 
both support fp32 precision, texture lookups, and the same instruction set. Specifically, here are the 
new features that have been added. Vertex Processor . Increased instruction count. The total instruction 
count is now 512 static instructions and 65,536 dynamic instructions. The static instruction count represents 
the number of instructions in a program as it is compiled. The dynamic instruction count represents 
the number of instructions actually executed. In practice, the dynamic count can be much higher than 
the static count due to looping and subroutine calls. . More temporary registers. Up to 32 four-wide 
temporary registers can be used in a vertex program. . Support for instancing. This enhancement was 
described earlier.  483414141 30.3 GPU Features . Dynamic flow control. Branching and looping are 
now part of the shader model. On the GeForce 6 Series vertex engine, branching and looping have minimal 
overhead of just two cycles. Also, each vertex can take its own branches without being grouped in the 
way pixel shader branches are. So as branches diverge, the GeForce 6 Series vertex processor still operates 
efficiently. . Vertex texturing. Textures can now be fetched in a vertex program, although only nearest-neighbor 
filtering is supported in hardware. More advanced filters can of course be implemented in the vertex 
program. Up to four unique textures can be accessed in a vertex program, although each texture can be 
accessed multiple times. Vertex textures generate latency for fetching data, unlike true constant reads. 
Therefore, the best way to use vertex textures is to do a texture fetch and follow it with arithmetic 
operations to hide the latency before using the result of the texture fetch. Each vertex engine is capable 
of simultaneously performing a four-wide SIMD MAD (multiply-add) instruction and a scalar special function 
per clock cycle. Special function instructions include: . Exponential functions: EXP, EXPP, LIT, LOG, 
LOGP . Reciprocal instructions: RCP, RSQ . Trigonometric functions: SIN, COS  Fragment Processor . 
Increased instruction count. The total instruction count is now 65,535 static instructions and 65,535 
dynamic instructions. There are limitations on how long the operating system will wait while the shader 
finishes working, so a long shader program working on a full screen of pixels may time-out. This makes 
it important to carefully consider the shader length and number of fragments rendered in one draw call. 
In practice, the number of instructions exposed by the driver tends to be smaller, because the number 
of instructions can expand as code is translated from Direct3D pixel shaders or OpenGL fragment programs 
to native hardware instructions. . Multiple render targets. The fragment processor can output to up 
to four separate color buffers, along with a depth value. All four separate color buffers must be the 
same format and size. MRTs can be particularly useful when operating on scalar data, because up to 16 
scalar values can be written out in a single pass by the fragment processor. Sample uses of MRTs include 
particle physics, where positions and velocities are computed simultaneously, and similar GPGPU algorithms. 
Deferred shading is another technique that computes and stores multiple four-component floatingpoint 
values simultaneously: it computes all material properties and stores them in 424242  separate textures. 
So, for example, the surface normal and the diffuse and specular material properties could be written 
to textures, and the textures could all be used in subsequent passes when lighting the scene with multiple 
lights. This is illustrated in Figure 30-8. . Dynamic flow control (branching). Shader Model 3.0 supports 
conditional branching and looping, allowing for more flexible shader programs. . Indexing of attributes. 
With Shader Model 3.0, an index register can be used to select which attributes to process, allowing 
for loops to perform the same operation on many different inputs. . Up to ten full-function attributes. 
Shader Model 3.0 supports ten full-function attributes/texture coordinates, instead of Shader Model 2.0 
s eight full-function attributes plus specular color and diffuse color. All ten Shader Model 3.0 attributes 
are interpolated at full fp32 precision, whereas Shader Model 2.0 s diffuse and specular color were interpolated 
at only 8-bit integer precision. . Centroid sampling. Shader Model 3.0 allows a per-attribute selection 
of center sampling, or centroid sampling. Centroid sampling returns a value inside the covered portion 
of the fragment, instead of at the center, and when used with multisampling, it can remove some artifacts 
associated with sampling outside the polygon (for example, when calculating diffuse or specular color 
using texture coordinates, or when using texture atlases). . Support for fp32 and fp16 internal precision. 
Fragment programs can support full fp32-precision computations and intermediate storage or partial-precision 
fp16 computations and intermediate storage.  MRTs make it possible for a fragment program to return 
four four-wide color values plus a depth value. 485434343 30.3 GPU Features . 3:1 and 2:2 coissue. 
Each four-component-wide vector unit is capable of executing two independent instructions in parallel, 
as shown in Figure 30-9: either one threewide operation on RGB and a separate operation on alpha, or 
one two-wide operation on red-green and a separate two-wide operation on blue-alpha. This gives the 
compiler more opportunity to pack scalar computations into vectors, thereby doing more work in a shorter 
time. . Dual issue. Dual issue is similar to coissue, except that the two independent instructions 
can be executed on different parts of the shader pipeline. This makes the pipeline easier to schedule 
and, therefore, more efficient. See Figure 30-10.  Two separate operations can concurrently execute 
on different parts of a four-wide register. Figure 30-10. How Dual Issue Works 444444 Independent instructions 
can be executed on independent units in the computational pipeline. Fragment Processor Performance The 
GeForce 6 Series fragment processor architecture has the following performance characteristics: . Each 
pipeline is capable of performing a four-wide, coissue-able multiply-add (MAD) or four-term dot product 
(DP4), plus a four-wide, coissue-able and dual-issuable multiply instruction per clock in series, as 
shown in Figure 30-11. In addition, a multifunction unit that performs complex operations can replace 
the alpha channel MAD operation. Operations are performed at full speed on both fp32 and fp16 data, although 
storage and bandwidth limitations can favor fp16 performance sometimes. In practice, it is sometimes 
possible to execute eight math operations and a texture lookup in a single cycle. . Dedicated fp16 normalization 
hardware exists, making it possible to normalize a vector at fp16 precision in parallel with the multiplies 
and MADs just described. . An independent reciprocal operation can be performed in parallel with the 
multiply, MAD, and fp16 normalization described previously. . Because the GeForce 6800 has 16 fragment-processing 
pipelines, the overall available performance of the system is given by these values multiplied by 16 
and then by the clock rate. . There is some overhead to flow-control operations, as defined in Table 
30-2.   487454545 30.3 GPU Features Table 30-2. Overhead Incurred When Executing Flow-Control Operations 
in Fragment Programs Instruction Cost (Cycles) If / endif 4 If/else / endif 6 Call 2 Ret 2 Loop/ endloop 
4 Furthermore, branching in the fragment processor is affected by the level of divergence of the branches. 
Because the fragment processor operates on hundreds of pixels per instruction, if a branch is taken by 
some fragments and not others, all fragments execute both branches, but only writing to the registers 
on the branches each fragment is supposed to take. For low-frequency and mid-frequency branch changes, 
this effect is hidden, although it can become a limiter as the branch frequency increases. 30.3.3 Supported 
Data Storage Formats Table 30-3 summarizes the data formats supported by the graphics pipeline.  30.4 
Performance The GeForce 6800 Ultra is the flagship product of the GeForce 6 Series family at the time 
of writing. Its performance is summarized as follows: . 425 MHz internal graphics clock . 550 MHz memory 
clock . 600 million vertices/second . 6.4 billion texels/second . 12.8 billion pixels/second, rendering 
z/stencil-only (useful for shadow volumes and shadow buffers) . 6 four-wide fp32 vector MADs per clock 
cycle in the vertex shader, plus one scalar multifunction operation (a complex math operation, such 
as a sine or reciprocal square root) . 16 four-wide fp32 vector MADs per clock cycle in the fragment 
processor, plus 16 four-wide fp32 multiplies per clock cycle . 64 pixels per clock cycle early z-cull 
(reject rate)  As you can see, there s plenty of programmable floating-point horsepower in the vertex 
and fragment processors that can be exploited for computationally demanding problems. 464646  Table 
30-3. Data Storage Formats Supported by GeForce 6 Series GPUs . = Yes . = No Vertex Fragment Render Texture 
Texture Target Format Description of Data in Memory Support Support Support B8 One 8-bit fixed-point 
number . . . A1R5G5B5 A 1-bit value and three 5-bit unsigned fixed-point . . . numbers A4R4G4B4 Four 
4-bit unsigned fixed-point numbers . . . R5G6B5 5-bit, 6-bit, and 5-bit fixed-point numbers . . . A8R8G8B8 
Four 8-bit fixed-point numbers . . . DXT1 Compressed 44 pixels into 8 bytes . . . DXT2,3,4,5 Compressed 
44 pixels into 16 bytes . . . G8B8 Two 8-bit fixed-point numbers . . . B8R8_G8R8 Compressed as YVYU; 
two pixels in 32 bits . . . R8B8_R8G8 Compressed as VYUY; two pixels in 32 bits . . . R6G5B5 6-bit, 5-bit, 
and 5-bit unsigned fixed-point numbers . . . DEPTH24_D8 A 24-bit unsigned fixed-point number and 8 bits 
of . . . garbage DEPTH24_D8_FLOAT A 24-bit unsigned float and 8 bits of garbage . . . DEPTH16 A 16-bit 
unsigned fixed-point number . . . DEPTH16_FLOAT A 16-bit unsigned float . . . X16 A 16-bit fixed-point 
number . . . Y16_X16 Two 16-bit fixed-point numbers . . . R5G5B5A1 Three unsigned 5-bit fixed-point numbers 
and a 1-bit . . . value HILO8 Two unsigned 16-bit values compressed into two 8-bit . . . values HILO_S8 
Two signed 16-bit values compressed into two 8-bit . . . values W16_Z16_Y16_X16 FLOAT Four fp16 values 
. . . W32_Z32_Y32_X32 FLOAT Four fp32 values . . . (unfiltered) (unfiltered) X32_FLOAT One 32-bit floating-point 
number . . . (unfiltered) (unfiltered) D1R5G5B5 1 bit of garbage and three unsigned 5-bit fixed-point 
. . . numbers D8R8G8B8 8 bits of garbage and three unsigned 8-bit fixed-point . . . numbers Y16_X16 FLOAT 
Two 16-bit floating-point numbers . . . 30.4 Performance 489 474747  30.5 Achieving Optimal Performance 
While graphics hardware is becoming more and more programmable, there are still some tricks to ensuring 
that you exploit the hardware fully to get the most performance. This section lists some common techniques 
that you may find helpful. A more detailed discussion of performance advice is available in the NVIDIA 
GPU Programming Guide, which is freely available in several languages from the NVIDIA Developer Web 
site (http://developer.nvidia.com/object/gpu_programming_guide.html). 30.5.1 Use Z-Culling Aggressively 
Z-cull avoids work that won t contribute to the final result. It s better to determine early on that 
a computation doesn t matter and save doing the work. In graphics, this can be done by rendering the 
z-values for all objects first, before shading. For general-purpose computation, the z-cull unit can 
be used to select which parts of the computation are still active, culling computational threads that 
have already resolved. See Section 34.2.3 of Chapter 34, GPU Flow-Control Idioms, for more details on 
this idea. 30.5.2 Exploit Texture Math When Loading Data The texture unit filters data before returning 
it to the fragment processor, thus reducing the total data needed by the shader. The texture unit s bilinear 
filtering can frequently be used to reduce the total work done by the shader if it s performing more 
sophisticated shading. Often, large filter kernels can be dissected into groups of bilinear footprints, 
which are scaled and accumulated to build the large kernel. A few caveats apply here, most notably that 
all filter coefficients must be positive for bilinear footprint assembly to work properly. (See Chapter 
20, Fast Third-Order Texture Filtering, for more information about this technique.) Similarly, the filtering 
support given by shadow buffering can be used to offload the work from the processor when performing 
compares, then filtering the results. 30.5.3 Use Branching in Fragment Programs Judiciously Because 
the fragment processor is a SIMD machine operating on many fragments at a time, if some fragments in 
a given group take one branch and other fragments in that group take another branch, the fragment processor 
needs to take both branches. Also, there is a six-cycle overhead for if-else-endif control structures. 
These two effects can reduce the performance of branching programs if not considered carefully. Branching 
can be very beneficial, as long as the work avoided outweighs the cost of branching. 484848  Alternatively, 
conditional writes (that is, write if a condition code is set) can be used when branching is not performance-effective. 
In practice, the compiler will use the method that delivers higher performance when possible. 30.5.4 
Use fp16 Intermediate Values Wherever Possible Because GeForce 6 Series GPUs support a full-speed fp16 
normalize instruction in parallel with the multiplies and adds, and because fp16 intermediate values 
reduce internal storage and datapath requirements, using fp16 intermediate values wherever possible can 
be a performance win, saving fp32 intermediate values for cases where the precision is needed. Excessive 
internal storage requirements can adversely affect performance in the following way: The shader pipeline 
is optimized to keep hundreds of fragments in flight given a fixed amount of register space per fragment 
(four fp324 registers or eight fp164 registers). If the register space is exceeded, then fewer fragments 
can remain in flight, reducing the latency tolerance for texture fetches, and adversely affecting performance. 
The GeForce 6 Series fragment processor will have the maximum number of fragments in flight when shader 
programs use up to four fp324 temporary registers (or eight fp164 registers). That is, at any one time, 
a maximum of four temporary fp324 (or eight fp164) registers are in use. This decision was based on 
the fact that for the overwhelming majority of analyzed shaders, four or fewer simultaneously active 
fp324 registers proved to be the sweet spot during the shaders execution. In addition, the architecture 
is designed so that performance degrades slowly if more registers are used. Similarly, the register file 
has enough read and write bandwidth to keep all the units busy if reading fp164 values, but it may run 
out of bandwidth to feed all units if using fp324 values exclusively. NVIDIA s compiler technology is 
smart enough to reduce this effect s impact substantially, but fp16 intermediate values are never slower 
than fp32 values; because of the resource restrictions and the fp16 normalize hardware, they can often 
be much faster.  30.6 Conclusion GeForce 6 Series GPUs provide the GPU programmer with unparalleled 
flexibility and performance in a product line that spans the entire PC market. After reading this chapter, 
you should have a better understanding of what GeForce 6 Series GPUs are capable of, and you should be 
able to use this knowledge to develop applications either graphical or general purpose in a more efficient 
way. 491494949 30.6 Conclusion 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198768</article_id>
		<sort_key>50</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Mapping computational concepts to GPUs]]></title>
		<page_from>50</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198768</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198768</url>
		<abstract>
			<par><![CDATA[Recently, graphics processors have emerged as a powerful computational platform. A variety of encouraging results, mostly from researchers using GPUs to accelerate scientific computing and visualization applications, have shown that significant speedups can be achieved by applying GPUs to data-parallel computational problems. However, attaining these speedups requires knowledge of GPU programming and architecture.The preceding chapters have described the architecture of modern GPUs and the trends that govern their performance and design. Continuing from the concepts introduced in those chapters, in this chapter we present intuitive mappings of standard computational concepts onto the special-purpose features of GPUs. After presenting the basics, we introduce a simple GPU programming framework and demonstrate the use of the framework in a short sample program.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39060385</person_id>
				<author_profile_id><![CDATA[81100116782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Harris]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NVIDIA Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>862247</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Fernando, Randima, and Mark J. Kilgard. 2003. The Cg Tutorial: The Definitive Guide to Programmable Real-Time Graphics. Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844189</ref_obj_id>
				<ref_obj_pid>844174</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Harris, Mark J., William V. Baxter III, Thorsten Scheuermann, and Anselmo Lastra. 2003. "Simulation of Cloud Dynamics on Graphics Hardware." In Proceedings of the SIGGRAPH/Eurographics Workshop on Graphics Hardware 2003, pp. 92--101.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[NVIDIA Corporation. 2004. The Cg Toolkit. Available online at http://developer.nvidia.com/object/cg_toolkit.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Pearson, John E. 1993. "Complex Patterns in a Simple System." Science 261, p. 189.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Chapter 31 Mapping Computational Concepts to GPUs Mark Harris NVIDIA Corporation Recently, graphics 
processors have emerged as a powerful computational platform. A variety of encouraging results, mostly 
from researchers using GPUs to accelerate scientific computing and visualization applications, have 
shown that significant speedups can be achieved by applying GPUs to data-parallel computational problems. 
However, attaining these speedups requires knowledge of GPU programming and architecture. The preceding 
chapters have described the architecture of modern GPUs and the trends that govern their performance 
and design. Continuing from the concepts introduced in those chapters, in this chapter we present intuitive 
mappings of standard computational concepts onto the special-purpose features of GPUs. After presenting 
the basics, we introduce a simple GPU programming framework and demonstrate the use of the framework 
in a short sample program. 31.1 The Importance of Data Parallelism As with any computer, attaining maximum 
performance from a GPU requires some understanding of its architecture. The previous two chapters provide 
a good overview of GPU architecture and the trends that govern its evolution. As those chapters showed, 
GPUs are designed for computer graphics, which has a highly parallel style of computation that computes 
output streams of colored pixels from input streams of independent 31.1 The Importance of Data Parallelism 
493 505050  data elements in the form of vertices and texels. To do this, modern GPUs have many programmable 
processors that apply kernel computations to stream elements in parallel. The design of GPUs is essential 
to keep in mind when programming them whether for graphics or for general-purpose computation. In this 
chapter, we apply the stream processing concepts introduced in Chapter 29, Streaming Architectures and 
Technology Trends, to general-purpose computation on GPUs (GPGPU). The biggest difficulty in applying 
GPUs to general computational problems is that they have a very specialized design. As a result, GPU 
programming is entrenched in computer graphics APIs and programming languages. Our goal is to abstract 
from those APIs by drawing analogies between computer graphics concepts and general computational concepts. 
In so doing, we hope to get you into the data-parallel frame of mind that is necessary to make the most 
of the parallel architecture of GPUs. 31.1.1 What Kinds of Computation Map Well to GPUs? Before we get 
started, let s get an idea of what GPUs are really good at. Clearly they are good at computer graphics. 
Two key attributes of computer graphics computation are data parallelism and independence: not only is 
the same or similar computation applied to streams of many vertices and fragments, but also the computation 
on each element has little or no dependence on other elements. Arithmetic Intensity These two attributes 
can be combined into a single concept known as arithmetic intensity, which is the ratio of computation 
to bandwidth, or more formally: arithmetic intensity = operations / words transferred. As discussed in 
Chapter 29, the cost of computation on microprocessors is decreasing at a faster rate than the cost of 
communication. This is especially true of parallel processors such as GPUs, because as technology improvements 
make more transistors available, more of these transistors are applied to functional units (such as 
arithmetic logic units) that increase computational throughput, than are applied to memory hierarchy 
(caches) that decrease memory latency. Therefore, GPUs demand high arithmetic intensity for peak performance. 
As such, the computations that benefit most from GPU processing have high arithmetic intensity. A good 
example of this is the solution of systems of linear equations. Chapter 44, A GPU Framework for Solving 
Systems of Linear Equations, discusses the efficient representation of vectors and matrices and how to 
use this representation to rapidly solve linear partial differential equations. These computations perform 
well on GPUs because they are highly data-parallel: they consist of large streams of data elements (in 
the form of matrices and vectors), to which identical computational kernels are applied. The data communication 
required to compute each element of the output is small and coherent. As a result, the number of data 
words transferred from main memory is kept low and the arithmetic intensity is high. Other examples of 
computation that works well on GPUs include physically based simulation on lattices, as discussed in 
Chapter 47, Flow Simulation with Complex Boundaries, and all-pairs shortest-path algorithms, as described 
in Chapter 43, GPU Computing for Protein Structure Prediction. 31.1.2 Example: Simulation on a Grid 
For the rest of this chapter, we employ a simple but effective example: simulating natural phenomena 
on a grid. The Cartesian grid shown in Figure 31-1 is a discrete representation of the 2D spatial domain 
on which our phenomenon evolves. The example in this case is a physically based cloud simulation. We 
won t go into the physical and mathematical detail of this simulation, except to illustrate some basic 
GPGPU concepts. For more information on cloud simulation, see Harris et al. 2003. Computation on a grid 
is common in GPGPU, because grids have a natural representation on GPUs: textures. Also, GPUs contain 
small texture caches that are optimized for 2D data locality, unlike the 1D data caches employed in CPUs. 
Many computations map naturally to grids, including matrix algebra; image and volume processing; physically 
based simulation; and global illumination algorithms such as ray tracing, photon mapping, and radiosity 
(see Chapter 39, Global Illumination Using Progressive Refinement Radiosity ). Computations that aren 
t naturally performed on grids can also be mapped to grid computation by converting 1D addresses into 
2D addresses. The cloud simulation algorithm consists of a number of steps, as shown in Figure 31-1. 
The important detail about the algorithm steps is that each step updates the entire grid, and each step 
must complete before the next proceeds. In stream processing terms, the data stored in the grid cells 
make up our streams, and the algorithm steps are our computational kernels. Each kernel is applied to 
each stream element, generating a new stream that becomes the input to the next step. 31.1 The Importance 
of Data Parallelism 495 525252  This cloud simulation executes on the GPU. The data streams used in 
the simulation are represented on the grid (shown with exaggerated coarseness) and stored in textures. 
The algorithm is shown at right; each step in the algorithm is a kernel, implemented using a fragment 
program on the GPU. 31.1.3 Stream Communication: Gather vs. Scatter High arithmetic intensity requires 
that communication between stream elements be minimized, but for many computations, communication is 
a necessary evil. In the cloud simulation, for example, some of the kernels must obtain information from 
cells other than the one currently being processed by the kernel. When discussing data communication 
on GPUs, it is helpful to consider two main types of communication: gather and scatter. Gather occurs 
when the kernel processing a stream element requests information from other elements in the stream: it 
gathers information from other parts of memory. Scatter, on the other hand, occurs when the kernel processing 
a stream element distributes information to other stream elements: it scatters information to other 
parts of memory. In terms of traditional memory concepts, gather requires only random-access load capability, 
while scatter requires only random-access store capability. Later we show why gather is typically preferable 
to scatter.  31.2 An Inventory of GPU Computational Resources To start mapping general computation 
onto the specialized hardware of a GPU, we should first survey the computational resources that GPUs 
provide. We start with the computational workhorses: the processors. 31.2.1 Programmable Parallel Processors 
GPUs have two types of programmable processors: vertex processors and fragment processors. Vertex processors 
process streams of vertices (made up of positions, colors, normal vectors, and other attributes), which 
are the elements that compose polygonal geometric models. Computer graphics typically represents 3D 
objects with triangular meshes. The vertex processors apply a vertex program (sometimes called a vertex 
shader) to transform each vertex based on its position relative to the camera, and then each set of 
three vertices is used to compute a triangle, from which streams of fragments are generated. A fragment 
can be considered a proto-pixel. It contains all information needed to generate a shaded pixel in the 
final image, including color, depth, and destination in the frame buffer. The fragment processors apply 
a fragment program (sometimes called a pixel shader) to each fragment in the stream to compute the final 
color of each pixel. Vertex Processors Modern GPUs have multiple vertex processors (the NVIDIA GeForce 
6800 Ultra and the ATI Radeon X800 XT both have six). These processors are fully programmable and operate 
in either SIMD- or MIMD-parallel fashion on the input vertices (see Chapter 34 for more information on 
these terms). The basic primitives of 3D computer graphics are 3D vertices in projected space, represented 
by an (x, y, z, w) vector, and fourcomponent colors stored as (red, green, blue, alpha) vectors (often 
abbreviated RGBA), where alpha typically represents an opacity percentage. Because of this, vertex processors 
have hardware to process four-component vectors. This allows them to produce transformed vertex positions 
in fewer cycles. Vertex processors are capable of changing the position of input vertices. If you think 
about this, the position of these vertices ultimately affects where in the image pixels will be drawn. 
An image is nothing but an array of memory; thus, because vertex processors can control where in memory 
data will be written, they are thus capable of scatter. However, most current vertex processors cannot 
directly read information from vertex elements in the input stream other than the one currently being 
processed. Therefore, 31.2 An Inventory of GPU Computational Resources 497 545454  they are incapable 
of gather. The NVIDIA GeForce 6 Series GPUs have a new feature called vertex texture fetch (VTF). This 
means that GeForce 6 vertex processors are capable of random-access memory reads. So, we can store part 
or all of our input stream data in a vertex texture and use VTF to implement a gather operation. Fragment 
Processors Modern GPUs also have multiple fragment processors (the NVIDIA GeForce 6800 Ultra and the 
ATI X800 XT both have 16). Like vertex processors, these are fully programmable. Fragment processors 
operate in SIMD-parallel fashion on input elements, processing four-element vectors in parallel. Fragment 
processors have the ability to fetch data from textures, so they are capable of gather. However, the 
output address of a fragment is always determined before the fragment is processed: the processor cannot 
change the output location of a pixel. Fragment processors are thus not natively capable of scatter. 
However, see Section 31.3 for further discussion and techniques for working around this limitation. For 
GPGPU applications, the fragment processors are typically used more heavily than the vertex processors. 
There are two main reasons for this. First, there are more fragment processors than vertex processors 
on a typical programmable GPU. Second, the output of the fragment processors goes more or less directly 
into memory, which can be fed straight back in as a new stream of texture data. Vertex processor output, 
on the other hand, must pass through the rasterizer and fragment processors before reaching memory. This 
makes direct output from vertex processors less straightforward. Rasterizer As mentioned earlier, after 
the vertex processors transform vertices, each group of three vertices is used to compute a triangle 
(in the form of edge equations), and from this triangle a stream of fragments is generated. This work 
of generating fragments is done by the rasterizer. We can think of the rasterizer as an address interpolator. 
Later we show how memory addresses are represented as texture coordinates. The rasterizer interpolates 
these addresses and other per-vertex values based on the fragment position. Because it generates many 
data elements from only a few input elements, we can also think of the rasterizer as a data amplifier. 
These functions of the rasterizer are very specialized to rendering triangles and are not user-programmable. 
Texture Unit Fragment processors (and vertex processors on the latest GPUs) can access memory in the 
form of textures. We can think of the texture unit as a read-only memory interface. Render-to-Texture 
When an image is generated by the GPU, it can be written to frame-buffer memory that can be displayed, 
or it can be written to texture memory. This render-to-texture functionality is essential for GPGPU, 
because it is the only current mechanism with which to implement direct feedback of GPU output to input 
without going back to the host processor. (Indirect feedback is also available via copy-to-texture, which 
requires a copy from one location in the GPU s memory to another.) We can think of render-totexture 
as a write-only memory interface. You may be wondering why we don t consider the texture unit and render-to-texture 
together as a read-write memory interface. The reason is that the fragment processor can read memory 
as many times as it wants inside a kernel, but it can write data only at the end of the kernel program 
(this is stream out). Thus, memory reads and writes are fundamentally separate on GPUs, so it helps to 
think about them that way. Data Types When programming CPUs, we are used to dealing with multiple data 
types, such as integers, floats, and Booleans. Current GPUs are more limited in this regard. Although 
some of the high-level shading languages used by GPUs expose integer and Boolean data types, current 
GPUs process only real numbers in the form of fixed- or floatingpoint values. Also, there are multiple 
floating-point formats supported by current GPUs. For example, NVIDIA GeForce FX and GeForce 6 Series 
GPUs support both 16-bit (a sign bit, 10 mantissa bits, and 5 exponent bits) and 32-bit (a sign bit, 
23 mantissa bits, and 8 exponent bits: identical to the IEEE-754 standard) floating-point formats. All 
current ATI products, including the Radeon 9800 and X800, support a 24-bit floating-point format, with 
a sign bit, 16 mantissa bits, and 7 exponent bits. The lack of integer data types on GPUs is a current 
limitation. This can typically be worked around using floating-point numbers, but, for example, not all 
32-bit integers can be represented in 32-bit floating-point format (because there are only 23 bits in 
the mantissa). One must be careful because floating-point numbers cannot exactly represent the same 
range of whole numbers that their same-size integer counterparts can represent. Table 31-1 shows the 
bit fields of each floating-point format and a description of the values they can represent. 31.2 An 
Inventory of GPU Computational Resources 499 565656  Table 31-1. Floating-Point Formats Currently Supported 
by NVIDIA and ATI GPUs Whole Supports Largest Number Specials Name Sign Exponent Mantissa Values Smallest 
Values Range1 (NaN, Inf, etc.) NVIDIA 16-bit 15 (1) 14:10 (5) 9:0 (10) 65,504 2-14 . 10-5 2048 Yes 
(2-24 with denorms) ATI 16-bit 15 (1) 14:10 (5) 9:0 (10) 131,008 2-15 . 10-5 2048 No ATI 24-bit 23 
(1) 22:16 (7) 15:0 (16) ~264 . 1019 ~2-62 . 10-19 131,072 No NVIDIA 32-bit 31 (1) 30:23 (8) 22:0 (23) 
~2128 . 1038 ~2-126 . 10-38 16,777,216 Yes (IEEE 754) 1. This is the contiguous zero-centered range 
of exactly representable whole numbers.  31.3 CPU-GPU Analogies Even for expert CPU programmers, getting 
started in GPU programming can be tricky without some knowledge of graphics programming. In this section, 
we try to aid your understanding by drawing some very simple analogies between traditional CPU computational 
concepts and their GPU counterparts. We start with the concept of streams and kernels. 31.3.1 Streams: 
GPU Textures = CPU Arrays This one is easy. The fundamental array data structures on GPUs are textures 
and vertex arrays. As we observed before, fragment processors tend to be more useful for GPGPU than vertex 
processors. Therefore, anywhere we would use an array of data on the CPU, we can use a texture on the 
GPU. 31.3.2 Kernels: GPU Fragment Programs = CPU Inner Loops The many parallel processors of a GPU are 
its computational workhorses they perform the kernel computation on data streams. On the CPU, we would 
use a loop to iterate over the elements of a stream (stored in an array), processing them sequentially. 
In the CPU case, the instructions inside the loop are the kernel. On the GPU, we write similar instructions 
inside a fragment program, which are applied to all elements of the stream. The amount of parallelism 
in this computation depends on the number of processors on the GPU we use, but also on how well we exploit 
the instruction-level parallelism enabled by the four-vector structure of GPU arithmetic. Note that vertex 
programs can also be thought of as kernels operating on a stream of vertices.  31.3.3 Render-to-Texture 
= Feedback As mentioned before, most computations are broken into steps. Each step depends on the output 
of previous steps. In terms of streams, typically a kernel must process an entire stream before the next 
kernel can proceed, due to dependencies between stream elements. Also, in the case of physically based 
simulation, each time step of the simulation depends on the results of the previous time step. All of 
this feedback is trivial to implement on the CPU because of its unified memory model, in which memory 
can be read or written anywhere in a program. Things aren t so easy on the GPU, as we discussed before. 
To achieve feedback, we must use renderto-texture to write the results of a fragment program to memory 
so they can then be used as input to future programs. 31.3.4 Geometry Rasterization = Computation Invocation 
Now we have analogies for data representation, computation, and feedback. To run a program, though, we 
need to know how to invoke computation. Our kernels are fragment programs, so all we need to know is 
how to generate streams of fragments. This should be clear from the previous section; to invoke computation, 
we just draw geometry. The vertex processors will transform the geometry, and the rasterizer will determine 
which pixels in the output buffer it covers and generate a fragment for each one. In GPGPU, we are typically 
processing every element of a rectangular stream of fragments representing a grid. Therefore, the most 
common invocation in GPGPU programming is a single quadrilateral. 31.3.5 Texture Coordinates = Computational 
Domain Each kernel (fragment program) that executes on the GPU takes a number of streams as input and 
typically generates one stream of output. Newer GPUs that support multiple render targets can generate 
multiple output streams (currently limited to four RGBA streams). Any computation has an input domain 
and an output range. In many cases, the domain of a computation on the GPU may have different dimensions 
than the input streams. GPUs provide a simple way to deal with this, in the form of texture coordinates. 
These coordinates are stored at vertices, and the rasterizer linearly interpolates the coordinates at 
each vertex to generate a set of coordinates for each fragment. The interpolated 31.3 CPU-GPU Analogies 
501 585858  coordinates are passed as input to the fragment processor. In computer graphics, these coordinates 
are used as indices for texture fetches. For GPGPU, we can think of them as array indices, and we can 
use them to control the domain of the computation. The domain and range may be the same size, or the 
domain can be smaller than the range (data amplification/magnification), or the domain can be larger 
than the range (data minification). The rasterizer makes it easy to correctly sample the input stream 
at the correct intervals for each of these cases.  31.3.6 Vertex Coordinates = Computational Range As 
discussed before, fragments are generated from input geometry by the rasterizer, and these fragments 
become output pixels after fragment processing. Because the fragment processors are not directly capable 
of scatter, the input vertices and the vertex program determine which pixels are generated. Typically, 
we specify four vertices of a quad in output pixel coordinates and apply a vertex program that simply 
passes the vertices through untransformed. Thus, vertex coordinates directly control the output range 
of the computation. 31.3.7 Reductions Everything we ve discussed up to this point has assumed purely 
parallel computation: each element is computed largely independently of the rest of the stream. However, 
there are times when we need to reduce a large vector of values to a smaller vector, or even to a single 
value. For example, we might need to compute the sum or the maximum of all values in an array. This 
sort of computation is called a parallel reduction. On GPUs, reductions can be performed by alternately 
rendering to and reading from a pair of buffers. On each pass, the size of the output (the computational 
range) is reduced by some fraction. To produce each element of the output, a fragment program reads two 
or more values and computes a new one using the reduction operator, such as addition or maximum. These 
passes continue until the output is a single-element buffer, at which point we have our reduced result. 
In general, this process takes O(log n) passes, where n is the number of elements to reduce. For example, 
for a 2D reduction, the fragment program might read four elements from four quadrants of the input buffer, 
such that the output size is halved in both dimensions at each step. Figure 31-2 demonstrates a max reduction 
on a 2D buffer.   31.4 From Analogies to Implementation By now you have a high-level understanding 
of how most GPGPU programs operate on current GPUs. The analogies from the previous section provide us 
a general implementation plan. Now, so that you can start putting the GPU to work, we dig into the nitty-gritty 
implementation details that you will need in practice. 31.4.1 Putting It All Together: A Basic GPGPU 
Framework To make this easy, we ve put together a very basic framework in C++ that you can use to write 
GPGPU programs. You ll find the framework on the CD included with this book. The framework, called pug, 
incorporates all of the analogies from the previous section in order to abstract GPGPU programming in 
a manner more accessible to experienced CPU programmers. Initializing and Finalizing a GPGPU Application 
The first step in a GPGPU application is to initialize the GPU. This is very easy in the framework: just 
call pugInit(). When the application is finished with the GPU, it can clean up the memory used by the 
graphics API by calling pugCleanup(). Specifying Kernels Kernels in our framework are written in the 
Cg language. Although Cg is designed for graphics, it is based on the C language and therefore is very 
easy to learn. For more information, we recommend The Cg Tutorial (Fernando and Kilgard 2003) and the 
31.4 From Analogies to Implementation 503 606060  documentation included with the Cg distribution (NVIDIA 
2004). There are very few graphics-specific keywords in Cg. We provide a Cg file, pug.cg, that you can 
include in your kernel files. This file defines a structure called Stream that abstracts the most graphics-centric 
concept: texture fetching. Streamis a wrapper for the texture sampler Cg type. Calling one of the value() 
functions of the Stream structure gives the value of a stream element. To load and initialize a kernel 
program from a file, use the pugLoadProgram() function. The function returns a pointer to a PUGProgram 
structure, which you will need to store and pass to the other framework functions to bind constants and 
streams to the kernel and to run it. Stream Management Arrays of data in the framework are called buffers. 
The pugAllocateBuffer() function creates a new buffer. Buffers can be read-only, write-only, or read-write, 
and this can be specified using the mode parameter of this function. This function returns a pointer 
to a PUGBuffer structure, which can be passed to a number of functions in the framework, including the 
following two. To load initial data into a buffer, pass the data to the pugInitBuffer() function. To 
bind an input stream for a kernel to a buffer, call pugBindStream(), which takes as arguments a pointer 
to the PUGProgram to bind to, the PUGBuffer pointer, and a string containing the name of the Stream parameter 
in the Cg kernel program to which this PUGBuffer should be bound. Specifying Computational Domain and 
Range To specify the domain and range of a computation, define a PUGRect structure with the coordinates 
of the corners of the rectangle that should be used as either the domain or range. Multiple domains can 
be specified. These will generate additional texture coordinates that the kernel program can use as needed. 
To bind a domain, call pugBindDomain(), passing it the PUGProgram, a string parameter name for this domain 
defined in the kernel Cg program, and the PUGRect for the domain. There can be only one range for a kernel, 
due to the inability of fragment programs to scatter. To specify the range, simply pass a PUGRect to 
the range parameter of the pugRunProgram() function. Specifying Constant Parameters Constant one-, two-, 
three-, or four-component floating-point parameters can be specified using pugBindFloat(), which takes 
as arguments a pointer to the PUGProgram, a string parameter name, and up to four floating-point values. 
Invoking a Kernel Once the preceding steps have been done, executing the computation is simple: just 
call the function pugRunProgram(). Pass it a pointer to the PUGProgram, the output PUGBuffer (which must 
be writable), and an optional PUGRect to specify the range. The entire buffer will be written if the 
range is not specified. Note that a stream cannot be bound to a buffer if that buffer is currently being 
used for the output of a kernel. The framework will automatically release all streams bound to any buffer 
that is specified as the output buffer in pugRunProgram(). Getting Data Back to the CPU To bring results 
on the GPU back to the CPU, call the pugGetBufferData() function, passing it a pointer to the PUGBuffer. 
This function returns a pointer to a C array of type float. Reading data back from the GPU can cause 
the GPU pipeline to flush, so use this function sparingly to avoid hurting application performance. Parallel 
Reductions The framework provides support for three types of simple parallel reduction. Buffers can be 
reduced along rows (to a single column vector), along columns (to a single row vector), or both (to a 
single value). The framework functions for these operations are pugReduce1D() and pugReduce2D().  31.5 
A Simple Example As a basic but nontrivial GPGPU example, we use a simulation of a phenomenon known as 
chemical reaction-diffusion. Reaction-diffusion is a model of how the concentrations of two or more 
reactants in a solution evolve in space and time as they undergo the processes of chemical reaction 
and diffusion. The reaction-diffusion model we use is called the Grey-Scott model (Pearson 1993) and 
involves just two chemical reactants. This phenomenological model does not represent a particular real 
chemical reaction; it serves as a simple model for studying the general reaction-diffusion phenomenon. 
Figure 31-3 shows the results of many iterations of the Grey-Scott model. 31.5 A Simple Example 505 626262 
  Grey-Scott consists of two simple partial differential equations that govern the evolution of the 
concentrations of two chemical reactants, Uand V: .U = Du.2U- UV2 + F(1 - U), .t .V 22 = D. V+ UV -(F+ 
kV . ) .tv Diffusion Reaction Here kand Fare constants; Duand Dvare the diffusion rates of the reactants; 
and .2 is the Laplacian operator, which represents diffusion. The Laplacian operator appears commonly 
in physics, most notably in the form of diffusion equations, such as the heat equation. A finite difference 
form of the Laplacian operator applied to a scalar field p on a two-dimensional Cartesian grid (with 
indices i, j, and cell size .x)is 2 pi+1, j + pi-1, j + pij, +1 + pij, -1 - 4 pij, . p= 2. (.x) The implementation 
of the Grey-Scott model is fairly simple. There is a single data stream: the Uand Vchemical concentrations 
are stored in two channels of a single texture that represents a discrete spatial grid. This stream serves 
as input to a simple kernel, which implements the preceding equations in discrete form. The kernel is 
shown in Listing 31-1. C code that uses the framework to implement the simulation is shown in Listing 
31-2. Listing 31-1. The Reaction-Diffusion Kernel Program float4 rd(float2 coords : DOMAIN, uniform 
stream concentration, uniform float2 DuDv, uniform float F, uniform float k) : RANGE { float2 center 
= concentration.value2(coords).xy; float2 diffusion = concentration.value2(coords + half2(1, 0)); diffusion 
+= concentration.value2(coords + half2(-1, 0)); diffusion += concentration.value2(coords + half2(0, 1)); 
diffusion += concentration.value2(coords + half2(0, -1));  // Average and scale by diffusion coeffs 
 diffusion *= 0.25f * DuDv; float2 reaction = center.xx * center.yy * center.yy; reaction.x = -1; reaction.x 
+= (1 DuDv.x) * center.x + F * (1 - center.x); reaction.y += (-F k + (1 DuDv.y)) * center.y;  // 
Now add the diffusion to the reaction to get the result. return float4(diffusion + reaction, 0, 0); 
} Listing 31-2. C++ Code to Set Up and Run a Reaction-Diffusion Simulation on the GPU See the source 
code on the accompanying CD for more details. PUGBuffer *rdBuffer; PUGProgram *rdProgram; void init_rd(){ 
// Call this once. pugInit(); // Start up the GPU framework // Create a double-buffered PUGBuffer. Two 
buffers allow the // simulation to alternate using one as input, one as output PUGBuffer *rdBuffer = 
pugAllocateBuffer(width, height, PUG_READWRITE, 4, true); PUGProgram *rdProgram = pugLoadProgram("rd.cg", 
"rd"); pugBindFloat(rdProgram, "DuDv", du, dv); // bind parameters pugBindFloat(rdProgram, "F", F); 
pugBindFloat(rdProgram, "k", k);  31.5 A Simple Example 507 646464  Listing 31-2 (continued). C++ Code 
to Set Up and Run a Reaction-Diffusion Simulation on the GPU // Initialize the state of the simulation 
with values in array pugInitBuffer(rdBuffer, array); } void update_rd(){ // Call this every iteration 
pugBindStream(rdProgram, "concentration", rdBuffer, currentSource); PUGRect range(0, width, 0, height); 
pugRunProgram(rdProgram, rdBuffer, range, currentTarget); std::swap(currentSource, currentTarget); } 
  31.6 Conclusion You should now have a good understanding of how to map general-purpose computations 
onto GPUs. With this basic knowledge, you can begin writing your own GPGPU applications and learn more 
advanced concepts. The simple GPU framework introduced in the previous section is included on this book 
s CD. We hope that it provides a useful starting point for your own programs. 31.7 References Fernando, 
Randima, and Mark J. Kilgard. 2003. The Cg Tutorial: The Definitive Guide to Programmable Real-Time Graphics. 
Addison-Wesley. Harris, Mark J., William V. Baxter III, Thorsten Scheuermann, and Anselmo Lastra. 2003. 
Simulation of Cloud Dynamics on Graphics Hardware. In Proceedings of the SIGGRAPH/Eurographics Workshop 
on Graphics Hardware 2003, pp. 92 101. NVIDIA Corporation. 2004. The Cg Toolkit. Available online at 
http://developer.nvidia.com/object/cg_toolkit.html Pearson, John E. 1993. Complex Patterns in a Simple 
System. Science 261, p. 189.            
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198769</article_id>
		<sort_key>73</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Linear algebra on GPUs]]></title>
		<page_from>73</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198769</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198769</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35035771</person_id>
				<author_profile_id><![CDATA[81100607061]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jens]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kr&#252;ger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Technische Universit&#228;t M&#252;nchen]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Chorin, A. J., Marsden, J. E. A Mathematical Introduction to Fluid Mechanics. 3rd ed. Springer, New York, 1993]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357695</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Briggs, Henson, McCormick A Multigrid Tutorial, 2nd ed. siam, ISBN 0-89871-462-1]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Acton Numerical Methods that Work, The Mathematical Association of America ISBN 0-88385-450-3]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882363</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Kr&#252;ger, J. Westermann, R. Linear algebra operators for GPU implementation of numerical algorithms, In Proceedings of SIGGRAPH 2003, ACM Press / ACM SIGGRAPH, http://wwwcg.in.tum.de/Research/Publications]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882364</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bolz, J., Farmer, I., Grinspun, E., Schr&#246;der, P. Sparse Matrix Solvers on the GPU: Conjugate Gradients and Multigrid, In Proceedings of SIGGRAPH 2003, ACM Press / ACM SIGGRAPH, http://www.multires.caltech.edu/pubs/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882365</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hillesland, K. E. Nonlinear Optimization Framework for Image-Based Modeling on Programmable Graphics Hardware, In Proceedings of SIGGRAPH 2003, ACM Press / ACM SIGGRAPH, http://www.cs.unc.edu/~khillesl/nlopt/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383260</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Fedkiw, R., Stam, J. and Jensen, H. W. Visual Simulation of Smoke. In Proceedings of SIGGRAPH 2001, ACM Press / ACM SIGGRAPH. 2001, http://graphics.ucsd.edu/~henrik/papers/smoke/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311548</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Stam, J. Stable Fluids. In Proceedings of SIGGRAPH 1999, ACM Press / ACM SIGGRAPH, 121--128. 1999, http://www.dgp.toronto.edu/people/stam/reality/Research/pub.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569061</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Harris, M., Coombe, G., Scheuermann, T., and Lastra, A. Physically-Based Visual Simulation on Graphics Hardware. Proc. 2002 SIGGRAPH / Eurographics Workshop on Graphics Hardware 2002, http://www.markmark.net/cml/]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Why LA on GPUs?  1. Why should we care about Linear Algebra at all? Use LA to solve PDEs solving PDEs 
can increase realism for VR, Education, Simulations, Games, Why Linear Alge bra o n GPUs? Getting sta 
r ted  2. and why do it on the GPU? a) The GPU is a fast streaming processor LA operations are easily 
streamable b) The result of the computation is already on the GPU and ready for display  Representa 
tion (cont.) Representa tion (cont.) Banded Sparse Matrix representation Banded Sparse Matrix representation 
 treat a banded matrix as a set ofdiagonal vectors combine opposing vectors to save space Matrix 2 Vectors 
Matrix 2 Vectors i i 2 2D-Textures 2 2D-Textures 1 2 1 2 N NN N N-i 12 12 NN Operations Operations (cont.) 
 Vector-Vector Operations Vector-Vector Operations Reduced to 2D texture operations Reduce operation 
for scalar products  Coded in vertex/fragment shaders  1 pass 2 passoriginal Texture stnd Example: 
Vector1 + Vector2 Vector3 ... ... ... Vector 1 Vector 2 Vector 3 + ... TexUnit 0 TexUnit 1 Render To 
Texture Reduce m x n region in fragment shader Static quad Pass through return tex0 + tex1 Vertex Shader 
Pixel Shader The single float on GPUs Operations (cont.) In depth example: Vector / Banded-Matrix 
Multiplication Some operations generate single float values A bx e.g. reduce ... Read-back to main-mem 
is slow = Keep single floats on the GPU as 1x1 textures 747474  Building a Framework Building a Framework 
Example: CG Presented so far: representations on the GPU for single float values  vectors  matrices 
  dense  banded  random sparse  operations on these representations add, multiply, reduce,  upload, 
download, clear, clone,  Encapsulate into Classes for more complex algorithms Example use: Conjugate 
Gradient Method, complete source: void clCGSolver::solveInit() { Matrix->matrixVectorOp(CL_SUB,X,B,R); 
// R = A*x-b - R->multiply(-1); // R = -R R->clone(P); // P = R - R->reduceAdd(R, Rho); // rho = sum(R*R); 
-= } void clCGSolver::solveIteration() {Matrix->matrixVectorOp(CL_NULL,P,NULL,Q); // Q = Ap; P->reduceAdd(Q,Temp); 
// temp = sum(P*Q); -= Rho->div(Temp,Alpha); // alpha = rho/temp; = X->addVector(P,X,1,Alpha); // X = 
X + alpha*P R->subtractVector(Q,R,1,Alpha); // R = R -alpha*Q - R->reduceAdd(R,NewRho); // newrho = 
sum(R*R); NewRho->divZ(Rho,Beta); // beta = newrho/rho - R->addVector(P,P,1,Beta); // P = R+beta*P; 
clFloat *temp; temp=NewRho; NewRho=Rho; Rho=temp; // swap rho and newrho pointers } void clCGSolver::solve(int 
maxI) { solveInit();for (int i = 0;i< maxI;i++) solveIteration(); }int clCGSolver::solve(float rhoTresh, 
int maxI) { solveInit(); Rho->clone(NewRho); - for (int i = 0;i< maxI &#38;&#38; NewRho.getData() > rhoTresh;i++) 
solveIteration(); = return i; }} 757575  ves (implicit) Example 2: 2D Wa ves (implicit) 4a+1 -a -a 
 1 1 t + x tc 1 -a 4a+1 -a -a 1 2 t + x tc 2 -a 4a+1 -a 1 3 t + x tc 3 -a 4a+1 -a -a 1 4 t + x = tc 
4 -a -a 4a+1 -a -a 1 5 t + x tc 5 -a -a 4a+1 -a 1 6 t + x tc 6 -a 4a+1 -a 1 7 t + x tc 7 -a -a 4a+1 
-a 1 8 t + x tc 7  -a -a 4a+1 1 9 t + x tc 9 t tttt tt-1 ii-1, ji, j-1 i+1, ji, j+1 i, ji, j c =a (x 
+ x + x + x )+ (2 - 4a ) x - x .t2 c2 wherea= 2.h2   NSE Disc re ti zat i on Navie r - Stokes Equations 
(cont.) Diffusion 22 2 . . . .().() . v 1 . vv . uvv p =.+.- - +g - . 22 .y .t Re ..x .y ..x .y .y 
Advection 2 ..v . vi+1, j -2vi, j +vi-1, j = . 2 .2 ..i, jy .x ()d 2 -+ ..v. vi, j+12vi, j vi, j-1 
..2 .2 = .y . ()dy i, j Pressure .(). (u +u +)(+v +)( +u - +)(v +v ). .u +u i, ji, j+1. uv 1 . i, ji, 
j 1 vi, ji 1, j ui-1, ji 1, j 1 i-1, ji, j 1 . (vi, j -vi+1, j )(ui-1, j +ui-1, j+1 )(vi-1, j -vi, j 
).. ..x .dx . 22 22 .dx . 22 - 22 . =.- .+a ....i, j . . ..p. pi, j+1 -pi, j .. = ..y .dy i, j Rewrite 
the Navier Stokes Equations ()1 dtt +dt ()1 t ()t ()+1 ()t+ ()t 1 ()t + ()+ + t t u =F - (p -p 1 ) v 
=G -(p -p 1 ) i, ji, ji+1, ji, ji, ji, ji, j+1 i, j dx dy where . . 22 . 2 . .. . .. . ..(). ..(). .1 
. uu . u uv . Fi, j =ui, j +.t .2 . +.2 .-. .-. .+gx ; . ..... . . .Re ..x .i, j .y .i, j .. x .i, j 
. y .i, j . . . 22 . 2 . . .. v . .. . . ..() ..()v .. 1 . v uv . Gi, j =vi, j +.t ..+..-..-. .+gy ; 
.. 22 .. .Re ...x .i, j ..y .i, j . ..x .i, j ..y .i, j . now F and G can be computed  Navie r - Stokes 
Equations (cont.) Navie r - Stokes Equations (cont.) Problem: Pressure is still unknown! 1 ()t dt ()+ 
()t ()t 1 ()t dt + ()+ ()t+ t 1 + +()t 1 t u =F -(p -p 1 ) v =G - (p -p 1 ) i, ji, ji+1, ji, ji, ji, 
ji, j+1 i, j dx dy From div(V ) =0 derive: t+1 t+1 t 2 t+1 t 2 t+1 .u .v .G .p .F .p 0 = + =-.t + -.t.x 
.y .x .x2 .y .y2 ...to get this Poisson Equation: + +++ ++ ()1 ()1 ()n ()1 n ()1 n () n () nn 1 n ()1 
n () n () npi+1, j -2 pi, j +pi-1, j pi, j+1 -2 pi, j +pi, j-11 .Fi, j -Fi-1, j Gi, j -Gi, j-1 . 22 .. 
+ =.+ . ()d () d.dx d. x dyt y The basic algorithm: 1. Compute F and G 1. add external forces easy 2. 
advect semi-lagrange [Stam 1999] 3. diffuse explicit  2. solve the Poisson equation use the CG solver 
 3. update velocities subtract pressure gradient   Multigrid on G P U s Multigrid in English  1. 
do a few Jacobi/Gauss-Seidel iterations on the finegrid Jacobi/G-S eliminate high frequencies in the 
error  conjugate gradient does not have this property !!!  2. compute the residuum of the last approximaton 
 3. propagate this residuum to the next coarser grid  can be done by the means of a matrix multiplication 
4. solve the coarser grid for the absolute error for the solution you can use another multigrid step 
5. backpropagate the error to the finer grid can be done by another matrix multiplication (transposed 
matrix from 3.) 6. use the error to correct the first approximation 7. do another few Jacobi/Gauss-Seidel 
iterations toremove noise introduced by the propagation steps 777777   Multigrid in Greek Multigrid 
(cont.) Consider this problem: x is the solution hh h Ax = b vector of a set of linear equations  hhh 
h this equation holds for current A (x'+ e )= b approximation x with the error e hhh hh Ae = b - A 
 x' rearranging leads to the residual equation  with residuum r h r 2hh h 2hh now multiply both 
sides with a nonIh  A  eN = Ih  r quadratic interpolation matrix and replace 2h 2h the error with 
an error times the Ie h transposed interpolation matrix Let A2h be the product of the Interpolation 
2hh2h 2h 2h (I  A  I )e = r Matrix, A and the transposed Interpolation matrix. hh 2h2h 2h A e = r 
Finally we end up with a new set of linear equations with only half the size in every dimension of the 
old one. We solve this set for the error at this grid level. Propagating the error the above steps we 
can derive the error for the large system and use it to correct out approximation  fine grid , coarse 
grid only makes sense if the problem to solve corresponds to a grid this is the case in the finite difference 
methods described before  need to find an interpolation matrix for the propagation step to generate 
the coarser grid (for instance simple linear interpolation)  need an extrapolation matrix to move from 
the coarse to the fine grid  the coarse grid matrices can be pre-computed  Multigrid on G P U s Observation: 
 you only need matrix-vector operations and a Jacobi smoother to do multigrid  to put it on the GPU 
simply use the matrix-vector operations from the framework  Improvement: to do the interpolation an 
extrapolation steps we can use the fast bilinear interpolation hardware of the GPU instead of a vector-matrix 
multiplication  Selected R e ferences  Chorin, A.J., Marsden, J.E. A Mathematical Introduction to Fluid 
Mechanics. 3rd ed. Springer. New York, 1993  Briggs, Henson, McCormick A Multigrid Tutorial, 2nd ed. 
siam, ISBN 0-89871-462-1  Acton Numerical Methods that Work, The Mathematical Association of America 
ISBN 088385-450-3  Krger, J. Westermann, R. Linear algebra operators for GPU implementation of numerical 
algorithms, In Proceedings of SIGGRAPH 2003, ACM Press / ACM SIGGRAPH, http://wwwcg.in.tum.de/Research/Publications 
 Bolz , J., Farmer, I., Grinspun, E., Schrder, P. Sparse Matrix Solvers on the GPU: Conjugate Gradients 
and Multigrid, In Proceedings of SIGGRAPH 2003, ACM Press / ACM SIGGRAPH, http://www.multires.caltech.edu/pubs/ 
 Hillesland, K. E. Nonlinear Optimization Framework for Image-Based Modeling on Programmable Graphics 
Hardware, In Proceedings of SIGGRAPH 2003, ACM Press / ACM SIGGRAPH, http://www.cs.unc.edu/~khillesl/nlopt/ 
 Fedkiw, R., Stam, J. and Jensen, H.W. Visual Simulation of Smoke. In Proceedings ofSIGGRAPH 2001, ACM 
Press / ACM SIGGRAPH. 2001, http://graphics.ucsd.edu/~henrik/papers/smoke/  Stam, J. Stable Fluids. 
In Proceedings of SIGGRAPH 1999, ACM Press / ACM SIGGRAPH, 121-128. 1999, http://www.dgp.toronto.edu/people/stam/reality/Research/pub.html 
 Harris, M., Coombe, G., Scheuermann, T., and Lastra, A. Physically-Based VisualSimulation on Graphics 
Hardware.. Proc. 2002 SIGGRAPH / Eurographics Workshop on Graphics Hardware 2002, http://www.markmark.net/cml/ 
   
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198770</article_id>
		<sort_key>79</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Sorting and searching]]></title>
		<page_from>79</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198770</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198770</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39061163</person_id>
				<author_profile_id><![CDATA[81100647803]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Purcell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NVIDIA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198771</article_id>
		<sort_key>88</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Interactive geometric computations using graphics processors]]></title>
		<page_from>88</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198771</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198771</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40026672</person_id>
				<author_profile_id><![CDATA[81100383019]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Naga]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Govindaraju]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[UNC Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198772</article_id>
		<sort_key>109</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[High level languages for GPUs]]></title>
		<page_from>109</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198772</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198772</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35035733</person_id>
				<author_profile_id><![CDATA[81100248942]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Buck]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NVIDIA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198773</article_id>
		<sort_key>114</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Debugging tools]]></title>
		<page_from>114</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198773</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198773</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39061164</person_id>
				<author_profile_id><![CDATA[81100647803]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Purcell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NVIDIA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
       1. Load / S t ore Style 2. Iterativ e Deepenin g Style ... ADD R0, R1, f[WPOS]; MAD R1, 
R0, R2, R3; TEX R2, R1, TEX0, RECT; ... ... ADD R0, R1, f[WPOS]; MAD R1, R0, R2, R3; TEX R2, R1, TEX0, 
RECT; ...  TEX R0, f[WPOS], TEX0, RECT; TEX R2, f[WPOS], TEX1, RECT; TEX R3, f[WPOS], TEX2, RECT; MAD 
R1, R0, R2, R3; MOV o[COLR], R1; END  2. Iterativ e Deepenin g Style 2. Iterativ e Deepenin g Style 
 ... ADD R0, R1, f[WPOS]; MAD R1, R0, R2, R3; TEX R2, R1, TEX0, RECT; ... ... ADD R0, R1, f[WPOS]; MAD 
R1, R0, R2, R3; TEX R2, R1, TEX0, RECT; ... ... ADD R0, R1, f[WPOS]; MAD R1, R0, R2, R3; MOV o[COLR], 
R1; END ... ADD R0, R1, f[WPOS]; MAD R1, R0, R2, R3; TEX R2, R1, TEX0, RECT; MOV o[COLR], R2; END 
 Later co d e m o re expen s iv e than early cod e   Basic Shadesmith Flow Future Work  Deco mpo s 
e program into smaller programs  U s e i t era t i v e de epe n i n g a ppr oa ch  Run pro g rams 
r e quired t o determine watch values  One pro g ram pe r value watched  Readback modi fi ed regi 
st er t o h o st   Vi a gl Read P i xel s ()  Display register values per pi x e l  V i sua l i 
za tion windo w s  Per -pix e l valu e s o n mou s e o ver    Occlu s ions fr om multip le f r agments 
  GL trace playback debugging  Repro d ucibl e bu gs  El iminate nee d t o drive a p p. a n d debug 
g er   Vert ex programs  Branching 118118118  
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198774</article_id>
		<sort_key>119</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Efficient data parallel computing on GPUs]]></title>
		<page_from>119</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198774</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198774</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP24038847</person_id>
				<author_profile_id><![CDATA[81100188094]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Cliff]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Woolley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Virginia / NVIDIA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 In this part of the course, we'll look at some tricks and traps for programming the GPU for general 
purpose computation more effectively. This first part of this section will attempt to get you, the CPU 
programmer, to start to think in "GPU terms." There are some mistakes that every beginning GPU programmer 
(even those who are experienced CPU programmers) seem to make; those are the things I'm aiming to address 
in this part of the talk. After this introduction to "GPU thinking," Aaron and Ian will delve into more 
details about exactly how you can sculpt your algorithms so that they make the best use of what the GPU 
has to offer. While modern CPUs do have SIMD processing extensions such as MMX or SSE, most CPU programmers 
never attempt to use these capabilities themselves. As a result, it s not uncommon to see new GPU programmers 
writing code that ineffectively utilizes vector arithmetic in other words, their code fails to leverage 
instruction-level parallelism. Alternatively, some problems are inherently scalar in nature and can be 
more effectively parallelized by operating on multiple domain elements simultaneously. This data-level 
parallelism is particularly common in GPGPU applications. 119119119  The easiest way to explain what 
I mean by most of the following is to give you an example to go from. Ignore the fact for now that this 
fragment program is more or less unreadable... we're going to factor it out to have it make more sense 
(and, more importantly, be more efficient), as we go along. This example was originally written for the 
paper "A Multigrid Solver for Boundary Value Problems Using Programmable Graphics Hardware", Goodnight 
et al., Graphics Hardware 2003. The complete original shader is in the course notes. My task in working 
on the research that went into that paper was to take shaders like this one and optimize them so that 
they'd perform more reasonably. I'll walk you through some of those transformations in the following 
slides. The first kind of parallelism you should get used to looking for is instruction-level parallelism. 
In these two lines of code, you can see that each multiplication and each addition or subtraction is 
operating on a scalar value. That's a waste of computational resources! If you can manage to get all 
of the data packed into a 4vector, you can get all of your multiples done in a single instruction, for 
example. The trick is to find a way to do it such that the packing of data amounts to fewer instructions 
than the original, separate multiplies would have been. In the second case listed above, that's particularly 
easy... swizzling is your friend! For the first line, a little simple algebraic manipulation turns out 
to work wonders... Granted, high-level compilers for GPU code and the internal run-time optimizers contained 
within the drivers are getting better all the time, and they handle this sort of situation better than 
they used to. In practice, however, it still seems to be the case that the more you can exploit the vector 
nature of the hardware yourself in your fragment and vertex programs, the better off you ll be. (Of course, 
make sure you run a benchmark both before and after each optimization you apply to make sure that it 
really does give you a speedup.) Let s look at the highlighted lines first. So here's what those same 
two lines might look like if we were to pack the data so as to extract better instruction-level parallelism. 
A particular combination of operations to watch out for is multiply-and-add, since that's a single instruction 
on both NVIDIA and ATI GPU's. We can thus turn our nasty offset computation, which had four multiplies 
and four subtractions into a single subtraction and a single multiply-and-add. One thing you might notice 
is that even though we've gotten better ILP out of the first example, we're still operating on 2-vectors 
rather than 4-vectors. This means half of our computational power for those two instructions is wasted. 
Superscalar capabilities of newer GPUs might mitigate this problem; for example, the NV40 has co-issue 
capability, which means that two 2-vector operations can run in parallel at the same speed as a single 
4-vector operation. But it's still worth keeping this kind of situation in mind, because if you find 
yourself consistently relying on co-issue 120120120 within a single shader, you might not have enough 
arithmetic to fill up all of the available slots. In that situation, you might be better off looking 
for parallelism at the data level rather than at the instruction level. Frequently in GPGPU-land, the 
geometry we end up drawing is really big quads, so that we can have our fragment programs run on a big 
2D array of data that happens to be represented as a texture map of some kind. Sometimes, the most effective 
parallelism you can get turns out to be to pack the data itself more efficiently. This gives you opportunities 
to have each instruction do four times as much work more readily, of course, but it also gives the additional 
important benefit that it cuts down on your memory bandwidth usage. That's not to say that this approach 
will always be applicable; maybe you need some of those extra channels to store other data in, for example. 
But it's worth considering whether moving that extra data to a separate texture and stacking the bulk 
of your data (also called "domain decomposition") could give you a speedup. Hint: if you're memory-bandwidth 
bound, it very well might. Here we see two common approaches and one custom approach to data packing. 
The two common approaches simply rearrange the data, either packing domain quadrants into the four color 
channels of a  size buffer or by stacking adjacent domain elements into the four channels. Which would 
be more efficient depends on the memory access patterns of your particular application. The custom method 
was the one used by Goodnight et al. in their EGSR2003 paper on tone mapping on GPUs. They duplicate 
the data, thus using additional GPU memory, but do so in a way that the data layout matches their computational 
needs closely and allows them to avoid unpacking overhead at the end of processing.  An interesting 
aspect of "GPU thinking" is that it's both possible and likely (at least for GPGPU applications) that 
subsequent stages of the GPU pipeline will have to do increasing amounts of work. For every big quad 
you draw, only four vertices get processed, but many many more fragments result. So the next part of 
wrapping your brain around efficient use of the GPU is deciding exactly how frequently each value you 
use needs to be computed. To put it in more familiar terms, this is more or less identical to loop invariant 
code from nested loops in a CPU program, except that the different levels of loop nesting in this case 
translate into entirely separate programs that run in parallel when possible. 121121121  There's one 
other aspect of computational frequency that I've yet to mention. In this case it's not so much a matter 
of precomputation as it is optimizing the "fast path" if you have a big block of code in your fragment 
program that will only get executed on some fragments and not on others. It might well be advantageous 
to split such a case up into multiple fragment programs; one that uses the block and one that omits it. 
Then just draw more than one primitive, using each shader in turn. In the case shown here, our sample 
"smooth" shader is much more complex on the boundaries of our domain than on the interior of the domain. 
So we split up the shader into two; one fast-path shader that doesn't handle any boundary conditions, 
and a slower one that does handle them. Again this is equivalent to an optimization you might do in equivalent 
CPU code; if you have a conditional in your inner loop, it might be advantageous to split it into two 
loops, one of which handles all the "true" cases for the condition and one of which handles all the "false" 
cases. Following are the final versions of the two smooth shaders after all optimizations have been applied. 
 An interesting aspect of "GPU thinking" is that it's both possible and likely (at least for GPGPU applications) 
that subsequent stages of the GPU pipeline will have to do increasing amounts of work. For every big 
quad you draw, only four vertices get processed, but many many more fragments result. So the next part 
of wrapping your brain around efficient use of the GPU is deciding exactly how frequently each value 
you use needs to be computed. To put it in more familiar terms, this is more or less identical to loop 
invariant code from nested loops in a CPU program, except that the different levels of loop nesting in 
this case translate into entirely separate programs that run in parallel when possible. An interesting 
aspect of "GPU thinking" is that it's both possible and likely (at least for GPGPU applications) that 
subsequent stages of the GPU pipeline will have to do increasing amounts of work. For every big quad 
you draw, only four vertices get processed, but many many more fragments result. So the next part of 
wrapping your brain around efficient use of the GPU is deciding exactly how frequently each value you 
use needs to be computed. To put it in more familiar terms, this is more or less identical to loop invariant 
code from nested loops in a CPU program, except that the different levels of loop nesting in this case 
translate into entirely separate programs that run in parallel when possible. The first mistake you're 
likely to make along these lines is to compute texture coordinates inside your fragment program when 
you don't really need to. If the texture coordinates (or any other value, for that matter) vary linearly 
across your domain, let the rasterizer do the work for you! This means you'll need to split your big 
nasty fragment program into a fragment program and a vertex program. Not only will you avoid doing redundant 
computation, but you'll make a bit more use of the vertex processor (which was probably sitting idle 
anyway if you use the fragment processor as heavily as most of us GPGPU types do), and you might even 
get a slight boost in your texture read performance (computing texture coordinates inside the fragment 
program causes those texture coordinates to effectively be treated as a texture indirection, possibly 
defeating prefetching.) 122122122  Let s look at this bit of our example shader. Here we have a vertex 
program that was created by stripping all of the texture coordinate computation out of the shader above. 
You end up with parts of your fragment program looking like this: OUT.COL.x = params.w*O.z + (params.z*U.z 
-(O.x *(f1texRECT(Source, IN.hneighbor.xz)+ f1texRECT(Source, IN.hneighbor.yz)) + O.y * f1texRECT(Source, 
IN.vneighbor.xy) + O.y * f1texRECT(Source, IN.vneighbor.xz))) / O.w;  Keep in mind that, once again, 
swizzling is our friend; the rasterizer will interpolate 4-vectors for us as cheaply as 2-vectors, so 
we might as well get the most bang for our buck. Using the swizzle to select which channels of a varying 
parameter contain your texture coordinates is efficient for several reasons; first, as I mentioned before, 
it aids in prefetching and reduces computations done in the fragment shader. Perhaps less obviously, 
though, fetching the channels you want out of a single pre-existing 4-vector by swizzling is free, whereas 
if you built a 2-vector on the fly, it would turn into several MOV instructions. So, for example, f1texRECT(Source, 
IN.hneighbor.xz); would be better than: f1texRECT(Source, float2(IN.foo.x, IN.bar.y)); You can sometimes 
even take what we did in the previous slide a step further and do some of the work on the CPU... use 
your glMultiTexCoord4f()'s and other pervertex data passed from the CPU creatively. Furthermore, don't 
neglect your uniform parameters; values that are invariant both per-fragment AND per-vertex can definitely 
be done on the CPU once rather than multiple times either per-vertex or per-fragment. Again, this is 
just like removing loop-invariant code from nested loops, even though we've now got three levels of code 
we're dealing with --things computed on the CPU, things computed on a per-vertex basis (and then interpolated), 
and things computed per-fragment; it s still the same principle. But let s stop and look more closely 
at this: you might actually get slightly betterperforming code if you think of the CPU program/vertex 
program/fragment program trio as a set of nested loops rather than as function calls. For example, if 
you have a value size that is uniform across your domain, it would make sense from a function call argument-passing 
perspective to pass size as a uniform parameter to your vertex or fragment program. But let s say you 
never actually use size only size*size+100. That expression is also uniform across the domain. If you 
think of 123123123 the different levels of programming as nested loops, passing size*size+100 as the 
uniform value makes sense; it s just a matter of removing loop-invariant code from the inner loops. From 
the function call perspective, however, passing size*size+100 rather than size makes no sense at all, 
as it has little semantic meaning. That s why I say it s better to think in terms of loop invariants 
rather than function call arguments. The other way to use precomputation to your advantage is to build 
lookup tables and bind them as texture maps. Functions with a constant-size domain and range that are 
constant across runs of an algorithm even if they vary in complex ways based on their input can be 
precomputed and store in texture maps. Texture maps can be used for storing functions of one, two, or 
three variables over a finite domain as 1D, 2D, or 3D textures. Textures can store up to four channels, 
so you can encode as many as four separate functions in the same texture. Texture lookups also provide 
filtering (interpolation), which you can use to get piecewiselinear approximations to vlaues in between 
the table entries. In this slide we see an example from our smooth shader. The original shader would 
take the window coordinate of the fragment being processed and would determine whether it was red or 
black (in the checkerboard sense). It turns out to be more efficient to build a texture map as a preprocess 
that replaces all of this computation with a value that specifies whether each cell is red or black. 
Once you ve factored out the computation into a lookup table, the code that executes per-fragment is 
reduced to something much simpler. In my case, what was left is shown here. It's important to note that, 
unlike the other types of precomputation you can do, this one is less guaranteed to provide a speedup. 
If you're memory bandwidth limited, for example, adding another memory fetch might slow things down rather 
than speeding them up. Whether it does or not will probably depend on just how much computation you're 
removing in favor of the table lookup. Benchmarking is the best way to know in this case --try it and 
see.  While I singled out table lookups above as being particularly needy of benchmarking, any optimization 
you apply will need to be benchmarked to be certain you got a speedup as you expected you would. Sometimes 
counterintuitive things enter the picture, and a code transformation that you were *sure* would give 
a speedup actually slows your program down. Once you've gone as far as you can go by just inspecting 
your fragment program for things you can factor out from it, though, how do you get additional speedups? 
At this point, you have to start trying to figure out exactly where in your overall system the bottleneck 
is. As I mentioned earlier, if you can shift work from busy parts of the GPU to idle parts, such as from 
the fragment processor to the vertex processor, that's all to the good. But if you're not sure which 
is the busy part, how do you know how to balance the load? Once you start trying to find (and remove) 
the bottleneck in your use of the GPU itself, however, things start to get a bit hairy. Listed here are 
a couple of tools (and in the case of NVPerfHUD, a talk that NVIDIA presented at Game Developers Conference 
Europe 2003 that talks about NVPerfHUD and other profiling topics) that will help you to track down the 
bottleneck. If neither of these tools does the job for you (for example, NVPerfHUD as of this writing 
only works on D3D applications, not OpenGL), you can do a bit of pseudoprofiling yourself. Basically 
you just start reducing the work on each part of the pipeline systematically; if reducing the work of 
the fragment processor (by temporarily reducing the instruction count in your fragment program) causes 
a speedup, then you re probably compute bound in the fragment processor; if reducing the number of texture 
reads causes a speedup (or increasing it causes a slowdown), you could be texture-bandwidth bound; etc. 
The first step in profiling, even on a GPU application, is always to run a standard software profiler. 
As important as this is for optimizing CPU applications, it s no less important for GPU applications. 
Even if it it s not the case that the CPU end of your application does a lot of work, a software profiler 
will help pinpoint which of your shaders needs the most attention if you have many (and will tell you 
what the relative time spent on each is). Furthermore, it might be the case that your real bottleneck 
isn t on the GPU at all, but rather is due to driver overhead (such as in context switching) or other 
CPU-side effects, even if your app seems relatively simple on the CPU side. A software profiler will 
sniff these kinds of problems out early before you waste a lot of time. Keep running your profiler repeatedly 
as you make improvements; new bottlenecks may emerge at unexpected times. Once you know where your GPU 
pipeline bottleneck is and understand it, there are any number of techniques you can use to try to mitigate 
it. Ultimately the goal is to shift work around (even if such shifts are counter-intuitive) to exploit 
the inherent parallelism of the GPU. These range from manipulations of what kind of graphics API calls 
you use in your CPU program (see the above-referenced talk by John Spitzer from NVIDIA, also from Game 
Developers Conference Europe 2003) to rearranging your entire data layout to try to balance the load. 
Understanding the bottleneck is usually key to knowing how to get it to go away. If you have contacts 
at NVIDIA or ATI, use them they re quite helpful with tracking down application bottlenecks. If you 
don t, why not? :) But there s also something to be said for having more a more fundamental understanding 
of the pipeline as a whole, and sometimes you can get more details on this from third parties who have 
studied the architectures than you can from the vendors themselves. For example, listed here are a couple 
of articles from 3DCenter that give some good insights into 125125125 the NV3x and NV4x pipelines. They 
may be educated guesses rather than solid facts, but having more information at your disposal rather 
than less is probably still a good thing. Once you get used to thinking like a GPU, you ll start to 
realize that most of the things you needed to know to make your GPU apps run fast are things you already 
knew for making your CPU apps run fast it just probably wasn t immediately obvious when you started 
how the concepts mapped from CPU-land to GPU-land. Hopefully through this talk you ve gained some insight 
into that mapping, and you ll eek more and more performance out of your system from the most unexpected 
of places. :) 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198775</article_id>
		<sort_key>127</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[GPU memory model overview]]></title>
		<page_from>127</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198775</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198775</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39056901</person_id>
				<author_profile_id><![CDATA[81100460149]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Aaron]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lefohn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Davis]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
        Frame B u ff er Objects Introductio n to Fra m e Buffer Obj e cts  W h er e is th e 
Pb uff e r Sur v ival Gu id e ?  Gone!!!  Frame Buffer objects (FBO) rece n tly replace d pbuf f ers 
  Frame Buf f ers e n abl e simple, int uitive, f a s t render -to -t e xtur e in OpenGL  http :// 
oss . sgi.com /pr o jects/ og l - sample/registry / EXT/framebuffer_object.t xt   What is an FB O? 
 A struct that holds pointers to m e mory objects  Each b o und memory ob ject can b e a f r ame buffer 
rendering surface   Aaron Lefohn University of California, Davis 31 Aaron Lefohn University of California, 
Davis 32 Frame B u ff er Objects Frame B u ff er Objects  Which m e mory can be bo u n d to an FBO? 
 Textures  Render bu ffers  Depth , ste n ci l , co lor  Traditiona l writ e - only fram e bu 
ff er surfac es  Created with n e w API   FBO Tips and T r icks  Driv er supp o rt stil l ev ol 
v i ng  Try te st i n GP UB en ch to tes t your d r i v er/GP U  Do not bind t e xt ure s of dif 
f er ent siz e o r for m a t to t h e sa me F B O  Atta ch/ una tta c h tex t u r es is ne arly as 
fas t as gl D r a w Buffer if fo r m at/siz e is the sam e  Cha n gi ng FBOs to us e a di ffer e nt 
f o rma t / s i ze i s sl ow er than keepin g sam e format, but still fas t er than wgl M a k eCurr e 
nt/gl X Ma keCurr ent   Aaron Lefohn University of California, Davis 33 Aaron Lefohn University of 
California, Davis 34 Conclusions Acknowled g eme n ts  GP U Memo ry Mo del Evo l ving  Writa b le 
G P U memory f o rm s lo op -back in an o t he rwise feed -forwar d str e aming pipeline  M e m o r 
y mo d e l w i ll c o n t i n u e to e v o l ve as GP Us b e c o me more ge neral str e a m proc ess 
o r s   GP GP U Data Str uctures  Basic me mory primi t ive is limite d -size, 2D texture  Use a 
ddres s tra n sl a t ion to fit a l l a rra y dimensi ons i n to 2D  S ee Glif t talk for G P U data 
structure template library   Nick Triantos, Crai g Kolb, Cass Ev eritt , Chri s S e i t z , NV ID 
I A  Mark Segal , Rob Mace, Ar cot Preetham , Ev an Ha rt, A T I  Brian Bud g e, Ph .D . s t ud ent 
at UCDa vi s an d NVID IA i n t e rn  The other GPGPU S iggraph 2005 course presenters  John Ow ens, 
Ph .D . ad v i sor, Univ. of C a l i fornia Davis  Ross Whitaker , M. S . advisor , SCI I n stitute, 
Univ. of Utah  National Science F National Science Fo undation Graduate Fellowship  Pi xar Animation 
St udios, summer internships   Aaron Lefohn University of California, Davis 35  Aaron Lefohn University 
of California, Davis 132132132 36  
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198776</article_id>
		<sort_key>134</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[GPU computation strategies & tricks]]></title>
		<page_from>134</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198776</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198776</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35035480</person_id>
				<author_profile_id><![CDATA[81100248942]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Buck]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NVIDIA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
  Arithmetic Intensity Arithmetic Intensity 7 Radeon X800 XT GFLO PS 7x Gap GFl o ats /sec Relative 
Performance GeForce 6800 Ultra GPU wi ns when  6 Pentium 4 3.0 GHz 5 Arithmetic i n tensity  Segment 
 4 3. 7 o p s per wo rd 3 12 GF LOPS  SG EMV 2 1/3 ops per word 1 R30 0 R36 0 R42 0 2 G F LOP S 
 ATI H a rdw a re Segment SGEMV 7 8 Arithmetic Intensity Memory Bandwidth  Overlapping computation 
with 7 communicat i on Relative Performance 3 4 5 6 GPU wi ns when  Streaming memo ry bandwi dth SAX 
P Y FFT 2 1 SAXPY FFT 9 10 Memory Bandwidth Computati o nal Inte nsity  Strea m in g Memor y System 
 Cons id er ing GPU tran sfe r cost s: T r  Opt i m i zed for s e quent i al performance CPU GPU 
cache is limit e d  O p ti mi zed for tex t ure filtering GPU Memory Read -only  Sm a l l GeForce 
6800 Ul tra Pe nt iu m 4 Memory Local storage  CPU >> GPU 11 135135135 12      
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198777</article_id>
		<sort_key>140</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[Glift]]></title>
		<subtitle><![CDATA[an abstraction for generic, efficient GPU data structures]]></subtitle>
		<page_from>140</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198777</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198777</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39060637</person_id>
				<author_profile_id><![CDATA[81100460149]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Aaron]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lefohn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Davis]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
     Overview Why a D a ta Structure Abstraction ?  Motivat i on and P r e v iou s W o rk  Abstraction 
  Glift t e mplate library  Cas e stu d y  Ad ap ti v e shad ow map s and octree 3D paint  Conclu 
s i ons   Separate dat a stru ctur es and algorithms  Enable more complex st ru ctur es  E n ab 
le more complex algorithm s  Provide per s pective on cl ass of GPU -compati b le str u ct ur e s 
 Is random read r e quire d ?  What is required for stream read/write?    Aaron Lefohn University 
of California, Davis 19 Aaron Lefohn University of California, Davis 20 Abstraction Abstraction Design 
Go als Abstraction Abstraction Design Approach  GPU data str u ctur e ab straction that  Enables easy 
cre a tion of new structures  Virtua lizes CPU a n d GPU memory interfaces  Separates contai ners 
from algorit h ms  Encourages effic i ency   Minimal eff i cient abstraction of GPU memory model 
  GPU is d i f f er ent t h an CPU (1D/2 D /3 D/Cube/M ip)  Identify c o mmon pa tterns in GPU pa 
pers a n d c o de  Other inspiration  STL, Boost, STAPL , Step ano v  Brook    Aaron Lefohn 
University of California, Davis 21 Aaron Lefohn University of California, Davis 22 Abstraction What 
is the GPU Memory Model? Abstraction What is the GPU Memory Model?  Natively multi -dimensional  CPU 
i n terfa c e  glTe xIm age malloc  glDe let eTe xtu res free   glTe xSu bIm age memcpy GP U - > 
CPU  glGe tTe xSu bIm age * memcpy CP U - > GPU  glCo pyT exS ubI mag e memcpy GP U - > GPU   glBi 
ndT ext ure read - only parameter bind  glFr ame buf fer Tex ture wri t e - only paramet e r bind 
 * Does no t ex ist. Emulate w i t h gl Rea dPi x els  GPU Int e rfa c e ( s hown in C g )  unif orm 
sa mpl erN D parameter dec l ar ation  texN D(t ex , ad dr ) random - acc e ss r e ad  exstream read 
  stre amN D(t ex)* * Does not e x i s t, b u t i s a useful constru c t for effi ci ency reaso ns 
 Aaron Lefohn University of California, Davis 23 Aaron Lefohn University of California, Davis 143143143 
 24    Abstraction Abstraction Example : Rename V a riables float3 physToVirt ( floa t2 pa, float2 
physSize , float3 virtSizes ) { float3 va ; float addr1D = pa.y * physSize.x + pa.x ; Physica l - to 
- Vi r t u a l va.z = floor( addr1D / virtSizes.z ); addr1D - = va .z * sizeConst3D.z; Address Translation 
va.y = floor( addr1D / virtSizes.y ); va.x  = addr1D - va.y * virtSizes.y ; return va ; } float2 virtToPhys 
( floa t3 va , float2 physSize , float3 virtSizes ) { float addr1D = dot( va , virtSizes ); Vi r t u 
a l - to - Physic a l float normAddr1D = a ddr1D / physSize.x ; float2 pa = float2 (fr ac(normAddr1D) 
* physSi ze.x , normAddr1D); Address Translation } float3 main( uniform samplerRECT phy sMem , uniform 
float2 physSize , uniform float3 virtSizes , float2 pa : WPOS ) : COLOR { float3 va = physToVir t ( 
floor(pa ), physSize , virtSizes ); float3 neighborAddr = va - float3(1, 1, 1); return texRECT (data 
, virtToPhys(neighborAddr 3D, physSize , virtSizes ) ); } PhysicalPhysical Memory Read Aaron Lefohn 
University ofCalifornia, Davis 37 Abstraction Example : GPU Shader with Glift  Cg U s age floa t3 
mai n( uni form VM em3 D s rcD ata , Ite rat or3 D iter ) : C OLO R { f loa t3 va = i ter. add r () 
; r etu rn src Dat a.vT ex3 D( va f loat 3(1 ,1, 1) ); } Aaron Lefohn University ofCalifornia, Davis 
 39 Abstraction Other Benefits of Abstraction  Mult iple P h ysMe m wi th s a me AddrTrans   Unlimit 
e d amo unt of data in structures  Mult iple AddrTrans wi th one Phy s Mem   reinterpr e t_cas t 
 physical memory  Continuguou s memory layout   Eff i cient str e am processing of Ph ysMem or AddrTra 
n s Aaron Lefohn University ofCalifornia, Davis 41 Example : Glift Components float3 physToVirt ( 
floa t2 pa, float2 physSize , float3 virtSizes ) { float3 va ; float addr1D = pa.y * physSize.x + pa.x 
; Iter a t or 3D va.z = floor( addr1D / virtSizes.z ); addr1D - = va .z * sizeConst3D.z; va.y = floor( 
addr1D / virtSizes.y ); va.x  = addr1D - va.y * virtSizes.y ; return va ; } float2 virtToPhys ( floa 
t3 va , float2 physSize , float3 virtSizes ) { float addr1D = dot( va , virtSizes ); VM e m 3D float 
normAddr1D = a ddr1D / physSize.x ; float2 pa = float2 (fr ac(normAddr1D) * physSi ze.x , normAddr1D); 
} float3 main( uniform samplerRECT phy sMem , uniform float2 physSize , uniform float3 virtSizes , 
float2 pa : WPOS ) : COLOR { float3 va = physToVir t ( floor(pa ), physSize , virtSizes ); float3 neighborAddr 
= va - float3(1, 1, 1); return texRECT (data , virtToPhys(neighborAddr 3D, physSize , virtSizes ) ); 
 } VM e m 3D Aaron Lefohn University ofCalifornia, Davis 38 Abstraction Example : Glift Data S t ructures 
 C++ U s age vec3i orig in(0 ,0,0 ); vec3i size (10, 10,1 0); ArrayG puND <vec 3i,v ec1f> srcD ata 
( siz e ); ArrayG puND <vec 3i,v ec1f> dstD ata ( siz e );  init iali ze d ataP tr srcDat a.wr ite 
 ( ori gin, s ize, dat aPtr ); gpu_ra nge_ iter ator it = dstD ata. gpu_ range( orig in , size ); it.bin 
d_fo r_re ad ( iterCg Para m ); srcDat a.bi nd_f or_r ead ( s rcCg Para m ); dstDat a.bi nd_f or_w rite 
( COLO R0, myFr ameBuf ferO bjec t ); gpuFor Each ( it ); Aaron Lefohn University ofCalifornia, Davis 
 40 Overview  Motivat i on and p r ev iou s w o rk  Abstraction  Glift t e mplate library impl em 
entation  Cas e stu d y   Ad ap ti v e shad ow map s and octree 3D paint  Conclu s i ons Aaron 
Lefohn University ofCalifornia, Davis 146146146 42    4D Array D e claration Example 4D Array U 
s age Example  Build 4D arra y of vec3f val u es type def Ph ysM emG PU <v ec2 i, vec 3f> PMe m2D ; 
type def Nd To2 DAd drTr ans <ve c4i ,ve c2i> A ddr 4to 2; type def Vi rtM emG PU <A ddr 4to 2, PMe m2D> 
VMe m4D ; vec4 i vi rtS ize ( 1 0, 10, 10, 10 ); vec2 i ph ysS ize ( 1 00, 100 ); PMem 2D p Mem 2D( 
phy sSi ze ); Addr 4to 2 a ddr Tra ns ( vir tSi ze , ph ysSi zse ); VMem 4D a rra y4D ( ad drT ran s 
, pMe m2D );  Interface sim i lar to nativ e textur e vec3 f* dat a = init ial ize da ta vec4 i ori 
gin (0, 0,0, 0); tSiarra y4D .wr ite ( o rigi n, vir tSizse , da ta );  arra y4D .bi nd_ for _rea d( 
ara cgP aram ); arra y4D .bi nd_ for _wri te( GL _CO LOR _ATT ACH MEN T0 ); arra y4D .re ad( or igin 
, irt v irtSiz e , data );  Aaron Lefohn University of California, Davis 55 Aaron Lefohn University 
of California, Davis 56 4D Array Shader Example  Interface sim i lar to nativ e textur e floa t4 mai 
n( uni form VM em4 D a rra y4D, fl oat 4 a ddr ) : CO LOR { r etu rn 2.0 f * arr ay4 D.v Tex 4D( add 
r ); }  Aaron Lefohn University of California, Davis 57 Sparse 3D Array Decl aration Exa m ple  Build 
sp ars e 3D grid of v e c4u b valu e s type def Vi rtP age Tabl e i, vec <v ec3 i, vec3f, vec 4ub , 
ageVMe m3D ; p age_al loc ato r > vec3 i ); vir tSi ze( 512, 51 2, 512 ); vec3 i ); phy sSi ze( 128, 
12 8, 128 ); VMem 3D spa rse 3D( vir tSi ze , ph ysS ize );  Aaron Lefohn University of California, 
Davis 58 Sparse 3D Array Usa g e Example Sparse 3D Array Shader Example  Interface sim i lar to nativ 
e textur e vec4 ub* da ta = ini tia liz e d ata vec3 i ori gin (0, 0,0, 0); spar se3 D.w rit e( orig 
in, vi rtS ize , da ta ); spar se3 D.b ind _fo r_re ad( cg Par am ); spar se3 D.b ind _fo r_wr ite 
( G L_C OLO R_AT TAC HME NT0 ); spar se3 D.r ead ( o rigi n, siz e, dat a );  Interface sim i lar 
to nativ e textur e floa t4 n( mai n( uni form VM em3 D s par se3D , fl oat 3 a ddr ) : CO LOR { etu 
r eturn spa rse 3D.v Tex 3D( ad dr ) / 2.0 f; }  Aaron Lefohn University of California, Davis 59 Aaron 
Lefohn University of California, Davis 149149149 60  More Information  Upco ming ACM Trans a ctio 
ns o n Gr aphics pa p e r  Gli f t : An Abstraction for Ge ner i c, Effici ent GPU Dat a Structure 
s  Predicted, October 2005   Google Lefohn GPU   http:// ~ grap hics.cs . ucd a vi s. ed u/ 
l ef ohn /  Aaron Lefohn University of California, Davis 151151151 67 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198778</article_id>
		<sort_key>152</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Database and stream mining using GPUs]]></title>
		<page_from>152</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198778</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198778</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40026672</person_id>
				<author_profile_id><![CDATA[81100383019]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Naga]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Govindaraju]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[UNC Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
  NVIDIA Ge Force F X 680 0 Ul tr a NVIDIA Ge Force F X 590 0 Ul tr a In tel Pe nti u m 4 Me m o ry 
Bandwi d t h 35. 2 GBp s 27. 2 GBp s 6.4 GB p s DDR2 400 RDRA M Peak S I MD I n stru ct io n s 6 Ve 
rt ex O p s 16 P i x e l O p s Floa t 4 Ve rt ex O p s 4 Pixel O p s Floa t 4 Fl oat Ops (SSE) 2 Do ubl 
e O p s (SSE2) Ve ct o r O p s per Cloc k 16 v e c t o r 4 (f lo at) 4 v e c t or 4 ( f l o a t ) 1 
v e c t or 4 ( f l o a t ) Peak Com par is on Op s pe r Clock 64 16 4 Clock 400 MHz 450 MHz 3.4 G H 
z        2 nd Largest in 9 Val u es  0011 1011 1101 0111 0101 0001 0111 1010 0010 m 0000 v2 
= 1011 32 Draw a Q u a d at Depth 8 1 st bit = 1 Compute c(1 0 00) 0011 1011 1101 0111 0101 0001 0111 
1010 0010 0011 1011 1101 0111 0101 0001 0111 1010 0010 m = 1000 v2 = 1011 m = 1000 v2 = 1011 c(m) = 
3  33 34 Draw a Q u a d at Depth 12 Compute c( 1100) 0011 1011 1101 0111 0101 0001 0111 1010 0010 
 m = 1100 v2 = 1011 35 3 rd bit = 1 Draw a Q u a d at Depth 10 Compute c( 1010) 0011 1011 1101 0111 
0101 0001 0111 1010 0010 0011 1011 1101 0111 0101 0001 0111 1010 0010 m = 1010 v2 = 1011 c(m) = 3 m 
= 1010 v2 = 1011  37 38 Draw a Q u a d at Depth 11 Compute c( 1011) 0011 1011 1101 0111 0101 0001 
0111 1010 0010 m = 1011 v2 = 1011 39     Conclusions Conclusions  Algorithms m a p well to rasterization 
and GPU s  Pr elim inary c o mp arisons w i th op timi ze d C P U i m ple m e n tations is promis ing 
  GPU a s a u s ef ul co -proc essor   Nov e l algorithms to p e rfor m database operations on G P 
Us  Eva l uation of pr edicat es, boo l ea n combinations of predica t es, aggr egations  Algorithms 
ta ke into accou n t GPU limitations  No data rearrang ements  No frame buffer readbac k s    
 55 56 161161161 Future Work  Improve perf ormance of many of our algorithms  Mor e databa s e op 
erat ions su ch a s join, sorting, classification and clust e ring.   oral databasesQuer i e s on sp 
atial an d tem p oral databases 57
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198779</article_id>
		<sort_key>162</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Geometry processing on GPUs]]></title>
		<page_from>162</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198779</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198779</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35035769</person_id>
				<author_profile_id><![CDATA[81100607061]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jens]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kr&#252;ger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Technische Universit&#228;t M&#252;nchen]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Lutz Latta et al., Building a Million Particle System, Game Developers Conference 2004 & Graphics Hardware 2004, http://www.2ld.de/gdc2004/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1058146</ref_obj_id>
				<ref_obj_pid>1058129</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[P. Kipfer, R. Westermann, UberFlow: A GPU-Based Particle Engine, Graphics Hardware 2004, http://wwwcg.in.tum.de/Research/Publications]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Kr&#252;ger, R. Westermann, GPU Simulation and Rendering of Volumetric Effects for Computer Games and Virtual Environments, Eurographics 2005, http://wwwcg.in.tum.de/Research/Publications]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1092800</ref_obj_id>
				<ref_obj_pid>1092712</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Kr&#252;ger, P., Kipfer, P. Kondratieva, R. Westermann, A Particle System for interactive Visualization of 3D Flows, IEEE Transactions on Visualization and Computer Graphics, http://wwwcg.in.tum.de/Research/Publications]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[NVIDIA, Cloth Simulation, 13D 2005 Presentation, http://developer.nvidia.com/object/i3d_2005_presentations.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882363</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kr&#252;ger, J. Westermann, R. Linear algebira operators for GPU implementation of numerical algorithms, In Proceedings of SIGGRAPH 2003, ACM Press / ACM SIGGRAPH, http://wwwcg.in.tum.de/Research/Publications]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882364</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Bolz, J., Farmer, I., Grinspun, E., Schr&#246;der, P. Sparse Matrix Solvers on the GPU: Conjugate Gradients and Multigrid, In Proceedings of SIGGRAPH 2003, ACM Press / ACM SIGGRAPH, http://www.multires.caltech.edu/pubs/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882365</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hillesland, K. E. Nonlinear Optimization Framework for image-Based Modeling on Programmable Graphics Hardware, In Proceedings of SIGGRAPH 2003, ACM Press / ACM SIGGRAPH, http://www.cs.unc.edu/~khillesl/nlopt/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383260</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Fedkiw, R., Stam, J. and Jensen, H. W. Visual Simulation of Smoke. In Proceedings of SIGGRAPH 2001, ACM Press / ACM SIGGRAPH. 2001, http://graphics.ucsd.edu/~henrik/papers/smoke/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311548</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Stam, J. Stable Fluids. In Proceedings of SIGGRAPH 1999, ACM Press / ACM SIGGRAPH, 121--128. 1999, http://www.dgp.toronto.edu/people/stam/reality/Research/pub.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569061</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Harris, M., Coombe, G., Scheuermann, T., and Lastra, A. Physically-Based Visual Simulation on Graphics Hardware. Proc. 2002 SIGGRAPH / Eurographics Workshop on Graphics Hardware 2002, http://www.markmark.net/cml/]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 AP I Bubble s PBO, VBO Copy  Shader Model 3.0 with Vertex Texture Fetch (VTF)  Pixel-Buffer-Objects 
(PBO) to Vertex-Buffer-Objects (VBO) copy  You need: floating point pbuffers a VBO (glGenBuffersARB) 
 Application Loop: Write geometry data into a pbuffer  Copy data from pbuffer to VBO (glReadPixels) 
 Set vertex array pointers to the VBO(glBindBufferARB, glVertexAttribPointerARB)and Render geometry 
as usual(glDrawArrays, glDrawElements)  Comparison  it s all the same somehow  Vertex Shader  PBO, 
VBO Copy  availability  requires memcopy , OpenGL only   FBO cast to Vertex-Array  no memcopy  
availability, OpenGL only   SM3 with VTF   Vertex Shader multi vendor, OpenGL/DirectX, flexible 
 more code, requires latest GPU   Texture Vertices  In principle, all 3 methods take one or more 
textures as input and displace a vertex stream accordingly, this makes them interchangeable.  Example 
1, Particle Tracing Vectorfield Texture Last Position Texture PingPong Switch Static Quad RenderToTexture 
 In e poa ion ntegration n Fragment Shader Vertex Shader  m Observed Speedups for 3D Vector fields 
Interpolation (x100) SIMD Integration (x20) SM 3.0 Particle Rendering (x20) ATI X800 XT vs. Pentium 4 
3Ghz   100+ fps Smoke with GPU Particles I 100+ fps Smoke with GPU Particles II  Texture  In erpo 
a ion ntegration Pass through  RenderToTexture n Fragment Shader Vertex Shader  Step 1: do a couple 
of independent 2D fluid simulations  run at a few hundred FPS on current GPUs  m Step 2: Bind the output 
of the simulation as vector field textures for the particle advection 163163163   Example 2, Water 
S u rf ace  Simulation generates height field texture static grid water surface   Selected R e ferences 
 Lutz Latta et al., Building a Million Particle System, Game Developers Conference 2004 &#38; Graphics 
Hardware 2004, http://www.2ld.de/gdc2004/  P. Kipfer, R. Westermann, UberFlow: A GPU-Based Particle 
Engine, Graphics Hardware 2004,  http://wwwcg.in.tum.de/Research/Publications J. Krger, R. Westermann, 
GPU Simulation and Rendering of Volumetric Effects for Computer Games and Virtual Environments , Eurographics 
2005, http://wwwcg.in.tum.de/Research/Publications  J. Krger, P. Kipfer, P. Kondratieva, R. Westermann, 
A Particle System for Interactive Visualization of 3D Flows, IEEE Transactions on Visualization and Computer 
Graphics, http://wwwcg.in.tum.de/Research/Publications NVIDIA, Cloth Simulation, I3D 2005 Presentation, 
http://developer.nvidia.com/object/i3d_2005_presentations.html Krger, J. Westermann, R. Linear algebra 
operators for GPU implementation of numerical algorithms, In Proceedings of SIGGRAPH 2003, ACM Press 
/ ACM SIGGRAPH, http://wwwcg.in.tum.de/Research/Publications  Bolz , J., Farmer, I., Grinspun, E., Schrder, 
P. Sparse Matrix Solvers on the GPU: Conjugate Gradients and Multigrid, In Proceedings of SIGGRAPH 2003, 
ACM Press / ACM SIGGRAPH, http://www.multires.caltech.edu/pubs/  Hillesland, K. E. Nonlinear Optimization 
Framework for Image-Based Modeling on Programmable Graphics Hardware, In Proceedings of SIGGRAPH 2003, 
ACM Press / ACM SIGGRAPH, http://www.cs.unc.edu/~khillesl/nlopt/  Fedkiw, R., Stam, J. and Jensen, H.W. 
Visual Simulation of Smoke. In Proceedings of SIGGRAPH 2001, ACM Press / ACM SIGGRAPH. 2001, http://graphics.ucsd.edu/~henrik/papers/smoke/ 
 Stam, J. Stable Fluids. In Proceedings of SIGGRAPH 1999, ACM Press / ACM SIGGRAPH, 121-128. 1999, 
http://www.dgp.toronto.edu/people/stam/reality/Research/pub.html  Harris, M., Coombe, G., Scheuermann, 
T., and Lastra, A. Physically-Based Visual Simulation on Graphics Hardware.. Proc. 2002 SIGGRAPH / Eurographics 
Workshop on Graphics Hardware 2002, http://www.markmark.net/cml/   
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198780</article_id>
		<sort_key>165</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[A dynamic adaptive multi-resolution GPU data structure]]></title>
		<subtitle><![CDATA[adaptive shadow maps, octree 3D paint, adaptive PDE solver]]></subtitle>
		<page_from>165</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198780</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198780</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39060631</person_id>
				<author_profile_id><![CDATA[81100460149]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Aaron]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lefohn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Davis]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
    Application ASM Data S t ructure R e quiremen ts  Adaptive  M u ltireso l utio n  Fast, parallel 
r a ndom - access r e ad  2x 2 native Pe rc e n ta ge C l o s er Filte r ing (PC F )  T r iline a r 
int e rp o l ate d mipmapped PC F  Fast, parallel w r ite  Fast, parallel in sert and erase Aaron 
Lefohn University of California, Davis 13 Application ASM Data S t ructure  Adaptive Pag e Tabl e 
 Map mul t iple vir t ual pag e s to singl e physica l pag e  Aaron Lefohn University of California, 
Davis 14 Application ASM Data S t ructure R e quiremen ts  Adaptive  M u ltireso l utio n  Fast, 
parallel r a ndom - access r e ad  2x 2 native Pe rc e n ta ge C l o s er Filte r ing (PC F )  T 
r iline a r int e rp o l ate d mipmapped PC F   Fast, parallel w r ite  Fast, parallel in sert and 
erase   Aaron Lefohn University of California, Davis 15 Application ASM Data S t ructure R e quiremen 
ts Application ASM Data S t ructure R e quiremen ts  Adaptive  M u ltireso l utio n  Fast, parallel 
r a ndom - access r e ad  2x 2 native Pe rc e n ta ge C l o s er Filte r ing (PC F )  T r iline a 
r int e rp o l ate d mipmapped PC F   Fast, parallel w r ite  Fast, parallel in sert and erase 
  How support bi linear filtering?  Du plicate 1 co lu m n an d 1 ro w of tex e ls in e a ch page 
  Mipmapped trilinear ?   By -ha nd inte rpo l a t io n be twee n mipm a p le ve ls  Aaron Lefohn 
University of California, Davis 17 Aaron Lefohn University of California, Davis 167167167 18    
  
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198781</article_id>
		<sort_key>171</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Sparse matrix solvers on the GPU]]></title>
		<subtitle><![CDATA[conjugate gradients and multigrid]]></subtitle>
		<page_from>171</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198781</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198781</url>
		<abstract>
			<par><![CDATA[Many computer graphics applications require high-intensity numerical simulation. We show that such computations can be performed efficiently on the GPU, which we regard as a full function <i>streaming</i> processor with high floating-point performance. We implemented two basic, broadly useful, computational kernels: a <i>sparse matrix conjugate gradient solver</i> and a regular-grid <i>multigrid solver</i>. Real-time applications ranging from mesh smoothing and parameterization to fluid solvers and solid mechanics can greatly benefit from these, evidence our example applications of geometric flow and fluid simulation running on NVIDIA's GeForce FX.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[GPU computing]]></kw>
			<kw><![CDATA[conjugate gradient]]></kw>
			<kw><![CDATA[fluid simulation]]></kw>
			<kw><![CDATA[mesh smoothing]]></kw>
			<kw><![CDATA[multigrid]]></kw>
			<kw><![CDATA[navier-stokes]]></kw>
			<kw><![CDATA[numerical simulation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Graphics processors</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.3</cat_node>
				<descriptor>Sparse, structured, and very large systems (direct and iterative methods)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.1.8</cat_node>
				<descriptor>Multigrid and multilevel methods</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003714.10003727.10003729</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Differential equations->Partial differential equations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010148.10010149.10010158</concept_id>
				<concept_desc>CCS->Computing methodologies->Symbolic and algebraic manipulation->Symbolic and algebraic algorithms->Linear algebra algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003719</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computations on matrices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010389</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics processors</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP31057445</person_id>
				<author_profile_id><![CDATA[81332490612]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jeff]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bolz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P587713</person_id>
				<author_profile_id><![CDATA[81322493531]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Farmer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40031469</person_id>
				<author_profile_id><![CDATA[81320489894]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Eitan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Grinspun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40023875</person_id>
				<author_profile_id><![CDATA[81100117380]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schr&#246;der]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Caltech]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>52802</ref_obj_id>
				<ref_obj_pid>52797</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Arvind, and Iannucci, R. A. 1987. Two Fundamental Issues in Multiprocessing. In Proceedings of DFVLR - Conference 1987, Parallel Processing in Science and Engineering.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barrett, R., Berry, M., Chan, T. F., Demmel, J., Donato, J., Dongarra, J., Eijkhout, V., Pozo, R., Romine, C., and der Vorst, H. V. 1994. Templates for the Solution of Linear Systems: Building Blocks for Iterative Methods, 2nd ed. SIAM.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91254</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Blelloch, G. E. 1990. Vector Models for Data-Parallel Computing. MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357695</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Briggs, W. L., Henson, V. E., and McCormack, S. F. 2000. A Multigrid Tutorial, 2nd ed. SIAM.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569052</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Carr, N. A., Hall, J. D., and Hart, J. C. 2002. The Ray Engine. In SIGGRAPH/Eurographics Workshop on Graphics Hardware.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cohen, M. F., Chen, S. E., Wallace, J. R., and Greenberg, D. P. 1988. A Progressive Refinement Approach to Fast Radiosity Image Generation. Computer Graphics (Proceedings of SIGGRAPH) 22, 75--84.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>264989</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Demmel, J. W. 1997. Applied Numerical Linear Algebra. SIAM, Philadelphia, PA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311576</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Desbrun, M., Meyer, M., Schr&#246;der, P., and Barr, A. H. 1999. Implicit Fairing of Irregular Meshes Using Diffusion and Curvature Flow. In Proceedings of SIGGRAPH, 317--324.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Desbrun, M., Meyer, M., and Alliez, P. 2002. Intrinsic Parameterizations of Surface Meshes. Computer Graphics Forum (Proceedings of Eurographics) 21, 3, 209--218.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>639177</ref_obj_id>
				<ref_obj_pid>639176</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Diewald, U., Morigi, S., and Rumpf, M. 2002. A Cascadic Geometric Filtering Approach to Subdivision. Comput. Aided Geom. Des. 19, 9, 675--694.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383260</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Fedkiw, R., Stam, J., and Jensen, H. W. 2001. Visual Simulation of Smoke. In Proceedings of SIGGRAPH, 15--22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Goodnight, N., Lewin, G., Luebke, D., and Skadron, K. 2003. A Multigrid Solver for Boundary Value Problems Using Programmable Graphics Hardware. Tech. Rep. CS-2003-03, University of Virginia.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hackbusch, W. 1985. Multi-Grid Methods and Applications. Springer Verlag, Berlin.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Hall, J. D., Carr, N. A., and Hart, J. C. 2003. Cache and Band-width Aware Matrix Multiplication on the GPU. Tech. rep., University of Illinois.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569061</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Harris, M. J., Coombe, G., Scheuermann, T., and Lastra, A. 2002. Physically-Based Visual Simulation on Graphics Hardware. In SIGGRAPH/Eurographics Workshop on Graphics Hardware.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Harris, M. J. 2002. Analysis of Error in a CML Diffusion Operation. Tech. Rep. TR02-015, UNC Chapel Hill.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882365</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Hillesland, K. E., Molinov, S., and Grzeszczuk, R. 2003. Nonlinear Optimization Framework for Image-Based Modeling on Programmable Graphics Hardware. ACM Transactions on Graphics.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311567</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Hoff, K. E., Keyser, J., Lin, M., Manocha, D., and Culver, T. 1999. Fast Computation of Generalized Voronoi Diagrams Using Graphics Hardware. In Proceedings of SIGGRAPH, 277--286.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97884</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Kass, M., and Miller, G. 1990. Rapid, Stable Fluid Dynamics for Computer Graphics. Computer Graphics (Proceedings of SIGGRAPH) 24, 4, 49--57.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258769</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Keller, A. 1997. Instant Radiosity. In Proceedings of SIGGRAPH, 49--56.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>624434</ref_obj_id>
				<ref_obj_pid>623298</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Khailany, B., Dally, W. J., Rixner, S., Kapasi, U. J., Mattson, P., Namkoong, J., Owens, J. D., Towles, B., and Chang, A. 2001. Imagine: Media Processing with Streams. IEEE Micro 21, 2, 35--46.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>822826</ref_obj_id>
				<ref_obj_pid>822080</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Khailany, B., Dally, W. J., Rixner, S., Kapasi, U. J., Owens, J. D., and Towles, B. 2003. Exploring the VLSI Scalability of Stream Processors. In Proceedings of the Ninth Symposium on High Performance Computer Architecture.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280831</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Kobbelt, L., Campagna, S., Vorsatz, J., and Seidel, H.-P. 1998. Interactive Multi-Resolution Modeling on Arbitrary Meshes. In Proceedings of SIGGRAPH, 105--114.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882363</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Kr&#252;ger, J., and Westermann, R. 2003. Linear algebra operators for gpu implementation of numerical algorithms. ACM Transactions on Graphics.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>582089</ref_obj_id>
				<ref_obj_pid>582034</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Larsen, E. S., and McAllister, D. K. 2001. Fast Matrix Multiplies using Graphics Hardware. In Supercomputing.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Leiserson, C., Rose, F., and Saxe, J. 1993. Optimizing synchronous circuitry by retiming. In Third Caltech Conference On VLSI.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97915</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Lengyel, J., Reichert, M., Donald, B. R., and Greenberg, D. P. 1990. Real-Time Robot Motion Planning Using Rasterizing Computer Graphics Hardware. Computer Graphics (Proceedings of SIGGRAPH) 24, 327--335.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Li, W., Wei, X., and Kaufman, A. 2003. Implementing Lattice Boltzmann Comptuation on Graphics Hardware. The Visual Computer. To appear.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383274</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Lindholm, E., Kilgard, M. J., and Moreton, H. 2001. A User-Programmable Vertex Engine. In Proceedings of SIGGRAPH, 149--158.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>545269</ref_obj_id>
				<ref_obj_pid>545261</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[M&#252;ller, M., Dorsey, J., McMillan, L., Jagnow, R., and Cutler, B. 2002. Stable Real-Time Deformations. In ACM SIGGRAPH Symposium on Computer Animation, 49--54.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1103901</ref_obj_id>
				<ref_obj_pid>1103900</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Olano, M., Ed. 2002. Real-Time Shading Languages. Course Notes. ACM SIGGRAPH.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569053</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Owens, J. D., Khailany, B., Towles, B., and Dally, W. J. 2002. Comparing Reyes and OpenGL on a Stream Architecture. In SIGGRAPH/Eurographics Workshop on Graphics Hardware, 47--56.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566640</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Purcell, T. J., Buck, I., Mark, W. R., and Hanrahan, P. 2002. Ray Tracing on Programmable Graphics Hardware. ACM Transactions on Graphics 21, 3, 703--712.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Semiconductor Industry Association, 2002. International Technology Roadmap for Semiconductors. http://public.itrs.net/, December.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Shewchuck, J. R. 1994. An Introduction to the Conjugate Gradient Method without the Agonizing Pain. http://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.ps., August.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311548</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Stam, J. 1999. Stable Fluids. In Proceedings of SIGGRAPH, 121--128.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2384121</ref_obj_id>
				<ref_obj_pid>2384110</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Strzodka, R., and Rumpf, M. 2001. Nonlinear Diffusion in Graphics Hardware. In Visualization, 75--84.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Strzodka, R. 2002. Virtual 16 Bit Precise Operations on RGBA8 Textures. In Vision, Modeling and Visualization.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[The C* Team. 1993. C* Manual, 2nd ed. Thinking Machines Corporation.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>774894</ref_obj_id>
				<ref_obj_pid>774861</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Thompson, C. J., Hahn, S., and Oskin, M. 2002. Using Modern Graphics Architectures for General-Purpose Computing: A Framework and Analysis. In International Symposium on Microarchitecture.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Sparse Matrix Solvers on the GPU: Conjugate Gradients and Multigrid JeffBolz IanFarmer Eitan Grinspun 
Peter Schroder Caltech Abstract Manycomputer graphics applications requirehigh-intensity numerical 
simulation.We show that such computations canbe performed ef.ciently on the GPU, which we regard asafull 
function streaming processor with high .oating-point performance. We implemented two basic, broadly useful, 
computationalkernels: a sparse matrix conjugate gradient solver andaregular-grid multigrid solver. Realtime 
applications ranging from mesh smoothing and parameterization to .uid solvers and solid mechanics cangreatly 
bene.t from these, evidence our example applications of geometric .ow and .uid simulation running on 
NVIDIA sGeForce FX. CR Categories: I.3.1 [ComputerGraphics]: Hardware Architecture Graphics processors; 
G.1.3 [Numerical Analysis]: Numerical Linear Algebra Sparse, structured, and very large systems (direct 
and iterative methods); G.1.8 [Numerical Analysis]: Partial Differential Equations Multigrid and Multilevel 
Methods; Keywords: GPU Computing, Numerical Simulation, Conjugate Gradient, Multigrid, Mesh Smoothing, 
Fluid Simulation, Navier-Stokes 1 Introduction High performance graphics processing units (GPUs) such 
as the Radeon 9700 and GeForce FX (among others) expose a .exible programming interface for their powerful 
.oatingpoint hardware. Due to their highly parallel nature, they are expected to outperform CPUs by an 
increasing margin[Semiconductor Industry Associ ation 2002; Khailany et al. 2003], consequently they 
are serious contenders as high performance computational engines for .oating point intensive applications. 
Aside from their currently utility, GPUs represent the .rst commercially successful examples of a class 
of future computing architectureskeyto high performance, cost effective super-computing[Khailanyet al. 
2001;Owens et al. 2002]. Understanding the issues in mapping a variety of funda mental algorithms to 
this new computing paradigm thus promises to have manylongterm pay-offs. Sofar the computational resources 
of GPUs have been applied mostly to traditional graphics problems, enhancing, for example, the shading 
models and effects applied at the pixel level[Olano 2002]. Current generation GPUs are capableoffar more 
general computation, evidence the GPU-based ray tracing engines demonstrated by Purcell et al. [2002]and 
Carret al. [2002]. Employing graphics hardware for purposes it was not designed forhasalong tradition[Lengyeletal.1990;Hoffetal.1999],in 
cluding early uses for numerical computing in the context of radiosity[Cohenetal.1988;Keller1997].Manyofthese 
algorithms were based on rendering suitably chosen geometry with appropriReprinted from "Sparse Matrix 
Solvers on the GPU: Conjugate Gradients and Multigrid" in ACM Transactions on Graphics {Volume 22 , Issue 
3 (July 2003)} &#38;#169; ACM, 2003.http://portal.acm.org/citation.cfm?doid=882262.882364 ate colors 
(e.g., object ID tags), followed by readback from the framebuffer.Withthe arrivalof programmablevertexand 
fragment units[Lindholmetal.2001]theavailable repertoire increasedsig ni.cantly. Sincevertex programssofardonotprovideaccess 
to memory ( textures ) most recent efforts to map numerical algorithms onto GPUs have focused on using 
integer based fragment processing hardware. Examples includesimulation of boiling[Har risetal.2002], 
.uidsand steam[Lietal.2003], non-lineardiffu sion[Strzodka and Rumpf 2001], and general purpose dense 
ma trix multiplication[Larsen and McAllister 2001; Thompson et al. 2002]. Manyof the severe technical 
limitations these authors had to deal with, such as low precision[Strzodka 2002; Harris 2002] and the 
need to express all operations as (fancy) texture compositing operations,havefallenaway: today s fragment 
shaders support full .oating-point arithmetic and broad access to memory. Contributions We map two fundamental 
computationalkernels onto the GPU: a conjugate gradient solver[Shewchuck 1994]for sparse, unstructured 
matrices and a multigrid solver for regular grids[Briggsetal.2000]. Both areworkhorsesofphysicalmod 
eling and optimization applications.We analyze their performance on NVIDIA s GeForce FX in realistic 
applications. Background The need for an unstructured sparse matrix solver arises in many simulations 
involving discretization of linear and non-linear partial differential equations (PDEs) over arbitrary 
meshes(e.g.,[Muller et al. 2002; Desbrun et al. 2002;Kobbelt et al. 1998]). In these settings a conjugate 
gradient solver (or oneofitsvariants[Barrettetal. 1994])is often appropriate. Implementing such solvers 
on the GPU requires the construction of (1) data structures for sparse matrices, (2) data parallel algorithms 
for sparse matrix vector multiplies, and (3) reduction operators for inner product computations. With 
data laid out in texture memory, and fragment program execution having, for a given group of fragments, 
identical control .ow, an ef.cient implementation furthermore requires the solution of a texture packing 
optimization problem (Section 3.2). Whenever the underlying PDE is non-linear it is desirable to compute 
the matrix entries on the GPU as well. Our algorithm accommodates this, making it well suited for both 
linear and non-linear PDEs on unstructured meshes. Unstructured meshes require a non-trivial mapping 
of sparse data structures onto single-instruction multiple-data (SIMD)hardware[Blelloch 1990]. In contrast 
regular grids, used in graphics applications such as[Kass and Miller 1990; Stam 1999], lead to highly 
structured sparse matrices which map more directly onto the GPU since they are akin to pixel (2D) or 
voxel (3D) structures. For these settings we considermultigrid solvers[Hackbusch 1985], which lead to 
optimal, O(n), runtime for many elliptic PDEs of interest(e.g., Laplace, Bi-Laplace, Helmholtz, Poisson, 
etc.). In graphics such solvers are used, for example, for the construction of subdivision surfaces[Diewald 
et al. 2002]. The main challenge in performing this computation entirely on the GPU is the construction 
of the coarser-level system matrices given only a knowledge of the .nest-level discretization and the 
prolongation (subdivision) operators.Weevaluatethe performanceof our multigrid implementation ona .uid-.ow 
problem[Stam 1999], which requires (among other steps) a Poisson solver with Neumann boundary conditions. 
While this paper was under review we learned of concurrent worktomakeamultigrid solver ontotheGPU[Goodnightetal. 
2003]. The mappingof other important computationalkernels onto theGPUis describedin these proceedings[KrugerandWestermann 
2003;Hillesland et al. 2003]. 171171171 2 Setup Weviewthe fragment shaderofa modernGPUasastream processor 
[Khailanyetal.2001].The processorexecutesthe samekernel (fragment program)to produce each element(rasterized 
pixel)of an output stream(group of rasterized primitives). The output stream is saved(texture memory)and 
used as input (viatexture fetches)for downstreamkernels. Our design maps the data structures and algorithms 
of our solvers into streams(textures)andkernels(shaders) respectively as proposedby[Purcell et al. 2002]. 
The design was strongly motivated by three salient features of GeForce FX hardware: (1) inexpensivegather 
operations, (2) lack of a scatter operation, and (3) SIMD semantics. Together, these three features characterize 
the abstract streaming model: Gather Operation: The processor provides random access memory fetch ( 
gather ) instructions into saved streams. The latencyof the random memory access is hidden so long as 
the bandwidth is not limited.  No Scatter Operation: Each run through thekernel produces exactly one 
output element. There are no random access memory write operations.  SIMD Semantics: The GPU has two 
SIMD characteristics:  (1) the same kernel is executed over all elements of a stream, and (2) processor 
instructions operate on wide data types, i.e., 4-tuples of .oating point values. Unconstrainedgathers 
bring freedom in choosing data structures. Lack of scatter forces the stream kernels to be organized 
into groups. Each fragment processor can read other memory,but only write its own output: this .ts well 
with manylinear algebra operations(suchasthe inner productoftwovectors)butnotall, e.g., applying the 
adjoint of an operator is most commonly formulated as a scatter operation. SIMD item (1) leads to a packing 
problem for unstructured matrices in order to minimize a batch quantization penalty (Section 3.2.1). 
SIMD item (2) motivated us to layer the four quadrants of a scalar problem into a single four channel 
texture for the multigrid solver.  3 Solver for Unstructured Grids Many algorithms for physical simulation 
or optimization on unstructured meshes use (multi-)linear .nite elements or mass-spring systems. The 
degrees of freedom (DOFs), such as position, velocity, temperature, etc., are associatedtoverticesofa2D 
(triangle, quadrilateral) or 3D (tetrahedral, hexahedral) mesh. The sparse linear systems that arise 
relate a given DOF to the DOFs on incident vertices.Oursolverisdesignedforthesesparselinear systems.For 
concreteness we assumea trianglemesh with linear .nite elements. Let the integers i =1,...,n denote the 
vertices V ofa 2manifold triangle mesh (with boundary), with edges E = {eij }. Denote the set of vertices 
in the 1-ring neighborhood of vertex i as N(i)= {j|eij . E} and a (generic) DOF associated with vertex 
i as xi. Example DOFs include 3D position xi := (x, y, z)i or texture coordinates xi := (s, t)i. Our 
goal is to solve the n  n system, Ax = f, .i =1,...,n : aiixi + aij xj = fi (1) j.N(i) where the fi 
encode the right hand side and possibly boundary conditions, depending on the original problem setup. 
The coef.cients aij typically depend on the state of the two triangles incident on edge eij . We exploit 
this later for the construction of matrix entries on the GPU. If the linear system is symmetric positive 
de.nite we may use conjugate gradients to solve it. More general systems requirevariantsof conjugate 
gradients[Barrettetal. 1994],which typically need explicit access to AT , but no additional functions 
otherwise.Weassumethattherowsofsystem(1)aresortedaccord ing to the number of non-zero off-diagonal coef.cients 
aij . These can range from 0 to n - 1,but are six onaverage fora single closed triangle mesh. Let ik, 
0 = k<n denote the number of equations with k non-zero entries. These then occupy ik contiguous rows 
.k-1 starting with row index ( l=1 il)+1. Example System: Geometric Flow Manycomputer graphics settings 
give rise to linear systems with the structure of Eq.(1). We use geometric (mean curvature) .ow as an 
examplenon-linear problem[Desbrun et al. 1999].Vertex positions xi(t) are functions of time according 
to .txi(t)= -.i(t)Hi(t).ni(t). Hi(t).ni(t) denotes the mean curvature normal at vertex i and time t while 
.i(t) is the speed function. For simplicity we assume that .i does not depend on time. This equation 
is typically linearized through a semi-implicit discretization using a backward difference in time (k+1) 
-t .t = t(k) for the left hand side and the state of the mesh at the beginning of a time step for the 
approximation of Hi(t).ni(t). Note that this requires recomputation of A(k) at every time step. (k)(k)(k)(k) 
We havea= -..t(cot(a) + cot()), where aand ij ijij ij (k) (k) ij are the angles opposite edge eij at 
time t. The diagonal (k)(k)(k)(k) entry ais given as 4A- awith Athe area of ii ij.N(i) ij i the triangles 
at time t(k) incident to vertex i. 3.1 Conjugate Gradient Solver Implementation of a conjugate gradient 
solver requires only a few non-trivial functions [Shewchuck 1994, p. 50]: sparse matrixvector multiply 
and vector inner-product. The sparse matrix-vector multiply requires a suitable sparse matrix data structure 
and an associated fragment programtoexecutethe multiply.The innerproduct computation requires a sum-reduction. 
 3.1.1 Sparse Matrix Vector Multiply Principle To understand the particular layout for the unknown variables 
consider the implementation of the sparse matrix vector multiply. The basic computationalkerneltobeexecutedbya 
fragment program is the inner product between a given row and the vector of unknowns. Fragment programs 
must execute in SIMD style lockstep (there is no branching or early termination, as yet). Thus we render 
groups of rows with an equal number of nonzero entries, i.e., each group is a rectangle associated to 
a fragment program specialized for a particular number of non-zero entries. The fragment program needs 
to access the non-zero entries in a given row and the associated elements of the vector of unknowns. 
Each of these the matrix A and vector x are stored in textures requiring appropriate indirections. Since 
x is read and written it must be laid out with particular care. The texture X x holds x, one element 
per pixel; here the superscript denotes the layout of the texture, implyingthat textures with the same 
superscript(e.g., X x , Yx , Rx)haveanatural correspondence betweentheir elements at the same location. 
The layout of X x is discussed in Section 3.2. Details The sparse matrix A is stored in two textures. 
The diagonal entries Axi are laid out the same as X x , i.e., aii is at the same coordinate as xi. The 
off-diagonal, non-zero entries of A are stored consecutively in a texture Aaj as segments, with one segment 
per matrix row(a layoutfamiliar from SIMD programming[Blelloch 1990];seealsoFigure1).Eachsegment sstarting(texture-)address 
is stored in an indirection texture Rx. Finally, wehaveatexture Ca keeping the correspondence between 
the addresses of aij in Aaj , matching xj in X x . The layouts of Aaj and Ca are identical; Aaj has values 
aij , and Ca has the corresponding pointers into xj in X x. Letting i nowbe the coordinatesofagiven elementin 
X x, the 172172172 Figure 1: Off-diagonal elements of each row are compacted into segments which are 
tightly packed into Aaj .Apointer to the beginning of each segment is stored in Rx . inner productkernel 
betweena sparsematrix row and thevectorof unknowns becomes Rx j =[i] ki-1 Yx[i]= Axi [i] *X x[i]+ Aaj 
[j + c] *X x[Ca[j + c]], c=0 here Yx denotes a destination texture with the same layout as X x . By rendering 
appropriate rectangles into Yx each bound to a fragment program with the appropriate upper bound on the 
above sum we can perform the desired sparse matrixvector product y = Ax (Figure2). Notes The indirection 
textures Rx and Ca depend onlyon the mesh connectivity and can be initialized at the time a mesh is .rst 
constructed. The separate storage for Ax and Aja is advantageous for i diagonal preconditioning divisionofthe 
residualvectorbythediagonal entries as well as the generally different methodsbywhich diagonal and off-diagonal 
entries are computed in the .rst place. With the setup we have given for sparse matrix vector product, 
transpose products require an explicit representation of AT . In the case that A and AT have differing 
numbers of non-zero entries per row, the lesser should be padded with zeros so that they have the same 
size. The number of texture indirections that can be performedinafragment program limitsthe numberof 
non-zero entries per row that can be processed without additional passes. For the GeForce FX rows with 
up to 200 non-zero entries can be processed in a single pass.  3.1.2 Computing Matrix Entries Principle 
In the case that the entries of A depend on x we require two additionalkernels. One to update Ax and 
another for Aaj . In i traditional FEM codes this is typically done by an iteration over all elements 
computing local stiffness matrices, i.e., the linear operator relating all DOFs incident on the element. 
These local stiffness matrices are then accumulated into a global stiffness matrix. Unfortunately this 
requires a scatter operation which is not available on current generation GPUs. Instead we must compute 
the nonzero entries directly. We have two types of non-zero entries, those associated withvertices Axi 
and edges Aja.Webegin with the latter. Details The coef.cient associated with a given edge is controlled 
by the two incident triangles, which in turn are completely described by their incident vertices a total 
of four. Consider for example the coef.cients which arise in the geometric .ow problem. Aside from Ca 
this requires three additional textures: Ia , N a (next), and Pa (previous), layout out like Ca. Together, 
these four Figure 2: When the fragment program executes on the pixel corresponding to row i, the window 
position is used as a texture coordinate to fetch xi in X x and aii in Axi . The window position also 
identi.es the segment pointer in Rx, whichpoints to the location of non-zero elements aij in Aja corresponding 
to row i. Finally, using the segment pointer from Rx we can access entries in Ca which reveal the addresses 
of xj in X x corresponding to non-zero aij . textures identify the vertices incident on the two triangles 
associated with edge eij . Computation of Aaj can now be performed by the fragment program (a - b)  
(c - b) cot(a, b, c)= .(a - b)  (c - b). xi = X x[Ia[j]] xj = X x[Ca[j]] xjp = X x[Pa[j]] xjn = X x[N 
a[j]] Aaj [j]= -..t(cot(xj ,xjp ,xi) + cot(xi,xjn ,xj )). The Axi are computed with the same overall 
structure as a sparse matrixvector multiply and the followingfragment program ki-1 Axi [i]= 4A(xi,xjp 
,xj ) -Aja[Rx[i]+ c]. c=0 Boundaries In geometric .ow one can either .x vertices on the meshboundaries(aswedointheexamples),orletthem.ow 
under a length minimizing curvature .ow. The latter requires its own tridiagonal linear system, which 
can be implemented on the GPU as well. Fixed boundaries effectively remove some vertices from the list 
of degrees of freedom, though they still enter into the matrix coef.cient computations. So while they 
are stored in X x, they are not assigned to a rectangle with a fragment program: there are no corresponding 
rows in the matrix.  3.1.3 Reduction Operators Reduction operators apply a binary associative1 operator 
to all elements of a vector returning the result r = v1 . v2 . . vn. The operator is not required 
to be commutative, e.g., the vector could contain matrices and . may be matrix multiplication. We require 
only sum-reduction and will take advantageofthefact that addition is commutative, i.e., we will not require 
anyparticular order. This allows us to perform reduction for vectors, such as X x, indexed by two indices 
without regard to the order2. To compute the inner 1Real addition associates, .oating point addition 
does not. We will ignore this distinction. 2The traditional way of dealing with higher-D is to perform 
reductions in each dimensionin order[Blelloch 1990;TheC*Team 1993]. 173173173 product oftwo vectors 
p = x  y, we need a sum-reduction on the pairwise products. Let X x be a vector holding elements to 
be sum-reduced. The reduction is achieved by rendering a quadrilateral with half the dimension along 
either axis, summing four elements. Applying this process repeatedly,akintoamipmappyramid,wewill.nally 
render a single pixel quadrilateral containing the sum-reduction result. Notes If the dimensions of 
X x are not powers of two the reduction must deal with odd length dimensions. One could always test 
whether texels are out of bounds before including them in the reduction. Alternatively, separate fragment 
programs can be run on the boundaries. Because of less than full utilization of functional units for 
smaller textures this is unattractive. Texels that do not correspond to actual data elements can be reduced 
so long as they contain the identity of the reduction operator. Thus to initialize a sum-reduction we 
place zeros in unused texels.  3.2 Packing Recall that X x textures will be read and written by fragment 
programs. For improved performance of writing operations we optimize the layout of X x variables. These 
come in groups of size ik according to the number k of non-zero off-diagonal entries in A. We discuss 
a performance model and then the optimization. 3.2.1 GPU Streaming Model Sofar wehave adopted an abstract 
streaming model. Now we specialize; consider the characteristics of a GPU streaming model: SIMD GPUsexecute 
fragment programsin SIMDfashion. Let p be the number of parallel pipelines; then every instruction operates 
on a tuple of p neighboring pixels. For peak performance we must make useful work of every pixel in the 
tuple. Triangle Rasterization GPUs are optimized for rendering triangles. We assume that axis aligned 
rectangles are rendered as a pair of axis aligned right triangles. In rendering each right triangle thereiswastedworkalongthehypotenuse 
sincepartsof sometuples will lie outside the triangle. Hence, in rendering a rectangle of tuple dimension 
w  h, tuples along the diagonal tend to be rasterized twice(onecopyis subsequently discarded,but computepower 
is wasted). The total number of tuples sent to the fragment stage is therefore w  h plus a number of 
wasted tuples bounded above by max(w, h). For peak performance we must minimize the wasted work along 
the diagonal. Round-Robin Pipelining of Texture Memory Access A fundamental issue in streaming architectures 
is hiding the memoryaccesslatency[Arvind and Iannucci 1987].To that end, streaming processors are typically 
multi-threaded (one early example was the HEP computer[Leiserson et al. 1993]). In a multi-threaded architecture, 
q independent stream records are processed in an interleaved manner: the program with instructions I1,I2,I3,... 
is executed over records R1 ...Rq using the sequential ordering I1(R1),I1(R2),...,I1(Rq),I2(R1),...,I2(Rq),I3(R1) 
... . Note that q - 1 cycles elapse between potentially data-dependent instructions. The designer must 
choose q large enough to hide memory latency and trade this off against the required additional chip 
area. A key consequence is that the fragment units process tuples in batches of size q. Since a partially 
.lled pipeline incurs the same cost asa full pipeline we can observea batchquantization effect (Figure3).For 
peak performance we must ensure that all q tuples provide useful work. Figure 3: Normalized plot showing 
time vs. rectangle area as observed on the GeForce FX, driver version 42.51. The value q  p = 512 is 
clearly noticeable, although the area is actually just below 500, consistent with the assumption that 
fragments on the diagonal are rasterized (not rendered) twice on the GeForce FX. To isolate the effect 
of batchquantization, we used a long fragment program (eliminatingsetup,rasterization and vertex-programoverhead) 
with no fetchoperations (eliminatingbandwidth overhead).  3.2.2 Optimization Taking into consideration 
our above model we pack an output stream into a sequence of identical rectangles, each with dimensions 
w by h. Optimizing for performance, we choose the dimensions w and h, partition the data stream over 
the rectangles, and assign a (possibly different) fragment program to every rectangle. Dimensions The 
dimensions are hardware and driver dependent: we .nd good choices for rectangle area, w  h, by simple 
experiments which reveal estimates of p  q (Figure3). A rectangle of dimensions w and h produces w 
 h tuples plus some number of additional wasted tuples bounded above by max(w, h). With the fragment 
stage processing batches of q tuples, an optimal rectangle maximizes the amount of useful work w  h 
subject to the constraint # tuples = z  q for some integer z. This de.nesafamily of optimal rectangles 
corresponding to the number z =1, 2,.... We chooseasingle solution from thisfamilyasit leadstoatrivial 
rectangle layout algorithm. Inparticular, we choose z =1 since this provides the .nest granularity in 
packing the stream. We neglect per-primitive startup costs, assuming this is small for primitives containing 
a minimal number of tuples(<w  h). We assume that batch quantization is only noticeable when changing 
programs, e.g., when a pipeline .ush is required. In reality, pipeline .ushes may or may not be performed 
when switching between programs, depending on the hardware and driver versions. Our model is conservative: 
it assumes that a change in program is always followed by a pipeline .ush. In practice, the rectangle 
size chosen based on this conservative modelhasworked well. The inef.ciency for z =1 as compared to z 
. 1, e.g., extra diagonalwaste and start-up cost, is negligible(< 10%) and well worth the triviality 
of the resulting layout problem. On the GeForce FX we found that a rectangle of dimensions 26  18 pixels 
gives the lowest proportion of wasted pixels. Rectangle Layout The uniformity of dimensions makes the 
packing problem trivial to precompute. The only parameter to the layout problemisthe numberof rectanglestolay 
out.We can compute off-line the optimal layout, i.e., determine the best texture dimensions s and t 
as a function of the number of rectangles to lay out. At runtime a simple lookup gives a good layout. 
Multiple Programs For the sparse matrix problem we have multiple streams Sk each with ik recordstobe 
processedbya program Pk. Note that program Pk can process sparse matrix rows with k or fewer non-zero 
off-diagonals if we allow zero padding. This property is useful in meshes with few vertices of a particular 
valence. The underlying assumptionis thata partially .lled batchof q tuples costs the same as a fully 
.lled batch due to pipeline .ushes. We adopt the following greedy solution. Lay out the streams in decreasing 
order of program cost k = n-1,..., 0 and assign them 174174174 Figure 4: On the upper left a cube with 
normal noise and to its right a smoothed version. On the lower left a scanned mesh contaminatedwith 
acquisitionnoise.Itis denoisedthroughgeometric .ow. Note that this mesh has complicated boundaries. For 
movies see http://multires.caltech.edu/pubs/GPUSim.mpg to rectangles R1,R2,..., .lling each rectangle 
to capacity. Use the least expensive program Pk valid for all elements of Rj . Notes The layout is resolved 
when the mesh is .rst created. However, the entries inAaj , i.e.,the length of each rowsegment, must 
be appropriately padded. The corresponding entries in Ca should point toa constant address in X x which 
contains thevalue zero(constant toavoid unnecessaryburdenonthetexture cache).  3.3 Performance We have 
implemented all of the components of a general conjugate gradient solver, as well as the speci.c matrices 
for geometric .ow, including their recomputation for each smoothing step. The most performance critical 
functions are the matrix-vector multiply and the sum-reduction. We performed timing tests on a GeForce 
FX board usingameshwith 37kvertices(the scannerdatainFigure4). The matrix-vector multiply takes 33 instructions 
on an average row of the matrix (seven non-zero elements), 21 of which are texture fetches. At 500 MHz 
and 37kvertices, one could theoretically perform over 500 matrix multiplies per second. In practice, 
we observe about 120 matrix multiplies per second. Further tests show that the discrepancy is due to 
the random access pattern causing cache thrashing. Areduction, including out of bounds checking, requires 
ten instructions (four fetches, three adds, three compares) per destination fragment per pass. For 
a 200  200 layout to be reduced to 100100,the cost of one pass of the reduction is100kinstructions. 
Doingthisatalllevelsofthe hierarchyincreasesthisbyafactorof 4/3. Theoretically,the sum reduction canbeperformedover 
15000 times per second. In practice our code executes at roughly 3400 reductions per second. TheCG innerloopdoesa 
single matrix multiplyandtwo reductions, as well as some signi.cantly less costly operations that can 
be considered free. This entire loop can be performed about 110 times per second. The CG solver typically 
only needs a few iterations e.g., .ve for each smoothing step, so an entire smoothing step can be performed 
in less than 1/20th of a second. Notes Currentdrivershaveaperformance penalty revalidationof the OpenGL 
pipeline state during pbuffer switches which is unnecessary for our computations. At present only about 
200 pbuffer switches per second are possible, severely limiting performance. This limitation will be 
removed in the near future. Hence all timings aregiven withthepbufferoverhead removed. The movies were 
produced from screen dumps running on actualhardware, in effect simulatinga setting with thepbuffer switchpenaltyremoved. 
 4 Solver for Regular Grids We now turn to a solver for discretizations of elliptic PDEs over regular 
grids. In that case the sparse matrices have a very regular structure enabling ef.cient implementation 
of multigrid solvers. For the generic setup we consider the Helmholtz equation with Dirichlet and/or 
Neumann boundary conditions on the unit square, O = [0, 1]2 -.2 u(x)+ su(x)= g(x) x . O . R2 u(x)= uD(x) 
x . .O or .n .u(x)= uN (x) x . .O, where .n denotes the outward pointing normal on the boundary of the 
domain whenever this quantity is well de.ned. This PDE may be solved via discretization which leads to 
a matrix problem. Whether one uses .nite elements,volumes, or difference, the structure of the resulting 
matrices is essentially identical. For concreteness we usea .nite difference discretization asin[Stam 
1999] Linear System After discretization we have to solve a linear system Ahuh = bh in (N + 1)  (N 
+ 1) variables, not all ofwhich are free. The linear operator Ah acting on the 2D grid uh may be described 
by a set of stencils, with possibly varying entries, each of size no larger than 3  3 (2  3 at the 
boundary, 2  2 at the corner). Careis requiredinthe Neumann caseasithasanon-trivial null space[Briggs 
et al. 2000, pp. 113 119]. 4.1 Incompressible Navier-Stokes Fluid simulations area typical representativeof 
settings whichgive rise to such systems. As a challenge problem we implemented Stam s solver for the 
incompressible viscous Navier-Stokes equations[1999]. The .uid is governed by a velocity .eld u which 
satis.es .u =0 ..u = -(u .)u + ..2 u + .b .t where b denotes external body force, . the viscous drag, 
and the . is the .uid density (we will assume it to be unity). Using a semiimplicit time discretization 
as well as a projection step to ensure a (k+1) divergence free vector .eld, the update from time t(k) 
to t= t(k) +.t proceeds as * (k)(k)(k)(k) (.I - ..t.2)u = .u+.t(.b- (u.)u) (2) .2 * p =(./.t).u (3) 
(k+1) * u= u - (.t/.).p, where p is a pressure .eld which may be discarded at the end of the time step. 
The .rst equation solves for a new velocity .eld using a Helmholtz solver with zero Dirichlet boundary 
conditions, while the second equation usesaPoisson solver with zero Neumann boundary conditions. Implementing 
this time stepping requires two non-trivial functions. One for the advection stepand the other for an 
elliptic PDE solver. 175175175 Notes Tokeepthe multigrid solver simple wedo notwork with staggered grids[Fedkiw 
et al. 2001],but instead colocate pressure and velocity .elds as was done by Stam[1999]. The domain is 
discretized into (N + 1)  (N + 1) uniformly spaced samples distance h =1/N apart with pressure and velocity 
variables pi,j ui,j =(ux,uy)i,j i, j =0,...,N In case periodic boundary conditions are used the associated 
indices are to be understood modulo N, i.e., 0 = N. 4.1.1 Advection Step Following Stam[1999] we trace 
integral curves back in time to compute the advected velocity .eld u adv =(u .)u adv ui,j = C(u, -.tu)i,j 
. where we used a simple .rst order integrator (higher order integrators can be de.ned as well). The 
operator C returns a .eld which is interpolated (typically bilinear) from its .rst argument .eld using 
offsetvectorsgivenbythe second argument .eld. Offsets that leave the domainare properlyclampedtothedomainboundary.Notethat 
boundary conditions are automatically preserved by the interpolation operation.  4.2 Multigrid In 
this section we assume that N =2j for some j> 5. Systems with fewer variables can be solved suf.ciently 
fast with a diagonally preconditioned conjugate gradient algorithm.To simplify the exposition we will 
onlydescribea simpleV-cycle with either Neumann or Dirichlet boundary conditions. Mixed boundaries are 
possible as well,but not requiredby ourexamples. The basic ingredients required for multigrid areasimple 
relaxation scheme we will use weighted Jacobi and interpolation and projection operators. Thelatterareusedtobuildthesystem 
matricesat coarserlevelsas well as to propagate residual and correction vectors between levels of resolution.Foranexcellent 
introductiontothe multigrid method we recommendthetextby Briggsandco-workers[2000]. Tobuild the coarser 
matricesweneed an interpolation operatorS from coarse to .ne and a projection operator P from .ne to 
coarse. ForS we chose bilinear subdivision and for P full weighting, i.e., P =1/4ST , resulting in a 
coarser level system matrix A2h = PAhS, and so on recursively to some coarsest level. With these in place 
theV-cycle multigrid algorithm canbe stated as uh . V-Cycle(.1,.2, vh, bh) If(CoarsestQ( h )) Return 
uh . Solve(Ah, vh, bh) Else vh . Relax(.1, vh, bh) // pre-smooth b2h . P(bh - Ahvh) // project residual 
v2h . V-Cycle(.1,.2, 02h, b2h) // recurse vh . vh + Sv2h // interpolate&#38;correct Return uh . Relax(.2, 
vh, bh) // post-smooth Iterationtowards solutionatthe .nestlevelis performedbystarting with an initial 
guess vh and the right hand side bh and improving it through repeated application of theV-cycle algorithm. 
The parameters .1 and .2 control the number of pre-and post-smoothing steps. Othervariants such as -cycle 
and full multigrid are straightforwardvariationsontheabove code[Briggsetal. 2000].Forthe smoother we 
chose the damped Jacobi iteration with . =2/3 uh . Relax(., vh, bh) For(i =0;i<.;i = i +1 ) r . bh - 
Ahvh vh . vh + .(Ah)-1 r ii Return uh . vh For simplicity we will use Jacobi iteration for the coarsest 
level solve as well. From the above pseudo code we see that we need the following non-trivial functions: 
(1) application of the interpolation operator S to a vector; (2) application of the projection operator 
P to a vector; (3) application of Ah to a vector; and (4) computation of A2h. Texture Layout Assuminga2D 
domain,welayoutalldatain2D textures. Access into textures is described through multi-index notation 
i =(i0,i1), with arithmetic understood in the vector sense. To iterate over neighbors, respectively entries 
in a stencil, we use index sets such as {0, 1}2 = {(0, 0), (0, 1), (1, 0), (1, 1)} using the standard 
de.nition of set product. Recall that Ah can be seen as a map from grid points to 3  3 stencils. We 
store the matrix as nine 2D textures Ad d . h[i], {-1, 0, 1}2 each a map from grid points i to the stencil 
entry indexedby d. Matrices A2h, A4h, etc. are similarly stored. Toutilize all four channels in the 
.oating point units, the computational domain is cut into four quadrants whichare layered into the (x, 
y, z, w) channelsofa singletexturewithhalfthesizeineach dimension. This layering must group odd and even 
indexed nodes so that interpolation and projection operators can be applied correctly. Since manycomputations 
require neighbor access, this layered format needs a single pixel border all around which contains duplicates 
of appropriate nodes respectively zeros for border edges. These duplicates must bekept in sync during 
computation, issues well knownfrom domain decomposition[Demmel 1997]. This synchronization is performed 
on the GPU with a set of programs that copythe appropriate data into the texture border. Layering and 
un-layering is performed as needed with short fragment programs whichdonotposea performanceproblemduetotheirbrevity.For 
an alternative approach to using four channels for scalar problems see[Hall et al. 2003]. Interpolation 
Given a vector v2h stored in a 2D texture, interpolation to the .ner level becomes vh[i]=1/4 v2h[.(i 
+ d)/2.]. d.{0,1}2 For Neumann conditions the boundaries get interpolated as any other point in the domain. 
For Dirichlet boundary conditions the boundary should not be interpolated,but we do so anyway. Since 
the Dirichlet boundary conditions always vanish, no harm is done and the implementation is simpli.ed. 
Projection Since we are using full weighting, projection is performed via the adjoint of subdivision 
save for a division by four v2h[i]=1/4 Sd vh[2i + d] d.{-1,0,1}2 where d indexes the stencil, S =1/4{1, 
2, 1, 2, 4, 2, 1, 2, 1} (using lexicographic order on d). This code applies at all points in the interior 
of the domain. On the boundary(i0 =0, N/2 and/or i1 =0, N/2)the abovecode is correct for Neumann boundary 
conditions with out of bounds accesses clamped to zero. For Dirichlet boundary conditions all boundary 
values of v2h must be set to zero explicitly. This is easily achieved by initializing to zero and rendering 
a rectangle covering only indices 1 . . . N/2 - 1. 176176176 Figure 5: An example of a few time steps 
during a simulation run with particle advection used for visualization of the velocity .eld (For movies 
see http://multires.caltech.edu/pubs/GPUSim.mpg). The inlet on the left has a high inward velocity (two 
grid spaces per timestep). This particular simulation was run with a domain size of 513  129. When .uid 
is pushed into the larger area, which is initially at rest, vortices are shed, a phenomenon clearly visible 
in the pattern of the particles. Matrix Vector Multiply Here stencil accesses to the matrix Ah must be 
mapped appropriately to index offsets in the vector uh vh[i]= Ahd [i]uh[i + d]. d.{-1,0,1}2 For Dirichlet 
boundaries this code is executed only in the interior. For Neumann boundaries it is also executed on 
the boundary with out of bounds accesses clamped to zero. Composition of Stencils The most involved operation 
is the computation of coarser level stencils as the composition of operators S, Ah, and P eachof whichisgiven 
asa stencil.Formally we can express this as the triple operator composition A2h = PAhS, which may be 
expanded in index notation as d Se+g-2d SeAg A2h[i]=1/4 h[2i + e] e,g.{-1,0,1}2 Stencils on the boundary 
only need to be computed for Neumann boundaries, in which case out of bounds accesses are clamped to 
zero. Performingthe stencil composition correctlywas oneofthemost subtle implementation issuesinour algorithm.Intheaboveexpression 
we assume that out of bounds accesses on S are clamped to zero, easily achieved by creating a very small, 
suitably padded texture map for S. The sum could also be teased apart with careful analysis of which 
terms actually contribute to the sum. This not being a time critical part of the algorithm we refrained 
from that optimization.  4.3 Performance Wehave implemented the .uid solverof Stam[1999] asa realistic 
application context fora multigrid solver. Following[Fedkiw et al. 2001] we did not perform diffusion(. 
=0)on the velocity variables, as visually the numerical diffusion is suf.cient. Consequently we used 
the multigrid solver only for the Neumman probleminvolvedin the pressure computation (Equation3). The 
most expensive operation in the multigrid V-cycle is the matrix-vector multiply, i.e., application of 
the stencil. The program has 27 instructions, 18 of which aretexture fetches.Ona 257257 grid (stored 
as a 129  129 4-deep texture), this operation can be performed over 1370 times per second at 500 MHz 
(the theoretical peak is 4500 per second). The operation is proportionally cheaper on smaller grids, 
except that on very coarse grids there is a penalty due to the batch quantization. On a 17  17 fragment 
grid this penalty is almost 50%, at 33  33 it is 29%, and decreases as the grid gets larger. The interpolation 
and projection steps are applied once per level intheV-cyclealgorithm.The interpolationkernelisten instructions 
long while projection takes 19. Thesekernels canexecute 4800 respectively 6000 times per second to move 
between 257  257 and 129  129. We have found that a good choice of parameters is to have several Jacobi 
iterations per level, which decreases the performance impact of interpolation and projection. In general, 
theydo not limit performance. The advection step is not performed directly on the layered velocity .eld 
because it is impossible to fetch each of four channels from different advected locations (texels) in 
a single instruction. Similarly the bilinear interpolation needed for the advection step mustbe codedexplicitly 
since .oating pointbuffersdo not provide this functionality. Consequently the advection step .rst un-layers 
the velocity .eld, performs the computations for advection, and then layers the velocity variables again. 
Since this must only be performed once per timestep the cost relative to the solver step is negligible. 
The number of pre-and post-smoothing iterations can be tweaked as necessary depending on the particular 
problem being solved.The systemin Figure5,withat timeslargedivergenceonly required four pre-smoothings, 
two post-smoothing steps, and two V-cycles. Neglecting pbuffer overhead, a single timestep with two multigrid 
V-cycles, using four pre-smoothing and two post-smoothing steps could be applied to a 513  513 grid 
in approximately 1/20th ofa second.For our simulations we useda gridof 513  129.  5 Conclusion We have 
demonstrated a mapping of two widely applicable solvers to the GPU, and have provided solutions to manyof 
the peculiarities that arise on this hardware. These design choices can be applied to other algorithms 
as well. Neglecting the unnecessary overhead of pbuffer switching, our implementation performs well. 
Both applications would run in realtime for the given problem instances. We implemented CPUversionsof 
the matrix multiplykernels using SSE, and tested them on a 3GHz Pentium 4. The GPU implementation achieves 
120 unstructured matrix multiplies per second whereas the CPU implementation can only do 75 per second 
on the stated problem instance.For the structured matrix multiply, the GPU can do 1370 matrix multiplies 
per second whereas the CPU can do 750 per second. Our tests haveshown that both the CPU and GPU implementations 
are bandwidth limited. The multigrid solver has enormous performance potential, and would be even more 
useful if it were applied to irregular grids. The issues involved in this deserve further study. A more 
straightforward extension would be application of the proposed sparse matrix conjugate gradient algorithm 
to simulations involving tetrahedral meshes. The Cg language could provide an alternative implementation 
path,butitisnotaswell suitedto scienti.c computing applications. 177177177 For example, the concept 
of a pointer is meaningful for numerical applications,but not necessarily for graphics. The ability to 
allocate partsofatexture similarto processor allocation [Blelloch 1990]in SIMD programming would alleviate 
some of the tedium of packing. A specialized compiler that hides such distinctions would make this hardware 
more accessible to those less familiar with computer graphics. Performance could be boosted further if 
texture fetch instructions allowed additional offsets to be added to input coordinates. This could decrease 
the instruction count of the CG matrix multiply by as much as 20%. Finally, reduction operators would 
bene.t greatlyfromafewglobally writableregisters.Forexample,asingle accumulationregisterwouldallowasum-reductiontobe 
performed in a single pass. Limiting such registers to commutative operators would avoid troublesome 
order dependencies. Reductions would also be simpli.ed by allowing borders on .oating point textures. 
Acknowledgment This work was supported in part by NSF (DMS-0220905, DMS-0138458,ACI-0219979), the DOE(W-7405-ENG-48/B341492), 
NVIDIA, the Center for Integrated Multiscale Modeling and Simulation, Alias|Wavefront, Pixar, and thePackardFoundation. 
Special thanks to MattPapakipos, NickTriantos, David Kirk,PaulKeller, MarkMeyer, Mika Nystr  om, Niles 
Pierce, Burak Aksoylu, Michael Holst, Jason Hickey, Andr eDeHon, Ian Buck, Mark Harris and all the speakers 
and studentsin the Hacking the GPU class(Caltech,Fall 2002).  References ARVIND,AND IANNUCCI,R.A. 1987.Two 
Fundamental Issuesin Multiprocessing. In Proceedings of DFVLR -Conference 1987,Parallel Processing 
in Science and Engineering. BARRETT, R., BERRY, M., CHAN, T. F., DEMMEL, J., DONATO, J., DONGARRA, J., 
EIJKHOUT, V., POZO, R., ROMINE, C., AND DER VORST, H. V. 1994. Templates for the Solution of Linear Systems: 
Building Blocks for Iterative Methods, 2nd ed. SIAM. BLELLOCH,G.E. 1990. Vector Models for Data-Parallel 
Computing. MIT Press. BRIGGS, W. L., HENSON, V. E., AND MCCORMACK, S. F. 2000. A MultigridTutorial, 2nd 
ed. SIAM. CARR,N.A.,HALL,J.D., AND HART,J.C. 2002. TheRay Engine.In SIGGRAPH/EurographicsWorkshop onGraphics 
Hardware. COHEN, M. F., CHEN, S. E., WALLACE, J. R., AND GREENBERG,D.P. 1988.AProgressiveRe.nement ApproachtoFast 
Radiosity Image Gen eration. Computer Graphics (Proceedings of SIGGRAPH) 22, 75 84. DEMMEL,J.W. 1997. 
Applied Numerical Linear Algebra. SIAM, Philadelphia,PA. DESBRUN,M.,MEYER,M.,SCHR ODER,P., AND BARR,A.H. 
1999. Im plicitFairing of Irregular Meshes Using Diffusion and Curvature Flow. In Proceedings of SIGGRAPH, 
317 324. DESBRUN,M.,MEYER,M., AND ALLIEZ,P. 2002. IntrinsicParameteri zations of Surface Meshes. Computer 
GraphicsForum (Proceedings of Eurographics) 21, 3, 209 218. DIEWALD,U.,MORIGI,S., AND RUMPF,M. 2002.ACascadic 
Geometric Filtering Approach to Subdivision. Comput. Aided Geom. Des. 19, 9, 675 694. FEDKIW,R.,STAM,J., 
AND JENSEN,H.W. 2001.Visual Simulationof Smoke. In Proceedings of SIGGRAPH, 15 22. GOODNIGHT, N., LEWIN, 
G., LUEBKE, D., AND SKADRON, K. 2003. AMultigrid Solver for BoundaryValue Problems Using Programmable 
Graphics Hardware.Tech.Rep. CS-2003-03,UniversityofVirginia. HACKBUSCH, W. 1985. Multi-Grid Methods and 
Applications. Springer Verlag, Berlin. HALL, J. D., CARR, N. A., AND HART, J. C. 2003. Cache and BandwidthAware 
Matrix Multiplication on the GPU. Tech. rep., University of Illinois. HARRIS, M. J., COOMBE, G., SCHEUERMANN, 
T., AND LASTRA, A. 2002. Physically-BasedVisual Simulation on Graphics Hardware. In SIGGRAPH/EurographicsWorkshop 
onGraphics Hardware. HARRIS, M. J. 2002. Analysis of Error in a CML Diffusion Operation. Tech. Rep. TR02-015, 
UNC Chapel Hill. HILLESLAND, K. E., MOLINOV, S., AND GRZESZCZUK, R. 2003. Nonlinear Optimization Framework 
for Image-Based Modeling on Programmable Graphics Hardware. ACMTransactions onGraphics. HOFF, K. E., 
KEYSER, J., LIN, M., MANOCHA, D., AND CULVER, T. 1999.Fast Computationof GeneralizedVoronoi Diagrams 
Using Graph ics Hardware. In Proceedings of SIGGRAPH, 277 286. KASS, M., AND MILLER, G. 1990. Rapid, 
Stable Fluid Dynamics for Computer Graphics. Computer Graphics (Proceedings of SIGGRAPH) 24, 4, 49 57. 
KELLER,A. 1997. Instant Radiosity. In Proceedings of SIGGRAPH, 49 56. KHAILANY, B., DALLY, W. J., RIXNER, 
S., KAPASI, U. J., MATTSON, P., NAMKOONG, J., OWENS, J. D., TOWLES, B., AND CHANG, A. 2001. Imagine: 
Media Processing with Streams. IEEE Micro 21, 2, 35 46. KHAILANY, B., DALLY, W. J., RIXNER, S., KAPASI, 
U. J., OWENS, J. D., AND TOWLES, B. 2003. Exploring the VLSI Scalability of Stream Processors. In Proceedings 
of the Ninth Symposium on High Performance Computer Architecture. KOBBELT,L.,CAMPAGNA,S.,VORSATZ,J., 
AND SEIDEL,H.-P. 1998. Interactive Multi-Resolution Modeling on Arbitrary Meshes. In Proceedings of 
SIGGRAPH, 105 114. KRLinear algebra operators UGER, J., AND WESTERMANN, R. 2003. for gpu implementation 
of numerical algorithms. ACMTransactions on Graphics. LARSEN,E.S., AND MCALLISTER,D.K. 2001.Fast Matrix 
Multiplies using Graphics Hardware. In Supercomputing. LEISERSON,C.,ROSE,F., AND SAXE,J. 1993. Optimizing 
synchronous circuitryby retiming. In ThirdCaltechConference On VLSI. LENGYEL, J., REICHERT, M., DONALD, 
B. R., AND GREENBERG,D.P. 1990. Real-Time Robot Motion Planning Using Rasterizing Computer Graphics Hardware. 
Computer Graphics (Proceedings of SIGGRAPH) 24, 327 335. LI,W.,WEI,X., AND KAUFMAN,A. 2003. Implementing 
Lattice Boltz mann Comptuation on Graphics Hardware. TheVisual Computer. To appear. LINDHOLM, E., KILGARD, 
M. J., AND MORETON, H. 2001. A User-ProgrammableVertex Engine. In Proceedings of SIGGRAPH, 149 158. M 
ULLER, M.,DORSEY, J., MCMILLAN, L., JAGNOW, R., AND CUTLER, B. 2002. Stable Real-Time Deformations. InACM 
SIGGRAPH Symposium on Computer Animation, 49 54. OLANO, M., Ed. 2002. Real-Time Shading Languages. Course 
Notes. ACM SIGGRAPH. OWENS, J. D., KHAILANY, B., TOWLES, B., AND DALLY, W. J. 2002. Comparing Reyes and 
OpenGL on a Stream Architecture. In SIGGRAPH/EurographicsWorkshop onGraphics Hardware, 47 56. PURCELL, 
T. J., BUCK, I., MARK, W. R., AND HANRAHAN, P. 2002. RayTracing on Programmable Graphics Hardware. ACMTransactions 
on Graphics 21, 3, 703 712. SEMICONDUCTOR INDUSTRY ASSOCIATION, 2002. International Technology Roadmap 
for Semiconductors. http://public.itrs.net/, December. SHEWCHUCK, J. R. 1994. An Introduction to the 
Conjugate Gradient Method without the Agonizing Pain. http://www.cs.cmu.edu/ quakepapers/painless-conjugate-gradient.ps., 
August. STAM,J. 1999. Stable Fluids. In Proceedings of SIGGRAPH, 121 128. STRZODKA,R., AND RUMPF,M. 2001. 
NonlinearDiffusionin Graphics Hardware. In Visualization, 75 84. STRZODKA,R. 2002.Virtual16 Bit Precise 
Operations on RGBA8Tex tures. In Vision, Modeling andVisualization. THE C*TEAM. 1993. C* Manual, 2nd 
ed. Thinking Machines Corporation. THOMPSON, C. J., HAHN, S., AND OSKIN, M. 2002. Using Modern Graphics 
Architectures for General-Purpose Computing: AFramework and Analysis. In International Symposium on Microarchitecture. 
 178178178 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198782</article_id>
		<sort_key>179</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[Radiosity on graphics hardware]]></title>
		<page_from>179</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198782</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198782</url>
		<abstract>
			<par><![CDATA[Radiosity is a widely used technique for global illumination. Typically the computation is performed offline and the result is viewed interactively. We present a technique for computing radiosity, including an adaptive subdivision of the model, using graphics hardware. Since our goal is to run at interactive rates, we exploit the computational power and programmability of modern graphics hardware. Using our system on current hardware, we have been able to compute and display a radiosity solution for a 10,000 element scene in less than one second.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P345954</person_id>
				<author_profile_id><![CDATA[81100408443]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Greg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Coombe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39056732</person_id>
				<author_profile_id><![CDATA[81100116782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Harris]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P20148</person_id>
				<author_profile_id><![CDATA[81100264426]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Anselmo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lastra]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198783</article_id>
		<sort_key>180</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[Interactive time-dependent tone mapping using programmable graphics hardware]]></title>
		<page_from>180</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198783</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198783</url>
		<abstract>
			<par><![CDATA[Modern graphics architectures have replaced stages of the graphics pipeline with fully programmable modules. Therefore, it is now possible to perform fairly general computation on each vertex or fragment in a scene. In addition, the nature of the graphics pipeline makes substantial computational power available if the programs have a suitable structure. In this paper, we show that it is possible to cleanly map a state-of-the-art tone mapping algorithm to the pixel processor. This allows an interactive application to achieve higher levels of realism by rendering with physically based, unclamped lighting values and high dynamic range texture maps. We also show that the tone mapping operator can easily be extended to include a time-dependent model, which is crucial for interactive behavior. Finally, we describe the ways in which the graphics hardware limits our ability to compress dynamic range efficiently, and discuss modifications to the algorithm that could alleviate these problems.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Graphics processors</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.8</cat_node>
				<descriptor>Photometry</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010227</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Scene understanding</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010389</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics processors</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P575232</person_id>
				<author_profile_id><![CDATA[81100024446]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nolan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Goodnight]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Virginia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39032689</person_id>
				<author_profile_id><![CDATA[81408591714]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Rui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Virginia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24011637</person_id>
				<author_profile_id><![CDATA[81100188094]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Cliff]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Woolley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Virginia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39038311</person_id>
				<author_profile_id><![CDATA[81100337084]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Greg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Humphreys]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Virginia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Ansel Adams. The Print. Little, Brown and Company, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[ATI. Radeon 9700 Pro, 2002. http://mirror.ati.com/products/pc/radeon9700pro/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882364</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Jeff Bolz, Ian Farmer, Eitan Grinspun, and Peter Schr&#246;der. Sparse matrix solvers on the GPU: Conjugate gradients and multigrid. ACM Transactions on Graphics, 22(3), July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Ken Chiu, Michael Herf, Peter Shirley, S. Swamy, Changyaw Wang, and Kurt Zimmerman. Spatially nonuniform scaling functions for high contrast images. In Proceedings of Graphics Interface 1993, pages 245--253, May 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732299</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Jonathan Cohen, Chris Tchou, Tim Hawkens, and Paul Debevec. Real-time high-dynamic range texture mapping. In Proceedings of Eurographics Workshop on Rendering, pages 313--320, June 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Michael F. Cohen, Donald P. Greenberg, David S. Immel, and Philip J. Brock. An progressive refinement approach to fast radiosity image generation. In Proceedings of SIGGRAPH 1988, pages 75--84, August 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258884</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Paul Debevec and Jitendra Malik. Recovering high dynamic range radiance maps from photographs. In Proceedings of SIGGRAPH 1997, pages 369--378, August 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kate Devlin, Alan Chalmers, Alexander Wilkie, and Werner Purgathofer. STAR: Tone reproduction and physically based spectral rendering. In Proceedings of Eurographics 2002, pages 101--123, September 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732137</ref_obj_id>
				<ref_obj_pid>647652</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Fr&#233;do Durand and Julie Dorsey. Interactive tone mapping. In Eurographics Workshop on Rendering, pages 219--230, June 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566573</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Raanan Fattal, Dani Lischinski, and Michael Werman. Gradient domain high dynamic range compression. ACM Transactions on Graphics, 21(3):249--256, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844190</ref_obj_id>
				<ref_obj_pid>844174</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Nolan Goodnight, Cliff Woolley, Gregory Lewin, David Luebke, and Greg Humphreys. A multi-grid solver for boundary value problems using programmable graphics hardware. In Proceedings of SIGGRAPH/Eurographics Workshop on Graphics Hardware, July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Mark Harris. GPGPU: General-purpose computation using graphics hardware, 2003. http://www.cs.unc.edu/~harrism/gpgpu.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569061</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Mark J. Harris, Greg Coombe, Thorsten Scheuermann, and Anselmo Lastra. Physically-based visual simulation on graphics hardware. In Proceedings of SIGGRAPH/Eurographics Workshop on Graphics Hardware, pages 109--118, August 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566639</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Greg Humphreys, Mike Houston, Ren Ng, Sean Ahern, Randall Frank, Peter Kirchner, and James T. Klosowski. Chromium: A stream processing framework for interactive graphics on clusters of workstations. ACM Transactions on Graphics, 21(3):693--702, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311567</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Kenneth E. Hoff III, John Keyser, Ming C. Lin, Dinesh Manocha, and Tim Culver. Fast computation of generalized Voronoi diagrams using graphics hardware. In Proceedings of SIGGRAPH 1999, pages 277--286, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2319385</ref_obj_id>
				<ref_obj_pid>2318950</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Daniel J. Jobson, Zia ur Rahman, and Glenn A. Woodell. A multiscale retinex for bridging the gap between color images and the human observation of scenes. IEEE Transactions on Image Processing, 6(7):965--976, July 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258769</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Alexander Keller. Instant radiosity. In Proceedings of SIGGRAPH 1997, pages 49--56, August 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882363</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Jens Kr&#252;ger and R&#252;diger Westermann. Linear algebra operators for GPU implementation of numerical algorithms. ACM Transactions on Graphics, 22(3), July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>582089</ref_obj_id>
				<ref_obj_pid>582034</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[E. Scott Larsen and David K. McAllister. Fast matrix multiplies using graphics hardware. In Proceedings of IEEE Supercomputing 2001, November 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614380</ref_obj_id>
				<ref_obj_pid>614268</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Greg Ward Larson, Holly Rushmeier, and Chistine Piatko. A visibility matching tone reproduction operator for high dynamic range scenes. IEEE Transactions on Visualization and Computer Graphics, 3(4):291--306, October-December 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97915</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Jed Lengyel, Mark Reichert, Bruce R. Donald, and Donald P. Greenberg. Real-time robot motion planning using rasterizing computer graphics. In Proceedings of SIGGRAPH 1990, pages 327--335, July 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882362</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[William R. Mark, Steve Glanville, and Kurt Akeley. Cg: A system for programming graphics hardware in a C-like language. ACM Transactions on Graphics, August 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844191</ref_obj_id>
				<ref_obj_pid>844174</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Kenneth Moreland and Edward Angel. The FFT on a GPU. In Proceedings of Graphics Hardware 2003, July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[NVIDIA. GeForceFX, 2003. http://www.nvidia.com/view.asp?PAGE=fx_desktop.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280922</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Sumanta N. Pattanaik, James A. Ferwerda, Mark D. Fairchild, and Donald P. Greenberg. A multiscale model of adaptation and spatial vision for realistic image display. In Proceedings of SIGGRAPH 1998, pages 287--298, July 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566640</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Tim Purcell, Ian Buck, William Mark, and Pat Hanrahan. Ray tracing on programmable graphics hardware. ACM Transactions on Graphics, 21(3):703--712, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566575</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Erik Reinhard, Michael Stark, Peter Shirley, and Jim Ferwerda. Photographic tone reproduction for digital images. ACM Transactions on Graphics, 21(3):267--276, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2384121</ref_obj_id>
				<ref_obj_pid>2384110</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Martin Rumpf and Robert Strzodka. Nonlinear diffusion in graphics hardware. In Proceedings of Eurographics/IEEE TCVG Symposium on Visualization, pages 75--84, May 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Annette Scheel, Marc Stamminger, and Hans-Peter Seidel. Tone reproduction for interactive walkthroughs. Computer Graphics Forum, 19(3):301--312, August 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Christophe Schlick. Quantization techniques for visualization of high dynamic range pictures. In Proceedings of Eurographics Workshop on Rendering, pages 7--20, June 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Mark Segal and Kurt Akeley. The OpenGL Graphics System: A Specification (Version 1.2.1). 1999. ftp://ftp.sgi.com/opengl/doc/opengl1.2/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>774894</ref_obj_id>
				<ref_obj_pid>774861</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Chris J. Thompson, Sahngyun Hahn, and Mark Oskin. Using modern graphics architectures for general-purpose computing: A framework and analysis. In Proceedings of IEEE/ACM International Symposium on Microarchitecture, pages 306--317, November 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300783</ref_obj_id>
				<ref_obj_pid>300776</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Jack Tumblin, Jessica K. Hodgins, and Brian K. Guenter. Two methods for display of high contrast images. ACM Transactions on Graphics, 18(1):56--94, January 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617873</ref_obj_id>
				<ref_obj_pid>616030</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Jack Tumblin and Holly E. Rushmeier. Tone reproduction for realistic images. IEEE Computer Graphics and Applications, 13(6):42--48, November 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311544</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Jack Tumblin and Greg Turk. LCIS: A boundary hierarchy for detail-preserving contrast reduction. In Proceedings of SIGGRAPH 1999, pages 83--90, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>180934</ref_obj_id>
				<ref_obj_pid>180895</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Greg Ward. A Contrast-based Scalefactor for Luminance Display. In Graphics Gems IV, chapter VII.2, pages 415--421. Academic Press, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Eurographics Symposium on Rendering 2003 Per Christensen and Daniel Cohen-Or (Editors) Interactive Time-Dependent 
Tone Mapping Using Programmable Graphics Hardware Nolan Goodnight, Rui Wang, Cliff Woolley, and Greg 
Humphreys Department of Computer Science, University of Virginia Abstract Modern graphics architectures 
have replaced stages of the graphics pipeline with fully programmable modules. Therefore, it is now possible 
to perform fairly general computation on each vertex or fragment in a scene. In addition, the nature 
of the graphics pipeline makes substantial computational power available if the programs have a suitable 
structure. In this paper, we show that it is possible to cleanly map a state-of-the-art tone mapping 
algorithm to the pixel processor. This allows an interactive application to achieve higher levels of 
realism by rendering with physically based, unclamped lighting values and high dynamic range texture 
maps. We also show that the tone mapping operator can easily be extended to include a time-dependent 
model, which is crucial for interactive behavior. Finally, we describe the ways in which the graphics 
hardware limits our ability to compress dynamic range ef.ciently, and discuss modi.cations to the algorithm 
that could alleviate these problems. Categories and Subject Descriptors (according to ACM CCS): I.3.1 
[Computer Graphics]: Hardware Architecture Graphics Processors I.3.3 [Computer Graphics]: Picture/Image 
Generation Display Algorithms I.4.8 [Image Processing and Computer Vision]: Scene Analysis Photometry 
I.4.1 [Image Processing and Computer Vision]: Enhancement Digitization and Image Capture 1. Introduction 
Dynamic range is de.ned as the range of light intensities present in a scene. In the real world, very 
large dynamic ranges are commonplace, sometimes exceeding ten orders of magnitude. It is quite easy to 
produce such an image on a computer by using either a physically-based rendering system or a combination 
of multiple photographs taken at different exposures7. However, displaying these images presents a challenge 
for computer graphics since most output devices have a relatively small displayable dynamic range; frequently 
only integer intensities between 0 and 255 are permitted. This disparity has given rise to the .eld 
of tone mapping, whose broad goal is to optimize the mapping from an image with a large dynamic range 
to a display with a small dynamic range. Although the algorithms used to achieve this goal are diverse, 
they all typically operate as an of.ine process rather than in real-time: a high dynamic range (HDR) 
image is either synthesized by a rendering system or recovered from multiple photographs, and then the 
tone mapping algorithm processes that image, eventually producing a &#38;#169; The Eurographics Association 
2003. low dynamic range version. Improvements in CPU processing power have recently led to impressive 
advancements in this .eld, producing nearly artifact-free images that closely mimic the local adaptation 
abilities of the human eye. We have also seen a recent revolution in high-performance graphics architecture. 
Previously .xed stages of the graphics pipeline have been replaced with fully programmable ones, giving 
the user complete control over the processing of vertices or fragments. The primary purpose of this design 
change is to enable complex visual effects in interactive graphics applications. Because of the streaming 
nature of graphics hardware, the graphics processing unit (GPU) is able to achieve extremely high computational 
rates; the pixel pipeline on NVIDIA s GeForce FX card are capable of sustaining 51 GFLOPS24, which is 
roughly 8 times the computational power of the fastest Pentium 4 available today. Very recently, these 
programmable graphics pipeline stages have become suf.ciently general that non-traditional tasks have 
been implemented on the GPU, such as ray-tracing, sparse matrix solving, and motion planning12. These 
algorithms perform extremely well on the GPU because they are able to take advantage of the parallelism 
available in the pixel-processing portion of the pipeline. Reprinted from "Interactive Time-Dependent 
Tone Mapping Using Programmable Graphics Hardware" in Proceedings of the 14th Eurographics Workshop on 
Rendering {(2003)}. &#38;#169; The Eurographics Association 2003. ISBN ~ ISSN:1727-3463 , 3-905673-03-7 
180180180 In this paper, we explore the potential for using this programmability to add real-time tone 
mapping to interactive graphics applications. This allows a substantial increase in .exibility of application 
design and brings considerable added realism to interactive visual simulation. Because of the enormous 
computational power present in the GPU, we have been able to implement a state-of-the-art tone mapping 
algorithm at interactive rates. In our experiments, we found that some algorithms are better suited to 
implementation on a GPU than others. In particular, the photography-inspired techniques of Reinhard et 
al.27 are especially well-suited to an interactive GPU implementation; we will describe our implementation 
in detail. We will also describe an alternate algorithm for computing photographic zones that produces 
qualitatively similar results but is much more amenable to a fragment processor implementation. Finally, 
we show that a GPU-based tone mapping algorithm can easily be extended to contain a time-dependent term 
using a technique very similar to the one described by Durand and Dorsey9. This is important in an interactive 
setting, because the average luminance in a scene can change quickly (for example, when a bright light 
source suddenly comes into view), and we would like to avoid temporal discontinuities in brightness. 
In practice, we have found that having some amount of temporal adaptation is more important than the 
details of the algorithm used to achieve it. 2. Background and Related Work Scenes in the real world 
have a dynamic range that far exceeds the capabilities of 8-bit-per-channel output devices. This is 
especially true of scenes that contain a combination of indoor and outdoor elements, such as a room illuminated 
through a window. A variety of tone mapping (or tone reproduction ) algorithms exist to display these 
high dynamic range (HDR) images on a low dynamic range device. Devlin et al. give an excellent comprehensive 
review of research in this area8. 2.1. Tone Mapping Tone mapping operators are usually classi.ed as either 
global (spatially uniform) or local (spatially varying). Global operators apply a single luminance transform 
function to every pixel in the image. The simplest global operator is a linear map between the HDR image 
and the range of the output device. Linear scaling preserves relative contrast but removes most details 
contained in the image due to uniform scaling. Tumblin and Rushmeier .rst proposed the idea of tone 
mapping based on human perception; their method preserves the overall impression of perceived brightness34. 
Ward then proposed preservation of perceived contrast rather than brightness36: his visibility-preserving 
operator maps the smallest perceptible luminance difference in the HDR image to the smallest perceptible 
luminance difference of the display device. In a later paper, Ward Larson et al. presented a histogram 
adjustment technique based on the distribution of local luminance adaptation in a scene20. This technique 
also improves image realism by incorporating models for human contrast sensitivity, glare, spatial acuity 
and color sensitivity. Tumblin et al. then introduced a new operator based on the human visual adaptation 
process. Their operator decomposed an image into illumination and re.ectance layers, then compressed 
the illumination layer while preserving details contained in the re.ectance33. Global operators are simple 
and computationally ef.cient, but they have dif.culty effectively preserving local contrast in most HDR 
images. Local operators solve this problem by using a spatially varying mapping, so two identical input 
luminances may be mapped to different output values based on properties of their local neighborhood. 
Chiu et al. and Schlick presented early experiments in local tone mapping4, 30. Jobson et al. and Pattanaik 
et al. later presented multi-resolution techniques (such as a retinexbased method) that attempted to 
mimic the behavior of the human visual system16, 25. Tumblin and Turk developed the Low Curvature Image 
Simpli.er (LCIS) method, which uses a formula inspired by anisotropic diffusion to detect gradient discontinuities, 
thereby preserving much of the local detail35. Their method works well, but can overemphasize details 
and also requires the user to set many parameters. Recently, Fattal et al. presented a new method based 
on attenuating magnitudes of large luminance gradients10. Their method is conceptually simple and computationally 
ef.cient, although it does require the solution of a Poisson equation. Goodnight et al.11 have implemented 
this algorithm on the GPU, though it does not run at interactive rates. Another recent paper by Reinhard 
et al. uses an approach inspired by Ansel Adams s photographic zone system 27. A summary of their algorithm 
is presented in Section 2.3. This algorithm maps particularly well to programmable graphics hardware 
with a few modi.cations; our implementation of Reinhard s method is the primary focus of this paper. 
Because of the computational complexity of tone mapping algorithms, interactive tone mapping techniques 
have received relatively little attention to date. Scheel introduced the application of tone reproduction 
in interactive walkthroughs29. This was done by modifying Ward Larson s operators36, 20 and using textures 
to represent the luminance produced by global illumination rendering. However, Scheel s operator is 
still computationally demanding, and this approach does not incorporate any time-dependent adaptation. 
The interactive tone mapping framework presented by Durand and Dorsey9 uses a multi-pass scheme that 
incorporates adaptation, glare, and loss of acuity. They use a global operator with time-dependent adaptation, 
incorporating a simple model for both light and chromatic adaptation. We adopt their time-dependent 
light adaptation to simulate the eye s adaptation in a dynamic setting, but apply it in the context of 
Reinhard s local tone mapping operator. 2.2. Programmable Graphics Hardware Modern graphics hardware 
such as the NVIDIA GeForce FX24 and the ATI Radeon 9700 and 98002 provides a .exible programming interface 
to the vertex and fragment portions of the graphics pipeline. Programs speci.ed to these stages (known 
as shaders) execute in lockstep on a SIMD architecture and enjoy substantially higher peak .oating-point 
performance than CPU programs. Although this computational horsepower has traditionally been used to 
enhance the visual appearance of interactive 3D rendering, GPUs have suf.cient computational expressiveness 
to implement very different algorithms, as demonstrated by Purcell et al. s raytracer that runs completely 
on graphics hardware26. Programmable vertex processing has limited applicability to general-purpose 
computation, because it cannot currently access memory (such as textures). Therefore, most general-purpose 
GPU computation work to date has concentrated exclusively on the programmable pixel pipeline. Even before 
programmability was added, special rasterization techniques were used to accelerate such diverse applications 
as motion planning21, Voronoi diagrams15, and radiosity6, 17. The addition of true fragment programmability 
has enabled the acceleration of myriad applications, including non-linear diffusion for solving partial 
differential equations28, coupled-map lattices used to simulate boiling13, and matrix multiplication19, 
32. Many of these techniques had to work around or tolerate quirks of the programmable graphics hardware, 
such as limited precision or awkward programming models. Much less awkward programming techniques and 
interfaces are now possible, especially with the introduction of .oatingpoint support in the GeForce 
FX and Radeon 9700 and of NVIDIA s high-level Cg programming language22. There has been little published 
research to date on integrating HDR images with a high-performance rendering pipeline. Cohen et al. 
represented and displayed high dynamic range texture maps (HDRTMs) using graphics hardware5. They .rst 
decompose 16-bit high dynamic range textures into two 8-bit texture maps and then perform dynamic exposure 
adjustment and gamma-correction of HDRTMs using programmable multitexturing. While this technique works 
well, it only uses a direct mapping from a slice of the HDRTM s range to the display, without performing 
any sophisticated tone mapping algorithms. 2.3. Review of Reinhard s Operator We have chosen to implement 
the tone mapping operator of Reinhard et al.27, although other operators could certainly be &#38;#169; 
The Eurographics Association 2003. implemented as well. Reinhard s operator is based loosely on the zone 
system in photography1. First, a global scaling is applied that is analogous to setting an exposure level 
in a camera. Suppose Lw(x, y) is world luminance of each pixel. The log average luminance is then given 
by 1 Lw = expN [log (8 + Lw (x, y))(1) x,y where N is the number of pixels in the image, 8 is a small 
constant used to avoid numerical under.ow when taking the logarithm of black pixels. Lw is then mapped 
to the middlegrey zone by scaling pixel luminance with: a L(x, y)= Lw(x, y) (2)Lw where a is a key value 
indicating whether a given image is subjectively light (high-key), normal, or dark (low-key). A normal-key 
image typically uses a = 0.18, which is the same value used by automatic exposure control in cameras. 
Next, a simple global tone mapping operator is applied, obtaining display luminances Ld (x, y): L(x, 
y) Ld (x, y)= (3) 1 + L(x, y) This simple tone mapping operator appears to be suf.cient to preserve details 
in low contrast areas, and it is guaranteed to bring all luminance within a displayable range of 0 to 
1. However, Reinhard observes that details can be lost in images with very high dynamic range, especially 
in very bright regions. To counteract this effect, he uses a local contrast enhancement technique that 
is similar to photographic dodging and burning . First, the image is convolved with a set of Gaussian 
convolution kernels de.ned at multiple spatial scales, giving a set of responses Vi. Subtracting adjacent 
responses gives an estimate of the local contrast at multiple spatial scales. Reinhard uses a center-surround 
function given by V (x, y, si) - V (x, y, si+1) Activity(x, y, si)= 2 (4) 2<a/si + V (x, y, si) to measure 
local contrast at a given scale si, using a, which is a sharpening parameter controlling edge enhancement 
(set to 8.0 in the paper). Reinhard considers 8 scale levels; the smallest scale s1 = 0.35 and si+1 = 
1.6  si. For each pixel, the center surround function is computed from the lowest scale s1, until the 
.rst scale sm is found which satis.es |Activity(x, y, sm)| > ., where threshold . is set to 0.05 by default. 
Essentially, sm gives the largest area around a given pixel where no sudden contrast changes occur. 
Hence V (x, y, sm) can be used as local area luminance, replacing L(x, y) in the denominator of Equation 
3: L(x, y) Ld (x, y)= (5) 1 + V (x, y, sm) Because of the potential difference between Ld (x, y) and 
182182182  Figure 1: Three images demonstrating different levels of local contrast preservation. The 
left image is compressed with the global transfer function, the middle with four adaptation zones, and 
the right with eight zones. V (x, y, sm), this new operator can retain substantial detail in very bright 
or dark regions. This operator is particularly attractive for hardware implementation for two reasons. 
First, the global transfer function (Equation 3) is both simple to evaluate and highly effective at compressing 
HDR into a viewable range. If we use only the global operator, we can compress an image s dynamic range 
using a small number of rendering passes, simple fragment programs, and without any context switching. 
In addition, Equation 3 involves only one global computation: the log average luminance. Global computations 
are not particularly amenable to graphics hardware. For example, modern GPUs do not provide a mechanism 
for computing the average pixel value in a buffer. In Section 4 we discuss a straightforward reduction 
method that can be used to solve this problem. However, the technique is relatively expensive and so 
we would like to avoid operators that require even more global information about the image. Second, while 
the local dodging and burning technique can be computationally expensive, the process lends itself to 
adaptive re.nement. In other words, we can vary the number of adaptation zones depending on the level 
of detail we wish to preserve. This allows us to trade off ef.ciency and accuracy, which can be crucial 
for interactive applications. This idea is illustrated in Figure 1, which shows three images tone mapped 
using Reinhard et al. s operator. As we increase the number of zones (from left to right) the computation 
time also increases. However, we are able to better preserve the detail in book text. 3. System Overview 
Tone mapping algorithms require no high-level geometric or textural information from the application 
in order to compress the .nal output. We can therefore decouple our tone mapping system from any application 
that wants to use it. 3.1. Library API Our system is implemented in a library that exports a small API 
(shown in Table 1). The API can be used by an application to compress its output prior to display. The 
application tmInit Initializes the tone mapping system and allocates video memory for storing in termediate 
results. tmEnable Marks the start of rendering to be compressed. This function retargets all OpenGL calls 
to the .oating-point buffer allocated by tmInit. tmDisable Turns off the tone mapping system and returns 
the application s rendering con text to the exact OpenGL state that ex isted at the time of tmEnable. 
tmCompress Executes the actual tone mapping algo rithm. The compressed image is held in a buffer local 
to the tone mapping sys tem. tmBind Binds the output buffer of the tone mapping system to a speci.ed 
texture unit. The application can then use that texture to display the result or read the data back for 
further processing or stor age. Table 1: The interface between the application and our tone mapping 
system. The system exports a simple API that allows the application to control when its output is compressed. 
must .rst call tmInit() once during startup to initialize the tone mapping system. During the application 
s display routine, a call to tmEnable() causes all OpenGL calls to be redirected into an off-screen buffer 
in video memory that is local to the tone mapping system. Once all rendering is completed, the application 
uses tmCompress() to invoke the dynamic range compression algorithm. The results of this algorithm are 
placed in another buffer, which can either be bound to a texture unit using the tmBind() function for 
display by the application or sent to the display on behalf of the application by the library itself. 
 3.2. Data Layout In many cases, it is not possible to represent high dynamic range imagery using only 
8-bit color precision. Floatingpoint support is required to store the full range of the image as well 
as to resolve small differences between pixel values. Because many tone mapping algorithms involve multiple 
passes over the image, high precision is also necessary to avoid the visual artifacts of error propagation. 
Fortunately, graphics vendors have recently started to provide .exible pixel buffers (pbuffers) that 
support multiple pixel formats, including .oating-point color representation. Pbuffers can be rendering 
targets as well as texture inputs. Additionally, each pbuffer can have several surfaces, which are exactly 
akin to the front and back surfaces used for double-buffered  Figure 2: A block diagram of our system 
for interactive tone mapping. Circular blocks represent shaders (or groups of shaders) that perform a 
particular part of the algorithm; rectangular blocks represent intermediate data storage. The global 
operator (Equation 3) is implemented using a single buffer (Buffer0) with multiple rendering surfaces. 
The local operator (Equation 5) requires two additional buffers (Buffer1 and Buffer2) to compute the 
Gaussian convolutions. Note that the local operator diagram illustrates one zone calculation (using 
level si and si+1 in the Gaussian pyramid); this process is repeated for subsequent zones until all zones 
have been accumulated (0, ..., i + 1 in the .gure). In general, the arrows represent data .ow as governed 
by the shaders. We only execute the dashed arrow paths (and all paths in Buffers 1 and 2) if we are running 
the local operator. rendering. In our tone mapping system, we store all image data in the surfaces of 
several .oating-point pbuffers. A high-level view of our shaders and the data.ow between them is presented 
in Figure 2. The system is divided into two conceptual components. The .rst uses a single pbuffer to 
store the initial HDR input from the application as well as several intermediate calculations needed 
to compute Reinhard s global transfer function (Equation 3). The second component requires two additional 
pbuffers, which are used to compute Gaussian convolutions and accumulate local adaptation zones for the 
local dodging-and-burning operations. Arrows in the .gure represent render passes, where pixel data 
is manipulated and transferred between buffers. 4. Implementation In this section we describe in detail 
how we compute Equation 3 (the global operator) and Equation 5 (the local operator) in graphics hardware. 
All of our algorithms are implemented using the OpenGL Architecture Review Board (ARB) fragment and 
vertex instruction sets. In the following text we frequently use the term buffer quite generally to 
denote any form of rendering target. These buffers, as described in the previous section, can be composed 
of multiple 4-channel surfaces. In many cases, implementation of the algorithms will require rendering 
back and forth among these surfaces to avoid reading from and writing to the same block &#38;#169; The 
Eurographics Association 2003. of memory, but we omit these details in our explanation of the algorithms. 
 4.1. Global Operator The global operator (Equation 3) is a monotonic, per-pixel transfer function that 
maps world luminance to display luminance. It is therefore quite simple to implement on the GPU, requiring 
only a few render passes. This is illustrated in the left half of Figure 2. Starting with the output 
from the application, we transform into the luminance domain. In the same pass, we compute the log luminance 
for every pixel, storing the luminance in one output channel and the log luminance in another. Unfortunately, 
computing the global average of the log luminance values requires a multi-pass approach in current 
hardware, which lacks any sort of global accumulator. The most straightforward approach is to perform 
repeated downsamplings, averaging four neighboring values down to one in each pass with a fragment shader; 
this is exactly equivalent to building a mipmap for traditional textures and is the approach also used 
by Krger et al.18. With this method, the log(n)th pass (where n is width of the image) results in a 
single value which is the log average luminance. This value is then read back into system memory and 
bound as a parameter to the fragment processor. In a .nal render pass, we access the world luminance 
Lw at each pixel (as calculated in the .rst pass), scale it according to Equation 2, and then convert 
it to display luminance Ld accord184184184  Figure 3: A block diagram illustrating how we perform 
Gaussian convolutions on the GPU. We store each 4-vector element of a 1  n .lter kernel in system memory 
and bind the values as parameters to the fragment pipeline. Likewise, we compress the image (scalar luminance) 
into a 4-channel texture map (shown in the bottom right). In this .gure, the register used to store each 
element of the kernel is labeled c0. We bind the source image to texture unit 0 and accumulate previous 
results from texture unit 1. Arrows that correspond to the same render pass share the same drawing pattern. 
ing to Equation 3. To recover the compressed RGB display value, we scale the display luminance according 
to: ()\()\()\ Rw Gw Bw Rd = Ld , Gd = Ld , Bd = Ld (6) Lw Lw Lw where e controls the saturation of the 
recovery; typical values of e are 0.4.0.8.   4.2. Local Operator Reinhard s local tone mapping operator 
(Equation 5) preserves detail by adding a local-area luminance term to Equation 3. In order to evaluate 
the center-surround function (Equation 4) used to determine local adaptation, we must .rst perform a 
series of Gaussian convolutions on the GPU. For large images or large kernels, it would be more ef.cient 
to perform this calculation in frequency space, where the convolutions can be replaced with a per-pixel 
multiplication, but this would require an implementation of FFT in hardware, and such a method has only 
recently been developed; see Moreland and Angel23 for details. The OpenGL image subset extension provides 
methods for performing separable convolutions in the frame buffer31 as an alternative, but support for 
this extension is missing on our target platform. We therefore found it necessary to implement an algorithm 
for performing arbitrary-sized convolutions on the GPU. For example, given a 1  n .lter kernel, we can 
express convolution at a point as a sum of 4-vector products. Since most GPU assembly languages provide 
a highly optimized 4-vector dot product instruction, we can perform convolutions ef.ciently by transforming 
a scalar-valued image into an array of 4-vectors. We start by binding four offsets as parameters to 
the vertex processor. These offsets correspond to the position of the .lter kernel relative to the image. 
For example, in each dimension we de.ne offsets that start at -n/2 and ultimately span the interval 
-n/2 to n/2. We then rasterize an image-sized quad to generate fragments. The offsets are used by the 
rasterizer to generate four sets of texture coordinates for every pixel in the source image, each corresponding 
to an adjacent pixel. We load those four adjacent pixel values into a single 4-vector .oating-point register. 
By storing part of the .lter kernel in another register we can compute a portion of the convolution with 
a simple dot product. In the next render pass, we repeat this process using the next 4-vector element 
of the kernel and corresponding vertex offsets, accumulating the results of each of these passes as 
we go along. The entire process is illustrated in Figure 3, which shows the three render passes required 
to convolve with a 1  11 Gaussian kernel. The process is identical for arbitrary-sized .lters; for symmetry, 
we pad each kernel with zeros until it is a multiple of four. Using the method just described, we can 
.lter an image with an n  n separable kernel in n/2 + 2 render passes. We found that in some cases, 
however, it is more ef.cient to compute multiple 4-vector products per render pass. This approach reduces 
the number of passes required to compute a convolution, thus reducing any overhead associated with binding 
new shaders, parameters, or textures. As an example, consider a 49  49 Gaussian kernel. Using the method 
above, it would take 26 passes to convolve this kernel with any size image. By exploiting the rasterizer 
s capability of generating multiple texture coordinates per fragment and binding multiple 4-vector components 
of the kernel as fragment pipeline parameters, we can perform three dot products per pass instead of 
the single one described above. This reduces the total number of passes by more than half. Note, however, 
that the speedup in practice is only about 25%; we have not fundamentally reduced the number of computations 
required or the amount of memory accessed. We also experimented with storing several kernels in a single 
2D RGBA .oating-point texture rather than in system memory. In this context, we can use the texture coordinate 
in one dimension to choose the appropriate kernel, while using the other dimension to access speci.c 
4-vector elements of the kernel. While this eliminates the need to repeatedly transfer the kernel from 
system memory to GPU registers, it requires that we perform an extra texture lookup in the fragment 
program. This additional texture memory access actually caused the algorithm to run slower, suggesting 
that the system is memory-bandwidth limited. Further optimizations would therefore require that we reduce 
texture memory accesses in some way, perhaps by combining reads in a method similar to the one used 
by Bolz et al.3. We discuss this further in Section 6.1. While performing any kind of convolution, it 
is important to properly deal with boundary conditions. In our current implementation, we use the common 
approach of replicating boundary pixels for all data access that falls outside the bounds of the image. 
In graphics hardware, all access to the image domain is through normalized (0 to 1) texture coordinates. 
We replicate boundary pixels by setting the GL_TEXTURE_WRAP parameter to GL_CLAMP_TO_EDGE, which guarantees 
that all texture coordinates outside the normal range return boundary values for a given texture. 4.3. 
Calculating adaptation zones on the GPU With a GPU-based method for performing large kernel convolutions, 
we can easily compute V (x, y, si) for any level si in a Gaussian pyramid. We could start by pre-allocating 
the entire pyramid s0, s1, ..., si, storing each level in a separate buffer, but this could result in 
the use of large amounts of video memory, especially if the image is screen-size. All that is necessary 
to determine a pixel s zone is the difference between neighboring levels in the pyramid, so we can perform 
all .ltering computation using just two buffers. In addition to being memory-ef.cient, this approach 
makes it easy to dynamically decide how many zones to calculate without having to transfer pixel data 
among several rendering contexts. Although we can compute all the adaptation zones using a single pass 
given suf.cient hardware resources, this requires extensive use of conditionals in the fragment shader. 
We would need to evaluate the center-surround function at every resolution in the Gaussian pyramid, 
using conditionals at each level. Because fragment programs execute in lock-step on a SIMD architecture, 
conditionals are very expensive; all execution paths are evaluated on all fragments. Furthermore, such 
a fragment shader would have to have simultaneous access to all levels in the Gaussian pyramid, meaning 
we would have to precompute every .ltered image and bind them as input textures before calculating zones. 
In order to avoid these complications, we build the adaptation zone map in multiple passes using a cumulative 
process. In a given render pass, we mark all pixels corresponding to a single zone. This process involves 
four buffers: two buffers used to store adjacent levels in the Gaussian pyramid and two buffers for accumulating 
adaptation zones. For example, if we have already calculated zone i, we can calculate zone i + 1 using 
the following steps: 1. Filter the scaled luminance according to level si+2 in the Gaussian pyramid. 
 2. Set the zone buffer used to store zones 0, ..., i - 1 as the render target. 3. Bind Gaussian pyramid 
level si+1 (.ltered in the previous pass) and si+2 as well as the remaining zone buffer as input textures. 
 4. Render an image-sized quad with the zone computation fragment shader activated.  &#38;#169; The 
Eurographics Association 2003. Figure 4: An illustration of how we accumulate adaptation zones in graphics 
hardware. We use two buffers to store adjacent levels in a Gaussian pyramid, which is labeled s0 through 
s3. The zone information is accumulated using another two buffers which we use as alternating render 
targets. The arrows in the .gure are drawn with different patterns to distinguish each render pass. Arrows 
entering the shader block represent input textures for that particular pass. The shader we use to calculate 
zones is a straightforward implementation of a center-surround threshold. For every pixel where |Activity(x, 
y, si)| > ., we output the luminance from level si to the target buffer. A texture lookup on the input 
zone buffer allows us to determine whether each pixel has already been assigned a zone; those that have 
are copied through to the target buffer. Pixels for which no zone has previously been selected and which 
are not chosen for the current zone by the above inequality are left unmodi.ed and empty in the target 
buffer using the fragment kill operation of the graphics hardware. This process is illustrated in Figure 
5 for the calculation of three zones using a total of four levels in the Gaussian pyramid. Figure 5 shows 
false-color visualizations of a zone map; one image is computed using our software implementation of 
Reinhard s local operator (Equation 5), and the other is computed in hardware. A total of eight zones 
is shown; darker region represent larger discontinuities in the luminance. The images are nearly identical; 
the small disparity is due to .oating-point imprecision on the GPU (see Section 5.2 for an error analysis). 
 4.4. Time-Dependent Model Interactive applications can often suffer from large temporal discontinuities 
in dynamic range (when, for example, a light source comes into view). We would like our tone mapping 
algorithm to smooth those discontinuities over time in order to create a more natural and plausible-looking 
animation. To do this, we have incorporated a model of time-dependent adaptation proposed by Durand and 
Dorsey9. The details of 186186186  Figure 5: False-color visualizations of the adaptation zones map 
as generated using Reinhard s local operator (Equation 5). Each of the eight zone values is normalized 
between 0 and 1, where darker regions represent lower levels in the Gaussian pyramid. We use 0.05 for 
the activity threshold. The image on the left is generated in software, and the image on the right is 
from our GPU implementation. The two images are nearly identical; differences arise due to the GPUs 
limited .oating-point precision. this model can be found in their paper; we summarize the key points 
below. This model simulates both multiplicative and subtractive light adaptation by applying a global 
multiplicative scale factor m during the mapping from world luminance Lw to display luminance Ld (Ld 
= mLw). When the dynamic range changes suddenly, sensitivity recovery is simulated by ; m-m changing 
m with an exponential .lter: dm = , where dt ; m* is the unmodi.ed scale factor that would be used without 
time-dependent adaptation, and d is a parameter controlling how fast the viewer will adapt to changes 
in light intensity. To use this model in our GPU-based system, we apply the exponential .lter to the 
log average luminance (Lw) for each frame. Recall that Reinhard s operator .rst scales world lu a minance 
by (see Equation 2), mapping the overall bright- Lw ness of the image to a subjective key value a for 
display. Modulating the log average luminance by the exponential .lter is therefore equivalent to controlling 
the gain m in Du- L; w rand s case. We therefore use dLw = -Lw to simulate light dt ; adaptation, where 
L*w is the target log average luminance. Although this is a simple model of adaptation and is not physically 
based (Durand and Dorsey give more involved models that more closely mimic the human eye), it produces 
qualitatively reasonable results. Our experience has been that the presence of a time adaptation model 
is much more important than the details of the model itself, since the visual content often changes much 
more quickly than the dynamic range. 5. Results All of our experiments have been conducted using the 
ATI Radeon 9800 Pro graphics card. This architecture supports medium-precision (24-bit) .oating-point 
computations and texture maps. All example images and timing reports were recorded on a dual-processor 
AMD Athlon 1800+ MP system with 512MB of memory running Windows XP. To test our implementation, we developed 
an OpenGL application that uses high dynamic range textures. The application .rst creates a window 
of the same size as the HDR image to be compressed. The application then renders a fullwindow quad that 
is textured with the HDR image. Without tone mapping, the output is clamped to the range of 0 to 1. Our 
application allows the user to pan a tone map window over the image to run our algorithm on a subset 
of the full HDR image. This allows us to test our time-dependent model easily by panning between dark 
and bright regions. Our algorithms are invoked simply by drawing the tone map window quad with our pixel 
shaders. Figure 6 shows a screenshot of this test application. The background image is a direct output 
to the application s frame buffer; the smaller viewport shows the tone mapped portion of the image. 
5.1. Performance In this section we discuss the performance of our GPU-based tone mapping system. The 
graph in Figure 7 gives frame  256x256 (GPU) 256x256 (CPU) 512x256 (GPU) 512x256 (CPU) 512x512 (GPU) 
512x512 (CPU) 1000 100 10 1 0.1 Figure 7: A log graph of frame rate achieved by our system compared 
to frame rate of a CPU implementation of the same algorithms. The curves show data for three different 
image resolutions and zones ranging from zero to eight. For the 256  256 case, we can maintain >20 fps 
in all cases. However, for 512  512 the frame rate is not quite interactive for a large number of zones. 
rates achieved by our system as well as frame rates for the same algorithms implemented in software. 
We should note that our CPU implementation is by no means highly optimized, but it is reasonably ef.cient. 
As with the GPU, we build the Gaussian pyramid using spatial convolutions instead of more ef.cient frequency 
space techniques (as used by Reinhard et al.). In addition to this we use a relatively expensive recovery 
function (Equation 6). However, the two implementations are consistent with regard to complexity. In 
the case of the global operator (zero zones), we are able to achieve extremely high frame rates for all 
of the listed image resolutions. This is not really surprising considering the simplicity of the transfer 
function. In fact, we found that for the global operator a substantial portion of the computation is 
spent building the mipmap. For example, disabling this step resulted in roughly a 60% speedup in some 
cases. However, as the number of zones increases, adding local adaptations, the Gaussian convolutions 
quickly become the bottleneck. To compute eight zones we must convolve with .lter kernels ranging from 
3  3 pixels to 49  49 pixels. Even with an ef.cient GPU-based convolution algorithm, such large kernels 
prevent us from maintaining real-time frame rates on today s hardware. With eight adaptation zones, our 
system runs at around 5 Hz for a 512 512 image and 20 Hz at 256  256. While 5 frames per second is 
not interactive, it does showcase the sheer computational power of the fragment hardware, and real-time 
frame rates (>30 Hz) are easily achievable if we limit ourselves to smaller image resolutions or a 
smaller number of zones. A gallery of results Frames Per Second &#38;#169; The Eurographics Association 
2003. at 512  512 generated at roughly 30 Hz each is shown in Plate 1. The given frame rates are calculated 
from the time taken to run the tone mapping algorithm in hardware. The overall frame rate would obviously 
be lower when we factor in the time taken by the application itself. The sudden falloff in frame rate 
when we move from the global operator to the local one is simply due to additional overhead incurred 
in the local case (signi.cantly more memory reads and writes must occur to prepare for the zone calculations). 
  5.2. Accuracy Tone mapping algorithms can be quite susceptible to numeric imprecision, and this 
is especially true for local operators because of their computational complexity. For example, without 
suf.cient precision when evaluating the centersurround function, it is possible that some pixels will 
be assigned incorrect adaptation zones. This can introduce unpleasant visual artifacts such as halos 
in the compressed image. Because local operators tend to require signi.cantly more computation that 
global operators, any shortcomings in precision can bring about compounded error. In order to avoid these 
problems, software implementations of tone mapping algorithms typically store data and perform all calculations 
using IEEE (32-bit) single-precision .oats. However, our target GPU architecture, ATI s Radeon 9800, 
only supports 24-bit .oating-point computations. In an effort to quantify the effects of this limited 
precision, we have run a series of experiments comparing output from the GPU to a software implementation 
of the same algorithm. To compare the results, we evaluate Root Mean Squared (RMS) percent error between 
the CPU and GPU implementations as: 1 pcpu(x, y) - pgpu(x, y) 2 errorRMS % =[(7) n x,ypcpu(x, y) where 
n is the number of pixels in the image and p(x, y) is the pixel value. We also evaluate the mean percent 
error as: 1 pcpu(x, y) - pgpu(x, y) errorMean% = [(8) n x,ypcpu(x, y) Table 2 gives error calculations 
for images resulting from several stages in the algorithm. The scaled luminance error takes into account 
all numeric inaccuracies accumulated by the repeated averaging technique as well as the transform to 
luminance space. Given the simplicity of these computations, we would expect this error to be small, 
and our experiments veri.ed that this is in fact the case. The convolution examples show the effects 
of 24-bit .oating-point precision over the course of many rendering passes. Naturally, the image that 
was .ltered with the larger kernel contains more error. The local area luminance image has a much higher 
percent error than the previous examples. This is due to the fact that even small errors 188188188 
 Image (computation) RMS % error mean % error Scaled luminance Convolution (5  5) Convolution (49  
49) Local area luminance Final image 0.022 % 0.026 % 0.032 % 4.552 % 1.051 % 0.022 % 0.026 % 0.032 % 
0.764 % 0.177 % Table 2: RMS percent error and mean percent error for different stages in our GPU implementation 
of Reinhard et al s local tone mapping operator. These values are calculated by treating the output from 
our CPU implementation as the accepted value. The relatively large RMS percent error for the local area 
luminance image can be attributed to slight variation in the number of pixels in each zone. in the threshold 
comparison can cause slight variations in the boundaries between zones. In other words, if the width 
of the Gaussian kernel increases signi.cantly between levels in the pyramid (as it does in this algorithm), 
small .nite difference errors can result in large errors in the local area luminance image. Fortunately, 
we have found that the visual impact of this is more or less negligible, and the error in the .nal tone 
mapped image is signi.cantly smaller. 6. Discussion We have shown that the graphics pipeline has suf.ciently 
evolved to support sophisticated tone mapping algorithms and compress images at interactive rates. This 
is not a panacea, however. Many questions remain, including when interactive tone mapping is most effective, 
and which tone mapping algorithms are best suited to interactive applications. 6.1. Optimizations A 
troublesome aspect of GPU programming is that it requires exceedingly careful optimization in order 
to extract the performance we would expect. A number of factors contribute to this problem, such as 
memory bandwidth, driver overhead (especially context-switching overhead), etc. Approaches to these 
problems have been explored at length in several recent papers, including Bolz et al.3 and Goodnight 
et al.11. Of particular note is a caveat to the use of pbuffers, which is that they cannot share a rendering 
context with the application. Context switching can become a serious bottleneck for an algorithm that 
must transfer data among a large number of buffers. We have minimized context switching by allocating 
pbuffers with multiple rendering surfaces (GL_FRONT, GL_BACK, GL_AUXi, etc.), all of which share the 
same rendering context. While we have been able to implement large portions of our tone mapping algorithm 
using only a small number of buffers for data storage, some amount of context switching is unavoidable. 
The remaining major bottleneck is certainly memory bandwidth, as we would expect in these types of algorithms. 
Memory accesses can be reduced somewhat by more tightly packing the data3, a technique that works well 
for a number of general-purpose GPU algorithms. In the case of interactive tone mapping, however, this 
data packing step (and the associated unpacking afterward) would have to occur once per frame, making 
it unclear that such a technique would give a signi.cant speedup. 6.2. The Effect of Varying Frame Rate 
on Our Time-Dependent Model Obviously, we only have an opportunity to apply our tone mapping algorithm 
once per frame. When we apply the exponential .lter described in Section 4.4, we need an estimate of 
the elapsed time At in order to determine how much to change the gain m. If the frame rate is very high, 
then At is low and m changes smoothly over time, giving a very convincing impression of adaptation. 
If, however, the application s frame rate is low, then using elapsed wall-clock time in our time-dependent 
model gives rise to large luminous discontinuities. Although applications with low frame rates tend to 
have large spatial discontinuities which severely detract from the user experience, compounding that 
problem with visual adaptation discontinuities seems to make the experience quite unpleasant. It is therefore 
advisable to establish some maximum estimate of elapsed time when applying a time-dependent model. If 
the frame rate drops below some threshold, the estimated elapsed time will then remain .xed. This has 
the effect of slowing down the adaptation with respect to wallclock time, but the effect appears much 
less upsetting to the user. Other heuristics such as boosting the value of d if the frame rate gets too 
low might be fruitful as well, but the key is to avoid severe adaptation discontinuities. 7. Conclusion 
and Future Work We have described our implementation of a state-of-theart tone mapping algorithm using 
programmable graphics hardware. Our time-dependent version of Reinhard s photographic tone reproduction 
algorithm achieves high refresh rates. In addition, our ability to add a time-dependent term to the tone 
mapping algorithm makes it quite suitable for interactive simulation. There are a number of directions 
for future work. First, we would like to implement our algorithm as a noninvasive add-on for unmodi.ed 
OpenGL applications using the Chromium framework14. It should be straightforward to allow an unmodi.ed 
application to render directly into a .oating-point texture, and we can then apply our algorithm whenever 
the application swaps buffers. This would allow anyone to experiment with the use of high dynamic range 
textures in an interactive application. We could thus allow existing games like Id Software s Quake III: 
Arena to use special .oating-point texture maps to draw very bright regions such as explosions or the 
sun. In addition, our OpenGL replacement could enable a vertex program to compute a standard OpenGL lighting 
model without clamping, allowing an ordinary OpenGL program to bene.t from HDR rendering without requiring 
selective texture replacement. Because the tone mapping algorithms require no high-level information 
from the application, any application could immediately bene.t from a real-time tone adaptation model. 
 Second, it would be useful to design an extended API so that HDR-aware applications could control the 
tone mapping subsystem. For example, the API could allow users to control tone mapping parameters such 
as the key level a and threshold . in Reinhard s algorithm. Applications might also desire to damp the 
HDR compression level near the extremes of the dynamic range to let more or less of the image wash out. 
More generally, we would like to explore the extent to which rapid interactive change affects the perceptual 
utility of precise tone mapping. Providing a feedback mechanism for the application to control performance 
by specifying how aggressively to preserve detail would be would be necessary to conduct such experiments. 
Acknowledgments We would like to thank Mark Segal and James Percy at ATI and David Kirk, Pat Brown, Matt 
Papakipos, Nick Triantos, and Matt Pharr at NVIDIA for providing early cards and excellent driver support; 
Mark Harris, Aaron Lefohn, and Ian Buck for productive discussions on general-purpose GPU computation; 
and the anonymous reviewers for their thorough and constructive comments. References 1. Ansel Adams. 
The Print. Little, Brown and Company, 1983. 2. ATI. Radeon 9700 Pro, 2002. http://mirror. ati.com/products/pc/radeon9700pro/. 
 3. Jeff Bolz, Ian Farmer, Eitan Grinspun, and Peter Schrder. Sparse matrix solvers on the GPU: Conjugate 
gradients and multigrid. ACM Transactions on Graphics, 22(3), July 2003. 4. Ken Chiu, Michael Herf, 
Peter Shirley, S. Swamy, Changyaw Wang, and Kurt Zimmerman. Spatially nonuniform scaling functions for 
high contrast images. In Proceedings of Graphics Interface 1993, pages 245 253, May 1993. 5. Jonathan 
Cohen, Chris Tchou, Tim Hawkens, and Paul  &#38;#169; The Eurographics Association 2003. Debevec. Real-time 
high-dynamic range texture mapping. In Proceedings of Eurographics Workshop on Rendering, pages 313 
320, June 2001. 6. Michael F. Cohen, Donald P. Greenberg, David S. Immel, and Philip J. Brock. An progressive 
re.nement approach to fast radiosity image generation. In Proceedings of SIGGRAPH 1988, pages 75 84, 
August 1988. 7. Paul Debevec and Jitendra Malik. Recovering high dynamic range radiance maps from photographs. 
In Proceedings of SIGGRAPH 1997, pages 369 378, August 1997. 8. Kate Devlin, Alan Chalmers, Alexander 
Wilkie, and Werner Purgathofer. STAR: Tone reproduction and physically based spectral rendering. In Proceedings 
of Eurographics 2002, pages 101 123, September 2002. 9. Frdo Durand and Julie Dorsey. Interactive tone 
mapping. In Eurographics Workshop on Rendering, pages 219 230, June 2000. 10. Raanan Fattal, Dani Lischinski, 
and Michael Werman. Gradient domain high dynamic range compression. ACM Transactions on Graphics, 21(3):249 
256, July 2002. 11. Nolan Goodnight, Cliff Woolley, Gregory Lewin, David Luebke, and Greg Humphreys. 
A multigrid solver for boundary value problems using programmable graphics hardware. In Proceedings 
of SIGGRAPH/Eurographics Workshop on Graphics Hardware, July 2003. 12. Mark Harris. GPGPU: General-purpose 
computation using graphics hardware, 2003. http://www.cs. unc.edu/~harrism/gpgpu. 13. Mark J. Harris, 
Greg Coombe, Thorsten Scheuermann, and Anselmo Lastra. Physically-based visual simulation on graphics 
hardware. In Proceedings of SIGGRAPH/Eurographics Workshop on Graphics Hardware, pages 109 118, August 
2002. 14. Greg Humphreys, Mike Houston, Ren Ng, Sean Ahern, Randall Frank, Peter Kirchner, and James 
T. Klosowski. Chromium: A stream processing framework for interactive graphics on clusters of workstations. 
ACM Transactions on Graphics, 21(3):693 702, July 2002. 15. Kenneth E. Hoff III, John Keyser, Ming C. 
Lin, Dinesh Manocha, and Tim Culver. Fast computation of generalized Voronoi diagrams using graphics 
hardware. In Proceedings of SIGGRAPH 1999, pages 277 286, August 1999. 16. Daniel J. Jobson, Zia ur 
Rahman, and Glenn A. Woodell. A multiscale retinex for bridging the gap between color images and the 
human observation of scenes. 190190190  IEEE Transactions on Image Processing, 6(7):965 976, July 1997. 
17. Alexander Keller. Instant radiosity. In Proceedings of SIGGRAPH 1997, pages 49 56, August 1997. 
18. Jens Krger and Rdiger Westermann. Linear algebra operators for GPU implementation of numerical 
algorithms. ACM Transactions on Graphics, 22(3), July 2003. 19. E. Scott Larsen and David K. McAllister. 
Fast matrix multiplies using graphics hardware. In Proceedings of IEEE Supercomputing 2001, November 
2001. 20. Greg Ward Larson, Holly Rushmeier, and Chistine Piatko. A visibility matching tone reproduction 
operator for high dynamic range scenes. IEEE Transactions on Visualization and Computer Graphics, 3(4):291 
306, October-December 1997. 21. Jed Lengyel, Mark Reichert, Bruce R. Donald, and Donald P. Greenberg. 
Real-time robot motion planning using rasterizing computer graphics. In Proceedings of SIGGRAPH 1990, 
pages 327 335, July 1990. 22. William R. Mark, Steve Glanville, and Kurt Akeley. Cg: A system for programming 
graphics hardware in a Clike language. ACM Transactions on Graphics, August 2003. 23. Kenneth Moreland 
and Edward Angel. The FFT on a GPU. In Proceedings of Graphics Hardware 2003, July 2003. 24. NVIDIA. 
GeForceFX, 2003. http://www. nvidia.com/view.asp?PAGE=fx_desktop. 25. Sumanta N. Pattanaik, James A. 
Ferwerda, Mark D. Fairchild, and Donald P. Greenberg. A multiscale model of adaptation and spatial vision 
for realistic image display. In Proceedings of SIGGRAPH 1998, pages 287 298, July 1998. 26. Tim Purcell, 
Ian Buck, William Mark, and Pat Hanrahan. Ray tracing on programmable graphics hardware. ACM Transactions 
on Graphics, 21(3):703 712, July 2002. 27. Erik Reinhard, Michael Stark, Peter Shirley, and Jim Ferwerda. 
Photographic tone reproduction for digital images. ACM Transactions on Graphics, 21(3):267 276, July 
2002. 28. Martin Rumpf and Robert Strzodka. Nonlinear diffusion in graphics hardware. In Proceedings 
of Eurographics/IEEE TCVG Symposium on Visualization, pages 75 84, May 2001. 29. Annette Scheel, Marc 
Stamminger, and Hans-Peter Seidel. Tone reproduction for interactive walkthroughs. Computer Graphics 
Forum, 19(3):301 312, August 2000.  30. Christophe Schlick. Quantization techniques for visualization 
of high dynamic range pictures. In Proceedings of Eurographics Workshop on Rendering, pages 7 20, June 
1994. 31. Mark Segal and Kurt Akeley. The OpenGL Graphics System: A Speci.cation (Version 1.2.1). 1999. 
ftp: //ftp.sgi.com/opengl/doc/opengl1.2/. 32. Chris J. Thompson, Sahngyun Hahn, and Mark Oskin. Using 
modern graphics architectures for generalpurpose computing: A framework and analysis. In Proceedings 
of IEEE/ACM International Symposium on Microarchitecture, pages 306 317, November 2002. 33. Jack Tumblin, 
Jessica K. Hodgins, and Brian K. Guenter. Two methods for display of high contrast images. ACM Transactions 
on Graphics, 18(1):56 94, January 1999. 34. Jack Tumblin and Holly E. Rushmeier. Tone reproduction 
for realistic images. IEEE Computer Graphics and Applications, 13(6):42 48, November 1993. 35. Jack 
Tumblin and Greg Turk. LCIS: A boundary hierarchy for detail-preserving contrast reduction. In Proceedings 
of SIGGRAPH 1999, pages 83 90, August 1999. 36. Greg Ward. A Contrast-based Scalefactor for Luminance 
Display. In Graphics Gems IV, chapter VII.2, pages 415 421. Academic Press, 1994.   4:1 53:1 56:1 
140:1 621:1 905:1 Plate 1: A series of 512  512 HDR images that have been tone mapped on the GPU using 
Equation 5. Underneath each image is the compression ratio achieved by our algorithm using two adaptation 
zones. All images were generated at nearly 30 Hz. 192192192 &#38;#169; The Eurographics Association 
2003.   
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198784</article_id>
		<sort_key>193</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[A multigrid solver for boundary value problems using programmable graphics hardware]]></title>
		<page_from>193</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198784</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198784</url>
		<abstract>
			<par><![CDATA[We present a case study in the application of graphics hardware to general-purpose numeric computing. Specifically, we describe a system, built on programmable graphics hardware, able to solve a variety of partial differential equations with complex boundary conditions. Many areas of graphics, simulation, and computational science require efficient techniques for solving such equations. Our system implements the <b>multigrid method</b>, a fast and popular approach to solving large boundary value problems. We demonstrate the viability of this technique by using it to accelerate three applications: simulation of heat transfer, modeling of fluid mechanics, and tone mapping of high dynamic range images. We analyze the performance of our solver and discuss several issues, including techniques for improving the computational efficiency of iterative grid-based computations for the GPU.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.1.8</cat_node>
				<descriptor>Multigrid and multilevel methods</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.8</cat_node>
				<descriptor>Elliptic equations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Graphics processors</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010389</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics processors</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003727.10003729</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Differential equations->Partial differential equations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003727.10003729</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Differential equations->Partial differential equations</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P575232</person_id>
				<author_profile_id><![CDATA[81100024446]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nolan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Goodnight]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Virginia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24011637</person_id>
				<author_profile_id><![CDATA[81100188094]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Cliff]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Woolley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Virginia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P575225</person_id>
				<author_profile_id><![CDATA[81100315743]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Gregory]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lewin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Virginia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14056692</person_id>
				<author_profile_id><![CDATA[81100131290]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Luebke]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Virginia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39038311</person_id>
				<author_profile_id><![CDATA[81100337084]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Greg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Humphreys]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Virginia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>882364</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Jeff Bolz, Ian Farmer, Eitan Grinspun, and Peter Schr&#246;der. Sparse matrix solvers on the GPU: Conjugate gradients and multigrid. ACM Transactions on Graphics, 22(3), July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347185</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[W. L. Briggs, V. E. Henson, and S. F. McCormick. A Multigrid Tutorial. Society for Industrial and Applied Mathematics, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569052</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Nathan Carr, Jesse Hall, and John Hart. The Ray Engine. In Proceedings of SIGGRAPH/Eurographics Workshop on Graphics Hardware, September 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258884</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Paul Debevec and Jitendra Malik. Recovering high dynamic range radiance maps from photographs. In Proceedings of SIGGRAPH 1997, pages 369--378, August 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566573</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Raanan Fattal, Dani Lischinski, and Michael Werman. Gradient domain high dynamic range compression. ACM Transactions on Graphics, 21(3):249--256, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Mark Harris. Flo: A real-time fluid flow simulator written in Cg, 2003. http://www.cs.unc.edu/~harrism/gdc2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Mark Harris. GPGPU: General-purpose computation using graphics hardware, 2003. http://www.cs.unc.edu/~harrism/gpgpu.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569061</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Mark J. Harris, Greg Coombe, Thorsten Scheuermann, and Anselmo Lastra. Physically-based visual simulation on graphics hardware. In Proceedings of SIGGRAPH/Eurographics Workshop on Graphics Hardware, pages 109--118, August 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311567</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Kenneth E. Hoff III, John Keyser, Ming C. Lin, Dinesh Manocha, and Tim Culver. Fast computation of generalized Voronoi diagrams using graphics hardware. In Proceedings of SIGGRAPH 1999, pages 277--286, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Greg James and Mark Harris. Simulation and animation using hardware-accelerated procedural textures. In Proceedings of the 2003 Game Developers Conference. CMP Media, March 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882363</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Jens Kr&#252;ger and R&#252;diger Westermann. Linear algebra operators for GPU implementation of numerical algorithms. ACM Transactions on Graphics, 22(3), July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>582089</ref_obj_id>
				<ref_obj_pid>582034</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[E. Scott Larsen and David K. McAllister. Fast matrix multiplies using graphics hardware. In Proceedings of IEEE Supercomputing 2001, November 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Gregory C. Lewin and Hossein Haj-Hariri. Modeling thrust generation of a two-dimensional heaving airfoil in a viscous flow. Journal of Fluid Mechanics, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882362</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[William R. Mark, Steve Glanville, and Kurt Akeley. Cg: A system for programming graphics hardware in a C-like language. ACM Transactions on Graphics, August 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[NVIDIA. OpenGL Extension Specifications, 2002. http://developer.nvidia.com/view.asp?IO=nvidia_opengl_specs.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[NVIDIA. GeForceFX, 2003. http://www.nvidia.com/view.asp?PAGE=fx_desktop.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344976</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Mark Peercy, Marc Olano, John Airey, and Jeffrey Ungar. Interactive multi-pass programmable shading. In Proceedings of SIGGRAPH 2000, pages 425--432, August 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>148286</ref_obj_id>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[William H. Press, Saul A. Teukolsky, William T. Vetterling, and Brian P. Flannery. Numerical Recipes in C: The Art of Scientific Computing. Cambridge University Press, second edition, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383275</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Kekoa Proudfoot, William Mark, Svetoslav Tzvetkov, and Pat Hanrahan. A real time procedural shading system for programmable graphics hardware. In Proceedings of SIGGRAPH 2001, pages 159--170, August 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566640</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Tim Purcell, Ian Buck, William Mark, and Pat Hanrahan. Ray tracing on programmable graphics hardware. ACM Transactions on Graphics, 21(3):703--712, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2384121</ref_obj_id>
				<ref_obj_pid>2384110</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Martin Rumpf and Robert Strzodka. Nonlinear diffusion in graphics hardware. In Proceedings of Eurographics/IEEE TCVG Symposium on Visualization, pages 75--84, May 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311548</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Jos Stam. Stable fluids. In Proceedings of SIGGRAPH 1999, pages 121--128, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>774894</ref_obj_id>
				<ref_obj_pid>774861</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Chris J. Thompson, Sahngyun Hahn, and Mark Oskin. Using modern graphics architectures for general-purpose computing: A framework and analysis. In Proceedings of IEEE/ACM International Symposium on Microarchitecture, pages 306--317, November 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Graphics Hardware 2003, pp. 1 11 M. Doggett, W. Heidrich, W. Mark, A. Schilling (Editors) A Multigrid 
Solver for Boundary Value Problems Using Programmable Graphics Hardware Nolan Goodnight1, Cliff Woolley1, 
Gregory Lewin2, David Luebke1, and Greg Humphreys1 1Department of Computer Science, 2Department of Mechanical 
&#38; Aerospace Engineering, University of Virginia Abstract We present a case study in the application 
of graphics hardware to general-purpose numeric computing. Speci.cally, we describe a system, built 
on programmable graphics hardware, able to solve a variety of partial differential equations with complex 
boundary conditions. Many areas of graphics, simulation, and computational science require ef.cient 
techniques for solving such equations. Our system implements the multigrid method, a fast and popular 
approach to solving large boundary value problems. We demonstrate the viability of this technique by 
using it to accelerate three applications: simulation of heat transfer, modeling of .uid mechanics, 
and tone mapping of high dynamic range images. We analyze the performance of our solver and discuss several 
issues, including techniques for improving the computational ef.ciency of iterative grid-based computations 
for the GPU. Categories and Subject Descriptors (according to ACM CCS): G.1.8 [Numerical Analysis]: Partial 
Differential Equations Multigrid and multilevel methods G.1.8 [Numerical Analysis]: Partial Differential 
Equations Elliptic equations I.3.1 [Computer Graphics]: Hardware Architecture Graphics Processors 1. 
Introduction The graphics processing unit (GPU) on today s commodity video cards has evolved into an 
extremely powerful and .exible processor. GPUs provide tremendous memory bandwidth and computational 
horsepower, with fully programmable vertex and fragment processing units that support short vector operations 
up to full IEEE single precision16. In addition, high level languages have emerged to support the new 
programmability of the vertex and fragment pipelines14, 19. Purcell et al.20 show that the modern GPU 
can be thought of as a general stream processor, and can therefore perform any computation that can be 
mapped to the stream-computing model. We present a case study on mapping general numeric computation 
to modern graphics hardware. In particular, we have used programmable graphics hardware to implement 
a solver for boundary value problems based on the multigrid method2. This approach enables acceleration 
of a whole set of real-world scienti.c and engineering problems and makes few assumptions about the governing 
equations or the structure of the solution domain. &#38;#169; The Eurographics Association 2003. 2. 
Background Here we brie.y review the multigrid method for solving boundary value problems (BVPs), as 
well as the relevant features of modern graphics architectures. 2.1. Boundary value problems and the 
multigrid algorithm Many physical problems require solving boundary value problems (BVPs) of the form: 
Lf = f (1) where L is some operator acting on an unknown scalar .eld f with a non-homogeneous source 
term f . Such problems arise frequently in scienti.c and engineering disciplines ranging from heat 
transfer and .uid mechanics to plasma physics and quantum mechanics. Computer graphics applications 
include visual simulation and tone mapping for compression of high dynamic range images. We will use 
simple heat transfer as an example to illustrate the algorithm. Finding the steady-state temperature 
distribution T in a solid of thermal conductivity k with thermal source S requires solving a Poisson 
equation k.2T = -S, a BVP in which L is the Laplacian operator .2. 193193193 In practice most BVPs cannot 
be solved analytically. Instead, the domain is typically discretized onto a grid to produce a set of 
linear equations. Several means exist for solving such sets of equations, including direct elimination, 
Gauss-Seidel iteration, conjugate-gradient techniques, and strongly implicit procedures18.Multigrid methods 
are a class of techniques that have found wide acceptance since they are quite fast for large BVPs and 
relatively straightforward to implement. A multitude of techniques can be classi.ed as multigrid methods; 
a full description of these is beyond the scope of this paper. We refer the reader to Press et al.18 
for a brief introduction and to a survey such as Briggs 2 for a more comprehensive treatment. We summarize 
the broad steps of the algorithm (called kernels) below in order to describe how we map them to the GPU. 
The smoothing kernel approximates the solution to Equation 1 after it has been discretized onto a particular 
grid. The exact smoothing algorithm will depend on the operator L, which is the Laplacian .2 in our example. 
The smoothing kernel iteratively applies a discrete approximation of L. The progress of the smoothing 
iterations is measured by calculating the residual. In the general case, the residual is de.ned as Lfi 
- f , where Lfi is the approximate solution at iteration i. In our heat transfer example, the residual 
at iteration i is simply .2Ti + S, where we have set the thermal conductivity k = 1. Reduction of the 
residual results in reduction of the error in the solution, and the solution may be considered suf.ciently 
converged once the residual falls below a (user-speci.ed) threshold. However, convergence on a full-resolution 
grid is generally too slow, due to long-wavelength errors that are slow to propagate out of the .ne 
grid. Multigrid circumvents this problem by recursively using coarser and coarser grids to approximate 
corrections to the solution. The restriction kernel therefore takes the residual from a .ne grid to 
a coarser grid, where the smoothing kernel is again applied for several iterations. Afterwards the coarse 
grid may be restricted to a still coarser grid, or the correction may be pushed back to a .ner grid using 
the interpolation kernel. Multigrid methods typically follow a .xed pattern of smoothing, restriction, 
and interpolation (examples of such patterns are V-cycles and Wcycles2; we use V-cycles for all results 
in this paper), then test for convergence and repeat if necessary. 2.2. Current graphics architectures 
A modern graphics accelerator such as the NVIDIA NV3016 consists of tightly coupled vertex and fragment 
pipelines. The former performs transformations, lighting effects, and other per-vertex operations; the 
latter handles screen-space operations such as texturing. The fragment processor has direct access to 
texture memory. This and the fact that fragment processors have enormous throughput roughly an order 
of magnitude greater data throughput than vertex programs3 makes the fragment engine well suited to certain 
numerical algorithms. Until recently, both pipelines were optimized to perform only graphics-speci.c 
computations. However, current GPUs provide programmability for these pipelines, and have also replaced 
the 8-10 bits previously available with support for up to full IEEE single-precision .oating point throughout 
the pipeline. Purcell et al.20 argue that current programmable GPUs can be modeled as parallel stream 
processors, the two pipelines highly optimized to run a user-speci.ed program or shader on a stream of 
vertices or fragments, respectively. The NV30 supports a fully orthogonal instruction set optimized 
for 4-component vector processing. This instruction set is shared by the vertex and fragment processors, 
with certain limitations for example, the vertex processor cannot perform texture lookups and the fragment 
processor does not support branching. The individual processors have strict resource limitations; for 
example, an NV30 fragment shader can have up to 1024 instructions. We have implemented our multigrid 
solver as a collection of vertex and fragment shaders for the NV30 chip using Cg14. We rely on two 
other features of modern graphics architectures: multi-texturing and render-to-texture. Multitexturing 
allows binding of multiple simultaneous textures and multiple lookups from each texture. Render-to-texture 
enables binding the rendering output from one shader as a texture for input to another shader. This avoids 
copying of fragment data from framebuffer to texture memory, which can be a performance bottleneck for 
large textures. As graphics hardware has become more programmable, high-level languages have emerged 
to support the programmer. Proudfoot et al.19 describe a real-time shading system targeting programmable 
hardware. Their system compiles shaders expressed in a high-level language to GPU code and supports multiple 
backend rendering platforms. Their language is not well suited for our purposes, however, since it is 
heavily graphics-oriented and designed to compile complex shaders into multiple passes, using the technique 
of Peercy et al.17 to virtualize the GPU s limited resources. More recent efforts include Cg14 and the 
OpenGL 2.0 Shading Language, both lower-level languages better suited to general-purpose computation. 
We chose Cg as our primary development platform, targeting the NV30 fragment pipeline. 3. Previous Work 
The recent addition of programmability to graphics chipsets has led to myriad efforts to exploit that 
programmability for computation outside the realm of 3D rasterization. Harris provides an excellent 
compendium of existing research7; we mention only the most related work here. Purcell et al.20 demonstrate 
the .exibility of modern graphics hardware by casting ray tracing as a series of fragment programs. 
c 194194194 Larsen and McAllister12 perform dense matrix-matrix multiplies on the GPU. Hoff et al.9 
have demonstrated a series of graphically-accelerated geometric computations, such as fast Voronoi diagrams 
and proximity queries. Thompson et al.23 apply graphics hardware to general-purpose vector processing. 
Their programming framework compiles vector computations to streams of vertex operations using the 4vector 
registers on the vertex processor; they demonstrate implementations of matrix multiplication and 3-SAT. 
They use the vertex processor exclusively, while most other researchers (including us) primarily use 
the faster but simpler fragment processor. This lets us feed results of one computation into the input 
of another, overcoming a major drawback faced by Thompson et al.: the need to read results from the GPU 
back to the CPU. Note that the latest hardware drivers allow the results of a fragment program to be 
fed directly into the vertex processor, enabling hybrid vertex/fragment programming approaches. Closer 
in spirit to our work are approaches to GPUaccelerated physical simulation. For example, several NVIDIA 
demos perform simple physical simulations modeling cloth, water, and particle system physics using vertex 
and fragment shaders16. Building on these ideas, Harris et al.8 employ graphics hardware for visual simulation 
using an extension of cellular automata known as coupled-map lattice. They simulate several .uid processes 
such as convection, diffusion, and boiling. Rumpf and Strzodka21 explore PDEs for image processing operations 
such as nonlinear diffusion and express solutions using Jacobi iteration and conjugategradient iteration 
as rendering passes. 4. Implementation We keep all grid data the current solution, residuals, source 
terms, etc. in fast on-card video memory, storing the data for each progressively coarser grid as a series 
of images. This allows us to use the fragment pipeline, optimized to perform image processing and texture 
mapping operations on billions of fragments per second, for our computations. We also eliminate the need 
to transfer large amounts of data from main memory to and from the graphics card (a common performance 
bottleneck). To keep the computation entirely on the card, we implement all operations smoothing, residual 
calculation, restriction, and interpolation using fragment shaders that read from a set of input images 
(textures) and write to an output image. 4.1. Mapping the multigrid algorithm to hardware The multigrid 
algorithm recursively solves a boundary value problem at several grid resolutions. In our implementation 
all computationally intensive steps successive kernel applications, implemented as fragment shaders 
are handled by the GPU. Results from one kernel become the input to the next kernel (Figure 1). In other 
words, we have implemented the multigrid algorithm as a series of stream computations performed in 
the fragment pipeline, using the CPU to keep track of the recursion depth and rendering state. Following 
this stream processing abstraction, the purpose of each multigrid shader is to operate on data from multi 
smooth Front Back smooth  3.1. Recent related work Two recent publications are particularly relevant. 
Krger and Westermann discuss implementation of linear algebraic op erators on the GPU11, while Bolz 
et al. describe a multigrid Increasing Time Back residual restrict smooth Grid i Front Back smooth (fine) 
+ interpolate solver on graphics hardware, which they demonstrate on visual simulation of .uid .ow1. 
Although their system is fundamentally similar to ours, the systems also differ in several interesting 
ways. These differences emerge primarily from the choice of driving problem and the strategies followed 
for optimization. For example, we target a complex domainspeci.c engineering code that requires ef.cient 
support for periodic boundaries and a way to transform the domain by varying the operator across grid 
cells (see Section 5.3). As another example, Bolz et al. use a quadrant-stacked data layout to maximize 
utilization of the four-register GPU vector processors, and report that the bottleneck in the remaining 
system is the cost of context-switching between OpenGL pbuffers. Our primary goal during optimization 
has been to eliminate this cost; our data layout makes less optimal use of the GPU memory bandwidth but 
eliminates contextswitching (see Section 6). &#38;#169; The Eurographics Association 2003. smooth Front 
smooth Back Grid i+1 (coarse) Layout in memory Figure 1: A conceptual illustration of two grids in the 
multigrid algorithm, each using the front and back surfaces of the solution buffer as alternating source 
and target. At grid Gi, the smoothing pass is performed by rendering between the surfaces labeled front 
and back. We then restrict the residual to the front buffer for grid Gi+1 and perform the same smoothing 
operations on this lower-resolution grid. The approximate solution at Gi+1 is then interpolated back 
to the higher resolution grid Gi, and the smoothing continues. By using two buffers at each grid level, 
we can bind one buffer as input and use the other as a rendering target. All arrows between buffers represent 
render passes. 195195195 ple input streams to produce a single output stream. For example, in the smoothing 
kernel we discretize and store the operator L from Equation 1 as a .ve-point stencil at every grid cell 
(storing a separate stencil at every cell enables non-Cartesian grids, such as cylindrical coordinates). 
Thus the smoothing kernel combines two data streams: one containing the discretized operator Lh and 
the other containing the current solution Uh. We use texture-mapped polygons to generate these streams 
as fragments streaming through the GPU fragment engine. Using the OpenGL API, the general procedure for 
each kernel is as follows: Bind as texture maps the buffers that contain the necessary data. These textures 
form the input for the kernel.  Set the target buffer for rendering. This buffer forms the output of 
the kernel.  Activate a fragment shader, programming the fragment pipeline to perform the kernel computation 
on every fragment.  Render a single quadrilateral with multi-texturing enabled, sized to cover as 
many pixels as the resolution of the current grid.  Using this procedure, we are able to perform all 
steps of the multigrid algorithm by simply binding the fragment program, the rendering target, and the 
appropriate combination of textures as input to the fragment pipeline. Next we describe the principal 
buffers and the four key multigrid kernels in detail, using as an example our heat-transfer problem 
modeled by the Poisson equation. 4.1.1. Input buffers The main buffers in the system are the solution 
buffer, the operator map, and the red-black map. Together these three buffers form the input textures 
for all of the multigrid kernel shaders. The operator and red-black maps are read-only textures, but 
the solution buffer also serves as the rendering target for all shaders. As discussed in Section 6, 
using a single buffer for both input and output avoids context switches, which is crucial for performance 
with current NVIDIA drivers. The solution buffer is a four-channel .oating-point OpenGL pixel buffer 
(a pbuffer) containing two surfaces, exactly akin to the front and back surfaces used for doublebuffered 
rendering. Each kernel shader reads from one surface of the solution buffer (the source surface) and 
writes to another (the target surface). After each kernel is run on a given grid level, the source and 
target surfaces for that level are toggled for the next rendering pass. Each pixel in the solution buffer 
represents a grid cell, with three .oating-point channels containing the current solution, the current 
residual, and the source term for that cell. We use a fourth channel for debugging purposes. The operator 
and red-black maps are also four-channel .oating-point textures in our current implementation. The operator 
map contains the discretized operator, described in the next section. The red-black map is an optimization 
used to accelerate fragment odd-even tests for the smooth and interpolate kernels and is described in 
Section 6. For convenience, these are stored on the front and back surfaces of a second four-channel 
pixel buffers, letting all buffers share a single OpenGL rendering context. 4.1.2. Smoothing In the 
multigrid algorithm, smoothing refers to the process of iteratively re.ning the solution to the boundary 
value equation 1 at each grid level. The actual implementation will depend on the operator represented 
by L; in the case of the Poisson equation, L is the Laplacian operator .2. The smoothing kernel applies 
this operator to a given grid cell, reading from the cell s immediate neighborhood to compute a new value 
for that cell. The inputs are simply the current solution U and a .ve-point discrete approximation of 
the Laplacian: .2Uij Ui-1, j +Ui+1, j +Ui, j-1 +Ui, j+1 - 4Ui, j (2) where i and j are row and column 
indices into the grid. The smooth shader applies the operator to each fragment (i.e., grid cell) being 
rasterized. It also factors in the nonhomogeneous term f , which for heat transfer problems is a spatially 
varying function of external heat source. Finally, we apply the necessary boundary conditions, as discussed 
later in Section 4.2. After performing these operations on every fragment, the output represents a closer 
approximation to the steady-state solution. In Jacobi iteration the operator is applied to every grid 
cell of the source surface, with the output being rendered to the target surface. However, we apply the 
smoothing using red-black iteration2, a common method that often converges faster in practice. In red-black 
iteration the operator is applied to only half of the grid cells at a time, so that one complete smooth 
operation actually requires two passes.  4.1.3. Calculating the residual At each grid cell, the residual 
value is calculated by applying the operator L to the current solution. For the Poisson equation (where 
L = .2), we compute residuals using a single rendering pass of the residual shader and store the result 
in the target surface in preparation for the restriction pass. The other data from the source surface 
(current solution and source term) is copied unmodi.ed to the target surface. We can exploit the occlusion 
query feature of recent graphics chips to determine when steady-state has been reached using the residual 
calculation. The occlusion query tests whether any fragments from a given rendering operation were written 
to the frame buffer15. Every nth iteration for some user-de.ned n we activate a fragment shader that 
compares the residual at each grid cell to some threshold c 196196196 value e and kills the fragment 
(terminating the corresponding SIMD fragment processor s execution) if the absolute residual is less 
than e. If an occlusion query for this operation returns true, we have found the solution to Equation 
1 within the tolerance e. By varying e we can govern the accuracy, and thus the running time, of the 
simulation. Note that this use of the occlusion query amounts to testing convergence with the L8 norm: 
iterate until no cell s residual exceeds e. This convergence test is often appropriate for scienti.c 
and engineering applications, such as the .apping-wing example in Section 5.3, but may be unnecessarily 
strict in other cases. For example, visual simulation often uses an L2 norm or even an L1 norm to avoid 
penalizing local concentrations of error when the overall error across all cells is small. Using these 
looser convergence tests leads to faster, more consistent run times, at the cost of less predictable 
error. However, to implement the L2 or L1 norm in a single pass is not possible on current fragment hardware; 
either the residual must be read out to the CPU (ruinously expensive) or some sort of recursive summation 
kernel (akin to building a mipmap) must be applied, increasing the cost of the convergence test. One 
potential architectural solution, helpful in this and other contexts, would be a globally accessible 
fragment accumulator register a sort of extended occlusion query that could sum a value across all fragments. 
 4.1.4. Restricting the residual If grid Gi represents the ith domain resolution, then Gi+1 is the next-coarser 
grid level. We restrict the residual from Gi to Gi+1 by setting the rendering output resolution to match 
the dimensions of grid Gi+1, then activating a fragment shader that re-samples residual values from Gi 
using bilinear interpolation and restricts the samples onto the coarser grid (so-called full weighting 
). In other words, the restriction shader takes as input two data streams: a fragment for every grid 
cell in the Gi+1 domain and a group of fragments in Gi for every cell in Gi+1. The output becomes the 
nonhomogeneous term f from equation 1 for the problem to be solved on the coarse grid Gi+1 stored in 
the appropriate channel of the target surface. As before, the other channels are passed directly through. 
 4.1.5. Interpolating the correction Finding the approximate solution at grid Gi+1 provides a correction 
we can interpolate to grid Gi. In this case we set the output rendering resolution to match the dimensions 
of Gi; the active fragment shader bilinearly interpolates solution values from one input stream (Gi+1) 
and adds these to another input stream (Gi).  4.2. Boundary Conditions The ability to specify arbitrarily 
complex boundary conditions is fundamental to solving boundary-value problems for &#38;#169; The Eurographics 
Association 2003. real-world situations. We treat boundary values as a simple extension to the state-space 
of the simulation, enabling the fragment processor to perform the same computation on every fragment 
and thereby avoiding the need to include boundary-related conditionals in the fragment shader. For example, 
our multigrid solver allows general boundary conditions, such as Dirichlet (prescribed value), Neumann 
(prescribed derivative), and mixed (coupled value and derivative). These boundary conditions can be expressed 
as: .Uk akUk + k = .k (3) .nk where ak, k, and .k are constants evaluated at the kth boundary position 
and Uk is the kth boundary value. The second term on the left hand side is the directional derivative 
with respect to the normal nk at a given boundary. Equation 3 can be implemented by storing each of the 
constants in texture memory. For the derivative term we simply replace the .vepoint operator stencil 
(the discretized operator from Equation 1) with a boundary condition stencil. We apply all boundary 
conditions as part of the smoothing pass; the user can specify a single texture that contains all boundary 
condition information. Often problems are modeled with periodic boundaries, meaning that cells on one 
boundary of the domain are considered adjacent to cells on the opposite boundary. For example, allowing 
periodicity at the vertical and horizontal boundaries of a quadrilateral results in a topologically 
toroidal domain. Note that periodicity affects the smooth, restrict, and residual kernels, since they 
all read from a neighborhood of several fragments. A naive implementation of periodic boundary conditions 
is straightforward: for each fragment being read, simply check within the shader whether that fragment 
is on a boundary, and if so, use different neighbor rules to determine where to sample in the textures 
when applying the operator. In practice, however, this kind of conditional code should be avoided because 
the SIMD fragment engine does not natively support branch instructions, so the hardware in fact executes 
all branches of the code on all fragments, using condition codes to suppress the unwanted results. The 
naive code is therefore signi.cantly slower than code for the non-periodic boundaries, especially when 
the kernel must perform some boundaryrelated computation that is wasted on the vast majority of fragments 
that are not near a boundary. To ef.ciently realize periodic boundary conditions, we support two versions 
of each multigrid kernel: a general shader that works for any fragment (grid cell) in the domain and 
a fastpath shader that works only for fragments interior to the domain (i.e., those that do not require 
boundary conditions). When applying the kernel to a domain we split it into two passes: the fastpath 
shader is rasterized using a rectangle covering the interior fragments of the destination grid, and then 
the general shader is rasterized as a series of 197197197 65x65 129x129 257x257 513x513 1025x1025 Grid 
Size Figure 2: Effects of fastpath optimization. The fully general shader ( Slow ) includes code supporting 
supporting periodic boundaries, unneeded on most grid cells. The Fast shader does not support periodic 
boundaries. The Fastpath optimization uses a two-pass approach to increase speed while supporting periodic 
boundaries. The slower shader is only used on fragments rasterized on the boundaries, while the interior 
region of the domain is rasterized using the faster shader. (possibly thick) lines along the boundary 
fragments of the grid. Since the number of interior fragments is quadratically greater than the number 
of perimeter fragments, the savings from applying the less expensive fastpath shader on these fragments 
more than compensates for the cost of binding two shaders and transforming multiple primitives. Figure 
2 summarizes the savings achieved by using a fastpath shader. Note that the concept of a fastpath shader 
was also presented by James and Harris10 and is analogous to splitting the computation in CPU implementations 
to avoid branch instructions in the inner loop. To simplify the maintenance of periodic boundaries and 
the construction of the kernels, we employ the common trick of replicating the cells on the periodic 
boundaries. For example, if a grid has a periodic vertical boundary, the .rst and last columns of the 
grid will contain the same data and actually represent the same region of the domain. 5. Applications 
We have applied our system to problems in heat transfer, .uid mechanics, and high dynamic range tone 
mapping. Here we brie.y describe the three applications and their use of the multigrid solver.  5.1. 
Heat transfer Steady-state temperature distribution across a uniform surface discretized on a Cartesian 
grid can be solved directly by the multigrid Poisson solver we have presented. We load the initial heat 
sources into the solution buffer s .nest grid and encode the boundary conditions (such as Dirichlet, 
Neumann, or periodic) in the operator map, using a simple procedural shader. We then pick the number 
of grids and the recursion depth and run iterations of the multigrid algorithm until we determine, using 
the occlusion query feature, that the system has converged. We used this straightforward application 
as a testbed, checking the validity and performance of our solver against a custom CPU implementation 
of the same algorithm developed to support the .uid .ow application in Section 5.3. In our tests, the 
GPU solver agreed with the CPU solver to within .oating-point precision. 5.2. Tone mapping for high 
dynamic range images Images spanning a large range of intensity values are becoming increasingly common 
and important in computer graphics. These high dynamic range (HDR) images typically arise either from 
special photography techniques4 or physically based lighting simulations; they are challenging to display 
due to the relatively low dynamic range of output devices. Several tone-mapping algorithms have been 
developed to compress the dynamic range of an HDR image. We have used our multigrid solver to implement 
the Gradient Domain Compression algorithm of Fattal et al.5 This technique applies a non-uniform scaling 
F(x, y)to the gradient of a log-luminance image H(x, y). Speci.cally, they compute G(x, y)=.H(x, y)F(x, 
y). Because F is designed to attenuate large gradients more than small gradients, the function G has 
similar detail to H in areas without large discontinuities, which is exactly the sort of detail-preserving 
compression desired. Unfortunately, turning G(x, y)back into an image is nontrivial, since G is not 
necessarily integrable. Instead, they solve the Poisson equation .2I =divG to .nd the image I whose gradient 
is closest to G in the least-squares sense. Fattal also uses a multigrid solver to solve this differential 
equation, although they use Gauss-Seidel iteration while our solver uses red-black iteration. 5.3. Fluid 
.ow around a .apping wing Fluid mechanics simulations have proven popular choices for acceleration using 
the GPU; for example, both Harris10, 6 and Bolz1 demonstrate stable .uids solvers based on the method 
of Stam22. Such solvers are particularly popular in computer graphics because they produce robust and 
visually convincing (if not entirely physically accurate) .uid .ow. Our work on GPU .uid simulation grew 
out of a desire to accelerate an engineering code that simulates .ow around a .apping airfoil using a 
model by Lewin and Haj-Hariri13. This code was the motivating problem for our work and remains the most 
complex model we have used our solver to accelerate. The model uses the vorticity-stream function formulation 
to solve for the vorticity .eld of a two-dimensional airfoil c 198198198 3 2 1 0 65x65 129x129 257x257 
513x513 1025x1025 Grid Size GPU CPU   Figure 3: CPU vs. GPU comparison. Seconds per V-Cycle is the 
time to run through a single V-Cycle iteration of the multigrid solver on the .uid mechanics problem. 
Each V-Cycle used the maximum number of grid levels and performed 8 smooths at each grid level. On large 
grids, GPU performance begins to signi.cantly exceed CPU performance. These results were obtained using 
a NVIDIA GeForceFX 5800 Ultra and an AMD Athlon XP 1800 with 512MB RAM. undergoing arbitrary heaving 
(vertical), lagging (horizontal), and pitching motions. In the non-inertial reference frame of the airfoil, 
the vorticity transport equation is modi.ed for the motion of the airfoil and becomes: .. .... 1 = -u 
- v + .2. - 2.(4) .t .x .y Re - .u where . = .v is the vorticity, Re is the Reynolds num .x .y ber, 
and .is the rotational acceleration of the airfoil. Because the .ow is considered incompressible, the 
velocity components in Equation 4 are found from the stream function .: .. .. u = , v = - (5) .y .x 
where the stream function is related to the vorticity by .2. = -. (6) At each time step, equations 4 
and 6 are solved for the new values of unknowns . and ., after which equation 5 is solved to obtain the 
new velocity .eld. The process is repeated for a predetermined number of time steps. Bolz et al.1 focus 
on the Poisson problem for the pressure term; similarly, we focus on the Poisson problem for the stream 
function in Equation 6. This equation accounts for the bulk of the computation and dovetails nicely with 
the multigrid Poisson solver presented above. To meet the needs of our .uid model requires extending 
that solver to handle transformed coordinates. The rectilinear domain is .rst wrapped into a circular 
disc and then warped into an airfoil using a Joukowski transformation. These extensions impact the basic 
solver in two important ways. First, since the cylindrical domain wraps onto itself, two sides of the 
grid must form a periodic boundary. Second, the distortion c &#38;#169; The Eurographics Association 
2003. Seconds perV-Cycle  due to the Joukowski transformation can be accomplished by transforming the 
discrete approximation to the Laplacian (Equation 2), which requires storing and applying a spatially 
varying stencil for each grid cell in the smoothing and residual shaders. Rather than hard-coding the 
coordinate transformations, we use a user-speci.ed shader to compute the operator for the Joukowski 
transformation at each cell at the beginning of the simulation. This approach allows for very general 
user-speci.ed domain transformations. Figure 3 compares performance of the GPU and CPU multigrid solvers 
on a variety of grid sizes with the parameters used in the .apping wing simulation. The results are 
summarized in Figure 3, but note that not too much stress should be placed on these results, since the 
CPU implementation while far from naive was not optimized with the same care as the GPU implementation. 
6. Optimizing the Solver Our initial implementation of the solver operated correctly but was disappointingly 
slow. We accordingly undertook a series of optimizations targeting some of the obvious performance bottlenecks. 
We describe this process here as an interesting case study on the issues involved in optimizing general-purpose 
computation for the GPU. A number of potential bottlenecks can limit the performance of a system built 
chie.y on the fragment processor. We focused .rst on perhaps the most obvious: the number of instructions 
in the various shaders and the number of registers used by those instructions. By pre-computing values 
such as texture coordinate offsets in vertex shaders and by vectorizing the remaining computations where 
possible (given our data layout, see below), we were able to reduce the instruction count of the four 
primary shaders by a factor of 3-4 while roughly halving the registers used (Table 1). Note that this 
includes the fastpath optimization described in Section 4.2, which avoids the extra work associated with 
boundary cells. shader original fp fastpath fp fastpath vp smooth 79-6-1 20-4-1 12-2 residual 45-7-0 
16-4-0 11-1 restrict 66-6-1 21-3-0 11-1 interpolate 93-6-1 25-3-0 13-2 Table 1: Instruction and register 
counts for original and fastpath shaders. For each shader, we give the fragment program complexity (instructions 
.oat registers half registers) of the original (original fp) and fastpath (fastpath fp) shaders. For 
the optimized fastpath shaders, we precompute some values such as texture offsets in a vertex program. 
fastpath vp reports the vertex program complexity (instructions temp registers). 199199199 129x129 
257x257 513x513 1025x1025 Grid Size Figure 4: The effect of context switches on performance. Our initial 
shaders ( Very naive ) were carefully optimized to reduce instruction count and better utilize the vectorized 
fragment processor ( Optimized shaders ), but all grid levels were stored as separate buffers, so performance 
was entirely limited by OpenGL context switches. Compacting the grid levels into two pbuffers by stacking 
grid levels and using front and back surfaces ( Two buffers ) greatly increased performance; further 
compacting all grid levels into one two-surface pbuffer ( One buffer ) brought a slight additional improvement. 
Note that at a resolution of 10251025, the Two buffers implementation ran out of memory, though the 
others did not. Surprisingly, the heavily optimized shaders made almost no difference in performance. 
We had encountered the same bottleneck reported by Bolz et al.1, namely, the overhead associated with 
context switches among multiple OpenGL pbuffers on the NV30 platform. Our initial implementation used 
two separate pbuffers for each grid level; the smooth and residual shaders (which operate on a single 
grid level at a time) alternated rendering between source and target pbuffers of the same size, while 
the restrict and interpolate shaders (which move from one grid level to another) would render between 
pbuffers of different size. The resulting system switched rendering context with every application of 
every kernel a naive approach that greatly limited performance. We therefore rearranged the layout of 
our grids to use only two pbuffers in total. One pbuffer contained two surfaces representing source 
and target grids for level 0, while the other contained all remaining grid levels both source and target 
in a single surface (see Figure 5). The resulting system eliminated most pbuffer overhead, speeding up 
the system by a factor of about 3. However, restrict and interpolate operations entering or leaving 
grid level 0 still incurred a switch of rendering context. Our .nal arrangement eliminates this remaining 
context switch, creating a single pbuffer with each grid level duplicated on front and back surfaces 
(Figure 5). The layout of grids within a surface is arbitrary; our only requirement was to ensure that 
we could still .t our largest-sized problem (10251025) into a single pbuffer, which currently has an 
absolutely size limit of 20482048. Eliminating the .nal rendering context switch with this arrangement 
accelerated the .nal system by an additional 8-10%. Figure 4 shows the relative performance of our various 
implementations. A simple state machine tracks which surface provides the source and target for each 
grid level as different kernels are applied. One subtlety arises: following this approach directly can 
lead to a technically illegal sequence of rendering calls. Alternating buffers across a series of restrict, 
smooth, and interpolate kernels may result in writing (rendering to) and reading (binding as an active 
texture) the same surface in the same or successive render passes. Render-to-texture disallows reading 
and writing from the same surface and requires a glFinish() call between such successive passes15,but 
this call proved too heavyweight, ruining performance. One solution is to insert a copy kernel which 
simply renders a grid from one surface to another when necessary to avoid this situation, but this incurs 
extra cost. In practice, we found that the rules can be broken and a surface used for simultaneous input 
and output if care is taken to ensure that all fragments output from one pass are written before they 
are read as input to another pass. By binding new shaders with new rendering state (called uniform parameters 
in Cg), we Figure 5: This .gure illustrates the memory layout of our grids in the Two buffers implementation 
(top) and One buffer implementation (bottom). Note that in the Two buffers case we render back and forth 
among three surfaces: the front and back surfaces of one pbuffer and a single surface of a second buffer. 
In the One buffer case, we packed all of the grids into two surfaces of a single pbuffer to eliminate 
context switches. 200200200 ensure that the pipeline gets .ushed between each rendering pass. Alternatively, 
we could have inserted no-op instructions into the fragment pipeline by rasterizing dummy fragments 
whose results are discarded, but this is a dangerously architecture-dependent strategy. After adjusting 
the grid layout to minimize rendering context switches, we implemented several other optimizations. 
For example, the smooth kernel requires the red-black status of each fragment. Rather than continuously 
computing this status for each fragment, we store a red-black mask as a texture map for about a 30% speedup. 
We also veri.ed the occlusion query optimization described in Section 4.1.3, which indeed provides substantial 
speedup (around 5 on large grids) over testing for convergence on the CPU. Figures 6 and 7 illustrate 
these savings. Bolz et al. describe a major optimization which we did not employ: domain decomposition 
for maximum utilization of the vectorized fragment hardware. They stack the four quadrants of the grid 
so that each fragment read or written represents four grid cells. Instead we held to the early design 
choice to use the simpler mapping described in Section 4.1.1, which stores the current solution, residual, 
and source term for a single grid cell at each fragment. This was largely to simplify implementation 
and testing of the complicated boundary conditions we wanted to provide. The optimizations we describe 
appear to be complementary to the domain decomposition used by Bolz et al., and although we have not 
done so, it should be possible to apply their approach to our system for signi.cant further speedup. 
7. Discussion We have implemented a general multigrid solver on the NV30 architecture, demonstrating 
a speci.c and broadly useful application of stream computing using graphics hardware. We increase performance 
by keeping all data current solution, residuals, source terms, operators, and boundary information on 
the graphics card stored as textures, and by performing calculations entirely in the fragment pipeline, 
using fragment shaders to implement the multigrid kernels: smoothing, residual, restriction, and interpolation. 
In general, one could use our framework to solve a variety of boundary value problems; as a concrete 
example, we solve the Poisson equation in the context of heat transfer, .uid mechanics, and tone mapping 
applications. Our solver outperforms a comparable CPU implementation and explores the computational 
power that can be harnessed by ef.cient use of graphics hardware.   7.1. Analysis of memory bandwidth 
Analysis of our .nal system has shown it to be limited by memory bandwidth. For example, on the NV30 
we can switch the entire system to use 16-bit half-precision .oatingpoint. The resulting system, while 
not useful for solving realworld problems, runs almost exactly twice as fast as the 32bit full-precision 
system a clear indication that memory bandwidth could be the limiting factor. To verify this, we ran 
additional experiments such as timing many smooth kernels at a single grid level, then comparing the 
same number of passes with a memory-bound trivial shader that simply outputs a constant value. A comparison 
of the total bytes accessed per second in each showed that they performed comparably, each accessing 
approximately 8 GB/sec. Given the nature of the multigrid algorithm, the fact that it is memory-bound 
is unsurprising. Whether implemented on the CPU or the GPU, the actual computation is relatively minor; 
when carefully optimized, each kernel performs only a few adds and multiplies at each grid cell. The 
many memory accesses understandably dominate. Seconds To Steady State 4 3 2 1 Red-black mask Compute 
red-black   Seconds To Steady State 15 10 5 NV_OCCLUSION_QUERY glReadPixels()   0 129x129 257x257 
513x513 1025x1025 0 Grid Size Figure 6: Effectiveness of the red-black map. Despite the fact that our 
solver is limited by memory bandwidth, using the stored red-black map to quickly determine odd-even status 
for the smooth and interpolate kernels ( One buffer ) remains more ef.cient than explicitly computing 
this information in the fragment shader ( Compute red-black ). &#38;#169; The Eurographics Association 
2003. 129x129 257x257 513x513 1025x1025 Grid Size Figure 7: Using the occlusion query to test for convergence. 
Explicitly calling glReadPixels() and examining the residuals on the CPU proves prohibitively expensive 
on large grids, but using the occlusion query feature allows us to test for convergence while keeping 
all data on the GPU. 201201201 Early versions of our system suffered from large amounts of graphics 
driver overhead and unnecessary computation in each shader. Our work to date has focused on removing 
these bottlenecks, removing context switches and carefully tuning each shader. Having done that, our 
system is now limited by memory bandwidth, as we would intuitively expect. Given that, the most important 
remaining optimizations will be those that address memory usage. 7.2. Limitations While the advent of 
32-bit .oating point throughout the modern GPU pipeline is a huge leap forward, many realworld science 
and engineering simulations require even greater precision. We would like to characterize whether workarounds 
could be developed for higher precision, using techniques similar to those used for quad-precision computation 
in traditional numeric computing (arbitraryprecision techniques also exist, but these seem poorly suited 
for ef.cient GPU implementation). Another limitation is the size of video memory, limited to 256 MB on 
today s boards; however, this still represents enough memory to model many problems of interesting size. 
Currently, driver limitations on the size of the .oating-point buffers prevent us from approaching the 
theoretical capacity of the boards: in practice we have been unable to allocate a .oating-point texture 
larger than 64 MB, somewhat limiting the utility of these techniques. 7.3. Avenues for future work We 
hope to extend the current multigrid implementation to accelerate a wide range of simulations that require 
fast and ef.cient solutions to boundary value problems. Our preliminary work raises the possibility 
that scientists may soon be able to accelerate their simulation substantially by investing in a commodity 
graphics card. We are particularly interested in parallelizing the multigrid computation, augmenting 
existing computational clusters with inexpensive graphics cards to provide speedups on some problems. 
Finally, we wish to explore general computational frameworks for the use of GPU as a sort of streaming 
coprocessor for computation-intensive tasks. Acknowledgements We would like to thank David Kirk and Pat 
Brown, Matt Papkipos, Nick Triantos and the entire driver team at NVIDIA for providing early cards and 
excellent driver support; James Percy at ATI and Matt Pharr at NVIDIA for demystifying the fragment pipeline; 
Mark Harris, Aaron Lefohn, and Ian Buck for productive discussions on general-purpose GPU computation; 
and the anonymous reviewers for their thorough and constructive comments. This work was supported by 
NSF Award #0092793. References 1. Jeff Bolz, Ian Farmer, Eitan Grinspun, and Peter Schrder. Sparse matrix 
solvers on the GPU: Conjugate gradients and multigrid. ACM Transactions on Graphics, 22(3), July 2003. 
 2. W.L. Briggs, V.E. Henson, and S.F. McCormick. A Multigrid Tutorial. Society for Industrial and Applied 
Mathematics, 2000. 3. Nathan Carr, Jesse Hall, and John Hart. The Ray Engine. In Proceedings of SIGGRAPH/Eurographics 
Workshop on Graphics Hardware, September 2002. 4. Paul Debevec and Jitendra Malik. Recovering high dynamic 
range radiance maps from photographs. In Proceedings of SIGGRAPH 1997, pages 369 378, August 1997. 5. 
Raanan Fattal, Dani Lischinski, and Michael Werman. Gradient domain high dynamic range compression. 
ACM Transactions on Graphics, 21(3):249 256, July 2002. 6. Mark Harris. Flo: A real-time .uid .ow simulator 
written in Cg, 2003. http: //www.cs.unc.edu/~harrism/gdc2003. 7. Mark Harris. GPGPU: General-purpose 
computation using graphics hardware, 2003. http://www.cs.unc.edu/~harrism/gpgpu. 8. Mark J. Harris, 
Greg Coombe, Thorsten Scheuermann, and Anselmo Lastra. Physically-based visual simulation on graphics 
hardware. In Proceedings of SIGGRAPH/Eurographics Workshop on Graphics Hardware, pages 109 118, August 
2002. 9. Kenneth E. Hoff III, John Keyser, Ming C. Lin, Dinesh Manocha, and Tim Culver. Fast computation 
of generalized Voronoi diagrams using graphics hardware. In Proceedings of SIGGRAPH 1999, pages 277 286, 
August 1999. 10. Greg James and Mark Harris. Simulation and animation using hardwareaccelerated procedural 
textures. In Proceedings of the 2003 Game Developers Conference. CMP Media, March 2003. 11. Jens Krger 
and Rdiger Westermann. Linear algebra operators for GPU implementation of numerical algorithms. ACM 
Transactions on Graphics, 22(3), July 2003. 12. E. Scott Larsen and David K. McAllister. Fast matrix 
multiplies using graphics hardware. In Proceedings of IEEE Supercomputing 2001, November 2001. 13. Gregory 
C. Lewin and Hossein Haj-Hariri. Modeling thrust generation of a twodimensional heaving airfoil in a 
viscous .ow. Journal of Fluid Mechanics, 2000. 14. William R. Mark, Steve Glanville, and Kurt Akeley. 
Cg: A system for programming graphics hardware in a C-like language. ACM Transactions on Graphics, August 
2003. 15. NVIDIA. OpenGL Extension Speci.cations, 2002. http://developer. nvidia.com/view.asp?IO=nvidia_opengl_specs. 
 16. NVIDIA. GeForceFX, 2003. http://www.nvidia.com/view.asp? PAGE=fx_desktop. 17. Mark Peercy, Marc 
Olano, John Airey, and Jeffrey Ungar. Interactive multi-pass programmable shading. In Proceedings of 
SIGGRAPH 2000, pages 425 432, August 2000. 18. William H. Press, Saul A. Teukolsky, William T. Vetterling, 
and Brian P. Flannery. Numerical Recipes in C: The Art of Scienti.c Computing. Cambridge University Press, 
second edition, 1992. 19. Kekoa Proudfoot, William Mark, Svetoslav Tzvetkov, and Pat Hanrahan. A real 
time procedural shading system for programmable graphics hardware. In Proceedings of SIGGRAPH 2001, 
pages 159 170, August 2001. 20. Tim Purcell, Ian Buck, William Mark, and Pat Hanrahan. Ray tracing on 
programmable graphics hardware. ACM Transactions on Graphics, 21(3):703 712, July 2002. 21. Martin 
Rumpf and Robert Strzodka. Nonlinear diffusion in graphics hardware. In Proceedings of Eurographics/IEEE 
TCVG Symposium on Visualization, pages 75 84, May 2001. 22. Jos Stam. Stable .uids. In Proceedings of 
SIGGRAPH 1999, pages 121 128, August 1999. 23. Chris J. Thompson, Sahngyun Hahn, and Mark Oskin. Using 
modern graphics architectures for general-purpose computing: A framework and analysis. In Proceedings 
of IEEE/ACM International Symposium on Microarchitecture, pages 306 317, November 2002.  c 202202202 
0 -0.5 -1 Colorplate 1: Flow around a .apping wing. We accelerate a vorticity-stream function .uid mechanics 
model using our multigrid solver for the Poisson problem in the stream function solution. Colorplate 
2: A high dynamic range image compressed with our gradient-domain tone mapping application. The top row 
shows some constituent images used to produce the HDR image; the bottom row shows compressions using 
multigrid CPU (left) and GPU (right) Poisson solvers. &#38;#169; The Eurographics Association 2003. 
203203203  
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198785</article_id>
		<sort_key>204</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[CULLIDE]]></title>
		<subtitle><![CDATA[interactive collision detection between complex models in large environments using graphics hardware]]></subtitle>
		<page_from>204</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198785</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198785</url>
		<abstract>
			<par><![CDATA[We present a novel approach for collision detection between multiple deformable and breakable objects in a large environment using graphics hardware. Our algorithm takes into account low bandwidth to and from the graphics cards and computes a potentially colliding set (PCS) using visibility queries. It involves no precomputation and proceeds in multiple stages: PCS computation at an object level and PCS computation at sub-object level, followed by exact collision detection. We use a linear time two-pass rendering algorithm to compute each PCS efficiently. The overall approach makes no assumption about the input primitives or the object's motion and is directly applicable to all triangulated models. It has been implemented on a PC with NVIDIA GeForce FX 5800 Ultra graphics card and applied to different environments composed of a high number of moving objects with tens of thousands of triangles. It is able to compute all the overlapping primitives up to image-space resolution in a few milliseconds.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40031127</person_id>
				<author_profile_id><![CDATA[81100383019]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Naga]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Govindaraju]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35036301</person_id>
				<author_profile_id><![CDATA[81100239543]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Stephane]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Redon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95041417</person_id>
				<author_profile_id><![CDATA[81452602436]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P67316</person_id>
				<author_profile_id><![CDATA[81100618474]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Dinesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Manocha]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 CULLIDE: Interactive Collision Detection Between Complex Models in Large Environments using Graphics 
Hardware Naga K. Govindaraju, Stephane Redon, Ming C. Lin, Dinesh Manocha Proc. of ACM SIGGRAPH/Eurographics 
Graphics Hardware 2003 Website: http://gamma.cs.unc.edu/CULLIDE We present a novel approach for collision 
detection between multiple deformable and breakable objects in a large environment using graphics hardware. 
Our algorithm takes into account low bandwidth to and from the graphics cards and computes a potentially 
colliding set (PCS) using visibility queries. It involves no precomputation and proceeds in multiple 
stages: PCS computation at an object level and PCS computation at subobject level, followed by exact 
collision detection. We use a linear time two-pass rendering algorithm to compute each PCS efficiently. 
The overall approach makes no assumption about the input primitives or the object's motion and is directly 
applicable to all triangulated models. It has been implemented on a PC with NVIDIA GeForce FX 5800 Ultra 
graphics card and applied to different environments composed of a high number of moving objects with 
tens of thousands of triangles. It is able to compute all the overlapping primitives up to image-space 
resolution in a few milliseconds. 204204204 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198786</article_id>
		<sort_key>205</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[Fast and reliable collision culling using graphics hardware]]></title>
		<page_from>205</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198786</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198786</url>
		<abstract>
			<par><![CDATA[We present a reliable culling algorithm that enables fast and accurate collision detection between triangulated models in a complex environment. Our algorithm performs fast visibility queries on the GPUs for eliminating a subset of primitives that are not in close proximity. To overcome the accuracy problems caused by the limited viewport resolution, we compute the Minkowski sum of each primitive with a sphere and perform reliable 2.5D overlap tests between the primitives. We are able to achieve more effective collision culling as compared to prior object-space culling algorithms. We integrate our culling algorithm with CULLIDE and use it to perform reliable GPU-based collision queries at interactive rates on all types of models, including non-manifold geometry, deformable models, and breaking objects.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40031137</person_id>
				<author_profile_id><![CDATA[81100383019]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Naga]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Govindaraju]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95035870</person_id>
				<author_profile_id><![CDATA[81452602436]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P67316</person_id>
				<author_profile_id><![CDATA[81100618474]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Dinesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Manocha]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Fast and Reliable Collision Culling using Graphics Hardware Naga K. Govindaraju, Ming C. Lin, Dinesh 
Manocha Proc. of ACM Virtual Reality and Software Technology 2004 Website: http://gamma.cs.unc.edu/RCULLIDE 
We present a reliable culling algorithm that enables fast and accurate collision detection between triangulated 
models in a complex environment. Our algorithm performs fast visibility queries on the GPUs for eliminating 
a subset of primitives that are not in close proximity. To overcome the accuracy problems caused by the 
limited viewport resolution, we compute the Minkowski sum of each primitive with a sphere and perform 
reliable 2.5D overlap tests between the primitives. We are able to achieve more effective collision culling 
as compared to prior object-space culling algorithms. We integrate our culling algorithm with CULLIDE 
and use it to perform reliable GPU-based collision queries at interactive rates on all types of models, 
including non-manifold geometry, deformable models, and breaking objects. 205205205 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198787</article_id>
		<sort_key>206</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[Fast computation of database operations using graphics processors]]></title>
		<page_from>206</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198787</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198787</url>
		<abstract>
			<par><![CDATA[We present new algorithms for performing fast computation of several common database operations on commodity graphics processors. Specifically, we consider operations such as conjunctive selections, aggregations, and semi-linear queries, which are essential computational components of typical database, data warehousing, and data mining applications. While graphics processing units (GPUs) have been designed for fast display of geometric primitives, we utilize the inherent pipelining and parallelism, single instruction and multiple data (SIMD) capabilities, and vector processing functionality of GPUs, for evaluating boolean predicate combinations and semi-linear queries on attributes and executing database operations efficiently. Our algorithms take into account some of the limitations of the programming model of current GPUs and perform no data rearrangements. Our algorithms have been implemented on a programmable GPU (e.g. NVIDIA's GeForce FX 5900) and applied to databases consisting of up to a million records. We have compared their performance with an optimized implementation of CPU-based algorithms. Our experiments indicate that the graphics processor available on commodity computer systems is an effective co-processor for performing database operations.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[aggregation]]></kw>
			<kw><![CDATA[graphics processor]]></kw>
			<kw><![CDATA[query optimization]]></kw>
			<kw><![CDATA[selection query]]></kw>
			<kw><![CDATA[selectivity analysis]]></kw>
			<kw><![CDATA[semi-linear query]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40026672</person_id>
				<author_profile_id><![CDATA[81100383019]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Naga]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Govindaraju]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P412743</person_id>
				<author_profile_id><![CDATA[81100028695]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Brandon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lloyd]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40031464</person_id>
				<author_profile_id><![CDATA[81322509168]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95041796</person_id>
				<author_profile_id><![CDATA[81452602436]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P67316</person_id>
				<author_profile_id><![CDATA[81100618474]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Dinesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Manocha]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Pankaj Agarwal, Shankar Krishnan, Nabil Mustafa, and Suresh Venkatasubramanian. Streaming geometric optimization using graphics hardware. In 11th European Symposium on Algorithms, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672367</ref_obj_id>
				<ref_obj_pid>645927</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Ailamaki, D. J. DeWitt, M. D. Hill, and M. Skounakis. Weaving relations for cache performance. In Proceedings of the Twenty-seventh International Conference on Very Large Data Bases 2001, pages 169--180, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671662</ref_obj_id>
				<ref_obj_pid>645925</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[A. Ailamaki, D. J. DeWitt, M. D. Hill, and D. A. Wood. DBMSs on a modern processor: Where does time go? In Proc. of VLDB, pages 266--277, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882364</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Bolz, I. Farmer, E. Grinspun, and P. Schr&#246;der. Sparse matrix solvers on the gpu: Conjugate gradients and multigrid. ACM Trans. on Graphics (Proc. of ACM SIGGRAPH), 22(3), 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671364</ref_obj_id>
				<ref_obj_pid>645925</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Peter A. Boncz, Stefan Manegold, and Martin L. Kersten. Database architecture optimized for the new bottleneck: Memory access. In Proc. of VLDB, pages 54--65, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Census bureau databases. http://www.bls.census.gov/cps/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335225</ref_obj_id>
				<ref_obj_pid>335168</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Zhiyuan Chen, Nick Koudas, Flip Korn, and S. Muthukrishnan. Selectively estimation for boolean queries. In Proceedings of the nineteenth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems, pages 216--225, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Ext_depth_bounds_test specification. http://www.nvidia.com/dev_content/nvopenglspecs/GL_EXT_depth_bounds_test.txt.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Michael Doggett. Programmability features of graphics hardware. ACM SIGGRAPH Course Notes # 11, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375727</ref_obj_id>
				<ref_obj_pid>375663</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Lise Getoor, Benjamin Taskar, and Daphne Koller. Selectivity estimation using probabilistic models. In Timos Sellis and Sharad Mehrotra, editors, Proceedings of the 2001 ACM SIGMOD International Conference on Management of Data 2001, Santa Barbara, California, United States, May 21-24, 2001, pages 461--472, 2001. ACM order number 472010.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844190</ref_obj_id>
				<ref_obj_pid>844174</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[N. Goodnight, C. Woolley, G. Lewin, D. Luebke, and G. Humphreys. A multigrid solver for boundary value problems using programmable graphics hardware. ACM SIGGRAPH/Eurographics Conference on Graphics Hardware, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882299</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[N. Govindaraju, B. Lloyd, S. Yoon, A. Sud, and D. Manocha. Interactive shadow generation in complex environments. Proc. of ACM SIGGRAPH/ACM Trans. on Graphics, 22(3):501--510, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569061</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[M. Harris, G. Coombe, G. Scheuermann, and A. Lastra. Physically-based visual simulation on graphics hardware. SIGGRAPH/Eurographics Workshop on Graphics Hardware, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>366647</ref_obj_id>
				<ref_obj_pid>366622</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[C. A. R. Hoare. Algorithm 65: find. Commun. ACM, 4(7):321--322, 1961.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311567</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[K. Hoff, T. Culver, J. Keyser, M. Lin, and D. Manocha. Fast computation of generalized voronoi diagrams using graphics hardw are. Proceedings of ACM SIGGRAPH, pages 277--286, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>545456</ref_obj_id>
				<ref_obj_pid>545381</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[S. Krishnan, N. H. Mustafa, and S. Venkatasubramanian. Hardware-assisted computation of depth contours. In 13th ACM-SIAM Symposium on Discrete Algorithms, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882363</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[J. Kruger and R. Westermann. Linear algebra operators for gpu implementation of numerical algorithms. ACM Trans. on Graphics (Proc. of ACM SIGGRAPH), 22(3), 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>582089</ref_obj_id>
				<ref_obj_pid>582034</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[E. S. Larsen and D. K. McAllister. Fast matrix multiplies using graphics hardware. Proc. of IEEE Supercomputing, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1437000</ref_obj_id>
				<ref_obj_pid>1435679</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[M. Macedonia. The gpu enters computing's mainstream. Computer, October 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672010</ref_obj_id>
				<ref_obj_pid>645926</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[S. Manegold, P. Boncz, and M L. Kersten. What happens during a join? Dissecting CPU and memory optimization effects. In VLDB 2000, Proceedings of 26th International Conference on Very Large Data Bases, September 10-14, 2000, Cairo, Egypt, pages 339--350, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1287387</ref_obj_id>
				<ref_obj_pid>1287369</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Stefan Manegold, Peter A. Boncz, and Martin L. Kersten. Generic database cost models for hierarchical memory systems. In Proceedings of the Twenty-eighth International Conference on Very Large Data Bases 2002, pages 191--202, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[D. Manocha. Interactive Geometric and Scientific Computations using Graphics Hardware. SIGGRAPH Course Notes # 11, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882362</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[William R. Mark, R. Steven Glanville, Kurt Akeley, and Mark J. Kilgard. Cg: A system for programming graphics hardware in a c-like language. In Proc. of ACM SIGGRAPH, 2003. http://developer.nvidia.com/page/cg_main.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Shintaro Meki and Yahiko Kambayashi. Acceleration of relational database operations on vector processors. Systems and Computers in Japan, 31(8):79--88, August 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[http://lava.cs.virgina.edu/bpred.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Nvidia geforce fx gpus: Intellisample technology. http://www.nvidia.com/object/intellisampletb.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Nv_occlusion_query specification. http://www.nvidia.com/dev_content/nvopenglspecs/GL_NV_occlusion_query.txt.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>181557</ref_obj_id>
				<ref_obj_pid>181550</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Niki Pissinou. Towards and infrastructure for temporal databases --- A workship report. SIGMOD Record (ACM Special Interest Group on Management of Data), 23(1):35--51, March 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566640</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[T. Purcell, I. Buck, W. Mark, and P. Hanrahan. Ray tracing on programmable graphics hardware. ACM Trans. on Graphics (Proc. of SIGGRAPH'02), 21(3):703--712, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844181</ref_obj_id>
				<ref_obj_pid>844174</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[T. Purcell, C. Donner, M. Cammarano, H. Jensen, and P. Hanrahan. Photon mapping on programmable graphics hardware. ACM SIGGRAPH/Eurographics Conference on Graphics Hardware, pages 41--50, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671362</ref_obj_id>
				<ref_obj_pid>645925</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Jun Rao and Kenneth A. Ross. Cache conscious indexing for decision-support in main memory. In Proc. of VLDB, pages 78--89, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>543628</ref_obj_id>
				<ref_obj_pid>543613</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Kenneth A. Ross. Conjunctive selection conditions in main memory. In ACM, editor, Proceedings of the Twenty-First ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems: PODS 2002, pages 109--120, 2002. ACM order number 475021.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134092</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[J. Rossignac, A. Megahed, and B. D. Schneider. Interactive inspection of solids: cross-sections and interferences. In Proceedings of ACM Siggraph, pages 353--60, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>758363</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Ambuj Shatdal, Chander Kant, and Jeffrey F. Naughton. Cache conscious algorithms for relational query processing. In 20th International Conference on Very Large Data Bases, 1994, pages 510--521, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>872813</ref_obj_id>
				<ref_obj_pid>872757</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Chengyu Sun, Divyakant Agrawal, and Amr El Abbadi. Hardware acceleration for spatial selections and joins. In ACM, editor, Proceedings of the 2003 ACM SIGMOD International Conference on Management of Data, pages 455--466, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>774894</ref_obj_id>
				<ref_obj_pid>774861</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[C. J. Thompson, S. Hahn, and M. Oskin. Using modern graphics architectures for general-purpose computing: A framework and analysis. Proc. of IEEE/ACM International Symposium on Microarchitectures, pages 306--317, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564709</ref_obj_id>
				<ref_obj_pid>564691</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Jingren Zhou and Kenneth A. Ross. Implementing database operations using simd instructions. In Proceedings of the 2002 ACM SIGMOD international conference on Management of data, pages 145--156. ACM Press, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Fast Computation of Database Operations using Graphics Processors Naga K. Govindaraju Brandon Lloyd 
Wei Wang Ming Lin Dinesh Manocha University of North Carolina at Chapel Hill {naga, blloyd, weiwang, 
lin, dm}@cs.unc.edu http://gamma.cs.unc.edu/DataBase ABSTRACT We present new algorithms for performing 
fast computation of several common database operations on commodity graphics processors. Speci.cally, 
we consider operations such as conjunctive selections, aggregations, and semi-linear queries, which are 
essential computational components of typical database, data warehousing, and data mining applications. 
While graphics processing units (GPUs) have been designed for fast display of geometric primitives, we 
utilize the inherent pipelining and parallelism, single instruction and multiple data (SIMD) capabilities, 
and vector processing functionality of GPUs, for evaluating boolean predicate combinations and semi-linear 
queries on attributes and executing database operations e.ciently. Our algorithms take into account 
some of the limitations of the programming model of current GPUs and perform no data rearrangements. 
Our algorithms have been implemented on a programmable GPU (e.g. NVIDIA s GeForce FX 5900) and applied 
to databases consisting of up to a million records. We have compared their performance with an optimized 
implementation of CPU-based algorithms. Our experiments indicate that the graphics processor available 
on commodity computer systems is an e.ective co-processor for performing database operations. Keywords: 
graphics processor, query optimization, selection query, aggregation, selectivity analysis, semi-linear 
query. 1. INTRODUCTION As database technology becomes pervasive, Database Management Systems (DBMSs) 
have been deployed in a wide variety of applications. The rapid growth of data volume for the past decades 
has intensi.ed the need for high-speed database management systems. Most database queries and, more recently, 
data warehousing and data mining applications, are very data-and computation-intensive and therefore 
demand high processing power. Researchers have actively sought to design and develop architectures and 
algo- Permission to make digital or hard copies of all or part of this work for personal or classroom 
use is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage, 
and that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, 
to post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. SIGMOD 
2004 June 13-18, 2004, Paris, France. Copyright 2004 ACM 1-58113-859-8/04/06 . . . $5.00. rithms for 
faster query execution. Special attention has been given to increase the performance of selection, aggregation, 
and join operations on large databases. These operations are widely used as fundamental primitives for 
building complex database queries and for supporting on-line analytic processing (OLAP) and data mining 
procedures. The e.ciency of these operations has a signi.cant impact on the performance of a database 
system. As the current trend of database architecture moves from disk-based system towards main-memory 
databases, applications have become increasingly computation-and memorybound. Recent work [3, 21] investigating 
the processor and memory behaviors of current DBMSs has demonstrated a signi.cant increase in the query 
execution time due to memory stalls (on account of data and instruction misses), branch mispredictions, 
and resource stalls (due to instruction dependencies and hardware speci.c characteristics). Increased 
attention has been given on redesigning traditional database algorithms for fully utilizing the available 
architectural features and for exploiting parallel execution possibilities, minimizing memory and resource 
stalls, and reducing branch mispredictions [2, 5, 20, 24, 31, 32, 34, 37]. 1.1 Graphics Processing Units 
In this paper, we exploit the computational power of graphics processing units (GPUs) for database operations. 
In the last decade, high-performance 3D graphics hardware has become as ubiquitous as .oating-point 
hardware. Graphics processors are now a part of almost every personal computer, game console, or workstation. 
In fact, the two major computational components of a desktop computer system are its main central processing 
unit (CPU) and its (GPU). While CPUs are used for general purpose computation, GPUs have been primarily 
designed for transforming, rendering, and texturing geometric primitives, such as triangles. The driving 
application of GPUs has been fast rendering for visual simulation, virtual reality, and computer gaming. 
GPUs are increasingly being used as co-processors to CPUs. GPUs are extremely fast and are capable of 
processing tens of millions of geometric primitives per second. The peak performance of GPUs has been 
increasing at the rate of 2.5 - 3.0 times a year, much faster than the Moore s law for CPUs. At this 
rate, the GPU s peak performance may move into the tera.op range by 2006 [19]. Most of this performance 
arises from multiple processing units and stream processing. The GPU treats the vertices and pixels constituting 
graphics primitives as streams. Multiple vertex and pixel processing engines on a GPU are connected via 
data .ows. These processing engines perform simple operations in parallel. Recently, GPUs have become 
programmable, allowing a user to write fragment programs that are executed on pixel processing engines. 
The pixel processing engines have direct access to the texture memory and can perform vector operations 
with .oating point arithmetic. These capabilities have been successfully exploited for many geometric 
and scienti.c applications. As graphics hardware becomes increasingly programmable and powerful, the 
roles of CPUs and GPUs in computing are being rede.ned.  1.2 Main Contributions In this paper, we present 
novel algorithms for fast computation of database operations on GPUs. The operations include predicates, 
boolean combinations, and aggregations. We utilize the SIMD capabilities of pixel processing engines 
within a GPU to perform these operations e.ciently. We have used these algorithms for selection queries 
on one or more attributes and generic aggregation queries including selectivity analysis on large databases. 
Our algorithms take into account some of the limitations of the current programming model of GPUs which 
make it di.cult to perform data rearrangement. We present novel algorithms for performing multi-attribute 
comparisons, semilinear queries, range queries, computing the kth largest number, and other aggregates. 
These algorithms have been implemented using fragment programs and have been applied to large databases 
composed of up to a million records. The performance of these algorithms depends on the instruction sets 
available for fragment programs, the number of fragment processors, and the underlying clock rate of 
the GPU. We also perform a preliminary comparison between GPUbased algorithms running on a NVIDIA GeForceFX 
5900 Ultra graphics processor and optimized CPU-based algorithms running on dual 2.8 GHz Intel Xeon 
processors. We show that algorithms for semi-linear and selection queries map very well to GPUs and we 
are able to obtain signi.cant performance improvement over CPU-based implementations. The algorithms 
for aggregates obtain a modest gain of 2 - 4 times speedup over CPU-based implementations. Overall, 
the GPU can be used as an e.ective co-processor for many database operations. 1.3 Organization The rest 
of the paper is organized as follows. We brie.y survey related work on database operations and use of 
GPUs for geometric and scienti.c computing in Section 2. We give an overview of the graphics architectural 
pipeline in Section 3. We present algorithms for database operations including predicates, boolean combinations, 
and aggregations in Section 4. We describe their implementation in Section 5 and compare their performance 
with optimized CPU-based implementations. We analyze the performance in Section 6 and outline the cases 
where GPU-based algorithms can o.er considerable gain over CPU-based algorithms.  2. RELATED WORK In 
this section, we highlight the related research in mainmemory database operations and general purpose 
computation using GPUs. 2.1 Hardware Accelerated Database Operations Many acceleration techniques 
have been proposed for database operations. Ailamaki et al. [3] analyzed the execution time of commercial 
DBMSs and observed that almost half of the time is spent in stalls. This indicates that the performance 
of a DBMS can be signi.cantly improved by reducing stalls. Meki and Kambayashi used a vector processor 
for accelerating the execution of relational database operations including selection, projection, and 
join [24]. To utilize the e.ciency of pipelining and parallelism that a vector processor provides, the 
implementation of each operation was redesigned for increasing the vectorization rate and the vector 
length. The limitation of using a vector processor is that the load-store instruction can have high latency 
[37]. Modern CPUs have SIMD instructions that allow a single basic operation to be performed on multiple 
data elements in parallel. Zhu and Ross described SIMD implementation of many important database operations 
including sequential scans, aggregation, indexed searches, and joins [37]. Considerable performance 
gains were achieved by exploiting the inherent parallelism of SIMD instructions and reducing branch 
mispredictions. Recently, Sun et al. present the use of graphics processors for spatial selections and 
joins [35]. They use color blending capabilities available on graphics processors to test if two polygons 
intersect in screen-space. Their experiments on graphics processors indicate a speedup of nearly 5 times 
on intersection joins and within-distance joins when compared against their software implementation. 
The technique focuses on pruning intersections between triangles based on their 2D overlap and is quite 
conservative. 2.2 General-Purpose Computing Using GPUs In theory, GPUs are capable of performing any 
computation that can be mapped to the stream-computing model. This model has been exploited for ray-tracing 
[29], global illumination [30] and geometric computations [22]. The programming model of GPUs is somewhat 
limited, mainly due to the lack of random access writes. This limitation makes it more di.cult to implement 
many data structures and common algorithms such as sorting. Purcell et al. [30] present an implementation 
of bitonic merge sort, where the output routing from one step to another is known in advance. The algorithm 
is implemented as a fragment program and each stage of the sorting algorithm is performed as one rendering 
pass. However, the algorithm can be quite slow for database operations on large databases. GPUs have 
been used for performing many discretized geometric computations [22]. These include using stencil bu.er 
hardware for interference computations [33], using depth-bu.er hardware to perform distance .eld and 
proximity computations [15], and visibility queries for interactive walkthroughs and shadow generation 
[12]. High throughput and direct access to texture memory makes fragment processors powerful computation 
engines for certain numerical algorithms, including dense matrix-matrix multiplication [18], general 
purpose vector processing [36], visual simulation based on coupled-map lattices [13], linear algebra 
operations [17], sparse matrix solvers for conjugate gradient and multigrid [4], a multigrid solver for 
boundary value problems [11], geometric computations [1, 16], etc.  3. OVERVIEW In this section, we 
introduce the basic functionality available on GPUs and give an overview of the architectural pipeline. 
More details are given in [9]. 3.1 Graphics Pipeline A GPU is designed to rapidly transform the geometric 
description of a scene into the pixels on the screen that constitute a .nal image. Pixels are stored 
on the graphics card in a frame-bu.er. The frame bu.er is conceptually divided into three bu.ers according 
to the di.erent values stored at each pixel: Color Bu.er: Stores the color components of each pixel 
in the frame-bu.er. Color is typically divided into red, green, and blue channels with an alpha channel 
that is used for blending e.ects.  Depth Bu.er: Stores a depth value associated with each pixel. The 
depth is used to determine surface visibility.  Stencil Bu.er: Stores a stencil value for each pixel. 
It is called the stencil bu.er because it is typically used for enabling/disabling writes to portions 
of the frame-bu.er.  Figure 1: Graphics architectural pipeline overview: This .gure shows the various 
units of a modern GPU. Each unit is designed for performing a speci.c operation e.ciently. The transformation 
of geometric primitives (points, lines, triangles, etc.) to pixels is performed by the graphics pipeline, 
consisting of several functional units, each optimized for performing a speci.c operation. Fig 1 shows 
the various stages involved in rendering a primitive. Vertex Processing Engine: This unit receives vertices 
as input and transforms them to points on the screen.  Setup Engine: Transformed vertex data is streamed 
to the setup engine which generates slope and initial value information for color, depth, and other parameters 
associated with the primitive vertices. This information is used during rasterization for constructing 
fragments at each pixel location covered by the primitive.  Pixel Processing Engines: Before the fragments 
are written as pixels to the frame bu.er, they pass through the pixel processing engines or fragment 
processors. A series of tests can be used for discarding a  fragment before it is written to the frame 
bu.er. Each test performs a comparison using a user-speci.ed relational operator and discards the fragment 
if the test fails. Alpha test: Compares a fragment s alpha value to a user-speci.ed reference value. 
 Stencil test: Compares the stencil value of a fragment s corresponding pixel with a user-speci.ed reference 
value.  Depth test: Compares the depth value of a fragment to the depth value of the corresponding 
pixel in the frame bu.er.  The relational operator can be any of the following : =, <, >, :, 2, and 
.In addition, there are two operators, never =. and always, that do not require a reference value. Current 
generations of GPUs have a pixel processing engine that is programmable. The user can supply a custom 
fragment program to be executed on each fragment. For example, a fragment program can compute the alpha 
value of a fragment as a complex function of the fragment s other color components or its depth. 3.2 
Visibility and Occlusion Queries Current GPUs can perform visibility and occlusion queries [27]. When 
a primitive is rasterized, it is converted to fragments. Some of these fragments may or may not be written 
to pixels in the frame bu.er depending on whether they pass the alpha, stencil and depth tests. An occlusion 
query returns the pixel pass count, the number of fragments that pass the di.erent tests. We use these 
queries for performing aggregation computations (see Section 4). 3.3 Data Representation on the GPUs 
Our goal is to utilize the inherent parallelism and vector processing capabilities of the GPUs for database 
operations. A key aspect is the underlying data representation. Data is stored on the GPU as textures. 
Textures are 2D arrays of values. They are usually used for applying images to rendered surfaces. They 
may contain multiple channels. For example, an RGBA texture has four color channels red, blue, green 
and alpha. A number of di.erent data formats can be used for textures including 8-bit bytes, 16-bit 
integers, and .oating point. We store data in textures in the .oating-point format. This format can precisely 
represent integers up to 24 bits. To perform computations on the values stored in a texture, we render 
a single quadrilateral that covers the window. The texture is applied to the quadrilateral such that 
the individual elements of the texture, texels, line up with the pixels in the frame-bu.er. Rendering 
the textured quadrilateral causes a fragment to be generated for every data value in the texture. Fragment 
programs are used for performing computations using the data value from the texture. Then the alpha, 
stencil, and depth tests can be used to perform comparisons. 3.4 Stencil Tests Graphics processors 
use stencil tests for restricting computations to a portion of the frame-bu.er based on the value in 
the stencil bu.er. Abstractly, we can consider the stencil bu.er as a mask on the screen. Each fragment 
that enters the pixel processing engine corresponds to a pixel in the frame-bu.er. The stencil test compares 
the stencil value of a fragment s corresponding pixel against a reference value. Fragments that fail 
the comparison operation are rejected from the rasterization pipeline. Stencil operations can modify 
the stencil value of a fragment s corresponding pixel. Examples of such stencil operations include 
 KEEP: Keep the stencil value in stencil bu.er. We use this operation if we do not want to modify the 
stencil value.  INCR: Increment the stencil value by one.  DECR: Decrement the stencil value by one. 
 ZERO: Set the stencil value to zero.  REPLACE: Set the stencil value to the reference value.  INVERT: 
Bitwise invert the stencil value.  For each fragment there are three possible outcomes based on the 
stencil and depth tests. Based on the outcome of the tests, the corresponding stencil operation is performed: 
 Op1: when a fragment fails the stencil test,  Op2: when a fragment passes the stencil test and fails 
the depth test,  Op3: when the fragment passes the stencil and depth tests.  We illustrate these operations 
with the following pseudocode for the StencilOp routine: StencilOp( Op1, Op2, Op3) if (stencil test 
passed) /* perform stencil test */ /* fragment passed stencil test */ if(depth test passed) /* perform 
depth test */ /* fragment passed stencil and depth test */ perform Op3 on stencil value else /* fragment 
passed stencil test */ /* but failed depth test */ perform Op2 on stencil value end if else /* fragment 
failed stencil test */ perform Op1 on stencil value end if  4. BASIC DATABASE OPERATIONS USING GPUS 
In this section, we give a brief overview of basic database operations that are performed e.ciently on 
a GPU. Given a relational table T of m attributes (a1,a2, ..., am), a basic SQL query is in the form 
of SELECT A FROM T WHERE C  where A may be a list of attributes or aggregations (SUM, COUNT, AVG, MIN, 
MAX) de.ned on individual attributes, and C is a boolean combination (using AND, OR, EXIST, NOT EXIST) 
of predicates that have the form ai op aj or ai op constant. The operator op may be any of the following: 
=, .=, >, 2, <, :. In essence, queries speci.ed in this form involve three categories of basic operations: 
predicates, boolean combinations, and aggregations. Our goal is to design e.cient algorithms for performing 
these operations using graphics processors. Predicates: Predicates in the form of ai op constant can 
be evaluated via the depth test and stencil test. The comparison between two attributes, ai op aj , can 
be transformed into a semi-linear query ai - aj op 0, which can be executed on the GPUs.  Boolean combinations: 
A boolean combination of predicates can always be rewritten in a conjunctive normal form (CNF). The 
stencil test can be used repeatedly for evaluating a series of logical operators with the intermediate 
results stored in the stencil bu.er.  Aggregations: This category includes simple operations such as 
COUNT, SUM, AVG, MIN, MAX, all of which can be implemented using the counting capability of the occlusion 
queries on GPUs.  To perform these operations on a relational table using GPUs, we store the attributes 
of each record in multiple channels of a single texel, or the same texel location in multiple textures. 
4.1 Predicate Evaluation In this section, we present novel GPU-based algorithms for performing comparisons 
as well as the semi-linear queries. 4.1.1 Comparison between an Attribute and a Constant We can implement 
a comparison between an attribute tex and a constant d by using the depth test functionality of graphics 
hardware. The stencil bu.er can be con.gured to store the result of the depth test. This is important 
not only for evaluating a single comparison but also for constructing more complex boolean combinations 
of multiple predicates. To use the depth test for performing comparisons, attribute values need to be 
stored in the depth bu.er. We use a simple fragment program for copying the attribute values from the 
texture memory to the depth bu.er. A comparison operation against a depth value d is implemented by 
rendering a screen .lling quadrilateral with depth d. In this operation, the rasterization hardware uses 
the comparison function for testing each attribute value stored in the depth bu.er against d. The comparison 
function is speci.ed using the depth function. Routine 4.1 describes the pseudo-code for our implementation. 
 4.1.2 Comparison between Two Attributes The comparison between two attributes, ai op aj , can be transformed 
into a special semi-linear query (ai - aj op 0), which can be performed very e.ciently using the vector 
processors on the GPUs. Here, we propose a fast algorithm that can perform any general semi-linear query 
on GPUs. Compare( tex, op, d ) 1 CopyToDepth( tex ) 2 set depth test function to op 3 RenderQuad(d) 
CopyToDepth( tex ) 1 set up fragment program 2 RenderTexturedQuad( tex ) ROUTINE 4.1: Compare compares 
the attribute values stored in texture tex against d using the comparison function op. CopyToDepth called 
on line 1 copies the attribute values in tex into the depth bu.er. CopyToDepth uses a simple fragment 
program on each pixel of the screen for performing the copy operation. On line 2, the depth test is 
con.gured to use the comparison operator op. The function RenderQuad(d) called on line 3 generates a 
fragment at a speci.ed depth d for each pixel on the screen. Rasterization hardware compares the fragment 
depth d against the attribute values in depth bu.er using the operation op. Semi-linear Queries on GPUs 
Applications encountered in Geographical Information Systems (GIS), geometric modeling, and spatial 
databases de.ne geometric data objects as linear inequalities of the attributes in a relational database 
[28]. Such geometric data objects are called semi-linear sets. GPUs are capable of fast computation on 
semi-linear sets. A linear combination of m attributes is represented as: i=m . si  ai i=1 where each 
si is a scalar multiplier and each ai is an attribute of a record in the database. The above expression 
can be considered as a dot product of two vectors s and a where s =(s1,s2, ..., sm) and a =(a1,a2, ..., 
am). Semilinear( tex, s, op, b ) 1 enable fragment program SemilinearFP(s, b) 2 RenderTexturedQuad( tex 
) SemilinearFP( s, op, b) 1 a = value from tex 2 if dot( s, a) op b 3 discard fragment ROUTINE 4.2: 
Semilinear computes the semi-linear query by performing linear combination of attribute values in tex 
and scalar constants in s. Using the operator op, it compares the the scalar value due to linear combination 
with b. To perform this operation, we render a screen .lling quad and generate fragments on which the 
semi-linear query is executed. For each fragment, a fragment program SemilinearFP discards fragments 
that fail the query. Semilinear computes the semi-linear query: (s  a) op b where op is a comparison 
operator and b is a scalar constant. The attributes ai are stored in separate channels in the texture 
tex. There is a limit of four channels per texture. Longer vectors can be split into multiple textures, 
each with four components. The fragment program SemilinearFP() performs the dot product of a texel from 
tex with s and compares the result to b. It discards the fragment if the comparison fails. Line 2 renders 
a textured quadrilateral using the fragment program. Semilinear maps very well to the parallel pixel 
processing as well as vector processing capabilities available on the GPUs. This algorithm can also be 
extended for evaluating polynomial queries. EvalCNF( A ) 1 Clear Stencil to 1. 2 For each of Ai, i =1, 
.., k 3 do 4 if( mod(i, 2) ) /* valid stencil value is 1 */ 5 Stencil Test to pass if stencil value is 
equal to 1 6 StencilOp(KEEP,KEEP,INCR) 7 else /* valid stencil value is 2 */ 8 Stencil Test to pass if 
stencil value is equal to 2 9 StencilOp(KEEP,KEEP,DECR) 10 endif 11 For each Bji , j =1, .., mi 12 do 
13 Perform Bji using Compare 14 end for 15 if( mod(i, 2)) /* valid stencil value is 2 */ 16 if a stencil 
value on screen is 1, replace it with 0 17 else /* valid stencil value is 1 */ 18 if a stencil value 
on screen is 2, replace it with 0 19 endif 20 end for ROUTINE 4.3: EvalCNF is used to evaluate a CNF 
expression. Initially, the stencil is initialized to 1. This is used for performing TRUE AND A1. While 
evaluating each formula Ai, Line 4 sets the appropriate stencil test and stencil operations based on 
whether i is even or odd. If i is even, valid portions on screen have stencil value 2. Otherwise, valid 
portions have stencil value 1. Lines 11 - 14 invalidate portions on screen that satisfy (A1 ! A2 ! ... 
! Ai-1) and fail (A1 ! A2 ! ... ! Ai). Lines 15 - 19 compute the disjunction of Bji for each predicate 
Ai. At the end of line 19, valid portions on screen have stencil value 2 if i is odd and 1, otherwise. 
At the end of the line 20, records corresponding to non-zero stencil values satisfy A.  4.2 Boolean 
Combination Complex boolean combinations are often formed by combining simple predicates with the logical 
operators AND, OR, NOT. In these cases, the stencil operation is speci.ed to store the result of a predicate. 
We use the function StencilOp (as de.ned in Section 3.4) to initialize the appropriate stencil operation 
for storing the result in stencil bu.er. Our algorithm evaluates a boolean expression represented as 
a CNF expression. We assume that the CNF expression has no NOT operators. If a simple predicate in this 
expression has a NOT operator, we can invert the comparison operation and eliminate the NOT operator. 
A CNF expression Ck is represented as A1 1 A2 1 ... 1 Ak where each Ai is represented as B1 i = B2 i 
= ... = Bi . Each Bji ,j =1, 2, .., mi mi is a simple predicate. The CNF Ck can be evaluated using the 
recursion Ck = Ck-1 1 Ak. C0 is considered as T RUE. We use the pseudocode in routine 4.3 for evaluating 
Ck. Our approach uses three stencil values 0, 1, 2 for validating data. Data values corresponding to 
the stencil value 0 are always invalid. Initially, the stencil values are initialized to 1. If i is 
the iteration value for the loop in line 2, lines 3 - 19 evaluate Ci. The valid stencil value is 1 or 
2 depending on whether i is even or odd respectively. At the end of line 19, portions on the screen with 
non-zero stencil value satisfy the CNF Ck. We can easily modify our algorithm for handling a boolean 
expression represented as a DNF. Range Queries A range query is a common database query expressed as 
a boolean combination of two simple predicates. If [low, high] is the range for which an attribute x 
is queried, we can evaluate the expression (x 2 low) AND (x : high) using Eval-CNF. Recent GPUs provide 
a feature GL EXT Depth bounds test [8], useful in accelerating shadow algorithms. Our algorithm uses 
this feature for evaluating a range query e.ciently. The pseudo-code for our algorithm Range is given 
in Routine 4.4. Although a range query requires the evaluation of two simple predicates, the computational 
time for our algorithm in evaluating Range is comparable to the time required in evaluating a single 
predicate. Range( tex, low, high ) 1 SetupStencil() 2 CopyToDepth( tex ) 3 Set depth bounds based on 
[low, high] 4 Enable depth bounds test 5 RenderQuad(low) 6 Disable depth bounds test ROUTINE 4.4: SetupStencil 
is called on line 1 to enable selection using the stencil bu.er. CopyToDepth called on line 2 copies 
the attribute values in tex into the depth bu.er. Line 3 sets the depth bounds based on [low, high]. 
The attribute values copied into the depth bu.er and falling within the depth bounds pass the depth bounds 
test. Lines 4 - 6 perform the depth bounds test. The stencil is set to 1 for the attributes passing the 
range query and 0 for the other.  4.3 Aggregations Several database operations aggregate attribute values 
that satisfy a condition. On GPUs, we can perform these operations using occlusion queries to return 
the count of records satisfying some condition. 4.3.1 COUNT Using an occlusion query for counting the 
number of records satisfying some condition involves three steps: 1. Initialize the occlusion query 
2. Perform the boolean query 3. Read back the result of the occlusion query into COUNT   4.3.2 MIN 
and MAX The query to .nd the minimum or maximum value of an attribute is a special case of the kth largest 
number. Here, we present an algorithm to generate the kth largest number. k-th Largest Number Computing 
the k-th largest number occurs frequently in several applications. We can utilize expected linear time 
selection algorithms such as QuickSelect [14] to compute the k-th largest number. Most of these algorithms 
require data rearrangement, which is extremely expensive on current GPUs because there is no functionality 
for data writes to arbitrary locations. Also, these algorithms require evaluation of conditionals and 
may lead to branch mispredictions on the CPU. We present a GPU-based algorithm that does not require 
data rearrangement. In addition, our algorithm exhibits SIMD characteristics that exploit the inherent 
parallelism available on the GPUs. Our algorithm utilizes the binary data representation for computing 
the k-th largest value in time that is linear in the number of bits. KthLargest( tex, k ) 1 b max = maximum 
number of bits in the values in tex 2 x=0 3 fori =bmax-1downto0 4 count = Compare( tex, 2, x +2i ) 5 
if count > k-1 6 x=x+2i 7 return x ROUTINE 4.5: KthLargest computes the k-th largest attribute value 
in texture tex. It uses b max passes starting from the MSB to compute the k-th largest number. During 
a pass i, it determines the i-th bit of the k-th largest number. At the end of b max passes, it computes 
the k-th largest number in x. The pseudocode for our algorithm KthLargest is shown in routine 4.5. KthLargest 
constructs in x the value of the k-th largest number one bit at a time starting with the most signi.cant 
bit (MSB), b max-1. As an invariant, the value of x is maintained less than or equal to the k-th largest 
value. Line 4 counts the number of values that are greater than or equal to x+2i, the tentative value 
of x with the ith bit set. This count is used for deciding whether to set the bit in x according to the 
following lemma: Lemma 1: Let vk be the k-th largest number in a set of values. Let count be the number 
of values greater than or equal to a given value m. if count > k - 1: m : vk  if count : (k - 1) : 
m>vk  Proof: Trivial. If count >k - 1 then the tentative value of x is smaller than the k-th largest 
number. In this case, we set x to the tentative value on line 6. Otherwise the tentative value is too 
large so we leave x unchanged. At the end of line 6, if the loop iteration is i, the .rst i bits from 
MSB of x and vk are the same. After the last iteration of the loop, x has the value of the k-th largest 
number. The algorithm for the k-th smallest number is the same, except that the comparison in line 5 
is inverted. 4.3.3 SUM and AVG An accumulator is used to sum a set of data values. One way of implementing 
an accumulator on current GPUs is using a mipmap of a .oating point texture. Mipmaps are multi-resolution 
textures consisting of multiple levels. The highest level of the mipmap contains the average of all the 
values in the lowest level, from which it is possible to recover the sum by multiplying the average 
with the number of values. A fragment program must be used to create a .oating-point mipmap. Computing 
a .oating-point mipmap on current GPUs tends to be problematic for three reasons. Firstly, reading and 
writing .oating-point textures can be slow. Secondly, if we are interested in the sum of only a subset 
of values, e.g. those that are greater than a given number, then introduce conditionals in the fragment 
program. Finally, the .oating point representation may not have enough precision to give an exact sum. 
Our accumulator algorithm avoids some of the problems of the mipmap method. We perform only texture reads 
which are more e.cient than texture writes. Moreover, we calculate the precise sum to arbitrary precision 
and avoid conditionals in the fragment program. One limitation of the algorithm is that it works only 
on integer datasets, although it can easily be extended to handle .xed-point datasets. Accumulator( tex 
) 1 alpha test = pass with alpha 2 0.5 2 sum = 0 3 for i = 0 to b max do 4 enable fragment program TestBit(i) 
5 initialize occlusion query 6 RenderTexturedQuad( tex ) 7 count = pixel count from occlusion query 8 
sum + = count *2i 9 return sum TestBit(i) 1 v = value from tex 2 fragment alpha = frac(v /2(i+1)) ROUTINE 
4.6: Accumulator computes the sum of attribute values in texture tex. It performs b max passes to compute 
the sum. Each pass computes the number of values with i-th bit set and stores it in count. This count 
is multiplied with 2i and added to sum. At the end of the b max passes, the variable sum aggregates 
all the data values in the texture. Accumulator sums the values stored in the texture tex utilizing the 
binary data representation. The sum of the values xj in a set X can be written as: |X||X| k . .. i xj 
= aij 2j=0 j=0 i=0 where aij ={0, 1} are the binary digits of xj and k is the maximum number of bits 
used to represent the values in X. Currently, no e.cient algorithms are known for summing the texels 
on current GPUs. We can, however, quickly determine the number of texels for which a particular bit 
i is set. If we reverse the order of the summations, we get an expression that is more amenable to GPU 
computation: k |X| .. i 2 aij. i=0 j=0 The inner summation is simply the number of xj that have the 
ith bit set. This summation is the value of count calculated on lines 4-6 where we render a quad textured 
with tex. The fragment program TestBit ensures that only fragments corresponding to texels with the 
ith bit set pass the alpha test. Determining whether a particular bit is set is trivial with bit-masking 
operations. Since current GPUs do not support bit-masking operations in fragment programs, we use an 
alternate approach. We observe that an integer x has its ith bit equal to 1 if and only if the fractional 
part of x/2i+1 is at least 0.5. In TestBit, we divide each value by 2i+1 and put the fractional part 
of the result into the alpha channel. We use the alpha test for rejecting fragments with alpha less than 
0.5. It is possible to perform the comparison and reject fragments directly in the fragment program, 
but it is faster in practice to use the alpha test. Pseudocode for our algorithm is shown in the routine 
4.6. Accumulator can be used for summing only a subset of the records in tex that have been selected 
using the stencil bu.er. Attributes that are not selected fail the stencil test and thus make no contribution 
to the .nal sum. We use the Accumulator algorithm to obtain SUM. AVG is obtained by computing SUM and 
COUNT, and computed as AVG = SUM/COUNT.   5. IMPLEMENTATION &#38; PERFORMANCE We have implemented and 
tested our algorithms on a high end Dell Precision Workstation with dual 2.8GHz Intel Xeon Processors 
and an NVIDIA GeForceFX 5900 Ultra graphics processor. The graphics processor has 256MB of video memory 
with a memory data rate of 950MHz and can process upto 8 pixels at processor clock rate of 450 MHz. 
This GPU can perform single-precision .oating point operations in fragment programs. 5.1 Benchmarks For 
our benchmarks, we have used a database consisting of TCP/IP data for monitoring tra.c patterns in local 
area network and wide area network and a census database [6] consisting of monthly income information. 
In the TCP/IP database, there are one million records in the database. In our experiments, each record 
has 4 attributes, (data count, data loss, f low rate, retransmissions). Each attribute in the database 
is stored in as a .oatingpoint number encoded in a 32 bit RGBA texture. The video memory available on 
the NVIDIA GeForce FX 5900 graphics processor can store more than 50 attributes, each in a texture of 
size 1000  1000, amounting to a total of 50 million values in the database. We transfer textures from 
the CPU to the graphics processor using an AGP 8X interface. The census database consists of 360K records. 
We used four attributes for each record of this database. We have benchmarked our algorithms using the 
TCP/IP database. Our performance results on the census data are consistent with the results obtained 
on the TCP/IP database. 5.2 Optimized CPU Implementation We implemented the algorithms described in 
section 4 and compared them with an optimized CPU implementation. We compiled the CPU implementation 
using Intel compiler 7.1 with full compiler optimizations 1 . These optimizations include Vectorization: 
The compiler detects sequential data scans and generates code for SIMD execution.  Multi-threading: 
We used the compiler switch -QParallel to detect loops which may bene.t from multithreaded execution 
and generate appropriate threading calls. This option enables the CPU implementation to utilize hyper-threading 
technology available on Xeon processors.  Inter-Procedural Optimization (IPO): The compiler performs 
function inlining when IPO is enabled. It reduces the function call branches, thus improving its e.ciency. 
  For the timings, we ran each of our tests 100 times and computed the average running time for the 
test. 1 http://www.intel.com/software/products/compilers/ techtopics/compiler_optimization_71.pdf Figure 
5: Execution time of a multi cate evaluation with 60% selectivity by a query with 60% selectivity using 
a GPU attribute query with 60% selectivity for CPU-based and a GPU-based algorithm. based and a CPU-based 
algorithm. Tim each attribute and a combination of Timings for the GPU-based algorithm ings for the 
GPU-based algorithm in- AND operator. Timei is the time to per include time to copy data values into 
the clude time to copy data values into the form a query with i attributes. We show depth bu.er. Considering 
only compu-depth bu.er. Considering only compu the timings for CPU and GPU-based im tation time, the 
GPU is nearly 20 times tation time, the GPU is nearly 40 times plementations. faster than a compiler-optimized 
SIMD faster than a compiler-optimized SIMD implementation. implementation. Figure 2: Plot indicating 
the time taken for copying data values in a texture to the depth bu.er.  5.3 GPU Implementation Our 
algorithms described in Section 4 are implemented using the OpenGL API. For generating the fragment programs, 
we used NVIDIA s CG compiler [23]. As the code generated by the compiler is often sub-optimal, we examined 
the assembly code generated by the current compiler and reduced the number of assembly instructions to 
perform the same operation. For the counting operations, we chose to use GL NV occlusion query for image-space 
occlusion queries. These queries can be performed asynchronously and often do not add any additional 
overhead.  5.4 Copy Operation Various database operations, such as comparisons, selection, etc, require 
the data values of an attribute stored in the depth bu.er. For these operations, we copy the corresponding 
texture into the depth bu.er. A fragment program is used to perform the copy operation. Our copy fragment 
program implementation requires three instructions. 1. Texture Fetch: We fetch the texture value corresponding 
to a fragment. 2. Normalization: We normalize the texture value to the range of valid depth values [0, 
1]. 3. Copy To Depth: The normalized value is copied into the fragment depth.  Figure 2 shows the time 
taken to copy values from textures of varying sizes into the depth bu.er. The .gure indicates an almost 
linear increase in the time taken to perform the copy operation as a function of the number of records. 
In the future, it may be possible to copy data values from textures directly to a depth bu.er and that 
would reduce these timings considerably. Also, the increase in clock rates of graphics processors and 
improved optimizations to perform depth bu.er writes [26] could help in reducing these timings.  5.5 
Predicate Evaluation Figure 3 shows a plot of the time taken to compute a single predicate for an attribute 
such that the selectivity is 60%. In our experiments, we performed the operation on the .rst attribute 
of each record in the database. The plot compares a compiler-generated SIMD optimized CPU code against 
a simple GPU implementation. The GPU timings include the computational time for evaluating the predicate, 
as well as the time taken to copy the attribute into the depth bu.er. We observe that the GPU timings 
are nearly 3 times faster than the CPU timings. If we compare only the computational time on the GPU, 
we observe that the GPU implementation is nearly 20 times faster than the SIMD optimized CPU implementation. 
 5.6 Range Query We tested the performance of Range by timing a range query with 60% selectivity. To 
ensure 60% selectivity, we set the valid range of values between the 20th percentile and 80th percentile 
of the data values. Again, in our tests, we used the data count as our attribute. Figure 4 compares 
the time taken for a simple GPU implementation and a compiler-optimized SIMD implementation on CPU. In 
the GPU timings, we included the time taken for the copy operation. We observe that overall the GPU 
is nearly 5.5 times faster than the CPU implementation. If we consider only the computational time on 
GPU and CPU, we observe that the GPU is nearly 40 times faster than the compiler optimized CPU implementation. 
 5.7 Multi-Attribute Query We have tested the performance of our hardware-based multi-attribute queries 
by varying the number of attributes and also the number of records in the database. We used queries with 
a selectivity of 60% for each attribute and applied the AND operator on the result for each attribute. 
In Figure 7: Time to compute k-th largest Figure 8: Time taken to compute the Figure 9: Time taken 
to compute the number on the data count attribute. We median using KthLargest and QuickS-K-th largest 
number by the two imple used a portion of the TCP/IP database elect on varying number of records. mentations. 
with nearly 250K records. Figure 6: Execution time of a semi-linear query using four attributes of the 
TCP/IP database. The GPU-based implementation is almost one order of magnitude faster than the CPU-based 
implementation. our tests, we used up to four attributes per query. For each attribute in the query, 
the GPU implementation copies the data values from the attribute s texture to the frame-bu.er. Figure 
5 shows the time taken by the GPU and CPU respectively, to perform multi-attribute queries with the 
varying number of attributes and records. The timings indicate that the GPU implementation is nearly 
2 times faster than the CPU implementation. If we consider only the computational times on the GPU by 
ignoring copy times, we observe that the GPU is nearly 20 times faster than the optimized CPU implementation. 
 5.8 Semi-linear Query We performed a semi-linear query on the four attributes by using a linear combination 
of four random .oating-point values and compared it against an arbitrary value. Figure 6 summarize our 
timings for various number of tests on GPU and CPU. In our tests, we observe that the GPU timings are 
9 times faster than an optimized CPU implementation.  5.9 K-th Largest Number We performed three di.erent 
tests to evaluate our Kth-Largest algorithm on GPU. In each of these tests, we compared KthLargest against 
a CPU implementation of the algorithm QuickSelect [14]. In our experiments, we used the data count attribute. 
This attribute requires 19 bits to represent the largest data value and has a high variance. Test 1: 
Vary k and compute the time taken for Kth-Largest and QuickSelect. The tests were performed on 250K records 
in the database. Figure 7 shows the timings obtained using each of the implementations. This plot indicates 
that time taken by KthLargest is constant irrespective of the value of k and is an interesting characteristic 
of our algorithm. On an average, the GPU timings for our algorithm are nearly twice as fast in comparison 
to the CPU implementation. It should be noted that the GPU timings include the time taken to copy values 
into the depth bu.er. Comparing the computational times, we note that the average KthLargest timings 
are 3 times faster than QuickSelect. Test 2: In these tests, we compared the time taken by KthLargest 
and QuickSelect to compute a median of a varying number of records. Figure 8 illustrates the results 
of our experiments. We observe that the KthLargest on the GPU is nearly twice as fast as QuickSelect 
on the CPU. Considering only the computational times, we observe that KthLargest is nearly 2.5 times 
faster than QuickSelect. Test 3: We also compared the time taken by KthLargest and QuickSelect for computing 
a median with on data values with 80% selectivity. Figure 9 indicates the time taken by KthLargest and 
QuickSelect in computing the median as a function of the number of records. Our timings indicate that 
KthLargest with 80% selectivity requires exactly the same amount of time as performing KthLargest with 
100% selectivity. We conclude from this observation that the use of a conditional to test for valid data 
has almost no e.ect on the running time of KthLargest. For the CPU timings, we have copied the valid 
data into an array and passed it as a parameter to QuickSelect. The timings indicate that the total running 
time is nearly the same as that of running QuickSelect with 100% selectivity.  5.10 Accumulator Figure 
10 demonstrates the performance of Accumulator on the GPU and a compiler-optimized SIMD implementation 
of accumulator on the CPU. Our experiments indicate that our GPU algorithm is nearly 20 times slower 
than the CPU implementation, when including the copy time. Note that the CPUs have a much higher clock 
rate as compared to the GPU. 5.11 Selectivity Analysis Recently, several algorithms have been designed 
to implement join operations e.ciently using selectivity estimation [7, 10]. We compute the selectivity 
of a query using the COUNT algorithm (Section 4.3). To obtain the selectivity count, image-space occlusion 
queries are used. We performed the experiments described in Sections 5.5, 5.6, 5.7, 5.8. We observed 
that there is no additional overhead in obtaining the count of selected queries. Given selected data 
values scattered over a 1000  1000 frame-bu.er, we can obtain the number of selected values within 0.25 
ms.   6. ANALYSIS In the previous section, we have highlighted the performance of our algorithms on 
di.erent database operations and performed a preliminary comparison with some CPUbased algorithms. In 
this section, we analyze the performance of our algorithms and highlight the database operations for 
which the GPUs can o.er considerable gain in performance. 6.1 Implementing Basic Operations on GPUs 
There are many issues that govern the performance of the algorithms implemented on a GPU. Some of the 
upcoming features in the next generation GPUs can improve the performance of these algorithms considerably. 
Precision: Current GPUs have depth bu.ers with a maximum of 24 bits. This limited precision can be an 
issue. With the increasing use of GPUs in performing scienti.c computing, graphics hardware developers 
may add support for higher-precision depth bu.ers. Copy Time: Several of our algorithms require data 
values to be copied from the texture memory to the depth bu.er. Current GPUs do not o.er a mechanism 
to perform this operation e.ciently and this operation can take a signi.cant fraction of the overall 
algorithm (e.g. algorithms for relational and range queries). In the future, we can expect support for 
this operation on GPUs which could improve the overall performance. Integer Arithmetic Instructions: 
Current GPUs do not o.er integer arithmetic instructions in the pixel processing engines. In addition 
to database operations, several image and video compression algorithms also require the use of integer 
arithmetic operations. Fragment programs were introduced in just the last few years. The instruction 
sets for these programs are still being enhanced. The instructions for integer arithmetic would reduce 
the timings of our Accumulator algorithm signi.cantly. Depth Compare Masking: Current GPUs support a 
boolean depth mask that enables or disables writes to a depth bu.er. It is very useful to have a comparison 
mask speci.ed for the depth function, similar to that speci.ed in the stencil function. Such a mask 
would make it easier to test if a number has i-th bit set. Memory Management: Current high-end GPUs have 
up to 512MB of video memory and this limit is increasing every year. However, due to the limited video 
memory, we may not be able to copy very large databases (with tens of millions of records) into GPU memory. 
In such situations, we would use out-of-core techniques and swap textures in and out of video memory. 
Another related issue is the bus bandwidth. Current PCs use an AGP8 bus to transfer data from the CPU 
to the GPU and the PCI bus from the GPU to the CPU. With the announcement of PCI-EXPRESS bus, the bus 
bandwidth is going to improve signi.cantly in the near future. Asynchronous data transfers would also 
improve the performance of these algorithms. No Branching: Current GPUs implement branching by evaluating 
both portions of the conditional statement. We overcome this issue by using multi-pass algorithms and 
evaluating the branch operation using the alpha test or the depth test. No Random Writes: GPUs do not 
support random access writes, which makes it harder to develop algorithms on GPUs because they cannot 
use data rearrangement on GPUs.  6.2 Relative Performance Gain We have presented algorithms for predicates, 
boolean combinations and aggregations. We have also performed preliminary comparison with optimized 
CPU-based implementations on a workstation with dual 2.8 GHz Xeon processors. Due to di.erent clock 
rates and instruction sets, it is di.cult to perform explicit comparisons between CPU-based and GPU-based 
algorithms. However, some of our algorithms perform better than others. We classify our algorithms into 
three categories: high performance gain, medium performance gain and low performance gain. 6.2.1 High 
Performance Gain In these algorithms, we have observed an order of magnitude speedup over CPU-based 
implementations. These include algorithms for semi-linear queries and selection queries. The main reason 
for the improved performance are: Parallel Computation: GPUs have several pixel processing engines that 
process multiple pixels in parallel. For example, on a GeForce FX 5900 Ultra we can process 8 pixels 
in parallel and reduce the computational time signi.cantly. Also, each pixel processing engine has vector 
processing capabilities and can perform vector operations very e.ciently. The speedup in selection queries 
is mainly due to the parallelism available in pixel processing engines. The semi-linear queries also 
exploit the vector processing capabilities.  Pipelining: GPUs are designed using a pipelined architecture. 
As a result, they can simultaneously process multiple primitives within the pipeline. The algorithms 
for handling multiple-attribute queries map well to the pipelined implementation.  Early Depth-Culling: 
GPUs have specialized hardware that early in the pipeline can reject fragments that will not pass the 
depth test. Since the fragments do not have to pass through the pixel processing engines, this can lead 
to a signi.cant performance increase.  Eliminate branch mispredictions: One of the major advantages 
in performing these selection queries on GPUs is that there are no branch mispredictions.  Branch mispredictions 
can be extremely expensive on the modern CPUs. Modern CPUs use specialized schemes for predicting the 
outcome of the branch instruction. Each branch mis-prediction can cost several clock cycles on current 
CPUs. For example, on a Pentium IV a branch misprediction can have a penalty of 17 clock cycles [25]. 
 6.2.2 Medium Performance Gain Several of our algorithms for database operations are only able to use 
a subset of the capabilities of the GPUs. In these cases, we have observed a speedup of nearly a factor 
of 2 to 4 times in comparison to an optimized-CPU implementation. For example, the KthLargest() routine 
exhibits these characteristics. The speedup in the KthLargest() is mainly due to the parallelism available 
in pixel processing engines. Given the GPU clock rate and the number of pixel processing engines, we 
can estimate the time taken to perform KthLargest() under some assumptions. We assume that there is 
no latency in the graphics pipeline and in transmitting the pixel pass count from the GPU to the CPU. 
On a GeForce FX 5900 Ultra with clock rate 450MHz and processing 8 pixels per clock cycle, we can render 
a single quad of size 1000 1000 in 0.278 ms. In our experiments, we render 19 such quads to compute 
the k-th largest number. Rendering these quads should take 5.28 ms. The observed time for this computation 
is 6.6 ms, which indicates that we are utilizing nearly 80% of the parallelism in the pipeline. The observed 
timings are slightly higher due to the latencies in transmitting the data from the GPU to the CPU and 
viceversa. A key advantage of our algorithm KthLargest() in comparison with other parallel order statistic 
algorithms is that it does not require any data rearrangement. Data rearrangements can be expensive 
when combined with branching.  6.2.3 Low Performance Gain In some cases, we did not observe any gain 
over a CPUbased implementation. Our GPU based Accumulator algorithm is much slower than the CPU-based 
implementation. There are several reasons for this performance: Lack of Integer Arithmetic: Current 
GPUs do not support integer arithmetic instructions. Therefore, we used a fragment program with at least 
5 instructions to test if the i-th bit of a texel is 1. There are several ways to implement such a feature 
in the hardware. A simplest mechanism is to copy the i-th bit of the texel into the alpha value of a 
fragment. This can lead to signi.cant improvement in performance.  Clock Rate: Not only are we comparing 
two architectures with di.erent instruction sets, but they also have di.erent clock rates. Our CPU implementation 
used top-of-the-line dual Xeon processors operating at 2.8GHz. Each Xeon processor has four SIMD processors 
that can perform four operations in parallel. On the other hand, the current GPU clock rate (450MHz) 
is much lower than the CPU clock rate. It is possible that the increasing parallelism in the GPUs and 
development of new instruction sets for fragment programs can bridge this gap in performance.  Our 
preliminary analysis indicates that it is advantageous to perform selection and semi-linear queries on 
GPUs. In addition, GPUs can also be used e.ectively to perform order statistics algorithms.   7. CONCLUSIONS 
AND FUTURE WORK In this paper, we have presented novel algorithms for performing database operations 
on the GPUs. These include algorithms for predicates, boolean combinations, and aggregation queries. 
We have implemented these algorithms on a state-of-the-art GPU and highlighted its performance for following 
queries: relational query, range query, multiattribute query, semi-linear query, kth-largest number 
computation, accumulator and selectivity analysis. We have also performed preliminary comparisons with 
optimized implementations of CPU-based algorithms. In some cases, we observed noticeable performance 
gain. We have shown that GPUs are excellent candidates for performing some of the databases operations. 
Some reasons for this .nding include: Commodity Hardware: High-end GPUs are freely available on PCs, 
consoles and workstations. The cost of a high-end GPU is typically less than the cost of a high-end CPU 
(by a factor of two or more).  Higher Growth Rate: Over the last decade the growth rate of GPU performance 
has been higher than that of CPUs. This trend is expected to continue for the next .ve years or so. The 
performance gap between the CPUs and GPUs will probably increase considerably and we can obtain improved 
performance for database queries on the GPUs.  Multiple Fragment Processors and Improved Programmability: 
Current high-end GPUs already have 8 fragment processors. This number is expected to increase in the 
future. As the instruction sets of fragment programs improve, the running time of many of our algorithms 
will further decrease.  Useful Co-Processor: Overall, the GPU can be used as an e.ective co-processor 
along with the CPUs. It is clear that GPU is an excellent candidate for some database operations, but 
not all. Therefore, it would be useful for database designers to utilize GPU capabilities alongside 
traditional CPU-based code.  There are many avenues for future work. It is possible to use new capabilities 
and optimizations to improve the performance of many of our algorithms. Furthermore, we would like to 
develop algorithms for other database operations and queries including sorting, join, and indexed search, 
and OLAP and data mining tasks such as data cube roll up and drill-down, classi.cation, and clustering, 
which may bene.t from multiple fragment processors and vector processing capabilities. We also plan 
to design GPU-based algorithms for queries on more complicated data types in the context of spatial 
and temporal databases and perform continuous queries over streams using GPUs. Acknowledgements This 
research is supported in part by ARO Contract DAAD1999-1-0162, NSF award ACI-0118743, ONR Contracts 
N0001401-1-0067 and N00014-01-1-0496, and Intel Corporation. We would like to thank NVIDIA Corporation 
especially Steven Molnar, Paul Keller and Stephen Ehmann for their support. We would also like to thank 
Jasleen Sahni for providing access to the TCP/IP database. 8. REFERENCES [1] Pankaj Agarwal, Shankar 
Krishnan, Nabil Mustafa, and Suresh Venkatasubramanian. Streaming geometric optimization using graphics 
hardware. In 11th European Symposium on Algorithms, 2003. [2] A. Ailamaki, D. J. DeWitt, M. D. Hill, 
and M. Skounakis. Weaving relations for cache performance. In Proceedings of the Twenty-seventh International 
Conference on Very Large Data Bases 2001, pages 169 180, 2001. [3] A. Ailamaki, D. J. DeWitt, M. D. Hill, 
and D. A. Wood. DBMSs on a modern processor: Where does time go? In Proc. of VLDB, pages 266 277, 1999. 
 [4] J. Bolz, I. Farmer, E. Grinspun, and P. Schroder. Sparse matrix solvers on the gpu: Conjugate gradients 
and multigrid. ACM Trans. on Graphics (Proc. of ACM SIGGRAPH), 22(3), 2003. [5] Peter A. Boncz, Stefan 
Manegold, and Martin L. Kersten. Database architecture optimized for the new bottleneck: Memory access. 
In Proc. of VLDB, pages 54 65, 1999. [6] Census bureau databases. http://www.bls.census.gov/cps/. [7] 
Zhiyuan Chen, Nick Koudas, Flip Korn, and S. Muthukrishnan. Selectively estimation for boolean queries. 
In Proceedings of the nineteenth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems, 
pages 216 225, 2000. [8] Ext depth bounds test speci.cation. http://www.nvidia.com/dev content/nvopenglspecs/ 
GL EXT depth bounds test.txt. [9] Michael Doggett. Programmability features of graphics hardware. ACM 
SIGGRAPH Course Notes # 11, 2003. [10] Lise Getoor, Benjamin Taskar, and Daphne Koller. Selectivity 
estimation using probabilistic models. In Timos Sellis and Sharad Mehrotra, editors, Proceedings of the 
2001 ACM SIGMOD International Conference on Management of Data 2001, Santa Barbara, California, United 
States, May 21 24, 2001, pages 461 472, 2001. ACM order number 472010. [11] N. Goodnight, C. Woolley, 
G. Lewin, D. Luebke, and G. Humphreys. A multigrid solver for boundary value problems using programmable 
graphics hardware. ACM SIGGRAPH/Eurographics Conference on Graphics Hardware, 2003. [12] N. Govindaraju, 
B. Lloyd, S. Yoon, A. Sud, and D. Manocha. Interactive shadow generation in complex environments. Proc. 
of ACM SIGGRAPH/ACM Trans. on Graphics, 22(3):501 510, 2003. [13] M. Harris, G. Coombe, G. Scheuermann, 
and A. Lastra. Physically-based visual simulation on graphics hardware. SIGGRAPH/Eurographics Workshop 
on Graphics Hardware, 2002. [14] C. A. R. Hoare. Algorithm 65: .nd. Commun. ACM, 4(7):321 322, 1961. 
[15] K. Ho., T. Culver, J. Keyser, M. Lin, and D. Manocha. Fast computation of generalized voronoi diagrams 
using graphics hardw are. Proceedings of ACM SIGGRAPH, pages 277 286, 1999. [16] S. Krishnan, N. H. Mustafa, 
and S. Venkatasubramanian. Hardware-assisted computation of depth contours. In 13th ACM-SIAM Symposium 
on Discrete Algorithms, 2002. [17] J. Kruger and R. Westermann. Linear algebra operators for gpu implementation 
of numerical algorithms. ACM Trans. on Graphics (Proc. of ACM SIGGRAPH), 22(3), 2003. [18] E. S. Larsen 
and D. K. McAllister. Fast matrix multiplies using graphics hardware. Proc. of IEEE Supercomputing, 2001. 
[19] M. Macedonia. The gpu enters computing s mainstream. Computer, October 2003. [20] S. Manegold, 
P. Boncz, and M L. Kersten. What happens during a join? Dissecting CPU and memory optimization e.ects. 
In VLDB 2000, Proceedings of 26th International Conference on Very Large Data Bases, September 10 14, 
2000, Cairo, Egypt, pages 339 350, 2000. [21] Stefan Manegold, Peter A. Boncz, and Martin L. Kersten. 
Generic database cost models for hierarchical memory systems. In Proceedings of the Twenty-eighth International 
Conference on Very Large Data Bases 2002, pages 191 202, 2002. [22] D. Manocha. Interactive Geometric 
and Scienti.c Computations using Graphics Hardware. SIGGRAPH Course Notes # 11, 2003. [23] William R. 
Mark, R. Steven Glanville, Kurt Akeley, and Mark J. Kilgard. Cg: A system for programming graphics hardware 
in a c-like language. In Proc. of ACM SIGGRAPH, 2003. http://developer.nvidia.com/page/cg main.html. 
[24] Shintaro Meki and Yahiko Kambayashi. Acceleration of relational database operations on vector processors. 
Systems and Computers in Japan, 31(8):79 88, August 2000. [25] http://lava.cs.virgina.edu/bpred.html. 
[26] Nvidia geforce fx gpus: Intellisample technology. http://www.nvidia.com/object/intellisample tb.html. 
[27] Nv occlusion query speci.cation. http://www.nvidia.com/dev content/nvopenglspecs/ GL NV occlusion 
query.txt. [28] Niki Pissinou. Towards and infrastructure for temporal databases A workship report. 
SIGMOD Record (ACM Special Interest Group on Management of Data), 23(1):35 51, March 1994. [29] T. Purcell, 
I. Buck, W. Mark, and P. Hanrahan. Ray tracing on programmable graphics hardware. ACM Trans. on Graphics 
(Proc. of SIGGRAPH 02), 21(3):703 712, 2002. [30] T. Purcell, C. Donner, M. Cammarano, H. Jensen, and 
P. Hanrahan. Photon mapping on programmable graphics hardware. ACM SIGGRAPH/Eurographics Conference on 
Graphics Hardware, pages 41 50, 2003. [31] Jun Rao and Kenneth A. Ross. Cache conscious indexing for 
decision-support in main memory. In Proc. of VLDB, pages 78 89, 1999. [32] Kenneth A. Ross. Conjunctive 
selection conditions in main memory. In ACM, editor, Proceedings of the Twenty-First ACM SIGMOD-SIGACT-SIGART 
Symposium on Principles of Database Systems: PODS 2002, pages 109 120, 2002. ACM order number 475021. 
[33] J. Rossignac, A. Megahed, and B.D. Schneider. Interactive inspection of solids: cross-sections and 
interferences. In Proceedings of ACM Siggraph, pages 353 60, 1992. [34] Ambuj Shatdal, Chander Kant, 
and Je.rey F. Naughton. Cache conscious algorithms for relational query processing. In 20th International 
Conference on Very Large Data Bases, 1994, pages 510 521, 1994. [35] Chengyu Sun, Divyakant Agrawal, 
and Amr El Abbadi. Hardware acceleration for spatial selections and joins. In ACM, editor, Proceedings 
of the 2003 ACM SIGMOD International Conference on Management of Data, pages 455 466, 2003. [36] C. J. 
Thompson, S. Hahn, and M. Oskin. Using modern graphics architectures for general-purpose computing: A 
framework and analysis. Proc. of IEEE/ACM International Symposium on Microarchitectures, pages 306 317, 
2002. [37] Jingren Zhou and Kenneth A. Ross. Implementing database operations using simd instructions. 
In Proceedings of the 2002 ACM SIGMOD international conference on Management of data, pages 145 156. 
ACM Press, 2002.  
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198788</article_id>
		<sort_key>218</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[Quick-CULLIDE]]></title>
		<subtitle><![CDATA[fast inter- and intra-object collision culling using graphics hardware]]></subtitle>
		<page_from>218</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198788</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198788</url>
		<abstract>
			<par><![CDATA[We present a fast collision culling algorithm for performing inter- and intra-object collision detection among complex models using graphics hardware. Our algorithm is based on CULLIDE and performs visibility queries on the GPUs to eliminate a subset of geometric primitives that are not in close proximity. We present an extension to CULLIDE to perform intra-object or self-collisions between complex models. Furthermore, we describe a novel visibility-based classification scheme to compute potentially-colliding and collision-free subsets of objects and primitives, which considerably improves the culling performance. We have implemented our algorithm on a PC with an NVIDIA GeForce FX 6800 Ultra graphics card and applied it to three complex simulations, each consisting of objects with tens of thousands of triangles. In practice, we are able to compute all the self-collisions for cloth simulation up to image-space precision at interactive rates.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40031433</person_id>
				<author_profile_id><![CDATA[81100383019]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Naga]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Govindaraju]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95041417</person_id>
				<author_profile_id><![CDATA[81452602436]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P67316</person_id>
				<author_profile_id><![CDATA[81100618474]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Dinesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Manocha]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Quick-CULLIDE: Fast Inter- and Intra-Object Collision Culling Using Graphics Hardware Naga K. Govindaraju, 
Ming C. Lin, Dinesh Manocha Proc. of IEEE Virtual Reality 2005 Website: http://gamma.cs.unc.edu/QCULLIDE 
We present a fast collision culling algorithm for performing inter- and intra-object collision detection 
among complex models using graphics hardware. Our algorithm is based on CULLIDE and performs visibility 
queries on the GPUs to eliminate a subset of geometric primitives that are not in close proximity. We 
present an extension to CULLIDE to perform intra-object or self-collisions between complex models. Furthermore, 
we describe a novel visibility-based classification scheme to compute potentially-colliding and collision-free 
subsets of objects and primitives, which considerably improves the culling performance. We have implemented 
our algorithm on a PC with an NVIDIA GeForce FX 6800 Ultra graphics card and applied it to three complex 
simulations, each consisting of objects with tens of thousands of triangles. In practice, we are able 
to compute all the self-collisions for cloth simulation up to imagespace precision at interactive rates. 
218218218 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198789</article_id>
		<sort_key>219</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[Interactive visibility ordering and transparency computations among geometric primitives in complex environments]]></title>
		<page_from>219</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198789</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198789</url>
		<abstract>
			<par><![CDATA[We describe a novel algorithm for visibility ordering among non-overlapping geometric objects in complex and dynamic environments. Our algorithm rearranges the objects in a back-to-front or a front-to-back order from a given viewpoint. We perform comparisons between the primitives by using occlusion queries on the GPUs and exploit frame to frame coherence to reduce the number of occlusion queries. Our visibility ordering algorithm requires no preprocessing and is applicable to all kind of models, including polygon soups and deformable models. We have used our algorithm for order-independent transparency computations in high-depth complexity environments and performing N-body collision culling in dynamic environments. We have implemented our algorithm on a PC with a 3.4 GHz Pentium IV CPU with an NVIDIA GeForce FX 6800 Ultra GPU and applied it to complex environments with tens or hundreds of thousands of polygons. Our algorithm can compute a visibility ordering among the objects and triangles at interactive frame rates.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40031130</person_id>
				<author_profile_id><![CDATA[81100383019]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Naga]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Govindaraju]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24032406</person_id>
				<author_profile_id><![CDATA[81100301163]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Henson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95041089</person_id>
				<author_profile_id><![CDATA[81452602436]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P67316</person_id>
				<author_profile_id><![CDATA[81100618474]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Dinesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Manocha]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Interactive Visibility Ordering and Transparency Computations among Geometric Primitives in Complex 
Environments Naga K. Govindaraju, Michael Henson, Ming C. Lin, Dinesh Manocha Proc. of ACM Interactive 
3D Graphics and Games, 2005 Website: http://gamma.cs.unc.edu/SORT We describe a novel algorithm for visibility 
ordering among non-overlapping geometric objects in complex and dynamic environments. Our algorithm rearranges 
the objects in a back-to-front or a front-to-back order from a given viewpoint. We perform comparisons 
between the primitives by using occlusion queries on the GPUs and exploit frame to frame coherence to 
reduce the number of occlusion queries. Our visibility ordering algorithm requires no preprocessing and 
is applicable to all kind of models, including polygon soups and deformable models. We have used our 
algorithm for orderindependent transparency computations in high-depth complexity environments and performing 
N-body collision culling in dynamic environments. We have implemented our algorithm on a PC with a 3.4 
GHz Pentium IV CPU with an NVIDIA GeForce FX 6800 Ultra GPU and applied it to complex environments with 
tens or hundreds of thousands of polygons. Our algorithm can compute a visibility ordering among the 
objects and triangles at interactive frame rates. 219219219 
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198790</article_id>
		<sort_key>220</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[Fast fluid dynamics simulation on the GPU]]></title>
		<page_from>220</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198790</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198790</url>
		<abstract>
			<par><![CDATA[This chapter describes a method for fast, stable fluid simulation that runs entirely on the GPU. It introduces fluid dynamics and the associated mathematics, and it describes in detail the techniques to perform the simulation on the GPU. After reading this chapter, you should have a basic understanding of fluid dynamics and know how to simulate fluids using the GPU. The source code accompanying this book demonstrates the techniques described in this chapter.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39060436</person_id>
				<author_profile_id><![CDATA[81100116782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Harris]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198791</article_id>
		<sort_key>221</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[Physically-based visual simulation on graphics hardware]]></title>
		<page_from>221</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198791</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198791</url>
		<abstract>
			<par><![CDATA[In this paper, we present a method for real-time visual simulation of diverse dynamic phenomena using programmable graphics hardware. The simulations we implement use an extension of cellular automata known as the coupled map lattice (CML). CML represents the state of a dynamic system as continuous values on a discrete lattice. In our implementation we store the lattice values in a texture, and use pixel-level programming to implement simple next-state computations on lattice nodes and their neighbors. We apply these computations successively to produce interactive visual simulations of convection, reaction-diffusion, and boiling. We have built an interactive framework for building and experimenting with CML simulations running on graphics hardware, and have integrated them into interactive 3D graphics applications.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39060388</person_id>
				<author_profile_id><![CDATA[81100116782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Harris]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P345954</person_id>
				<author_profile_id><![CDATA[81100408443]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Greg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Coombe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP28018706</person_id>
				<author_profile_id><![CDATA[81100098694]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Thorsten]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Scheuermann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P20148</person_id>
				<author_profile_id><![CDATA[81100264426]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Anselmo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lastra]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198792</article_id>
		<sort_key>222</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[Real-time cloud simulation and rendering]]></title>
		<page_from>222</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198792</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198792</url>
		<abstract>
			<par><![CDATA[Clouds are a ubiquitous, awe-inspiring, and ever-changing feature of the outdoors. They are an integral factor in Earth's weather systems, and a strong indicator of weather patterns and changes. Their effects and indications are important to flight and flight training. Clouds are an important component of the visual simulation of any outdoor scene, but the complexity of cloud formation, dynamics, and light interaction makes cloud simulation and rendering difficult in real time. In an interactive flight simulation, users would like to fly in and around realistic, volumetric clouds, and to see other aircraft convincingly pass within and behind them. Ideally, simulated clouds would grow and disperse as real clouds do, and move in response to wind and other forces. Simulated clouds should be realistically illuminated by direct sunlight, internal scattering, and reflections from the sky and the earth below. Previous real-time techniques have not provided users with such experiences.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39056707</person_id>
				<author_profile_id><![CDATA[81100116782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Harris]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198793</article_id>
		<sort_key>223</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[Simulation of cloud dynamics on graphics hardware]]></title>
		<page_from>223</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198793</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198793</url>
		<abstract>
			<par><![CDATA[This paper presents a physically-based, visually-realistic interactive cloud simulation. Clouds in our system are modeled using partial differential equations describing fluid motion, thermodynamic processes, buoyant forces, and water phase transitions. We also simulate the interaction of clouds with light, including self-shadowing and light scattering.We implement both simulations - dynamic and radiometric - entirely on programmable floating-point graphics hardware. We use "flat 3D textures" - 3D data laid out as slices tiled in a 2D texture - to implement 3D simulations on the GPU. This has scalability advantages over the use of traditional 3D textures. We exploit the relatively slow evolution of clouds in calm skies to enable interactive visualization of the simulation. The work required to simulate a single time step is automatically spread over many frames while the user views the results of the previous time step. This technique enables the incorporation of our simulation into real applications without sacrificing interactivity.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39060441</person_id>
				<author_profile_id><![CDATA[81100116782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Harris]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31055399</person_id>
				<author_profile_id><![CDATA[81100207483]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[V.]]></middle_name>
				<last_name><![CDATA[Baxter]]></last_name>
				<suffix><![CDATA[III]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP28018704</person_id>
				<author_profile_id><![CDATA[81100098694]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Thorsten]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Scheuermann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P20148</person_id>
				<author_profile_id><![CDATA[81100264426]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Anselmo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lastra]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198794</article_id>
		<sort_key>224</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[Nonlinear optimization framework for image-based modeling on programmable graphics hardware]]></title>
		<page_from>224</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198794</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198794</url>
		<abstract>
			<par><![CDATA[Graphics hardware is undergoing a change from fixed-function pipelines to more programmable organizations that resemble general purpose stream processors. In this paper, we show that certain general algorithms, not normally associated with computer graphics, can be mapped to such designs. Specifically, we cast nonlinear optimization as a data streaming process that is well matched to modern graphics processors. Our framework is particularly well suited for solving image-based modeling problems since it can be used to represent a large and diverse class of these problems using a common formulation. We successfully apply this approach to two distinct image-based modeling problems: light field mapping approximation and fitting the Lafortune model to spatial bidirectional reflectance distribution functions. Comparing the performance of the graphics hardware implementation to a CPU implementation, we show more than 5-fold improvement.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[image-based modeling]]></kw>
			<kw><![CDATA[nonlinear optimization]]></kw>
			<kw><![CDATA[programmable graphics hardware]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Graphics processors</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Digitizing and scanning</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Viewing algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010506</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Document scanning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010389</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics processors</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P587720</person_id>
				<author_profile_id><![CDATA[81100129211]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Karl]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Hillesland]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P437456</person_id>
				<author_profile_id><![CDATA[81100170129]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sergey]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Molinov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Intel Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P237369</person_id>
				<author_profile_id><![CDATA[81100560226]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Radek]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Grzeszczuk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Intel Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>525960</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bishop, C. M. 1995. Neural Networks for Pattern Recognition. Clarendon Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882364</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bolz, J., Farmer, I., Grinspun, E., and Schroder, P. 2003. Sparse Matrix Solvers on the GPU: Conjugate Gradients and Multigrid. ACM Transactions on Graphics 22, 3 (July). (Proceedings of ACM SIGGRAPH 2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Carr, N. A., Hall, J. D., and Hart, J. C. 2002. Ray Engine. 2000 SIGGRAPH / Eurographics Workshop on Graphics Hardware, 1--10.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566601</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Chen, W.-C., Bouguet, J.-Y., Chu, M. H., and Grzeszczuk, R. 2002. Light Field Mapping: Efficient Representation and Hardware Rendering of Surface Light Fields. ACM Transactions on Graphics 21, 3 (July), 447--456. ISSN 0730--0301 (Proceedings of ACM SIGGRAPH 2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1096889</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Dennis, J. E. J., and Schnabel, R. B. 1996. Numerical Methods for Unconstrained Optimization and Nonlinear Equations. Classics in Applied Mathematics, 16. SIAM.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>581929</ref_obj_id>
				<ref_obj_pid>581896</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Furukawa, R., Kawasaki, H., Ikeuchi, K., and Sakauchi, M. 2002. Appearance Based Object Modeling Using Texture Database: Acquisition, Compression and Rendering. Eurographics Rendering Workshop 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569061</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Harris, M. J., Coombe, G., Scheuermann, T., and Lastra, A. 2002. Physically-Based Visual Simulation on Graphics Hardware. 2002 SIGGRAPH / Eurographics Workshop on Graphics Hardware, 1--10.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311567</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hoff, K., Culver, T., Keyser, J., Lin, M., and Manocha, D. 1999. Fast Computation of Generalized Voronoi Diagrams Using Graphics Hardware. In Proceedings of SIGGRAPH 99, Computer Graphics Proceedings, Annual Conference Series, 277--286.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383838</ref_obj_id>
				<ref_obj_pid>2383815</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Kautz, J., and McCool, M. D. 1999. Interactive Rendering with Arbitrary BRDFs using Separable Approximations. Eurographics Rendering Workshop 1999 (June).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>624434</ref_obj_id>
				<ref_obj_pid>623298</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Khailany, B., Dally, W. J., Rixner, S., Kapasi, U. J., Mattson, P., Namkoong, J., Owens, J. D., Towles, B., and Chang, A. 2001. Imagine: Media Processing with Streams. IEEE Micro (March/April), 35--46.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882363</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kr&#252;ger, J., and Westermann, R. 2003. Linear Algebra Operators for GPU Implementation of Numerical Algorithms. ACM Transactions on Graphics 22, 3 (July). (Proceedings of ACM SIGGRAPH 2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258801</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Lafortune, E. P. F., Foo, S.-C., Torrance, K. E., and Greenberg, D. P. 1997. Non-Linear Approximation of Reflectance Functions. Proceedings of SIGGRAPH 97 (August), 117--126.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383274</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Lindholm, E., Kilgard, M. J., and Moreton, H. 2001. A User-Programmable Vertex Engine. In Proceedings of ACM SIGGRAPH 2001, Computer Graphics Proceedings, Annual Conference Series, 149--158.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569057</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[McAllister, D. K., Lastra, A., and Heidrich, W. 2002. Efficient Rendering of Spatial Bidirectional Reflectance Distribution Functions. Eurographics Rendering Workshop 2002 (June).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383276</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[McCool, M. D., Ang, J., and Ahmad, A. 2001. Homomorphic Factorization of BRDFs for High-Performance Rendering. Proceedings of SIGGRAPH 2001 (August), 171--178.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Nishino, K., Sato, Y., and Ikeuchi, K. 1999. Eigen-Texture Method: Appearance Compression Based on 3D Model. In Proceedings of the IEEE Computer Science Conference on Computer Vision and Pattern Recognition (CVPR-99), 618--624.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566640</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Purcell, T. J., Buck, I., Mark, W. R., and Hanrahan, P. 2002. Ray Tracing on Programmable Graphics Hardware. ACM Transactions on Graphics 21, 3 (July), 703--712. ISSN 0730-0301 (Proceedings of ACM SIGGRAPH 2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258885</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Sato, Y., Wheeler, M. D., and Ikeuchi, K. 1997. Object Shape and Reflectance Modeling from Observation. Proceedings of SIGGRAPH 97 (August), 379--388.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2384121</ref_obj_id>
				<ref_obj_pid>2384110</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Strzodka, R., And Rumpf, M. 2001. Nonlinear Diffusion in Graphics Hardware. Proceedings EG/IEEE TCVG Symposium on Visualization, 75--84.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>774894</ref_obj_id>
				<ref_obj_pid>774861</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Thompson, C. J., Hahn, S., and Oskin, M. 2002. Using Modern Graphics Architectures for General-Purpose Computing: A Framework and Analysis. Proceedings of 35th International Symposium on Microarchitecture (MICRO-35).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>826631</ref_obj_id>
				<ref_obj_pid>826030</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Yang, R., Welch, G., and Bishop, G. 2002. Real-Time Consensus-Based Scene Reconstruction using Commodity Graphics Hardware. Proceedings of Pacific Graphics.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311559</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Yu, Y., Debevec, P. E., Malik, J., and Hawkins, T. 1999. Inverse Global Illumination: Recovering Reflectance Models of Real Scenes From Photographs. Proceedings of SIGGRAPH 99 (August), 215--224.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198795</article_id>
		<sort_key>234</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[Linear algebra operators for GPU implementation of numerical algorithms]]></title>
		<page_from>234</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198795</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198795</url>
		<abstract>
			<par><![CDATA[In this work, the emphasis is on the development of strategies to realize techniques of numerical computing on the graphics chip. In particular, the focus is on the acceleration of techniques for solving sets of algebraic equations as they occur in numerical simulation. We introduce a framework for the implementation of linear algebra operators on programmable graphics processors (GPUs), thus providing the building blocks for the design of more complex numerical algorithms. In particular, we propose a stream model for arithmetic operations on vectors and matrices that exploits the intrinsic parallelism and efficient communication on modern GPUs. Besides performance gains due to improved numerical computations, graphics algorithms benefit from this model in that the transfer of computation results to the graphics processor for display is avoided. We demonstrate the effectiveness of our approach by implementing direct solvers for sparse matrices, and by applying these solvers to multi-dimensional finite difference equations, i.e. the 2D wave equation and the incompressible Navier-Stokes equations.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[graphics hardware]]></kw>
			<kw><![CDATA[numerical simulation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.6.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010366</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation support systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP35035780</person_id>
				<author_profile_id><![CDATA[81100607061]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jens]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kr&#252;ger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Technical University, Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31050462</person_id>
				<author_profile_id><![CDATA[81100626078]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[R&#252;diger]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Westermann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Technical University, Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>323215</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Anderson, E., Bai, Z., Bischof, C., Blackford, S., Demmel, J., Dongarra, J., Du Croz, J., Greenbaum, A., Hammarling, S., McKenney, A., and Sorensen, D. 1999. LAPACK Users' Guide, third ed. Society for Industrial and Applied Mathematics, Philadelphia, PA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[ATI, 2003. Sample effects on the ATI graphics cards. http://www.ati.com/developer/techpapers.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280821</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Baraff, D., and Witkin, A. 1998. Large steps in cloth simulation. Computer Graphics SIGGRAPH 98 Proceedings, 43--54.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882364</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bolz, J., Farmer, I., Grinspun, E., and Schroeder, P. 2003. Sparse matrix solvers on the GPU: Conjugate gradients and multigrid. Computer Graphics SIGGRAPH 03 Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>203303</ref_obj_id>
				<ref_obj_pid>203297</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Chen, J., and Da Vitoria Lobo, N. 1995. Towards interactive-rate simulation of fluids with moving obstacles using Navier-Stokes equations. Graphical Models and Image Processing 57, 2.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258896</ref_obj_id>
				<ref_obj_pid>258734</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Curtis, C., Anderson, S., Seims, J., Fleischer, F., and Salesin, D. 1997. Computer-generated watercolor. Computer Graphics SIGGRAPH 97 Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383262</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Debunne, G., Desbrun, M., M.-P., C., and Barr, A. 2001. Dynamic real-time deformations using space and time adaptive sampling. In Computer Graphics SIGGRAPH 01 Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311576</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Desbrun, M., Meyer, M., Schroeder, P., and Barr, A. 1999. Implicit fairing of irregular meshes using diffusion and curvature flow. In Computer Graphics SIGGRAPH 99 Proceedings, 317--324.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>42291</ref_obj_id>
				<ref_obj_pid>42288</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Dongarra, J., Du Croz, J., Hammarling, S., and Hanson, R. 1988. An extended set of FORTRAN basic linear algebra subprograms. ACM Transactions on Mathematical Software 14, 1--17.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>79170</ref_obj_id>
				<ref_obj_pid>77626</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Dongarra, J., Du Croz, J., Hammarling, S., and Hanson, R. 1990. A set of level 3 basic linear algebra subprograms,. ACM Transactions on Mathematical Software 16, 1--17.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Elder, G. 2002. Radeon 9700. In Proceedings Eurographics/SIGGRAPH Workshop on Graphics Hardware 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383260</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Fedkiw, R., Stam, J., and Jensen, H. 2001. Visual simulation of smoke. Computer Graphics SIGGRAPH 01 Proceedings, 15--22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383261</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Foster, N., and Fedkiw, R. 2001. Practical animation of liquids. Computer Graphics SIGGRAPH 01 Proceedings, 23--30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>244315</ref_obj_id>
				<ref_obj_pid>244304</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Foster, N., and Metaxas, D. 1996. Realistic animation of liquids. Graphical Models and Image Processing 58, 5, 471--483.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569061</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Harris, M., Coombe, G., Scheuermann, T., and Lastra, A. 2002. Physically-based visual simulation on graphics hardware. In Proceedings Eurographics/SIGGRAPH Workshop on Graphics Hardware 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383531</ref_obj_id>
				<ref_obj_pid>383507</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Hart, J. 2001. Perlin noise pixel shaders. In Proceedings Eurographics/SIGGRAPH Workshop on Graphics Hardware 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300538</ref_obj_id>
				<ref_obj_pid>300523</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Heidrich, W., Westermann, R., Seidel, H.-P., and Ertl, T. 1999. Applications of pixel textures in visualization and realistic image synthesis. In ACM Symposium on Interactive 3D Graphics, 110--119.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882365</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Hillesland, K., Molinov, S., and Grzeszczuk, R. 2003. Nonlinear Optimization Framework for Image-Based Modelling on Programmable Graphics Hardware. Computer Graphics SIGGRAPH 03 Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>319457</ref_obj_id>
				<ref_obj_pid>319351</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Hopf, M., and Ertl, T. 1999. Accelerating 3D convolution using graphics hardware. In Proceedings IEEE Visualization'99, 471--474.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Hopf, M., and Ertl, T. 2000. Hardware accelerated wavelet transformations. In Proceedings EG/IEEE TCVG Symposium on Visualization VisSym '00, 93--103.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>601678</ref_obj_id>
				<ref_obj_pid>601671</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Jobard, B., Erlebacher, G., and Hussaini, Y. 2000. Lagrangian-Eulerian advection of noise and dye textures for unsteady flow visualization. In Proceedings IEEE Visualization'00, 110--118.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97884</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Kaas, M., and Miller, G. 1990. Rapid, stable fluid dynamics for computer graphics. Computer Graphics SIGGRAPH 90 Proceedings, 49--57.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>582089</ref_obj_id>
				<ref_obj_pid>582034</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Larsen, E. S., and McAllister, D. 2001. Fast matrix multiplies using graphics hardware. In Proceedings Supercomputing 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383274</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Lindholm, E., Kilgard, M., and Moreton, H. 2001. A user-programmable vertex engine. Computer Graphics SIGGRAPH 01 Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Microsoft, 2002. DirectX9 SDK. http://www.microsoft.com/DirectX.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Montrym, J., and Moreton, H. 2002. GeForce4. In Proceedings Eurographics/SIGGRAPH Workshop on Graphics Hardware 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[NVidia, 2002. nvidia OpenGL game of life. http://www.nvidia.com/view.asp?IO=ogl-gameoflife.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[NVidia, 2003. Sample effects on the nVIDIA graphics cards. http://developer.nvidia.com/view.asp?PAGE=papers.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280857</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Olano, M., and Lastra, A. 1998. A shading-language on graphics hardware. Computer Graphics SIGGRAPH 98 Proceedings, 159--168.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>506164</ref_obj_id>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Press, W., Teukolsky, S., Vetterling, W., and Flannery, B. 2002. Numerical Recipes in C++: The Art of Scientific Computing. Cambridge University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566640</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Purcell, T., Buck, I., Mark, W., and Hanrahan, P. 2002. Ray tracing on programmable graphics hardware. Computer Graphics SIGGRAPH 98 Proceedings, 703--712.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311548</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Stam, J. 1999. Stable fluids. Computer Graphics SIGGRAPH 99 Proceedings, 121--128.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2384121</ref_obj_id>
				<ref_obj_pid>2384110</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Strzodka, R., and Rumpf, M. 2001. Nonlinear diffusion in graphics hardware. In Proceedings EG/IEEE TCVG Symposium on Visualization 2001, 75--84.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Strzodka, R., and Rumpf, M. 2001. Using graphics cards for quantized FEM computations. In Proceedings VIIP 2001, 98--107.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>774894</ref_obj_id>
				<ref_obj_pid>774861</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Thompson, C., Hahn, S., and Oskin, M. 2002. Using modern graphics architectures for general-purpose computing: A framework and analysis. Proceedings of 35th International Symposium on Microarchitecture (MICRO-35).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>718500</ref_obj_id>
				<ref_obj_pid>647260</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Weiskopf, D., Hopf, M., and Ertl, T. 2001. Hardware-accelerated visualization of time-varying 2D and 3D vector fields by texture advection via programmable per-pixel operations. In Proceedings Workshop on Vision, Modeling, and Visualization VMV'01, 439--446.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Weiskopf, D., Hopf, M., and Ertl, T. 2002. Hardware-accelerated Lagrangian-Eulerian texture advection for 2D flow visualization. In Proceedings Workshop on Vision, Modeling, and Visualization VMV '02.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198796</article_id>
		<sort_key>243</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[A streaming narrow-band algorithm]]></title>
		<subtitle><![CDATA[interactive computation and visualization of level sets]]></subtitle>
		<page_from>243</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198796</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198796</url>
		<abstract>
			<par><![CDATA[Deformable isosurfaces, implemented with level-set methods, have demonstrated a great potential in visualization and computer graphics for applications such as segmentation, surface processing, and physically-based modeling. Their usefulness has been limited, however, by their high computational cost and reliance on signi&pound;cant parameter tuning. This paper presents a solution to these challenges by describing graphics processor (GPU) based algorithms for solving and visualizing level-set solutions at interactive rates. The proposed solution is based on a new, streaming implementation of the narrow-band algorithm. The new algorithm packs the level-set isosurface data into 2D texture memory via a multi-dimensional virtual memory system. As the level-set moves, this texture-based representation is dynamically updated via a novel GPU-to-CPU message passing scheme. By integrating the level-set solver with a real-time volume renderer, a user can visualize and intuitively steer the level-set surface as it evolves. We demonstrate the capabilities of this technology for interactive volume segmentation and visualization.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[GPU]]></kw>
			<kw><![CDATA[deformable models]]></kw>
			<kw><![CDATA[image segmentation]]></kw>
			<kw><![CDATA[level sets]]></kw>
			<kw><![CDATA[streaming computation]]></kw>
			<kw><![CDATA[virtual memory]]></kw>
			<kw><![CDATA[volume visualization]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14161228</person_id>
				<author_profile_id><![CDATA[81100460149]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Aaron]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Lefohn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14041492</person_id>
				<author_profile_id><![CDATA[81100087816]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Joe]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Kniss]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14162476</person_id>
				<author_profile_id><![CDATA[81100464350]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Charles]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Hansen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P249754</person_id>
				<author_profile_id><![CDATA[81100483298]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Ross]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[Whitaker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>56815</ref_obj_id>
				<ref_obj_pid>56813</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[S. Osher and J. Sethian, 'Fronts propagating with curvature-dependent speed: Algorithms based on Hamilton-Jacobi formulations," Journal of Computational Physics, vol. 79, pp. 12--49, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Fedkiw and S. Osher, Level Set Methods and Dynamic Implicit Surfaces. Springer, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. A. Sethian, Level Set Methods and Fast Marching Methods Evolving Interfaces in Computational Geometry, Fluid Mechanics, Computer Vision, and Materials Science. Cambridge University Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R. T. Whitaker, 'Volumetric deformable models: Active blobs," in Visualization In Biomedical Computing 1994 (R. A. Robb, ed.), (Mayo Clinic, Rochester, Minnesota), pp. 122--134, SPIE, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>602117</ref_obj_id>
				<ref_obj_pid>602099</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[T. Tasdizen, R. Whitaker, P. Burchard, and S. Osher, "Geometric surface smoothing via anisotropic diffusion of normals," in IEEE Visualization, pp. 125--132, October 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299682</ref_obj_id>
				<ref_obj_pid>299660</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. Whitaker, "A level-set approach to 3D reconstruction from range data," International Journal of Computer Vision, vol. October, pp. 203--231, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617767</ref_obj_id>
				<ref_obj_pid>616024</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[T. Yoo, U. Neumann, H. Fuchs, S. Pizer, T. Cullip, J. Rhoades, and R. Whitaker, "Direct visualization of volume data," IEEE Computer Graphics and Applications, vol. 12, pp. 63--71, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Droske, B. Meyer, M. Rumpf, and C. Schaller, "An adaptive level set method for medical image segmentation," in Proc. of the Annual Symposium on Information Processing in Medical Imaging (R. Leahy and M. Insana, eds.), Springer, Lecture Notes Computer Science, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>205143</ref_obj_id>
				<ref_obj_pid>205127</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[D. Adalsteinson and J. A. Sethian, "A fast level set method for propogating interfaces," Journal of Computational Physics, pp. 269--277, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>338913</ref_obj_id>
				<ref_obj_pid>338852</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[D. Peng, B. Merriman, S. Osher, H. Zhao, and M. Kang, "A PDE based fast local level set method," Journal of Computational Physics, vol. 155, pp. 410--438, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Owens, Computer Graphics on a Stream Architecture. PhD thesis, Stanford University, Nov. 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844190</ref_obj_id>
				<ref_obj_pid>844174</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[N. Goodnight, C. Woolley, G. Lewin, D. Luebke, and G. Humphreys, "A multigrid solver for boundary value problems using programmable graphics hardware," in Graphics Hardware 2003, pp. 102--111, July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>582089</ref_obj_id>
				<ref_obj_pid>582034</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[E. S. Larsen and D. McAllister, 'Fast matrix multiplies using graphics hardware," in Super Computing 2001, ACM SIGARCH/IEEE, Nov. 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[R. Strzodka and M. Rumpf, 'Using graphics cards for quantized FEM computations," in Proceedings VIIP Conference on Visualization and Image Processing, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[M. Rumpf and R. Strzodka, 'Level set segmentation in graphics hardware," in International Conference on Image Processing, pp. 1103--1106, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[A. E. Lefohn and R. T. Whitaker, "A GPU-based, three-dimensional level set solver with curvature cow." University of Utah tech report UUCS-02-017, December 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882364</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[J. Bolz, I. Farmer, E. Grinspun, and P. Schr&#246;der, 'Sparse matrix solvers on the GPU: Conjugate gradients and multigrid," in ACM Transactions on Graphics, vol. 22, pp. 917--924, July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882363</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[J. Kr&#252;ger and R. Westermann, "Linear algebra operators for GPU implementation of numerical algorithms," in ACM Transactions on Graphics, vol. 22, pp. 908--916, July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237276</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[A. C. Beers, M. Agrawala, and N. Chaddha, "Rendering from compressed textures," in Proceedings of SIGGRAPH 96, Computer Graphics Proceedings, Annual Conference Series, pp. 373--378, Aug. 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569048</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[M. Kraus and T. Ertl, "Adaptive texture maps," in Graphics Hardware 2002, pp. 7--16, Sept. 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1081467</ref_obj_id>
				<ref_obj_pid>1081432</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[A. Sherbondy, M. Houston, and S. Nepal, "Fast volume segmentation with simultaneous visualization using programmable graphics hardware," in IEEE Visualization, pp. 171--176, October 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378484</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[R. A. Drebin, L. Carpenter, and P. Hanrahan, "Volume rendering," in Computer Graphics (Proceedings of SIGGRAPH 88), vol. 22, pp. 65--74, Aug. 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>44652</ref_obj_id>
				<ref_obj_pid>44650</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[M. Levoy, "Display of surfaces from volume data," IEEE Computer Graphics & Applications, vol. 8, pp. 29--37, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378476</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[P. Sabella, "A rendering algorithm for visualizing 3D scalar &pound;elds," in Computer Graphics (Proceedings of SIGGRAPH 88), vol. 22, pp. 51--58, Aug. 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>197972</ref_obj_id>
				<ref_obj_pid>197938</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[B. Cabral, N. Cam, and J. Foran, "Accelerated volume rendering and tomographic reconstruction using texture mapping hardware," in ACM Symposium On Volume Visualization, pp. 91--98, Oct. 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>902673</ref_obj_id>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[O. Wilson, A. V. Gelder, and J. Wilhelms, "Direct Volume Rendering via 3D Textures," Tech. Rep. UCSC-CRL-94-19, University of California at Santa Cruz, June 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383515</ref_obj_id>
				<ref_obj_pid>383507</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[K. Engel, M. Kraus, and T. Ertl, "High-Quality Pre-Integrated Volume Rendering Using Hardware-Accelerated Pixel Shading," in Graphics Hardware 2001, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614529</ref_obj_id>
				<ref_obj_pid>614287</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[J. Kniss, G. Kindlmann, and C. Hansen, "Multi-Dimensional Transfer Functions for Interactive Volume Rendering," Transactions on Visualization and Computer Graphics, vol. 8, pp. 270--285, July-September 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566640</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[T. J. Purcell, I. Buck, W. R. Mark, and P. Hanrahan, "Ray tracing on programmable graphics hardware," ACM Transactions on Graphics, vol. 21, pp. 703--712, July 2002. ISSN 0730--0301 (Proceedings of ACM SIGGRAPH 2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>580960</ref_obj_id>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[A. Silberschatz and P. Galvin, Operating System Concepts. Addison-Wesley, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360145</ref_obj_id>
				<ref_obj_pid>360128</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[U. Kapasi, W. Dally, S. Rixner, P. Mattson, J. Owens, and B. Khailany, "Ef&pound;cient conditional operations for data-parallel architectures," in Proceedings of the 33rd Annual International Symposium on Microarchitecture, pp. 159--170, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1081455</ref_obj_id>
				<ref_obj_pid>1081432</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[A. E. Lefohn, J. Kniss, C. Hansen, and R. Whitaker, "Interactive deformation and visualization of level set surfaces using graphics hardware," in IEEE Visualization, pp. 75--82, October 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[A. E. Lefohn, J. Kniss, C. Hansen, and R. Whitaker, "A streaming narrow-band algorithm: Supplemental information." IEEE Digital Library.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>329653</ref_obj_id>
				<ref_obj_pid>329646</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[R. Fedkiw, T. Aslam, B. Merriman, and S. Osher, "A non-oscillatory Eulerian approach to interfaces in multimaterial cows (the ghost uid method)," Journal of Computational Physics, vol. 152, pp. 457--492, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>776766</ref_obj_id>
				<ref_obj_pid>776751</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[J. Kniss, S. Premoze, C. Hansen, P. Shirley, and A. McPherson, "A model for volume lighting and modeling," Transactions on Visualization and Computer Graphics, vol. 9, pp. 150--162, April-June 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[The Insight Toolkit http: //www. itk. org, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>200867</ref_obj_id>
				<ref_obj_pid>200862</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[R. Malladi, J. A. Sethian, and B. C. Vemuri, "Shape modeling with front propagation: A level set approach," IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 17, pp. 158--175, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[A. E. Lefohn, J. Cates, and R. Whitaker, "Interactive, GPU-based level sets for 3D brain tumor segmentation," in Medical Image Computing and Computer Assisted Intervention, pp. 564--572, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1081509</ref_obj_id>
				<ref_obj_pid>1081432</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[J. Kniss, S. Premoze, M. Ikits, A. E. Lefohn, and C. Hansen, "Gaussian transfer functions for multi-&pound;eld volume visualization," in IEEE Visualization, pp. 497--504, October 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[J. Percy and R. Mace, "OpenGL extensions: Siggraph 2003." http://mirror.ati.com/developer/techpapers.html, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[R. Whitaker and X. Xue, "Variable-conductance, level-set curvature for image denoising," in IEEE International Conference on Image Processing, pp. 142--145, October 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198797</article_id>
		<sort_key>258</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>33</seq_no>
		<title><![CDATA[Photon mapping on programmable graphics hardware]]></title>
		<page_from>258</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198797</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198797</url>
		<abstract>
			<par><![CDATA[We present a modified photon mapping algorithm capable of running entirely on GPUs. Our implementation uses breadth-first photon tracing to distribute photons using the GPU. The photons are stored in a grid-based photon map that is constructed directly on the graphics hardware using one of two methods: the first method is a multipass technique that uses fragment programs to directly sort the photons into a compact grid. The second method uses a single rendering pass combining a vertex program and the stencil buffer to route photons to their respective grid cells, producing an approximate photon map. We also present an efficient method for locating the nearest photons in the grid, which makes it possible to compute an estimate of the radiance at any surface location in the scene. Finally, we describe a breadth-first stochastic ray tracer that uses the photon map to simulate full global illumination directly on the graphics hardware. Our implementation demonstrates that current graphics hardware is capable of fully simulating global illumination with progressive, interactive feedback to the user.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[global illumination]]></kw>
			<kw><![CDATA[photon mapping]]></kw>
			<kw><![CDATA[programmable graphics hardware]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P382471</person_id>
				<author_profile_id><![CDATA[81100647803]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Timothy]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Purcell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P575224</person_id>
				<author_profile_id><![CDATA[81100639133]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Craig]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Donner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, San Diego]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P396755</person_id>
				<author_profile_id><![CDATA[81100563882]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Mike]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cammarano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P109434</person_id>
				<author_profile_id><![CDATA[81100640205]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Henrik]]></first_name>
				<middle_name><![CDATA[Wann]]></middle_name>
				<last_name><![CDATA[Jensen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, San Diego]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P219805</person_id>
				<author_profile_id><![CDATA[81100482576]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Pat]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hanrahan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[ATI. Radeon 9800 Pro product web site, 2003. http://mirror.ati.com/products/pc/radeon9800pro/index.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Kenneth E. Batcher. Sorting networks and their applications. Proceedings of AFIPS Spring Joint Computing Conference, 32:307--314, 1968.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>361007</ref_obj_id>
				<ref_obj_pid>361002</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Jon Louis Bentley. Multidimensional binary search trees used for associative searching. Communications of the ACM, 18(9):509--517, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882364</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Jeff Bolz, Ian Farmer, Eitan Grinspun, and Peter Schr&#246;der. Sparse matrix solvers on the GPU: Conjugate gradients and multigrid. ACM Transactions on Graphics, 2003. (To appear in Proceedings of ACM SIGGRAPH 2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569052</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Nathan A. Carr, Jesse D. Hall, and John C. Hart. The ray engine. In Graphics Hardware, pages 37--46, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>355832</ref_obj_id>
				<ref_obj_pid>355826</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[John Gerald Cleary. Analysis of an algorithm for finding nearest neighbors in Euclidean space. ACM Transactions on Mathematical Software (TOMS), 5(2):183--192, 1979.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Robert L. Cook, Thomas Porter, and Loren Carpenter. Distributed ray tracing. In Proceedings of the 11th Annual Conference on Computer Graphics and Interactive Techniques (SIGGRAPH '84), pages 137--145, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cindy M. Goral, Kenneth E. Torrance, Donald P. Greenberg, and Bennett Battaile. Modelling the interaction of light between diffuse surfaces. In Computer Graphics (Proceedings of SIGGRAPH 84), volume 18, pages 213--222, July 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569061</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Mark Harris, Greg Coombe, Thorsten Scheuermann, and Anselmo Lastra. Physically-based visual simulation on graphics hardware. In Graphics Hardware, pages 109--118, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>275461</ref_obj_id>
				<ref_obj_pid>275458</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Henrik Wann Jensen. Global illumination using photon maps. In Rendering Techniques '96: 7th Eurographics Workshop on Rendering, pages 21--30, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>500844</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Henrik Wann Jensen. Realistic Image Synthesis using Photon Mapping. A K Peters, 2001. ISBN 1568811470.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[James T. Kajiya. The rendering equation. In Computer Graphics (Proceedings of ACM SIGGRAPH 86), pages 143--150, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360145</ref_obj_id>
				<ref_obj_pid>360128</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Ujval J. Kapasi, William J. Dally, Scott Rixner, Peter R. Mattson, John D. Owens, and Brucek Khailany. Efficient conditional operations for data-parallel architectures. In Proceedings of the 33rd Annual ACM/IEEE International Symposium on Microarchitecture, pages 159--170, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882363</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Jens Kr&#252;ger and R&#252;diger Westermann. Linear algebra operators for gpu implementation of numerical algorithms. ACM Transactions on Graphics, 2003. (To appear in Proceedings of ACM SIGGRAPH 2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>582089</ref_obj_id>
				<ref_obj_pid>582034</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[E. Scott Larsen and David McAllister. Fast matrix multiplies using graphics hardware. In Supercomputing 2001, page 55, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569059</ref_obj_id>
				<ref_obj_pid>569046</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Vincent C. H. Ma and Michael D. McCool. Low latency photon mapping using block hashing. In Graphics Hardware (2002), pages 89--98, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882362</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[William R. Mark, Steve Glanville, and Kurt Akeley. Cg: A system for programming graphics hardware in a c-like language. ACM Transactions on Graphics, 2003. (To appear in Proceedings of ACM SIGGRAPH 2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Microsoft. DirectX home page, 2003. http://www.microsoft.com/directx/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[NVIDIA. Geforce FX 5900 product web site, 2003. http://nvidia.com/view.asp?PAGE=fx_5900.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300537</ref_obj_id>
				<ref_obj_pid>300523</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Steven Parker, William Martin, Peter-Pike J. Sloan, Peter Shirley, Brian Smits, and Charles Hansen. Interactive ray tracing. In 1999 ACM Symposium on Interactive 3D Graphics, pages 119--126, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566640</ref_obj_id>
				<ref_obj_pid>566654</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Timothy J. Purcell, Ian Buck, William R. Mark, and Pat Hanrahan. Ray tracing on programmable graphics hardware. ACM Transactions on Graphics, 21(3):703--712, July 2002. ISSN 0730-0301 (Proceedings of ACM SIGGRAPH 2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732120</ref_obj_id>
				<ref_obj_pid>647652</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Frank Suykens and Yves D. Willems. Density control for photon maps. In Rendering Techniques 2000: 11th Eurographics Workshop on Rendering, pages 23--34, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>581899</ref_obj_id>
				<ref_obj_pid>581896</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Ingo Wald, Thomas Kollig, Carsten Benthin, Alexander Keller, and Philipp Slusallek. Interactive global illumination using fast ray tracing. In Rendering Techniques 2002: 13th Eurographics Workshop on Rendering, pages 15--24, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Ingo Wald, Philipp Slusallek, Carsten Benthin, and Markus Wagner. Interactive rendering with coherent ray tracing. Computer Graphics Forum, 20(3):153--164, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Greg Ward and Paul Heckbert. Irradiance gradients. In Eurographics Rendering Workshop, pages 85--98, May 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Turner Whitted. An improved illumination model for shaded display. Communications of the ACM, 23(6):343--349, 1980.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	<article_rec>
		<article_id>1198798</article_id>
		<sort_key>268</sort_key>
		<display_label></display_label>
		<article_publication_date>07-31-2005</article_publication_date>
		<seq_no>34</seq_no>
		<title><![CDATA[Ray tracing on programmable graphics hardware]]></title>
		<page_from>268</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1198555.1198798</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1198798</url>
		<abstract>
			<par><![CDATA[Recently a breakthrough has occurred in graphics hardware: fixed function pipelines have been replaced with programmable vertex and fragment processors. In the near future, the graphics pipeline is likely to evolve into a general programmable stream processor capable of more than simply feed-forward triangle rendering.In this paper, we evaluate these trends in programmability of the graphics pipeline and explain how ray tracing can be mapped to graphics hardware. Using our simulator, we analyze the performance of a ray casting implementation on next generation programmable graphics hardware. In addition, we compare the performance difference between non-branching programmable hardware using a multipass implementation and an architecture that supports branching. We also show how this approach is applicable to other ray tracing algorithms such as Whitted ray tracing, path tracing, and hybrid rendering algorithms. Finally, we demonstrate that ray tracing on graphics hardware could prove to be faster than CPU based implementations as well as competitive with traditional hardware accelerated feed-forward triangle rendering.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[programmable graphics hardware]]></kw>
			<kw><![CDATA[ray tracing]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Graphics processors</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Raytracing</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010374</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Ray tracing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010389</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics processors</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P382471</person_id>
				<author_profile_id><![CDATA[81100647803]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Timothy]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Purcell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35026550</person_id>
				<author_profile_id><![CDATA[81100248942]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Buck]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39035744</person_id>
				<author_profile_id><![CDATA[81100279370]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Mark]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P219805</person_id>
				<author_profile_id><![CDATA[81100482576]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Pat]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hanrahan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[3DLabs, 2001. OpenGL 2.0 whitepapers web site. http://www.3dlabs.com/support/developer/ogl2/index.htm.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>255132</ref_obj_id>
				<ref_obj_pid>77726</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Alverson, R., Callahan, D., Cummings, D., Koblenz, B., Porterfield, A., and Smith, B. 1990. The Tera computer system. In Proceedings of the 1990 International Conference on Supercomputing, 1--6.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Amanatides, J., and Woo, A. 1987. A fast voxel traversal algorithm for ray tracing. In Eurographics '87, 3--10.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258725</ref_obj_id>
				<ref_obj_pid>258694</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Anderson, B., Stewart, A., MacAulay, R., and Whitted, T. 1997. Accommodating memory latency in a low-cost rasterizer. In 1997 SIGGRAPH/ Eurographics Workshop on Graphics hardware, 97--102.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[ATI, 2001. RADEON 8500 product web site. http://www.ati.com/products/pc/radeon8500128/index.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Carr, N. A., Hall, J. D., and Hart, J. C. 2002. The ray engine. Tech. Rep. UIUCDCS-R-2002-2269, Department of Computer Science, University of Illinois.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>55429</ref_obj_id>
				<ref_obj_pid>55364</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Delany, H. C. 1988. Ray tracing on a connection machine. In Proceedings of the 1988 International Conference on Supercomputing, 659--667.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Fajardo, M. 2001. Monte carlo ray tracing in action. In State of the Art in Monte Carlo Ray Tracing for Realistic Image Synthesis - SIGGRAPH 2001 Course 29. 151--162.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>13044</ref_obj_id>
				<ref_obj_pid>13043</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Fujimoto, A., Tanaka, T., and Iwata, K. 1986. ARTS: Accelerated ray tracing system. IEEE Computer Graphics and Applications 6, 4, 16--26.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Hall, D., 2001. The AR350: Today's ray trace rendering processor. 2001 SIGGRAPH / Eurographics Workshop On Graphics Hardware - Hot 3D Session 1. http://graphicshardware.org/previous/www_2001/presentations/ Hot3D_Daniel_Hall.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Havran, V., Prikryl, J., and Purgathofer, W. 2000. Statistical comparison of ray-shooting efficiency schemes. Tech. Rep. TR-186-2-00-14, Institute of Computer Graphics, Vienna University of Technology.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>285321</ref_obj_id>
				<ref_obj_pid>285305</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Igehy, H., Eldridge, M., and Proudfoot, K. 1998. Prefetching in a texture cache architecture. In 1998 SIGGRAPH/ Eurographics Workshop on Graphics hardware, 133-ff.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J. T. 1986. The rendering equation. In Computer Graphics (Proceedings of ACM SIGGRAPH 86), 143--150.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Khailany, B., Dally, W. J., Rixner, S., Kapasi, U. J., Mattson, P., Namkoong, J., Owens, J. D., and Towles, B. 2000. IMAGINE: Signal and image processing using streams. In Hot Chips 12. IEEE Computer Society Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Kirk, D., 2001. GeForce3 architecture overview. http://developer.nvidia.com/docs/IO/1271/ATT/GF3ArchitectureOverview.ppt.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383274</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Lindholm, E., Kilgard, M. J., and Moreton, H: 2001. A user-programmable vertex engine. In Proceedings of ACM SIGGRAPH 2001, 149--158.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383527</ref_obj_id>
				<ref_obj_pid>383507</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Mark, W. R., and Proudfoot, K. 2001. The F-buffer: A rasterization-order FIFO buffer for multi-pass rendering. In 2001 SIGGRAPH/Eurographics Workshop on Graphics Hardware.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Marshall, B., 2001. DirectX graphics future. Meltdown 2001 Conference. http://www.microsoft.com/mscorp/corpevents/meltdown2001/ppt/DXG9.ppt.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Microsoft, 2001. DirectX product web site, http://www.microsoft.com/directx/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134067</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Molnar, S., Eyles, J., and Poulton, J. 1992. PixelFlow: High-speed rendering using image composition. In Computer Graphics (Proceedings of ACM SIGGRAPH 92), 231--240.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[NVIDIA, 2001. GeForce3 Ti Family: Product overview. 10.01v1. http://www.nvidia.com/docs/lo/1050/SUPP/gf3ti_overview.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>288266</ref_obj_id>
				<ref_obj_pid>288216</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Parker, S., Shirley, P., Livnat, Y., Hansen, C., and Sloan, P.-P. 1998. Interactive ray tracing for isosurface rendering. In IEEE Visualization '98, 233--238.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300537</ref_obj_id>
				<ref_obj_pid>300523</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Parker, S., Martin, W., Sloan, P.-P. J., Shirley, P., Smits, B., and Hansen, C. 1999. Interactive ray tracing. In 1999 ACM Symposium on Interactive 3D Graphics, 119--126.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344976</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Peercy, M. S., Olano, M., Airey, J., and Ungar, P. J. 2000. Interactive multi-pass programmable shading. In Proceedings of ACM SIGGRAPH 2000, 425--432.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732126</ref_obj_id>
				<ref_obj_pid>647652</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Reinhard, E., Smits, B., and Hansen, C. 2000. Dynamic acceleration structures for interactive ray tracing. In Rendering Techniques 2000: 11th Eurographics Workshop on Rendering, 299--306.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Spitzer, J., 2001. Texture compositing with register combiners. http://developer.nvidia.com/docs/IO/1382/ATT/RegisterCombiners.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237274</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Torborg, J., and Kajiya, J. T. 1996. Talisman: Commodity realtime 3D graphics for the PC. In Proceedings of ACM SIGGRAPH 96, 353--363.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>732298</ref_obj_id>
				<ref_obj_pid>647653</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Wald, I., Slusallek, P., and Benthin, C. 2001. Interactive distributed ray tracing of highly complex models. In Rendering Techniques 2001: 12th Eurographics Workshop on Rendering, 277--288.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Wald, I., Slusallek, P., Benthin, C., and Wagner, M. 2001. Interactive rendering with coherent ray tracing. Computer Graphics Forum 20, 3, 153--164.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Whitted, T. 1980. An improved illumination model for shaded display. Communications of the ACM 23, 6, 343--349.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
	</article_rec>
	</section>
</content>
</proceeding>

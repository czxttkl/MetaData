<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>06/25/1975</start_date>
		<end_date>06/27/1975</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[Bowling Green]]></city>
		<state>Ohio</state>
		<country></country>
	</conference_loc>
	<conference_url></conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES382</series_id>
		<series_title><![CDATA[International Conference on Computer Graphics and Interactive Techniques]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>563732</proc_id>
	<acronym>SIGGRAPH '75</acronym>
	<proc_desc>Proceedings of the 2nd annual conference</proc_desc>
	<conference_number>2</conference_number>
	<proc_class>conference</proc_class>
	<proc_title>Computer graphics and interactive techniques</proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>1975</copyright_year>
	<publication_date>06-25-1975</publication_date>
	<pages>280</pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<publisher>
		<publisher_id>PUB27</publisher_id>
		<publisher_code>ACMNY</publisher_code>
		<publisher_name>ACM</publisher_name>
		<publisher_address>2 Penn Plaza, Suite 701</publisher_address>
		<publisher_city>New York</publisher_city>
		<publisher_state>NY</publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>10121-0701</publisher_zip_code>
		<publisher_contact>Bernard Rous</publisher_contact>
		<publisher_phone>212 869-7440</publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url>www.acm.org/publications</publisher_url>
	</publisher>
	<sponsor_rec>
		<sponsor>
			<sponsor_id>SP932</sponsor_id>
			<sponsor_name>ACM Special Interest Group on Computer Graphics and Interactive Techniques</sponsor_name>
			<sponsor_abbr>SIGGRAPH</sponsor_abbr>
		</sponsor>
	</sponsor_rec>
	<categories>
		<primary_category>
			<cat_node/>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
	<chair_editor>
		<ch_ed>
			<person_id>PP14276119</person_id>
			<author_profile_id><![CDATA[81100095587]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>1</seq_no>
			<first_name><![CDATA[Robert]]></first_name>
			<middle_name><![CDATA[M.]]></middle_name>
			<last_name><![CDATA[Dunn]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[Fort Monmouth, NJ]]></affiliation>
			<role><![CDATA[Conference Chair]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
	</chair_editor>
	<ccc>
		<copyright_holder>
			<copyright_holder_name>ACM</copyright_holder_name>
			<copyright_holder_year>1975</copyright_holder_year>
		</copyright_holder>
	</ccc>
</proceeding_rec>
<content>
	<article_rec>
		<article_id>563733</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>04-01-1975</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[On the organization of a remote low cost intelligent graphics terminal]]></title>
		<page_from>1</page_from>
		<page_to>8</page_to>
		<doi_number>10.1145/563732.563733</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563733</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP77042027</person_id>
				<author_profile_id><![CDATA[81409591991]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Dill]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[General Motors Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP79027734</person_id>
				<author_profile_id><![CDATA[81100411412]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Thomas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[General Motors Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Cotton, I. W. and F. S. Creatorex. "Structures and techniques for remote computer graphics." Proc. 1968 FJCC, 37, AFIPS Press, Montvale, N.J., 533-544.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cotton, I. W. "Languages for graphic attention handling." Proc. Computer Graphics 70 Symposium, Brunel University, April 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Hobbs, L. C. "The rationale for smart terminals." Computer, Nov.-Dec. 1971, 33-55.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Hobbs, L. C. "Terminals." Proc. IEEE, 60, 1972, 1273-1284.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Joyce, J. D. and 14.C. Cianciolo. "Reactive displays--improving man-machine graphical communications." Proc. AFIPS 1967 FJCC, 31, 713-721.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Machover, C. "The intelligent terminal." Pertinent Concepts in Computer Graphics, Proc. 2nd U. of Illinois Conf. on Computer Graphics, Farman an Nievergelt (eds.), University of Illinois press, Urbana, 1969, 179-189.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Marcotty, M. and H. Schutz. "The systems programming language Malus." Software-Practice and Experience, 4(1), 1974, 79-90.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Prince, D. M. Interactive Graphics for Computer-Aided Design. 1971. Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Ryden, K. H. and C. M. Newton. "Graphics software for remote terminals and their use in radiation treatment planning." Proc. AFIPS 1972 SJCC. AFIPS Press, Montvale, N.J., 1145-1156.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[van Dam, A. and G. M. Stabler. "Intelligent satellites for interactive graphics." Proc. AFIPS 1973 NCC, AFIPS Press, Montvale, N.J., 229-238.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.Siggraph 
75 Bowling Green John C. Dill JamesJ. Thomas Computer Science Department Research Laboratories General 
Motors Corporation 1. INTRODUCTION This paper describes the organization of software for an intelligent 
graphics terminal. The motivations for undertaking this work were twofold. First, current computer-aided 
design work at General Motors is making increasingly heavy use of IBM 2250/III graphics terminals which 
are expensive and generally must be connected by channel to the host. There has also been an increasing 
demand for remote graphics terminals. Thus our primary goal was development of a (relatively) low cost 
terminal and one which could be remoted. A second goal was development of a base for further work in 
the general area of remote processing (e.g. the division of labor problem) for graphics. It is appropriate 
here to outline what is meant by the terms low cost, remotable, and "intelligent." Graphics terminalsare 
available in a wide range of prices and capabilities, from the Tektronix 4010 to the Evans and Sutherland 
LDS-2. Somewhat arbitrarily the attribute low cost is given to those terminals whose base price is under 
$20,000. By remotable is meant simply that the terminal has a ccmmuniactions interface that allows it 
to communicate over telephone lines to a host. More difficult to define is what we mean by intelligent 
terminal. We generally agree with van Dam and Stabler's definition (3,4,6,10) that "intelligence ... 
generally connotes that the device has a degree of autonomy or processing ability which allows it to 
perform certain (classes of) tasks without assistance from the mainframe to which it is connected." More 
specifically, we use the following definitions for graphics terminals : Simple Terminal: These have 
essentially no programmable processing power. Intelligent Terminal: These have a programmable processor. 
Functionally, the processor can be used for extended :editing features, memory.. management, display 
transformations, local interrupt handling, etc. More generally, the processor can be used to enhance 
the capabilities of the hard­ware, or to simulate a more expensive terminal. Intelligent Satellite: 
The primary distinction between this and an intelligent terminal is that there is sufficient processing 
power so that some of it can be controlled by the application. Whereas the processing in an intelligent 
terminal is application­ independent, here the application programmer either controls which programs 
are in the satellite, or programs it himself. This means that tasks ranging from complete execution of 
simple jobs to data structure and picture editing can be accomplished in the satellite. Additional hardware, 
 which generally includes more memory plus some secondary storage, will be required to form an intelligent 
satellite. An intelligent terminal configuration was chosen for our work since it would permit substitution 
of processing power for costly graphics hardware while allowing for develcpment of communication software 
for remotability. Also considered in the selection of a graphics terminal was the base of applications 
to be supported. These ranged from simple plotting systems through statistical data analysis to major 
 high volume production use application systems for computer aided design. The current configuration 
consists of a DEC GT40 (8K core) with 1200 bps asynchronous half duplex voicegrade lines to an IBM 370/168 
host with IBM's TSS operating system. Although 1200 bps is acceptable for a limited number of applications,especially 
to new users, it is not sufficient for experienced users of current major applications. We expect that 
9600 bps or 19.2 bps (synchronous) will suffice for the latter. In the following sections are described 
our design, an analysis of software components, and a summary of our experience so far. The design section 
takes a top down approach, beginning with design constraints, following with an overview of how the major 
components work together, and finishing with a descriptionof the graphic software operation. Since a 
major constraint was core size, the analysis deals primarily with the amount of space required to perform 
various graphic functions. 2. DESIGN This section outlines design constraints, gives an overview of components, 
and details the graphic operations of the terminal software. 2.1 Initial Considerations The major design 
constraints were: core size (which follows from our low cost requirement), remotability (which has implications 
for the communications modules), and the fact that the overall result is to be made available both to 
current users of existing largeapplication programs making use of IBM 2250's and to new users. Users 
of the 2250 had, on average, 8K bytes of display spaceavailable, thus our constraint here is to provide 
at least that much. As a result,all of the software in the terminal was required to fit in 2 -4 K words. 
The primary areas to be supported by the graphic software were: 1. "Display Entities". (5) A display 
is made up of a collection of logically separate items called entities. Each entity is composed of an 
array of contiguous "elements", where an element is a homogeneous array of vectors, points, or characters. 
Under application program control an entity may be enabled or disabled for user selection with the light 
pen. 2. Dynamic Feedback. Any enabled entity must brighten if seen by the light pen. 3. Light Pen. The 
user must be able to point at any location on the displayand have the tracking algorithm "find" the pen, 
after which a tracking cross is to follow pen movements. 4. Text. Character strings are allowed in two 
forms--protected and unprotected.Unprotected text may be modified by the user whereas protected text 
cannot be altered. 5. Function Keys or their equivalent are to be supported.  Also considered in the 
design were various application characteristics. The most important of these were: 1. Displays generally 
consist of large numbers of small entities. A typicaldisplay contains several hundred entities taking 
20 -40 bytes each (2 ­ 4 elements or 7 -30 vectors). 2. An analysis of existing message traffic showed 
a ratio of approximately 50:1 between output (to console) and input(from console). Further, there were 
several hundred to a thousand "interactions" per hour (where an interaction is a light pen selection, 
function key press, etc.). 3. Entity creation and deletion are done far more often than is modification 
of an existing entity.  2.2 Design Overview The primary functions of the terminal­resident software 
are: 1. Build and modify a display file on command from the host. 2. Accept input from the user in the 
form of light pen selections, function key presses, etc., and pass these on to the host application program. 
These requirerelated support . functions such as lightpen tracking, etc. 3. Communication with host. 
In addition to graphic communication, the software must simulate a teletype-like terminal for communication 
with the host command language processor, since the latter does not support graphic consoles.  Because 
there is a single communication line to the host, 1 and 2 above require that the console accept two kinds 
of information: graphic, and TTY(Teletype).So that the console can determine which kind of information 
it is receiving during a given transmission, graphic information is sent in the form of a message  consisting 
of a header followed by data followed by a software generated checksum. The first character of the header 
never appears in TTY transmissions.. The graphicdata is a sequence of one or more graphic commands (e.g. 
add entity to display file). The major components of the console­resident software are communications, 
monitor, TTY simulator, and graphics. The major modules of the latter are Director Code Handler(DCH), 
graphic interrupthandler, and graphic and storage management support routines. In operational overview, 
the communications modules build a message character bycharacter; when complete, the monitor examines 
the header and asses the messageeither to the DCH..or the TTY.simulator. If a TTY message, the simulator 
displays it and the Monitor awaits a reply from the user. The commands in a graphic message are decoded 
by DCH and appropiate modifications made to the display file. Graphic interrupts are processed by suitable 
routines with possible changes to the display file. If there is nothing to process, the monitor goes 
into a hardware wait state to make more cycles available to the display processing hardware.  2.3 Graphic 
Operations Graphic operations are initiated either from the host sending a graphics command hereafter 
called a graphic director code, or from the user through.some input device such as a keyboard, light 
pen, etc. The constraints discussed earlier impose several rules on the format for director codes to 
achieve simplicity, conciseness, and unifornity. 1. All director codes coming from the host must have 
the same format: <function> <length> <data> 2. The number of director codes should be limited without 
penalizing the most frequently used graphic operations. 3. The director codes should be general providing 
greater flexibility in usage. 4. The director codes and their data may not be split across communication 
message boundaries. 5. Any requests requiring a response to be sent back to the host must be the last 
director code in a message.  The director codes implemented are shown in Table 1 with a brief description 
for each. The director code handlers do not interpret the data associated with a function therefore allowing 
the use of "special entities" for I/O device status, graphic mode switches, etc. This simplifies implementation,and 
reduces main line control logic in the intelligent terminal. The data portion of the director codes contains 
data identification (e.g. entity name) and the GT40 display processor code.  The display file organization 
is shown in Figure 1. The two prime considerationsin design are simplicity and space. The display storage 
pool contains two -dynamically changing sections; first, a correlation table(CT) to map the application 
entity names to the actual storage location of the display entity; and second, the actual display data. 
Several storage management schemes were considered using combinations of forward and backward pointers. 
Since the number of entities is large the overhead per entity becomes impor tant. After co mparing 
the increase in overhead plus the corresponding variations in code to support each, the simplest of 
schemes was chosen. Each entity has a single entry in the correlation table consisting of the address, 
 length and name. The Define  Entity operation takes the next slot in the CT and adds the user entity 
on the top of the display list. The Delete Entity operation results in the name field of the CT being 
"nulled" and the display file being routed around the deleted entity. Garbage collection occurs only 
when the current high water mark of CT meets the current high water mark of the entity space. To support 
these operations, the set of storage management functions shown in Table 2 were defined. These functions 
are also used by the graphic support as described later.  2.4 Attention Handling for handling attentions 
 Several methods the constraint  were evaluated(1,2) with that the communications line speed could 
slow as 300-1200 bps half-duplex or be as as 277 Kbps, With attentions  as fast occuring at the rate 
of 1 every 3 seconds, time (of several  the line-turnaround hundred Billiseconds) becomes the dominant 
factor in the entire system. To solve this problen the attention queue must at least in part be contained 
in the remote avoid reads on  intelligent terminal. To every attention a queue is also set up in the 
host. Typically the following sequence of events occur: a set of devices  1.Applicaticnenables for 
attentions. 2. Application continues processing.  3. Application then requests an attention by first 
looking in the host queue. If empty then a read of the remote queue  is issued. For options on the 
read see Table 1. 4. The entire queue is passed to the host only the oldest attention being passed application. 
 2.5 Human Factors One of the prime areas of human factors that must be addressed is dynamic required 
for our feedback. The feedback applications involves four areas. 1. Intensity feedback. As the light 
pen passes over any portion of the entity the entire entity is intensified. This is heavily used especially 
in. complicated displays. An added complexity is introduced when the rule is imposed that only one entity 
per refresh cycle may be intensified. This is done to make it easier for the user to distinguish between 
two entities physically close on the CRT.  2. Light pen Support. The required operations are listed 
in Table 3. The most difficult was full sceeen light  5  pen tracking. The complicating factor here 
was that other support functions (i.e. draw, drag, pick, point, intensity feedback) could be occurring 
simultaneously. Several algorithims were tested (8) with the one shown in Figure 2 having the best response 
characteristics. The density of the medium scan needed was found to be a function of pen field of view 
and sensitivity. 3. Keyboard Interaction. This involved  support for entities that contained unprotected 
character strings.  4. System Status Information. When  designing a graphic system that may have a 
wide variety of interaction rates and communication speeds, it is essential to provide the user with 
a means for determining the current status of the system. This is done by using a four character message 
area indicating the status. Currently the messages indicate: 1. Whether the system is waiting for a 
user input or is executing the application program.  2. Which mode (graphic or teletype) the console 
is in.  3. Which graphic director code was last processed.   2.6 Input Device Support A key design 
decision was to establish all device status (input and output) in a system entity with each device using 
one element. Thus, reading and modifyingdevice status could be done with standard read/modify element 
director codes.  6  3. ANALYSIS OF GRAPHIC FUNCTIONS It is instructive to consider which graphic 
operations utilize the intelligent terminal's resources. Space will be the comparison factor since 
it is the prime resource of a mini based system. The total space used was about 3000 16 bit words. 
 The communications and the graphics software took approximately equal portions of the space. The communications 
included asynchronous half-duplex protocol, TTY message handling with scrolling, and double buffering 
for graphic messages. Since this terminal could be used from a variety of hosts the communications 
had to encode and decode special line protocol characters. Since adding function to the intelligent 
terminal will require more graphics software than communications software, the former will be described 
in more detail. The table below shows a breakdown of the four major areas in the graphics section: 
Graphic Display SupportDirector Code Handlers 44% Storage Management Attention Handling * Queue 12% 
7% A further breakdown is needed to illustrate why the graphic display support utilizes 441:  Cursor 
Control 37%  Full Screen Tracking 12%  Draw Facility 11%  IntensityFeedback 10%  Function Keys Support 
9%  Pick Facility 9%  Keyboard Support 5% Point Facility 4% Drag Facility 3%  These figures will 
depend somewhat on the charactistics of the particular mini­computer and input devices used, but the 
ratios should not radically differ. Thus the following conclusions may be asserted: 1. Communicationsplays 
a major part when developing a minimum graphics facility in an intelligent terminal.  2. The storage 
required for interpeter control and director code handlers averages about 60 words per director code. 
Thus adding director codes to  increase function should not be costly in terms of resource utilization. 
 3. Except for the simpler input devices  (e.g. Function Keys), graphic display control functions take 
a significant amount of space. One should therefore be selective when considering increased function 
in this area. 4. SUMMARY The minimum remote graphic intelligent terminal must be able to perform some 
graphic and support operations to decrease response time, reduce communications,and reduce host cpu time 
by moving device dependent operations to the intelligent terminal. In developing such a system a minimum 
set of graphic functions should be implemented and evaluated with regard to resource utilization in the 
mini-computer. Based on the evaluation, additional functions may be added to make use of available resources. 
It is the authors' opinion that two areas show the greatest potential for attacking the division of labor 
problem between the host and mini: 1. Simple control logic should be added to the current director codes. 
This logic should be specified by the application to be invoked via events in the intelligent terminal. 
The events are an extension of the method used for attention handling. Since the resource utilization 
for director codes was minimal this addition should use up the remaining resources. An example of the 
type cf control to be added is a simple form of the DO CASE and DO WHILE statements described in the 
MALUS language(7). 2. In addition to the control logic a simple means of recording a set of director 
codes should be considered. This involves adding SAVE and REPLAY director codes. Thus, complicated menus 
need not be re-transmitted. Menu stacking and selection logic will also be provided. Resource utilization 
  involves the code necessary to handle recording and replay, and the space required for the pictures 
and associated control logic. Since insufficient resources remain for this, auxiliary storage (e.g. a 
disc) must be added. The system described did fulfill out design expectations in providing low cost 
remotable graphics and will be used in a production environment. It has also provided a sound framework 
for developing increased function for an intelligent graphics satellite. 5. REFERENCES 1. Cotton, I.W. 
and F.S. Creatorex. "Structures and techniques for remote computer graphics." Proc. 1968 FJCC, 37, AFIPS 
Press, Montvale, N.J., 533-544.  2. Cotton, I.W. "Languages for graphic attention handling." Proc. Computer 
Graphics 70 Symposium, Brunel University, April 1970. 3. Hobbs, L.C. "The rationale for smart terminals." 
Computer, Nov.-Dec. 1971, 33-55. 4. Hobbs, L.C. "Terminals." Proc. IEEE, 60, 1972, 1273-1284. 5. Joyce, 
J.D. and 14.C. Cianciolo. "Reactive displays--improving man-machine graphical communications." Proc. 
AFIPS 1967 FJCC, 31, 713-721. 6. Machover, C. "The intelligent terminal." Pertinent Concepts in Computer 
Graphics, Proc. 2nd U. of Illinois Conf. on Computer Graphics, Farman an Nievergelt (eds.), University 
of Illinois press, Urbana, 1969, 179-189.  7. Marcotty, M. and H. Schutz. "The systems programming 
language Malus." Software-Practice and Experience, 4(1), 1974, 79-90. 8. Prince, D.M. Interactive Graphics 
for Computer-Aided Design. 1971. Addison-Wesley. 9. Ryden, K. H. and C.M. Newton. "Graphics software 
for remote terminals and their use in radiation treatment planning." Proc. AFIPS 1972 SJCC. AFIPS Press, 
Montvale, N.J., 1145-1156. 10. van Dam, A. and G. M. Stabler. "Intelligent satellites for interactive 
graphics." Proc. AFIPS 1973 NCC, AFIPS Press, Montvale, N.J., 229-238.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563734</article_id>
		<sort_key>9</sort_key>
		<display_label></display_label>
		<article_publication_date>04-01-1975</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Configurable applications for graphics employing satellites (CAGES)]]></title>
		<page_from>9</page_from>
		<page_to>19</page_to>
		<doi_number>10.1145/563732.563734</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563734</url>
		<abstract>
			<par><![CDATA[This paper reports on CAGES, a programming system which substantially simplifies the process of writing interactive graphics application programs for use in a distributed processing, satellite-host configuration. It allows programs written in a PL/I subset to be configurable: program modules . (main program, subroutines) and data can be easily reassigned from the host to the satellite, or vice versa. That is, the division of labor between the two computers is readily modified.The CAGES system supplements the operating system services normally provided on the host or satellite computers by providing the illusion that the application is executing in a single computer memory with dual CPUs. In reality the application is distributed between the memories of the host and satellite computers. To maintain this illusion CAGES provides three types of services:Inter-computer subroutine CALLs and RETURNs. A subroutine call executed on one computer and targeted to a subroutine resident on the other computer is known as a remote procedure call. It is supported just as one would expect. A message containing the subroutine's name and parameters is sent to the computer where the subroutine is to be executed. Following its execution, a message containing results (modified parameters) is sent back, and the calling routine continues its execution.(2) Inter-computer CONDITIONs. A SIGNAL statement or interrupts on one computer raising a CONDITION for which there is an enabled ON-BLOCK in the other computer is much like a parameterless remote procedure call. It is supported in essentially the same manner as a remote calls.(3) GLOBAL data references. Variables with EXTERNAL scope which may be referenced from subroutines in both computers are known as GLOBAL variables. If, when referenced, a GLOBAL variable is not located in the memory of the referencing computer, the reference is said to be a remote reference.The CAGES system handles such references by obtaining the needed data from the remote computer and placing a local copy of it in the memory of the referencing computer. The program is then allowed to access this copy.Figure 1 illustrates the over-all structure of CAGES. Application programs are written as if they were going to be resident on only one computer. The programmer then adds extended declarations specifying GLOBAL variables and the desired configuration of the application program. These declarations and the source code are input to the CAGES preprocessor. The preprocessor slightly changes the declarations of the GLOBAL variables in the source code, generates some additional procedures, and outputs three files. One file contains procedures destined for the host (IBM 360/75), one contains procedures destined for the satellite (PDP-11/45), and one contains symbol table entries for GLOBAL variables. The (modified) source procedures are then compiled by either the PL/I-F compiler (host procedures) or the PLCD[1,2] compiler (satellite procedures). Finally, the link-editors of each computer combine CAGES run-time routines with the object modules produced by the previous compile steps to produce two executable load modules,one for each computer. Although the implementation at U.N.C. is based on PL/I, other languages which can be compiled for both host and satellite could be used with this approach.It should be clear that CAGES is not a graphics package in the usual sense. Indeed, any graphics subroutines or other graphics support used by the application program appears to the CAGES system as part of the application, as figure 2 shows. Thus CAGES does not require or provide for any particular type of graphic data structure. In fact, the CAGES system is equally useful to non-graphics programs which must for some reason be distributed in the memories of a two computer network.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P330584</person_id>
				<author_profile_id><![CDATA[81100294055]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Griffith]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hamlin]]></last_name>
				<suffix><![CDATA[Jr.]]></suffix>
				<affiliation><![CDATA[University of North Carolina, Chapel Hill, N.C.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P132223</person_id>
				<author_profile_id><![CDATA[81100302796]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Foley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina, Chapel Hill, N.C.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>904146</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Dunigan, T., "PLCD-PL/1 for the DEC PDP-11/45", Master's Degree Thesis, University of North Carolina, Chapel Hill, N.C. 1973]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>904198</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Kehs, D., "Extensions to the PLCD Compiler" Master's Degree Thesis, University of North Carolina, Chapel Hill, N.C. 1974]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[van Dam, A., Stabler, G. M., "Intelligent Satellites for Interactive Graphics", Proc. 1973 National Computer Conference, pp. 229-238.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[van Dam, Stabler, G. M., & Harrington, R. J., "Intelligent Satellites for Interactive Graphics", Proc. of the IEEE, 62,4 (April 1974), pp. 483-492.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>805684</ref_obj_id>
				<ref_obj_pid>800192</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Foley, J. D., "Software for Satellite Graphics Systems", Proc. of the ACM 1973 Annual Conference, pp. 76-80.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>908018</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Stabler, G. M., "A System for Interconnected Processing", Ph. D. Thesis, Brown University Providence, R.I., 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.Siggraph 
75 Bowling Green CONFIGURABLEAPPLICATIONS FOR GRAPHICS EMPLOYING SATELLITES (CAGES) Griffith Hamlin, 
Jr. James D. Foley, Assistant Professor Department of Computer Science Universityof North Carolina Chapel 
Hill, N.C. This work was partially sponsored by the Air Force Systems Command, Rome Air Development 
Center, New York 13441, contracts F30602-73-C-0249 and F30602-74-0296; the National Science Foundation,Grant 
GJ-3444697; and InternationalBusiness Machines, from whom G. Hamlin holds a graduate fellowship. 1. 
INTRODUCTION. This paper reports on CAGES, a programming system which substantiallysimplifies the process 
of writing interactive graphics application programs for use in a distributed processing, satellite-host 
configuration. It allows programs written in a PL/I subset to be configurable: program modules .(main 
program, subroutines) and data can be easily reassigned from the host to the satellite, or vice versa. 
That is, the division of labor between the two computers is readily modified. The CAGES system supplements 
the operating system servicesnormally provided on the host or satellite computers by providing the illu­sion 
that the application is executing in a single computermemory with dual CPUs. In real­ity the application 
is distributedbetween the memories of the host and satellite computers. To maintain this illusionCAGES 
provides three types of services: (1) Inter-computersubroutine CALLs and RETURNs. A subroutine call 
executed on one computer and targeted to a subroutine resident on the other computer is known as a 
remote procedure call. It is supported just as one would expect. A message con­ taining the subroutine's 
name and param­ eters is sent to the computer where the subroutine is to be executed. Following its 
execution, a message containing results (modified parameters) is sent back, and the calling routine continues 
its execution. (2) Inter-computer CONDITIONs. A SIGNAL statement or interrupts on one computer raising 
a CONDITION for which there is an enabled ON-BLOCK in the other computer is much like a parameterless 
remote procedure call. It is supported in essentially the same manner as a remote calls.  (3) GLOBAL 
data references. Variables with EXTERNAL scope which may be referenced from subroutinesin both computers 
are known as GLOBAL variables. If, when referenced, a GLOBAL variable is not located in the mem­ory of 
the referencing computer, the refer­ence is said to be a remote reference.  The CAGES system handles 
such references by obtaining the needed data from the remote computer and placing a local copy of it 
in the memory of the referencing computer. The program is then allowed to access this copy.  Figure 
1 illustrates the over-all structure of CAGES. Applicationprograms are written as if they were going 
to be resident on only one com­puter. The programmer then adds extended dec­larations specifyingGLOBAL 
variables and the desired configurationof the application program. These declarations and the source 
code are input to the CAGES preprocessor. The preprocessor slightly changes the declarations of the GLOBAL 
variables in the source code, generates some additionalprocedures, and outputs three files. One file 
contains procedures destined for the host (IBM 360/75), one contains procedures des­tined for the satellite 
(PDP-11/45),and one contains symbol table entries for GLOBAL vari­ables. The (modified) source procedures 
are then compiled by either the PL/I-F compiler (host procedures) or the PLCD[1,2] compiler (satellite 
procedures). Finally, the link-editors of each computer combine CAGES run-time routines with the object 
modules produced by the previous compile steps to produce two executable load modules,onefor each computer. 
Although the implementation at U.N.C. is based on PL/I, other languages which can be compiled for both 
host and satellite could be used with this approach. It should be clear that CAGES is not a graph­ 
ics package in the usual sense. Indeed, any graphics subroutines or other graphics support used by 
the application program appears to the CAGES system as part of the application, as figure 2 shows. 
Thus CAGES does not require or provide for any particular type of graphic data structure. In fact, 
the CAGES system is equally useful to non-graphicsprograms which must for some reason be distributed 
in the memories of a two computer network.  2. FIXED-FUNCTIONVERSUS PROGRAMMABLE SATELLITES There 
are two basic ways to approach software for satellite graphics systems. One is to make the satellite 
a fixed function "black box" so far as the applicationprogrammer is concerned. He accesses it by subroutine 
calls from the ap­ plication program executing on the host.  FIGURE 1 built into the black box, and 
cannot be easily changed by the user. 2. There is no way to change the division of labor between the 
host and satellite in at­tempts to improve performance, short of going into the black box. This is infeasible 
or at least very unattractivefor an application programmer.  3. This approach simply won't work for 
demanding applications with high interaction rates and short response time requirements, especially if 
non-trivial data base or picture structure is involved.  However, black box systems exist, are in use, 
and are quite suitable for some classes of applica­tions. The second approach uses a satellite which 
the applicationprogrammer can directly program. This gives him direct access to interactionde­vices and 
hence to human factors, and gives him explicit control over the division of processing Notice of user 
actions are sent from the satel­lite to the host, and are processed there. This is most typically done 
with relatively small and inexpensive minicomputers, a display, and perhaps (not necessarily) some bulk 
store. This system approach has several problems: 1. Most user actions have to be handled by the host. 
Only some "fixed functions" such as pen tracking, text input/edit, pen hit feed­back, dragging, etc. 
can be handled locally in the satellite. Further, the basic human factors, or low-level protocols for 
dealing with interaction devices, are necessarily and data, so he can attempt to optimize response time, 
or host usage, or whatever. A. van Dam [3] and Foley [5] have reviewed and discussed both fixed-functionand 
programmable satellites. The problemwith the programmable satellite system is that the programmer must 
learn two languages: one for the host, and another for the satellite. Further, any changes in the division 
of labor come at the cost of recoding a program module in the target computer's language, and changing 
the control structure of those programmodules which interact with the moved module. Van Dam and Stabler 
at Brown [4] and Foley at  U.N.C. [5] have proposed system meant to overcome. these shortcomings, and 
both have been built. The Brown counterpart of CAGES is known as ICOPS [6]. The two systems were built 
with different criteria and techniques. CAGES programs have richer inter-process communication capabilities 
and are written in PL/I, but actually changing a program's division of labor requires a recompila­ tion. 
ICOPS programs are limited to subroutine calls and parameter passing for inter-process com­munications, 
but the division of labor can be changed dynamically at run-time, and ICOPS is not tied to any specified 
language. Both systems represent a stride forward in making programmable satellitesmore viable as useful 
tools in inter­ active graphics. 3. WHY CONFIGURABLE PROGRAMS? The configurable programming approach 
to satel­lite graphics programs is desirable for several reasons, some of which were alluded to in the 
preceeding section. First, explicit programming of both host and satellite often requires the applicationprogram­mer 
to learn two languages. This does not happen with configurableprograms, since the same program is required 
to run on either computer.. Second, configurable programs allow "tuning" the division of labor based 
on performance statisticsgathered during a previous execution. Binding the division of labor when the 
applica­tion is being designed is undesirable, because the programmer cannot always anticipate the ways 
in which programmodules will interact in actual use. Hence the amounts of time and other resources required 
by each module are difficult to determine during the design process. In addition, different users of 
the application may have different styles of use, causing the various parts of the application to be 
exer­cised in different ways. The ability to tune the division of labor allows the application to be 
optimized for an individual user's style. Third, the application programmer does not explicitly program 
inter-CPU communications. Such communications are automaticallyprovided by the run-time system whenever 
a reference to a non-resident procedure or data element is made. The programmer continues to use the 
familiar subroutine call or data reference to implicitly initiate the communication. Fourth, the programmer 
canconceiveof and write the entire application program as a whole, as if it were going to be executed 
only on one computer, without knowing its eventual config­uration. This should be helpful in his concep­tion 
of the applicationas a whole. For exec­ution efficiency, however, he may want to be aware when designing 
the program structure that it will eventually be distributed. He may also want to optimize performance 
for what he considers to be likely configurations. Fifth, program configurabilityis a necessary but 
not sufficient condition for programporta­bility among dissimilar host-satellite systems. This is because, 
when moving to another satellite graphics system, the size of the host and satel­lite computers may change 
drastically. Some parts of the application programmay have to be moved from the satellite to the host 
due to memory or other restrictions on the satellite. Configur­ability is not sufficient for portability. 
The compilers at all installations at which the ap­plication is used must be both syntactically and semantically 
equivalent, and CAGES must be avail­able at each installation. Also, the graphics subroutine package 
used by the application must be device-independentand available for all displays with which the program 
is used. 4. IMPLEMENTATION In this section, each step in preparing and executing a configurableprogram 
is described. The design decisions embodied in this implement­ation are explained and justified. 4.1 
Preprocessor The first step in configuring an application program is performed by the CAGES preprocessor. 
It accepts as input PL/I-like declarations de­scribing which procedures are to reside in which computer, 
and the source code for all procedures. The configuration specification is given separate­ly from the 
source program so that only it need be changedwhen changing configurations. The actual binding of specific 
procedures to the host or satellite thus occurs at preprocess time. This allows the possibility of preprocessor 
analysis of the source program's structure in order to predict references to remote data and procedures. 
This knowledge could allow overlap­ping of the associated inter-computercommunica­tions with processing. 
The CAGES preprocessor does not take full advantage of this ability. It performs only a very simple analysis 
to determine what global data items are referencedwithin each procedure. Also, source program analysis 
could allow the number of system calls to be minimized by placing them in strategic locations. For example, 
consider the source code: DO I=1 to 100; Access global variable; END;  A single run-time system call 
requesting a local copy of the referenced global variable could be placed before the DO statement. Then 
the 100 referenceswithin the loop would not require system help or checking for the presence of the global 
variable. After the loop, the system could be notified to inform it that the applica­tion no longer needed 
the local copy of the glob­al variable. Again the CAGES preprocessor employs a simple strategy of moving 
all such system calls to the beginning of each procedure. Configurationbinding time. The binding of 
the configurationcould be done at other times, ranging from compile time, to link-edit time, to load 
time, to dynamically during execution. In the latter case, all calls between procedures and all references 
to data with global scope-are potentially remote references. The run-time system must intercept all 
of these references. "dope vectors" (data descriptions)maintained by This would produce considerable 
run-time overhead if calls to the run-time system were inefficient. Many such calls will be needlesslymade 
because the referenced object will already exist at the referencing computer. Also, two copies of each 
procedure must exist, one on each computer. This could be costly in terms of space if the proce­dures 
for the satellite must be kept in the satel­lite's main memory, which is usually at a premi­um. Dynamic 
binding is employed by ICOPS at Brown, using a very efficient run-time system. The ad­vantage is that 
the configurationcan be quickly altered to take advantage of changes in the host's work load during execution. 
Preprocess-timebind­ing of the configurationwas chosen for the CAGES system primarily for the ability 
to perform pre­paging analysis of the source program. The dis­advantage of this is, of course, that one 
must preprocess and recompile in order to reconfig­ure the application. Global Data. The preprocessor 
creates two files of source code, one for each computer. All glob­al variable declarationsare changed 
from EXTERNAL to BASED on an external pointer. This allows the run-time system to manage the storage 
allocation policy of global variables. The run­time system can access global data by knowing the names 
of the external pointers, which are generated by the preprocessor. A second change to the application 
source code is to insert a run-time system call somewhere before each global is referenced. This call 
re­quests the run-time system, if necessary, to copy one or more global variables from the remote com­puter. 
This "prepaging" of remote data allows the inter-computerI/O to overlap application program execution. 
Prepaging (as opposed to demand paging) is more attractive in a distrib­uted program than in the typical 
batch paged program. This is partly due to the longer time required to obtain a global data item and 
partly due to the absence of multiprogrammingon many satellite computers. Upon referencing a remote­ly 
located data item, after the request for the data is sent to the host computer, the satellite has nothing 
to do but wait idle until it arrives. There is usually no other user whose task could be run. Furthermore, 
the time spent waiting is at least the time required for sending and re­ceiving a message via the inter-computer 
com­ munications channel. This is typically much longer than the delay incurred when accessing a paging 
disk or drum in a paging environment. This is certainly true if the inter-computer channel is a low-speed 
line (not uncommon) or if the host's work load is heavy. A third file of output created by the prepro­cessor 
is a symbol table with an entry for each global data item which is not a PL/I structure. It is used 
at run-time to aid in the translation of global data from one computer's representation to the other's 
representation. To do this it is necessary to know the data type and number of dimensions of all arrays. 
Other information such as string lengths can be obtained from run-time PL/I. For global variables 
which are PL/I structures a different approach is taken. In this case the preprocessor generates PL/I 
source code to effect the data translation. This is done because of the added complexity of saving in 
the run-time symbol table information describing the structure of these globals. Interpretingsuch information 
at run-time would require much more CPU time than is needed by generated code tailored to each global 
structure. Remote Procedures. The preprocessor generates and places in the source code output files 
dummy procedures corresponding to each remotely called procedure. These dummy procedures have the same 
 name as their remote counterparts but they reside in the calling computer'smemory. Thus these dummy 
procedures intercept all remote calls. As the example of Figure 3 shows,they also execute exactly the 
same ON statements that are in the remote procedures. This is done in order to intercept any condition 
that might be raised on one computer for which there could be an ON- BLOCK activated on the other computer. 
Next, these dummy procedures format and send an inter­ computer message containing the actual argument 
values for the remote call. They then wait for the remote procedure to finish executing, receive the 
message containing changed parameters, and update the actual arguments of the caller. The approach 
of generating specialized code to handle parameter translation for remote calls and global structures 
is more efficient of CPU time than a single generalized table-drivenrun-time subroutinewould have been. 
 In addition, generated code is more independent of the implementationof the language in which it is 
written. For example, the compiler's methods for mapping arrays and structures onto memory would not 
effect generated code. The table-drivenrun-time subroutine approach would have to make much more use 
of knowledge of the particular implementationof the application language in order to access arbitrary 
types of data without declaring them properly. Hence this latter approach loses portability to another 
host­satellite system where there may be a different implementation of the language. On the other hand, 
the table driven approach requires less memory at run-time than does the generated source code approach. 
 4.2 Compile and Link-Edit The second step in the CAGES system is to com­pile with the PL/I-F compiler 
all procedures (including generated ones) for the host computer, and to compile using the PLCD [1,2] 
compiler, all procedures for the satellite. The PLCD com­piler implements only a subset of PL/I-F, which 
is briefly described in Appendix II. Hence only that portion of PL/I acceptable to both com­pilers may 
be used in any application procedures that the programmer may wish to move between host and satellite. 
 Next the compiled object modules are ling-edit­ed together using the link-editors provided with each 
computer's operating system. Since the pre­processor inserted references to the CAGES run­time system, 
the link-editor's library call mechanism automatically includes the required CAGES run-time routines. 
In addition, any pre­viously compiled subroutines called by any of the application procedures are also 
linked in. An example of such subroutines could be the graph­ics package used by the application program. 
These subroutines may be written in any PL/I cal­lable language, but may not reference any global data 
or procedures. They may execute SIGNAL statements or ON-BLOCKS for conditions in the other computer. 
They may also call and be called by remotely located procedures provided they were properly declared 
to the preprocessor in the specification of the configuration.  4.3 Executionof a Configurable Program 
 Global Data Allocation. The two load modules thus produced by the link-edit step can now be executed 
on their respective computers. The CAGES run-time system subroutines which were incorporated into the 
load modules perform several functions. First, they manage the storage allocation for global variables. 
A "floating" policy is used rather than assigning each global variable to a computer. That is, global 
variables have no permanently assigned "home" computer. When referenced by any computer they simply move 
to that computer and remain there until referenced by the other com­puter, or until their storage is 
needed for some other purpose. In some situations this policy saves unnecessary transfers of a global 
variable. For example, consider the situations of Figure 4. ProcedureA on the host calls procedures B 
and C on the satellite several times. Global variable X is referenced each time B is called and between 
 calls to C. If X were permanently assigned to the host computer, it would be needlessly transferred 
 between computers each time B is called. If it were permanently assigned to the satellite, it would 
be transferred each time C returns to A. However, by allowing it to "float", it will only be transferred 
to the satellite once upon the first call to B, and will be transferred to the host once after the 
first return of C. This "floating" global storage policy is not without cost. Initially, global variables 
exist nowhere and storage must be allocated for each global on the computerwhich first references it. 
 More important, both computers must be checked for the presence of a global variable before an access. 
The fixed policy allows one computer to eliminate this checking. Checking by software in lieu of address 
translation hardware on the satel­ lite could be very costly. However, CAGES mini­mizes the number of 
such checks to at most once per procedure so that these costs are bearable. Allowing global data to 
"float" also requires a global data replacement policy which specifies when storage for global data is 
to be freed if the preprocessor does not specify such freeing by in­serting run-time system calls. This 
is analogous to a page replacement policy in a paging environ­ment. Such a policy is not needed with 
"fixed" allocation of globals, as it is then determined by the assignment of globals to computers. The 
CAGES run-time system simply frees all global variables which no longer have correct values in the copy 
on the computer requiring memory. As a consequence of the minimization of check­ing for the existence 
of local copies of global data (see section 4), the run-time system must remember which global variables 
have been checked  in each computer. Such globals must remain present number of global variables, and 
S is the number of in a particular computer until such time as the application program no longer assumes 
that they are present. Hence after any action that cannot be anticipated by the source program analysis 
 (such as activation of an ON-BLOCK or procedure after an interrupt) which could cause a global data 
item to no longer be present,the run time system must check again to insure that all pre­viously present 
globals are still present. If they are missing, the applicationprogram must wait until they can be brought 
from the other computer. The run-time system and preprocessor of the CAGES system assume that once created, 
a local copy of a global data item will remain avail­ able until the procedure that created it finishes. 
 Inter-ComputerMessages. Another service of CAGES' run-time system is to handle all inter­ computermessages. 
As a consequence of overlap­ping global data I/O and processing, messages may arrive at arbitrary times. 
Hence, a second task is created by the CAGES run-time system in each computer. This task continously 
monitors the inter-computerchannel for messages. Some mes­ sages can be handled by the system message 
task without notifying the application task(s). Others specify some action which requires application 
 program intervention, such as a remote procedure call. For these messages, the system message task 
sets a flag which will be tested by a CAGES run-time system routine executing under the application 
task. If the application program's flow of control leaves a computer more than once, this CAGES run-time 
routine is recursively act­ ivated once for each time the program flow leaves the local computer. The 
stack of such activ­ ations which could be built up by application programcalls back and forth between 
the two computers insures that all arriving messages will be handled promptly and replies to previous­ 
ly sent messages will reach their proper sender. Figure 5 shows an example of this in which act­ ivations 
stack up two levels deep due to three remote subroutine calls. 5. CAGES RESOURCE UTILIZATION The complete 
run-time system of CAGES requires about 21,600 bytes on the PDP/11satellite, and 33,000 bytes on the 
IBM 360/75 host. Further­more for each procedure which is remotely called there may be a generated dummy 
procedure on the calling computer. Finally, for each global variable there is a symbol table entry on 
each computer, and for each structured global vari­able there is some code generated for both com­puters 
to effect translationbetween internal representations. Thus the storage required to run the CAGES system 
on the host computer is about 33,000 + 500*N1 + 300*N2 + 20*M + 500*S bytes. The storage required on 
the satellite is about 22,200 + 20*N1 + 260*N2 + 16*M + 300*S bytes where N1 is the number of remote 
procedures cal­ led from the host, N2 is the number of remote procedures called from the satellite,M 
is the structured global variables. If no global data is required by an application, only a subset 
of the satellite-resident run-time system need be linked with the application. This reduces the satellite 
space requirement by about 18,000 bytes. In addition, if the application program has no remotely signalled 
ON-units, the term 260*N2 in the above formula becomes 16*N2+300. Data on CAGES CPU-time requirements 
was collect­ed during execution of an application which had been retro-fitted to run under the CAGES 
system. Therefore the structure of the various applica­tion modules was not designed to help minimize 
distributionoverhead. The application is a man-machine interactive solution to a numerical analysis problem 
of fitting a multicomponent ex­ponential function to a set of exponentially decaying data containing 
large amonts of noise. It originally executed on an IBM 360/40 using an IBM 2250 display. The structure 
of the various procedures in this application is given in Figure 6. Also shownare two different configurations 
that were tried. In both configurations the 14 main-lineprocedures which perform the floating-point calculations 
required by the 14 steps in the solution process are placed on the host computer. During execution each 
of these procedures is executed once, in the order shown. After performing its calculations, each procedure 
causes a picture to be shown to the user. Based upon this picture, (usually a graph), the user inputs 
parameters for the next step in the solution process. The subroutine ATTN which waits for all user inputs 
and returns them to its caller is placed on the satellite in both configurations. The six procedures 
that are moved in the different configurations create the display program when called by the main-line 
routines. These six procedures accept data in a form used by the main-line programs and with the aid 
of a graphics package for the Vector General display, create the display program. When using the first 
configuration, there were many more inter-computer calls and many more mes­sages. This is because several 
of the V.G. program generating subroutines had to be called to build each complete picture shown to the 
user. In this distribution,CAGES run-time routines used 24% of the total CPU time on the host computer. 
The total of all 14 response times (time from user input until the next picture is shown to him) was 
45 seconds. When using the second configuration, only one inter-computercall to the procedure ATTN was 
required for each display to the user. However, the entire Vector General program built on the host had 
to be sent to the satellite computer. Therefore the total number of words in inter­computer messages 
was not radically different (up 35%). The CAGES system used only 6 1/2 of the host's CPU-time. However, 
the total response time increased from 46 seconds to 61 seconds. It must be realized, however, that 
if CAGES were not providing inter-processorcommunications services, the application program would. 
Thus major portions of the 24% and 6 1/2% of CPU time are not being "added on" by CAGES; rather, the 
 time is just shifted from the application program to CAGES. Since the applicationwas originally written 
for one computer, no advantagewas taken of pos­sible parallelism. The satellite computer could logically 
generate parts of the Vector General program at the same time as the host is calcul­ating more data to 
be used in other parts. However, the main-line programs would have to be changed so that a multitasking 
call to a satel­ lite-resident Vector General program generating subroutinewould be made as soon as 
data needed for that call was calculated. This should improve response times, but would represent changing 
the original application, which we wished to avoid. Other applications are now being written at U.N.C. 
for use with CAGES. These applications can be structured during their design to take advantage of their 
eventual distributed execu­tion on two computers.  6. SUMMARY In summary, a configurable program approach 
to the problems of host-satelliteprogramming has been implemented. Based on the experimental use of the 
system with a few applications to date, it does in fact facilitate easily changing the divi­ sion of 
labor between host and satellite. In implementing such a programming system there are several design 
decisions which involve trade­offs. Some are based on the designer's ideas of the relative frequency 
of occurence of several types of situations that typical ap­ plications programs will produce. The wisdom 
 of one set of answers to these questions is being tested by the CAGES implementation. These include 
the decision to provide for prepaging of global data, the global data allocation policy, the use of 
generatedvs. table-drivenrun-time subroutines for data translation,and the manner of checking for the 
presence of global data items in each computer. Indeed, whether or not to allow global data items at 
all represents a decision based on the designer's ideas about the use­fulness of that ability vs. its 
costs in memory and run-time complexity. Experimental usage to date with the CAGES system indicates 
that "tuning" the configuration of the application after it has executed is very useful. It can significantly 
improve response times over the configuration in which the satel­ lite is a "fixed function" black box, 
used only to access graphics devices. To aid the programmer in obtaining an effi­cient distribution,a 
mathematical directed graph model of a distributed program is being developed. With it we wish to understand 
the essential at­tributes an application must have in order to be efficiently distributable. This will 
be com­municated to applicationsprogrammers by a set of programming guidelines for designing and writing 
configurableprograms. The more general case of distribution of a program among N computers in a network 
is more complex. There can be more than one type of inter-computer connection. Also, each computer must 
have available tables of information tel­ ling where each remote procedure and data item is located 
at any time during execution. These problems have not been attacked by the current CAGES implementation. 
 Appendix 1 --using the CAGES system Restrictions on the Application Program The following restrictions 
must be observed by the application program: 1. Only EXTERNAL procedures can be reconfigured (placed 
on either computer).  2. No BASED or CONTROLLED data types can be  'global' (i.e. referenced from either 
com­puter at run-time).  3. No POINTER,BASED, or CONTROLLEDvariable  types can be parameters in a 
remotely called procedure. BASED variables can be used as arguments in a CALL, but the corresponding 
 parameters cannot be declared BASED in the called procedure. The same is true of CONTROL- LED. 4. Because 
the PLCD compiler accepts only a sub­set of the PL/I language, any procedure that is to be placed on 
the satellitemust be written in that subset of PL/I. Also, all global data items must have attributes 
found in that subset.  5. Multiprocessingmay be accomplishedby a PL/I  multitasking call from a host-resident 
to a satellite-resident subroutine. However, no series of inter-computercalls or signals is allowed that 
would imply the existence of more than one task on the satellite computer. In addition, the calling 
task should not access any of the parameters that the sub-task may change. This is because it is necessary 
to pass parameters by value-result to remotely located procedures, rather than by reference as would 
otherwise be the case. Hence if a calling procedure references the parameters of the called remote task 
before the remote task completes, it could get different values than if the called procedure had been 
passed its parameters by reference. 6. Programs that are not written in PL/I or are not input to the 
preprocessor for some other reason may not access global data items. Provided they are proerly declared 
to the pre­processor in the specification of the config­ uration, they may call or be called by remote 
procedures, and may signal remote ON CONDITIONS. All such calls and signals must follow PL/I conventions. 
 7. The CAGES system does not support inter-com­puter files. To reference a file located on the remote 
computer, it is suggested that an "accessing subroutine" be written which resides on the same computer 
as the file. This subroutine reads the file and returns a record to its caller as a paramater. Specificationof 
a Configuration One of the preprocessor's inputs is a specifi­cation of the desired configuration. The 
syntax used is that of PL/I DECLARE statements with 5 additional keyword phrases allowed. The syntax 
of each clause in these declarations is of the form: entryname ENTRY (attribute list) RETURNS (attribute 
list) SATELLITE or HOST SETS(number list) USES(numberlist) CALLS(entryname list) ONS(on-condition list) 
EXTERNALS(externalvariable list) or  variablenameEXTERNAL other PL/I attributes Rules for use: (1) 
Every procedure or entry point that may be remotely called must appear as entryname in exact­ly one 
clause. (2) If the entry point has any parameters they must appear in the ENTRY phrase. This phrase 
must be placed first.  (3) If the entry point returns any value it must be described in the RETURNS 
phrase. This phrase, if present, must follow the ENTRY phrase.  (4) The positional keyword HOST or SATELLITE 
must appear immediatelyafter the ENTRY and RETURNS attributes to place the procedure on a particular 
computer. All secondary entry points into an external proceduremust specify the same  computer.  (5) 
SETS and USES are always optional. If used they describewhich parameters are written into (SETS) and 
which are only read (USES). The number­list contains the position number of each para­meter which is 
either set or used. If both SETS and USES are omitted all parameters are as­sumed to be both SET and 
USED. (6) If the entryname calls any other external procedure which might be remotely located, they 
must appear in a CALLS clause.  (7) If entryname is a procedure name, all ON unit names which appear 
anywhere within the proceduremust appear in an ONS phrase, separated by commas.  (8) The names of all 
global external variables which are referenced by entryname must appear in an EXTERNALS phrase. It is 
always acceptable to list the names of all EXTERNALvariables  referenced by entryname. (9) Each global 
data item must appear as variable­name in one EXTERNAL clause. Its declared at­tributes must follow. 
 After interpreting the above control cards the preprocessor reads all source procedures from dataset 
SOURCE. Each external procedure is preceeded by a statement of the following form: *PROCESS(procname); 
 where procname is the name of the procedure which follows. The *PROCESS must be written in card columns 
1-8. Normal PL/I is used within each procedure with one exception. Variables which were declared EXTERNAL 
in the control cards (see (9). above) should not be declared in the source program. Instead they should 
appear in a statement of the form *DCL name-1,name-2,...,name-n The *DCL must be written in cards columns 
1-4. All global variablesmust appear in such state­ments, and all EXTERNAL variables may appear in such 
statements. Use of the *DCL and *PROCESS statements in the source text, and the extended entry declarations 
in the text specifying the configuration, elim­inates the need for a full preprocessor parse of the actual 
PL/I text. All the informationneeded could be obtained directly from standard PL/I source code with an 
OPTIONS clause added to each procedure statement stating where the procedure is to be placed, but the 
cost of doing so would be high. Alternatively,much of the information could be obtained from the compiler's 
symbol ta­bles, but we did not have available the manpower needed for such a course.  An Example Suppose 
that procedure A calls procedure B, and B calls procedure C. We wish procedure A and C to be resident 
on the host computer and procedure B to be on the satellite. These procedures each have one or two parameters 
as seen from the part­ial listing of their source code in Figure 7. Procedure A referencesEXTERNAL data 
items I and J, procedure B references I, J., and K, and procedure C referencesK and L. The specifica­tions 
of the configuration shown in Figure 7 is written as follows: DECLARE A ENTRY HOST CALLS(B) EXTERNALS(I,J), 
B ENTRY(FIXED BIN,FIXED BIN) SATELLITE CALLS(C) EXTERNALS(I,J,K), C ENTRY(CHAR(*) HOST EXTERNALS(K,L); 
 DECLARE I EXTERNAL FIXED BIN, J EXTERNAL CHAR(4), K(10) EXTERNAL FIXED BIN, L(10) FIXED BIN EXTERNAL; 
 Appendix II --PLCD Features The PLCD compiler supports storage classes of AUTOMATIC, BASED, EXTERNAL 
AND STATIC. Data types are FIXED BIN(15,m), (-16 m 16), BIT(m) and CHARACTER(m), (0m 256), FILE and LABEL. 
 Variables can be used in arrays and structures. Statements types allowed are assigned, DECLARE, PROCEDURE, 
CALL DO-WHILE, BEGIN, END, RETURN, STOP, EXIT, GOTO, IF-THEN-ELSE, ON, REVERT, SIGNAL, limited forms 
of GET AND PUT, sequential READ and WRITE, OPEN, CLOSE, ALLOCATE, AND FREE. In addition, a number of 
built in functions are provided. There are a few syntactic and semantic differ­ences between the above 
subset of PL/I and PLCD. Some of these the preprocessor accomodates; others the application programmermust 
still be concerned with. Our goal is to completely remove at least this latter class of differences. 
 REFERENCES 1. Dunigan, T., "PLCD-PL/1for the DEC PDP-11/45",Master's Degree Thesis, University of North 
Carolina, Chapel Hill, N.C. 1973  2. Kehs, D., "Extensions to the PLCD Compiler" Master's Degree Thesis, 
University of North Carolina, Chapel Hill, N.C. 1974  3. van Dam, A., Stabler, G. M., "Intelligent Satellites 
for Interactive Graphics", Proc. 1973 National Computer Conference, pp. 229­  238. 4. van Dam, Stabler, 
G. M., &#38; Harrington, R. J., "Intelligent Satellites for Interactive Graphics", Proc. of the IEEE, 
62,4 (April 1974), pp. 483-492.  5. Foley, J. D., "Software for Satellite Graphics  Systems", Proc. 
of the ACM 1973 Annual Conference, pp. 76-80. 6. Stabler, G. M., "A System for Interconnected Processing", 
Ph. D. Thesis, Brown University Providence,R.I., 1974.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563735</article_id>
		<sort_key>20</sort_key>
		<display_label></display_label>
		<article_publication_date>04-01-1975</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[The development of a dynamic interactive computer graphics research and educational support environment]]></title>
		<page_from>20</page_from>
		<page_to>31</page_to>
		<doi_number>10.1145/563732.563735</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563735</url>
		<abstract>
			<par><![CDATA[The Pennsylvania State University Computation Center is currently performing research and development in providing an effective research and training support environment which enables a user, whether researcher or student, to become familiar with an available base of graphics hardware and software support and to proceed to original programming with confidence and effectiveness.The main consideration is to provide an interactive programming environment in which users can become self-sufficient in coping with both hardware operation and potential as well as effective utilization of software in a reasonably short period of time. Such users should not have to be computer graphics specialists to apply a graphics system to their fields of expertise. Users should be thoroughly trained to understand and handle an available hardware/software system in order to be better able to evaluate the potential system usage directly and effectively.This paper, together with a film, describes an approach developed at the Computation Center and tested and implemented in three offerings of a Computer Science advanced undergraduate course.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P362633</person_id>
				<author_profile_id><![CDATA[81100460244]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Frederick]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Stocker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Pennsylvania State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379798</person_id>
				<author_profile_id><![CDATA[81100449037]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Gerald]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Johnson]]></last_name>
				<suffix><![CDATA[Jr.]]></suffix>
				<affiliation><![CDATA[The Pennsylvania State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379800</person_id>
				<author_profile_id><![CDATA[81100391663]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Herbert]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[McKinstry]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Pennsylvania State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[AMRMX, Disk System Resident Monitor, Programmer's Reference Manual, Revision B, May, 1972, page 45-48.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[(IBM 360) JCL Techniques, The Pennsylvania State University, December, 1971, page 30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[IBM System/360 Operating System, Job Control Language Reference, File Number S360-36, Order Number GC28-6704-03.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Classes taught at the Pennsylvania State University during Spring and Fall terms, 1973 and Spring term, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Graphic Geometric Perception and Communication, F. R. Stocker and T. Minsker, Journal of Computers and Graphics, Volume 1, Number 1, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Adage Programmer's Reference Manual, Vol. 1, Edit 7, 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Adage Programmer's Reference Manual, Vol. 1, Fortran IV, February 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Adage start-up procedure, P.S.U. Computation Center, July 2, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Stocker and Minsker-Graphics Transformation Comprehension and Evaluation, to be published.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Log and Sawing Simulation Through Computer Graphics, S. M. Pnevmaticos, P. E. Dress, F. R. Stocker, Forest Products Journal, Volume 24, No. 3 pages 53-55, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Developed as part of a materials science film series under N.S.F. contract GY-7698.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 The Development of a Dynamic Interactive Computer Graphics Research and Educational Support Environment 
 Frederick R. Stocker Gerald G. Johnson, Jr. Herbert A. McKinstry The Pennsylvania State University 
 The PennsylvaniaState University Computation Center is currently performing research and dev­elopment 
in providing an effective research and training support environment which enables a user, whether researcher 
or student, to become familiar with an available base of graphics hardware and software support and to 
proceed to original programmingwith confidence and effectiveness. The main consideration is to provide 
an interactive programming environment in which users can become self-sufficient in coping with both 
hardware operation and potential as well as effective utilizationof software in a reasonably short period 
of time. Such users should not have to be computer graphics specialists to apply a graphics system to 
their fields of expertise. Users should be thoroughly trained to understand and handle an available hardware/software 
system in order to be better able to evaluate the potential system usage directly and effectively. This 
paper, together with a film, describes an approach developed at the Computation Center and tested and 
implemented in three offerings of a Computer Science advanced undergraduate course. Introduction Although 
Graphics support scopes have been available since the advent of computer technology, recent developments 
during the past fifteen years have enabled computer.systems to support dynamic man/machine interaction 
through the use of such devices. At one time, each application utilizing graphics imagery necessitated 
total dedication of a researcher over an extended period of time. This included the need to acquire considerable 
knowledge of computer graphics. More recently, computer systems have made it much more feasible Permission 
to make digital or hard copies of part or all of this work or personal or classroom use is granted without 
fee provided that copies are not made or distributed for profit or commercial advantage and that copies 
bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on 
servers, or to redistribute to lists, requires prior specific permission and/or a fee.Siggraph 75 Bowling 
Green for researchers with varied backgrounds to achieve day-to-day results through hands-oninteraction. 
There is now a need to increase the availability of resources to maximize researcher efficiency with 
minimal resource allocation. Systems need to be developed which: 1. Allow a researcher to interact 
directly with computer systems without first having to obtain detailed information about the system environment. 
 2. Rapidly maximize a researcher's com­petence in an interactive graphics environment.  3. Allow a 
user to grasp the fundamentals of the system so that the user eventually feels comfortable in operating 
the computer system.  4. Reduce the researcher'sinvolvement with primary resources as sophisticationin 
system usage is developed.  5. Minimize the demands upon people already familiar with the system.  
 Such a system has been designed, tested and implemented, and is in interactive development at the Computation 
Center on an Adage Model 30 Graphics Terminal. System Implementation A front-end interface was desired 
which would allow a computer user, whether novice or sophisticate,to achieve system comprehension within 
an interactive self-guiding control environment. Such a structure should provide the user initial hands-on 
usage of the system with a minimum of apprehension. It was desired that such tasks as file editing, program 
loading, program execution, library demonstration and hardware operation be available to the user without 
requir­ing the continual supervision of a system console operator. The implemented system consists of 
interactive computer control programs which allow the basic operation of the Adage Graphics Terminal 
to be placed under the control of a novice, be he a researcher or a student. 20 guagel is an interactive 
systems operating programmer to pass on computer graphics infor­language, providing a set of commands 
for step­ The ADAGE AMOS2 monitor job control lan­ being enhanced, which allows the knowledgeable mation 
once it has become advisable or necessary by-step interactive systems control. The macro to do so. 
Typical areas include: 2-D/3-D feature permits the combination of control image structuring, dynamic 
motion techniques to commands in a manner similar to the catalogued enhance structure meaning, spatial 
interaction procedure languages provided by various current techniques, along with the prerequisite 
software 23 systems.' " In addition the Adage Macro facility programming references. provides higher 
level programming support for system development. Through the use of the Adage command language, a structure 
has been evolved at the Computation Center which pro­vides for dynamic user support. This structure aids 
the user in so far as he needs help with basic systems operations. Nature of Implementation In order 
to become accustomed to the graphics environment, the user's first several sessions on the system are 
attended by a know­ledgeable programmer/operator. The user is shown how to handle the hardware and is 
assisted in areas of weak comprehension. With such an orientation an individualwill typically reach a 
productive operations level within two to four sessions of 45 minutes each. This phase has been successfully 
tested by about 30 research users drawn from many different university disciplines as well as three 
classes of undergraduate and graduate students of computer graphics (a total of 70 In designing the system, 
extensive thought was given, and structure implemented, to help the novice avoid the pitfalls inherent 
in having a full systems control language available at his fingertips. For example, such areas as software/ 
hardware failure detection and file storage and removal, have verification levels built into the structure 
to aid the user. In addition, whenever the user is in potential difficulty with respect to basic systems 
operation, a warning and/or assistance is given by the system. Such assis­tance may be ignored by the 
operator unless it is in a critical operations area where it may affect other users, in which case additional 
 assistance is given. If unexpected events occur related to either hardware or software, then the user 
may enter control and/or recovery areas where diagnostics are available to aid him in determining if 
the situations encountered are due to this programming or to systems software/ hardware problems. The 
trainee is first introduced to the rudiments of the hardware and software support. The trainee is then 
required to demonstrate a basic ability to handle the hardware before being allowed to operate the system 
alone. Available to the user is a set of programs which may be used in the enunciation and clarificationof 
systems and hardware concepts. These programs are first encountered in the presence of a knowledge­able 
programmer. The program allows visual reference to structure, motion, and interaction techniques that 
indicate potential image support in the researcher's problem area. For example, in the Pennsylvania State 
University Adage implementation,a 3-D graphics training support package has been developed, and is currently 
 Proper use of the above package allows the user to feel comfortable with the available graphics system 
as learning progresses. The user is in an environment which rapidly allows the application of developed 
skills to the user's basic research. The user operates the system confidently and alone. He continually 
gains an increased sense of control over the hardware with minimal hands-on time. This is particularly 
 important since programmers and computer science departments typically can obtain, at most, a minimal 
amount of experience in the hands-on approach to computer hardware systems. This is due in part to 
the high costs of large powerful systems. After becoming qualified, the user is allowed to schedule 
available time at his own convenience at any time of the day or night. Thus the trainee is permitted 
full interaction with the system and is allowed to operate with no further human supervision. The fundamentals 
of the system are presented to him while he pursues his research. As the user continues to operate, 
 necessary informationwhich is germane to his area of operations is presented. Users are allowed to 
proceed at their own rate in becoming competent, as well as comfortable,in the use of the available 
hardware and software. As the programmer becomes more sophisticated in systems interaction, he may 
eventually modify, ignore or delete various components of the control infor­ mation, allowing him to 
redirect control in a manner most suitable to the support of his research endeavor. This approach 
allows one to develop a familiarity with the interactive job control language resulting in better comprehension 
of the fundamental control and operation of a computer hardware structure from a software standpoint. 
Tasks such as system bootstrapping techniques, interacting with a monitor control program, preparing 
a card-like file, printing a.card-like file, editing a computer program, compiling a program, on line 
debugging, disk file storage and retrieval, graphic image display and plotting, and file backup and 
recovery, become second nature to the user as a result of his willingness to work and develop through 
hands-on interaction. The novice user is given full macro support, and, as experience is gained, the 
user may invoke higher levels of macro processing, causing many tasks to become transparent. Thus, the 
system developed on the Adage allows for varied and evermore complex interaction as the researcher's 
 comprehension increases. The structure specified in Table 2 indicates Documentationand Graphics Support 
 how the macro operating system eliminates the Manufacturer's manuals, delivered in machine­readable 
form, were first rewritten in modular form, and are now dynamically updated as problem areas are encountered. 
Areas of user difficulty are rapidly upgraded, thereby increasing the effectivenessof documentationfor 
the present and future. When a knowledgeable programmeris available, a mechanism is provided whereby 
the trainee can specify difficulties,real or imagined, which have come to his attention. DetailedDescription 
of the System Control Implementation Almost everyone experienced in computer systems is familiar with 
the problems of computer operation. The Adage command facility allows an experienced operator to interactwith 
the system to perform a variety of tasks. Tasks such as programediting, compilation, assembling, execu­tion, 
file and image printing, and storage checking, core interrogation,general systems are simpli­ maintenance,training 
and diagnosing fied through use of the macro operating system. For example, after initializing the system, 
the operator may want to retrieve and edit a file of He may then want to run a Fortran source text. 
 compilation on the resultant source text, load the file produced by the compilation (with all references 
being resolved), execute the program and check the results of the execution. If a "bug" is encountered 
at any step the procedure can be repeated. Otherwise, once satisfying results are obtained, the operatormay 
reenter a text editor and save the program text, make a hard copy of the text and finally terminate 
the session. A set of monitor commands for such a session is contained in Table 1. The above session 
requires that a user know a great deal about the system, including such things as: 1. What each program 
does  2. Where each program is stored  3. What work space is available  4. How to manage the available 
work space  5. What command arguments are  6. When major changes in the system's organizations occurred. 
  These problems are virtually eliminated by the use of the macro operating system. One simple example 
of how the macro oper­ ating system simplifies system operationis indicated by the command sequences 
presented in Tables 1 and 2. The session specifiedby Table 1 might take the form specified in Table 
2 at the macro level. need to understand most of the computer system organization; everything short 
of program editing is handled automatically by the macro operating system, allowing the novice to take 
 charge of systems operation with a minimum of 6 training. An editor operatingmanual, a Fortran 7 on 
how to take care of the hardware and make it operational, is all the user needs to start working on 
a research problem. Extensive training is un­necessary. Each level of operation is linked to programming 
manual, and a document   all other levels via a menu control structure with visual prompting adding 
all the necessary support. The principalmenu control structure All areas of is diagrammed as shown in 
Table 3. basic operation are linked out of the control menu (CM). There is a recovery path available 
from any point of operation in the system. The menu control structure provides a bush-like framework 
in which the console operator can think ahead as he performs task after task. All elements of system 
operation are equally accessible from any point in the macro menu structure. No task is dictated to the 
operator unless it is needed to maintain system integrity. Hence, as the operator's knowledge of the 
system fades into increases, the menu control structure the background and the operator proceeds at 
a In this sense, the macro operating faster pace. system provides empathetical support for user control. 
As the user proceeds, a comprehension of systems design, control and operation develops naturally. 
The operator is protected from loss of informationand assisted at various critical points of recovery, 
including initial detection of hardware problems through the use of standardized diagnostic test programs. 
 For the user who no longer needs heavy prompting, the approach is further simplified by the addition 
of function switch controlwhere all the tasks mentioned (with the exception of editing and program entry) 
are performed through the use of switches. At this level, the operator merely responds to prompting 
on the scope by The function switch depressing a function switch. overlay specified in Table 4 is given 
to the user at the operations level and contains comments Note additional to those discussed earlier. 
that mnemonics are specified for each task to relate it to the user's earlier experience. PROGRAM EDIT, 
COMPILE, LOAD AND EXECUTE Command Description ON Sign on the system LISTA(1) Look at the user disk pack 
listing for a file to be worked on RESET("EDIT",002) Bring in the editor by name from the disk pack 0, 
Vol. 2 EDIT(0) Enter the editor with work area (scratch pad) on disk pack 0  ASSIGNIN(0,0) START("FORTRAN",2) 
 SETOBJECT(4) FORTRAN (A1,A2,A3,A4,A5,A6) Assign the editor work area contents for com­pilation Bring 
in the Fortran compiler from Vol. 2 (disk pack 0) Assign the compiler output volume to be volume 4 
of disk pack 0. Perform a Fortran com­pilation with compiler options specified as arguments Al thru 
A6.  START(F#,(4,7)) Start file by number and give disk volumes where references are located ENTRY Execute 
the program START ("FILST",6) Bring in the file print­ing program from disk pack 0, Vol. 6 FILST(F3,PVV,2) 
Print out a hard copy of the program source text OFF Sign off system TABLE 1 For detailed explanations 
of the command language see reference 1, pages 17-54. MACRO SYSTEM COMMANDS Command Description ON 
Sign on the system Ll List the content of disk pack #1 (the users storage pack) E Handle all aspects 
of editor entry (Editor Session) F Handle all aspects of compiling the program text in the editor (Check 
Results) S Handle all aspects of loading the object file, including reference resolving ENTRY Enter the 
program (Terminate Program) FIP Print the current text OFF Sign off the system TABLE 2  (DEMOS) f 
 (LP) ii Listing and Printing (DIAGS) DEMOnstrationS DIAGnosticS TABLE 4 Typical Programs The following 
photographs and accompanying text indicate some of the areas in whichuser prototype programs were developed. 
The pictures are single extractions from the scope face of dynamic interactive graphics research applications, 
as well as teaching support programsdeveloped and implemented on the Computation Center Adage Model 30 
during the past four years. The running commentary is supplied to indicate what each general program 
was structured to exem­plify and the area for which it was developed. To aid in further development of 
graphicscomprehension such programs are available for interrogation in the demonstration library of the 
system so that applications of graphics concepts encountered while using the system may be studiedat 
any time. Computer Graphics Comprehension This hardware/software simulation This software structuring 
programassists in developing two and three aids in comprehending the relation­dimensional comprehension.[5] 
ship between written source code and geometric programming concepts. 5 This program supports the study 
oftransformations from a basic stand­point at the two and three-dimen­sional levels.9 Crystallography 
An asymmetric image is acted on by crossed mirror planes. Four unit cells are generated showing the symmetry 
ofthe plane group pmm. This program allows the observer to select any one of sevenimages for any of the 
twelve orthogonal plane groups. Developed initially for use in an X-ray crystallography course.  25 
Acoustics and Vibrations This is a reconstruction from an acoustic hologram of a steel circular plate 
driven on edge below coincidence frequency. This study is being done by the Applied ResearchLaboratory 
 under contract with the Naval Sea Systems Command. Biomechanics Models are structurable and dynam­ically 
manipulatable to aid studies in human performance. Developed by a Ph.D student in the Biomechanics program 
of the College of Health, Physical Education and Recreation.  Coal Research In two terms, a simulation 
of a dry flow particle separator was developed by a graduate student and his advisor to demonstrate how 
effective the particular device might be. Computer Science A simulation of the IBM 370/168 assembler 
language was programmed by a graduate student in Computer Science. The program is written and edited 
at the terminal, assembly is shown step by step, execution is initiated, and the code handling of pointers 
to the registers and memory is shown dynamically.  Crystallography An instructional package to aid 
in the understandingof the use of the Ewald reciprocal space concept allows the learner to orient a cyrstal 
and then to see the development of a crystal diagram as the sphere of reflection enlarges. A talk and 
movie were presented to the American Crystallography meeting in Berkeley, California, April, 1974. The 
right frame, extracted from the movie, shows a Laue diagram. The program was developed in support of 
a Master's Thesis in Computer Science.  Crystallography A simulation of the Guinier camera shows 
how a curved monochrometer can be used to focus X-ray diffraction lines on forward and back reflection 
films. A talk and film were presented at the American Crystallography Meeting at Charlottesburg, Virginia, 
1974. Electron Diffraction The electron diffraction image of a grain boundary is calculated and displayed 
with dynamic rotations for visual interpretation. This program is part of a student's doctoral research 
in Metallurgy on grain boundary structure in face­centered cubic materials.  Art Forestry Untitled. 
This picture represents part of an art film developed to illustrate computervisuals in 3-dimensional 
space in a fog medium. The film was presented at a media conference in San Francisco in 1971. A sawyer 
in the saw mill can see the results of his cut only after it has been made. The simulated model of a 
log shows how defects might occur in the log and allows an observer to make intelligent judgments with 
respect to lumber production.l0   Physics A very sophisticated simulation of pool was developed to 
be played interactively. The interactions of all 16 balls are monitored at high speed so that the game 
is playable in real time. Story Animation A program was developed to animate the story of a romance 
of a line and a dot. From the story, "The Dot and the Line; A Romance In Lower Mathematics" by Norman 
Juster.  Materials Science This stereo pair depicts the Gibbs free energy surface in polarization 
space for ferroelectric BaTiO3. This program was developed for use in a materials science film series. 
These pictures are taken from a film presented by Dr. L. E. Cross at the Inter-disciplinarySymposium 
held at Stoney Brook on Reactions in Ceramic and Metallic Systems in August of 1972.  Material Science 
 A collection of fibers with known lengths can be synthesized using the data tablet. This known pattern 
can then be scanned by a fiber analyzer to determine the effectiveness of the analyzer. This program 
was used for part of a report presented to the U.S. Bureau of Mines, 1973. A phase diagram, on the bottom 
half of this picture, can be seen on the computer scope to evolve dynamically from the Gibbs free energy 
curves, shown in the top half of the 1   Summary To date it has been found, through practical experience 
with the approximately 30 research users and 70 students using this system, that the startup time* for 
a person trying to develop a research program can be reduced from approximately six months to less than 
 three weeks. In some cases, this is the only reason the system has been used by a researcher for certain 
jobs. At the research level, through use of the macro control system, learning how to operate the computer 
is no longer an obstacle to develop­ing research support programs of an interactive nature. The macro 
operating system establishes an environmentwhere the user is free to pursue the research project at hand 
without becoming enmeshed in the details of system operation. Embodied in the macro system is the continued 
possibility for further learning by the user, but such learning is neither forced nor necessary. The 
user is free to digest as much or as little of the detail of system operation as desired. However, since 
 only necessary operating information is encountered,total systems learning proceeds rapidly, and the 
user is not over-burdenedwith information irrelevent to his area of endeavor. In addition, users who 
have been trained in the use of the system have been able to return to it after absences of four months 
or more and immediatelyresume their systems interaction at both the hardware and software levels with 
no aid forthcoming or required. At the systems development level, major changes in the layout of the 
computer software environmentmay be made by the systems pro­ gramming staff without disturbing the active 
 user performance. The self-documentingsystem and machine readable manuals can be continually enhanced 
to strengthen the user's ability to retain necessary written support information. Because the system 
allows the on-line modif­ ication or addition of control programs as well as the bypassing of interaction, 
the system and the user can be matured con­ currently. In course work, this approach has allowed the 
graphics system to be used as a base for developing knowledge of computer graphics without the course 
becoming one of merely learning how to operate the computer in one ten week term. Furthermore, the 
student acquires skills in computer operation and control in a comfortable manner. Several students 
with no previous graphics experience had interactive projects running, and, in two cases, highly enthusiastic 
studentswere able to have the resultant dynamic models transferred to motion picture film, all within 
a three-week period. This involved approximately four hours per week devoted by each user to his project. 
 It should be noted that the course developed concurrently as part of this research has evolved to the 
point where it could prove to be of value in the undergraduatecurriculumat the university level both 
to computer science majors and non­majors. It has also become apparent that the approach can be just 
as readily implemented in any higher level language environment such as a COBOL programming environment 
given that the necessary support resources are, or can be made, available. *Startup time here denotes 
the time required to become familiarwith a computer support system so that the available hardware/softwareis 
understood, and so that the person can operate the system comfortably and alone, concentratingon the 
 research problem at hand. Acknowledgments The authors wish to thank the following people for their 
support: 1. Mr. John Leavitt for assisting in the graphics course.  2. Mr. Will Tracz for assisting 
with the student qualifications sessions.  3. Dr. Daniel L. Bernitt, Research Associate, Computation 
Center, for supporting the system development.  4. Dr. Donald T. Laird, Director, Computation Center, 
for supporting the system development.  5. Rosemary Hallenbeck, Secretary, Computation  Center, for 
editing and producing this manuscript.  6. ADAGE, Inc., Boston, Massachusetts for their systems support. 
  In addition, the authors thank the following people for their programming contributions. Wissam 
W. Ahmed Ramakrishna T. Bhatt Connie Mae Clark Robert L. Cohen Richard Ford John J. Gibbons John 
Hadden Karl M. Herpel Mark S. Lang Peter A. Lucas Ali Madani-pour Kenneth E. McIlvried Thomas Minsker 
 Joseph M. O'Niel Stelios M. Pnevmaticos Scott M. Troutman Susan M. Vicroy James S. Walton References 
 1. AMRMX, Disk System Resident Monitor, Programmer's ReferenceManual, Revision B, May, 1972, page 45-48. 
 2. (IBM 360) JCL Techniques, The Pennsylvania State University, December, 1971, page 30.  3. IBM System/360 
Operating System, Job Control Language Reference, File Number S360-36, Order Number GC28-6704-03.  4. 
Classes taught at the Pennsylvania State University during Spring and Fall terms, 1973 and Spring term, 
1974.  5. Graphic Geometric Perception and Commun­ication, F. R. Stocker and T. Minsker, Journal of 
Computers and Graphics, Volume 1, Number 1, 1975.  6. Adage Programmer's Reference Manual, Vol. 1, Edit 
7, 1972.  7. Adage Programmer's Reference Manual, Vol. 1, Fortran IV, February 1972.  8. Adage start-up 
procedure, P.S.U. Computation Center, July 2, 1973.  9. Stocker and Minsker-Graphics Transformation 
Comprehension and Evaluation, to be published.  10. Log and Sawing SimulationThrough Computer Graphics, 
S. M. Pnevmaticos, P. E. Dress,  F. R. Stocker, Forest Products Journal, Volume 24, No. 3 pages 53-55, 
1974.  11. Developed as part of a materials science film series under N.S.F. contract GY-7698.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563736</article_id>
		<sort_key>32</sort_key>
		<display_label></display_label>
		<article_publication_date>04-01-1975</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Computer animation of the sphere eversion]]></title>
		<page_from>32</page_from>
		<page_to>39</page_to>
		<doi_number>10.1145/563732.563736</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563736</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15033556</person_id>
				<author_profile_id><![CDATA[81100480335]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nelson]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Max]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Case Western Reserve University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379806</person_id>
				<author_profile_id><![CDATA[81542427556]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Clifford]]></last_name>
				<suffix><![CDATA[Jr.]]></suffix>
				<affiliation><![CDATA[Case Western Reserve University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Armit, A. P., "Multipatch and Multiobject Design Systems," Proceedings Royal Society, London, A 321 (1971), p. 325.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Birchoff, G., "Tricubic Polynomial Interpolation," Proc. Nat. Acad. Sci. USA, Vol. 68, No. 6, p. 1162]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>889976</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Coons, S. A., Surfaces for Computer Aided Design of Space Forms, M.I.T. Project MAC TR-41 (1967).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Domebook 2, Shelter Publications, Salinas, California (1971).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Gouraud, H., Computer Display of Curved Surfaces, University of Utah, TUECH-CSC-70-101 (1970).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Max, N. L., "Computer Animation of Smooth Surfaces II," Proc. 1973 UAIDE Meeting, available on microfiche from Nat'l. Microfilm Assoc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Phillips, A., "Turning a Sphere Inside Out," Scientific American, Vol. 214, No. 5, (1966), p. 112.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Watkins, G. S., A Real Time Visible Surface Algorithm, Com. Sci. Dept., U. Utah, UTECH-CSC-70-101 (1970).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Permission to make digital or hard copies of part or all of this work or personal or classroom use 
is granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.Siggraph 
75 Bowling Green COMPUTER ANIMATION OF THE SPHERE EVERSION Nelson L. Max and William H. Clifford, Jr. 
Case Western Reserve University The Sphere Eversion In 1958, Stephen Smale, a mathematicianwho was 
then at the University of Chicago, proved that it was possible to turn the surface of a sphere inside 
out by a special kind of deformation, called a 'regular homotopy'. During a regular homotopy, the surface 
must remain continuous, without any tears or holes; and smooth, without any creases or singularities. 
However, the surface is allowed to cross and pass through itself. In other words, if we consider a 
position of the sphere as a function from the standard round spherical surface S into three dimensional 
space 3 R , this function must be continuous and smooth (C ),but not necessarily one-to-one. Such 
a function is called an immersion, and some sample immersions of the sphere are shown in the figures 
 here. A regular homotopy is then a continuous family of immersions, satisfying a technical con­dition 
that its partial derivativeswith respect tpiooSar 2 2 tions of time, as well as of position on S . 
This is the smoothness conditionwhich prohibits creases and kinks. Smale actually proved that there 
was a regular The ordinary round sphere and an inside-out round sphere are special cases of immersions, 
so there must be a regular homotopy between them. Smale's proof was by induction and in principal contained 
a construction of an actual regular homotopy but one so complicated that it would be impractical to 
vi­ sualize. Once the solutionwas known to be pos­ sible, a number of people tried to invent simple 
and easily visualizedhomotopies. One of these is discussed in ScientificAmerican article [7], which 
 contains a more extensive description of the prob­ lem, and a complete sequence of illustrations for 
 the homotopy. However, in order to understand the deformation, the reader must imagine the motions 
between the illustrations in the sequence, and con­ vince himself that they are continuous and smooth. 
 Clearly it would be preferable to have a movie show­ ing the whole deformation. Since each frame is 
a different complicated surface, this is an obvious candidate for computer animation. The film projected 
at the meeting and illus­ trated in the figures here shows a regular homotopy developed by Bernard Morin, 
a blind French mathema­tician who was also instrumental in the creation of several other such homotopies. 
The one used here  is among the simplest known, since it contains only fourteen critical stages, the 
minimum among the homotopies known at present. There were two main problems in the creation of the 
film; first the mathematicaldefinition of the homotopy to the computer, and second, the ef­ficient computation 
of the frames for output through suitable hardware onto film. These will be discussed in the sections 
to follow. Definition of the Surface The surface of the sphere was divided into eighteen rectangular 
and eight triangular patches, shown in Figure 1. For each patch, the three co­ ordinates x, y, and z 
were represented as cubic polynomials in the two patch parameters u and v. Thus the rectangular patches 
were Coons' 'bicubic patches' [3], and the triangular ones were Birchoff's 'tricubic' patches [2]. 
The coeffici­ ents for these polynomials were calculated from the coordinates of the vertices, the tangent 
vec­ tors at the vertices, and the mixed partial deriv­ ative vector, called the 'twist vector'.  In 
order for two independent tangent vectors at a vertex to relate meaningfully to the partial derivatives 
for the patches having this vertex as a corner, each vertex must be a corner of four patches. Since 
it is impossible to cover a sphere using only rectangular patches which meet in this way, the triangular 
patches were needed. Since the rectangular patches are entirely determined by the tangent informationat 
their ver­ tices, they join automatically along their common edges to form a smooth continuous surface. 
After the program was written, Ed Catmull and Robert Barnhill at the University of Utah pointed out 
 that the formulas for the triangular patches cause slight creases at their edges. However the smooth 
 shading algorithm to be described later suppressed these creases anyway, so they were never corrected. 
 The coordinate, tangent, and twist information to describe the surface involvesmore than 200 num­ bers, 
which must be specified for each positionof the surface. However, each surface of the regular homotopy 
has two-fold rotational symmetry, visible in the symmetry of the patch structure in Figure 1. By taking 
advantage of this symmetry, the amount of information to describe each position is cut in half. In 
addition, the regular homotopy is symmet­rical in time. At the halfway stage, shown in Figures 2 and 
3, the inside surface and outside surface appear in identical positions, rotated by 90 degrees. The second 
half of the homotopy is a reversal of the first half with the inside and outside surfaces changing roles. 
Thus only half the homotopy need be specified.  Figure 2. Wire frame network on halfway stage. Figure 
3. Smooth surface rendering of halfway stage. The vertex and tangent descriptions were en­tered interactively 
into a PDP-10 computer, using a program inspired by Andrew Armit's 'MultiObject' system [l] at Cambridge 
University. The original hope was to create the surfaces completely with this interactive program, comparing 
graphical out­put of the patches to a mental image of how the surfaces should look, and revising the 
data accord­ingly. However it was found that the surfaces were just too complicated for this to work 
well. One particularly annoying problem was the fact that a differentiable surface can nevertheless have 
a where the two partial de­ singuiarity, at a point rivative vectors become linearly dependent. It is, 
difficult to recognize how to modify the vertex and tangent information to eliminate these singu­ larities. 
Luckily, a sequence of chicken-wire models for the homotopy had been constructed by Charles Pugh, at 
the University of California -Berkeley (see Figure 4). Patches were laid out on these models, and the 
necessary data measured by hand, and en­ tered into the computer. The interactive program was then run 
at the Stanford Artificial Intelli­gence Laboratory, so that the data could be im­ proved while the models 
were still accessible. This proved to be a much more satisfactory process, and we wish to thank Les Ernest 
for making the fa­cilities at Stanford available. Figure 4. Since the deformation proceeds similarly 
for­wards and backwards from the halfway position shown in Figures 2 and 3, the patches were chosen to 
fit best on this central surface, in the hope that they could be deformed both forward and back­ward 
to the beginning and final round spheres. 34 However, this involved much twisting and distortion .:>t. 
of the patches, and the surfaces resulting at the extremes of the homotopy had an unpleasant appear­ance. 
Therefore a completely different global rep­ resentation, in terms of spherical coordinates, i.e. latitude 
and longitude, was employed for the beginning and final stages of the homotopy. Start­ing with the round 
sphere, trigonometric polynomi­als in the spherical coordinates were applied to push and twist the surface 
until it reached posi­tion S', Figure 5, approximating the modelM, of Figure 4 part way through the homotopy, 
where the patch representation takes over. In order to get a transition between the two representations, 
the patch surface P, for M, was also computed, and each patch subdivided into a number of small poly­ 
gons, as shown in Figure 6. For each vertex of this subdivision, the spherical coordinates of the closest 
point on S, were computed, using a metric which required nearness of the tangent planes as well as ordinary 
distance. In effect, this plastered the patch representation P, onto the spherical coordinate surface 
S,, and once the crumpled parts of the surface were straightened out by hand, a smooth transition resulted. 
Each square patch was subdivided into a 6 , by 6 array of smaller squares, shown on Figures 3 and 6 and 
the triangular and rectangular patch­es were divided similarly. For the global rep­resentation in terms 
of spherical coordinates, the sphere was subdivided onto a collection of tri­angles based on Buckminster 
Fuller's geodesic dome (see [4]). The coordinates of the vertices of these subdivisions and of their 
"outward" surface normals were computed for a number of key frames and used as input for the shading 
process. The I.' '2. :; , .- .,t!:..~~c y;::. definition of these key frames was done at the Carnegie-Mellon 
University Computer Science Depart­ment and we wish to thank Raj Reddy for making the facilities there 
available to us. Figure 5. Figure 6. The Evans and Sutherland LSD2 animation ma­chine at Case Western 
Reserve University was used to output the regular homotopy as a continuous family of smoothly shaded 
opaque surfaces. This machine takes as its input a sequence of polygon edges on the surface, and sends 
them through a interpolates the data between the key frames, and pipeline where they are translated and 
rotated in a matrix multiplier, clipped on the screen edges, put into perspective, and stored in a sorted 
list. Then, a 'Watkins box' [8] computes those segments of these polygons which are visible on each scan 
line, and a shader outputs the appropriate inten­ sity signal at video rates. The shader computes the 
intensity by linearly interpolating the z component of the unit normal vectors at the vertices of the 
polygons. This piecewise linear intensity function approximates a cosine law of reflection as suggested 
by Gouraud [5]. If the subdivision into polygons is suffici­ently fine, an apparently smoothly shaded 
surface results. However if two polygons meet at an edge with too sharp an angle, the eye,using contrast 
en­hancement edge detection circuits in the retina, detects the discontinuity of the derivative of the 
piecewise linear shading and the edge shows as a bright 'Mach band', some of which are visible in Figure 
7. There is also an anti-rastering device on the pipeline, to eliminate the staircase effect produced 
on sharp edges by the finite resolution of the raster scan. The inside and outside surfaces of the sphere 
are colored in two contrasting colors, depending on whether the normal to the 'outside' surface points 
toward or away from the viewer. To produce a segment of the movie, two key frame descriptions are stored 
in the PDP-11 computer which works with the LDS-2. These descriptions contain the posi­tions and normals 
for corresponding vertices on the two surfaces, and a list of polygons which con­nect them. For each 
intermediate frame, the PDP-11 sends it through the LDS-2. Figure 7. The only problem is with polygons 
which-cross the profile curve, and thus have some vertex nor­mals pointing cowards the viewer, and some 
pointing away, making the decision as to color impossible. For each vertex the dot product of the vertex 
nor­mal times the vector pointing from the vertex to the point of view is taken. These dot products are 
positive if the vertex is visible in the outside surface, and negative otherwise. An edge like AB connecting 
two points whose dot products have op­posite signs is assumed to cross the profile curve at a point E. 
To find it, a weight is computed which would make the weighted average of the dot products for A and 
B come out zero. A cubic ap­proximation to the curved side AEB of the patch is then formed using the 
normals of A and B to specify the curvature, and evaluated at the weight to find E. The point F is found 
similarly. The profile curve EGF is then also approximated by a cubic, and intermediate points G, H, 
. . . calculated, so that the polygon EFGH approximates the smooth profile curve, and the polygon ABCD 
is replaced by ': :_ f, the two polygons AEGHFD and BEGHFC which can then be .- ._ colored appropriately. 
The resulting smoothed pro­ file is particularly beneficial when the surface is rotating or deforming, 
since otherwise vertices moving past the profile would cause temporary bumps to appear and disappear. 
 Figure 8. The LDS-2 is capable of continuously refresh­ ing a fixed position of the surface for viewing 
with a 512 line raster, and is even capable of ro­tating it in real time if the dot product and pro­file 
smoothing computations are omitted. For high quality filming in color, three color filters are moved 
into place in turn under computer control, and a slower 1024 line high resolution scan is used. The computer 
also controls the advance of the film in the animation camera. We wish to thank Ted Glaser at Case Western 
Reserve Univer­sity for making the LDS-2 available during the preparation of this paper. Once the key 
frame.8 have been defined, the surfaces may be rotated, magnified, and filmed from any point of view, 
as in Figure 9. They can also be sliced by a clipping plane, to show the interior structure which would 
otherwise be obscured. As shown in Figure 10, this can be done on the LDS-2 . hardware, which can clip 
with respect to a front and back plane, as well as on the screen boundaries. It can also be done in software, 
giving the smooth­er clipping edge shown in Figure 11, using methods analogous to those which produce 
a smooth profile edne. Figure 9. Figure 10. Another way to show the interior structure is to shrink 
the polygons on the surface, so that gaps appear between them, as shown in Figure 12, reveal­ing the 
surfaces behind. A final way is to use a wire frame representation, as described below, which can be 
drawn on a vector scope. Figure 11. Figure 12. Wire Frame Representation The wire frame sequences in 
the film were made on a Graphics Display Processor (GDP), a high­speed digital vector scope, developed 
at Carnegie-Mellon University. Like the LDS-2, the GDP works in conjunction with a PDP-11, which can 
perform the interpolation between key frames, and in this case also does the matrix multiplication for 
the rotation. The screen has sixteen logarithmically spaced intensity levels, which are used to make 
the distant parts of the surface dimmer. 38 For the animation, the two key frames are de­scribed in display 
lists, containing visible and invisible vectors in three dimensions. These are interpolated to form intermediate 
frames, and the vectors are rotated and transformed into a display list suitable for the GDP. Only half 
the vectors need be kept in core, since the others can be ob­tained by rotation about the axis -of two-fold 
sym­metry of the surface. Iwo sorts of wire frame approximations were used: a cross hatching, suitable 
for the patch representation shown in Figures 2, 6, and 13 and a 'chicken wire' array of hexagons, derived 
from the 'geodesic' subdivision on the global representa­tion,shown in Figures 5, 14 and 15. No attempt 
was made to provide a consistent representation throughout the deformation, since any pleasant looking 
wire frame approximation to the round sphere would inevitably become unpleasantly dis­ torted when the 
sphere was turned completely inside out. Instead, 'live' film of the real chicken wire model M1 in Figure 
4 was used to cover the transition. Figure 13. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563737</article_id>
		<sort_key>40</sort_key>
		<display_label></display_label>
		<article_publication_date>04-01-1975</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Wave]]></title>
		<subtitle><![CDATA[interactive color graphics for waveform analysis]]></subtitle>
		<page_from>40</page_from>
		<page_to>41</page_to>
		<doi_number>10.1145/563732.563737</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563737</url>
		<abstract>
			<par><![CDATA[WAVE, an interactive color graphics software system for Waveform Analysis Visualization and Edification, is an evolving software interface between an Anagraph Color Graphics System, a CDC 6400/7600 computer configuration, and User Application programs coded in standard FORTRAN source language.WAVE, when mated with the user application modules provides a complete specialized interactive graphical analysis system. The system features:&#8226; Full interaction of user with program operation via keyboard/trackball inputs;&#8226; A large repertoire of viewing and display options for interactive selection;&#8226; Interactive storage and retrieval of displays and off-line or job-to-job capabilities available through magnetic tape;&#8226; A variety of methods for the retrieval of analytical information;&#8226; Automatic adjustment of scaling, centering, and other detailed viewing parameters to maximize user convenience;&#8226; Application program options displayed in user terminology to minimize learning time;&#8226; Modular construction to facilitate addition of new application modules.The WAVE program is readily modified to meet specialized user requirements. Several applications of the WAVE system are currently operational at the Ballistic Missile Defense Advanced Technology Center's (BMDATC) Advanced Research Center (ARC) in Huntsville, Alabama. The WAVE technique has been applied comprehensively to the problem of radar ambiguity analysis and clutter rejection. Other applications of WAVE are currently in progress or have been less comprehensively developed.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379796</person_id>
				<author_profile_id><![CDATA[81100065988]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fred]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Robbins]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[System Development Corporation (SDC), Huntsville, Alabama]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379807</person_id>
				<author_profile_id><![CDATA[81100200981]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Green]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[System Development Corporation (SDC), Huntsville, Alabama]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.Siggraph 
75 Bowling Green WAVE: INTERACTIVE COLOR GRAPHICS FOR WAVEFORM ANALYSIS Fred E. Robbins and William 
G. Green System DevelopmentCorporation (SDC), Huntsville, Alabama INTRODUCTION WAVE, an interactive 
color graphics software system for WaveformAnalysis Visualization and Edi­fication, is an evolving software 
interface between an Anagraph Color Graphics System, a CDC 6400/7600 computer configuration, and User 
Application pro­grams coded in standard FORTRAN source language. WAVE, when mated with the user application 
modules provides a complete specialized interactive graphical analysis system. The system features: 
 o Full interaction of user with program opera­tion via keyboard/trackball inputs;  o A large repertoire 
of viewing and display options for interactive selection;  o Interactive storage and retrieval of dis­ 
 plays and off-line or job-to-job capabil­ities available through magnetic tape; o A variety of methods 
for the retrieval of analytical information;  o Automatic adjustment of scaling, centering,  and other 
detailed viewing parameters to maximize user convenience; o Application program options displayed in 
user terminology to minimize learning time;  o Modular construction to facilitate addition of new application 
modules.  The WAVE program is readily modified to meet specialized user requirements. Several applica­tions 
of the WAVE system are currently operational at the Ballistic Missile Defense Advanced Tech­ nology 
Center's (BMDATC) Advanced Research Center (ARC) inHuntsville, Alabama. The WAVE technique has been applied 
comprehensivelyto the problem of radar ambiguity analysis and clutter rejection. Other applications 
of WAVE are currently in pro­gress or have been less comprehensively developed. DESCRIPTION The WAVE 
technique isimplemented (via SDC developed software) on an Anagraph Color Graphics System integrated 
with a CDC 6400/7600 computer configuration as shown in Figure 1. A display console includes a keyboard, 
trackball, and a television monitor capable of displaying alpha­numeric text and graphics data incolor. 
One of four display consoles may be diverted to a GE projector to produce 4 x 6 foot displays inthe 
main ARC conference room, allowing a large audi­ence to view "live" computer generated graphics. User 
interaction is through the artifice of displayed menus of program options. Separate menus are utilized 
for the display of user appli­cation program input and visualization options. The radar ambiguity application 
of WAVE featured some 25 applications and 40 visualization options. WAVE plots four principal types 
of images: a two dimensional line graph; a three dimensional representationof a wave surface; a two dimensional 
 slice of the surface; and a color coded contour map of the surface. Figures 2-5 are typical displays 
produced by the Radar Ambiguity application. These displays illustrate some of the visualization features 
of the WAVE system. Figure 2 represents a compara­tive analysis of several radar ambiguity surfaces 
through the presentation of color coded, overlayed two dimensional slices of each surface. The image 
isobtained by portraying the magnitude of the wave along the vertical axis and one argument of the function 
along the horizontal. Figure 3 presents a three dimensional image of the ambiguity surface. Successive/slices 
of the surface for increments of the third dimension are stepped down the page. The three dimensional 
illusion is enhanced by the visual perception cue of removing "hidden lines and surfaces" and displaying 
the image intwo colors: an outline or boundary color and a body or mass color. Figure 4 is a color coded 
contour map of the ambiguity surface. Figure 5 shows a side-by-side comparison of two ambiguity surfaces. 
The view rotation capabilities of the program are also indicated in Figure 6 via a block and inclined 
plane representation. Retrieval of analytical information is facili­tated via the use of color coded 
contour maps, superimposed grids of user selected sizes, color coded displays of user selected options, 
readout of coordinates of user selected point, and re­call of previous analyses. Permanent analysis records 
are available via tape or hard copy. 40 * ADAPTATIONS/APPLICATIONS It is believed that the WAVE technique 
has widespread application to interactive analysis and complex function visualization. Applications which 
have been identified include: . Radar Ambiguity Analysis and Clutter Rejection; * Radar Antenna Pattern 
Analysis; * Spacecraft' Orbit Selection; * Optical Sensor Extended Target Analysis; * Analysis of 
Dynamic Data from Dispersed  Sensors (Geophones); . Bivariant Function Analysis. Demonstrations of 
the WAVE system and discus­sions of possible new applications/adaptations of the WAVE techniques may 
be arranged by appointment.  Figure 4. Ambiguity Contour Map All visitations to the ARC facility must 
be coordinated and approved by Mr. C. R. Vick, Chief of the BMDATC Data Processing Directorate.   
 Figure 1. System Configuration Figure 5. Side-by-Side Ambiguity Slice Figure 2. .  Figure 3. Ambiguity 
Surface Figure 6. Rotated Views 41 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563738</article_id>
		<sort_key>42</sort_key>
		<display_label></display_label>
		<article_publication_date>04-01-1975</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[A graphics operating system]]></title>
		<page_from>42</page_from>
		<page_to>48</page_to>
		<doi_number>10.1145/563732.563738</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563738</url>
		<abstract>
			<par><![CDATA[Stand alone graphic systems and time-shared graphics provide different benefits to a user. The same is true of refresh graphics and storage displays. An operating system is described which supports these combined modes through the integration of graphics into the operating system. Realization of the role of the system, generality, and flexibility were the major factors in the development of the system. The result is a computer graphic system providing high-level interactive graphics at a relatively low cost.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379802</person_id>
				<author_profile_id><![CDATA[81100577026]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lawrence]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Koenigsberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tektronix, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14052955</person_id>
				<author_profile_id><![CDATA[81100120155]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jon]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Meads]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tektronix, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379801</person_id>
				<author_profile_id><![CDATA[82459068657]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shaw]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tektronix, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31045061</person_id>
				<author_profile_id><![CDATA[81100501148]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Ned]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Thanhouser]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tektronix, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379804</person_id>
				<author_profile_id><![CDATA[81100331653]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vollum]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tektronix, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Newman, William M., Sproull, Robert F., "Principles of Interactive Computer Graphics," McGraw-Hill Book Company, New York, N.Y., 1973]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Newman, William M., Sproull, Robert F., "An Approach to Graphic System Design", Proceedings of the IEEE, Vol. 62, No. 4, April, 1974]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Sproull, Robert F., Thomas, Elaine L.,"A Network Graphics Protocol," Network Graphics Group, ARPA Network Information Center, Stanford Research Institute, Menlo Park, Calif., 1973]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Meads, Jon A., "A Terminal Control System", Graphic Languages, North-Holland Publishing Company, Amsterdam, 1972]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Meads, Jon A., "Basic Graphics Software", Special Conference on Computer Graphics as related to Engineering Design (Proceedings), National Science Foundation, Washington, D.C., 1973]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>810849</ref_obj_id>
				<ref_obj_pid>800269</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Koenigsberg, Lawrence, Thanhouser, Ned, "A Graphics System for APL Users --- APL/Graph II", Proceedings of the Sixth International APL Users' Conference, Coast Community College District, Anaheim, Calif., 1973]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Foley, James D., Wallace, Victor L., "The Art of Natural Graphic Man-Machine Conversation", Proccedings of the IEEE, Vol. 62, No. 4, April, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>805684</ref_obj_id>
				<ref_obj_pid>800192</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Foley, James D., "Software for Satellite Graphic Systems", Proceedings of the ACM, 1973]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Christensen, C., Pinson, E. N., "Multi-Function Graphics for a Large Computer System", FJCC 1967, Thompson Books, Washington, D.C.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Cotton, I. W., Greatorex, F. S., Jr., "Data Structures and Techniques for Remote Computer Graphics", FJCC 1968, Thompson Books, Washington, D.C.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Ninke, W. H., "Graphic 1-A Remote Graphical Display Console System", FJCC 1965, Spartan Books, Washington, D.C.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Rapkin, M. D., Abu-Gheida, O. M., "Stand Alone/Remote Graphic System", FJCC 1968, Thompson Books, Washington, D.C.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Van Dam, Andries, Stabler, George M., "Intelligent Satellites for Interactive Graphics", Proceedings of the NCC, Vol. 43, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>810878</ref_obj_id>
				<ref_obj_pid>800270</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Ross, D. T, Stotz, R. H., Thornhill, D. E, "The Design and Programming of a Display Interface System Integrating Multi-Access and Satellite Computers", Proceedings of the 4th Share/ACM Design Automation Workshop, 1967.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.Siggraph 
75 Bowling Green A GRAPHICS OPERATING SYSTEM by Lawrence Koenigsberg, Jon A. Meads, John Shaw, Ned Thanhouser, 
Steven Vollum Tektronix, Inc. Abstract Stand alone graphic systems and time-shared graphics provide 
different benefits to a user. The same is true of refresh graphics and storage displays. An operating 
system is described which supports these combinedmodes through the integration of graphics into the 
operating system. Realization of the role of the system, generality, and flexibility were the major 
factors in the development of the system. The result is a computer graphic system providing high-level 
interactive graphics at a relatively low cost. Introduotion Many individuals have recognized the benefits 
of using a small satellite computer to provide high­ level interactive graphical communication.while 
 accessing remote large-scale computers. 8,9,10,11,1213  Most of these describe the satellite software 
in display list interfacing.910,,1Others concern terms of graphic support and primarily data base/ 
 112 themselves with division of labor from the stand­ point of optimizing computational resources in 
 the performance of the users' task.8,13 This paper differs from the above in that it assumes certain 
 functions (the graphic transformations) are permanently relegated to the satellite computer. These 
functions are integrated into the satellite computer's operating system and coordinated with device-independentgraphical 
output. Overview Computer graphic systems may be divided into stand-alone systems and time-share based 
systems. A system usually consists of a small or medium size computer and various I/0 devices. The graphic 
unit and associated input devices are included with these I/0 devices. Usually the system is designed 
for and dedicated to a particular application. A time-share based system uses larger, more powerful 
computers and services remote users. Each of these has its advantages and disadvantages (Table 1). 
Another divisionwhich may be made is between refresh graphics and storage tube graphics. A picture on 
a random scan refresh CRT must be continuously redrawn. Thus it is possible to change picture parameters 
between frames and display animated figures. Refresh graphics may be supported by direct output from 
the central processor (Whirlwind displays; DEC 30D) or may be driven by a display processor directly 
accessing memory (IMLAC PDS-1,PDS-4; DEC GT-40). A storage tube (Tektronix4010; 4012, 4014) retains the 
 displayed image within the CRT itself, and does not require continuous picture regeneration. For this 
reason, time-shared graphics have used storage tubes almost exclusively. There are other advan­ tages 
and disadvantages with both refresh and storage tube graphics (Table 2).  Analytical Capability High 
level User Interaction Ability to Display Complex/HighVolume Pictures Fast Response Dynamic Display 
and Animation High Level Language Programming Software Transferability Cost A system which can provide 
a significant level of improvement in all of these areas would be a stand­alone graphics station capable 
of interfacing to a time-sharedhost computer and supporting both refresh and storage tube graphics. 
The Graphics Operating System was developed for such a station. Although a single monitor which provides 
both storage and refresh simultaneously is used, the operating system is general enough to support several 
monitors of either type. Concepts Top-down programmingis considereda virtue. So is top-down system 
building. A Graphics Operating System is but part of a larger system. The con­ struction of a Graphics 
Operating System should be one which carries out given concepts. The overall system cannot be thought 
of as a graphics system. It is a total system to be used in the solution of problems. It includes the 
user as well as the hardware and software. One of the concepts is the "general purpose" concept. This 
 means it is necessary to abstract the purpose or role of each piece of the total system. These abstractions 
are illustrated in Figure 1. The local graphics system is essentially a communica­tion device. It allows 
the human user to apply his intuitive understanding to the discrete computer analysis in obtaining 
a solution to the problem.  From the other direction the local graphics system must receive output 
from the analysis program and present it to the user in a form fit for human consumption. In addition, 
the local system should perform other appropriate tasks such as picture manipulationand editing, storage 
and retrieval of commonly used data, and perhaps minor computations suitable for local processing. A 
GraphicsOper­ating System has the responsibility of managing the resources of the local system, simplifying 
its use, and performing common tasks. Other concepts included in the design of the Graphics Operating 
System are the common concepts of gen­erality and device independence. The major dif­ference with most 
operating systems is the inclusion of graphics processing as an integral part of the operating system. 
Since this is a graphic system providing user-problemcommunication,it should be expected that among 
the common tasks to be performed are graphic output and user input. Another common task is that of remote 
communication. The inclusion of these services in the operating system add an extra dimension to the 
concepts of generality and device independence. System Description The hardware configuration for the 
local graphics system consists of a mini-computerwith 32K bytes of memory, a 19 inch storage CRT with 
a display processor capable of displaying refreshed objects as well as handling storage output, an alphanumeric 
 keyboard, 12 function keys, a joystick, graphic tablet, flexibledisk, a cassette magnetic tape unit, 
and a programmable modem. (Figure 2).  Graphic Output Conceptuallythe handling of vector output was 
the simplest task. Graphic output techniques are well known and fairly straightforward. Actual imple­ 
mentation was a bit more complex. An early decision was made to allow the user or application program 
to work with the problem coordinates by providing him with a virtual space in which he could construct 
his picture naturally. Rotation, scaling, clipping, viewport transformation, etc. were to be left to 
the operating system. Another early decision was that it should be possible to output graphic data 
on any appropriate peripheral including local storage devices such as the flexible disk or cassette 
tape. Also, it was decided that display monitors should be treated in a fashion similar to disks for 
logical output. Just as a disk may have several files presented to the user as separate logical units, 
so may one display monitor have several viewports on it, each appearing to the user as a separate logical 
unit (display). Two mechanisms were used to provide these cap­ abilities. One was the Graphic Control 
Block. The other was the use of psuedo-display code files. The psuedo-code provides a common '12 
organized into segmented transformed display denominator among the various possible graphic devices. 
Using a segmented transformed display allows for the mixing of refreshed objects and stored vectors as 
output to the same graphics logic unit. The Graphic Control Blocks are the basic units of reference 
information for the Graphic Operating System, and contain the environmental parameters required to 
map a vector in virtual space onto some device's space. This mapping encompasses the following transforms: 
 1) If the vector is relative, it is scaled, rotated, and converted to an appropriate absolute vector. 
 2) The vector is clipped against a window. 3) If the vector is not entirely clipped and is to be displayed, 
it is transformed for display on the viewport. Graphic Control Blocks are 44-word blocks, organized 
according to a specified format (Figure 3). Space allocationand initial set up is the responsibility 
ofthe application program. Maintenance is split between the applica­tion program,which sets window, viewport, 
scale, and rotation parameters, and the operating system which preserves virtual display and device 
status. The Graphic Control Block is activated by attaching it to a logical unit thru a request to the 
Graphics Operating System. Up to sixteen Graphic Control Blocks may be assigned to logical units at a 
given time. However, the program may construct as many as it desires, activating and deactivating Graphic 
Control Blocks as needed. A seventeenth Graphic Control Block is always active. It is part of the Graphics 
Operating System and is reserved for support of the Monitor Viewport. Function Bytes Scale for Relative 
Vectors 4 Rotation Factor for Relative Vectors 6 Virtual Display Status 16 Window Coordinates 8 Device 
Status 2 Viewport Coordinates 8 Total 44 Figure 3 A Graphic Control Block All future graphic output 
to a given logical unit will be processed by the Graphics Operating System according to the assigned 
Graphic Control Block. The result is a psuedo-display code which is then added to the appropriate buffer 
for output by the device handler during an interrupt cycle. (Figure 4).  Figure 4 A Simplified View 
of the Graphics Operating System Since pictures can be processed and stored on the flexible disk or 
cassette magnetic tape, it is possible to save pictures for re-display, or to store a picture for output 
to a plotter when the system is not busy. Future addition of back­ ground processing to the Graphics 
Operating System will allow spooling of pictures to a plotter con­ current with general usage. Refresh 
Graphics The device handler (or driver) for the display controllerallows refresh graphics to be intermixed 
with storage graphics. There are three major modules within the Display Controller Driver. One is the 
Psuedo-Display Code Interpreter which converts the psuedo-display code into display controller code. 
 The second major module is the Display List Handler which manages the insertion, deletion, or modifica­ 
tion of the Refresh Display List. The third is the Display Controller Interrupt Service Routine which 
manages the actual output to the display unit. (Figure 5).  Figure 5 Refresh/Storage Intermixing A 
refreshed object may be generated by enclosing the refreshed object vector command in an OPEN (or APPEND) 
command and a POST command.3 The OPEN (or APPEND) command signals the Psuedo-Display Code Interpreter 
that the commands following are for refreshed vectors. The converted display code, along with special 
display list handling commands, are provided to the Display List Handler for addi­tion or modificationto 
the Refresh Display List. A POST command signals the end of refresh data and switches interpreter output 
to the storage dis­play queue. Modifications to the Refresh Display List are not realized until the POST 
command has been issued. This allows the actual update to occur between refresh frames with little or 
no display interruption. In execution, the mixture of refresh graphics with storage graphics is similarly 
handled. The Display Controller Interrupt Service Routine first cycles through the Refresh Display List. 
Once having completed a refresh cycle, it starts out­putting storage vectors until the refresh timer 
indicates another refresh cycle is to be initiated. Care is taken to see that at least one storage vector 
is output between refresh cycles. This in­sures that storage display requests will always be output even 
if very slowly. Graphic Input Device independence for graphic input can be achieved by dividing graphic 
input into classes identified by their features rather than by the device. Two classes of graphic input 
are supported the System; locators and A locator returns agiven point in X, Y coordinates while a tracer 
returns a stream of X, Y coordinate pairs. An enhancement of this concept which was incorporated into 
the Graphics Operating System is the ability to return points in either screen coordinates or in virtual 
coordinates relative to a given window-viewportpair. (Figure 6).  The object of a locator is to return 
or select a given point. Usually this is done by manipulating a system-supplied crosshair cursor until 
it is positioned at the desired point and then noting this with a function key push. The Graphic Operating 
System lets the calling program specify which function keys are to be used for termination and allows 
for specification of a cursor by the application program. If the normal crosshair cursor is desired 
a default option will enable it. Otherwise the user may define a refreshed object and indicate that it 
is to be used as a cursor by specifying its segment number when requesting graphic input. The Graphic 
Operating System will automatically manipulate the refreshed object by updating its set point in coordinationwith 
user input. This provides the user with the ability to display and position given objects. When the cursor 
is properly positioned, the user presses the appropriate function or alphanumerickey and the Graphics 
Operating System will return either the screen or virtual coordinates of the selected point. By allowing 
function or alphanumerickey to act as terminator, the user is able to specify an action to be taken as 
well as the point to be selected. The operation of tracers is very much like the locators. The additional 
facility of distance filtering is provided for tracers. When requesting tracer input, it is possible 
to set the distance filter as desired. The user is then able to obtain both the coordinates of the filtered 
points plus the number of points that arrived before the filter distance was exceeded. (Figure 7). This 
number may be used as an indication of the speed of input for such purposes as on-line character recognition. 
 The first point returned is the initial trace point. as the Monitor Window and Monitor Viewport are 
The last point is the last filtered point plus defined by the same coordinates. Vectors outside filtered 
count received before tracer termination. the Monitor Windowwill be clipped.  Points 1 through 8 arrive 
in numerical order. Points 2 and 3 are filtered out. Point 4 is the first point received outside the 
filter distance, f. Point 5 is filtered out, point 6 is accepted, and points 7 and 8 are not. Data 
returned to the calling program would be of the form (X,Y,N). If the filter count is not wanted, just 
(X,Y) pairs are returned. In this case, data returned would be:  All alphanumeric characters are software 
generated. Two modes exist, however One mode is the regular software character which exists in virtual 
space and may be rotated and scaled. The other mode is called "emulated hardware characters" allowing 
 for direct output of characters in one of ten standard sizes. Rotation of "hardware"characters is 
not possible. Regular software characters that exist outside a window are clipped. They also are additionally 
scaled with the window-viewport transformationof the entire picture. "Hardware" characters are associated 
with a viewport. When the "hardware" character string being output exceeds the righthand boundary of 
the viewport, an automatic respositioning equivalent to a carriage return/line feed occurs. "Hardware" 
characters are used in conjunction with alphanumeric input (whenautomatic echoing is desired) and for 
monitor level output (e.g., log on and system messages). Since it is not desirable to output system 
messages so that they overlay normal graphic output, the concept of a Monitor Viewport was introduced. 
The Monitor Viewport is a section of the screen that is reserved for system output. It plays the role 
of the ubiquitous teletype and will accept input/ output for an application program. Initially the Monitor 
Viewport covers the entire screen, but it may be reset at any time by either the user or an applicationprogram 
through a request to the Graphics Operating System. It is possible to output graphics through the Monitor 
Viewport with certain restrictions. Rota­ tion and scaling of relative vectors is not possible and all 
output is on a one-to-one scale Alphanumeric input is flexible but straightforward. An application 
program may request either record input or single character input. Record input is a line of input 
terminated by a carriage return or line feed. The Graphics Operating System will provide automatic 
input editing (character delete or line cancel) and echoing for record input. Either or both options 
may be disabled on request. No editing is allowed with single character input. As soon as the character 
is received it is fed directly to the calling program. Echoing may be enabled or disabled for single 
character input. Communications Possibly the most complex portion of the Graphics Operating System 
is the provision of device­ independent telecommunications. Device-independence here means being independent 
of all the communica­ tion parameters such as host system protocol, bit representationof characters, 
parity, baud rate, and communication line protocol. Regretfullywe have not achieved 100% device-independencein 
this area simply because of the number of possibilities which must be accounted for. Currently, only 
asynchronous ASCII communicationwith variable baud rate (up to 9600 baud)is supported. However, we have 
developed some techniques for handling this area. The basic concept lies in the recognition that at times 
the operator must be in direct contact with the host computer, while at other times, it is the local 
satellite program which is communicating with the host computer. These two modes have been respectively 
identified as Host Mode and ProgramMode. Figure 8 provides an overview of how these modes are accommodated 
by the Graphics Operating System.  The Host Mode lowers the IQ of the system by trans­forming it into 
an alphanumeric terminal, providing direct communicationto the host computer. Every­ thing the operator 
enters on the terminal is sent to the host computer and everything received from the host is displayed 
on the Monitor Viewport. Local echo is supportedwithin the Graphics Operating System and may be enabled 
or disabled as desired. Host Mode is normally used for logging onto the host computer, initiating a 
host program, and terminating communicationwith the host. Host Mode is entered by an initiating request 
to the Graphics Operating System. Once entered, the operator may return to the local monitor only by 
 hitting the Monitor AttentionKey. All other input, including BREAK, is automatically sent to the host 
without local inspection. By hitting the Monitor AttentionKey, the user "wakes up" the Graphics Operating 
System which completes any pending I/O and re-enters the monitor state. Program Mode allows local satellite 
programs to communicatewith the host computer. It is the normal communicationmode in which the host 
computer appears to be a peripheral device to the local program. Input/Output is handled as records 
rather than by single characters as done in Host Mode. An operator would communicate only with the 
local program. This allows the local program to handle editing and graphic input, and the collection 
of data before transmissionto the host. It also allows the local program to converse with either the 
host or the operator independent of the other. Program Mode has been implemented in two different ways. 
A simple version is the Unformatted Mode which allows only for the transmissionand recep­ tion of ASCII 
records. Limited error checking such as parity errors and carrier loss is performed. Unformatted Mode 
is useful wherever data errors are not serious and data transfer rates are not higher than normal interactive 
communication rates. Its simplicity facilitates programming of the host for communication to the local 
graphics system. Entry to and exit from unformatted mode is made by request to the Graphics Operating 
System. In a more complex version of Program Mode, the CommunicationDriver formats each record and monitors 
its status. For obvious reasons this version is called Format Mode. Since the trans­mitted data is formatted 
for the host, it is possible to encode binary records for transmission. This, of course, assumes that 
the host program is aware of the binary records and is able to decode them properly. At this time, the 
format used is a simple packing of binary data into ASCII non­control characters,preceded by a special 
header character and followed by a longitudinalparity check character. If transmission errors occur, 
the transfer is repeated automatically until it is correct. Format Mode also assures synchroniza­tion 
between the host and the local program. Handshaking is provided, and each is aware of the status of the 
other. Finally, Format Mode is able to detect unexpected host system messages due to their unformatted 
appearance. These may be immediately displayed to the operator for appro­priate action. Both Unformatted 
and Formatted Modes exist within the Graphics Operating System. The user or application program may 
request that the Graphics Operating System use one or the other mode. Need­ less to say, the executing 
host program must be aware of which mode is currently in effect. The FormattedMode is normally used 
almost exclusively for interactionwith specific host application programs, while the UnformattedMode 
allows the local program to communicate with the host monitor and general purpose host programs. Summary 
 The Graphics Operating System currently occupies about 24K bytes of memory. It is estimated that further 
refinement can lower the size to about 16K bytes. It is a powerful system that performs much work originally 
left to the executing program. The major advantage of incorporating graphics into the operating system 
is the ability to support a very high degree of device independent graphics and user interaction. This 
allows the developer of a local program to concentrate on the problem of man-machine communicationat 
the concept level rather than the device level. The graphic processing capabilities provided are, by 
their integration in the operating system, maximized for speed, efficiency, and interactionwith other 
system operations. Another benefit was the enjoyment of the authors in the constructionof a complex 
system which supports both refresh and storage graphics, accepts various types of user input, and attempts 
to satisfy general purpose communicationrequirements. The debates, expoundments of ideas, deification 
of techniques, shattering of philosophies, and general rabble-rousingwere really quite a bit of fun. 
 Acknowledgements The authors are deeply indebted to the many people who have advanced the state of 
the art of inter­active computer graphics and particularly to the referenced individualswhose concepts 
and ideas were directly or indirectly incorporated into the Graphics Operating System. We also acknowledge 
the assistance of our colleagues for their thoughts and willingness to discuss ideas with us and the 
assistance of the referees in the finalizationof this paper. In addition, we are grateful to Tektronix 
for providing us with the time and resources to investigate this area of development. Finally,we are 
extremely thankful to numerous secretaries and typists who transformed disorganized illegibility into 
readable documents. References (1) Newman, WilliamM., Sproull, Robert F.,  "Principles of Interactive 
Computer Graphics," McGraw-Hill Book Company, New York, N.Y., 1973  (2) Newman, William M., Sproull, 
Robert F., "An Approach to Graphic System Design", Proceedings of the IEEE, Vol. 62, No. 4, April, 1974 
 (3) Sproull, Robert F., Thomas, Elaine L.,"A Network Graphics Protocol," Network Graphics Group, ARPA 
Network Information Center, Stanford Research Institute,Menlo Park, Calif., 1973  (4) Meads, Jon A., 
"A Terminal Control System", Graphic Languages, North-Holland Publishing Company, Amsterdam,1972  (5) 
Meads, Jon A., "Basic Graphics Software", Special Conference on Computer Graphics as related to Engineering 
Design (Proceedings), National Science Foundation, Washington,D.C., 1973  (6) Koenigsberg, Lawrence, 
Thanhouser, Ned, "A Graphics System for APL Users -APL/Graph II", Proceedings of the Sixth International 
APL Users' Conference, Coast Community College District, Anaheim, Calif., 1973  (7) Foley, James D., 
Wallace, Victor L., "The Art of Natural Graphic Man-Machine Conversa­tion", Proccedings of the IEEE, 
Vol. 62, No. 4, April, 1974.  (8) Foley, James D., "Software for Satellite Graphic Systems", Proceedings 
of the ACM, 1973  (9) Christensen, C., Pinson, E.N., "Multi-Function Graphics for a Large Computer System", 
FJCC 1967, Thompson Books, Washington,D.C.  (10) Cotton, I.W., Greatorex, F.S., Jr., "Data Structures 
and Techniques for Remote Computer Graphics", FJCC 1968, Thompson Books, Washington,D.C.  (11) Ninke, 
W.H., "Graphic 1-A Remote Graphical Display Console System", FJCC 1965, Spartan Books, Washington, D.C. 
 (12) Rapkin, M.D., Abu-Gheida, O.M., "Stand Alone/ Remote Graphic System", FJCC 1968, Thompson Books, 
Washington, D.C.  (13) Van Dam, Andries, Stabler, George M., "Intelligent Satellites for Interactive 
Graphics", Proceedings of the NCC, Vol. 43, 1973.  (14) Ross, D.T, Stotz, R.H., Thornhill, D.E, "The 
Design and Programming of a Display Interface System Integrating Multi-Accessand Satellite Computers",Proceedings 
of the 4th Share/ACM Design AutomationWorkshop, 1967.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563739</article_id>
		<sort_key>49</sort_key>
		<display_label></display_label>
		<article_publication_date>04-01-1975</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Towards device-independent graphics systems]]></title>
		<page_from>49</page_from>
		<page_to>52</page_to>
		<doi_number>10.1145/563732.563739</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563739</url>
		<abstract>
			<par><![CDATA[A formalism for logical input devices is presented that opens the way to input device independent graphics systems combined with a high degree of flexibility to study and utilize the psychological differences of logical equivalent physical input devices.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P334155</person_id>
				<author_profile_id><![CDATA[81100519312]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ulrich]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Trambacz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Technical University of Berlin, 35 -37 Einsteinufer, D-looo Berlin lo, West-Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>988479</ref_obj_id>
				<ref_obj_pid>988476</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[W. M. Newman, Where Are We ?, SIGGRAPH-ACM Computer Graphics, Vol.8, no.1, Spring 1974, pp.12-29]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. D. Foley and V. L. Wallace, The Art of Natural Man-Machine Conversation, Proc.IEEE, April 1974]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[W. M. Newman, A system for interactive graphical programming, Proc. AFIPS 1968 SJCC, vol.32, pp.47-54]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[I. W. Cotton, Network graphic attention handling, ONLINE 72, Conf.Proc., pp.465-49o]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[W. M. Newman, An Approach to Graphics System Design, Proc. of AFCET/IRIA journees graphiques 1973, pp.23-26.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Encarnacao and U. Trambacz, The Design and Organization of a General-Purpose Display Processor, Proc. of AFCET/IRIA journees graphiques 1973, pp. 37-5o]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[C. H. A. Koster, Portable compilers and the UNCOL problem, Proc. IFIP Working Conf. on Machine Oriented High Level Languages, Trondheim, Aug.1973]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[W. M. Newman, A graphical technique for numerical input, Computer Journal, vol. 11, May 1968, pp.63-64]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 TOWARDS DEVICE-INDEPENDENTGRAPHICS SYSTEMS Permission to make digital or hard copies of part or all 
of this work or personal or classroom use is granted without fee provided that copies are not made or 
distributed for profit or commercial advantage and that copies bear this notice and the full citation 
on the first page. To copy otherwise, to republish, to post on servers, or to redistribute to lists, 
requires prior specific permission and/or a fee.Siggraph 75 Bowling Green Ulrich Trambacz Technical University 
of Berlin Department of Cybernetics 35 -37 Einsteinufer D-looo Berlin lo,West-Germany Abstract A formalism 
for logical input devices is presented that opens the way to input device independent graphics systems 
com­bined with a high degree of flexibility to study and utilize the psychological dif­ferences of logical 
equivalent physical input devices. Introduction "Why is Graphics Always a Year Away?" There are at 
least two answers to this somewhat optimistic question addressed at a conference in Seattle, Wa., organized 
in summer 1973 by Batelle's Seattle Research Center. First: There is a great diversity of graphic terminals 
and their attached input devices. Programming facilities are de­signed to take advantage of the specific 
hardware features of these systems and to evade their disadvantages. Therefore, pro­grams for these systems 
are highly device­dependent, and there is nearly no portabil­ity of application programs among those 
systems. Thus, the first step towardshigh­level and general-purpose graphics systems /1/ is to achieve 
device-independency. And second: Still there is only a slight understandingof the nature of design and 
the ergonomic aspects of se­quences of user-input activity. WALLACE stated in /2/ "tactile and visual 
conti­nuity" and "sentence structuring" in the command language as a pre-requisite for conversational 
input sequences in graphic systems. To meet this postulate further research has to investigate the psycholog­ical 
and physiological differences of the various input devices and to provide those current or future devices 
most suitable for a specific application.Again, to achieve device-independencya reasonable categorizing 
of the input devices is needed. Logical Input Devices In 1968 NEWMAN /3/ defined seven user­ input 
categories: text string with and without embedded carriage return, decimal and octal valuator, pick, 
 locator, and keyboard push buttons. In 1972 COTTON /4/ reduced the graphi­ cal input devices to just 
four physical devices: button, analog, tablet, and light pen. In 1973 again NEWMAN /5/ suggested 
 the provision of five high-level primitive functions, each implementing a particular form of interaction. 
These are positioning, pointing, inking, character recognition, and dragging. At the same conference 
a classifica­ tion of graphical input devices in terms of user actions was proposed /6/: object identification, 
position indication, input of conditions, and dynamic input of parameter. It turns out that the normal 
use of the keyboard does not fit into this scheme which might have been arisen from a certain aversion 
against typewriters. Recently, FOLEY and WALLACE /2/ pre­ sented a very nice and promising virtual 
device concept. They defined four virtual devices ­ pick, button, locator, and valuator ­ to which they 
associateddistinct physical input devices as prototypes. As COTTON /4/ already pointed out, the physical 
input devices are interchange­able and occasionally they have to be ex­changed because not all of them 
are appli­ cable with every output device. Substitu­tion is not only useful in this case. Because of 
their psychologicaldifferences it is -until now only in theory -possible to provide the user with that 
physical device which fits best his needs in the sense of tactile and visual continuity.To ease the 
studies of the action sequence designers and to achieve portability of graphics systems the logical device 
ap­proach is most suitable. Keeping the terminology of FOLEY and WALLACE but with some modifications 
in their definitions and the grouping of the physical devices, the following definitions are proposed: 
 <device>::=<pick> <locator>l<button>I <valuator> <pick> ::= indication of object defined within the 
use of the applica­tion system by <applied pick> <locator>:= indication of position by <applied locator> 
 by <applied button> <valuator>::= indication of value by <applied valuator> These logical input devices 
are the only devices the system deals with in order to obtain input device independency. On the user's 
side the logical devices are representedby a number of physical reali­zations or their functional equivalences 
which are interfaced with the logical de­vices either by macros /7/ or by an input handling micro-processor 
/6/. The functional equivalences and the physical realizations of the logical de­vices are given in 
table 1. A comment concerning the modificatiors of the definitions given in /2/ is ap­ propriate:FOLEY 
and WALLACE defined the pick as an indicator of "user defined objects" and the button as an indicator 
of "system defined objects". There might exist systems which allow, e.g., not only the applicationprogrammer 
but also the user to define the meaning of menu items (light buttons) or to define predefined movements 
of a pick or a locator. Despite of the fact that these objects are user defined they are acting as system 
defined objects. To solve this adversity the but­ton is defined as "indication of object defined within 
the application system", and the pick is defined as "indication of object defined within the use of the 
application system". As already pointed out, the gain of the presented formalism is -beside getting 
input device independency -the inter­ changeability of physical input devices. We can discover some 
interesting methods by substituting one device by another. Of course, some substitutions are far-off 
methods, e.g. substitutinga pick by a button and again substituting the button by a pick. And we can 
get pleonasms: <button>::= indication of object defined within the application system  In this case, 
"boxing controlled by a cursor which is controlledby an<applied button>" is a detour and a pleonasm to 
"boxing controlled by <applied button>". A distinguishedinput device, the Light Handle, is described 
by NEWMAN /8/. It is found in the presented formalism by a multi-level substitution:  Example One philosophy 
is to avoid the use of the light pen and to exchange the light pen for a tablet for reasons of tactile 
continuity and greater accuracy. The light pen is the prototype of a logical device called pick. To exchange 
the light pen we produce the following substitutions: The "applied devices" might be sub­stituted either 
by their physical realiza­tions or by the functional equivalences for further substitutions. Conclusions 
 The presented definition of logical input devices opens the way to inputdeice independent graphics systems 
combinedwith a high degree of flexibility to study and utilize the psychological and physiological differences 
of logical equivalent physical input devices, so that "in a year" a user might use a graphics system 
in a way natu­ral to him rather than being used by the system as it is mostly true today. Further research 
should be directed towards the inclusion of psychological weights and time constraints into this formalism. 
 References /1/ W.M.Newman,Where Are We ?, SIGGRAPH- ACM Computer Graphics,Vol.8, no.1, Spring 1974, 
pp.12-29 /2/ J.D.Foley and V.L.Wallace, The Art of Natural Man-Machine Conversation, Proc.IEEE, April 
1974 /3/ W.M.Newman,A system for interactive graphical programming,Proc.AFIPS 1968 SJCC, vol.32, pp.47-54 
 /4/ I.W.Cotton, Network graphic attention handling, ONLINE 72, Conf.Proc., pp.465-49o /5/ W.M.Newman,An 
Approach to Graphics System Design, Proc.of AFCET/IRIA journees graphiques 1973, pp.23-26. /6/ J.Encarnacaoand 
U.Trambacz, The De­sign and Organizationof a General- Purpose Display Processor, Proc.of AFCET/IRIA journees 
graphiques 1973, pp. 37-5o /7/ C.H.A.Koster, Portable compilers and the UNCOL problem, Proc.IFIP Working 
Conf. on Machine Oriented High Level Languages, Trondheim,Aug.1973 /8/ W.M. Newman, A graphical technique 
for numerical input, Computer Journal, vol. 11, May 1968, pp.63-64 Table 1: Definition of logical input 
devices <device>::= <pick>I<locator>l<button>l<valuator> <pick> ::= indication of object defined within 
the use of the applicationsystem by <applied pick> <locator>::= indication of position by <applied locator> 
<button>::= indication of object defined within the application system by <applied button> <valuator>::= 
indication of value by <applied valuator> <applied pick>::=-<physical pick>l<functional equivalent to 
physical pick> <applied locator>::= <physical locator>l<functional equivalent to physical locator> <applied 
button>::= <physical button>l<functional equivalent to physical button> <applied valuator>::= <physical 
valuator>l<functional equivalent to physical valuator> <physical pick>::= light pen <physical locator>::= 
tablet stylus <physical button>::= keyboard I light pen switch tablet stylus switch programmed function 
 key Iprogrammed footpedal voice input analyzer <physical valuator>::= potentiometer Ijoystick Imouse 
Itrackball Idigitizer <functional equivalent to physical pick>::= boxing controlled by <applied locator>j 
 boxing controlled by <applied button>linput of name by <applied button> brightening controlled by 
<applied button> boxing controlled by <applied valuator> <functional equivalent to physical locator>::= 
tracking symbol controlled by <applied controlled by<applied button>I by <applied valuator> <functional 
equivalent to physical button>::= menu item selected by <applied pick>I predefined movement of <applied 
pick>I predefinedmovement of <applied locator>I tuning dialling by <applied valuator> <functional 
equivalent to physical valuator>::= value selected from displayed scale by <applied pick>I numeric input 
by <applied button> 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563740</article_id>
		<sort_key>53</sort_key>
		<display_label></display_label>
		<article_publication_date>04-01-1975</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[IMAGE]]></title>
		<subtitle><![CDATA[a language for the interactive manipulation of a graphics environment]]></subtitle>
		<page_from>53</page_from>
		<page_to>60</page_to>
		<doi_number>10.1145/563732.563740</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563740</url>
		<abstract>
			<par><![CDATA[This paper addresses itself to the problems involved in programming an interactive computer graphics display. A list of graphical programming facilities considered necessary for an interactive graphic programming language is presented. An examination of several application programs, written in a variety of existing languages, revealed that many of these facilities are usually lacking.This paper presents the design of a new interactive graphics language 'IMAGE', developed specifically to satisfy the above criteria. The language places particular emphasis on providing a graphics application programmer the ability to program graphical interaction. The 'IMAGE' language utilizes the better features of several current graphic languages and combines these features with a unique interaction control structure. This OBJECT / ACTION control structure, the display picture description syntax and the hardware independent handling of input devices are the main features of the language, providing excellent graphical input response and drawing facilities. The device independent input / output structure permits the implementation of a portable language syntax, since there are no references to display hardware devices. All display references are performed through a virtual terminal. This paper contains a detailed description of the main features of the language and these features are illustrated in an example 'IMAGE' program.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P37958</person_id>
				<author_profile_id><![CDATA[81100311348]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[O'Brien]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Government of Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P102272</person_id>
				<author_profile_id><![CDATA[81100142496]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[H.]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Bown]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Government of Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[O'Brien, C. D., "IMAGE - a language for the Interactive Manipulation of A Graphics Environment". M. Eng. Thesis, Carleton University, Ottawa, Canada, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Newman,W. F., -and Sproull, R. F., "Principles of Interactive Computer Graphics", McGraw-Hill, New York, 1973]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Maclean, M. A., "Designing a Language for Interactive Control Programs", 2nd Man-Computer Communications Seminar, 31 May - 1 June, 1971, pp. 30-39.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M., "An Experimental Display Programming Language for the PDP-10 Computer", University of Utah, UTEC-CSC-70-104, July, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Foley, J. D. and Wallace, V. L., "The Art of Natural Graphic Man-Machine Conversation", Proc. of IEEE, Vol.62, No.4, April 74.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Woodsford, P. A., "GINO: Graphical Input/Output", University of Cambridge Computer Aided Design Group, June 1969.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Hurwitz, A., Citron, J. P., and Yeaton, J. B., "GRAF - Graphical Extension to Fortran", SJCC, 1967, Thompson Books, Wash. D.C., 553.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>362808</ref_obj_id>
				<ref_obj_pid>362759</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M., "Display Procedures", CACM, Vol.14, No.10, Oct., 1971.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M., Gouraud, II., and Oestreicher, D. R., "A Programmer's Guide to PDP-10 Euler", University of Utah, UTEC-CSC-70-105,Jan, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Williams, D. L., "GRAPPLE - Graphics Application Programming Language". NRC 3rd Man-Computer Communications Seminar, May, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>367619</ref_obj_id>
				<ref_obj_pid>367593</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Wirth, N., "A Generalization of Algol", CACM, Vol 6, No.9, Sept., 1963.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>986983</ref_obj_id>
				<ref_obj_pid>986953</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Miller, E. F., "Extensions to Fortran to Support Structured Programming, (IFTRAN)". Sigplan Notices, Vol.8, No.6, June. 1973, p. 63-64.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>811158</ref_obj_id>
				<ref_obj_pid>800284</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Bezanson, W. R, "Teaching Structured Programming in FORTRAN with IFTRAN", Proc. of the 5th ACM SIGCSE symposium, Feb., 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Miller, E. F., "Program Validation Project", General Research Co., 1974]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 IMAGE Permission to make digital or hard copies of part or all of this work or personal or classroom 
use is granted without fee provided that copies are not made or distributed for profit or commercial 
advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, 
to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or 
a fee.Siggraph 75 Bowling Green a language for the Interactive Manipulation of A Graphics Environment 
 by C.D.O'Brien and H.G.BOWN Communications Research Centre Department of Communications Government 
of Canada ABSTRACT This paper addresses itself to the problems involved in programming an interactive 
computer graphics display. A list of graphical programming facilities considered necessary for an interactive 
 graphic programming language is presented. An examination of several application programs, written in 
a variety of existing languages, revealed that many of these facilities are usually lacking. This paper 
presents the design of a new interactive graphics language 'IMAGE', developed specifically to satisfy 
the above criteria. The language places particular emphasis on providing a graphics application programmer 
the ability to program graphical interaction. The 'IMAGE' language utilizes the better features of several 
current graphic languages and combines these features with a unique interaction control structure. This 
OBJECT / ACTION control structure, the display picture description syntax and the hardware independent 
handling of input devices are the main features of the language, providing excellent graphical input 
response and drawing facilities. The device independent input / output structure permits the implementation 
of a portable language syntax, since there are no references to display hardware devices. All display 
references are performed through a virtual terminal. This paper contains a detailed description of the 
main features of the language and these features are illustrated in an example 'IMAGE' program. INTRODUCTION 
 An interactive computer graphic system is a system which permits a 'conversation' to occur between the 
user and the computer, where the communications medium is a computer driven display. The complexities 
of the interactive dialogue, which result from the use of an interactive computer graphics system create 
complex programming problems. Conventional programming languages are executed serially, instruction 
by instruction, with the execution flow controlled by conditional statements. Although it is possible 
to write a graphics application program in this serial fashion it can be quite awkward to do so. The 
highly interactive nature of a graphics program lends itself to programming in an action oriented language. 
In this paper the design of a new interactive graphics language 'IMAGE' is presented. This language places 
particular emphasis on providing a graphics applications programmer the ability to easily program graphical 
interaction. From an examination of programs written in a variety of languages [1] it was concluded 
that the writing of interactive graphical application programs is greatly aided when the following five 
facilities are available. a) Graphical input response facilities b) Graphical drawing facilities c) 
Structured programming constructs d) Data manipulation facilities e) Easy access to external software 
 a) Graphical Input Response Facilities: One of the main requirements of any interactive process is to 
define the response of the system to each input. One approach which has been suggested by Newman [2] 
is that this system should be considered as a finite state automaton where an 'action' is simply an 
input to the system and the corresponding 'reaction' is determined by the state of the system at the 
time. This approach to defining a program control sequence can be implemented such that the programmer 
is required to be specifically aware of all the states of his system in order to specify the action-reaction 
sequences, or the system can be designed such that these state transitions are transparent to the programmer. 
DIAL [41 is an example of the former system, whereas ICPL [3] is an example of the latter. Because it 
puts less of a burden on the programmer, it is felt that the latter method is superior. Most languages 
provide only highly device dependent information about particular inputs. This device dependence can 
be removed by providing suitable language constructs referencing a small number of idealized devices 
[5]. b) Graphical Drawing Facilities: There are two common ways of providing graphical drawing facilities 
needed in a general purpose interactive graphical programming system. The first involves the notion of 
 function or subroutine calls and does not require any modification to the base language from which they 
are called. Many graphic systems available today (especially those supplied by manufacturers) are of 
this type. Specific examples are GINO [6] and GRAF [7]. Graphical drawing facilities may also be provided 
by specific instructions within the language. This provides the capability of defining display procedures 
[8]. This method , however, requires modification of the syntax of the base language or the creation 
of a complete new language. Display procedures provide distinct items on which to apply transformations, 
and therefore provide a compact, high-level method of defining pictures. EULER/G [9] and GRAPPLE [101 
are examples of language systems providing this display procedure capability. c) Structured Programming 
Constructs: It is very important that the base language provide good facilities for defining the overall 
structure of the program. Examples of languages exhibiting excellent program structure facilities are 
ALGOL [11] and to a lesser extent, IFTRAN [12,13]. Both these languages provide good constructs for iterative 
and conditional operations such as IF, WHILE and ELSE. A local subroutine capability is desirable, and 
provides a convienent method of implementing a display procedure capability. d) Data Manipulation Facilities: 
A computer graphics program describes pictures in a numerical form and textual information in terms of 
character strings and it is therefore useful to have both numerical and character data types. In certain 
applications it is essential that a representation of a picture be stored in a dynamic data structure, 
thus providing the capability of manipulating and regenerating it. It may overburden the syntax of a 
graphics language to provide a generalized data structure capability, so, as a minimum, access to external 
facilities written in other languages should be provided. e) Easy Access to External Software: Any 
good programming'systemshould provide an easy and convenient access to external software packages. Very 
often an application program will require access to some external routines that are already provided 
in the computer system library or that already exist written in some other language like FORTRAN or ALGOL. 
The communication of data to external software should be in a simple manner, such as direct narameter 
references. We do not feel that these requirements are adequately met in any existing language. The 
'IMAGE' language was designed to specifically satisfy the above criteria. A unique interaction control 
structure, along with a display procedure based picture description grammar and device independent interaction 
input facilities were combined to form 'IMAGE'. The remainder of this paper will present a brief description 
of the syntax of 'IMAGE'. THE 'IMAGE' LANGUAGE 'IMAGE' has been designed in order to provide a language 
in which a relatively untrained person can program interactive graphic application programs. The language 
is designed for 'application programmers'; that is, persons who have some knowlege of programming but 
have most of their expertise in the field of their application. The language provides a basic set of 
graphical drawing commands and augments this with a powerful set of display modifiers. The language is 
procedure oriented and procedures may be easily defined within a program. An easy method has been provided 
to communicate with external programs written in other languages, so that an applications programmer 
can write sections of his program package in languages more suited to other tasks such as data manipulation 
or complex calculations. This feature has the virtue of easily allowing the programmer to add a graphics 
capability to an already existing applications package written in some other language. This permits the 
major emphasis of the syntax of this language to be for picture description and interaction control. 
 The form of the execution flow control statements borrows from the format of the 'IFTRAN' FORTRAN preprocessor 
(Bezanson [13], Miller [12,14]) in order to provide a structured programming capability. The adoption 
of a simple data formatting scheme and the use of character string variables has allowed for the design 
of a language structure which uses no labels at all. This language has been designed so that it addresses 
the graphical problem directly in a hardware independent manner. A program written in this language should 
onerate regardless of which I/O devices are available. Device independence has been designed into the 
language so that particular device technologies have a minimum effect on the programs written in the 
language. For example, a program which uses a light-pen as an identifier on one system should operate 
just as well using a trackball and a cursor on another. The language treats all displays as identical 
and allows similar operations to occur on them. The programmer introduces device dependency only when 
he depends on the speed of a particular implementation. The myriad of input devices have been broken 
into six classes. Three of these classes are particularly concerned with interaction with the display. 
The other classes of interaction are general in nature and could be associated with a non-graphical program. 
Interaction control commands allow these graphical devices to be assigned to particular input functions. 
Each device behaves as a virtual device so that it is possible to use software techniques to allow one 
real device to perform the function of another. For example a positioning device such as a track-ball 
can be used to identify light-buttons, even though the concept of a light-button was derived from light-pen 
usage. GENERAL PROGRAM FORMAT The structure of an 'IMAGE' program consists of a number of independent 
blocks of executable code. There are four types of blocks: OBJECT, ACTION, ENTRY and PROCEDURE definition 
blocks. OBJECT blocks define graphical material to be displayed and ACTION blocks delimit code to be 
executed upon an identifier strike on that displayed material. ACTION blocks must follow their associated 
OBJECT blocks, thereby indicating that association. One ENTRY block may appear to allow initialization 
 and it is usually the first block of executable code. The procedure blocks provide a local subroutine 
capability, necessary to prevent the duplication of code. Transformation operators may be applied to 
a PROCEDURE block to modify the displayed appearance of any graphical instructions discribed within the 
block. Statements within an OBJECT block are executed when the object is displayed by invoking the language 
statement DISPLAY. Any display code generated is marked (TAGged) so that an ACTION routine may be executed 
upon the stimulus of the displayed OBJECT. OBJECT blocks therefore define what is commonly refered to 
as a 'light-button'. An ACTION block defines the action to occur upon the stimulus of the preceeding 
OBJECT block. An ACTION block is basically a high-level interrupt handler routine. The identifier interrupt 
structure is disabled upon the execution of an ACTION block and is re-enabled by the use of a SEEK command. 
Execution is suspended at the end of an ACTION block by the use of a WAIT command. The program then reads 
as a series of OBJECT / ACTION pairs whose execution is interactively controlled. Figure 1 illustrates 
this program structure.  LANGUAGE STATEMENTS The 'IMAGE' graphics language consists of two types of 
instructions, executable statements and definitional statements. The definitional statements determine 
the structure of a program by defining the block structure, the graphics environment and all variable 
types to be used. Executable statements are normally executed serially within the blocks defined by 
the definitional statements. They are used to manipulate character and arithmetic expressions, perform 
I/O with the display, invoke procedure and subroutine calls, set display modification variables and 
control the flow of execution. Commands to execute simple control within a block are the IF ... ORIF 
... ELSE ... FIN, CASE, and WHILE ... FIN constructs. These commands delimit the executable code within 
an OBJECT, ACTION, ENTRY or PROCEDURE block into sub-blocks. This structured programming capability 
provides a total freedom from the use of labels. String and arithemetic assignments, flow control and 
subroutine calling procedures are provided in a conventional manner and will not be discussed further. 
The graphical drawing, display editing and interaction control statements will be discussed below in 
greater detail, because together they provide a novel approach to manipulating graphical images. DISPLAY 
EDITING INSTRUCTIONS The display editing instructions are provided to permit creation and modification 
of displayed pictures. These commands are only legal in ENTRY or ACTION blocks or PROCEDURES called by 
them. The following five commands provide the core of the control structure. Variations on these five 
commands are available to append material to the screen and to erase dynamic material from the screen. 
An 'EXCLUDING' phrase may be added to those commands which reference named OBJECTs to indicate a reference 
to all OBJECTs except those named. DISPLAY [ name, ... ] -erase the screen and execute all OBJECT blocks 
or all named OBJECT blocks. The unconditional DISPLAY is the normal method of generating a picture and 
associated light-button menu on the screen. ERASE [ name, ... ] -erase the named OBJECT or OBJECTs from 
the screen. If no names are specified erase the entire screen. SEEK [ name, ... ] -enable the identifier 
interrupt mechanism for all OBJECTs, or for the named OBJECTs, if names are specified. WAIT -suspend 
execution of the program and wait for an identifier interrupt. RESUME -continue execution of the section 
of the program which was interrupted when the current ACTION routine was entered. The normal manner 
of ending an ACTION or an ENTRY block is by executing the command sequence DISPLAY then SEEK, then WAIT. 
This clears the display and executes all of the OBJECT blocks regenerating the picture and menu of light-buttons. 
A typical sequence of instructions is given below. OBJECT -executable statements ACTION -executable 
statements DISPLAY SEEK WAIT A SEEK / WAIT is assumed when an ACTION routine is ended by the definition 
of another OBJECT. If a seek command is executed before the end of an ACTION block then the identifier 
interrupt system is enabled and the remainder of the ACTION block may be aborted or suspended by an 
interrupt on another OBJECT. GRAPHICAL DRAWING INSTRUCTIONS The graphical drawing facilities are provided 
in this language by a small number of special drawing instructions. POINTs, LINEs, TEXT and SYMBOLs may 
be drawn, and modifiers may be used to transform them. The format of these instructions has been derived 
from several current graphics languages, especially EULER/G [9]. The following examples illustrate the 
simplicity and power of these instructions. LINES dxl,dyl/dx2,dy2/ ... [ AT (x,y) ] The instruction 
given above defines the drawing of concatenated lines of relative displacement. The starting position 
is normally at the end of the previous item drawn but may be redefined by the optional AT phrase. -The 
use of switches or pushbuttons. TEXT string [ AS (format) ] [ AT (x,y) ] The statement above causes 
the text string to be displayed on the screen (optionally at the position defined by the AT phrase). 
The format list is used to describe the manner in which it will be displayed. Each drawing instruction 
may be transformed by appending to it one or more modifiers separated by semicolons. Modifiers are provided 
for translation, rotation, reflection, scaling, line texture, and for viewing. The use of these modifiers 
is illustrated in Figure 2. A triangle is drawn using the lines command. It was reflected about the 
X axis, rotated 48 degrees, and finally translated using the AT command to location (20,0)  Figure 2 
Example of Modification Operations INTERACTION CONTROL Interaction with the graphics display can be 
attained through the use of many hardware input devices such as tablets, light-pens, knobs, switches, 
pushbuttons, and keyboards, but whatever the device there are only a few basic modes or classes of interaction. 
A real hardware device may be ideally suited to one class of interaction or it may be able to handle 
several classes of interaction with varying ease. The actual hardware devices used are determined at 
load time by device assignments. Conceptually, this language recognizes six input functions and associates 
with them six virtual input devices. These six input functions can be further divided into two groups. 
Three input functions are general in nature and could be associated with a non-graphical language (but 
only the keyboard usually is). The other three functions relate specifically to the graphics display. 
The general input functions are: -Input of textual strings (with or without a carriage return delimiter). 
 Input a numeric value using a 'valuator'. A 'valuator' [5] is a device which allows the input of a number 
without the need of syntax checking. The number is input by some type of continuous device such as a 
potentiometer. The specific graphic functions are: -Identify specific OBJECTs drawn on the display 
screen. -Position a marker to a position on the display screen. -Sketch (accumulating the x,y positions 
visited). There are six virtual devices, each ideally suited to performing a particular input function. 
The real device assigned at run time to perform the task of a virtual device emulates the function in 
the best manner possible. The virtual devices are:  In the class of graphical input functions it is 
possible to interchange the associated device by command within the program. By using suitable software 
techniques, any of the three virtual graphic devices can be made to perform any of the three graphical 
functions. The default condition is for the PICKER to be used for IDENTIFYing, for the DIGITIZER to be 
used for SKETCHing, and for the LOCATOR to be used for POSITIONing. This gives the programmer the ability 
to control the form of input he requires. There may be only one device active at one time per input 
function, but one device may be assigned to several functions. For example: IDENTIFY USING : PICKER 
 This command causes the virtual device PICKER to be used for identifying OBJECTs. A real hardware device 
which can handle the task of picking should be assigned to the virtual device PICKER at load time. What 
 the real devices are, and how well they match the virtual tasks is an imnlementation consideration. 
For example, a light-pen is an excellent PICKER, but the task can be adequately accomplished using one 
of several other devices. IDENTIFYING IDENTIFYing is handled by the OBJECT / ACTION structure of the 
program. Upon an identifier interrupt caused by the identifying instrument 'seeing' the displayed OBJECT, 
the ACTION routine associated with that OBJECT is executed. Also, if the indicated OBJECT is in a graphics 
subroutine and is a sub-object of another OBJECT in the calling program, the ACTION associated with both 
OBJECTs is executed, in hierarchical order. SKETCHING When a user sketches on the graphics display screen 
in a free-hand manner he accumulates data describing where the free-hand drawing stylus has been. The 
sketching mechanism provides him with a queue of the x and y positions visited. Every valid point accumulated 
is stored in a queue. It is the responsibility of the programmer to provide some visual feedback to the 
user. POSITIONING A controllable marker is provided through the positioning facility in order to allow 
a user to indicate specific screen locations. The motion of this marker is controlled by a device such 
as a locator and may be constrained to specific directions. INPUT OF TEXTUAL STRINGS The input of textual 
information in the form of character strings can be performed in several ways. Conventional programming 
languages have record oriented input facilities. One string of characters is entered at a time and execution 
of the program is suspended until the entire record is entered. This type of input is useful but, in 
a highly interactive environment, it is often necessary to perform interupt driven input. A unique feature 
of this language is its ability to handle interrupts, so interrupt based innut is easily performed. 
PUSHBUTTONS A pushbutton is treated as a special type of object within an OBJECT block. Upon a pushbutton 
'strike' (push) the ACTION associated with the OBJECT containing the pushbutton statement is executed. 
Distinguishing one pushbutton from another is a programming problem because there is no standard terminal 
and therefore no standard location for buttons. One installation may have footpedals while another may 
have a function keyboard or individual buttons or a combination of these. To avoid this problem a simple 
numbering scheme is assumed. VALUATORS A valuator is a device which allows the input of numeric information 
in a manner which requires none of the syntax checking needed in character oriented operations. Numbers 
are input by a continuous device such as a potentiometer. As a valuator is adjusted, the value is updated 
continously. In order for a valuator to be useful it must be possible to provide immediate feedback of 
the value in a user defined format. AN EXAMPLE PROGRAM The following program illustrates the use of 
'IMAGE'. The program generates a menu of five light-buttons and displays a picture on the screen of a 
stylized lunar lander and command ship. The first light-button moves the lander to the left, towards 
but not beyond, the command ship. The second light-button moves the lander to the right, away from the 
ship, the third light-button causes the lander to rotate by 10 degrees, and the fourth and fifth light-buttons 
move the lander up and down. Successful docking is indicated when accomplished. Figure 3 indicates the 
initial status of the screen.  CONCLUSIONS This paper presents the design philosophy of the interactive 
computer graphics language 'IMAGE'. This language has been specifically designed to ease the task of 
interactive graphics applications programming and as such contains a powerful set of display creation, 
editing and interaction control instructions. The 'IMAGE' language utilizes the better features of several 
current graphics languages and combines these features with a unique interaction control structure. This 
OBJECT / ACTION control structure, the display procedure picture description syntax and the hardware 
independent handling of input devices are the main features of the language, producing excellent graphical 
input response and drawing facilities. The conditional control structure embodies the use of structured 
programming constructs and easy access to external software has been provided. The language contains 
only simple numeric and character data types with access to more powerful data manipulation facilities 
provided via external software. The device independent input / output structure permits the implementation 
of a portable language syntax since there are no references to particular display hardware devices within 
a program. All interaction is performed through a virtual display terminal. REFERENCES 1. O'Brien, C.D., 
"IMAGE -a language for the Interactive Manipulation of A Graphics Environment". M.Eng. Thesis, Carleton 
University, Ottawa, Canada, 1975. 2. Newman,W.F., -and Sproull,R.F., "Principles of Interactive Computer 
Graphics", McGraw-Hill, New York, 1973  3. Maclean,M.A., "Designing a Language for Interactive Control 
Programs", 2nd Man-Computer Communications Seminar, 31 May -1 June, 1971, pp. 30-39.  4. Newman,W.M., 
"An Experimental Display Programming Language for the PDP-10 Computer", University of Utah, UTEC-CSC-70-104,July, 
1970.  5. Foley,J.D. and Wallace,V.L., "The Art of Natural Graphic Man-Machine Conversation", Proc. 
of IEEE, Vol.62, No.4, April 74.  6. Woodsford, P.A., "GINO: Graphical Input/Output", University of 
Cambridge Computer Aided Design Group, June 1969.  7. Hurwitz,A., Citron,J.P., and Yeaton,J.B., "GRAF 
-Graphical Extension to Fortran", SJCC, 1967, Thompson Books, Wash. D.C., 553. 8. Newman, W.M., "Display 
Procedures", CACM, Vol.14, No.10, Oct., 1971.  9. Newman,W.M., Gouraud,ll., and Oestreicher, D.R., "A 
Programmer's Guide to PDP-10 Euler", University of Utah, UTEC-CSC-70-105,Jan,1970. 10. Williams, D.L., 
"GRAPPLE -Graphics Application Programming Language". NRC 3rd Man-Computer Communications Seminar, May, 
1973.  11. Wirth,N., "A Generalization of Algol", CACM, Vol 6, No.9, Sept., 1963.  12. Miller,E.F., 
"Extensions to Fortran to Support Structured Programming, (IFTRAN)". Sigplan Notices, Vol.8, No.6, June. 
1973, p. 63-64.  13. Bezanson,W.R, "Teaching Structured Programming in FORTRAN with IFTRAN", Proc. of 
the 5th ACM SIGCSE symposium, Feb., 1975.  14. Miller,E.F., "Program Validation Project", General Research 
Co., 1974  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563741</article_id>
		<sort_key>61</sort_key>
		<display_label></display_label>
		<article_publication_date>04-01-1975</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[On high-level programming systems for structured display programming]]></title>
		<page_from>61</page_from>
		<page_to>69</page_to>
		<doi_number>10.1145/563732.563741</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563741</url>
		<abstract>
			<par><![CDATA[The main topic of the paper is to introduce a concept for structured display programming in interactive computer graphics and to discuss the suitability of FORTRAN, ALGOL, PL/I, and APL as the host language for such a programming system. To this end, the interrelationship between picture structures, data structures, and language structures is first established. Based on the obtained conclusions, a model language for interactive display programming (GRIP) is introduced. The suitability of the above mentioned languages is discussed, and experiences with the implementation of the GRIP philosophy in some of these languages are communicated.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39040733</person_id>
				<author_profile_id><![CDATA[81100391683]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wolfgang]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Giloi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota, Minneapolis, Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Meads, J., A terminal control system, Proc. of the IFIP Working Conf. on Graphic Languages, North Holland Publ. Co. (1972), 271-290.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Scoop, K., The design and use of a PL/I based graphic programming language, ONLINE 72, vol. 2, 601-615.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Hurwitz, A., Citron, J. P., and Yeaton, J. B., GRAF: Graphic Addition to FORTRAN, Proc. AFIPS SJCC 1967, 553-557.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Kay, A. C., FLEX - A Flexible Extendable Language, Computer Science Technical Report 4-7, Univ. of Utah (June, 1968).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Giloi, W. K., Encarnacao, J. and Kestner, W., APLG -APL extended for Graphics, ONLINE 72, vol. 2, 579-599.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Shaw, A. C., A formal picture description scheme as a basis for picture processing systems, Inf. & Control 14, 1 (1969), 938-947.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Johnson, C. I., Principles of interactive systems, IBM Systems Journal, 7, 314 (1968), 147-174.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Knuth, D. E., Structured programming with GOTO statments, Stanford Univ. Tech. Report STAN-CS-74-416 (May, 1974).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>361591</ref_obj_id>
				<ref_obj_pid>355604</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Dijkstra E., The humble programmer, CACM 15, 10 (1972), 859-866.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Messer, D., GRAP 3.0, Preliminary User's Manual; Dept. of Computer, Information and Control Science, University of Minnesota (1975).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Giloi, W. K., Encarnacao, J., APLG- An APL based system for interactive computer graphics,Proc. AFIPS 1974 NCC, 521-528.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ON HIGH-LEVEL PROGRAMMINGSYSTEMS FOR STRUCTUREDDISPLAY PROGRAMMING Permission to make digital or hard 
copies of part or all of this work or personal or classroom use is granted without fee provided that 
copies are not made or distributed for profit or commercial advantage and that copies bear this notice 
and the full citation on the first page. To copy otherwise, to republish, to post on servers, or to redistribute 
to lists, requires prior specific permission and/or a fee.Siggraph 75 Bowling Green Wolfgang K. Giloi 
Professor University of Minnesota Minneapolis, Minnesota 55414 The main topic of the paper is to introduce 
a concept for structured display pro­gramming in interactive computer graphics and to discuss the suitability 
of FOR- TRAN, ALGOL, PL/I, and APL as the host language for such a programming system. To this end, the 
interrelationshipbetween picture structures, data structures, and language structures is first established. 
Based on the obtained conclusions, a model language for interactive display programming (GRIP) is introduced. 
The suitability of the above mentioned languages is discussed,and experiences with the implementationof 
the GRIP philosophy in some of these languages are communi­cated. 1. INTRODUCTION Over the years a 
number of FORTRAN subrou­tine packages for computer graphics have been implemented. In a number of papers, 
language extensions for computer graphics have been proposed. It is not just by chance that subroutine 
packages for com­puter graphics are widely used, whereas proposed language extensions are usually not 
generally accepted. The main rea­son for this is that a subroutine package can always be easily added 
to an existing compiler, whereas an extension requires ma­jor modificationor a rewriting of a com­piler. 
The approach of providing a dis­play procedure package instead of a lan­guage extension, pragmatic as 
it is, has one shortcoming. It does not offer the possibility of introducing new data types and, hence, 
it rules out language con­structs in which graphic objects may function as variables of expressions and 
statements. Therefore, a package of special procedures is not the proper approach if one wants to compose 
pictures by applying algebraic operations on gra­phics primitives (this is done, for exam­ple, in PDL6 
or similar picture descrip­tion languages)- Hence, graphic procedure packages are appropriate and convenient 
for generative computer graphics but not for the relational-descriptive approach or for what we may call 
"inferential" graphics. The primary justificationfor the dominant use of FORTRAN subroutine packages 
for graphics programming systems lies obvious­ ly in the fact that FORTRAN is the most  commonly used 
language and that, in the case of stand-alone graphics systems, the small-scale to medium-scalecomputers 
used as the dedicated sole processor in the system has FORTRAN as the only high-level language available 
anyway. Authors of papers dealing with the design of subroutine packages for (or the extension of) languages 
other than FORTRAN will never hesitate to emphasize the advantages of their chosen language over FORTRAN, 
but it seems that very little attempt has been made yet to compare the most eligible languages systematically. 
More than FORTRAN,we consider PL/I, APL, and ALGOL (or ALGOL-like languages like, for in­ stance, PASCAL) 
to be the most eligible lan­ guages whose suitability to function as a host language for display programming 
shall be dis­ cussed. In the course of this discussion, we should consider the fact that in actual computer 
 graphics applications the ability of a language for constructing and managing data bases is equally 
or even more important than its ability for writing picture-generatingprograms. The reason why we shall, 
nevertheless, dwell more on the picture-generatingaspects rather than the data base management aspects 
is that in the latter case the language capabilities are fairly well understood,whereas in the former 
 case it appears necessary to study first the interrelationshipbetween picture structures, data structures,language 
structures, and the mechanism of picture specification in order to identify the required capabilities. 
 Generated pictures can be classified into two cases, namely: Program-created pictures (plot­ ting) 
and interactively created pictures. Whereas the former case is relatively straight­ forward, the latter 
case includes the "atten­ tion handling" mechanism, and the associated program structure is affected 
by the choice as to whether all steps of an interactiveprocedure are directly controlledby the main 
program or whether we have an "intelligent" terminal with some global directives, whereatthe individual 
steps of a procedure are controlledand execu­ ted locally. 2. Picture Structure The task of a programmer 
who has to write a program for the generation, identification,and manipulationof graphics objects displayed 
on a CRT screen will be considerably simplified by a picture structure that enables him to deal glo­bally 
with certain entities beyond just single graphic primitives such as lines, dots, charac­ ters, etc. 
Therefore, we may partition the set of all primitives of a picture into equivalence classes with respect 
to certain common features such as appearance, status, origin, and identi­ fier. Under appearance we 
subsume controllable fea­ tures such as the beam intensity (or a gray­ level in halftone displays or 
a color in color displays, etc.) and the line style (in line­ drawings). The status determines whether 
or not an entity is "pickable"by a lightpen or a cursor, whether or not a character string can be overwritten, 
and whether or not an entity may blink to attract the users attention. Origin is a point in the picture 
domain to which all other coordinatesof an entity are relative. This facilitates the performance of 
picture transformations. Any such entity is identified by a name, and any member of it represents the 
whole set with respect to a lightpen pick. A picture structure should, on the other hand, conformwith 
the structure of the language in which the picture-generatingprograms are writ­ ten. Two common features 
of high-level langua­ ges can be exploited for the purpose of picture structuring,namely (i) the occurrence 
of arrays as a primitive data type and (ii) the possibilitiesof nesting program blocks (albeit not 
in all languages) and external procedures (subroutines)in connectionwith the control of the scope of 
variables. Similar to the sub­ routine techniques, we furthermore want pictures to be able to invoke 
subpictures. As a result of these considerations we intro­ duce a general picture structure in the form 
of a three-level hierarchy as follows: A picture is a collection of subpictures and/or items, generated 
by a program block. An item is a collection of primitives of the same type, generated by a library 
function. A primitive is anything for which we have a hardware generator in the display processor (dots, 
lines, circles, surface patches, etc.). We now have the choice of declaring a picture as well as a 
subpicture or an item as an entity. Unlike regular programs which produce results in the form of a 
data set obtained by applying a sequence of transformations on an initial set of data, a program for 
picture generation produces a sequence of instructionswhose execution by a special hardware processor 
results in the genera­ tion of a number of graphic primitives in a cer­ tain appearanceon the CRT screen. 
Hence, the execution of a display program consists mainly in the process of translating a high-level 
language program segment into an object language which is interpreted by the special display processor. 
Therefore,we call the object language display processor code and the object program the display processor 
code list (DPCL). The object program is strictly sequential except for subpicture jumps. In order to 
preserve the above introduced picture structure, we may embed the DPCL into a data structure in which 
each picture is represented by a three-level tree. This is accomplishedby adding a name list, con­ taining 
the names of pictures, subpictures, and items and a correlation table, containing pointers which bound 
the part of DPCL representing a cer­ tain picture, subpicture, or item. The totality of the name list, 
correlation table, and the display processor code list is called the display file. Thus in the process 
of translating a dis­play program,we need also routines for updating thename list and the correlation 
table. Of course, this requires that the programmer desig­ nates the entities of his structured pictures 
to the translator, that is, he must structure his program properly. The display file management is usually 
performed by the section of the display system which we call the 'display processor' (other names for 
it are 'display controller' or 'programmablememory'), whereas the data base and the application program 
 reside in a larger computer which we call the 'host computer'. The host may be dedicated to the graphics 
system, or it may be a time-sharing system in which the display console is one of many terminals. In 
any case, it is an important design objective to limit the computing power re­ quired for the display 
file management by keeping the data structure of the display file as simple as possible. Therefore, 
we impose the additional constraint that items shall be partitions of the set of primitives of a picture. 
Hence, the re­ sulting data structure is that of a tree. By this constraintwe deal with trees as the 
basic display file structure instead of graphs (which are more difficult to handle). Primitivesmay 
be categorized as being either graphic primitives or symbols. In the former case the data type is that 
of real or integer numbers representing coordinates, and in the latter case the data type is that of 
character codes. To define primitives through their data structure, we have the coordinate point for 
 graphic primitives and the character string for symbols. In general, a point is an n-tuple (n depending 
on the dimensionality of the picture domain and on whether ordinary or homogeneous coordinates are 
used) of real or integer numbers (depending on how the picture domain is defined). A dot is the pictorial 
representationof a point. A vector connects two points. For the sake of consistency and economy, it is 
customary that a vector be specified only by one point, its end point, whereas its start point is given 
by the current beam position (whichmay be the end point of the previously drawn vector). Vectors concate­nated 
in such a way form a polygon, and by pro­viding the possibility of inserting blank (invisi­ble) vectors, 
any line-drawing can be defined as a polygon. Therefore, a control vector of data type boolean is added, 
specifyingwhether a cor­responding line is visible or not. In a declara­ tion-free language like APL 
we can combine the point coordinates and the control vector into one array. In other languages, however, 
this implies that we restrict ourselves to the use of integer coordinate values. Pictures, subpictures, 
and items are entities which shall be identifiedby names. Subpictures shall be defined as entities which 
are not further di­visible. Contrastingly, in the case of items, it is desirable to be able to identify 
individual primitives in the item. Items, as defined above, are ordered sets; the order being defined 
by the ordering of the components of the homogeneous array that is assigned as data to the item genera­ting 
statement.Hence for a set of primitives, P = Pl,.. Pn , there exists a bijective mapping  P  [1 : n 
]. Thus, primitives in an item may be identified by a triple (picture name, item name, ordinal number). 
 3. Picture Definition Mechanismand Picture Transformations The notion of a graphic entity suggests 
that a piece of programwritten for the generation of an entity can be divided into two parts, namely 
 (1) the entity initialization and (2) the entity specification. The entity initializationencompasses 
the speci­fication of appearance, status, origin, and entity name. This is partly accomplished through 
a status vector whose components (I,J,K,L) specify blink status, beam intensity (or colors, respec­tively), 
line style, and lightpen pick or over­write enable/disable. All specifications are such that the parameter 
value 0 is assigned to the "normal" status or appearance. Hence, 0 is the logical default value for any 
non-specified parameter. An entity specification consists in the assignment of data (points or character 
code) to an entity­generating program. The usefulness of the notion of separating entity initialization 
and specifica­tion becomes quite apparent when we examine subpic­tures. Subpictures are prespecified 
entities to which an initialization has to be added prior to the calling sequence (by name). Pictures 
may have a uniform status and appearance for all its items, or we may want to assign such parameters 
individually to different items (after all, the major reasoning for introducing a pic­ture structure 
is that it provides exactly such a possibility). Therefore, an efficient program­ ming system will give 
the programmer the choice either to specify the status and appearance of each item in a picture individually 
or to do it once for the entire picture. In the process of displaying a picture that is defined by the 
display program in connectionwith graphical data residing in a data base, certain picture transformationsmay 
be performed. In such a case, we have to distinguish between the picture original and its currently displayed 
 instant. It is very useful to distinguish be­ tween two classes of transformations, namely (1) Euclidean 
transformations and (2) domain trans­ formations. Euclidean transformationsare trans­ lation, scaling, 
and rotation. Domain transfor­mations perform a mapping from the domain of the original (whichmay, for 
example, be the Cartesian plane) to the domain of the instant (which is the CRT screen, usually measured 
in raster units). Such a mapping may be defined by a windowing function w: W - V , that is, a mapping 
of a "window" W (e.g.: W cR x R) onto a "viewport" V (e.g.:  [0:1023]x[0:1023]). The windowing of a 
picture requires a clipping, that is, the elimination of all parts lying outside the window boundaries. 
Therefore, a windowing may effect the display program as certain primitives may disappear while others 
may have to be clipped. Contrasting­ly, Euclidean transformations effect only the graphical data by multiplying 
the points of a picture by a transformation matrix. There are two possible ways of concatenatingall 
these transformations: (i) <Euclidean transformations in the orig­inal domain including scaling into 
screen coordinates>, <Execution of the picture­generating procedures>, <Clipping in the screen domain> 
 (ii) <Clipping in the original domain>, <Eu­clidean transformations including scaling into screen coordinates>, 
<Execution of the picture-generatingprocedures ("," denotes concatenation).   One of the benefits of 
the picture structure in­ troduced in section 1 is that the type of an item is not affected by a clipping 
but only its cardin­ ality (whichmay be decreased or increased). However, the cardinality of an item 
is only re­ flected in the dimensions of its data array and, therefore, the same procedures for Euclidean 
transformations can be applied before or after clipping, thus providing a choice as to the order of operations. 
Furthermore,a substantial sim­plificationis obtained by excluding the trans­lation required for picture 
positioning from the sequence of picture transformations and introducing it instead as part of a "picture 
initialization" procedure. 4. Language Structures Naturally,we have on the display processor level 
 a one-to-one correspondencebetween a primitive and a program statement, as the display processor code 
is a low-level language providing no possi­ bility (nor is there any necessity)for further structuring. 
Many suggested language extensions and some existing subroutinepackages maintain the same one-to-one 
correspondence between state­ ment and primitive in the high-level graphics programming system. Such 
an approach contra­ dicts somehow the idea of a high-level language, and it is certainly more logical 
and appropriate to reserve the statement level for items and the procedure level for pictures. In that 
case, primitives occur only implicitly as the objects of items. Procedure calls may be nested, as 
pictures may call subpictures, etc. The only exceptionwhere single primitives may have to be generated 
in a statement-by-statementfash­ ion occurs in the case of interactive program creation under control 
of the application program, if the display system is a stand-aloneunit in which all the computing power 
is concentratedin one dedicated computer. The statement-wise generation of primitives may here be required 
in order to provide immediate feedback to the user about the results of his actions. E.g.: The user's 
action may consist of indicating a point on the screen by the lightpen, and the immediate response 
by the systemmay consist of generating a vector that connects this new point with a previously indicated 
one. The adequate control device for such a procedure is a DO LOOP, and a special device has to be 
provided for grouping the thus generated primitives into items. Fur­ thermore, such primitive-generatinginstructions 
have to be combined with a routine for the input of point coordinates by placing a cursor on the screen 
with the aid of a lightpen, a joystick, a mouse, etc. Such a routine must be event­driven. The language 
structure ideally suited for struc­turing a display program according to the struc­turing of pictures 
is the ALGOL-type language, that is, a language which has internal procedures (blocks) as well as external 
procedures of the function or statement type. In contrast to such a highly structured language, APL and 
FORTRAN provide only structurally independent external procedures. However, APL offers more subtle means 
 of controlling the scope of variable names than FORTRAN (where names can only be local to one procedure 
or common to all of them). A common way of compensating for the missing block struc­ ture of a language 
is to introduce a pseudo block structure by appropriate procedure calls. Of course, such a measure does 
not provide additional means of variable scope control, and if we want in APL to pass parameters from 
one program block to another,we can only do this within the defined function mechanism. On this basis, 
we may have the following mechanism for entity specification. (A) Items. Items are the building blocks 
of picturesor subpictures. Therefore,we may design a set of item-generating library functions with 
reserved names. (B) Subpictures. Subpictures and pictures are not generated by library procedures but 
by a re­ spective, ad hoc written program segment which has to be declared as a picture-generatingentity. 
 Therefore, we have to provide a device for build­ ing such program blocks, consisting of a pair of 
delimiting library procedures. The actions taken by these procedures are to enter the entity name into 
the name list and a start pointer and end pointer into the correlation table. The reason why we must 
distinguish between pictures and sub­pictures is that the execution of a subpicture DPC is deferred until 
it is invoked by a picture. Moreover, subpictures are non-divisible entities. (C) Pictures. The proper 
form for picture defini­tion is that of a procedure which invokes library functions for item-generation 
or subpicture calls. In languages with a block structure, picture def­initions and/or subpicture definitions 
may be nested within picture definitions,and the common­ly available mechanism of declaring variables 
as global or local permits either the assignment of individual status parameters to each of these items, 
subpictures, or pictures, or to have them assume the status and appearance of the calling picture. In 
APL, where we have such a block struc­ture only in form of nested external procedures, we must consequently 
write picture definitions and subpicture definitions as 'defined functions' if we want to control the 
passing of parameters. We want to emphasize the distinctionbetween a subpicture call and a repeated 
call of a picture­generating procedure. A picture-generatingproce­dure call may be combined with various 
transforma­tions, changing from call to call. Hence, such a sequence of repeated calls generates a sequence 
of different instances of the picture. Contrastingly, a subpicture is an instant residing in the display 
 file which may be called during the execution of the display processor program. This implies that a 
subpicture cannot be subject to picture trans­formations other than those performed by hardware in the 
display processor. The following table sum­marizes the result of our discussion. 5. InteractionHandling 
Routines In the case that pictures are constructed inter­ actively, i.e., primitive-wise,we need a device 
 for grouping primitives into items. This can be accomplished analogously to the grouping of items 
into pictures. The devices for the graphical dialoguemay be primarily a lightpen, a position­ ing device 
such as joystick, control ball, or tablet, and a control keyboard. One of the most popular media for 
man-machine interaction is the display of light buttons by the programs and the "pick" of such light 
buttons by the user. Con­ sequently,we need a number of library procedures  for the output and input 
of information through these devices. Attentions, i.e., the activation of such a device by the user, 
are handled by a part of the program called the task scheduler. Johnson7 lists four principles for the 
implementation of a task sche­duler, namely: (1) PROGRAM FLOW MODIFICATION (synchronous), (2) TABULAR 
SPECIFICATION, (3) DYNAMIC PROCEDURE DECLARATION (asynchronous), and (4) STATE DIAGRAMAPPROACH. The 
last method is equivalent to the first one (differing only in its formal representationbut not in its 
proce­dural essence). The third method would certainly be the most efficient approach; alas, it is not 
existent in any of the languages considered here, and thus, its implementationmakes a language ex­tension 
mandatory. The second method is rather inappropriateand may give rise to programming pitfalls. This leaves 
the first method as the scheme that is mainly used. Its application is based on the use of the IF statement, 
or a sequence of IF statements in the case of multi-branching. Multi-branching is typical for light button 
 con­ trol, where different light button picks trans­fer control to different points in the program. 
Thus, the CASE OF clause would be a more effi­cient construct than is a sequence of skip-jump combinations 
(as in FORTRAN and APL) or IF-THEN- ELSE constructs (as in ALGOL and PL/I). Event-driven constructs (e.g., 
like the one pro­ posed by Knuth8), would even be more appropriate, for they allow to apply the third 
method listed above. We can find them in discrete event simu­lation languages(e.g., SIMULA) but in none 
of the languageswe are discussing here. PL/I, however, could be easily extended, as the syntactic form 
is already given by the ON statement. That is, only the scope of the ON CONDITION would have to be extended 
as to include external interrupts. The lack of event-driven constructs can be com­pensated for by writing 
interrupt-drivenassembly code procedures. Whenever such a procedure is invoked, it waits for the attention 
and returns on its occurrence the associated information. Related informationmay be the attention source 
plus data such as, for example, a booleanvariable signal­ling an event, a coordinatepair indicated by 
a pointing device, the identifier of a control key, a text string keyed in by the user. However, the 
input device to be used at a certain point in the execution of an interactive program is nor­mally predeterminedby 
the program and, thus, we find it the best approach to provide individual procedures for the various 
attention sources. An attentioncalled for by the program need not iden­ tify itself. 6. GRIP (Graphical 
Procedures for Instructional Purposes) The conclusions drawn from our discussion are re­ flected in 
a model language called GRIP. GRIP was originally designed as an instructional vehi­ cle for clarifying 
the mechanism of high-level display programming without having to deal with the idiosyncrasies of secondary 
importance which existing programming systems may exhibit. How­ ever, it turned out thatGRIP provided 
an excel­ lent blueprint for a graphical subroutine package or a language extension. The reader will 
notice that GRIP is very procedure oriented. Therefore, it can be easily transposed into a FORTRAN 
sub­ routine package, a PL/I procedure package, or an APL function package, etc. Parameter names are 
 (i) mnemonic and (ii) declares them as integers in FORTRAN or (by default) in PL/I.   Group 2 : Display 
file manipulationand object identification SHOW (<Picturename/Subpicturename>): Inserts the code for 
a picture or a subpic­ture into the display file Note: The scope of ISV extends over all items or subpictures 
of a picture unless their sta­tus is individually specified. END Closes picture generation block; not 
necessary if the following statement is again PICTURE.  1.2 Item Level Common Parameters: <Itemname> 
identifies the created item MXR, MYR : Origin of the following item specificationin co­ordinates relative 
to MXA, MYA (absolute for MXA=0, MYA=0) ISV : Item status vector (see above) If ISV is not specified, 
the system as­signs the default value  0,0,0,0. POLYGON (<Itemname> , MXR, MYR, ISV, IDAT, N) Parameters: 
N : Number of primitives in the item IDAT : Array of coordinates, rela­tive to (MXA,MYA) and control 
para­meters; dimension (IDAT) = 3,N  Note: Control parameters for polygon segments: O=off, l-on DOTSET 
(<Itemname> ,MXR, MYR, ISV, IDAT, N) Parameters: same as in POLYGON,but no control parameters in IDAT; 
dimension(IDAT) -2,N TEXT (<Itemname>, MXR ,MYR , ISV ,MESS-AGE ,N , M ) Parameters: N : Number of characters 
in the string MESSAGE: Character string of the text ISV : Item status vector M : Character write mode 
 1.3 Subpicture Level LINK SUBPICTURE (<Subpicturename>, MXR, MYR, ISV) Parameter: Subpicturename identifies 
a subpic­ ture to be linked to the preceeding picture specification MXR, MYR : Origin attached to the 
 called subpicture  SUBPICTURE (<Subpicturename>): Begins subpic­ture created by the item generating 
statements following the BEGIN SUB- PICTURE statement ISV = common subpicture status MXR: subpicture 
origin relative to MYR: beam positionwhen sub-link is  made END Closes subpicture definition block CLEAR 
:Erases the entire display file DELETE (<Picturename>,<Itemname>) : Deletes an item or a picture Parameters: 
If an item shall be erased, it has to be identified by its name and the name of the picture it belongsto. 
Omission of <Itemname>: The entire picture identifiedby <Picturename> will be erased.  DROP (<Picturename>,<Itemname>, 
IN) Parameters : IN : Indexnumber of the primitive in the identified picture and item to be removed 
from view ADDITEM (<Picturename>, <Itemname>,) Parameters: The identified item is added to the identified 
picture CATENATE (<Picturename>, <Itemname>, N, IDAT) Parameters : N : Number of primitives to be con­ 
catenated to the identified item in the identified picture IDAT : Data array for the addi­tional primitives 
 PICK (PNAME, PINAME, IN) Parameters : The output parameters PNAME, PINAME, and IN return the picture 
name, the item name, and the primitive ordinal of the picked object. The search through the picture tree 
is accord­ingly truncated ifPINAME and/or IN is not listed. NEWSTATUS (<Picturename>, <Itemname>, ISV) 
 Parameters : ISV is a new status vector, replacing the one currently assigned to the specified item 
in the specified picture. NEWORIGIN (<Picturename>, <Itemname>, IPX, IPY, IIX, IIY) Parameters : IPX, 
IPY : Increments that will be added to the current picture coor­dinates (MXA,MYA) in order to change 
 the picture origin; IPX=0 , IPY=0 : no change of the picture origin IIX, IIY : Increments that will 
be added to the current item coordin­ates (MXR,MYR) in order to change the item origin; IIX=O , IIY=0 
: no change of the item origin Group 3: Input commands POINTIN (IX,IY): Input of a coordinate point 
Parameters: IX, IY : Output parameters returning the absolute coordinates of a point on the screen marked 
by placing a cursor on it.  TYPEIN(MAX,MESSAGE) : Input of a text string Parameters : NMAX : Maximum 
number of characters that can be typed in MESSAGE: Output vector containing the character string typed 
in by the user  KEYIN(ILLUM, KEYCODE) : Activation of a control key Parameters : ILLUM : Vector of 
length dimension (ILLUM)=(numberof control keys) whose components are ei­ther 0 (key not illuminated) 
or 1 (illuminated) KEYCODE : Output parameter identifying the control key pressed by the user  Note: 
POINTIN, TYPEIN, KEYIN are interrupt driven routines. Group 4 : Interactive picture generating state­ments 
 ITEM (<Itemname>, MXR ,MYR, ISV)  Parameters: <Itemname> identifies the item created by the subsequentprimitive 
generating statements; all other parameters: see above END Closes an item-generating program block DOT 
(IX , IY ) LINE (IX, IY ) NOLINE ( IX, IY ) Parameters : IX , IY : Absolute screen coordinates specifying 
a dot or the end­point of a line (or noline, respectively)whose start­point is the current beam position 
 CIRCLE ( IDAD ) Parameters : IDAD : Array containing the coor­dinates of the points spe­cifying a circle 
 MENU ( NC , ID , MESSAGE ,LOC ) Parameters: NC : Number of characters in each light button (has to 
be the same for all light buttons of a menu) ID : Array of ordinal numbers identi­fying the light buttons 
 MESSAGE: Character string of the light buttons (padded up by blanks to equal length) LOC : Array defines 
location of the equally spaced light buttons by the 4 components, specifying the absolute coordinates 
of the first character in the first button (from left to right and from top down) and the x-and y-increment 
from button to but­ton. BUTTON : Function returning the identifier of a picked light button DRAW-DOTSET(<Itemname>,ISV 
,NMAX , NP , IDAT ) Parameters: <Itemname> identifies the item to be generated interactively by the 
user ISV : Item status vector (see above) NMAX : Maximum number of primitives in the item NP : Actual 
number of primitives in the item IDAT : Output array containing the point coordinates of the item (dimen­sion: 
2 x NP) DRAW-POLYGON(<Itemname>,ISV, NMAX, NP, IDAT, MXT, MYR) Parameters: For the first four see DRAW-DOTSET 
 IDAT: Output array (3xNP) con­taining the point coordin­ates and the control vector of the item MXR, 
MYR: Coordinates of the item origin SKETCH (<Itemname>, ISV, NMAX, NP, IDAT, MXR, MYR) Parameters: as 
in DRAW-POLYGON,but without con­trol parameters Comment: DRAW-DOTSET and DRAW-POLYGONbuild up items 
by using POINTIN. SKETCH is a freehand drawing routine strictly for lightpen use. The programmer speci­fies 
in NMAX how many sample points he wants to obtain in maximum. The procedure selects the spacing of the 
sample points adaptively such that NMAX/2< NP<NMAX. The routines in­clude in each case the generation 
of a light button menu by which the se­quence of steps to be taken in the man-machinedialog is controlled. 
 7. Language Evaluation  7.1 FORTRAN FORTRAN lacks structuring facilities and, there­fore, provides 
no support for a structured pro­gramming as introduced above. Standard FORTRAN offers no tools for bit 
manipulationand string handling, nor does it have any facilities for building data structures and handling 
files. A particular disadvantage is that fixed arrays have to be delcared. The control structure of FORTRAN 
is awkward. In the case of a graphics subroutine package, the required structuring of the program can 
be intro­duced as pseudo block structure by respective subroutine calls. The lack of scope control fa­cilities 
can be compensated for by a default me­chanism: If no status is specified for an item, it assumes the 
one specified for the picture it is part of. The FORTRAN concept is general enough to offer ultimately 
a solution for any problem,but at the costs of a poor program structuring. However, for a genuine extension, 
FORTRAN is certainly the least appropriate can­didate. 7.2 ALGOL 60 A positive feature of ALGOL 60 is 
the block struc­ture and the possibility of dynamic array decla­ration. On the negative side, we find 
the same deficiency as in FORRRAN, namely an overly re­strictive set of data types (no bit or character 
strings). The often semantically unnecessary need of elaborate declarations is sometimes both­ersome. 
This declarative overhead may be espe­cially annoying in the case of display programming,  if pictures 
are defined in the screen domain (i.e., all numbers are integer by nature). Real numbers and boolean 
variableswhich are logical­ly connected cannot be packed into one array. The control structure of ALGOL 
60 is inadequate. ALGOL 60 was designed strictly as an algorithmic language and is, therefore, rather 
inadequate for the programming of file management systems. 7.3 PL/I PL/I has almost all the desirable 
features: A block structure,all required data types and oper­ators for bit manipulation, string handling, 
and file handling (especially the data types STRUC- TURE and POINTER in connection with the BASED storage 
class is here extremely useful). The only operators missing are those for array opera­tions (as provided 
in APL); however, they can easily be substituted for by respective subrou­tines. PL/I is not declaration-free,but, 
com­ pared with ALGOL, its declarationmechanism is more efficient. A negative feature of the lan­guage 
is its arbitrary and voluminous ad hoc constructions, albeit this is mitigated by a built-in default 
mechanismwhich allows the use of the language even if not all of its facets are completely understood. 
From a practical point of view, PL/I is a strong competitor for the title of the "best" language for 
graphics programming. 7.4 APL Among the languages considered here, APL is the only genuinely conversationallanguage 
and, thus, it is predestined for interactive computer graph­ics carried out in time-sharing systems. 
In addition, a decisive asset is the existence of operators for all matrix operations applicable to 
picture transformations. APL is declaration­ free (except for the required distinctionbetween numerical 
(including boolean) values and charac­ters. An extremely useful property of APL for graphics purposes 
is the total freedom in using arrays dynamically. Since the name-value binding of variables is derived 
by the system from con­text, arrays can be arbitrarily redefined, re­structured or concatenated. This 
makes it very simple to perform domain transformations, to aug­ment items by adding more primitives, 
or to con­nect items. Objections voiced against APL are basically: (1) APL has only scalars and (rectangular) 
arrays as data structures but no lists; (2) its control structure lacks the iterative con­trol clauses 
of modern languages which help to reduce the use of GOTOs; (3) APL program are hardly intelligible for 
anybody but the one who wrote the program. APL shares the first deficiencywith mostother languages, albeit 
there is always the possibility of setting up a file management system in an APL workspace that provides 
the required data base management capabilities. The second argument is certainly a valid point. However, 
it has to be considered that in the case of "intelligent" ter­minals most of the iterative loops of a 
display program are handled locally. In this case, the "sequentialization"of the main program (which 
is the main purpose for abolishing GOTOs in fa­vor of clauses such as WHILE and REPEAT) is automatically 
obtained. Furthermore, it is possible to introduce for the sake of readabil­ity pseudo constructs of 
the desired types by introducing the desired keywords in the form of functions and labels. Certainly, 
the extreme liberalism of APL requires from its user more self-disciplinethan other languages, but when­ever 
such discipline is exercised, APL programs can be as readable as other programs. 7.5 ALGOL 68 and ALGOL-likeLanguages 
ALGOL 68 has the richness of PL/I, but is more systematicallyconstructed, using as few basic notions 
as possible and avoiding special cases (of which PL/I is abundant) wherever possible. Similar to PL/I, 
ALGOL 68 has homogeneous arrays and structureswith named elements as aggregate data types as well as 
an equivalent of the PL/I pointer. However, ALGOL 68 has scarcely been implementedyet, that is, it is 
hardly a usable language yet. The difficulties of implementing the language seem to be great. The difficulties 
for the casual user of becoming familiar with the language are equally great. This has to be attributed 
to the fact that ALGOL 68 exhibits what Knuth8 calls "fundamental errors of human engineering". If PL/I 
can be called a "baroque" language,9 this holds equally so for ALGOL 68, the more as the casual use of 
the language is not alleviated by an elaborate default mechanism as in PL/I. One particular asset of 
ALGOL 68 is its extensibility, permitting the user to define new operators. However, for the purpose 
of computer graphics, the same can be accom­plished by simpler means like, for example, the defined function 
mechanism of APL. For all these reasons, we rule out for the time being ALGOL 68 as a real possibiltiy 
for being the host for a graphics programming system. An example for a simpler ALGOL-likelanguage is 
PASCAL. PASCAL combines a concept of outstand­ing clarity and simplicity with a modern control structure 
and is, therefore, of high pedagogical value. It has the block structure of ALGOL 60, but exhibits in 
comparison with the latter a number of improvements. Examples are: A better control structure; a more 
elegant and efficient declarationmechanism; the existence of input/ output operators; the existence of 
character strings as a data type and of certain string handling capabilities; the existence of linear 
lists as a data type. Of course, the two aggre­gate data structures available in PASCAL, namely the (sequential) 
file (the PASCAL name for linear lists) of components of the same type and the array, would not be sufficient 
for real-world computer graphics applications. However, for instructional purposes, we can strongly endorse 
a PASCAL-based GRIP implementation. 8. Implementationsof the GRIP Philosophy at the Universityof Minnesota 
 8.1 GRAP (GRaphicsApplication Package) GRAP is a realization of GRIP in the form of a FORTRAN subroutinepackage, 
i.e., the GRIP com­ mands occur in GRAP in the form of subroutine or function 0 Moreover, GRAP encompasses 
sub­routines for windowing, two-dimensionaland three­dimensional picture transformations, hidden-line 
elimination, and Berzier-Spline approximationof surfaces. The logical constructionand conven­ience of 
the underlying GRIP concept make this graphical language easy to learn and to apply. Thus it has become 
quite popular among students and staff members. 8.2 APLG (APL extended for Graphics)ll The main restrictionwhich 
APL imposes on the transpositionof the GRIP concept into an APL en­vironment is given by the syntax of 
the APL "de­fined functions" (theseare external procedures which can be of the function type as well 
as of the statement type). Defined functions have at most two arguments and one result. However, an item 
definition requires the specificationof three parameters, NAME, STATUS, and DATA. There­fore, we use 
two dyadic functions for the creation of an item. The first function (named STATUS) specifies the status 
of an entity. Consequently, its two arguments are the entity name and a sta­ tus vector. The second 
function specifies the item, and therefore, its two arguments are the name and an array of data. The 
STATUS function may repeatedly be invokedwhenever the status of this item is re-specified. The call 
of the STATUS function can be elided if the item is to assume the status of the picture to which it 
belongs. Features by which APL excels most other languages are that a data array may include a boolean 
control vector and that character strings for the display of text lines or light buttons can be put in 
directly as such. Moreover,we can use natural language names for pictures, subpictures, and items. All 
other features correspond with the ones outlinedby the GRIP concept. The lack of additional input/output 
operators (besides of the APL "quad" or "quote-quad" operators), as required for input or output carried 
out via the display terminal, can be substituted for by two special APL functionswhose sole task is 
to mark such display messages as different from regular teletype messages. Hence, APLG can be strictly 
 implemented as a package of library functions (whosenames are reserved by underlining the first character), 
and no language extension is neces­sary. REFERENCES 1. Meads, J., A terminal control system, Proc. 
of the IFIP Working Conf. on Graphic Lan­guages, North Holland Publ. Co. (1972), 271-290.  2. Scoop, 
K., The design and use of a PL/I based  graphic programming language, ONLINE 72, vol. 2, 601-615. 
 3. Hurwitz, A., Citron, J.P., and Yeaton, J.B., GRAF: Graphic Addition to FORTRAN, Proc. AFIPS SJCC 
1967, 553-557.  4. Kay, A.C., FLEX -A Flexible Extendable Lan­  guage, Computer Science Technical Re­port 
4-7, Univ. of Utah (June, 1968).  5. Giloi, W.K., Encarnacao, J. and Kestner, W., APLG -APL extended 
for Graphics, ONLINE 72, vol. 2, 579-599.  6. Shaw, A.C., A formal picture description scheme as a basis 
for picture pro­cessing systems, Inf. &#38; Control 14, 1(1969), 938-947.  7. Johnson, C.I., Principles 
of interactive systems, IBM Systems Journal, 7, 314 (1968), 147-174.  8. Knuth, D.E., Structured programming 
with GOTO statments, Stanford Univ. Tech. Report STAN-CS-74-416 (May,1974).  9. Dijkstra E., The humble 
programmer, CACM 15, 10(1972), 859-866.  10. Messer, D., GRAP 3.0, Preliminary User's Manual; Dept. 
of Computer, Information and Control Science, University of Minnesota (1975).  11. Giloi, W.K., Encarnacao, 
J., APLG-An APL based system for interactive computer graphics,Proc.AFIPS 1974 NCC, 521­  528.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563742</article_id>
		<sort_key>70</sort_key>
		<display_label></display_label>
		<article_publication_date>04-01-1975</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[ESP<sup>3</sup>]]></title>
		<subtitle><![CDATA[a high-level graphics language]]></subtitle>
		<page_from>70</page_from>
		<page_to>77</page_to>
		<doi_number>10.1145/563732.563742</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563742</url>
		<abstract>
			<par><![CDATA[Most graphics languages are composed of a primitive set of commands which allow for the creation and manipulation of graphical objects. These commands are generally at a low level, in that each command causes one operation to be performed. Often the commands are to subroutines embedded in an algorithmic language so that the arithmetic and control features of the higher level language may be used.ESP<sup>3</sup> (Extended SNOBOL Picture Pattern Processor) is a new high-level graphics and pattern recognition language. ESP<sup>3</sup> was designed in an effort to provide simple, natural, and efficient manipulation of line drawings. ESP<sup>3</sup> differs from present graphics languages in the following ways:1) It provides a high-level method for picture construction. The evaluation of a picture expression (analagous to the SNOBOL4 string-valued expression) causes the construction of a picture.2) It provides extensive referencing facilities for naming and accessing points, subpictures, and attributes of pictures.3) It provides predicates for testing attributes of and relationships among pictures and points.4) It provides a means for defining picture patterns that describe classes of line drawings in much the same way that SNOBOL4 patterns describe classes of strings. Picture pattern matching is a built-in facility.ESP<sup>3</sup> is based on the premise that structural descriptions are an essential part of both picture construction and pattern recognition. The concept of a structural description of a picture has its origin with the linguistic-approach to pattern recognition. In the linguistic approach, formal grammars are used as a mechanism for picture description. [Kirsch (1964), Narasimhan (1964, 1966,1970), Anderson (1968), Evans (1968), Miller and Shaw (1969), Fu and Swain (1971), Shaw (1970, 1972), Chien and Ribak (1972), Thomason and Gonzalez (1975)]. Stanton (1970) described a graphics language based on linguistic pattern recognition. ESP<sup>3</sup> incorporates and extends many ideas from the above work, and includes all of the features of SNOBOL4 to provide a high-level graphics and pattern recognition language. Some suggested applications of ESP<sup>3</sup> are the generation of graphical output, AI programs with imaging capabilities, pattern recognition systems, and scene analysis programs.This paper will describe picture construction and pattern recognition in ESP with emphasis on picture construction. Some tests performed with an experimental version of ESP<sup>3</sup> will also be discussed. For a more detailed description of ESP<sup>3</sup>, see Shapiro (1974).]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP48024580</person_id>
				<author_profile_id><![CDATA[81100431840]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Linda]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Shapiro]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Kansas State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Anderson, R. H., "Syntax-Directed Recognition of Hand-printed Two-Dimensional Mathematics", in Interactive Systems for Experimental Applied Mathematics, M. Klerer and J. Reinfelds (Eds.), Academic Press, New York, 1968, 436-459.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Chien, Y. T. and Ribak, R., "A New Data Base for Syntax-Directed Pattern Analysis and Recognition", IEEE Transactions on Computers, C-21, 1972, 790-801.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Dewar, R. B. K., SPITBOL Version 2.0, Illinois Institute of Technology, 1971.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Evans, T. G., "A Grammar-Controlled Pattern Analyzer", Proceedings of the IFIP Congress 68, A. J. H. Morell (Ed.), North Holland Publishing Co., Amsterdam, 1969.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Fu, K. S. and Swain, P. H., "On Syntactic Pattern Recognition", in Software Engineering 2, J. T. Tou (Ed.), Academic Press, New York, 1971, 155-182.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kirsch, R. A., "Computer Interpretation of English Text and Picture Patterns", IEEE Transactions on Electronic Computers, EC-13, 1964, 363-376.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Miller, W. F. and Shaw, A. C., "Linguistic Methods in Picture Processing - A Survey", Proceedings AFIPS Fall Joint Computer Conference, 33, Thompson Book Co., Washington D.C., 1969, 279-290.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Narasimhan, R., "Labelling Schemata and Syntactic Description of Pictures", Information and Control, 7, 1964, 151-179.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>365258</ref_obj_id>
				<ref_obj_pid>365230</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Narasimhan, R., "Syntax-Directed Interpretation of Classes of Pictures", CACM, 9, 3, 1966, 166-173.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Narasimhan, R., "Picture Languages", in Picture Language Machines, S. Kaneff (Ed.), Academic Press, New York, 1970, 1-30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Shapiro, L. G., ESP3 : A Language for the Generation, Recognition, and Manipulation of Line Drawings, Technical Report 74-04, Department of Computer Science, University of Iowa, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>321598</ref_obj_id>
				<ref_obj_pid>321592</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Shaw, A. C., "Parsing of Graph-Representable Pictures", JACM, 17, 3, 1970, 453-481.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Shaw, A. C., "Picture Graphs, Grammars, and Parsing", in Frontiers of Pattern Recognition, S. Watanabe (Ed.), Academic Press, New York, 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Stanton, R. B., The Recovery of Descriptions in Graphical Communications, Doctoral Dissertation, Department of Electronic Computation, The University of New South Wales, Sydney, N.S.W., Australia, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Thomason, M. G. and Gonzales, R. C., "Syntactic Recognition of Imperfectly Specified Patterns", IEEE Transactions on Computers, C-24, 1975, 93-95.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.Siggraph 
75 Bowling Green ESP3: A High-Level Graphics Language Linda G. Shapiro Kansas State University INTRODUCTION 
 Most graphics languages are composed of a primitive set of commands which allow for the creation and 
manipulationof graphical objects. These commands are generally at a low level, in that each command causes 
one operation to be performed. Often the commands are to subroutines embedded in an algorithmic language 
so that the arithmetic and control features of the higher level language may be used. ESP3 (Extended 
SNOBOL Picture Pattern Pro­cessor) is a new high-level graphics and pattern recognition language. ESP3 
was designed in an effort to provide simple, natural, and efficient manipulation of line drawings. ESP 
3 differs from present graphics languages in the following ways: 1) It provides a high-level method 
for pic­ ture construction. The evaluation of a picture expression (analagous to the SNOBOL4 string-valuedexpression) 
causes the construction of a picture. 2) It provides extensive referencing faci­ lities for naming and 
accessing points, subpictures, and attributes of pictures. 3) It provides predicates for testing attributes 
of and relationshipsamong pictures and points. 4) It provides a means for defining picture patterns that 
describe classes of line drawings in much the same way that SNOBOL4 patterns describe classes of strings. 
Picture pattern matching is a built-in facility. ESP3 is based on the premise that structural descriptions 
are an essential part of both picture constructionand pattern recognition. The concept of a structural 
description of a picture has its origin with the linguistic-approachto pattern recognition. In the linguistic 
approach, formal grammars are used as a mechanism for picture description. [Kirsch (1964), Narasimhan 
(1964, 1966,1970), Anderson (1968), Evans (1968), Miller and Shaw (1969), Fu and Swain (1971), Shaw 
(1970, 1972), Chien and Ribak (1972), Thomason and Gon­zalez (1975)]. Stanton (1970) described a graph­ics 
language based on linguistic pattern recogni­ tion. ESP3incorporates and extends many ideas from the 
above work, and includes all of the features of SNOBOL4 to provide a high-level graph­ ics and pattern 
recognition language. Some sug­ gested applicationsof ESP3 are the generation of graphical output, AI 
programs with imaging capa­ bilities, pattern recognition systems, and scene analysis programs. This 
paper will describe picture construction and pattern recognition in ESP with emphasis on picture construction. 
Some tests performed with an experimental version of 3 will also be dis­cussed. For a more detailed description 
of ESP3, see Shapiro (1974). 3 PICTURE CONSTRUCTION IN ESP All of the SNOBOL4 datatypes are present 
in ESP3. Two new datatypes are the POINT and the PICTURE. The POINT is an ordered pair (<x-coordi­nate>, 
<y-coordinate>) where <x-coordinate> and <y-coordinate> must be REAL or convertible to REAL. If P is 
a POINT, the functions XVAL(P) and YVAL(P) return the x-and y-coordinates of P. The PICTURE is a datatype 
which represents a two-dimensional line drawing. Throughout this paper, "point" and "picture" will refer 
to the datatypes POINT and PICTURE. The Picture Primitives -Their Pattern Points, Pattern Reals, and 
Pattern Parameters Pictures are constructed in ESP3 through the hierarchic composition of a fixed set 
of picture primitives. The ESP3 picture primitives include LINE, FIGURE, CURVE, FUNCTION, ARC, CIRCLE, 
REC- TANGLE, SQUARE, and TRIANGLE. Each picture primi­tive names an abstract form. An instance of a picture 
primitive is a picture specified by the name of the primitive plus size, shape, and place­ment information. 
 The DRAW function is used to construct an instance of a primitive. The function call DRAW(<primitive 
name expression>,<information specification list>) returns an instance of an ESP3 primitive. The <primitive 
name expression>is a SNOBOL4 string expressionwhich evaluates to the name of an ESP3 primitive, and the 
<information specification list>  is a string expressionwhich, when evaluated, supplies size, shape, 
and placement information, For example, the function call ' DRAW( ) returns an instance of a LINE with 
start point at the point (1,2) and end point at the point (1.5,3). In general, the informationspecification 
list contains a sequence of clauses of one of three forms: <pattern point> <value> <pattern real> <value> 
 <pattern parameter> <value>. Pattern points, pattern reals, and pattern para­meters are logical entities 
associated with the individual primitives. The logical entities correspond to physical points, real-valued 
attri­butes, and parameters of particular instances of the primitives. For example, START is a pattern 
point of the LINE, RADIUS is a pattern real of the CIRCLE, and POINTS is a pattern parameter of the CURVE 
whose value is a string specifying the physical points through which the CURVE must pass. Figure 1 shows 
each primitive and its pattern points, pattern reals, and pattern parameters. The following are examples 
of the construction of instances of primitives using the DRAW function.   The first call to DRAW returns 
a line segment with start point at the point (2,2), of length 1, and oriented at an angle of 45 degrees 
from the hori­zontal. The second and third calls return the FIGURE (sharp corners) and CURVE (smooth 
curve) passing through the specified points. See Figure 2. The fourth call produces a clockwise arc 
of radius 2.3 from 180 degrees to 45 degrees, starting  at the point (1,1), and the fifth returns a 
starting at the leftmost point of C2, having length 2  picture of the graph of the function y=x , -l<x<l. 
1, and pointing to the left. Add it to SNOWMAN.  Referencing Pattern Points, Pattern Reals, and Pattern 
Parameters of Primitives It is often useful to construct instances of primitives whose size or position 
is related to some point or attribute of an existant picture. In order to retrieve the values or physical 
points corresponding to the pattern points, pattern reals, 3 and pattern parameters of a picture, ESPprovides 
the referencing functions POINT and VALU. Function calls of the form  return the physical point (value) 
of the picture represented by <picture expression> that coincides with the pattern point (patternreal 
or pattern parameter) specified by <string expression>. For example, if L is the line created by the 
statement  assign the point (1.5,1) to MIDPT and the value 1 to LEN, respectively. A Simple Picture 
Expression The example below shows the use of the above functions and introduces the binary operators 
"i" and ":". If A and B are pictures, the expression "A  B" denotes the picture consisting of both 
A and B. The dynamic assignment operator ":" pre­ceding a call to DRAW specifies that the identifier 
to the left of ":" is to be assigned the picture returned by DRAW. The following is an ESP3 picture expression. 
  The expression can be translated as follows. Con­struct a CIRCLE with bottom at the point (5,0) and 
radius 1.5 and assign it to C1. Add it to SNOWMAN. Construct a CIRCLE with bottom at the top point of 
C1 and having radius 1. Assign it to C2 and add it to SNOWMAN. Construct a CIRCLE with bottom at the 
top of C2 and having radius .5. Add it to SNOWMAN. Construct a LINE starting at the right­most point 
of C2, having length 1, and pointing to the right. Add it to SNOWMAN. Construct a LINE Transformations 
 ESP3 allows any picture to be transformed by the operations of translation, rotation, scaling, and reflection. 
The transformationsare effected by the four built-in functions TRANSPIC, TURNPIC, SCALEPIC, and REFLECTPIC, 
which may appear as com­ponents in any picture expression. Calls to the four functions have the form 
 Each call returns a picture which is the trans­ lation, rotation, enlargement (reduction) or re­ flection 
of the picture resulting from the evalua­tion of <picture expression>. The transformation is specified 
by the information in <translation expression> or one of the specification lists. A translation expression 
is of the form "<point expression>=><point expression>. The translation operator "=>" specifies that 
the point of the untransformed picture resulting from the evaluation of the left <point expression> should 
be moved, in the transformed picture, to the point resulting from the evaluation of the right <point 
expression>. The specificationlists are of the same form as the information specification list of the 
DRAW func­ tion. As an example, let T be the picture resulting from execution of the statement  T 
consists of an equilateral triangle with lower left corner at the point (0,0) and base length 1. Execution 
of the statements  assign to T1 a picture consisting of a translated instance of the triangle T with 
top corner at the point (1.5,1), to T2 a 180 degree rotation of T about its top corner, to T3 a picture 
consisting of an instance of T scaled to half size about its center, and to T4 an instance of T reflected 
about the line y=1. See Figure 3.    Referencing Points, Values, and Sub-Pictures of Pictures ESP3 
contains two referencing systems: a system-defined reference facility and a user­defined reference facility. 
The referencing of pattern points, pattern reals, pattern parameters, and sub-primitives described earlier 
is a part of the system-defined facility. Also included in the system-defined facility is a set of pattern 
points called spacial pattern points which are associated with every 3 picture. The spacial pattern points 
of a picture are its LTOP, RTOP, TOP, LBOT, RBOT, BOT, TLEFT, BLEFT, LEFT, TRIGHT, BRIGHT, and RIGHT. 
The LTOP of a picture is th leftmost of its highest points, and the RTOP is the rightmost of its highest 
points. The TOP is the point midway between the LTOP and the RTOP. In a picture which has one point of 
maximum height, the LTOP, RTOP, and TOP are all the same point. The other spacial pattern points are 
defined analogously. The spacial pattern points of a picture are helpful in determining the size of the 
picture and creating translations of the picture that fit within a predeterminedrectangle (for instance, 
a plotter frame). The user-defined referencing facility adds flexibility to the system by allowing the 
user to associate ordered pairs, each consisting of a reference name and a value, with each ESP3 picture. 
If the value is a point, numeric value, or component of the picture, then the reference name may be used 
to refer to the corresponding point, numeric value, or component of any trans­formed instance of the 
picture. A reference definition is an expression of the form <reference name> t <picture identifier> 
 where both <reference name> and <picture identi­fier> are identifiers. A statement of the form <reference 
definition> = <value> associates the specified reference name and value pair with the picture. For example, 
the statements   In the simplest form, "REFNAME1 # PIC", REFNAMEl must be either a reference name 
of PIC or of a picture PIC2 where PIC is a transformed instance of PIC2. During evaluation of the expression 
 "REFNAME1# PIC" all the transformationswhich produced PIC from PIC2 are applied to the value of REFNAME1 
if the datatype of that value allows their application.  As a simple example, if D is the picture created 
by the definition of A above and the statements  causes plotted output of the picture obtained by evaluating 
the expression. The statement  causes a digitized version of the picture to be printed on a line printer. 
Although interactive graphic capabilitiesare currently not a part of ESP , there is nothing inherent 
in the language that would prevent their addition. PICTURE PATTERNS A picture pattern describes a 
set of pictures in much the same way that a SNOBOL4 pattern describes a set of strings. Picture patterns 
and 3 pattern matching are included in the ESP language to allow the user to describe a possibly infinite 
class of pictures and to locate a member of that class within a given line drawing. Picture pat­terns 
are composed of  1) the picture primitives LINE, CURVE, ARC, CIRCLE, SQUARE, TRIANGLE, and RECTANGLE, 
2) pictures, 3) predicates (both built-in and user­defined) which test attributes and rela­tionships, 
4) other picture patterns, 5) picture valued functions (both built-in and user-defined), 6) pattern valued 
functions, and 7) "such-that-fields"which provide infor­mation to guide the search program during pattern 
matching. Patterns composed of 1) through 6) are very similar in form to SNOBOL4 patterns. For example, 
 the pattern  then the expressions "CROSSBAR # D", "HEIGHT # D", "FOOT # D", and "NAME-# D" are valid 
reference expressionswhose values are a horizontal line from the point (4.65,2.35) to the point (5.35,2.35), 
the number .707, the point (5,2.707), and the string 'A' respectively. See Figure 5. Multiple references 
are useful.in pictures which contain many levels of transformations of the same sub­picture. Output 
of Pictures Pictures constructed through the evaluation of picture expressions are data structuresmaintained 
 3  by ESP. In.order for a picture to be viewed, it must be plotted, digitalized,or displayed on a graphics 
terminal. The statement describes a class of perfect letter "T"s, each consisting of a horizontal line 
and a vertical line which begins at the midpoint of the horizontal line. During the execution of a pattern 
matching  statement, the ESP3 system tries to find occurrences of subpictures within a subject picture 
which match (are described by) a given picture pattern. The pattern matching program of a control program 
and a search program, the picture scanner. The control program evaluates the pattern components, performs 
value assignments and backup when necessary, and calls on the scanner to find a match for the primitive 
pattern com­ ponents. The scanner searches a spacial repre­ sentation of the subject picture in a left 
to right, top to bottom search for subpictures which match the given primitive component. In the context 
of the pattern matching state­ment "PIC T", the pattern T (defined above) can be interprettedas the following 
commands to the scanner. 1) Find a (so far untried) straight line segment in PIC and assign it to the 
identifier L1. If none can be found, then FAIL. 2) Test that the angle of line L1 is equal to 0 degrees 
(the line ishorizontal). If not, go to 1). 3) Find a second straight line segment and assign it to the 
identifierL2. If none can be found, go to 1). 4) Test that the start point of line L2 coincides with 
the midpoint of L1. If not, go to 3). 5) Test that the angle of line L2 is equal to 270 degrees (the 
line is vertical). If not, go to 3). If so, SUCCEED. The remainder of this paper will describe picture 
patterns in more detail. Picture Pattern Primitives -What They Match Each primitive matches a class 
of pictures. The particular subpicture matched by a primitive depends on the context of the pattern match 
(the subject picture, the components preceding the primitive component in the pattern, and the such-that-field 
of the primitive component). Intuitively, each primitive matches any subpicture described by its name. 
For example, the CIRCLE primitive matches any circle or collection of overlapping arcs which form a circle. 
A complete description of the pictures matched by picture primitives is given in Shapiro (1974). The 
Built-in Predicates The built-in predicates of ESP3allow the user to test many basic attributes of and 
relations among pictures and points. Each predicate either succeeds and returns NULL or causes failure. 
Some of the most often used predicates are defined below. In these definitions, the phrase "a line of 
PIC" will refer to any straight or curved line of the picture PIC. AT(PT1,PT2) succeeds iff the point 
PT1 coin­cides with the point PT2. ON(PT,PIC) succeeds iff the point PT lies on a line of the picture 
PIC. ABOVE (P1,P2) succeeds iff the point or picture P1 lies entirely above the point or picture P2. 
(BELOW, LEFTOV, and RIGHTOV are defined analogously.) INSIDE(P1,PIC) succeeds iff the point or picture 
P1 lies entirely within or on some closed contour of the picture PIC. (OUTSIDE is described analogously.) 
 INTERSECTS(PIC1,PIC2) succeeds iff there exists at least one point which lies on a line of PIC1 and 
also on a line of PIC2. INTHERANGE(R,R1,R2) succeeds iff the real values R, R1, and R2 satisfy R1<R<R2. 
 All built-in predicates of SNOBOL4 are also built­in predicates of ESP3. The Such-that-field While 
the predicate components of a pattern keep the control program from proceeding further if it has matched 
a picture which fails to satisfy the constraints, predicates do not guide the scanner in its search. 
The such-that-field was designed specifically to guide the scanner and has a dual purpose: 1) to limit 
the region in the picture which is being searched for the pattern component, and 2) to specify attributes 
of the picture being sought which will further decrease the scanner's choice of pictures to return. 
A such-that-fieldprovides information that guides the scanner in finding a match for the pattern component 
immediately to the left of the such-that-field. The such-that-field consists of a such-that-expression 
delimitted by slashes. A such-that-expressionis a list of such-that-clauses each of which defines one 
constraint on the picture which is to match the pattern component. Each such-that-clauseis of the form 
"SUBJECT VERB OBJECT". The VERB is one of a subset of the built­in predicates, possibly negated by the 
string "NOT", the SUBJECT is usually a pattern point, pattern real, or pattern parameter of the picture 
being sought, and the OBJECT is generally a picture, point, or numeric value. Using such-that-fields, 
the pattern for the letter "T"may be written as follows. T LINE /ANGLE EQ 0/ $ LI 4 LINE /START AT 
*POINT(L1,'MID'),ANGLE EQ270)/  $ L2 Now the instructions to the search program in the pattern matching 
statement "PIC T" would be 1) Find an (as yet untried) horizontal line segment in PIC and assign it 
to L1. If no such line can be found, then FAIL. 2) Find a vertical line segment which starts at the 
midpoint of L1 and assign it to L2. (Note that this severely restricts the area of search.) If the search 
fails, go to 1). Otherwise SUCCEED.  The OBJECT of a such-that-clause may be one of the system symbols 
@LINE, @CURVE, @ARC, @CIRCLE, @RECTANGLE, @SQUARE, @TRIANGLE, @PRIM, and @LONGEST. The first six symbols 
refer to any picture which matches a LINE, CURVE, ARC, CIRCLE, RECTANGLE, SQUARE, or TRIANGLE, respectively. 
The symbol @PRIM refers to any picture that matches any one of the picture pattern primitives. The symbol 
@LONGEST, specifies that the LINE or CURVE returned must have no extensions longer than itself. The following 
pattern illustratesthe use of the system symbols.  The function REVERSE is defined by DEFINE( REVERSE(ANG)') 
REVERSE REVERSE REVERSE = INTHERANGE(ANG,0,180) = ANG -180 ANG * 180 :S(RETURN) :(RETURN) Here the line 
segment which matches the first LINE component must have both START and END points on some other line 
segments. Thus the scanner will not return an isolated line segment which could not possibly be part 
of a parallelogram. The other system symbols similarly restrict the search. 3 AN IMPLEMENTATIONOF 
ESP A restricted subset of ESP3 has been imple­mented on an IBM 360 model 65 computer as an embedding 
in SNOBOL4, using the SPITBOL compiler (see Dewar (1971)). The subject includes func­tions for picture 
construction, pattern con­struction, and pattern matching. Pictures built from the primitives LINE, CURVE, 
ARC, FIGURE, and CIRCLE, and the functions TRANSPIC, TURNPIC, and SCALEPIC may be constructed and plotted. 
Patterns built from the primitives LINE, CURVE, CIRCLE, and FAIL may be constructed. Patterns may include 
such-that-fieldsassociated with primitive com­ponents and immediate value assignment associated with 
any component. Pattern matching has been implemented for non-recursivepatterns. The scanner currently 
can search for LINEs, CIRCLEs, and CURVEs, and uses some of the information in the such-that-field to 
limit its search. The programwhich simulates ESP3 is called ESP3. A number of tests of the program have 
 3 shown that the ESPlanguage is both powerful and easy to use. The program of Figure 6 pro­duces a 
picture of the complete graph on K nodes. A sample output for K=8 is shown in Figure 7a. A slight modificationto 
the program produced the picture of Figure 7b. The SPITBOL execution times for these runs were 3.05 seconds 
and 3.166 seconds, respectively, using 200K bytes of core. The plotting routines were invoked in a separate 
FORTRAN job step.   ESP3 located and plotted the single snowman in the picture. Total SPITBOL execution 
time was 6.433 seconds using 400K bytes of core.   (where the function PRINTRI prints the string 
 'TRIANGLE' and the coordinates of the end points of the three lines), ESP3 located all 27 tri­angles 
with total SPITBOL execution time of 3 minutes, .305 seconds. In most cases, picture generation without 
curves was relatively fast, and pattern recognition relatively slow. Much of the execution time is due 
to the large number of cal­ culations performed during pattern recognition and curve generation using 
SNOBOL4 arithmetic, and the large number of data structures created during pattern matching. SUMMARY 
AND CONCLUSIONS ESP3is an initial attempt to satisfy the need for a high-level graphics language. Such 
features as the picture expressions,picture patterns, referencing facilities, built-in predicates, and 
pattern matching system enable the user to create and manipulate line drawings naturallyand efficiently. 
The experimental implementation has shown the feasibility of the above features while revealing the language 
to be both powerful and easy to use. The experi­ments have indicated the need for an ESP3 compiler and 
more efficient recognitionalgorithms. Some desirable additions to the language would be an interactive 
facility, a three-dimensional exten­ sion, a picture pattern to describe surfaces, shading, and texture, 
and an "inexact match mode" 3 in which imperfect pictures could match ESP patterns. The last project 
is currently being undertaken. REFERENCES Anderson,R.H., "Syntax-Directed Recognitionof Hand-printedTwo-DimensionalMathematics", 
 in Interactive Systems for Experimental Applied Mathematics,M. Klerer and J. Reinfelds (Eds.), Academic 
Press, New York, 1968, 436-459.  Chien, Y.T. and Ribak, R., "A New Data Base for Syntax-DirectedPattern 
Analysis and Recog­ nition", IEEE Transactions on Computers, C-21, 1972, 790-801.  Dewar, R.B.K., SPITBOL 
Version 2.0, Illinois Insti­tute of Technology, 1971. Evans, T.G., "A Grammar-ControlledPattern Analyzer", 
Proceedings of the IFIP Congress 68, A.J.H. Morell (Ed.), North Holland Publishing Co., Amsterdam, 1969. 
 Fu, K.S. and Swain, P.H., "On Syntactic Pattern Recognition", in Software Engineering 2, J.T. Tou (Ed.), 
Academic Press, New York, 1971, 155-182.  Kirsch, R.A., "Computer Interpretation of English Text and 
Picture Patterns", IEEE Transactions on Electronic Computers, EC-13, 1964, 363-376. Miller, W.F. and 
Shaw, A.C., "Linguistic Methods in Picture Processing -A Survey", Proceedings AFIPS Fall Joint Computer 
Conference, 33, Thompson Book Co., Washington D.C., 1969, 279­ 290.  Narasimhan, R., "Labelling Schemata 
and Syntactic Description of Pictures", Information and Control, 7, 1964, 151-179. Narasimhan, R., "Syntax-Directed 
Interpretation of Classes of Pictures", CACM, 9, 3, 1966, 166­ 173.  Narasimhan, R., "Picture Languages", 
in Picture Language Machines, S. Kaneff (Ed.), Academic Press, New York, 1970, 1-30. Shapiro, L.G., 
ESP3 : A Language for the Genera­ tion, Recognition,and Manipulationof Line Drawings, Technical Report 
74-04, Department of Computer Science, University of Iowa, 1974.  Shaw, A.C., "Parsing of Graph-RepresentablePic­tures", 
JACM, 17, 3, 1970, 453-481. Shaw, A.C., "Picture Graphs, Grammars, and Parsing", in Frontiers of Pattern 
Recognition, S. Watanabe (Ed.), Academic Press, New York, 1972.  Stanton, R.B., The Recovery of Descriptions 
in Graphical Communications,Doctoral Disserta­tion, Department of Electronic Computation, The University 
of New South Wales, Sydney, N.S.W., Australia, 1970.  Thomason, M.G. and Gonzales, R.C., "Syntactic 
Recognitionof Imperfectly Specified Patterns", IEEE Transactionson Computers, C-24, 1975, 93-95. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563743</article_id>
		<sort_key>78</sort_key>
		<display_label></display_label>
		<article_publication_date>04-01-1975</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Computer animation of free form images]]></title>
		<page_from>78</page_from>
		<page_to>80</page_to>
		<doi_number>10.1145/563732.563743</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563743</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P204438</person_id>
				<author_profile_id><![CDATA[81100067748]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[N.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Burtnyk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Research Council of Canada, Ottawa, Ontario]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39036435</person_id>
				<author_profile_id><![CDATA[81100294917]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wein]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Research Council of Canada, Ottawa, Ontario]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Burtnyk, N. and M. Wein, Computer Generated Key-Frame Animation, J. SMPTE, V. 80(3), March 1971, pp. 149-153.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Burtnyk, N. and M. Wein, Towards a Computer Animating Production Tool, Proc. Eurocomp Congress, May 1974, Pub: Online Ltd., Brunel, England, pp. 174-185.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.Siggraph 
75 Bowling Green COMPUTER ANIMATION OF FREE FORM IMAGES N. Burtnyk and M. Wein National Research Council 
of Canada Ottawa, Ontario K1A OR8 Our main interest, at the National Research Council of Canada, has 
been the development of a system for the professional animator in the traditional film industry. The 
primary form has been animation with free form drawn images. More recentlywe have been investigating 
the exten­sion of our system towards the animation of graphs and charts where the dynamics in the image 
are de­rived from time series data. The data are in turn the output from a computer based model. For 
the most part this paper is discussing the first area of animation defined above; the problems that are 
posed by the requirements and some of the solutions. Because we are dealing mainly with free-form drawn 
images, we have confinedourselves to two dimen­sional drawings, prepared on a graphic tablet. Working 
through the graphic tablet the artist uses his well developed skills in preparing the picture material. 
The tablet is therefore an important component in the system. The animation approach that we have taken 
is based on the concept of key frame animation in which the artist provides key images in a sequence 
and the program computes by interpolation the in-between frames. Key frame animation techniques offer 
two advantages in the type of animation that we have been inves­tigating. First, the techniquemimics 
conventional animation, in which the key positions are estab­lished in a storyboard, and therefore it 
is a good point of departure for traditionally trained ani­mators. Secondly, inherent in this technique 
is the ability to animate distortion or change of shape. The success of this technique depends on the 
extent to which the animator is able to control the interpolationprocess. In our system he does this 
by establishing the key positions and by deciding on the order in which he traces the lines in the key 
image. The one-to-onecorrespondence between the source and the destination key is be­ tween stroke lines 
in the image. The process has been described previously (1). It is straightforward to provide a wide 
range of dyanamics in time by controlling the rate at which interpolation is performed. Thus the artist 
has at his disposal means for producing a wide range of motion dynamics and motion tapers. However, inter­polation 
in space is linear. Each in-between frame is determineduniquely by the source key, the des­ tination 
key, and the time dynamics. Hidden Line Removal and Matting A simple technique for removing transparency 
in two dimensional images is through the use of hier­archy of parallel 2D planes. The actual image is 
composed of elements which are placed on different planes. In the computationof the composite image, 
 the elements on higher planes block out elements on lower planes. The image components are drawn as 
silhouettes, en­closed by connectedoutlines which are subsequently filled in by a scan conversion program, 
so as to produce solid areas. This matting process was used in the sequence shown in Fig. 1,taken from 
"Daphnis et Chloe" by Peter Foldes. In this sequence there are fourteen levels of visibility, (each finger 
is at a different level). The figure shows the composite-line image with transparencyremoved. A companionsequence 
 contains the correspondingcolour areas, which are derived from the silhouette outlines. The matte 
techniquewas also used to remove transparency in overlapping areas. How the two sequences are com­bined 
to form the final sequence, depends whether the desired effect is colour areas with black lines or white 
lines (Fig. 2). Black-line image is closer to conventional animation in appearance. Treating the image 
material as a hierarchy of par­ allel planes makes the process of computing the hidden portions of the 
image suited to mini-compu­ ter based systems in that the data are implicitly sorted (by plane). Since 
only the current level need be kept in high speed memory at any one time, the desired composite image 
can be conveniently segmented as dictated by the available memory. Extension of Key Frame Animation 
 The capabilityoffered by key frame techniqueshas been sufficient to permit Peter Foldes to make the 
 award-winning film "Hunger" (Prizes at film festi­ vals at Cannes, Chicago, Barcelona as well as a 
nomination for an Academy Award). There are, how­ ever, limitations imposed by the fact that motion 
is linear in space and there usually is a discon­ 78 tinuity at each key frame. We are investigating 
methods of extending key frametechniques in order to add a capability for bettercontrol over the action. 
Clearly, drawing a large number of closely spacedkey images would achieve a richer range of move­ment, 
but it is hardly a practical way. We also feel that drawing or defining a path forcontrolling the movement 
of an object is not a suf­ficiently general capability. The method workswell for a single path controlling 
a rigid object.As such, it is a useful capability. However, thetechnique breaks down if several paths 
are required Fig. 1 (left). Composite line, from Daphnis etChloe by Peter Foldes. Fig. 2 (above). Composite 
line and area (Black/ white reproduction). to control an object, that is changing shape. Theproblem 
is that it is no longer clear what theshape is at any instant. The concept of simultane­ity is no longer 
clear. Instead we have chosen a different approach. Wehave made two extensions to the basic linear inter­polation 
process. The first extension offers a capability for defining a rotation component abouta specified centre, 
and this rotation is super­imposed on the linear interpolation. The secondextension is the ability to 
produce additional keyimages from those that have been drawn by applyinga distortion which is defined 
by a stick figureskeleton. With this technique, stick figure skele­tons, one for the source key image 
and one for the 79 desired intermediatekey image, are used as a basis for computing the new key image. 
Thus a large num­ber of key images can be used without it being nec­essary to draw each of them. Playback 
in Interactive Systems An important feature in an animation system is the ability to preview animation 
sequences at a rate which is equivalent to the cine projection rate of 24 frames/second. It is also desirable 
that the cycle which goes from the preparation of the sequence,to previewtomodificationbe reasonably 
short so as not to impede the creativeprocess. In practice cine playback is difficult to achieve, except 
for relatively simple sequences. Where the image is as complex as in Fig. 1 containing in ex­cess of 
104 points it is not practicable to achieve a display rate equivalent to 24 frames/second con­currentlywith 
the computationof the in-between images and of the visibilitymatting. It is unrealistic to assume that 
all that is neces­ sary is a more powerfulcentral processingunit and a memory large enough to store the 
key images in their entirety to sustain the cine playbackrate. Besides being expensive there would still 
be a hard limit on the complexity of the picture material. Our attitude has been that frame-by-frameconver­ 
sion of animation sequences to video format for presentationon a video monitor is a viable alter­ native 
if not the only one. The main advantage of using the video format for playback at a projection rate is 
the fact that once the sequence is convert­ed, the display process is independent of image content. Thus, 
there is no built-in limit on the number and complexity of sequences that can be viewed satisfactorily. 
The only limit is the time necessary to convert from the digital format to the video format. Three steps 
are implied in conversionto a video format: (a)Scan conversion from coordinateend­ point data to a rectangulararray 
of intensity values, (b)a facility for storing one frame or part of a frame, either in analogue form 
(storage tube) or in digital form (framebuffer), and (c) a mechanism for storing and reading back a sequence 
with a sufficient number of frames to sustain play­back for a reasonabletime, between 30 and 60 seconds. 
 An ideal, if expensive,medium for storing the video sequence is a video disc. Its main advantage is 
the facility for building the sequence frame-by­frame or even line-by-line. A video disc is expen­sive 
however. resolutionand picture quality. If the projection playback is not at full resolution, then a 
separate frame-by-frameplayback is a useful adjunct for de­tailed image inspection. Looking Ahead Our 
animation system is implemented in assembly code on an obsolete system (SEL 840A) and is there­fore not 
easily transferable. Our objective is to make the software system more readily available. Because of 
the high level of interactionthat is implicit in the system, the intention is to convert the system to 
run a modern machine but still to be machine dependent. Some comments are in order about the future 
beyond our immediate plans. What steps are necessary to make computer animation more effective as a practi­ 
cal tool? The main thrust in hardware development that ap­pears to be desirable is in the application 
of video techniques to computer animation. Our moti­ vation for the use of video has been described 
earlier in the context of preview playback of ani­mation sequences. The main advantage that the video 
format offers is the immediacy of seeing the product in as nearly a finished form as possible. The main 
component is a frame buffer capableof storing one complete frame. The all-digital solu­ tion is appealingbut 
expensive ($50K to $80K). The development of frame buffers is likely to bene­ fit from the decreasing 
costs of semiconductor memories. On the more immediate time scale it is worth exploring the capabilities 
of analog storage tubes with electrical read-write facility, such as the Hughes silicon target tube. 
 As far as the host computer goes, our experience indicates that a powerful animation system can be 
 supported on a stand-alone computer, like DEC PDP 11/45, Varian 73, or Data General Eclipse, running 
 in a single user mode. At present it is not clear whether time sharing a large system (such as S/370) 
or the use of distributedcomputers could provide comparableperformance at a lower cost. Cost of systems 
and the minimum staffing with computer specialists remains a significant impediment for getting a wider 
use of computer animation. Until now computer animation activity has been an adjunct of other computer 
related activity so as to share the resources. Hopefully a downward trend in the cost of hardware will 
make computer animation sys­ tems more accessible to potential users. With a wider use in the production 
environment,we should expect a significant input from the animation community. In the NRC system we 
have implemented an interim compromise solution to sustainplayback of video sequences. By reducing the 
spatial resolution to 200 lines of 256 one-bit elements we are able to refresh a video display from 
a conventional moving­head digital disc. The playback system isnot new and it has been de­scribed before 
(2). The underlying argument is the fundamentalneed for a playback facilitywith true motion dynamics 
with a sacrifice, if necessary, in References 1. Burtnyk,N. and M. Wein, Computer Generated Key- Frame 
Animation, J. SMPTE, V. 80(3), March 1971, pp. 149-153. 2. Burtnyk, N. and M. Wein, Towards a Computer 
Ani­ mating Production Tool, Proc. Eurocomp Congress, May 1974, Pub: Online Ltd., Brunel, England, pp. 
174-185. 80 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563744</article_id>
		<sort_key>81</sort_key>
		<display_label></display_label>
		<article_publication_date>04-01-1975</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Computer animation at Lawerence Livermore Laboratory]]></title>
		<page_from>81</page_from>
		<page_to>84</page_to>
		<doi_number>10.1145/563732.563744</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563744</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14089721</person_id>
				<author_profile_id><![CDATA[81332511887]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[S.]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Levine]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lawrence Livermore Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.Siggraph 
75 Bowling Green COMPUTER ANIMATION AT LAWERENCE LIVERMORE LABORATORY S.R. Levine Lawrence Livermore 
Laboratory Inany discipline where the desired results of expended effort can be pictorial innature, 
we find computer graphics. Inthose particular cases where the results can be displayed as a sequence 
of pictures so as to give the illusion of motion, we find computer animation. The uses of animation made 
by any discipline are as varied as the disciplines themselves. At the Lawrence Livermore Laboratory, 
we have been producing computer animated films for well over 10 years. These films have been used both 
as a means to aid researchers with their work and as a means to communicate to others the results of 
their calculations. Until a few years ago, the only means of direct computer film output was 35mm black 
and white microfilm. This film was either viewed directly on a 35mm projector or else reduced to 16mm 
on an in-house optical printer. The use of 35mm proved unsatisfactory for the obvious reason that 35mm 
projectors are not commonplace like 16mm projectors. Whereas we actually have a 35mm projector at LLL, 
itwas recognized that most other laboratories that we exchange film with will not have a 35mm projector. 
The 16mm motion picture film isthe most reasonable medium inwhich to exchange film inthe scientific 
community. The main reason isthe abundance of 16mm motion picture film projectors. Also recognize the 
fact that there isa single standard for 16mm film. Itisthis standard that allows computer animated 
films to enjoy the popularity they do. The production of color computer generated film isa simple extension 
to the optical re­duction process. The user produces a number of 35mm black and white films each correspond­ 
ing to the particular color desired. These films are then superimposed one upon another onto 16mm color 
film with the appropriate color filter inserted into the light path. This technique iscurrently the 
most popular method for the production of scientific computer animation. The major drawback is the time 
required to make the film. The users generally expect to see their results soon after running their 
program. Itisfor this reason that computer films are more often used to show final results rather than 
as an alternative to other forms of computer output. These are however, a few advantages to production 
of film in this manner. The quality of the finished product is better than by any other technique. 
 This isbecause high resolution 81 color print film can be used instead of high speed Ektachrome used 
inmost direct color film recorders (described below). There are color print films that have a resolution 
inexcess of 200 line pairs/mm inany color. That contrasts sharply with the 20-50 line pairs/mm obtainable 
 with high speed Ektachrome. This becomes important when we recognize the fact that a high quality 
film recorder iscapable of imaging over 150 line pairs/mm on 16mm film. Thus, it isclear that the indirect 
approach can potentially produce a far superior product. A second point isthat during the optical reduction, 
it ispossible to use the printer for special effects that are not easily programmed. For example, fades 
and dissolves can be added for essentially no additional effort. A far better control over color can 
be expected. If the user isunhappy with the choice of colors, the film can be reprinted with different 
colors. This involves no additional computer runs. There isone special effect we have used at Livermore 
on a number of occasions that provides a result that isnot easily accomplished by programming. As a 
simple example, consider two distorted grids that overlay one another. Let the one to be infront colored 
red and the one to be in back colored green. Suppose further that these grids move with respect to one 
another. At all those points that the grids cross the film will show yellow (red + green = yellow). 
This array of yellow dots gives an undesirable effect that can distract from the information the programmer 
was trying to convey. Itis, ineffect, a type of optical noise. To eliminate this effect by programming 
means computing all of the intersections of the two grids, breaking the green lines into segments with 
the proper spaces left for the red lines. This isa very time-consuming process and not a trivial one 
to be done efficiently. A far simpler solution isto first make a negative copy of the black and white 
film that is to be colored red. We call this a negative mask. This film isclear except for the black 
lines. Now the film to be colored red is printed onto color film with the red filter. After the color 
film isbacked up inthe printer, the film to be colored green is printed through the negative red mask. 
This isaccomplished by loading both films into the optical printer with the mask closest to the color 
print film. The black lines from the negative red mask prevent light from passing through the "green" 
 film at exactly those places where the two cross. Thus, the red lines will be unbroken and appear infront 
of the green lines. Since the negative red mask was made from the original film to be colored red, there 
isno registrationproblem. These techniques are used by Hollywood to insert a scene into a different 
background. We also use our optical printer for the pro­duction of color stereo movies. The printer 
is used to place the images side by side as required by the Bolex stereo system we use at LLL. It isclear 
that the calculation of the stereo pair isonly a time-consuming extension to the calculation of a single 
perspective view. The optical reduction isno more difficult then the 35mm to 16mm reduction. The lack 
of popular­ ity of color stereo movies inthe scientific community is not because of the lack of interest 
 insuch film nor the ability to produce them, but rather because of the great difficulty of showing 
them. Given that we can produce the film, there is the problem of a special lens for projection, poloroid 
glasses for viewing on a special type screen that is probably not available. Inaddition there isnot 
a standard for a 16mm stereo format. The advantages are not all on the side of the optical printing 
method. A number of instal­lations employ a film recorder with direct color recording capability. The 
essential differences are in the CRT phospor, lenses, and use of a filter changer. The white phospor 
CRT isusually a P4, P24, P48 or other braod band phosphor. What is impor­ tant isthat the CRT be capable 
of emitting relatively equal amounts of red, green and blue light. The lens must be corrected for this 
 light. Most high quality black and white film recorders employ a P11 phospor and use a lens corrected 
for the blue light this phosphor emits. There are two systems for generation of color film. The first 
iscalled additive color and isgenerally implementedwith a filter changer that consists of a single 
disk containing at least a red, green and blue filter. Itisclear that any color can be generated by 
the proper combination of red, green and blue light. However only three colors; namely, red, green 
and blue can be generated by a single exposure. Generation of the secondary colors require two exposures 
for each element to be colored, with other colors requiring up to three exposures. For the reproduction 
of continuous tone images, this triple exposure per element isrequired inany case and a color disk 
isgenerally satisfactory. Here each image isrecorded sequentially and only three filter changes are 
required per frame. However where the computer film consists of colored lines and points, the color 
disk has some serious disadvantages. The major drawback is the multiple exposures Ifwe required for 
all but the primary colors. choose to minimize the filter change time (between 100-250 ms for most 
disks), this requires process­ ing the data three times to compute the red, green and blue component. 
The drift inthe CRT deflection system will cause some mis-registration resulting ina loss of resolution 
which isvery noticeable inpictures consisting of many fine lines. Ifwe choose to avoid the drift by 
changing the filter for each element as required, then the time to generate a frame becomes excessive. 
 The second system used by film recorders consists of movable arms attached to rotary solenoids or stepping 
motors. These arms are arranged so that more than one filter at a time can be inserted into the optical 
path. This allows the use of subtractive color. The advantage here isthat seven colors (white, red, 
green, blue, yellow, cyan, magenta) can be produced without the need for multiple exposures. For pictures 
that contain a collection of colored lines and characters, this can be a timesaving device. We have found 
that five or six colors isgenerally sufficientfor most of our work. The loss inresolution due to more 
than one filter inthe optical path ismore than made up for by the poor resolution inherent inhigh speed 
Ektachrome. The major advantage of the direct color recording systems is one of fast turn around After 
the film isrecorded and processed, time. the user has a color film. Even with our in-house optical 
printer, a color film isat least 24 hours away (more typical isone week). The quick turn around time 
means color film can be used as another form of output and for many users, this far outweighs the advantage 
of added quality obtainable by the indirect procedure. There is,on the horizon, a new technique that 
promises us the best of both worlds. The technique isdirect color recording using lasers. The laser 
has enough light output to directly expose slow speed high resolution color print film. Use of HeNe, 
Argon, HeCd give red, green and blue light sources eliminating the need for filters. Lasers can be focused 
down to spot sizes less than 1 micron. This compares to a minimum of 20 microns on a white phospor CRT 
and can provide all the resolution the color print film can handle. The color laser film recorder is 
insome sense, a far simpler device than the color CRT film recorder. The three laser beams are passed 
through intensity modulators and folded into a single optical path. Using the modulators, the three 
lasers can produce a light beam of any color. There isno need for multiple exposures. A color laser 
recorder has been built by CBS and isoperating ina production environment at their studio inNew York 
City. Itwas designed to transfer videotape to film and is therefore adjusted to record approximately500 
 lines on 16 or 35mm film inreal time (30 frames per second). This particular recorder iscapable of 
over 1000 lines resolution. Because of the real time recording requirement, the device becomes bandwidth 
limited before itis resolution limited. Ifone were to slow the frame rate down, CBS assures us resolution 
of 4000 pixels presents no major problem. Our only problem would be incomputing all those points. The 
laser recorder has the fundamental advantage inthat itismuch faster than a comparable CRT system. There 
isapparently no problem inbuilding a machine that can record colored spots with varying intensity at 
a rate exceeding 7.5 million points per second. This istwo orders of magnitude faster than conventional 
 82 high resolution color film recorders. The major drawback to Laser recording today isdeflection 
of the Laser beam. The CBS system solves the problem by deflecting the beam horizontally with a rotating 
minor and vertically with a galvanometer. This works well for videotape but leaves much to be desired 
for most computer generated data. Forcing the data to be organized in a raster means that vector and 
character data must be scan converted to a raster format. This means either special purpose hardware 
or time­consuming software. Inaddition, there isthe problem of "jaggies." When a vector is broken into 
a string of points on a finite raster, there will be dis­continuities. For a still picture, this may 
or may not be objectionable. For movies, the discontinuities along the line move and appear as stair 
steps moving along the lines and are extremely distracting. This isanother form of optical noise. These 
effects can be suppressed inseveral ways. The most straightforwardapproach isto use a raster finer than 
the resolution of the film. The only problem is increased computation and storage costs which rise as 
the square of the raster. We have found that for black and white 16mm microfilm,a raster of 4096 x 4096 
is required to remove the "jaggies". A second technique that has been used requires a recorder with 
gray scale capability. The screen isconsidered to be a grid that isintersected by a straight line. Each 
cell that the line passes through isassigned an intensity propor­tional to the area subtended by the 
line. More sophisticated approaches take into account slope and adjacent cells. This produces a smooth 
appearing line. However, the line appears thicker and hence, resolution isreduced. RCA, among others, 
isdeveloping a solid  state deflector for laser beams based upon a 2 crystal. The amount of deflection 
is small but can be opticly amplified. Current crystals have a resolution of 512 points which isnot 
enough for high quality film. Deflectors with 2048 point resolution are operating ina laboratory environment 
and will be available soon. The solid state deflector has the obvious advantages over a rotating mirror 
deflector. A recorder built with these crystals will neces­sarily be more a complex device. This isdue 
inthe main to the fact that the deflection isa function of the wavelength of the incident light. We believe 
that these problems can be solved and a high quality color laser recorder will be built soon: Its only 
a matter of money. We believe that the color laser film recorder will provide a quantum jump in the production 
and quality of color computer generated film. LLL isnow inthe process of building a complete system 
for the generation of color computer generated film. The objectiveswere to provide the user both fast 
turn around time and high quality color film output. Since a color laser recorder was not within our 
budget, a dual system has been designed. Itwill consist of a high quality direct color film recorder 
and a video subsystem. The film recorder will use the subtractive color technique to provide for seven 
separate colors without the need for multiple exposure. Itwill be fast enough to record a 200 x 200 
grid composed of 40,000 short vectors inless then 10 seconds. Itwill also be capable of recording continuous 
tone type images with up to 4096 x 4096 points. We have found however, that 1024 x 1024 ismore then adequate 
for any computer movies we have made. Inaddition, since the device will not record on print film, we 
end up resolution limited by the Ektachromefilm. The resolutionon the CRT will be at least 1500 line 
pairs across the image area. The major limitation to quality is the film itself. We expect to use the 
high resolution capability of the CRT with large format film such as 70mm or 4"x 5". We have found in 
talking to users and vendors, a lack of under­standing of the interplay of CRT phospher, lens design 
and film response. We were advised by a vendor that ifwe purchased their color recorder we would be undertaking 
a large in-house R and D project just to learn to use it. A major concern was the elapsed time from 
 running the program until the film was processed. For movies, the major portion of that time is the 
recording itself. For continuous tone, three color 1024 x 1024 pictures, at least 30 seconds recording 
time will be required for each frame. That comes out to 12 hours per minute of film. We felt that a good 
preview capability was essential to prevent recording film generated by a program with a bug. Note that 
a laser recorder could record the same film inreal time. The video subsystem isdesigned to preview 
movies before committing them to film. It is attached to the same minicomputer as the film recorder. 
The primary element isa video disk such as those used by the television networks for the instant replay. 
Itwill have at least three independent channels each capable of recording 300 frames. The three channels 
can be used to record an RGB picture to be viewed on an RGB monitor for the highest quality pictures. 
This allows us to look at a movie 10 seconds at a time. We can select frames at random for checking or 
certain whole sequences to examine timing. Ifit isrequired to look at a longer sequence,we can encode 
the RGB picture into NTSC format and record iton videotape. Inorder to do this with standard television 
equipment means the picture can contain only 480 scan lines instead of the expected 512. The commercially 
available digital color television systems use a 512 x 512 picture which isnot compatible with standard 
television. Itcannot be encoded and recorded with standard television equipment. We have given up those 
mystical 32 lines for the sake of compatibility. There are many people here who would willingly trade 
the ability to record their material incolor for those 32 lines. Some habits are just hard to break. 
 Itis important to note that the NTSC recording does not have the resolution of the RGB image. This isdue 
to the bandwidth limitation of the 1" video tape and the NTSC signal. We do not envision this to be 
amajor problem since the video isfor a quick check only with the quality image to be recorded on film. 
We do, however, expect to'find a class of user for whom color video isadequate for their needs. The 
recent advent of the digital time base 83 corrector gives us one new dimension not possible a few years 
ago with a 1" video recorder. We can record our RGB picture as three separate images and using the time 
base corrector, dump the three images onto the video disk inperfect time registration for high quality 
viewing. Of course only ten seconds at a time can be viewed. As far as we have determined, this is the 
first time this will have been tried. This entire system (video disk, video tape, video switches, etc.) 
isunder computer control. We feel that we will have a most advanced system for the productionand editing 
of computer generated  84 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563745</article_id>
		<sort_key>85</sort_key>
		<display_label></display_label>
		<article_publication_date>04-01-1975</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[Effective application of computer graphics]]></title>
		<page_from>85</page_from>
		<page_to>91</page_to>
		<doi_number>10.1145/563732.563745</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563745</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379797</person_id>
				<author_profile_id><![CDATA[81100264395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Tressel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Battelle Columbus Laboratories, Columbus, Ohio]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Hales, John, and Roger Marvell, The Technique of Film Animation, Hastings House; 1968.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Heath, Robert P., Animation in Twelve Hard Lessons, Robert P. Heath Productions, Inc., 1627 Scott Avenue, West Islip, Long Island, New York 11795; 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Madsen, Roy, Animated Film, Interland Publishing; 1969.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Herdeg, Walter, and John Hales, Film and TV Graphics, Graphic Press; 1967.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.Siggraph 
75 Bowling Green EFFECTIVE APPLICATION OF COMPUTER GRAPHICS George W. Tressel* Several years ago, Battelle's 
Seattle Research Center hosted a conference entitled "Computer Graphics--Why Is ItAlways a Year Away?" 
 The concensus at that time seemed to be that the state of hardware and programming capability had 
not yet reached maturity as a working tool. Since then, the progress has been impressive. But we are 
still a year away, and I suggest that we are passing into a new phase of development. While it is both 
intriguing and necessary to continue refin­ ing the hardware and logic, an increasingly impor­ tant consideration 
must be the application of com­ puter animation to practical problems, and this will prove far more 
difficult than is generally recognized. Although the strengths of animation are formidable, they are 
an art rather than a science, and they are severely limited by the ingenuity and imagination of the user. 
Until now, most computer animation inevitably has been self-centered ... that is to say, the applications 
have generally been chosen to display the hardware performance rather than in response to an external 
problem. In short, like many other sophisticated tools, computer animation is a solution in search of 
a problem. When faced with "real world" tasks, practical exercises in illustration and exposi­tion, 
the strengths and weaknesses will be pain­fully apparent. It may be helpful at this point to examine 
the characteristics of expository ani­mation, so as to anticipate, to some extent, areas where computer 
animation will prove power­ful . . . areas where it is doomed to failure ..and most importantly, areas 
where it can be merged with other techniques to provide a truly formidable tool. * Educational Development 
Section Center for Improved Education Battelle Columbus Laboratories 505 King Avenue Columbus, Ohio 
43201 Three Types of Computer Animation We see three general approaches to "computer animation" .. 
. one of which is not generally recognizedas such, but which we suspect will ultimately play a critical 
role.  Wholly digital techniques --A fairly common scientific approach to computer animation uses the 
device largely for mathematical manipula­tion and display (Figures 1 and 2). Raw infor­mation ispresented 
in numeric form, a table of data describing the coordinates of points in space and time. The machine 
is then instructed to manipulate these numbers according to some series of mathematical procedures. The 
results can be scientifically profound and provide a rapid insight into problems and processes that 
would be otherwise extremely difficult to visualize.  Figure 1. Digitally produced graphics: Above 
a cross section of a forging appear a series of pressure curves, calculated and displayed by the computer. 
 Computer-Aided Design and Manufacture of Forging Dies. Battelle, 1974 85  Figure 2. Digitally produced 
graphics: An off­shore oil tower iswarped by wave action, calculated and displayed by the computer. 
Dynamic Response of an Offshore Platform. Battelle, 1968 Such wholly digital systems combine a precision 
of manipulations, displays, and re­cordings but are likely to be comparatively slow. In return for this, 
they offer the ability to precisely duplicate sequences, to create segments which fit together like pieces 
of a puzzle, and to manipulate these components with mathematical precision. At the same time, this very 
precision can imply difficult and costly problems of entry, and a cold-blooded mathematical base that 
is antithetical to many subjects and artists. The creative writer, producer or artist does not conceptualize 
in terms of X-Y-Z coor­dinates and milliseconds. Rather he tends to think and speak in distinctly nonmathematical 
terms of rhythm, style, tempo, etc. The graphic artist is often so dependent upon in­tuitive feedback 
that he must constantly test his ideas on paper and "can't talk without a pencil in his hand". This problem 
can be mitigated to some extent through elaborate "standard instruction" algorithms and clever "preparatory" 
devices to convert sketches or models to digital information. But the diffi­culty is deep-seated: a systemwhich 
is inherentlynumeric and mathematical is most easily applied to problems of numeric and mathematical 
display. Hybrid systems. Just as one can devise tech­niques to approximate a drawing or a model or even 
a person's movements as a table of numer­ic information, so it is possible to build such "analog" devices 
directly into the mach­ine both at the input and display stages, re­sulting in a substantially greater 
interactive flexibility. The artist can then "draw" di­rectly on the machine, composing, manipulating, 
and modifying components with perhaps even more responsiveness than is available with pencil and paper. 
 By adding a variety of such analog com­ponents, the control and display can be made faster and more 
responsive, a full order of magnitude closer to the playful style and mode of the creative artist. In 
return for this new interactive flexibility, however, one must trade a bit of the precision and replicability. 
The very virtue of analog devices in this pro­cess is their ability to translate ambiguous material into 
numeric form which can be pro­cessed by the machine ... then once again re­translate the results into 
slightly ambiguous display forms. There is an inevitable loss in the translation which may or may not 
prove serious. One is reminded of the computer which was asked to translate from English to Russian and 
then retranslate back into English. When given the phrase "The spirit is willing but the flesh isweak", 
the computer answered back, "The wine is good but the meat is bad". The output of such a hybrid system 
may well appear, either directly or indirectly, as a television signal. Once in this form it is available 
to be inserted directly into a program or manipulated still further through a wide range of video techniques. 
Through the use of "chroma-key", for example, animation may be in­stantly inserted into a live sequence 
to cut away the side of a machine or add an illustra­tive diagram. Video techniques provide this ability 
to insert and combine pictures in real time at essentially negligible cost. There is already a palette 
of such television techniques which cannot be duplicated on film without great cost and difficulty . 
. . though they often are accompanied by some lack of precision. Computer-controlledanimation. At the 
same time that these elaborate techniques are being developed to generate and record images direct­ 
ly, there is a parallel development of computer hardware applied to the control of conventional animation 
equipment. While this may not appear directly related to the use of computer graphics, it is having a 
profound effect on some of the problems which computer animation offers to solve. Furthermore, as will 
be seen, a merger of these techniques seems inevitable, both in order to manipulate and embellish computer-generatedfilms, 
and also to alter some of the characteristic features of computer­generated materials. Battelle's approach 
to this alternative combines several pieces of specially developed animation equipment so as to provide 
precise manipulation and combination of still and motion pictures under the control of a dedicated com­ 
puter. This computer control allows exact dup­lication of even the most elaborate photographic manipulation. 
The hardware was specifically developed for expository animation and is ex­ ceptionally flexible. The 
basic hardware (Figure 3) consists of an animation camera (A)which prepares motion picture film by photographing 
one frame at a time of artwork, models, photographs, trans­parencies or film, later projected on the 
table (B). 86  The camera motor and the shutter which controls its exposure are independently con­trolled 
by a minicomputer (C). The same com­puter controls motors which precisely position both the table and 
the camera height. At the same time, computer-controlled peg bars (D) can move overlay cels over the 
surface of the artwork. Because of the computer control, it is possible to combine multiple exposures 
with precision--building an animated sequence in several successive steps. Adjacent to the stand is an 
"aerial image" projector (E), which allows us to pro­ject 16-mm film into a rear projection field lens 
in the bed of the stand. By thus pro­jecting and rephotographing a 16-mm film one frame at a time, it 
is possible to copy the film precisely, combine it with other pictures, or carry out a wide variety of 
other manipula­tions. This projector is also controlled by the computer, and it would be possible to 
add computer control to the micrometer screws which position its image. With such an almost totally automated 
tool one can carry out routine mechanical activi­ ties of animation in a perfunctory manner. Fur­ thermore, 
conventional animation techniques may be combined with other photography, either live or animated, to 
produce a variety of new effects. In the process we can also alter and embellish mate­ rials produced 
by other means, such as computer­ generated graphics. We can add color, accelerate or diminish the tempo, 
and directly combine these materials using each to its fullest advantage. Because of the precision of 
numeric control the final version may be assembled bit by bit. Most important, the effect is to remove 
much of the tedious effort of most of the basic animation techniques. With this perspective, one must 
re­examine some of the basic reasons for computer graphics and reconsider the tasks for which they are 
best suited. Basic Animation Processes In order to explore the potential of these tools, let us examine 
some of the principal techniques which have proven useful in illustrat­ing a concept, or process, or 
object. This dis­cussion will be largely directed to problems of exposition and nontheatrical subjects. 
The prin­ciples also apply to the entertainment field--they are, after all, the basic tools of the trade. 
But the heavy investment in computer graphics develop­ment (and its justification) has been directed 
toward improved exposition and display--rather than toward a new "special effects" machine. It is clear 
that computer animation will offer tech­niques and manipulations which have not yet been conceived. But 
it is not likely that these tech­niques will change the basic problems and processes of exposition. There 
is in fact a fundamental syntax of explanation that is aided but not changed by illustration. And because 
of this, I suggest that these basic explanatory techniques will be with us regardless of how the image 
is generated. 87 Progressive Development Many concepts are most easily explained and understood in a 
step-by-step fashion, success­ively adding one point to another, until we see a working image of the 
whole (Figure 4). We describe an engine as a cylinder . . . with a piston . . . -pushed by an explosion 
. . . to drive a shaft . . . etc. And pictorially we tend to add components as we add concepts. Motion 
may help . . . or it may prove distracting if it conflicts with the basic development of the concept. 
In a similar manner, a graph is more understandable if it grows before our eyes. Multiple curves are 
more understandable if they are added and explained one by one. An elaborate isometric graph is most 
effective if built and explained in stages. A whole class of expository animation is built on this simple 
and perfunctory technique, building a concept and a picture bit by bit. . . sometimes in motion, but 
often more effective when the action is frozen or indicated symbolically. In some cases, the order is 
reversed, penetrating a subject layer by layer, but the process is essentially the same. Cycle or Flow 
(Figure 5) Some processes, devices, and concepts are characterized by a repetitious activity which is 
clearer or almost self-explanatory, if we can only watch it happen repeatedly . . . the action of a pump 
. . . or the flow of air in a storm front. In a related manner, we can punctuate an abstract concept 
by adding a symbolic, continuous movement to a portion of a diagram . . . the flow of credit between 
several countries . . . or a pulsating portion of a circuit diagram. Leading the Viewer (Figure 6) Perhaps 
the principal power of the film medium is its ability to focus the viewer's atten­tion, limiting his 
vision to a small area or a limited subject chosen by the filmmaker. Thus, one can tell the viewer (without 
ever verbalizing the instruction) "Look at this picture! How examine this detail and follow me as I show 
you where it leads." In much the same way that one can build a concept by adding components to a pic­ 
ture, one can build a mental image by progressive­ ly examining limited areas of an overall picture. 
Full Animation I have chosen these three "primitive" techniques in order to emphasize how often anima­tion 
revolves about the concept rather than the Figure 4. Animation by Progressive Development: A mass of 
Uranium. . . ... is distributed among lumps of graphite. . . 88 Supported by a wood frame . . . . 
. . and enclosed it forms the first atomic "pile", CP-1. The Day Tomorrow Began. Argonne National Laboratory, 
1967. Figure 5. Cycle Animation: A stream of plasma (dotted line) enters a magnetic field. FusionResearch. 
Argonne National Laboratory, 1964  Figure 6. Animation by camera movement: Focusing the viewer's attention. 
The Sunny Rock. George W. Tressel, 1958. tool. The simple abilities to build an image to move about 
within it . . . and to add just a 7 touch of emphasis and motion are the critical tools to a large portion 
of exposition and explanation. At the other end of the spectrum are the elaborate wonders of full animation 
the ability to draw and display any fantasy the mind can conceive. Bringing it to life through a laborious 
and largely abstract process of planning, drawing, and photography . . . calls for an artful and almost 
indescribable facility of tempo, sugges­tion, and imagination. The subtleties of this are far more than 
simple routine labor and time, and the impact of stylized alternatives to intensive labor can be far 
greater than the simple saving of dollars. 89 Often the appearance of extemporaneous activity is a critical 
ingredient . . . while skill and tech­nical sophistication are often immaterial. Will Mr. Magoo, Mickey 
Mouse, and Charlie Brown be more impressive inthree-dimensional shaded color with life-like fleshtones? 
 The Conversion from Idea to Image Despite all of its flexibility and the promise to display "anything 
the mind can con­ceive", animation presents its most difficult problems inplanning. Both the exposition 
and the process require a methodical continuity of image and thought, largely established and annotated 
in abstract terms .. . frame by frame . .. at the expense of difficult, detailed, and cold-blooded planning 
.. . in content, in presentation tech­nique, and inexecution. Setting aside momentarily efforts of sheer 
whimsy and invention, where the solution is its own problem, most animation begins with a script and 
storyboard (not necessarily in that order). This is so because they are the documen­ tation of an idea, 
and they may well be generated by an "idea man", who has no part inthe artistic display. Usually they 
are then converted to a detailed plan which sets pictorial and sound details. Possibly the most important 
of these is tempo, the timing and rhythm of presentation which, perhaps surprisingly, isas critical inex­position 
as inmusic or dance. The decision for a narrator's explanation to lead or lag its pictor­ial development 
. .. and by how long .. . can significantly change its impact and lucidity. The difference may be miniscule, 
only a fraction of a second, or itmay be a substantial pause to "let the idea sink in". Like the graphics 
themselves the decis­ions are a question of art, intuition, and empathy with a still hypothetical audience; 
but they are nonetheless real and must be determined and docu­mented inthe cold-blooded terms of seconds 
or frame-counts. Perhaps the most common approach is to prepare a soundtrack visualizing the sequence 
from a storyboard as one listens. Once such a soundtrack isprepared itcan be measured pre­cisely, frame 
by frame, to provide the numeric plan for the subsequent animation or photography. Thus the tempo of 
animation isoften entirely determined by a sound track--either a musical tempo, a narrator's,voice, or 
some other driving force. Along the way, however, an editor or dir­ector may very well intervene to alter 
this tempo inan intuitive effort to punctuate the action or clarify the meaning. The end result isa series 
 of meticulous instructions: o The picture will look like this.  o The sound will say thus. o Such 
and such will happen. o And itwill happen at precisely the nth frame.  This precision of this tempo 
iscritical and in some cases even the shift of a few frames can easily destroy the meaning or impact 
of a delicate sequence. The reason then that all of this is spelled out insuch detail isnot an accident 
of the mechanics, but an inherent part of the precis­ion and flexibility that are the strength of ani­mation. 
And they are the core of animation diffi­culty despite the fact that some mechanical costs can be reduced 
dramatically by the right tools. Even more important, however, unless the mechanics match the plan (or 
vice versa), even the most novice artist or planner can (and does) almost in­stantly develop concepts 
and demands that will baffle execution. Often the limitations of the tools become the strength of an 
art because they set the limits and style. The Role of Computer Animation Inthe light of this, let 
us look at the; strengths of computer animation. Wholly digital techniques are ideally suited to mathematical 
ex­planations and manipulations. We can watch a fourier combi­nation develop with instant and formidable 
clarity because the subject is mathematical and the system is mathematical. We can watch a diagram of 
an offshore drilling tower sway and vibrate when buffeted by the waves because the motions are mathemati­cal 
. . .the process is mathemat­ical .. . the information is mathematical ... and the display process is 
mathematical. We can watch the transfer of heat across a fuel rod, or the neutron flux in a nuclear explosion 
because the information, display, and the tools are all mathematical and matched. The impact of these 
examples is formida­ble, as are the tools to produce them. There is no comparable technique. But they 
are hardly cheap, and the strength is based upon a mathemati­ cal subject. Without this, the input conversion 
and manipulation problems begin to become awesome, and the results less than overwhelming. Hybrid systems 
have overcome much of this problem by providing the ability to create and manipulate pictures inreal 
time. They have reached a level of sophistication and utility where one cannot deny that they are a 
real tool . .. a cathode ray substitute for paint, paper, and ace­tate . . . perhaps even for the camera. 
But one must still plan the exposition to match the repertoire of the machine ... and this isnot inharmony 
with the usual approach to filmmaking. Content is usually decided by planners and scriptwriters rather 
than by the cameramen and artists (even though they sometimes play dual roles). 90 I suggest that the 
introduction of a simple log listing frame counts and a stream of demands of the minimal nature described 
earlier (aplanning document which isroutine and straightforwardto the filmmaker) is likely to cause chaos 
in the computer graphics shop for some time to come. This isnot meant to minimize the accomplishments 
of computer animation but to add realism to the appraisal of its development. It is time to put less 
emphasis on developing the tools and begin making real films so as to learn the real problems. I am 
afraid that the first lesson learned will be an appreciationof the fact that much of what we would like 
to draw can best be drawn with ink instead of electrons. And that much of what we would like to animate 
can be done quite nicely and perfunctorilywith the conven­tional tools--dissolves,moves, and cycles. 
 What then isthe myth of animation cost and labor? Was computer graphics developed to solve a nonexistent 
problem? No, animation is in­deed expensive. Even the simplest techniques are labor intensive. The most 
routine move, zooming, and sliding within a picture islikely to mean hours at the stand, sitting in the 
dark, moving (e.g.) ".002 East, .003 North, zoom in .001, peg­bar .005 to the left, shoot 2 frames" ... 
and then begin again. And this isbut the simplest example. With such primitive techniques and brute force 
resort to labor, is it any wonder that ani­mation proves expensive and formidable? portrayal was developed 
with awholly digital sys­tem, converted to film through a microfilm unit and then combined with other 
artwork prepared con­ventionally on the same animation stand. Together these techniques are mutually 
reinforcing. They offer a new palette instead of a new color. Ifwe recognize and pay attention to the 
limitations of these components, we can avoid a "Pandora's Box" of frustration and disillusion­ment inthe 
growing application of computer animation. References (1) Hales, John, and Roger Marvell, The Technique 
of Film Animation, Hastings House; 1968.  (2) Heath, Robert P., Animation inTwelve Hard Lessons, Robert 
P. Heath Productions, Inc., 1627 Scott Avenue, West Islip, Long Island, New York 11795; 1972.  (3) Madsen, 
Roy, Animated Film, Interland Pub­lishing; 1969.  (4) Herdeg, Walter, and John Hales, Film and TV Graphics, 
Graphic Press; 1967.  But these are routine problems, solved every day by numeric machine controls. 
And indeed, our experience at Battelle demonstrates that most routine presentation problems can be solved 
in a comparatively perfunctory manner, given the flexi­bility, power, and precision of computer control. 
 Incontrast, computer graphics are a solution to a particular class of problems--large­ly, the ability 
to replace the multiplicityof cels inconventional full animation, and to de­liver interpolations, mathematical 
manipulation, and three-dimensional effects without the enormous labor of a Hollywood factory. At the 
same time, itmust be emphasized that they also have yet to replicate the scope and flexibility of convention­al 
full animation. We see these three approaches to com­puter animation as components of a system, allow­ing 
an unprecedented flexibility of application. For example, in a recent title sequence, we com­bined a 
live picture of an enormous radio­telescope .. . with an overlay of a rotating globe, produced by a computer 
graphics terminal . . . and additional artwork and titles prepared with conventional animation. All three 
components were combined, paced, and manipulated through an aerial image system on our computer-controlled 
animation stand. Each of the components was pre­pared separately and could not have been accommo­ dated 
otherwise. Inanother film, we illustrated the modes of oscillation and their influence on the design 
of an offshore drilling tower. This 91
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563746</article_id>
		<sort_key>92</sort_key>
		<display_label></display_label>
		<article_publication_date>04-01-1975</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Computer animation]]></title>
		<page_from>92</page_from>
		<page_to>101</page_to>
		<doi_number>10.1145/563732.563746</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563746</url>
		<abstract>
			<par><![CDATA[A comprehensive 3-D real-time computer animation system is based upon a broad range of research activities in the field of computer graphics. In many ways the requirements for such a system are more challenging and complex than for other graphics systems. This is particularly true if one builds a language and a system which is truly user oriented and which has viable production capabilities for researchers and film makers. Too often systems which are the result of a research experiment in hardware or software design do not go beyond a beautiful demonstration of potentialities. Such experimentation is essential to advance the state of knowledge but if computer animation is to become a new research and production instrument we must, in addition, provide more examples of useable systems.Although each of the following topics are aspects of a real-time animation environment deserving a detailed explanation, they will be dealt with in a way to introduce to the reader basic requirements and problems. The topics are:I. STATE OF THE ART SYSTEMS, AND LANGUAGES&#8226; Used as references and as a basis of comparison.II. AN ANIMATION ENVIRONMENT&#8226; Several systems and languages are being implemented to run under RSX-11/D on our PDP-11/45 computer.A. VISIBLE SURFACE SYSTEM&#8226; Allan Myers' algorithm&#8226; VILAN (VIsual LANguage)B. GRAPHICS SUPPORT SYSTEM&#8226; Manfred Knemeyer's system for handling hardware devices, data structures, management of transformations and time, and memory management for the graphics buffer.C. ANIMA&#8226; A new graphics programming language has been designed and is being implemented.D. DATA GENERATION SYSTEM&#8226; Some approaches to problems are briefly discussed.III. DISPLAY HARDWARE AND GRAPHICS ALGORITHMS&#8226; The problems presented by the order of transformations in an algorithm are briefly described.IV. HIGH PERFORMANCE GRAPHICS&#8226; some speculations]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39040862</person_id>
				<author_profile_id><![CDATA[81100394889]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Charles]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Csuri]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Rougelot, Rodney S.; Schumacker, Robert--"G.E. Real-Time Display", NASA Contract NAS 9-3916, Defense Electronics Division, General Electric Company, Syracuse, New York.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Wild, C.; Rougelot, R.; and Schumacker, R. A., "Computing Full Color Perspective Images", General Electric Technical Information Series R71ELS-26, (May, 1971).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Greenberg, Donald, "Computer Graphics in Architecture", Scientific American, pp. 98-106, April, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Sutherland, Ivan E.; Sproull, Robert F.; Schumacker, Robert A., "A Characterization of Ten-Surface Algorithms", Computing Surveys, Vol. 6, No. 7, March, 1974, pp. 1-55.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Watkins, Gary S., "A Real-Time Visible Surface Algorithm", Computer Science, University of Utah, Technical Report UTEC-CSC-70-101, July, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Sproull, Robert F., and Sutherland, Ivan E., "A Clipping Divider", Proceedings of the Fall Joint Computer Conference, pp. 757-764, Thompson Publishing Company, 1968.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Gourand, Henri, "Computer Display and Curved Surfaces", University of Utah, UTEC-CSC-71-113, June, 1971 and IEEE, TC-20, p. 623.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Brooks, Joan, et. al., "An Extension of the Combinatorial Geometry Technique for Modeling Vegetation and Terrain Features", MAGI, Inc., NTIS report no. AD-782883, June, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Goldstein, Robert A., "A System For Computer Animation of 3-D Objects", Proceedings of the Tenth Annual UAIDE Meeting, 1971, pp. 3-128-3-139.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>642094</ref_obj_id>
				<ref_obj_pid>642089</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Eastman, Jeffrey F.; Staudhammer, John; "Computer Display of Colored Three-Dimensional Objects", The 2nd Annual Symposium on Computer Architecture (ACM-SIGARCH) Vol. 3, No. 4, December, 1974, pp. 23-27.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[National Science Foundation report 1972, "Real-Time Film Animation", see section I, "Graphics Symbiosis System", by T. DeFanti and The Computer Graphics Research Group (contact C. Csuri for copies).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Csuri, Charles, "Real-Time Film Animation", Proceedings of the Ninth Annual UAIDE Meeting, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[_____, "Real-Time Computer Animation", Proceedings of the IFIP Congress 74, Stockholm, Sweden, pp. 707-711. North-Holland Publishing Company.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>906875</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Gillenson, Mark, "The Interactive Generation of Facial Images on a CRT Using a Heuristic Strategy", Ph.D. Dissertation in the Department of Computer and Information Science, The Ohio State University, March, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>907099</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Clark, James H., "3-D Design of Free-Form B-Spline Surfaces", University of Utah, Ph.D. dissertation and NTIS report no. AD/A-002 736, September, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Sutherland, Ivan E.; Sproull, Robert F.; Schumacker, Robert A., "Sorting and the Hidden-Surface Problem", Proceedings of AFIPS 1973 National Computer Conference, Vol. 42, pp. 685-693.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Sutherland, Ivan E.; Sproull, Robert F.; Schumacker, Robert A., "A Characterization of Ten-Surface Algorithms", Computing Surveys, Vol. 6, No. 7, March, 1974, pp. 1-55.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Sutherland, Ivan E., "Three-Dimensional Data Input by Tablet", Proceedings of the IEEE, Vol. 62, No. 4, pp. 453-462, April, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.Siggraph 
75 Bowling Green COMPUTER ANIMATION by Charles Csuri* The Ohio State University INTRODUCTION A comprehensive 
3-D real-time computer animation system is based upon a broad range of research activities in the field 
of computer graphics. In many ways the requirements for such a system are more challenging and complex 
than for other graphics systems. This is particularly true if one builds a language and a system which 
is truly user oriented and which has viable production capabilities for researchers and film makers. 
Too often systems which are the result of a research experiment in hardware or soft­ware design do not 
go beyond a beautiful demonstration of potentialities. Such experimentation is essential to advance the 
state of knowledge but if computer animation is to become a new research and production instrument we 
must, in addition, provide more examples of use­able systems. Although each of the following topics 
 are aspects of a real-time animation environment deserving a detailed explan­ ation, they will be dealt 
with in a way to introduce to the reader basic require­ments and problems. The topics are: I. STATE 
OF THE ART SYSTEMS, AND LANGUAGES  Used as references and as a basis of comparison. II. AN ANIMATION 
ENVIRONMENT * Several systems and languages are being implemented to run under RSX-11/D on our PDP-11/45 
com­puter.  A. VISIBLE SURFACE SYSTEM  Allan Myers' algorithm  VILAN (VIsual LANguage) B. GRAPHICS 
SUPPORT SYSTEM  Manfred Knemeyer's system for handling hardware devices, data structures, management 
of transformations and time, and memory management for the graphics buffer. C. ANIMA  A new graphics 
programming language has been designed and is being implemented. D. DATA GENERATION SYSTEM  Some approaches 
to problems are briefly discussed. III. DISPLAY HARDWARE AND GRAPHICS ALGO- RITHMS * The problems presented 
by the order of transformations in an algorithm are briefly described. IV. HIGH PERFORMANCE GRAPHICS 
 * some speculations  I. STATE OF THE ART SYSTEMS  During the past ten years several state of the 
art graphics systems and algorithms have been used to produce computer animat­ed films. Some of these 
involve 3-D graphics using high performance algorithms in software and/or hardware and have set a high 
standard for computer graphics. General Electric's multi-milliondollar color display system built for 
NASA was the first major example(l). Concave 3-D objects with 250-300 edges were displayed in real-time. 
Rougelot(2) of General Electric, using some of the same concepts and technology, developed an "off line" 
system to produce color movies. Using some custom electronic circuits. his  system could process a color 
scene of about 350 polygons (1400 edges) in one second. Greenberg(3), using the Rougelot system, produced 
a stunning animated film representing movement through the Cornell campus. The data for the Cornell campus 
had about 12,000 polygons (48,000-50,000 edges) and each movie frame required 20­ 30 seconds of calculationtime. 
 The Rougelot system used the Schumacker(4) algorithm. This algorithm processes shaded and colored objects 
but its data representationrequirements place a heavy burden upon the user. Essentially the user must 
organize the data based upon certain topological properties of the scene. This involves, among other 
things, faces whose fixed priorities can be com­puted relative to each other. The effect is to reduce 
certain computational prob­lems for the algorithm. With a model of an entire universitycampus, this can 
be a horrendous task. The preparationof the data for the 12 buildings represent­ing the Cornell campus 
took 12 students one semester. The algorithm's speed is dependent upon such data representation and thus 
is not so general as most later algorithms. Another major system is the Watkins Box at Case Western 
Reserve University. The Watkins(5) solution to the visible sur­face problem for 3-D concave polyhedra 
was hard-wired by the Evans and Sutherland Corporation so that it can run in real­time. This system also 
includes hardware clipping, smooth shading, perspective calculation and light source calculation. The 
algorithm for clipping was developed by Sutherland and Sproull(6) while the one for smooth shading was 
developed by Gourand(7). The display system cost about $500,000 (the computer is extra) and is capable 
of displaying shaded objects in real-time. A real-time image may contain up to 2000 edges at 512 x 512 
resolution. Interesting results based upon the Watkins algorithm in software (including routines for 
clipping, per­spective and smooth shading) are the University of Utah films on the "Face" and the "Hand". 
The "Face", for instance, involved about 750 edges. It is inter­esting to note that although many hours 
of computer time were required to make films several minutes in length tradi­tional animation would have 
taken far longer. Perhaps the most spectacular single com­puter picture to be produced is MAGI's (MathematicalApplications 
Group, Inc.) tree. A calculation at 500 x 500 resolu­tion of a 3-D deciduous tree in color with hundreds 
of leaves took nearly three hours on an IBM 360/65(8). MAGI's(9) algorithm has been used to produce some 
of the best'computer animated films. Staudhammer's(10) system at North Carolina State University approaches 
a real-time color video display for 3-D concave ob­jects. Using another implementationof the Watkins 
algorithm, he and his asso­ciates have hard-wiredthe scan segment conversion section of the algorithm 
to increase its speed. Objects of 2000 edges complexity typically take about 20-25 seconds with simple 
objects taking eight seconds. Staudhammer's system does not normally provide for clipping, smooth shading 
or perspective, but these features can be introduced at some cost in perfor­mance. As is the case with 
all known systems, the speed is also dependent upon the type of object selected. Significant­ly lower 
in cost than other systems, his approach has potential for widespread computer animation. There have 
been several attempts at anima­tion/graphicsprogramming languages with a concern for naturalness. An 
experimental effort of the Computer Graphics Research Group at O.S.U. produced the Graphics Symbiosis 
System (DeFanti)(11), and its derivative the Animation-Real-Time (ART) system. Both of these, providing 
an easy to use language syntax, are for users who have little or no programming experience. One can quickly 
learn how to build pic­tures, use picture manipulation commands (move, scale, rotate, warp, group, hide, 
etc.) and to write programs in the lan­guage. These systems can be easily used to make film and video-tape. 
After accom­plishing these initial goals, it was noted that it is sometimes difficult for users to produce 
animation sequences to their liking. Analysis indicated that the easy to use nature of the systems enables 
users to go from naive to sophisticated so quickly that they overreach the systems capabilities. Thus, 
the current challenge is to retain some aspects of naturalness and real-time response and to build a 
lan­guage and system with powerful algorithmic features. II. AN ANIMATION ENVIRONMENT The Computer 
Graphics Research Group is in the process of constructing major portions of an animation environmentintegrated 
under the RSX-11/D multitaskingoperating system on a PDP-11/45 minicomputer. Por­tions selected to be 
implemented are either essential or are currently suitable for research. It seems clear that it is not 
yet time for a complete production system althoughwe will ultimately use the environment described here 
as a production system. This procedure which was also used with our prior systems (IBM 1130 pro­grams, 
GRASS and ART)(11) is guaranteed to show what significant research problems remain. A. VISIBLE SURFACE 
SYSTEM The essential basis of the best known real-time graphics systems is a signifi­cant algorithm 
which handles the visible surface problem. The requirements of complex algorithms such as hidden line 
 removal and visible surface calculation are so great that language designers tend to suggest that such 
algorithms must be hard-wired. Since it is so difficult to obtain a sufficiently efficient implemen­tation, 
they sometimes claim that the super-fast computers have not arrived to handle such problems in software. 
For example, in the particular case of the visible surface problem, one expert has stated "hidden surface 
algorithms take too long to compute to be useful in a real-time system"(12). What many people believe 
can only be accomplished in hard­ware, has now been achieved on a mini­computer in software. Allan Myers, 
of O.S.U.'s Computer Graphics Research Group has designed and imple­mented a major new visible surface 
algo­rithm for concave polyhedra. It is based on some of the latest programming tech­niques including 
structured programming* and it solves (actually avoids) the sort­ ing problem as expressed by Ivan Sutherland(13), 
et al. This algorithm functions by efficiently accomplishing the work to be done as opposed to using 
time consuming strategies to avoid this work, as is the case with previous algo­rithms. Thus, it represents 
the first of a new class of algorithms. Myers' technique does not place a heavy burden upon the user 
for data representa­ tion as is the case with the Schumacker and Newell algorithms. Unlike any other 
known algorithm its computation time grows as a function no worse than linear as the number of faces 
increases. Implemented** on a PDP-11/45 minicomputer under the RSX-11/D multitaskingoperating system 
in a 32K (16 bit word) main memory partition, it can manage over 24 frames per second for small simple 
concave objects at 512 x 512 resolution. This includes clipping, perspective and smooth shading. The 
routine can manage over ten frames per second for multiple simple  objects with independenttransformations. 
The routine is not assisted by any special purpose hardware and uses only the point plotting, auto-increment, 
Z depth cuing and subroutine stack capabilities of the Vector General 3-D display. The routine is capable 
of displaying an image of up to ten thousand edges* from the 32K partition which contains the algorithm,data 
and free space**. Although complicated and/or large objects cannot be displayed in real­time, an image 
of five to ten thousand edges can be displayed in as little as several seconds. Further, scenes of reasonable 
complexity can be displayed in real-time at 100 x 100 resolution. At this resolution the user can make 
basic judgements about objects in terms of their position, intensity, speed of motion, clipping, etc. 
After achieving the de­sired visual effects, he can film the sequence at a higher resolution. Note that 
this is practical using Myers' aolo­rithm because the computation time de­creases as a function greater 
than linear as the resolution decreases. The routine was designed with the scien­tific experimenter 
in mind and includes the following capabilities: A. Scene Structure 1. Multiple objects per scene. 
 2. Multiple surfaces per object.  3. Multiple faces per surface.  B. Image Quality*** 1. Clipping 
on a scene (a new, efficientmethod).  2. Perspective on a scene.  3. Smooth shading of surfaces (if 
desired).  4. Variable transparency of surfaces (not in real-time).  5. Three independentgray scales 
(each of 2048 levels) for color during filming (the average is displayed for direct viewing).  6. Face 
intensities based on the angle between the light source and the face (if desired).  C. ManipulationCapabilities 
 1. Scaling of objects.  2. Rotation of objects.   3. Translation of objects.  4. User specified 
face intensities (if desired).  Although interesting in itself, the algo­rithm with all of its capabilities 
does not satisfy our primary research goal. This is to make powerful algorithmic graphics capabilities 
available to the scientific research in a natural and flexible manner. Consequently,the kernel of a 
graphics language to be called VILAN (pronounced 'vl-lan) will be designed and implemented to allow a 
researcher the use of a sophisticated "solid" object manipulation and display capability. B. GRAPHICS 
SUPPORT SYSTEM We have a sophisticated graphics support system consisting of a privileged task and several 
device handlers under RSX-11/D. The graphics subsystem consists of four major components. These are, 
(i) the display driver and interrupt service rou­tine, (ii) a refresh buffer, (iii) a communicationarea, 
and (iv) a subroutine library. If required, independent access is available to the user to each of these 
components. The general user, however, interfaces to the graphics subsystem through the driver and treats 
the display as an I/O device. This system greatly facilitates hardware control, data structure manipulation, 
memory management for the graphics buffer, and the management of transformations and time. It should 
be noted that the graph­ics support system in and of itself pro­vides more graphics capabilities than 
most graphics languages. C. ANIMA We have completed the detailed design specifications for a new graphics 
pro­gramming language called ANIMA and we are in the process of implementing it. The language has been 
designed for the scien­tific researcher who can use real-time animation and film as a research tool. 
Our conception of a graphics programming language is very inclusive with a full range of facilities, 
support algorithms, graphics algorithms, a compiler, power­ful numeric capabilities, a generalized list 
structure for data, and other features not usually found in graphics languages. We plan to use 32K* (16 
bit words) of main memory for the lan­guage and support algorithms and we already use 32K for picture 
buffer space. While it is beyond the scope of this paper to describe details, a few important fea­ 
tures will be identified. We have devised  95 a systematic method for the specification of the common 
transformationswhich are essential for basic object manipulation capabilities. Our format for handling 
a general class of transformations is dif­ferent from the typical method which is to develop a package 
of transformationmatrix generating subroutines. Within our lan­guage transformationsmay be specified 
by expression definitions which are re-eval­uated for every regeneration cycle. The implications of 
our method are important relative to reduced overhead costs in response time, the options and the facil­ities 
provided for the user, and the terms in which the user develops a solution to his problem. It is extremely 
difficult to appreciate the difference this makes with respect to the user actually being able to accomplishwhat 
he wants to do with a reasonable amount of effort. The language is designed so that within a single 
"motion command" capabilities exist which include the following: limits, and mode. Limits specify the 
limits of the motion; mode specifies the action to be taken upon reaching the limits. Mode includes 
such things as repeat action, reverse action and halt. For instance, a requirement in a real-time animation 
environmentmight involve a 3-D shaded butterfly flapping its wings as it moves in 3 dimensional space. 
The flapping might be accomplishedby means of a rotate command per wing with appropriate limits and with 
an appropriate mode specification to indicate whether the movement should restart, reverse or stop when 
the limit is reached. In a real-time environment there are many instances where one must re-evaluate 
the parameters that modify transformations. Using analog input devices as well as variables and invoking 
programs to make the necessary changes in the motion se­ quence, the problem is a complex one. Everything 
cannot be re-evaluated in real­ time, but we have devised a method of notation for the specificationof 
contin­ uous motion. For example, ".ROTATE NOSE,5, rotated a constant 5° about the X axis and @(7*A)" 
where the picture "NOSE" will be a variable amount about the Y axis speci­ fied by "7*A" which is re-evaluated 
for every display regeneration using the current value of A. Note that including a local clock in 
the re-evaluatedexpression produces continuous motion. If the above specificationswere ".ROTATE NOSE,5, 
 @(7*.F)" then the picture "NOSE" will be rotated about the Y axis by an angle de­ pending upon the 
current "frame clock" .F. This expression is re-evaluatedon every regenerationcycle. TIME MANAGEMENTAND 
TRACKING FACILITY IN ANIMA The scientific researcher in a real-time animation system requires accurate 
and repeatable images on the graphics display. It is necessary for the user to perceive the dynamics 
of a model correctly if it is to be a research tool. There are many algorithms that exceed the capacity 
of the computer to calculate and display pictures at a real-time rate. Conse­quently, time management 
will often be a significant problem: it will often be time to display the next "frame" well before the 
required computations for the frame are complete. Traditional methodology for time manage­ment involves 
system clock support. The usual implementationof such support in­volves timer queues and communication 
between the clock support component and the task scheduler. A significant short­coming of most implementationsof 
system clock support relative to real-time ani­mation is that there is no time-mapping-­there is no way 
to correlate "action time" with film frame number. There is also significant overhead involved with system 
clock support. We developed a technique for such support which is to be controlled by our graphics language; 
and this support is embedded in the graphics system itself. A tracking facility, which depends very 
heavily on time management,has the fol­lowing capabilities: (1) the ability to dynamically record in 
real-time suffi­cient information to replay the totality of the visual effects produced originally; 
(2) the ability to dynamically modify in real-time and under user control the play­back of a previous 
track thus producing a new track, for example, adjust the rota­tion of one particular object over one 
particular span of time; (3) explicit commands designed to perform often-desired effects, essentially 
a superset of editing and similar operations performed on film; for example, inserting fades, combining 
 ("splicing") tracks, modifying time rela­tionships, etc.; and (4) the capability of putting a track 
on film with the visual effects essentially unmodified. D. DATA GENERATION SYSTEM One of the major 
problems remaining in computer animation is data generation or data input of three dimensional objects. 
 One input technique uses a physical model, for instance, a plaster cast of a head, covered with lines 
establishing convex polygons and then set upon a digitizing table(14). The user applies an electronic 
 probe to the vertices of the polygons, in an order suitable for a shade algorithm, and the three dimensional 
coordinate data is automatically recorded on cards or tape. Sutherland(15) describes an input technique 
using two electronic pens se lecting coordinate data from a draftsman's representation of several views 
of a three dimensional object. The multiple pens enable the user to indicate a single point simultaneously 
in two such views, thus defining the three dimensional position of a point. Provided that one has the 
blue­ prints, this is very useful for a repre­ sentation of a model to a shade algorithm. However, in 
the typical case with animat­ ors the object is usually just something in their imagination. At best 
there may be a few rough sketches of the model on paper with many details missing. There have also 
been research efforts to use a laser beam scan of a physical model for the automatic recording of data. 
This technique has the problem of excessive data, and more importantly getting the system to recognize 
sub-pictures or bound­aries, for instance, in a human head--eyes, ears, or a nostril. Techniques of arti­ficial 
intelligence and pattern recognition are also being applied to the data gener­ation/input problem. It's 
an intriguing approach,but the results at best are tentative and there are horrendous problems to be 
solved before such techniques become practical. One suspects that some aspects of the data generation 
problem are likely to be solved much sooner using more straightforwardmethods. Other methods employ 
mathematical tech­niques to generate basic forms such as polyhedra or quadric surfaces and planes. These 
forms are combined to construct a model of a car, tree, tank, building, etc. Although these methods have 
produced beautiful representationsof various objects, they are not general enough to meet the needs of 
different animators. We need methods that are somewhat analogous to the sculptor working in clay to 
create three dimensional models. One should have the freedom to quickly describe arbitrary surfaces, 
to smooth one surface into another one in order to establish conti­nuity, to add to or subtract from 
small sections of surfaces, to stretch, twist or even squeeze a form with kinesthetic feed­back--essentiallyto 
shape it into the final form. Then with simple commands one should be able to specify the color, the 
texture and the degree of transparency of surfaces. The analogy of the sculptor's approach to data 
generation is an artist's fantasy in working with computers and one which usu­ ally brings gales of 
laughter from soft­ ware designers and systems programmers (not ours). Obviously, when the user's data 
generationproblem involves an inter­ active process and there is no formal model, then the software 
requirements become very complex. The communication problem between man and machine in an interactive 
graphics environment is still a challengingone. Much of this inter­ action depends upon the kinds of 
defini­ tions that can be permitted by the soft­ware. One must be concerned about approaches to data 
structures, the type of interactive language to be used, the relationshipbetween the data structures 
 and the language and the mathematicaland algorithmic techniques to be used. Data generationwill be 
another system, running under RSX-11/D and our graphics support system, which will exploit a three dimensional 
sonic pen with a special interface. Dr. Leslie Miller of our group has developed some algorithms to easily 
create surfaces. These are tech­niques to build three dimensional curvilinear forms and to add surfaces 
together and through interpolation tech­niques provide for smooth continuity. When the user is finished 
his forms are automaticallyput into a format for visi­ble surface calculation. Although Miller's approach 
has promise for a reasonablygeneral class of forms, con­siderable work remains before it might be considered 
a system. Eventually,when files are created with the data genera­tion system, they will be transferable 
to either the ANIMA system or Myers' shade system (VILAN). III. DISPLAY HARDWARE DESIGN AND ALGO- RITHMS 
 As one considers how to integrate graphics algorithms into a language, and how to order transformations 
to optimize speed in relationship to a graphics display, one clearly recognizes that display de­signers 
did not have animation in mind when they built current hardware. Al­ though film is made with these 
systems, the dollar market is with customers who need assistance for drafting problems, circuit diagram 
design and other engi­ neering applications. These are usually applications where there is a requirement 
 for displaying large amounts of data with "occasional" small changes to this data. Typically, the 
display designer's approach to transformationshas serious drawbacks for real-time animation. Even the 
most general state of the art hardware imple­mentation (microprogrammedor digital transformations and 
read-back) is not general enough to permit certain algo­ rithms to efficientlyuse the capabilities 
representedby the hardware. Myers' visible surface routine is a specific example of an algorithm requir­ 
ing calculations in an order different from that assumed by the display designer. The algorithm needs 
to do the transforma­ tions of the objects before most of the processing. In the case of a micropro­grammed 
display, there are two ways one might attempt to use the capabilities it represents. The first is to 
use it to do the transformations. This has the diffi­ culty that transferring the relevant information 
back and forth between the general purpose processor and the display consumes a significant proportion 
of the time that was to be saved. The second way is to use it to perform the final phase of the algorithm. 
There are two difficulties with this second alternative: the display was optimized for transformationsand 
is now being used for something else, and it may well have insufficientmemory or no memory at all to 
perform the algorithm that was intended. In the case of hardware with digital trans­ formations and 
read-back, there is one of the same problems as with the micropro­ grammed hardware. This problem is, 
once again, that transferringthe relevant information back and forth between the general purpose processor 
and the display consumes a significant proportion of the time that was to be saved. Note that for 
almost all practical purposes, the display hardware cannot be used to effectively implement any algorithm 
except those for which it was originally designed. IV. HIGH PERFORMANCE ANIMATION/GRAPHICS Advances 
in computer technology are bring­ ing more powerful minicomputers with greater memory capacity, relatively 
low­ cost dynamically-alterable-horizontally­microprogrammedprocessors and displays, and microcomputers. 
In view of these developments it is important to re-examine the basic "black-box" premise under which 
high performance graphics has been operat­ ing. It should be possible to increase the generality and 
flexibility of graphics beyond the black-box approach. The black­box approach to graphics, epitomized 
by Sutherland, et. al., has long been the "right" way to do graphics. In the early stages of computer 
graphics it was the only way to achieve the performanceneces­ sary for real-time transformationssuch 
as clipping and perspective. Now there are minicomputers available which, in a relatively straightforward 
multiprocessor configuration,are capable of real-time graphic transformations for a moderate cost. For 
example, the following configuration (see illustration, next page) would, with current technology,provide 
performance of the same order of magnitude as special purpose hardware. Although the performance on tasks 
that are traditionally hard-wired (e.g., rotation, clipping) would be less, the performance on tasks 
 that are not hard-wiredwould be consider­ ably greater than the traditional single processor system 
with special purpose hardware. Note that in the black-box approach the special hardware is of no use 
except in the special cases, whereas a general purpose system (microprogrammedor otherwise) lacks only 
a program to be of use in any task. In the not too distant future it should be possible to equal or 
exceed the current MYERS' FANTASY MACHINE  capabilities of the hard-wired approach even in the special 
cases. For example, the Watkins shading hardware at Case Western Reserve University is capable of calculating 
in real-time the visible sur­ faces described by 2000 edges. The upper limit of the hardware with severe 
flicker is 4000 edges. Since this is a hard­wired implementationof a particular algorithm, and since 
the computation increases at a rate greater than linear, there is a fairly restrictive upper limit on 
the number of edges this hardware can handle in a reasonable amount of time. If, however, the algorithmwere 
not hard­wired, then there would be the possibility of increasing the buffer size and replac­ing the 
algorithm by a better one. One can anticipate the "graphics machine" in the preceeding diagram being 
expanded in parallel. By extending the same organization over and over it would be possible to allocate 
one graphics machine per picture, thus creating "intelligent pictures". Although such a configuration 
 is not currently very economical, the advent of low cost microcomputers and memory is rapidly making 
such approaches possible. ACKNOWLEDGEMENTS The author is indebted to Allan Myers, Manfred Knemeyer, 
Sam Cardman and Tony Lucido for their assistance on this paper, particularly their comments on the 
current status of ANIMA and their ideas on the state of current and future technology. The work of the 
Computer Graphics Research Group mentioned in the paper is supported in part by the National Science 
Foundation grant number DCR74-00768 A01. Allan Myers' Visible Surface Algorithm. The following pictures 
were produced using Myers'algorithm. There are several variables which deter­mine the calculation time 
of a particular picture.The most significant of these are the number of edges, the orientation of the 
object(s) and the areaof the faces (roughly measured by the size of theobjects). The table gives the 
average time per frame for a number of objects. The average is calculated as 256 256 1 zi+ 1 yi i=1 
i=1 512 where: Zi is the time for one "transform, calcu­ late and display" step of the 256 steps taken 
for one revolution about the Z axis. Yi is the time for one "transform, calculate and display" step of 
the 256 steps taken for one revolution about the Y axis. These times are for 512 x 512 resolution. The 
designation large means an object almost the size of the area displayed and small means 1/4 (in height) 
of large. Timings (averages for 512 different orientations at 512 x resolution.)   Mask "Mathematical" 
Surface Virtual intersection of an apple, mask and violin. 100 REFERENCES Three-DimensionalObjects", 
The 2nd Annual Symposium on Computer 1. Rougelot, Rodney S.; Schumacker, Robert--"G.E. Real-Time Display", 
Architecture (ACM-SIGARCH)Vol. 3, No. 4, December, 1974, pp. 23-27. NASA ContractNAS 9-3916, Defense 
Electronics Division, General Elec­ 11. National Science Foundation report tric Company, Syracuse, New 
York. 1972, "Real-Time Film Animation", see section I, "Graphics Symbiosis 2. Wild, C.; Rougelot, R.; 
and Schumacker,R. A., "ComputingFull Color Perspective Images", General Electric Technical Information 
Se- System", by T. DeFanti and The Computer Graphics Research Group (contact C. Csuri for copies). ries 
R71ELS-26, (May, 1971). Csuri, Charles, "Real-TimeFilm Animation", Proceedings of the Ninth 3. Greenberg, 
Donald, "ComputerGraphics Annual UAIDE Meeting, 1970. in Architecture", Scientific American, pp. 98-106, 
April, 1974. "Real-Time Computer Animation", Proceedings of the IFIP 4. Sutherland, Ivan E.; Sproull, 
Robert F.; Schumacker, Robert A., "A Charac- Congress 74, Stockholm, Sweden, pp. 707-711. North-Holland 
Publishing terization of Ten-Surface Algorithms", Company. Computing Surveys, Vol. 6, No. 7, March, 1974, 
pp. 1-55. Gillenson, Mark, "The Interactive Generation of Facial Images on a CRT 5. Watkins, Gary S., 
"A Real-Time Visi­ble Surface Algorithm", Computer Sci­ence, University of Utah, Technical Report UTEC-CSC-70-101, 
July, 1970. Using a Heuristic Strategy", Ph.D. Dissertation in the Department of Computer and Information 
Science, The Ohio State University, March, 1974. 6. Sproull, Robert F., and Sutherland, Ivan E., "A Clipping 
Divider", Pro­ceedings of the Fall Joint Computer Conference, pp. 757-764, Thompson Publishing Company, 
1968. 12. Clark, James H., "3-D Design of Free-Form B-Spline Surfaces", University of Utah, Ph.D. dissertationand 
NTIS report no. AD/A-002 736, September, 1974. 7. Gourand, Henri, "Computer Display and Curved Surfaces", 
University of Utah, UTEC-CSC-71-113, June, 1971 and IEEE, TC-20, p. 623. 13. Sutherland, Ivan E.; Sproull, 
Robert F.; Schumacker, Robert A., "Sorting and the Hidden-SurfaceProblem", Proceedingsof AFIPS 1973 National 
8. Brooks, Joan, et. al., "An Extension Computer Conference,Vol. 42, pp. of the Combinatorial Geometry 
Tech­ 685-693. nique for Modeling Vegetation and Terrain Features", MAGI, Inc., NTIS report no. AD-782883, 
June, 1974. 14. Sutherland, Ivan E.; Sproull, Robert F.; Schumacker,Robert A., "A Charac­terization of 
Ten-Surface Algorithms", 9. Goldstein, Robert A., "A System For Computer Animation of 3-D Objects", Proceedings 
of the Tenth Annual UAIDE Meeting, 1971, pp. 3-128-3-139. 15. Computing Surveys, Vol. 6, No. 7, March, 
1974, pp. 1-55. Sutherland, Ivan E., "Three-Dimen­sional Data Input by Tablet", Pro­ 10. Eastman, Jeffrey 
F.; Staudhammer, John; "Computer Display of Colored ceedings of the IEEE, Vol. 62, No. 4, pp. 453-462, 
April, 1974. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563747</article_id>
		<sort_key>102</sort_key>
		<display_label></display_label>
		<article_publication_date>04-01-1975</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Three-dimensional human display model]]></title>
		<page_from>102</page_from>
		<page_to>110</page_to>
		<doi_number>10.1145/563732.563747</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563747</url>
		<abstract>
			<par><![CDATA[A two-dimensional computer graphic display of a three-dimensional model depicting a human being is presented. The major body segments of the model are represented as non-uniform elliptic cylinders. The shadow outlines of these cylinders are displayed on the terminal screen and connected by circular arcs and straight lines to produce a realistic representation of a human being in any position.This human model was developed for the display of results of three-dimensional simulation programs which calculate the positions of an occupant during vehicle impact. However, it is well suited to any other type of human motion. The approach allows the user to select the viewing orientation and was designed for low cost computer and graphic terminal systems.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379805</person_id>
				<author_profile_id><![CDATA[81100200458]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Potter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Xerox Corp., Webster, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P322586</person_id>
				<author_profile_id><![CDATA[81100242029]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Willmert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Clarkson College of Technology, Potsdam, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Fleck, J. T., Butler, F. E., and Vogel, S. L., "An Improved Three Dimensional Computer Simulation of Motor Vehicle Crash Victims," Report No. ZQ-5180-L-1, Calspan Corporation, Buffalo, New York, July 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Potter, T. E., "Three Dimensional Human Display Model for Two Dimensional Computer Graphics," Department of Mechanical and Industrial Engineering, Clarkson College of Technology, Potsdam, N.Y., Report No. MIE-006, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563212</ref_obj_id>
				<ref_obj_pid>563182</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Willmert, K. D., "Occupant Model for Human Motion," Presented at the Conference on Computer Graphics and Interactive Techniques, Boulder, Colorado, July 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Dreyfuss, H., The Measure of Man, Whitney Publications, New York City, New York, 1960.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.Siggraph 
75 Bowling Green THREE-DIMENSIONALHUMAN DISPLAY MODEL by T. E. Potter Engineer Xerox Corp., Webster, 
New York and K. D. Willmert Assistant Professor Mechanical and Industrial Engineering Department Clarkson 
College of Technology, Potsdam, New York Abstract A two-dimensionalcomputer graphic display of a three-dimensionalmodel 
depicting a human being is presented. The major body segments of the model are represented as non-uniform 
elliptic cylinders. The shadow outlines of these cylinders are displayed on the terminal screen and 
connected by circular arcs and straight lines to produce a realistic representation of a human being 
in any position. This human model was developed for the dis­ play of results of three-dimensional simulation 
 programs which calculate the positions of an occu­ pant during vehicle impact. However, it is well 
suited to any other type of human motion. The approach allows the user to select the viewing orientation 
and was designed for low cost compu­ ter and graphic terminal systems. Introduction In simulating general 
three-dimensional motion of the human body, the normal approach is to represent each major body segment 
by a rigid member which is connected to its associated parts by appropriate joints. The positions of 
the seg­ ments are then determined relative to each other using proper kinematic or dynamic relationships 
 as well as internal muscle forces and external reactions which depend on the type of motion being 
simulated. This basically results in a stick model representationof the human being with body segments 
having mass and moment of inertia and joints having torsional springs, applied muscle torques, etc. 
There is generally little regard in these models to the actual shape of the body parts. The results 
of the simulation are simply the coordinates of the joints or cen­ ters of gravity of the body segments 
and direction cosine matrices correspondingto the orientation of each segment. From this information 
the posi­tions of the body could be displayed in stick form or using some other simple representations 
of the body segments. This approach was taken in displaying the positions of an occupant during the 
crash of a vehicle in the three-dimensional simu­lation program developed by Calspan Corporation [1]. 
In this work the body segments are represen­ ted as ellipsoids which results in a two­dimensional display 
similar to that shown in Figure 1.  In many applications, it is desirable to have a more realistic model 
of the human body that can be used to display the results of these simu­lation programs. This was the 
goal of the work presented in this paper. It was assumed that the coordinates of the centers of gravity 
and direc­tion cosine matrices of each body segment at all positions to be displayed were available, 
which generally would be generated by these simulation programs. Presented here is a means of taking 
this informationand constructing a realistic body around the individual segments, connecting them with 
realistic joints and displaying the resulting model on a two-dimensional computer graphic terminal. 
 The body segments of the three-dimensional display model developed in this work are repre­sented by 
non-uniformelliptic cylinders as shown in Figure 2. The edge lines of these cylinders viewed in an orthographic 
projection from any direction, which we shall call shadow lines, are drawn on the graphic terminal screen 
and connected  by circular arcs or linear type fits to form the required joints. This produces a realistic 
out­line of the human body for almost any position as viewed from any desired direction.  The Body 
Segments It is assumed in this work that the body of the displayed model is divided into fifteen seg­ments; 
lower torso, center torso, upper torso, neck, head, left and right upper legs, left and right lower legs, 
left and right feet, left and right upper arms, and left and right lower arms. This particulardivision 
was selected because it was used in the original representation of the human body in the crash simulation 
program developedby Calspan. Other divisions are pos­sible depending on the application. Each of these 
segments in the display model is repre­ sented by a common geometric shape which we refer to as a non-uniformelliptic 
cylinder, as The ends of this cylinder are parallel ellipses, whose major and minor axes are not 
necessarily the same. shown in Figure 2. Also the centers of the ellipses may be offset relative to 
each other. By adjusting the dimensions of this cylinder, all fifteen parts of the body can be represented 
 fairly realistically. The surface of these elliptic cylinders can be expressed mathematically in terms 
of the X", Y", and Z" coordinate system whose origin is at the center of gravity of the segment as 
shown in Figure 2. As functions of parametric coordinates s, 1, and t2 this surface is defined as: 
 The parametric coordinates are limted to the fol­lowing ranges:  In order that Equations (1), (2), 
and (3) define a proper surface, there must be a relationship be­tween tl and t2. This is found by 
assuming that as s varies from 0 to 1, i.e. from one end of the cylinder to the other, the slope of 
the surface dY"/dX" remains constant for given values of tl and t2. Equating this slope at the ends 
of the cylinder results in the equation (see reference [2] for more details):  where like quadrants 
map to each other. Equations (1) through (7) define the required surface of the non-uniformelliptic 
cylinder. The Shadow Lines In order to consider the orthographicpro­jection of the body segments onto 
the terminal screen, i.e. the shadow lines, we must define two additional coordinate systems. First, 
X', Y', and Z' as shown in Figure 3 define a body coordinate system fixed in space, or in the case of 
Calspan's crash simulation these coordinates are fixed on the vehicle and move with it. The motion 
of the body segments are defined relative to this system. It is assumed in this work that the location 
of the center of gravity and direction cosine matrix of each segment relative to this coordinate system 
 is available as data. In order to view the body from any direction a third coordinate system is This 
system is defined as shown in Figure 4.  attached to the screen of the graphic terminal. X and Y lie 
in the plane of the screen and Z is per­pendicular to it. The origin of this system and the body coordinate 
system and their orientation are generally different. The relative orienta­tion between the two systems 
is selected by the user to give different views of the body. The distance between the origins is defined 
so that the body appears approximately in the center of the terminal screen. For each body segment 
the surface of the non-uniformelliptic cylinder in the segment coordinate system is given by X", Y", 
and Z" in Equations (1), (2), and (3). This same surface in the screen coordinate system can be obtained 
from the equations:  where E = A D. The matrix D is the direction co­ sine matrix associatedwith the 
segment, and XCG, ZCG are the coordinates of the center of gravity of the segment, as shown in Figure 
3, relative to the body coodinate system. It is assumed in this work that D, X~G, Y6G, and ZCG are known 
values for each segment at all body posi­tions. The XT, YT' and ZT correspond to displace­ments needed 
to assure that the body appears approximately at the center of the screen. The matrix A can be written 
as:  where Ar, Ap, and Ay are roll, pitch and yaw matrices defined by:  and u, v, and w are roll, pitch 
and yaw angles which are rotations about the screen Z, X, and Y axes respectively. By selecting the angles 
u, v, and w the body can be viewed from any direction. We are now ready to determine the shadow lines 
of the body segments in the screen coor­dinate system. A vector normal to the surface of the elliptic 
cylinder can be determined from:  where r is the position vector to the surface. The values of the parameter 
t which results in the Z component of this vector being zero will produce the shadow lines. Thus:  The 
partial derivatives can be determined from Equations (8) using Equations (1), (2) and (3). The Z component 
of the normal is a function of both the axial parameter s and circumferential parameter t. For particular 
values of s, the equation = 0 will produce zero, one, or more z values of t, which, when substituted 
into Equa­ tions (1) and (2), will yield points lying on the outline of the shadow of the ellipse projected 
onto the screen. The outline of the elliptic cylinder, for most orientations, will consist of straight 
line segments, so it is only necessary to determine the end points of these shadow lines, which will 
occur at s = 0 and s = 1. At s = 0, the circumferential parameter t becomes tl as defined in Equations 
(1), (2), and (3). Thus, Equation (14) becomes:  Once tl is determined from this equation, the other 
end of the shadow line (i.e. at s = 1) can be determined from Equation (7). After some simplification,Equation 
(15) becomes:  However, in order to solve this equation for t,, we must eliminate t2. This can be accomplished 
 using Equation (7) which may be rewritten as:  Since and tmust lie in the same quadrant, 12 then 
the cosine of t2 can be obtained from:   Applying a standard procedure, the solution of this quartic 
equation can be determined in closed form. This yields a maximum of four pos­sible values of costl, from 
which eight values of  are obtained. These values are then substitu­ted into the modified form of Equation 
(16), i.e. after thas been eliminated, to remove extraneous 2 roots. Once the values of tl are determined, 
the coordinates of the end points of the shadow lines are easily calculated using Equations (1) through 
 (4) and (8) where the cost2 is determined from Equation (19) and sint2 from:  This results in a noniterative 
procedure for determining the shadow lines of the non-uniform elliptic cylinder body segments in terms 
of the screen coordinate system. The Connections Between Shadow Lines In order to achieve a realistic 
display, suitable connections between adjacent shadow lines would be desirable. Four types of connections 
have been developed which allow a reasonable dis­play to be obtained. The first type is a point to point 
connec­tion. It is simply a straight line connection between the end points of the two shadow lines which 
are to be joined together. A point to point connection is shown in Figure 5 where (X to 1) and (X2) 
to (X3,Y3) are the two shadow lines and 1) to 2,Y2) is the connection line.  The second type of connection 
is a clip and crease which is made when the two shadow lines, that are to be joined, intersect as shown 
in Figure 6a. The two shadow lines are (XO,YO) to  1) and (X2 2) to (X3,Y3), which are clipped at the 
intersectionpoint (X,Y) given by:  The third type of connection is a circular circular connection 
is made from (Xl,Y1) to arc fit as shown in Figure 7. This connection was adopted for the three-dimensionalman 
from the work on the two-dimensionalhuman model by Willmert [3]. Again, the two shadow lines are (XO,Y0) 
to 1) and (X2,Y2) to (X3,Y3). A (X4,Y4) and then a straight line segment from (X4,Y4) to (X2,Y2), where 
(X4,Y4) is determined so that the connectionhas the same slope as the shadow lines at 1) and (X2,Y 2). 
The equa­tions for the circular arc are:  106  If D3 = 0, which implies that one of the shadow lines 
is a single point, or 1 , which occurs when the shadow lines are parallel, a point to point connection 
is applied in place of the cir­cular arc connection.  4= The major modification of the two-dimensional 
fit developed in this work is the inclusion of the capability of drawing a circular arc for angles a 
 ° greater than . To do this, the absolute value of a is determined and the connection is drawn by varying 
8 in Equations (29) and (30) from zero to 180 , then: Alpha is determined by the relationship be­tween 
principle values of inverse trigonometric ° ° functions. If 0 <   then the intersectionpoint is 
beyond the shadow lines as shown in Figure 8a and la] is less than °  . Then  is determined from Equation 
(32). ° greater than 180 as shown in Figure 8b, and its value is determined from Equation (33). If 
E1 = 0, then lal is equal to 180 . If neither of these conditions are satisfied, then is °  107 
then the circular arc starts at (X2,Y2) rather than 1). If this occurs, the points (XO,Yo), 1), (X2,Y2), 
and (X3,Y3) are simply redefined so that the arc eminates from 1). A detailed flow chart for the circular 
connection is given in reference [2]. Normally, two shadow lines exist for a body segment, in which 
case one of the above connec­tions between segments is made. However, when zero, one, three, or four 
shadow lines exist for any one segment, which occurs when the Z" axis of the segment is perpendicular 
to the viewing screen, then a fourth type of connection is used. This consists of drawing the end ellipses 
of the seg­ment and ignoring all connections to adjoining body parts. This connection is also used when 
two shadow lines exist, but are short in relation to the true length of the segment, which results when' 
 Z" is nearly perpendicular to the screen. Selection of the point to point, clip and crease, or circular 
arc connection is based on the location of the intersection of the two shadow lines which are being connected, 
except when a body segment is connected to itself, as for the top of the head, where a circular connection 
is automaticallyused. If the intersectionpoint be­tween the shadow lines being connected occurs out­side 
the lines themselves, then a circular connec­tion is used. If on the other hand, the two shadow lines 
intersect somewhere along their length, a clip and crease connection is applied. In this case, a check 
is made to prevent the clip and crease connection from completely removing a shadow line, which occurs 
if the intersection point is at (XO,Yo) or (X3,Y3) as defined in Figure 6. When a shadow line is completely 
re­moved by a connection, it is no longer available for connection to a second adjacent body segment. 
 The check which is made on this is as follows: if the intersection between shadow lines lies between 
 the point (X5,Y5) defined by:  and the end point or if the intersection is between the point (X6,Y6) 
defined by:  and the end point (X3,Y3) where  is a given per­centage of the length of the shadow lines, 
then a circular arc, rather than a clip and crease con­nection is applied to the original shadow lines. 
If the two shadow lines being connected are paral­lel then a circular arc fit is used when the angle 
 ° a between them is and a point to point con­nection is applied if a is zero. For all remain­ ing situations, 
the point to point connection is applied. Reference [2] gives a detailed flow chart of the selection 
logic for the three main connections. Finally, the determinationof which of the two shadow lines for 
a segment is to be connected to the two shadow lines of the adjacent segment, is made by comparing the 
tl parameters that pro­duced the shadow lines. The set of shadow lines which are connected together 
are those with the most similar values of tl. A general connection routine has been des­cribed to complete 
the display model of the three-dimensional human being. Using this proce­ dure a realistic display of 
the human body in almost any position viewed from any direction can be obtained. Results Figures 9 
through 18 show a number of typical displays using the model described in this paper. Figure 9 shows 
a side view of a standing man be­fore the connection routines are applied. The  lines shown in this 
figure are the shadow lines of the non-uniformelliptic cylinders. The di­mensions of these cylinders 
were basically taken from Dreyfuss [4]. Figure 10 is the same view  of the standing man after the appropriate 
connec­tions between segments have been completed. Note how the clip and crease connection at the instep 
of the ankle, the point to point connection at the chin, and the numerous circular connections im­prove 
the appearance of the man over the unconnec­ted version shown in Figure 9. Figure 11 is a back view 
of the same standing man which shows an example of the display of the end ellipses of the feet. This 
is a result of the segment Z" axis  ° screen Y axis, is 90 in Figures 9 and 10, pro­ducing a side view, 
while it is zero in Figure 11 giving the back view of the model. Figures 12, 13, and 14 are three views 
at different yaw and pitch angles of a man seated in a vehicle in a position similar to the one in the 
ellipsoidal display shown in Figure 1. As can be seen, these three displays are much simpler and clearer 
than the ellipsoidal representationused by Calspan.  Figures 15 and 16 show the shadow lines of the 
side view of an occupant at two instances of time in a 15 mph crash obtained from the Calspan simulationprogram. 
Figures 17 and 18 show the connected views of 15 and 16 respectively. Al­though an extra circular connection 
is apparent at the hip joint in Figure 18, it is internal to  Conclusions The three-dimensionalhuman 
display model developed in this work can be used to produce realistic views from any direction of a man 
in any positionon a computer graphic terminal. The model is quite suitable for small computers using 
inexpensive graphic terminals. Further details concerningthe model can be obtained from Potter [2]. 
 Additional work on this model is needed in several areas, The most fruitful would involve further investigation 
of the connectionsbetween body segments--perhaps developing some kind of three-dimensionalconnections, 
and the removal of hidden lines. Acknowledgment The authors would like to express their appre­ciation 
to the Office of Naval Research for their support of this research at Clarkson College of Technology 
through Contract No. N00014-70-A-0003­ 01. References: 1. Fleck, J. T., Butler, F. E., and Vogel, S. 
L., "An Improved Three Dimensional Computer Simula­tion of Motor Vehicle Crash Victims," Report No. ZQ-5180-L-1, 
Calspan Corporation, Buffalo, New York, July 1974. 2. Potter, T. E., "Three Dimensional Human Display 
Model for Two Dimensional Computer Graphics," Department of Mechanical and Industrial Engineering,Clarkson 
College of Technology, Potsdam, N.Y., Report No. MIE-006, 1975.  3. Willmert, K. D., "Occupant Model 
for Human Motion," Presented at the Conference on Compu­ter Graphics and Interactive Techniques, Boulder, 
Colorado, July 1974.  4. Dreyfuss, H., The Measure of Man, Whitney Publications,New York City, New York, 
1960.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563748</article_id>
		<sort_key>111</sort_key>
		<display_label></display_label>
		<article_publication_date>04-01-1975</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[A special-purpose computer system for on-line generation and display of "random-dot" stimuli for stereoscopic vision experiments]]></title>
		<page_from>111</page_from>
		<page_to>114</page_to>
		<doi_number>10.1145/563732.563748</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563748</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379799</person_id>
				<author_profile_id><![CDATA[81100283959]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Harry]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Wyatt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Physiology and Biophysics]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39030521</person_id>
				<author_profile_id><![CDATA[81100164786]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Ellis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Systems Laboratory, Washington University, St. Louis, Missouri]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Julesz, B., Foundations of Cyclopean Perception, University of Chicago Press, Chicago, 1971.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Clark, W. A., and Molnar, C. E., "Macromodular Computer Systems", In Computers in Biomedical Research, edited by R. R. Stacy and B. R. Waxman, Academic Press, New York, 1974, Vol. 4, p 45.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Franklin, M., and Sadeh, E., "A Macromodule Shift Register Random Number Generator", Technical Memorandum 159, Computer Systems Laboratory, Washington University, St. Louis, Missouri, May 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A SPECIAL-PURPOSE COMPUTER SYSTEM FOR ON-LINE GENERATION AND DISPLAY OF "RANDOM-DOT" STIMULI FOR STEREOSCOPIC 
VISION EXPERIMENTS Harry J. Wyatt, Department of Physiology and Biophysics Permission to make digital 
or hard copies of part or all of this work or personal or classroom use is granted without fee provided 
that copies are not made or distributed for profit or commercial advantage and that copies bear this 
notice and the full citation on the first page. To copy otherwise, to republish, to post on servers, 
or to redistribute to lists, requires prior specific permission and/or a fee.Siggraph 75 Bowling Green 
with Robert A. Ellis, Computer Systems Laboratory Washington University, St. Louis, Missouri Depth 
Perception and "Random-Dot" Stimuli observer capable of stereopsis. To construct a There are a number 
of ways in which we can typical stimulus of this class, the left eye view tell, visually, the absolute 
or relative distances of Figure 1 is covered with a random pattern of of objects from us. The most importantway 
is dots. Then to make the right eye view, all dots stereopsis: in stereopsis, the brain interprets falling 
within the boundaries of the stripe are the slight differences between the views of the shifted left 
by the amount that the stripe is world through the left and right eyes to reveal shifted left in the 
right eye view. The dots in the relative distances of objects in the field of the left eye view which 
are "covered" by this view. An example of how stereopsisworks is shift, are omitted from the right eye 
view, and shown in Figure 1: the "hole" createdby the shift is filled up with some more randomly arranged 
dots. Finally, the boundary lines in Figure 1, that were used in making these dot stimuli, are erased, 
and we have constructeda "random-dot stereogrampair". A normal observer who looks only at one or the 
other eye view cannot see the stripe, as he could in Figure 1, but when the two views are put to- When 
the brain puts together the left and right gether ("fused") into a single image, a stripe of eye views 
into a single picture, the shaded dots stands out in depth from the background of stripe is seen as standing 
out in front of the dots. A more detailed picture of the manipula­background. In effect, in the left 
eye view tions used to construct the random dot patters is one sees more background "around the left 
side" shown in Figure 2 for a grid of 7 x 17 elements, a of the stripe, as if it were in front of the 
bar width of 4 elements, and a lateral shift background, and one sees "around the right side" between 
patterns of 2 elements. Each square in the in the right eye view. grid is a possible dot position. Julesz 
(1) devised a type of stimulus which If an observer views a succession of random­may be seen as three-dimensional 
only by an dot stereograms with, say, successive shifts in  the position of the stripe seen in depth, 
the percept is a stripe changing position in time.  Computer System A special-purpose computersystem 
has been constructed, using digital hardware macromodules (2), to generate and display random-dot stereo­gram 
pairs in real time on a pair of oscillo­scopes. Macromodules are register-transfer modules which may 
be easily interconnectedby the electronically-naive user to form arbit­ rarily complex digital systems. 
Problems of timing, loading, signal deterioration,etc., have been solved by the designers of macromodules 
such that the user is presentedwith a situation where the design and implementationof a digital system 
is only an exercise in logic. A flow chart for the system is shown in Figure 3. The heart of the system 
is a pseudorandom number generator which generates 12-bit random numbers (3). A high degree of randomness 
is not neces­ sary for this system. Given an initial setting, the random number generator will generate 
a sequence of random numbers on repeated entry at Entry 1 (Figure 3), it will regenerate the same sequence 
if a single entry at Entry 2 is followed by repeated entry at Entry 1, and it will gener­ ate a new sequence 
(whichcan be repeated) if a single entry at Entry 3 is followedby repeated  Once a random number has 
been produced, the 12-bit number is split into a 7-bit x co-ordinate and a 5-bit y co-ordinate. Thus, 
the random co-ordinates generated are converted to points on a 3210 x 12810 grid. The randomly-generated 
point co-ordinates are then tested to see if the point lies in the following zones: (a) in the bar to 
be seen in depth: in this case, the point is displayed on the left screen and also shifted left  positions 
and displayed on the right screen, (b) in the area "covered on the right screen by shifting the bar left: 
in this case, the point is displayed on the left screen only, (c) in the 5 columns at the extreme right 
of the grid: these are set equivalent to the columns in the "hole" created on the right screen, and 
points in them are displayed on the right screen only, after changing the x co-ordinate to lie in the 
"hole", (d) points not in (a), (b), or (c) are dis­played on both screens as generated. The remaining 
control features are tests to see if the preset number of dots has been dis­played. If it has, the pattern 
may be repeated by entering the random number generator at Entry 2, or a new pattern may be generatedby 
using Entry 3. Usually, a new pattern is combined with a change in the position of the bar seen in depth. 
If this is the case, an observer sees a bar in depth which changes positions with successive pattern 
presentations. Since successive patterns are uncorrelated, the systematic motion is not visible unless 
the observer has binocular depth perception. This type of display has been called a "dynamic" random-dot 
stereogram by Julesz (1). In the system used, the trajectory of this bar was either an oscillatory or 
a sawtooth motion. However, by interfacing the system with a small computer, it would be possible to 
generate more complex motions. The control pattern could then be set by the computer, and the individual 
random dot stereograms could be generated by the macro­modules. The particular advantage of using macro­modules 
for generating random-dotstereograms is their speed, due partly to a fast display system (about 3.4 usec. 
is required to load the co-ordinates and intensify a point on an oscil­loscope), and partly to their 
suitability for parallel processing pathways. The system described, even with some added pathways which 
are used to control a movie camera, generates and displays a pair of 3210 x 12810 dot patterns on a 
 3210 x 12810 point grids in 0.046 sec. This means that the patterns may be examined on-line without 
excessive flicker, and the parameters (e.g., number of dots, number of cycles of the same pattern, trajectory 
of the bar seen in depth) may be adjusted, and the results examined in real time. Statistics Since the 
positions of points to be dis­ played are selected randomly with replacement, the probability that a 
point will have a dot displayed m times during the display of one pat­ tern is given P(m)= (Pm)= 
where N = number of grid points, and n = number of dots displayed in one pattern. So, for a pattern 
of 3210 x 12810 points displayed on a 32 x 128 grid (n = N), on the average 37% of the grid points will 
be blank, 37% will have a dot displayed once, 18% twice, 6% three times and so on. This has the effect 
of creating a number of different spot brightnesses, which tends to facilitate the task of fusing the 
stereogram pair (1). Display For on-line display, the two screens were superimposedwith a half-silveredmirror. 
The transmitted screen was plane polarized with the E-vector horizontal and the reflected screen with 
the E-vector vertical. These may be viewed as is, with polarizing spectacles, or a quarter-wave plate 
may be introduced, after the beams are combined, to produce oppositely rotating circu­larly polarized 
light which can then be separated with spectacles made of quarter-wave plate plus polarizer. Off-line 
display has been accomplished with movies, by means of an Arriflex 16-S/B 16mm movie camera which can 
be interfaced with the macro­modular system. Movies can be made in two ways, either as two-color anaglyphs, 
superimposed on color film, for viewing with colored spectacles, or as black and white movies with the 
screens photographed in a non-superimposed configuration. In the latter case, some optics must be added 
for projection with standard equipment. For 16 frame/ sec projection, each pattern is usually reproduced 
on two successive frames so that the change rate is 8 patterns/sec. This was selected as a change rate 
which allows for rapid but smooth shift of the position of the depth stimulus while still producing a 
strong sensation of depth. We are using these stimuli as test stimuli for studying depth perception in 
children and subjects with deficiencies in their binocular vision. Acknowledgements We acknowledge the 
extensive help with the computer system given by George L. Bickmore, Computer Systems Laboratory, Washington 
Univer­ sity; and the support to H.J.W. by Nigel W. Daw, Physiology Department, Washington University 
Medical School, during the period of this research. Support This research was supported by the National 
Institutes of Health Grant Numbers EY-00053 and RR-00396. References (1) Julesz, B., Foundations of Cyclopean 
Perception, University of Chicago Press, Chicago, 1971. (2) Clark, W. A., and Molnar, C. E., "Macromodular 
Computer Systems", In Computers in Bio­medical Research, edited by R. R. Stacy  and B. R. Waxman, Academic 
Press, New York, 1974, Vol. 4, p 45. (3) Franklin, M., and Sadeh, E., "A Macromodule Shift Register Random 
Number Generator", Technical Memorandum 159, Computer Systems Laboratory, Washington University, St. 
Louis, Missouri, May 1972. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138358</article_id>
		<sort_key>115</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[A terminal-oriented clinical record system]]></title>
		<page_from>115</page_from>
		<page_to>135</page_to>
		<doi_number>10.1145/563732.1138358</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138358</url>
		<abstract>
			<par><![CDATA[The key to physician acceptance of computer-based clinical record systems lies in the development of comprehensive record systems providing rapid data input, retrieval, and interaction for the physician. Comprehensiveness is important to avoid duplication of record media in computerized and paper forms. Input and retrieval speeds must be competitive with traditional manual or dictation techniques so that productivity of the physician may be maintained or enhanced rather than degraded.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14014638</person_id>
				<author_profile_id><![CDATA[81100005286]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ben]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[Williams]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Regional Health Resource Center, Urbana, Illinois]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P789646</person_id>
				<author_profile_id><![CDATA[81314488354]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Regional Health Resource Center, Urbana, Illinois]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14277943</person_id>
				<author_profile_id><![CDATA[81100622896]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Schultz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Regional Health Resource Center, Urbana, Illinois]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P789643</person_id>
				<author_profile_id><![CDATA[81314489282]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Roger]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Johnson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois, Urbana, Illinois]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Sherman, Herbert, D. E. E., "Computer Mapping of Disease Data - Costs and Benefits," A FIRST ILLINOIS CONFERENCE ON MEDICAL INFORMATION SYSTEMS, University of Illinois, Urbana, October 17 & 18, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bitzer, D. and Skaperdas, D., "The Design of an Economically Viable Large-Scale Computer-Based Education System," Computer-Based Education Research Laboratory, University of Illinois, Urbana.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Stifle, Jack, "The PLATO IV Architecture," CERL REPORT X-20, Computer-Based Education Research Laboratory, University of Illinois, Urbana.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Stifle, Jack, "The PLATO IV Student Terminal," CERL Report X-15, Computer-Based Education Research Laboratory, University of Illinois, Revised, January, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Weed, Lawrence, M. D., in <u>The Problem Oriented System</u>, Hurst, J. W. and Walker, H. K., (ed.), Medcom Press, 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Wolff, Heinz, INTERNATIONAL CONFERENCE ON ENGINEERING IN MEDICINE, Davos, Switzerland, September 18, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[<u>Diagnotes</u>, Lufkin Medical Laboratories, Minneapolis, Minnesota, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hall, J. H. and Robbins, L. C., <u>How to Practice Prospective Medicine</u>, Methodist Hospital of Indiana, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Kiely, J. M., Juergens, J. L., Hisey, B. L., and Williams, P. E., "A computer-Based Medical Record: Entry of Data from the History and Physical Examination by the Physician," <u>JAMA</u>, <u>205</u>: 571--576, 8/19/68.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Stone, M., Bloemer, R., Feretich, R., and Johnson, R. L., "An Intelligent Graphics Terminal with Multi-Host System Compatibility," COMPCON 74, No. 9, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Gordon, Burgess L., "The Problem of the Medical Record," <u>Trans., Am. Acad. Opth. & Otolaryn.&lt;&lt;</u>, <u>75</u>:1113--1119, 1971.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Gordon, Burgess L., "Regularization and Stylization of Medical Records," <u>JAMA</u>, <u>212</u>:1502--1507, 1971.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Johnson, R. L., and others, "The Use of Intelligent Terminals in Computer-Based Medical Information Systems," (to be published).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138359</article_id>
		<sort_key>136</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[Display of electrical wave forms from the heart]]></title>
		<page_from>136</page_from>
		<page_to>136</page_to>
		<doi_number>10.1145/563732.1138359</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138359</url>
		<abstract>
			<par><![CDATA[Full text of paper to appear in a subsequent issue of Computer Graphics]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P343324</person_id>
				<author_profile_id><![CDATA[81100610865]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[B.]]></middle_name>
				<last_name><![CDATA[Warren]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pediatric Cardiology, Duke University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14275497</person_id>
				<author_profile_id><![CDATA[81100069918]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Barr]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pediatric Cardiology, Duke University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P330359</person_id>
				<author_profile_id><![CDATA[81100350126]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[G.]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Herman-Giddens]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pediatric Cardiology, Duke University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14278010</person_id>
				<author_profile_id><![CDATA[81100493782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Spach]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pediatric Cardiology, Duke University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138360</article_id>
		<sort_key>137</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[A computer graphics system for modular building elevation design]]></title>
		<page_from>137</page_from>
		<page_to>147</page_to>
		<doi_number>10.1145/563732.1138360</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138360</url>
		<abstract>
			<par><![CDATA[This paper describes a computer graphics system which has been developed to produce Modular Building Elevation Designs (MODBED) in support of the architectural designer in a time sharing environment. This system is only a small part of a Master Control System in Architecture (MCSA), see Fig. 1, which will benefit the architectural profession and construction industry by cutting time and cost on construction projects.Also discussed are the advantages and disadvantages of various input-output environments; batch processing and interactive display devices are compared.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P607930</person_id>
				<author_profile_id><![CDATA[81100445216]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[Warren]]></middle_name>
				<last_name><![CDATA[Collins]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois at Chicago Circle, Chicago, Illinois]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Csuri, C., "Real Time Film Animation", Annual report to the National Science Foundation Office of Computing Activities, Grant Number GJ-204, January 1, 1972 to January 1, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M. and Sproull, R. F., &lt;u&gt;Principals of Interactive Computer Graphics&lt;/u&gt;, McGraw-Hill, New York, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Prince, M. D., &lt;u&gt;Interactive Graphics for Computer-Aided Design&lt;/u&gt;, Addison-Webley, Massachusetts, 1971.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138361</article_id>
		<sort_key>148</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[Computer aided design of sculptured surfaces]]></title>
		<page_from>148</page_from>
		<page_to>159</page_to>
		<doi_number>10.1145/563732.1138361</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138361</url>
		<abstract>
			<par><![CDATA[Have you ever designed a molded product with one or more intricately curved surfaces? If you did, chances are that you had a difficult time getting the idea on paper and communicating to those who would manufacture it. This dilemma does not have to be one if innovative and relatively easy mathematical computer techniques are applied, One does not have to be a super mathematician or programmer to implement the methods described here.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14278047</person_id>
				<author_profile_id><![CDATA[81332527744]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Simon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Digital Equipment Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Parslow, R., D., &lt;u&gt;Advances in Computer Graphics&lt;/u&gt;, Plenum press, London, 1971.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Armit, A., P., "A Multipatch Design System For Coons' Patches", IEEE International Conference On Computer Aided Design, Conf Publ., 51, Southampton, April 1969.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Prince, David, &lt;u&gt;Interactive Graphics For Computer Aided Design&lt;/u&gt;, Addison-Wesley Publishing Co., Reading, Mass., 1971.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>889976</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Coons S., "Surfaces For Computer Aided Design Of Space Forms," MAC-TR41, MIT 1967.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Forrest, A., R., "Curves And Surfaces For Computer Aided Design," Doctoral Dissertation, University Of Cambridge, July 1968.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Simon, Richard, L., "A Sculptured Surface Program You Can Write Yourself," Machine Design, August 6, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Albert, David, "New, Low-Cost Interactive Graphics," Machine Design, January 25, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138362</article_id>
		<sort_key>160</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[The computer/plotter and the 17 ornamental design types]]></title>
		<page_from>160</page_from>
		<page_to>167</page_to>
		<doi_number>10.1145/563732.1138362</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138362</url>
		<abstract>
			<par><![CDATA[Every possible repetitive design in the Euclidean plane belongs to one or the other of 17 types of design, each with its own characteristic group of isometries. This report deals with the use of a comprehensive plotter program, written in FORTRAN, which permits one to create designs by specifying a motif and selecting one of the seventeen types, into which the motif will be incorporated.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P789641</person_id>
				<author_profile_id><![CDATA[81314487971]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Howard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Alexander]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Earlham College, Richmond, Indiana]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138363</article_id>
		<sort_key>168</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[Design rules checking for integrated circuits using graphical operators]]></title>
		<page_from>168</page_from>
		<page_to>176</page_to>
		<doi_number>10.1145/563732.1138363</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138363</url>
		<abstract>
			<par><![CDATA[The Design Rules Checking (DRC) Program is a powerful set of graphical routines for manipulating and checking integrated circuit (IC) masks for geometrical information and design rule violations. The DRC program can be divided into four major parts: Input, Graphical Manipulators, Graphical Tests, and Output.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P789637</person_id>
				<author_profile_id><![CDATA[81314488143]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[B.]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Crawford]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[American Microsystems, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138364</article_id>
		<sort_key>177</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[Display of two-dimensional functions using grey scale simulated on a bilevel display]]></title>
		<page_from>177</page_from>
		<page_to>180</page_to>
		<doi_number>10.1145/563732.1138364</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138364</url>
		<abstract>
			<par><![CDATA[A technique is described for displaying functions of two independent variables on a matrix of bilevel display cells. The function value is associated with an n-level grey scale which is simulated by the ordered dither processing technique. Using only one cell per coordinate pair, ordered dither gives the subjective effect of grey scale through the appropriate spatial arrangement of on and off cells. Aside from subjective advantages, this technique executes much faster and requires considerably less memory than conventional contouring or 3-D perspective methods when the function is given as a large matrix array.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P789638</person_id>
				<author_profile_id><![CDATA[81314489567]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[N.]]></middle_name>
				<last_name><![CDATA[Judice]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bell Laboratories, Holmdel, New Jersey]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[K. Knowlton and L. Harmon, "Computer-Produced Grey Scales," Computer Graphics and Image Processing, <u>1</u>, pp. 1--20 (1972).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[David L. Fulton, "A Spatial Gray Scale for Plasma Display Panels," SID Symposium, Digest of Papers, pp. 20--21 (1973).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C. N. Judice, J. F. Jarvis, and W. H. Ninke, "Using Ordered Dither to Display Continuous Tone Pictures on an AC Plasma Display," Proc. of SID, 4th Quarter 1974, p. 161.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[n2 = 2m where m = 0,1,2,..&#8734;]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Goodall, W. W., "Television by Pulse Code Modulation," BSTJ, <u>30</u>, No. 1, (January 1951), pp. 33--49.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Limb, J. O., "Design of Dither Wave-forms for Quantized Visual Signals," BSTJ, <u>48</u>, No. 7 (September 1969), pp. 2555--2582.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[B. Lippel and M. Kurland, "The Effect of Dither on Luminance Quantization of Pictures," IEEE Transactions on Communications Technology, 6, pp. 879--888, (1971).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[B. E. Bayer, "An Optimum Method for Two-Level Rendition of Continuous-Tone Pictures," Int. Conf. on Comm., Conf. Record, pp. (26-11)--(26-15), (1973).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[F. D. Tappert and C. N. Judice, "Recurrence of Nonlinear Ion Acoustic Waves," Phys. Rev. Letters, Vol. <u>29</u>, (1972).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138365</article_id>
		<sort_key>181</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[Multi-dimensional function display using a color scale]]></title>
		<page_from>181</page_from>
		<page_to>183</page_to>
		<doi_number>10.1145/563732.1138365</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138365</url>
		<abstract>
			<par><![CDATA[Similar to the use of color on maps to indicate height information on a two-dimensional display, color can be used to convey a sense of the fourth dimension in a three-dimensional display. The information then appears as a set of color dots arranged in three dimensions. A color display system then shows sections of this assembly, much like a series of stacked colored maps.A particularly simple implementation occurs when the fourth-dimension variable is of limited range, such as in the display of complex-variable functions. By showing magnitude of the function as height and phase angles as colors, colored three-dimensional surfaces may be used to depict such functions vividly. The choice of the phase-angle color-scale determines the ease of reading off details from this display.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14277877</person_id>
				<author_profile_id><![CDATA[81100545248]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Staudhammer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[North Carolina State University, Raleigh, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Staudhammer, "Circuit Analysis by Digital Computer," Prentice-Hall, Inc., 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. G. Truxal, "Automatic Feedback Control System Synthesis," McGraw-Hill, Inc., 1955.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[H. S. Carslaw and J. C. Jaeger, "Operational Methods in Applied Mathematics," Oxford University Press, 1953.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563206</ref_obj_id>
				<ref_obj_pid>563182</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Staudhammer and D. J. Ogden, "Computer Graphics for Half-Tone Three-Dimensional Object Images," Computers and Graphics, in print.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>642094</ref_obj_id>
				<ref_obj_pid>642089</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. F. Eastman and J. Staudhammer, "Computer Display of Colored Three-Dimensional Objects," Proc. Second Annual Symposium on Computer Architecture, Houston, January 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. F. Eastman and J. Staudhammer, "Interactive Verification of Roadbed Topologies," presented at this conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138366</article_id>
		<sort_key>184</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[An area organized data structure for interactive graphics]]></title>
		<page_from>184</page_from>
		<page_to>190</page_to>
		<doi_number>10.1145/563732.1138366</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138366</url>
		<abstract>
			<par><![CDATA[A problem common to many applications of interactive graphics is the response time of the system to a user input. This response time increases in severity as the quantity of data being manipulated increases. Programs for the design of integrated circuit masks are good examples of graphics systems where large quantities of data are processed. This response time problem is particularly severe for the windowing operation and other algorithms that must iteratively search the graphical data base.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14276461</person_id>
				<author_profile_id><![CDATA[81314489260]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Jarvis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bell Laboratories, Holmdel, New Jersey]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. F. Jarvis, "The Design of Interactive Graphics Aids to Mask Layout," Proc. IEEE, Vol. 60, pp. 35--39, January 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356584</ref_obj_id>
				<ref_obj_pid>356583</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Williams, "A Survey of Data Structure for Computer Graphics Systems," Computing Surveys, Vol. 3, pp. 1--22, March 1971.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356573</ref_obj_id>
				<ref_obj_pid>356571</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. J. Denning, "Virtual Memory," Computing Surveys, Vol. 2, pp. 153--190, September 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>361061</ref_obj_id>
				<ref_obj_pid>361011</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. M. Ritchie and K. Thompson, "The UNIX Time Sharing System," CACM, Vol. 17, pp. 1365--1375, July 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563191</ref_obj_id>
				<ref_obj_pid>563182</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. F. Jarvis, "A Graphical Display System Utilizing Plasma Panels," presented at First Annual Conference on Computer Graphics, Boulder, Colorado, July 15, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138367</article_id>
		<sort_key>191</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[Extending the information transfer in multidimensional analysis through the use of interactive graphics]]></title>
		<page_from>191</page_from>
		<page_to>200</page_to>
		<doi_number>10.1145/563732.1138367</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138367</url>
		<abstract>
			<par><![CDATA[The models and methods available to the social scientist are now more numerous and more complex than ever before. One of the most complex family of models presently available is non-metric multidimensional analysis. In multidimensional analysis the investigator seeks a spatial representation of a set of data. Ideally the rank-order of the interpoint distances in the multidimensional space should be identical to the rank order of the variables they represent. The emphasis on non-metric models has been due to a self-conscious attempt by social scientists to accommodate cruder levels of observation in their conceptualization and measurement procedures. The algorithms for multidimensional analysis all use iterative procedures which take some initial spatial representation of the data, assess the degree of fit with a criterion, and then change the configuration of points in ways designed to improve the fit. This iterative process is continued until some arbitrary cutoff is reached.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14277995</person_id>
				<author_profile_id><![CDATA[81100155430]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Edward]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Schneider]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Michigan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P789639</person_id>
				<author_profile_id><![CDATA[81314488769]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[John]]></middle_name>
				<last_name><![CDATA[Gow]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Hawaii]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[The general field of dimensional analysis is best explained in Clyde H. Coombs, <u>A Theory of Data</u>, (New York: John Wiley & Sons, INC., 1964). For an introduction to that area of the field which is generally known as non-metric multidimensional scaling see Joseph B. Kruskal, "Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis", <u>Psychometrika</u>, 29 (1964) pp. 1--27. For more recent developments in the field see Roger N. Shepard, A. Kimball Romney and Sara Beth Nerlove (Eds.), <u>Multidimensional Scaling: Theory and Applications in the Behavioral Sciences</u>, Volumes I and II, (New York: Seminar Press, 1972). For a good review of the available programs and applications see Paul Green and Vithala Rao, <u>Applied Multidimensional Scaling: A Comparison of Approaches and Algorithms</u>, (New York: Holt, Rinehart and Winston, Inc., 1972).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[In this paper we shall use the terms spatial representation, space, and configuration interchangeably.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. B. Kruskal, "Multidimensional Scaling: A Numerical Method", <u>Psychometrika</u>, 29 (1964) pp. 115--129. Recently KYST has become available. KYST combines the best features of MDSCAL and TORSCA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[L. Guttman, "A General Nonmetric Technique for Finding the Smallest Coordinate Space for a Configuration of Points", <u>Psychometrika</u>, 33 (1968) pp. 469--506. J. C. Lingoes and E. E. Roskam, "A Mathematical and Empirical Analysis of Two Multi-dimensional Scaling Algorithms", <u>Psychometrika</u>, 38 (1973) Monograph Supplement.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[F. W. Young and W. S. Torgerson, "TORSCA, A FORTRAN IV Program for Shepard-Kruskal Multidimensional Scaling Analysis", <u>Behavioral Science</u>, 12 (1967) p. 498.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[I. Spence, "Multidimensional Scaling: An Empirical and Theoretical Investigation", <u>Psychometrika</u>, 37 (1972) 461--486. J. C. Lingoes and E. E. Roskam, <u>op. cit.</u>]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. C. Lingoes and E. E. Roskam, pp. 64--66.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[For a review of interactive graphics applications see the two papers by L. B. Smith, "The Use of Interactive Graphical Systems for Mathematics", <u>Communications of the ACM</u>, 13 (1970) pp. 625--634; and "A Survey of Interactive Graphical Systems for Mathematics", <u>Computing Surveys</u>, 2 (1970) pp. 261--301.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[IMDS is written in FORTRAN IV(G) and runs under the Michigan Terminal System on a virtual memory IBM 370/168. IMDS can be run from a standard teletype or a cathode ray tube terminal. The cathode ray tube can be either storage or refresh. IMDS employs subroutines which were originally written for batch programs. These routines are J. B. Kruskal's MDSCAL-V; J. C. Lingoes' MFIT; and S. C. Johnson's HICLUS. IMDS is not the only interactive scaling system. See J. E. Dannemiller and D. J. Gow, "An APL/360 Program for Monotone Distance Analysis", <u>Behavior Research Methods and Instrumentation</u>, 6 (1974) pp. 356--357.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[E. J. Schneider and H. F. Weisberg, "An Interactive Graphics Approach to Dimensional Analysis", <u>Behavior Research Methods and Instrumentation</u>, 6 (1974) pp. 185--194.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[For a discussion of the ability to retrieve metric information from ordinal information see B. N. Shepard, "Metric Structure in Ordinal Data", <u>Journal of Mathematical Psychology</u> 3 (1966) pp. 287--315.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Throughout this paper we will describe IMDS as it is typically used. Such use can be modified by the user at any time by normal IMDS commands. For example, the plane displayed does not have to be the plane 1, 2; it could be the plane 2, 3. The dictionary need not be displayed; variable names could be used to label the points rather than numbers or alternatively, a single character may be used. The maximum value for display can be changed from 2.0 to whatever degree of resolution the user desires. The choice of options can tailor the display to the user's requirements.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Stress is a measure of fit that corresponds to the coefficient of alienation in regression analysis. See Kruskal, supra. fn. 3.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[For a discussion of the Shepard diagram see Kruskal supra. fn. 3.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[For a discussion of the steepest descent algorithm see Kruskal supra. fn. 3.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[The hash marks along the vectors represent the first attempt which the program will make in the next iteration. If the stress increases instead of decreases, the program realizes that it may have gone too far along the gradient (i.e., the stepsize was too large). It will then "back-up" by reducing the stepsize by a factor of ten. Unfortunately the negative gradient (Figure 3) in our display is not particularly large.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[For a discussion of the elbow diagram used in the scree test see R. J. Rummel, <u>Applied Factor Analysis</u> (Evanston: Northwestern University Press 1970) p. 361.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[For an excellent description of the state of the art of three dimensional display see W. N. Newman and R. F. Sproull, <u>Principles of Interactive Computer Graphics</u>, (New York: McGraw-Hill Book Co. 1973). Unfortunately most three dimensional graphics literature is inappropriate to our work because it deals with solid objects and/or continuous surfaces.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[The scaling literature contains few examples of three dimensional displays. When a three dimensional display is used it is either a photograph of flags on sticks or balls on strings, or an elaborately shaded diagram drawn by a draftsman. For example see D. J. Carroll and M. Wish, "Measuring Preference and Perception with Multidimensional Models", <u>Bell Telephone Record</u> 49 (1971) pp. 146--154. Computer generated three dimensional displays have not been used in the scaling literature.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[S. C. Johnson, "Hierarchical Clustering Schemes". <u>Psychometrika</u> 32 (1967) pp. 241--254.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[P. H. Sch&#246;nemann and R. M. Carroll, "Fitting One Matrix to Another under Choice of a Central Dilation and a Rigid Motion", <u>Psychometrika</u> 35 (1970) pp. 245--255. J. C. Lingoes, "A FORTRAN IV Program Generalizing the Sch&#246;nemann-Carroll Matrix Fitting Algorithm to Monotone and Linear Fitting of Configurations", <u>Educational and Psychological Measurement</u> 34 (1974) pp. 121--124.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[See J. G. Rusk and H. F. Weisberg, "Perceptions of Presidential Candidates: Implications for Electoral Change", <u>Midwest Journal of Political Science</u> 16 (1972) pp. 388--410.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Perhaps the most massive transfer of information on multidimensional scaling occurred in 1972 at the Bell Laboratories-University of Pennsylvania Workshop on Multidimensional Scaling. The audience consisted of relatively sophisticated users from a variety of fields. They were presented with a series of lectures which employed a considerable amount of graphical displays. Perhaps the highlight of which was a film produced by Bell Laboratories which traced the movement of points and the smoothing of the regression curve. The unanimous impression was that everyone who viewed the film learned more about the behavior of the algorithm in the process. This film provided the impetus for many of the features of IMDS. It is noteworthy that IMDS has been used by some of the principal developers of the scaling model and algorithm. Even these individuals felt they had learned something by being able to interact with the system and by seeing the graphical result. Their experience was similar to the audience experience at the Workshop.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[An algorithm for placing points for individuals in a multidimensional space is described in G. B. Rabinowitz, <u>Spatial Models of Electorate Choice: An Empirical Analysis</u> (Chapel Hill: Institute for Research in the Social Sciences, 1973).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[We added the default system to the commands in order to minimize this problem.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Some potential users are reluctant to use a CRT because they want a hard copy of the analysis. IMDS provides hard copy on a remote line printer. This removes a potential stumbling block for most, but not all potential users.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138368</article_id>
		<sort_key>201</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[Time management in a real-time animation/graphics environment]]></title>
		<page_from>201</page_from>
		<page_to>207</page_to>
		<doi_number>10.1145/563732.1138368</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138368</url>
		<abstract>
			<par><![CDATA[An important aspect of a real-time animation/graphics system is the definition and management of time and time-dependent relationships: a correlation between "time in the outside world" and the program parameter considered to be "time" by the system must be established, and time-dependent relationships between user-defined objects must be fairly easily specified and possibly subsequently changed.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P789644</person_id>
				<author_profile_id><![CDATA[81314488060]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Samuel]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Cardman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University, Columbus, Ohio]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baecker, R. M., Picture-driven Animation, AFIPS 1969 Spring Joint Computer Conference Proceedings, vol 34, 1969, pp 273--288]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cardman, S. J., Time Management in a Real-Time Animation/Graphics Environment, Technical Report to the NSF, DCR74-00768A01, to be published August 1975]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[DeFanti, T. A., The Graphics Symbiosis System, &lt;u&gt;Real-Time Film Animation&lt;/u&gt;, Annual Report to the NSF, GJ-204, 1973, pp 5--115]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Frailey, D. J., Timing Features for Systems Implementation Languages, &lt;u&gt;Information Processing 74&lt;/u&gt;, IFIP Congress 74 Proceedings, North-Holland, Amsterdam, 1974, pp 354--358]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Futrelle, R. P., and Potel, J. J., The System Design for GALATEA, An Interactive Real-Time Computer Graphics System for Movie and Video Analysis, GALATEA Report #3, University of Chicago, May 1974]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Futrelle, R. P., Concurrent Computations Driven By Real-Time Events, GALATEA Report #5, University of Chicago, August 1974]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Futrelle, R. P., Hard-Real-Time Structures in GALATEA, GALATEA Report #8, University of Chciago, October 1974]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138369</article_id>
		<sort_key>208</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[An experiment in interaction between independent music and graphics processors]]></title>
		<page_from>208</page_from>
		<page_to>211</page_to>
		<doi_number>10.1145/563732.1138369</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138369</url>
		<abstract>
			<par><![CDATA[This paper describes an effort to design and implement an interactive system involving two independent processors - one a display processor and the other a music processor. The goal of the work was to develop tools and techniques for the artist interested in working with the media of animation and music in an integrated fashion. Since the purpose of our project was purely artistic, its success and significance can be evaluated only in terms of the uniqueness and viability of the products which our tools and techniques have yielded thus far. Our present results are unique to the extent that they would be extremely difficult, if not impossible, to reproduce on other existing animation systems. As far as aesthetic criteria are concerned, all we can say is that we find our results viable enough to warrant public exposure.The basic principle of our system is that both animation and music are process-oriented. That is, both the display sequence and the performance of a musical score are described in terms of programs written in low-level interpretive languages. Both the animation and the music are performed in real time with all timing provided by external clocks which interrupt the interpreter programs at regular intervals. These clocks are actually built into the data communications hardware, so that all processor-to-processor communication is incorporated into the interrupt routine which services timing.The music interpreter is designed in such a way that it supervises the execution of four independent "voice programs", each of which describes the performance of a single sequence of notes. In an analogous fashion the graphic interpreter supervises the execution of four lower-level programs, each of which describes the motion of a single object in terms of the direction of its path, the distance it proceeds in that direction, and the amount of time it takes to traverse that distance. The sounding of each individual note by the music processor is determined by two external parameters which specify the pitch and duration of that note. These parameters are maintained at the top of stacks, a data structure which was chosen for being conducive to the representation of information relevant to the organization of tonal music (Smoliar, 1972).Processor-to-processor communication is unilateral - from the music processor to the display processor. The music processor constantly informs the display processor of the data at the top of its eight stacks (pitch and duration parameters for four voices). The display processor then transforms the information it receives into parametric data regarding the motions of its objects. These transformations are subject to program control, and experiments have been performed in using different transformations as graphic interpretations of the initial musical data. The results of each experiment constitute a "graphical choreography" of the musical score represented in the music processor, displayed in real time while the music processor performs the score.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P789647</person_id>
				<author_profile_id><![CDATA[81100316628]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kaczmarek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Pennsylvania, Philadelphia, Pennsylvania]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14278134</person_id>
				<author_profile_id><![CDATA[81100544848]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Stephen]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Smoliar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Pennsylvania, Philadelphia, Pennsylvania]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>805892</ref_obj_id>
				<ref_obj_pid>800194</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Smoliar, S. W., "Music Theory - A Programming Linguistic Approach", &lt;u&gt;Proceedings of Annual Conference of Association for Computing Machinery&lt;/u&gt;, New York, 1972, pp. 1001--1014.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Smoliar, S. W., "EUTERPE-8: A PDP-8-based Music Processor", Technical Report, The Moore School of Electrical Engineering, University of Pennsylvania, Philadelphia, November, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138370</article_id>
		<sort_key>212</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[WHATSISFACE]]></title>
		<subtitle><![CDATA[human facial composition by computer graphics]]></subtitle>
		<page_from>212</page_from>
		<page_to>221</page_to>
		<doi_number>10.1145/563732.1138370</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138370</url>
		<abstract>
			<par><![CDATA[Sketching a human face is a task which involves spatial decisions and a knowledge of the aspects of the face that are important in recognition. These are talents which non-artists lack.This paper describes WHATSISFACE, a system with which a non-artist can create, on a graphic display, any male Caucasian facial image resembling the face on a photograph in front of him. The computer system contains prestored facial features, an average face used as a starting point, and a heuristic strategy which guides the user through a carefully constructed sequence of questions, choices, and feature manipulations. The user makes all of the visual decisions and can change the individual features or hierarchically organized sets of features using analog input devices.Several specialized graphics algorithms were developed for this work and are described.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P190276</person_id>
				<author_profile_id><![CDATA[81100625050]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Gillenson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[International Business Machines Corporation, Yorktown Heights, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14276007</person_id>
				<author_profile_id><![CDATA[81100659169]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[B.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chandrasekaran]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University, Columbus, Ohio]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bertillon, Alphonse, Signaletic <u>Instructions</u>, The Werner Co., Chicago, 1893.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Conroy, P., "Simulation of Texture by Computer Graphics, M. S. Thesis, University of Toronto, 1969.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[DeFanti, Thomas A., "The Graphics Symbiosis System - An Interactive Minicomputer Animation Graphics Language Designed for Habitability and Extensibility", Ph.D. Thesis, The Ohio State University, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>906875</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Gillenson, Mark L., "The Interactive Generation of Facial Images on a CRT Using a Heuristic Strategy", Ph.D. Thesis, The Ohio State University, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Harmon, Leon D., "The Recognition of Faces", <u>Scientific American</u>, Vol. 229, No. 5, 1973, pp 70--82.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Knuth, Donald E., <u>The Art of Computer Programming</u>, Vol. 1, Addison-Wesley Publishing Co., Reading Mass., 1968.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569955</ref_obj_id>
				<ref_obj_pid>800193</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Parke, Frederick I., "Computer Generated Animation of Faces", <u>Proceedings of The ACM Annual Conference</u>, Vol. 1, 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Zavala, Albert and Zavala, R. Thomas, "The Dimensions of Facial Features", in <u>Personal Appearance Identification</u>, ed. by Zavala, Albert, and Paley, James, Charles C. Thomas, Springfield, Ill., 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138371</article_id>
		<sort_key>222</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[Implementation of a simulated display processor for computer graphics education]]></title>
		<page_from>222</page_from>
		<page_to>231</page_to>
		<doi_number>10.1145/563732.1138371</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138371</url>
		<abstract>
			<par><![CDATA[To provide student experience at the detail level of graphics output, a simulated graphics display processor was written in FORTRAN to run on a CDC 6400 computer equipped with microfilm graphics output. The simulated processor has a command set conforming to the course textbook, a memory of 4096 16-bit words and accepts directions only in absolute octal code. This last feature caused the class to write an octal code generator which accepts graphic primatives as commands.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P647059</person_id>
				<author_profile_id><![CDATA[81100356710]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Patricia]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Mohilner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Colorado State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[William M. Newman and Robert F. Sproull, "Principles of Interactive Computer Graphics," McGraw-Hill, New York, 1973, pp. 62--73.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Colorado State University Computer Center Users Manual, CSU, Fort Collins, 1972, pp. V.20-V.38.2.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[A listing of the Fortran code for the simulator will be supplied upon request to the author.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[William M. Newman and Robert F. Sproull, op. cit., p. 87.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138372</article_id>
		<sort_key>232</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[Device independent graphics software]]></title>
		<subtitle><![CDATA[is it possible??]]></subtitle>
		<page_from>232</page_from>
		<page_to>245</page_to>
		<doi_number>10.1145/563732.1138372</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138372</url>
		<abstract>
			<par><![CDATA[Today there is an ever growing need (if not demand) for the development of a graphics software "standard". Compatibility between different elements of the graphics industry has often been the issue of heated debate. Even the idea that any graphics standard would be premature and could stifle future design creativity is a highly argumentative issue. However, let us accept the premise that a graphics standard &lt;u&gt;is&lt;/u&gt; to be derived and address the question of what considerations, methods, go&#228;ls, practical economics and human factorings should be included within the design of an ideally compatible passive/interactive device independent standard.Before hierarchical languages such as EULER-G, LEAP, METAVISU, BCPL, etc. can be evaluated for standardization, a basic set of standard graphic "primitives" must be defined on which further evolutions of graphic applications and languages can be based. These primitives are the basic operators which will define the mode and capabilities of system operation. The "primitive standard" should then be the first issue of attack. Concepts such as extendibility, portability, upward compatibility and device independence must be critically interrogated so as not to limit the role of the primitive standard, or compromise the capabilities of future based software.This paper will not attempt to answer the question it presents, but perhaps will provide some tangible elements with which to better assess the argumentative issues. Conclusions will therefore be left up to the reader. What is presented is a survey and evaluation of past and current techniques (i.e. potential goals, graph theory, system design, and human engineering) as assessed from practical observations and experience, and which lend themselves for consideration within the design of a primitive "standard" system. The conclusion of this paper projects a possible systems concept which has been drawn from techniques presented by several independent sources. Such a concept demonstrates perhaps, one potential answer for the "primitive standards" question.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P789642</person_id>
				<author_profile_id><![CDATA[81314488034]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jack]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Davis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Versatec Corp., Santa Clara, Calif.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>361180</ref_obj_id>
				<ref_obj_pid>361179</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Sterling, T. D.: "Guidelines for Humanizing Computer Information Systems" &lt;u&gt;Comm. ACM&lt;/u&gt; 7, 11 (Nov. 1974) pp609--613.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Nake, F and Rosenfeld, A (eds): &lt;u&gt;Graphic Languages&lt;/u&gt;, North-Holland Publishing Co., 1972, pp271--283: Meads, J. "A Terminal Control System".]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Gallup, J.: "GRAPHX-11", &lt;u&gt;DECUS Proceedings - Fall 1973&lt;/u&gt;, DECUS, p195]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Garner, W. R.: &lt;u&gt;Tech Brief 73--10322 "Characteristics of FORTRAN"&lt;/u&gt;. Technology Utilization Office, NASA Langely Research Center. (LAR-11177, Oct. 1973).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>361112</ref_obj_id>
				<ref_obj_pid>361147</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Watkins, S. L.: "Masked Three-Dimensional Plot Program with Rotations" &lt;u&gt;Comm. ACM 17, 9&lt;/u&gt; (Sept. 1974) pp520--523]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138373</article_id>
		<sort_key>246</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[Algorithms to reveal graphic terminal characteristics]]></title>
		<page_from>246</page_from>
		<page_to>251</page_to>
		<doi_number>10.1145/563732.1138373</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138373</url>
		<abstract>
			<par><![CDATA[Algorithms to discover terminal characteristics are presented as a set of Standard Fortran subroutines as an aid in developing portable and device independent graphical systems. The algorithms compute the screen representation, the character sizes, the incremental vector action and the boundary action in both the character and graphic mode. The assumptions, restrictions and implications of the algorithms are discussed.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[environment inquiry]]></kw>
			<kw><![CDATA[graphical software]]></kw>
			<kw><![CDATA[graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14127566</person_id>
				<author_profile_id><![CDATA[81100355978]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[George]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Los Alamos, New Mexico]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Beach, Robert C. The SLAC unified graphics system. Computation Group, Stanford Linear Accelerator Center, Stanford, California, CGTM 143, January 1973. Also, an abstract appeared in Abstracts of Presentations, ACM-SIGGRAPH/NBS Workshop on Machine Independent Graphics, April 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Meads, J. A. A terminal control system, in <u>Graphic Languages</u>, Nake, F. and Rosenfeld, A. (Eds.), North-Holland Publishing Co., Amsterdam, 1972, 271--290.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>988479</ref_obj_id>
				<ref_obj_pid>988476</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Newman, William M. Where are we? Proceedings of the Batelle Computer Graphics Conference, Computer Graphics, 8, 1 (Spring 1974), 12--29.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Newman, William M. and Sproull, Robert F. An approach to graphics system design. Proceedings of the IEEE, 62, 4 (April 1974), 471--483.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>988624</ref_obj_id>
				<ref_obj_pid>988622</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Walsh, John P. A plea for standards - graphics vs. freedom - the unending plot routine problem. Computer Graphics, 6, 3 (Winter 1972), 6--7 and 13.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Woodsford, P. A. The design and implementation of the GINO 3D graphics software package. Software - Practice and Experience, 1 (1971), 335--365.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Woodsford, P. A. Introduction to the graphics compatability system. Computer Graphics Project, United States Military Academy, 1974. Also, an abstract appeared in Abstracts of Presentations, ACM-SIGGRAPH/NBS Workshop on Machine Independent Graphics, April 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Woodsford, P. A. Guidelines for initiation of a program for graphic standards and a graphic standards planning committee. Computer Graphics, 8, 2 (Summer 1974), 19--22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Michener, Jim and Sproull, Bob. Proposed network graphics protocol. ARPA Network Information Center, Stanford Research Institute, NIC 19933, Network Graphics Group, Note 5, October 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Michener, Jim and Sproull, Bob. Decystem -10 display systems. Computer Center Branch, Division of Computer Research and Technology, National Institutes of Health, Bethesda, Maryland, March 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Michener, Jim and Sproull, Bob. GINO-F user manual. Computer Aided Design Centre, Madingley Road, Cambridge CB3 OHB, England, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hirschsohn, Ian. DISSPLA -- A proven machine and device independent graphics software system. Abstracts of Presentations, ACM-SIGGRAPH/NBS Workshop on Machine Independent Graphics, April 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Naur, Peter. Machine dependent programming languages. BIT 7 (1967), 123--131.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1052615</ref_obj_id>
				<ref_obj_pid>1052614</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Redish, K. A. and Ward, W. Environment enquiries for numerical analysis. SIGNUM Newsletter, 6, 1 (January 1971), 10--15.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>361870</ref_obj_id>
				<ref_obj_pid>355606</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Malcolm, Michael A. Algorithms to reveal properties of floating-point arithmetic. CACM, 15, 11 (November 1972), 949--951.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>361003</ref_obj_id>
				<ref_obj_pid>360980</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Gentleman, W. Mowen and Marovich, Scott B. More on algorithms that reveal properties of floating-point arithmetic units, CACM, 17, 5 (May 1974), 276--277.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[George, James E. Algorithms to reveal the representation of characters, integers and floating-point numbers. Submitted to CACM.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>876694</ref_obj_id>
				<ref_obj_pid>364888</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[George, James E. FORTRAN vs. Basic FORTRAN - a programming language for information processing on automatic data processing systems. CACM, 7, 10 (October 1964), 591--625.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138374</article_id>
		<sort_key>252</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>33</seq_no>
		<title><![CDATA[A schizophrenic system plot package]]></title>
		<page_from>252</page_from>
		<page_to>255</page_to>
		<doi_number>10.1145/563732.1138374</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138374</url>
		<abstract>
			<par><![CDATA[A system plot package is a set of routines that forms plotter machine instructions. Here, system plot routines are assumed to form instructions for relatively low-level plotting tasks such as drawing a line or, at most, drawing an annotated axis, while graphics utility routines are used to perform higher level tasks, such as drawing a contour map, through the use of the lower level routines. System plot packages have certain desirable attributes which are often conflicting or even mutually exclusive. For example, at NCAR almost all plotting is done on a CDC DD80, suggesting that the plot package should be designed to produce instructions for that particular plotter, but the occasional use of other plotters makes device independence essential.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14278776</person_id>
				<author_profile_id><![CDATA[81450594467]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wright]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NCAR, Boulder, Colorado]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Wright, T., "Utility Plotting Programs at NCAR," <u>Atmospheric Technology</u>, Vol. 1, No. 3 (Sep. 1973), pp. 51--57.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>362746</ref_obj_id>
				<ref_obj_pid>362736</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Hirschsohn, I., "AMESPLOT - A Higher Level Data Plotting Software System." <u>Comm ACM</u>, Vol. 15, No. 9 (Sep 1972), pp. 546--555.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA["NCAR Scientific Subroutine Library", Chapter 12.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138375</article_id>
		<sort_key>256</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>34</seq_no>
		<title><![CDATA[At the interface of cartography and computer graphics]]></title>
		<page_from>256</page_from>
		<page_to>259</page_to>
		<doi_number>10.1145/563732.1138375</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138375</url>
		<abstract>
			<par><![CDATA[Developing technology has always had an impact on cartography, the art and science of making maps. This impact has been particularly noticeable in recent centuries. The expanded use of copper engraving plates in the 17th century added immeasurably to the ability of the cartographer to add more clear detail to his maps. In the last century the introduction of photoprocessing coupled with existing offset printing techniques added much more efficiency to the process as well as reduced the cost of map production. It is no wonder, then, that computer driven machinery has had, and will continue to have, a significant impact on the field of cartography.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P789640</person_id>
				<author_profile_id><![CDATA[81384613914]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Harold]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Moellering]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Boyle, A. R., et. al., 1973, &lt;u&gt;Computer Aided Map Compilation: CAMC Program User Description&lt;/u&gt;, Graphic Systems Design and Application Group, Electrical Engineering Department, University of Saskatchewan.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Brassel, Kurt, 1973, &lt;u&gt;Modelle und Versuche zur automatischen Schr&#228;glichtschattierung; Ein Beitrag zur Computer-Kartographie&lt;/u&gt;, Buchdruckerei E. Brassel, 7250 Klosters/Schweiz.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Brassel, Kurt, 1974a, "Mono- and Multi-Colored Line Printer Display", &lt;u&gt;Proceedings of the American Congress on Surveying and Mapping&lt;/u&gt;, 34th Annual Meeting, St. Louis.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Brassel, Kurt, 1974b, "A Model for Automatic Hill Shading", &lt;u&gt;The American Cartographer&lt;/u&gt;, Vol.1, No.1, April, pp.15--27.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Brassel, Kurt, J., Little, and T. K. Peucker, 1974 "Automated Relief Representation", &lt;u&gt;Map Supplement Number 17, Annals of the Association of American Geographers&lt;/u&gt;, Vol. 64, No. 4, December.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Broome, Frederick R., 1974, "Micrographics: A New Approach to Cartography at the Census Bureau", &lt;u&gt;Proceedings of the American Congress of Surveying and Mapping&lt;/u&gt;, Fall Convention, September, pp.1--14.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Canadian Department of Transportation and Communication, 1971, &lt;u&gt;City of Peterborough, Ontario and Environs.&lt;/u&gt;]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Central Intelligence Agency, 1974 &lt;u&gt;CAM: Cartographic Automatic Mapping: Program Documentation- Version 4&lt;/u&gt;, document BGI CD 75-1.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Chrisman, Nicholas, 1974 "The Impact of Data Structure on Geographic Information Processing", paper presented to the International Conference on Automation in Cartography, Reston, Virginia.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Experimental Cartography Unit, 1970 &lt;u&gt;Automatic Cartography and Planning&lt;/u&gt;, Architectual Press, London.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Gardiner-Hill, Col. R. C., 1972 &lt;u&gt;The Development of Digital Maps&lt;/u&gt;, Ordinance Survey Professional Papers No. 23, Southhamption.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Geography Program Exchange, 1973, Index of Programs Currently Available, mimeograph, contact: Dr. Robert Wittick, Computer Institute for Social Science Research. Michigan State University, East Lansing, MI 48824, U.S.A.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Laboratory for Computer Graphics, 1971 &lt;u&gt;Symap User's Manual&lt;/u&gt;, Harvard University, Cambridge, Massachusetts.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[LeBlanc, Aubry L., Ed., 1973 &lt;u&gt;Computer Cartography in Canada&lt;/u&gt;, Cartographica monograph no. 9, Supplement No.3 to the Canadian Cartographer, Vol. 10.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[McLellan, William G. and Barry K. Moritz, 1974, "An Interactive On-Line Multi Mini Computer Configuration for Application to Cartography", &lt;u&gt;Proceedings of the American Congress of Surveying and Mapping&lt;/u&gt;, 34th Annual Meeting, St. Louis, pp. 458--477.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Moellering, Harold, 1973a, "The Automatic Mapping of Traffic Crashes" &lt;u&gt;Surveying and Mapping&lt;/u&gt;, Vol. XXXIII, No.4, December, pp. 467--477.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>805682</ref_obj_id>
				<ref_obj_pid>800192</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Moellering, Harold, 1973b, "The Computer Animated Film: A Dynamic Cartography", &lt;u&gt;Proceedings, ACM 73&lt;/u&gt;, pp. 64--69.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Moritz, Barry K., 1974, comment made at a session of the International Conference on Automation in Cartography, Reston, Virginia.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Peucker, Thomas, K., 1972, &lt;u&gt;Computer Cartography&lt;/u&gt;, Commission on College Geography Resource Paper No. 17, Association of American Geographers, Washington, D.C.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Peucker, Thomas, K., and Nicholas Chrisman, 1974, "Cartographic Data Structures," paper presented to the 34th Annual Meeting of the American Congress of Surveying and Mapping, St. Louis, 23 pp.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>805683</ref_obj_id>
				<ref_obj_pid>800192</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Phillips, R. L. and D. E. Geister, 1973, "Interactive Graphics in Water Quality Investigations", &lt;u&gt;Proceedings, ACM 73&lt;/u&gt;, Atlanta, pp.70--75.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Tobler, W. R., 1970, "A Computer Movie Simulating Urban Growth in the Detroit Region", &lt;u&gt;Economic Geography&lt;/u&gt;, Vol.46, No.2, (Supplement), June, pp. 234--240.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Tomlinson, R. F., Ed., 1972, &lt;u&gt;Geographical Data Handling&lt;/u&gt;, Commission on Geographical Data Sensing and Processing for the UNESCO/IGU Second Symposium on Geographical Information Systems, Ottawa.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[U.S. Army Engineer Topographic Laboratories, 1974, examples of UNIMACE plotting, Automated Cartography Branch, Ft. Belvoir, Virginia.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[U.S. Bureau of the Census, 1970, &lt;u&gt;The DIME Geocoding System&lt;/u&gt;, Census Use Study No.4, Washington, D.C.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[U.S. Defense Mapping Agency Topographic Center, 1974, &lt;u&gt;Sh&#239;r&#228;z, Iran Quadrangle&lt;/u&gt;, Series K-753, sheet 6549 III.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[U.S. Geological Survey, 1970, Slope &lt;u&gt;Map: Mt. Sizer&lt;/u&gt;, California, experimental edition, N3707.5-W12130/7.5.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Youngmann, Carl E., 1972, "A Thematic Cartography Application of Computer-Aided Design" paper presented to the annual meeting of the Association of American Geographers.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138376</article_id>
		<sort_key>260</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>35</seq_no>
		<title><![CDATA[The present status of automated cartography]]></title>
		<page_from>260</page_from>
		<page_to>266</page_to>
		<doi_number>10.1145/563732.1138376</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138376</url>
		<abstract>
			<par><![CDATA[At this time it is necessary for us to examine afresh the aspects of computer graphics concerned with automated cartography. The particular reason for this is that during the last two years there have been appreciable changes in the attitudes of cartographers and available technology; the research interest is rapidly being replaced by one of production. The means of change and the various methodologies should now be assessed in some detail.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P789636</person_id>
				<author_profile_id><![CDATA[81314487485]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Boyle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Saskatchewan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Concord Controls Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Contraves, A. G., Switzerland]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Kongsberg Systems, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Gerber Scientific Inst. Co.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[U.S. Army Engineering Topographical Alboratory]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[University of Saskatchewan, Canada]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Xynetics, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[National Ocean Survey]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Rome Air Development Centre]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[MBA Information Systems Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[CBS Laboratories Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[I/Ometrics, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Information International Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Image Graphics, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Calcomp]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Surveys and Mapping, EMR, Canada]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Defense Mapping Agency, Topographic Command]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Instronics Ltd., Canada]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Calspan, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Goodyear Aerospace, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Tektronix Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[U.S. Geological Survey]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Calma Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Computer Vision Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Dynamap Ltd., Canada]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Applicon, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[A. R. Boyle, 'Automation in Hydrographic Charting', The Canadian Surveyor, Vol.24, No.4, Dec.1970, pp.519--537.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[A. R. Boyle, 'Geographic Information Systems in Hydrography and Oceanography', The Canadian Cartographer, Vol.11, No.2, Dec.1974, pp.125--141.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[U. of Saskatchewan (GSK & AG) Reports: 'Advanced Interactive Digitication Program, DIGIT', Jan.1974 'A Minicomputer Geographic Information System, IMAGE', Jan.1974 'Computer Aided Map Compilation, CAMC', Oct.1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1138377</article_id>
		<sort_key>267</sort_key>
		<display_label></display_label>
		<article_publication_date>06-25-1975</article_publication_date>
		<seq_no>36</seq_no>
		<title><![CDATA[Computer cartography]]></title>
		<subtitle><![CDATA[some critical comments]]></subtitle>
		<page_from>267</page_from>
		<page_to>269</page_to>
		<doi_number>10.1145/563732.1138377</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1138377</url>
		<abstract>
			<par><![CDATA[Depending upon how we look at it, Computer Cartography can be considered now to be twenty years old (the first contour map was produced about twenty years ago), or a dozen years (the first major project in Computer Cartography, the Canadian Geographical Information System was started in 1963). This is not to say that we started out from scratch twelve or twenty years ago. On the contrary, we had all the tools and all the power from different disciplines, including Computer Science, Geography, Cartography and the Survey Sciences. If we assume that every discipline has some milestones in its development, it has to be said that in Computer Cartography these milestones did not happen or happened virtually unnoticed by the discipline.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P789645</person_id>
				<author_profile_id><![CDATA[81314491397]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Peucker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Simon Fraser University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>806009</ref_obj_id>
				<ref_obj_pid>800196</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Boehm, B. M., 1967, "Tabular Representations of Multi-Variate Functions with Applications to Topographic Modelling." &lt;u&gt;Proceedings&lt;/u&gt;, 22nd National Conference, Association for Computing Machinery, pp.403--415.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Tomlinson, R. F., 1974, &lt;u&gt;The Application of Electronic Computing Methods and Techniques to the Storage, Compilation, and Accessment of Map Data&lt;/u&gt;, Ph.D. dissertation, University of London.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1975</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
</content>
</proceeding>

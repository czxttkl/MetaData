<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>07/20/1977</start_date>
		<end_date>07/22/1977</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[San Jose]]></city>
		<state>California</state>
		<country></country>
	</conference_loc>
	<conference_url></conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES382</series_id>
		<series_title><![CDATA[International Conference on Computer Graphics and Interactive Techniques]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>563858</proc_id>
	<acronym>SIGGRAPH '77</acronym>
	<proc_desc>Proceedings of the 4th annual conference</proc_desc>
	<conference_number>4</conference_number>
	<proc_class>conference</proc_class>
	<proc_title>Computer graphics and interactive techniques</proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>1977</copyright_year>
	<publication_date>07-20-1977</publication_date>
	<pages></pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<publisher>
		<publisher_id>PUB27</publisher_id>
		<publisher_code>ACMNY</publisher_code>
		<publisher_name>ACM</publisher_name>
		<publisher_address>2 Penn Plaza, Suite 701</publisher_address>
		<publisher_city>New York</publisher_city>
		<publisher_state>NY</publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>10121-0701</publisher_zip_code>
		<publisher_contact>Bernard Rous</publisher_contact>
		<publisher_phone>212 869-7440</publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url>www.acm.org/publications</publisher_url>
	</publisher>
	<sponsor_rec>
		<sponsor>
			<sponsor_id>SP932</sponsor_id>
			<sponsor_name>ACM Special Interest Group on Computer Graphics and Interactive Techniques</sponsor_name>
			<sponsor_abbr>SIGGRAPH</sponsor_abbr>
		</sponsor>
	</sponsor_rec>
	<categories>
		<primary_category>
			<cat_node/>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
	<ccc>
		<copyright_holder>
			<copyright_holder_name>ACM</copyright_holder_name>
			<copyright_holder_year>1977</copyright_holder_year>
		</copyright_holder>
	</ccc>
</proceeding_rec>
<content>
	<article_rec>
		<article_id>563859</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[ECOSITE]]></title>
		<subtitle><![CDATA[an application of computer-aided design to the composition of landforms for reclamation]]></subtitle>
		<page_from>1</page_from>
		<page_to>7</page_to>
		<doi_number>10.1145/563858.563859</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563859</url>
		<abstract>
			<par><![CDATA[Surface mining, though an efficient method of extracting near-surface coal for the nation's mounting energy needs, requires sound reclamation if the harmful environmental impacts of the method are to be held to a tolerable minimum. Another important requirement is aesthetic quality, a feature which should, but as yet does not, involve professional planners and designers at the early preplanning stage of reclamation. To encourage this needed improvement a multidisciplinary research group at the University of Massachusetts is developing a comprehensive "preplanning-and-design resource package" that includes an interactive graphics program <b>for landform</b> design as an important component. Called ECOSITE, this user-oriented program is the first serious effort to apply the power of interactive graphics and CAD to the design and sculpturing of large-scale topographical compositions for reclamation and other forms of site preparation and improvement. This paper discusses the program from the standpoint of its application, specifications, design, current capabilities and necessary improvements, including the ability to test its own output against relevant criteria.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[applications programming]]></kw>
			<kw><![CDATA[interactive computer graphics]]></kw>
			<kw><![CDATA[landform and topographical design]]></kw>
			<kw><![CDATA[man/machine synergism]]></kw>
			<kw><![CDATA[surface mine reclamation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P245680</person_id>
				<author_profile_id><![CDATA[81100597554]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mallary]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Massachusetts, Amherst, Massachusetts]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379956</person_id>
				<author_profile_id><![CDATA[81100361363]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ferraro]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Massachusetts, Amherst, Massachusetts]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>563324</ref_obj_id>
				<ref_obj_pid>563274</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Gonin, M. and Moffett, T. J. ARTES, an Improved Highway Design Program. Proceedings of the Third Annual Conference on Computer Graphics and Interactive Techniques-SIGGRAPH '76, Computer Graphics. Vol. 10, No. 2, Summer, 1976, pp. 268-274.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Mallary, R. and Carlozzi, C. A. The Aesthetics of Surface-Mine Reclamation: an On-site Survey in Appalachia 1975/76. ARSTECNICA/Institute for Man and Environment (1976) The University of Massachusetts, Amherst.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Laboratory for Computer Graphics and Spatial Analysis SYMVU Manual. (1975) Harvard University, Cambridge, Mass.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Environmental Systems Research Institute, VIEWS User's Manual. (1975), Redlands, Calif.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cole, N. et al., Visual Design Resources for Surface-mine Reclamation. ARSTECNICA/Institute for Man and Environment (1976), University of Massachusetts, Amherst, Mass.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Mathematical Applications Group, Inc. Description of the MAGI Technique for Accurate Modeling and Graphic Display of Three Dimensional Objects. (1967) Elmsford, New York.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M. and Sproull, R. F. Principles of Interactive Computer Graphics, McGraw-Hill, New York, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Mallary, R. TRANS2: a Computer-graphics Program to Make Sculpture, AFIPS Conference Proceedings, Fall Joint Computer Conference, Vol. 37 (1970) AFIPS Press, Montvale, New Jersey, pp. 451-460.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ECOSITE AN APPLICATION OF COMPUTER-AIDEDDESIGN TO THE COMPOSITION OF LANDFORMS FOR RECLAMATION* Robert 
Mallary and Michael Ferraro Surface Mine Research Group Institute for Man and Environment The University 
of Massachusetts Amherst, Massachusetts 01003 Surface mining, though an efficient method of extracting 
near-surface coal for the nation's mounting energy needs, requires sound reclamation if the harmful environmental 
impacts of the method are to be held to a tolerableminimum. Another important requirement is aesthetic 
quality, a feature which should, but as yet does not, involve professionalplanners and de­signers at 
the early preplanning stage of reclamation. To encourage this needed improvement a com­ a multidisciplinaryresearch 
group at the University of Massachusetts is developing prehensive "preplanning-and-designresource package" 
that includes an interactive graphics Called ECOSITE, this user-oriented program for-landform design 
as an important component. program is the first serious effort to apply the power of interactive graphics 
and CAD to the design and sculpturing of large-scale topographical compositions for reclamation and other 
forms of site preparation and improvement. This paper discusses the program from the stand­point of its 
application, specifications,design, current capabilitiesand necessary improve­ments, including the ability 
to test its own output against relevant criteria. CR Categories: 3.41, 4.22, 8.2 KEYWORDS: Surface 
Mine Reclamation, ApplicationsProgramming, Interactive Computer Graphics, Landform and Topographical 
Design, Man/machineSynergism 1. INTRODUCTION Computer graphics began as an adjunct to scien­ tific 
research and engineering design, but almost immediatelybegan to be applied as a useful de­sign aid in 
fields like automotive design and architecture that require a synthesis of aesthet­ic and functional 
considerations. More recently, interactive computer graphics and CAD have expand­ed into fields of design 
such as urban planning and highway design that are environmental in both dimension and import [1]. Related 
in some degree to all of these prior applications of CAD, ECO- SITE is the first serious effort to apply 
the full resources and power of interactive graphics and CAD to the design of landforms and landform 
 configurations for surface-minereclamationand other earthmoving projects involving large-scale excavation 
and site preparation.  2. BACKGROUND While it is gradually becoming standard practice in the surface-mine 
industry to preplan the en­ vironmental, economic, legal/regulatory,and land­ use factors that must all 
be considered together in sound reclamation, the important aesthetic factor, when considered at all 
at this early stage, in general continues to be handled in a decidedly haphazard and amateurish fashion. 
Lacking care­ fully prepared maps and other material to go by, and relying almost soley on vague and 
inadequate verbal instructions, key decisions effecting the  Permission to make digital or hard copies 
of part or all of this work or personal or classroom use is granted without fee provided that copies 
are not made or distributed for profit or commercial advantage and that copies 1bear this notice and 
the full citation on the first page. To copy otherwise, to republish, to post on servers, or to redistribute 
to lists, requires prior specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California 
aesthetic quality of reclamation are improvised while the reclamation is underway by field super­visors 
and workmen without professional qualifi­ cations in design and aesthetics. Though the sur­face-mine 
industry as a whole deserves credit for making a genuine effort to improve the overall quality of reclamation,only 
a few of the more pro­ gressive-mindedoperators have begun to even con­ sider the possibilityof preplanning 
the aesthet­ ics of reclamation and of involving professional designers and planners (i.e., landscape 
archi­ tects) in the preplanning process [2].  Confident, however, of the spread and eventual ac­ ceptance 
of this needed improvement in the recla­ mation process, the Surface Mine Research Group at the University 
of Massachusettsobtained a one­ year (1975/76) grant from the National Endowment for the Atts (NEA) 
to undertake a preliminary re­ search effort in this energy-and environment-re­ lated policy area. Among 
the first concrete pro­ ducts of this research is ECOSITE, an interactive program for the computer-aided 
design of landforms for reclamation as a key element in a proposed package of "how-to" informationand 
technicalsug­ gestions pertaining to the aesthetics of reclama­ tion. Current plans call for the continuing 
im­ provement and expansion of this interactive pro­ gram and for its implementationon a number of different 
systems.  3. SPECIFICATIONS The first requirement of an effectiveprogram for computer-aided landform 
design is that it be cap­ able of generating and representing in clear graphical form the many varieties 
of topography  involved in reclamation. This refers both to the varied classes of natural topography 
found in those regions of the country where surface mining is concentrated (i.e., Appalachia, the Midwest, 
and parts of the Far West) and to the broad class of formalized and stylized landforms that are geo­ 
metric or quasi-geometricin character, or that combine elements of the natural and the stylized. That 
it is well within the state-of-the-art of com­ puter graphics to translate three-dimensionalco­ ordinate 
data provided by existing surveying and ranging techniques into acceptable topographical perspective 
plots with the hidden lines removed is demonstratedby the example of SYMVU, VIEWS, and other available 
packages having this capability [3,4]. For if the designer in his effort to inte­ grate the new landforms 
with the ones that are al­ ready there is to achieve the degree of fusion, harmony, and syntactic coherence 
that is necessary in terms of sound principles of design, the ability to generate both classes of landforms 
on the dis­ play is mandatory [5]. A second requirement is that the program and the system on which 
it is implemented exploit the full power of man/machine synergism inherent in inter­active graphics, 
CAD, computer simulation, and other areas of computer science and technology that are relevant to this 
new application of the com­puter. More specifically, it refers to the most effective way to implement 
the five categories of "modes" shown in Fig. 1 (proposedcapabilities are represented as broken lines). 
Needless to say, this proposed expanded facility presupposes a ful­ ly optimized operating system which 
includes among its important components an efficient executive monitor, data base manager, error detection 
and handling routines, and a powerful system control­ler in the form of a high-level graphics language 
geared to the requirements of landform design. 4. PRESENT CAPABILITIES Landforms generated by ECOSITE 
are the product of a substructure of interpenetratingcones that by their arrangement and by the skilled 
manipulation of the parameters governing their breadth, height, slope, and other features can be made 
to represent a wide variety of landforms, both naturalistic and formalized. By working with as few 
as one or two of these conical forms, or with as many as a hun­ dred or more, the designer can either 
create an arrangement of precise, geometrically shaped forms as a kind of landform sculpture on an 
environmen­ tal scale, or he can fuse and blend the same col­ lection into a configurationof gentle rolling 
 hills or other form of natural topography. Indeed, this single geometrical element--the cone--has 
turned out to be so versatile as regards the trans­ formations to which it is susceptible that there 
 is reason to question whether more might be lost than gained in learnability and operating conve­ nience 
by expanding the library to include, for example, the full set of geometrical primitives utilized by 
the MAGI system [6]. ECOSITE, although it has already achieved a sub­stantial degree of interactive 
conversationality on the remote batch and time-sharing system on which it is currently implemented,will 
only begin to demonstrate its full potential when it has been expanded and upgraded as a fully interactive 
sys­tem. With this and other improvements in mind, the program has been designed as a modular block 
structure that allows for an increase both in the number of blocks and the number of functions and routines 
that can be incorporated into a single block. Consisting of three at this point, the first block (called 
INITS) provides for the ini­tialization of the X/Y grid plane and of the para­ meters of the starting 
collection of forms; the 2  second (called MODIFY) provides for the manipula­ tion of the forms and 
their parameters as the com­position undergoes development and refinement, while the third (called PLOTS) 
incorporates all the routines pertaining to both the kind of graphic image that is wanted and the kind 
of output device on which the images are generated. Unlike Fig. 1, which portrays structuremore than 
process, Fig. 2 graphically depicts both the dynamics as well as the structure of ECOSITE by showing 
the start-up sequence of commands and operations, the feedback loops, and the multiple interactive options 
that can be accessed once the conversationalphase of the design process is underway. Since coal strata 
are mainly horizontal in their orientation the effect of the stripping operation is to lay bare a generally 
flat surface on which the overburden is backfilled and reshaped. This overall flatness is a welcome 
convenience since it enables the design­ er to deploy the forms in relation to a horizont­ ally-orientedX/Y 
grid plane. So with this as the basic frame of reference the design process gets underway with the following 
sequence of operations.  The X/Y Grid Plane At present the standard format for the grid plane is a 
128 X 128 square, though the proportion can be varied for matching the shape of a particular site. Moreover, 
if the designer should have ac­ cess to a display with a superior image resolution capability he can 
take advantage of this by in­creasing the number of elements in the grid plane far beyond the standard 
128 X 128. As seen from a somewhat arbitrary "front" the origin of the X, Y,Z coordinate system is the 
lower left hand cor­ner of the grid, with X extending to the right, Y extending back into the 3-space, 
and with Z as the elevation values of the landforms (see Fig. 3). Although the design process is considered 
to be concentratedmainly within the grid plane, forms can also straddle the edge in such a way as to 
 fall partly within and partly outside the grid. Conversely, a region within the grid plane can be 
selected as the work space if the designer wishes to zoom in on a portion of the composition for a 
closer inspection of the details. Shaping the Base of a Form Each form is named and identified by referring 
to its base, such as BASEl, BASE2. The size and shape of the base are determined by the length of 
the four axes shown in the top drawing in Fig. 4, and it is by varying the relative lengths of these 
 axes that an impressive diversity of both symmet­ rical and asymmetrical elliptical shapes are gen­ 
erated, as shown in the other plots in this same series. By varying the parameters of HYPER, what starts 
as an ellipse can be changed by degrees into an approximate rectangle, as shown by the series of plots 
comprising Fig. 5. If HYPER is assigned a negative value, the shape of the el­ lipse goes into reverse, 
as it were, and become somewhat cruciform in character. By assigning different values of HYPER to each 
of the four quadrants of the base the more complex shapes within this group are generated. Other Parameters 
for Shaping the Form Although the width, breadth, and shape of the base are indispensible parameters 
for generating a form, they are hardly sufficient for defining its full three-dimensionalcharacter. Therefore 
additional 3 parameters are needed. HITE determines the elevation of the cone on its vertical axis. 
If assigned an extremely high value the cone approximates a towering cylinder, a topographical impossibility 
which must then be truncated and flattened if it is to serve as a disc-like landform having any plausible 
relation­ ship to reclamation design. If assigned a low value the form retains a conical and somewhat 
more naturalistic appearance. Despite its name what HITE determines is not the height of the form but 
 rather the angle and slope of its sides in rela­ tion to the grid plane (see Fig. 6). TRUNC is the 
point above the grid plane at which the cone is truncated for determining the height of the form--i.e., 
this parameter, not HITE, es­ tablishes this conspicuous feature (see Fig. 6). FLAT determines the shape 
of the crown of the form. If the parameter is assigned a value of 3.0 or less, the crown is rounded 
and parabolic; higher values flatten the crown to the point that the form is effectively a truncated 
cone (see Fig. 7). SMOOTH determines the level at which the form be­ gins to blend into the grid plane 
and/or into ad­ jacent forms, including forms in which it may be imbedded or that may be imbedded within 
it. A powerful feature of the program is that each form can be assigned its own smoothing value so 
that some can be left sharp and geometrically precise in shape while others are fused and homogenized 
as clusters and arrays (see Fig. 8). However, when adjacent and/or interpenetrating forms are assign­ed 
different values, the form initialized first in the series imposes its smoothing value on the others 
(see Fig. 9). Positioning and Orienting the Form on the Grid Plane Two values, one for the X coordinate 
and the other for the Y, locate the center of the form on the grid plane. A third parameter, ANGLE, 
determines the rotation of the form in reference to the X axis, which can be any value between zero 
and 360 degrees (see Fig. 3). For generating naturalistic topography of the "gentle rolling hills" 
variety it is normal to interweave serialized clusters of forms, most of which are interpenetrating 
one an­ other. In general, the more rugged and irregular the terrain that is being designed or simulated, 
 the greater the number of forms that is apt to be used and the greater the care and patience that must 
be exercised in the design process. A Variety of Graphic Modes Having generated and arranged an initial 
collection of forms on the grid plane, the designer must as­sess the effect as a coherent design then 
continue to monitor the changes as the composition undergoes   4  revision and development--a form 
of "editing," as it were. The opportunity to refer to a variety of graphic modes in the form of maps, 
diagrams, and various kinds of perspective renderings (and in­cluding, of course, rotation in real-time 
if pos­ sible) can help the designer arrive at a more ac­curate three-dimensionalimpression of the spatial/ 
volumetric relations in the design being developed. At present four kinds of plots are available, though 
more are planned for the future. (see the items under "graphic modes" in Fig. 1). PERSP generates a 
wireframe drawing in perspective with the hidden lines removed, this being the clos­est approximation 
to a realistic representationof landforms that it is possible to achieve with ECOSITE at its present 
stage of development. De­pending on how it is displayed, the plot can be interpretedby the viewer as 
a representation of either an actual reclamation site or of a three- Either way, dimensional relief 
model of a site. since the representationis authentically three­dimensional it can be subjected to all 
of the stan­dard operations (rotation, windowing, etc.) in the current repertory of interactive graphics 
(see Fig. 13 and Fig. 14) [7]. PLANVIEW enables the composition to be seen from above as a two-dimensionalplan. 
Essentially a diagram,it anticipates a time in the future when the computer, in addition to all the other 
alpha­ numeric and graphical documentation it will be gen­ erating in the course of the design process, 
will also output quantitative and symbolical information pertaining to the syntactic organization of 
the landform composition as a formal design. But for  the present the drawings produced by this routine 
perform the far more useful function of helping the designer keep track of the forms as they keep chang­ 
ing their shape, orientation, and location on the grid plane (see Fig. 10). CONTOUR calls up a routine 
to translate the com­position into yet another graphical form: a conven­map of the sort used as extensively 
 tional contour in the surface-mineindustry as in other fields of Like PLAN­ large-scale excavation 
and site design. VIEW, since it as well involves a crude form of proto-analysis of the syntactic relations 
in the an eventual  landform composition, it anticipates link between CAD, computer art, and computer-based 
 research in experimental aesthetics. But in a more practical vein it also anticipates the time when 
computer-made maps and blueprints will be used both for preplanning reclamation and for carrying out 
the plans and designs as well (see Fig. 11). SLICE plots a series of vertical contour slices that can 
be used As templates for transforminga promising composition into a three-dimensionalre­ lief model (see 
Fig. 12) [8]. Thus viewed as an actual object the composition can be fully assessed for its sculptural 
qualities, the contours can be revised and improved by hand if necessary, and miniature trees, roads, 
structures, and other land­scape features can be hand-fashionedand attached to the relief model for 
helping to develop all the requirementsof a complete reclamation plan. Though hand made at present, 
the three-dimensional coordinate information used by SLICE for generating these templates also has the 
potential of being used for automating the productionof these models through some form of numerical 
control (N/C). Modification and Developmentof the Composition After having used INITS to initialize 
and arrange a set of forms on the grid plane and then used PLOTS to view the result, the designer is 
ready to enter the truly interactive phase of the design process by using MODIFY to develop and "edit" 
the composition. But as an alternativepossibility, INITS can be by-passed by either drawing upon one 
 or more "stock" arrangements of forms and using these as the point of departure,or by retrieving an 
entire composition that has previouslybeen cre­ ated and stored (see Fig. 2). Though the set of form-processingroutines 
incorporated into MODIFY is restricted to only four at present, the reper­ tory should and will be much 
expanded in the future.  FACTOR enables the designer to select any one or more of the forms and any 
one or more of their par­ ameters, then factor them by a given value. In this way a form, a group of 
forms, or all of the forms in the composition can be, for example, ro­ tated by a given number of degree, 
translated a certain distance, made larger or smaller in size, and changed in shape. The smoothing 
parameter is particularlypowerful in this respect since it can transforman entire collection of clean, 
geometric forms into a simulation of gentle undulating natu­ ralistic topography. Or, by the syntactic 
princi­ pal of gradient transitions [5], it can be used to fuse and harmonize the one class of landforms 
with the other. REPLACE enables the designer to substitute any ex­ isting parameter value with a new 
one. That this  can be done to each form and to each form feature one at a time permits the designer 
to "massage" and refine the forms and in general to exercise the degree of precise control that is 
so essential, particularlyat the final stage of the design process.  ADD/DELETE enables the designer 
to introduce new forms at any stage of the design process and to remove (and then re-introduce, if necessary) 
forms that are already there. Though ADD/DELETE draws upon the same routines used at the start-up stage 
of the design process (INITS), these have been cloned and inserted in MODIFY for efficiency and faster 
access. INSTANCE enables the designer to incorporate en­tire sets of forms into a new composition in 
the ways that have already been noted. In other words, these sets may have been previouslydevised to 
serve as standard start-up configurations,or they can be portions of another composition that has been 
filed away for subsequent assessment, rework­ ing, and possible completion. The parameters re­ quired 
for this surgery pertain to the rescaling and repositioning of the old compositionwithin the new one. 
 5. EVALUATION Though ECOSITE as a prototype program has been successful in demonstrating that the 
resources of interactive graphics and CAD can indeed be applied to the design of landforms for reclamation, 
a number of substantial improvements are necessary before this fledgling application of CAD is ready 
 for an all-out testing in the real-world of sur­ face mining and reclamation. Of these improve­ ments 
the most important is that ECOSITE should ultimately be developed into a program for land­ scape as 
well as landform design. Since landform structure is the relatively durable foundation for the many 
dynamic events that take place on the surface through a 'combinationof natural processes and human 
intervention, the ability to help design landforms is without doubt the most important single requirement 
for any computer-assistedfa­ cility for reclamation preplanning-and-design. But landform design is but 
a subset of landscape design, a more inclusive schema that -incorporates  not only the substructure 
of topographical relief formations, but also includes the trees, roads, ponds, and other vegetative 
features, objects,and structures that embellish and vitalize the under­lying landforms. Hence ECOSITE 
(or any other pro­gram developed with the same purpose in mind) should eventually be able to represent 
and display all aspects of landscapes and scenery, including colors, forms, textures, and other visual 
 attributes ACKNOWLEDGEMENTS The support of the NEA to this research has al­ready been noted. But we 
should also acknowledge the initial seed funding provided jointly by the Sloan Foundation and the Graduate 
Research Council of the University of Massachusetts, as well as the invaluable assistance provided by 
Dr. Michael Mallary of Northeastern University, who conceived and designed the initial version of ECOSITE 
and who has since continued to make substantial con­tributions to the development of the program. Fig. 
13 Symmetrical configuration of geometrical, formalized landforms  6  [1] Gonin, M. and Moffett, 
T.J. ARTES, an Improved Highway Design Program. Proceedings of the Third Annual Conference on Computer 
Graphics and Interactive Techniques-SIGGRAPH '76, Computer Graphics. Vol. 10, No. 2, Summer, 1976, pp. 
268-274. [2] Mallary, R. and Carlozzi, C.A. The Aesthetics of Surface-MineReclamation: an On-site Survey 
in Appalachia 1975/76. ARSTECNICA/Institutefor Man and Environment (1976) The University of Massachusetts,Amherst. 
 Laboratory for Computer Graphics and Spatial Analysis SYMVU Manual. (1975) Harvard Univer­sity, Cambridge, 
Mass.  [4] Environmental Systems Research Institute, VIEWS User's Manual. (1975), Redlands, Calif. 
[5] Cole, N. et al., Visual Design Resources for Surface-mine Reclamation. ARSTECNICA/Institute for Man 
and Environment (1976), University of Massachusetts, Amherst, Mass. [6] Mathematical Applications Group, 
Inc. Description of the MAGI Technique for Accurate Modeling and Graphic Display of Three Dimen­sional 
Objects. (1967) Elmsford, New York. [7] Newman,W.M. and Sproull, R.F. Principles of Interactive Computer 
Graphics,McGraw-Hill, New York, 1973. [8] Mallary, R. TRANS2: a Computer-graphics Pro­gram to Make Sculpture, 
AFIPS Conference Pro­ceedings, Fall Joint Computer Conference, Vol. 37 (1970) AFIPS Press, Montvale, 
New Jersey, pp. 451-46,0.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563860</article_id>
		<sort_key>8</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Graphical pre- and post-processor for 2-dimensional finite element method programs]]></title>
		<page_from>8</page_from>
		<page_to>12</page_to>
		<doi_number>10.1145/563858.563860</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563860</url>
		<abstract>
			<par><![CDATA[This paper describes a two-dimensional interactive graphics pre- and post-processor system developed at the U. S. Army Engineer Waterways Experiment Station (WES) for the finite element method (FEM). The paper describes advantages of the data structure of the package and new algorithms developed for grid generation and analysis output display. The programs are developed especially for a time-sharing system (Honeywell G-635) to be used on a storage tube type terminal (Tektronix 4012 or 4014). Programming techniques used to counter the lack of immediate response on such a system are also discussed.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35027348</person_id>
				<author_profile_id><![CDATA[81100305306]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fred]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[Tracy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Waterways Experiment Station, Vicksburg, MS]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Zienkiewicz, O. C., and Phillips, D. V., An Automatic Mesh Generation Scheme for Plane and Curved Surfaces by 'Isoparametric' coordinates. IJNME 3 (1971), 519-528.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Crawford, J. E., GEN2D user's manual (1973).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Kamel, H. A., A Two-Dimensional Package for Finite Element Analysis Utilizing Interactive Mini-Computer Graphics. IFID IFAC, JSNA Conference on computer applications in the automation of shipyard operation and ship design. Tokyo, Japan (Aug 1973).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Kamel, H. A., A Graphics Oriented Interactive Finite Element Time Sharing Package (Jul 1973).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cavendish, J. C., Automatic Triangulation of Arbitrary Planar Domains for the Finite Element Method (IJNME 8 (1974)), 679-696.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Akyuz, F. A., An Automatic Data Generation Scheme for a Finite Element Method. Nuclear Engineering and Design 11 (1970), 195-207.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Yeung, S. F., and Hsu, M. B., A Mesh Generation Method Based on Set Theory, Computers and Structures 3 (1973), 1063-1077.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Frederick, C. O., Wong, Y. C., and Edge, F. W., Two-Dimensional Automatic Mesh Generation for Structural Analysis (IJNME 2 (1970)), 133-144.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 GRAPHICAL PRE- AND POST-PROCESSORFOR 2-DIMENSIONAL FINITE ELEMENT METHOD PROGRAMS Fred T. Tracy Waterways 
Experiment Station Vicksburg, MS 39180 This paper describes a two-dimensionalinteractive graphics pre-and 
post-processorsystem developed at the U. S. Army Engineer Waterways Experiment Station (WES) for the 
finite element method (FEM). The paper describes advantages of the data structure of the package and 
new algorithms developed for grid generation and analysis output display. The programs are developed 
especially for a time-sharing system (Honeywell G-635) to be used on a storage tube type terminal (Tektronix4012 
or 4014). Programming tech­niques used to counter the lack of immediate response on such a system are 
also discussed. 1. Pre-processor If the user wants a triangular mesh, he needs only to divide the problem 
into simply connected The pre-processor is composed of four subregions (see Fig. 2 and the resulting 
grid in modules: Fig. 3). For all quadrilateral grids the subdi­ vision shown in Fig. 4 which has four-sided 
sub­ a. Reads and interactively edits the input regions is used. Fig. 5 shows the resulting grid. data 
which are used to generate the FEM grid, and then if no errors are detected, 3. Defining subregions generates 
the grid. b. Applies boundary condition information to the grid. GIFTS developed by Kamel (3) and (4) 
requires the user to specify what line segments form the subregions, whereas the system being described 
c. Applies automatic editing features of automaticallymakes this determination. While smoothing, bandwidth 
minization, and this is a feature useful for any type hardware, it triangle removal. is especially helpful 
in a medium response time­ d. Plots and interactively edits the grid. sharing system. It is done as follows: 
a. Arrange all line segments about their The basic concept used in generating a grid respective subregion 
points in counter­ is to divide the geometry into subregions. The clockwise order. four-sided subregion 
using the isoparametric in­terpolationfunction developed by Zienkiewicz and Phillips (1) was chosen as 
the basic sub­region for its speed and generation of esthetic grids. A transition zone algorithm generating 
triangular meshes for irregularly shaped simply connected subregions was developed to compliment the 
four-sided subregion. Laplace smoothing as used by Crawford (2) can now be applied to both b. Start at 
a given subregion point and a line segment going into that point. Ad­vance to the second point of the 
line segment, and using that point as a pivot, advance to the next line segment in the counterclockwisedirection. 
This line segment is the second line of the subregion. mesh types with only a few iterations being re­ 
c. Repeat the process outlined above until quired for convergence. the second point of the new line segment 
is the original point, thus closing the 2. Data structure for grid generator subregion. The grid generator 
needs only two types of 4. Triangular mesh generation algorithm data: subregion points and line segments 
(see Fig. 1). Note there is a curved line segment, a The technique used in this pre-processorto hole 
making the geometry multiply-connected,and generate a triangularmesh inside a simply con­ a notch. The 
asterisks represent generated nodes nected subregion is faster, simpler, and places along the line segments, 
the A represent material less restrictions on the geometry than most other type 1, and the perpendicularlines 
which inter­ techniques. Rather than generate a set of nodes sect the line segments identify interpolation 
inside the given region by random number tech­ points for the quadradic line segments. The niques or 
by subdivisiontechniques such as was dashed lines represent temporary line segments used by Cavendish 
(5) and then try to piece the with respect to smoothing. nodes into a triangular mesh, this algorithm 
Permission to make digital or hard copies of part or all of this work or developes both nodes and elements 
concurrently. personal or classroom use is granted without fee provided that copies are not made or distributed 
for profit or commercial advantage and that copies bear this notice and the full citation on the first 
page. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior 
8 specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California  9 Also topographical 
limitations imposed by Akyuz (6) and Yeung and Hsu (7) are not required. The technique is similar to 
that of Frederick, Wong, and Edge (8) but requires less checking in general. Below is an outline of the 
algorithm: a. Assemble the nodes of the subregion in an array in counterclockwise order to form a polygon. 
 less than or equal to 90° by forming triangular elements (see Fig. 6a). Up­date the polygon array (less 
one point for each triangle formed) to represent that part of the subregion not as yet filled with elements. 
 b. Remove all vertex angles of the polygon  c. Start at some vertex (B) with angle less  °  adjacent 
points to the vertex (A and C) and new point D (see Fig. 6b). ) For (XD, use  90 . If so, repeat step 
b until it is possible to do step c again or the regiol has only three points left. From the last three 
points form a triangular ele­ment, and the process is complete.  the new polygon less than or equal 
to ° Smoothing is usually required after the ini­tial grid has been generated. Triangle annihlia­tion 
may also be useful. 5. Sample grids Fig. 7 shows some typical grids generated by this package.  6. 
Post-processor The post-processortakes a data file gener­ated by a FEM analysis program and plots the 
out­put in various ways: (a) numbers, (b) vectors, (c) contours, (d) displaced grid. While these options 
are rather standard, one innovative addi­tion has been made. The FEM grid is checked by a one-time-only, 
nonsearch technique developed by the author to determine what nodes lie on the boundary of the grid. 
This allows the outline of the grid to be plotted with other graphic display. The reason the input line 
segment data described above cannot be used is that one cannot assume the results being plotted are from 
a generated grid. Fig. 8 shows some typical output from this package. 7. Determining the exterior nodes 
 The exterior nodes can be determined by a nonsearch technique as follows:  a. Initialize to zero an 
array IOUT the length of the number of node points.  b. Loop over all the elements, and for the nodes 
I, J, K, L, of each element, do  c. After this element loop, internal nodes will have IOUT = 0, and 
external nodes will have IOUT 0.  Acknowledgements The above work was done using Army R&#38;D funds. 
Special thanks go to the CAB staff, ADPC, WES, for their advice and support throughout the project. 
References 1. Zienkiewicz, O. C., and Phillips, D. V., An Automatic Mesh Generation Scheme for Plane 
and Curved Surfaces by 'Isoparametric' coordinates. IJNME 3 (1971), 519-528. 2. Crawford, J. E., GEN2D 
user's manual (1973).  3. Kamel, H. A., A Two-Dimensional Package for Finite Element Analysis Utilizing 
Interac­tive Mini-Computer Graphics. IFID IFAC, JSNA Conference on computer applications in the automation 
of shipyard operation and ship design. Tokyo, Japan (Aug1973).  4. Kamel, H. A., A Graphics Oriented 
Interac­tive Finite Element Time Sharing Package (Jul 1973).  5. Cavendish, J. C., Automatic Triangulation 
of Arbitrary Planar Domains for the Finite Ele­ment Method (IJNME 8 (1974)), 679-696.  6. Akyuz, F. 
A., An Automatic Data Generation Scheme for a Finite Element Method. Nuclear Engineering and Design 11 
(1970),;195-207.  7. Yeung, S. F., and Hsu, M. B., A Mesh Genera­tion Method Based on Set Theory, Computers 
and Structures 3 (1973), 1063-1077.  8. Frederick, C. 0., Wong, Y. C., and Edge, F. W., Two-DimensionalAutomatic 
Mesh Generation for Structural Analysis (IJNME 2 (1970)), 133-144.  12 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563861</article_id>
		<sort_key>13</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[CASS]]></title>
		<subtitle><![CDATA[computer-assisted stereotaxic surgery]]></subtitle>
		<page_from>13</page_from>
		<page_to>17</page_to>
		<doi_number>10.1145/563858.563861</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563861</url>
		<abstract>
			<par><![CDATA[An interactive computer graphics system has been developed for online use with a two-stage stereotaxic technique in man. The computer plots sagittal sections approximating the region of the brain being stimulated on a display screen located in the operating room. When responses are elicited by electrical stimulation, they are graphically illustrated on the template, accurately positioned at the brain site being stimulated. If such evoked responses do not fit the template, they can be replotted on a modified template in a manner prescribed by the neurosurgeon. Such a system allows optimal localization of subcortical lesion sites.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[stereotaxis figurine mappings graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379960</person_id>
				<author_profile_id><![CDATA[81100068393]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[P.]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Hawrylyshyn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Toronto, and Toronto General Hospital, Toronto, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379962</person_id>
				<author_profile_id><![CDATA[81100367781]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Tasker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Toronto, and Toronto General Hospital, Toronto, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379955</person_id>
				<author_profile_id><![CDATA[81100010468]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[L.]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Organ]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Toronto, and Toronto General Hospital, Toronto, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bertrand, A., Oliver, A., and Thompson, C. J. : Computer display of stereotaxic brain maps and probe tracts. Acta. Neurochir. (Suppl.) 21 (1974), pp. 235-243.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Hawrylyshyn, P. A., Rowe, I. H., Tasker, R. R., and Organ, L. W. : A computer system for stereotaxic neurosurgery. Comput. Biol. Med. 6 (1976) pp. 87-97.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Peluso, F. and Gybels, J. : Computer calculation of the position of the side-protuding electrode tip during penetration in the human brain. Confin. Neurol. 34 (1972) , pp. 94-99.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Schaltenbrand, G. and Bailey, P. : Introduction to stereotaxis with an atlas of the human brain Georg-Thieme, Stuttgart (1959) , Volume 1.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Tasker, R. R. : Simple localization for stereo-encephalotomy using the portable central beam of the image intensifier. Confin. Neurol. 26 (1965) , pp. 209-212.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Tasker, R. R., Rowe, I. H., Hawrylyshyn, P. A.,. and Organ, L. W. : Computer mapping of brainstem sensory centres in man. J. Neurosurg. 44 (1976) pp. 458-464.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 CASS : Computer-Assisted Stereotaxic Surgery P.A. Hawrylyshyn, R.R. Tasker,L.W. Organ Departments of 
Physiology &#38; Surgery, University of Toronto, and the Neurosurgical Unit Toronto General Hospital, 
Toronto, Canada. Keywords : Stereotaxis Figurine ABSTRACT An interactive computer graphics system has 
been developed for online use with a two-stage stereotaxic technique in man. The computer plots sagittal 
sections approximating the region of the brain being stimulated on a display screen located in the operating 
room. When responses are elicited by electrical stimulation, they are graphically illustrated on the 
template, accurately positioned at the brain site being stimulated. If such evoked responses do not fit 
the template, they can be replotted on a modified template in a manner pre­scribed by the neurosurgeon. 
Such a system allows optimal localization of subcortical lesion sites. INTRODUCTION Stereotaxic surgery 
has been variously defined, but its essential feature is the introduction of a surgical probe through 
the brain using guidance methods other than direct vision, towards a target that is not accessible to 
open operative approaches The technique has expanded from its earliest application in treating dyskinesias, 
to include the treatment of pain syndromes,seizure disorders and brain tumors. However, since such surgery 
ultimately leads to irreversible destruction of subcortical structures, stereotaxis remains a challenging 
and demanding operative technique necessitating precise localization of intracranial structures. The 
interactive, online computer graphics system to be described, represents a new concept enabling the neurosurgeon 
to recognize and select lesion sites with greater accuracy than has previously been possible. NEUSURGICAL 
CONSIDERATIONS In order to appreciate the need for computer assistance during stereotaxis, the complexity 
of the technique and the relevant problems confronting the neurosurgeon must be briefly discussed. Any 
stereotaxic technique consists of the following steps: 1. Determination of the co-ordinates of the target 
structure relative to an external reference system by roentgenological means. 2. Corroboration of the 
roengenological co­ordinates by neurophysiological means, while approaching the target area employing 
a precision stereotaxtic apparatus. 3. Destruction of the target structure.  Permission to make digital 
or hard copies of part or all of this work or personal or classroom use is granted without fee provided 
that copies are not made or distributed for profit or commercial advantage and that copies bear this 
notice and the full citation on the first page. To copy otherwise, to 13 republish, to post on servers, 
or to redistribute to lists, requires prior specific permission and/or a fee. Siggraph 77, July 20-22 
San Jose, California Mappings Graphics The stereotaxic Leksell frame when firmly se­cured to the patient 
s head with special skull pins, establishes a three-dimensional rectangular co-ordinate system which 
serves as a reference for all subsequent measurements (Fig. 1). A semi­circular arc attached to the frame 
acts as a guid­ance mechanism for the probe, in this case a concentric bipolar electrode. From the frame 
geometry it is always possible to calculate the frame co-ordinates for the electrode tip, but it remains 
to relate these to the patient s intra­cranial structures. Two prominent anatomical landmarks bounding 
the target area are used to define the target structure relative to the Leksell frame. The anterior (AC) 
and posterior (PC) commissures are identified during the first stage of the operation by positive contrast 
ventriculography, when special plastic bars carrying longitudinal steel wires are attached to both sides 
of the Leksell frame. This permits the determination of the frame co-ordinates for the AC and PC with 
the help of a portable image intensifier.(5) Such reference structures are also important in that they 
define a brain co-ordinate system used by standard stereotaxic atlases.(4) That is, atlas templates have 
been prepared from anatomical studies, which relate the position of brain struc­tures of interest to 
an internal brain co-ordinate system based upon reference structures identifiable Figure 1 -Stereotaxic 
Leksell frame attached to the patient s head. The electrode is seen attached to the semicircular arc. 
 -tY Leksell Figure 2 -Relationship of the Leksell frame to the brain X-axis (AC-PC line), and the thalamic 
lesion site. by radiographic techniques. For the thalamic region, the intercommissural or AC-PC line 
defines the X­axis of the brain atlas, while the Y-axis is positioned at the midpoint of the AC-PC line, 
the brain-origin (Fig. 2). If the relationship between the target structure and the brain origin is known 
from the stereotaxic atlas,and the AC and PC frame co-ordinates have been established, it is possible 
to derive the frame co-ordinates for the target structure. However, these will only be the true frame 
co­ordinates if the individual patient s brain is identical to that from which the stereotaxic atlas 
was constructed. As this is highly unlikely, the roentgenological frame co-ordinates of the target structure 
are only approximate, and must be precisely corroborated by additional neurophysio­ logical methods. 
For this, electrical stimulation is employed to delineate the various neural path­ways near the target 
structure. Stimulation is carried out with 100Hz biphasic electrical pulses at incremental steps of 2mm 
along a trajectory which passes through the tentative target site. To allow for individual variability, 
two alternative target sites lying 2 mm in front of and behind the tentatively selected target site are 
also stimulated. Such threshold stimulation elicits characteristic, reproducable responses permitting 
more precise localization. With thalamic stimulation the most common response is paraesthesia in some 
portion of the body, usually described as a tingling or numbness. Less frequently auditory, visual and 
vestibular effects are also elicited. With the records from stimulation at up to 50 sites covering an 
area of brain about 20mm X 4mm, the neurosurgeon is confronted with a mass of data which must be interpreted 
during the course of the operation. From this, one site must be selected for the final therapeutic lesion, 
which is pro­ duced with a specially designed radiofrequency lesion generator. COMPUTER SYSTEM IMPLEMENTATION 
In order to facilitate more accurate localiza­tion of the subcortical lesion sites, an inter­active computer 
graphics system was developed to process the data collected during the operation. its development was 
guided by two major objectives: 1. Correction for frame misalignments and variations in individual brain 
dimensions.  2. Provision of an online graphical display of the evoked responses.  Previous applications 
of computer technology to stereotaxic procedures were designed to calculate the position of the electrode 
tip based upon radiological measurements.(3) However, such programs involved offline systems and provided 
numerical results in tabular form. Subsequent attempts in­troduced the concept of displaying stereotaxic 
brain templates on a computer display. Our own group became interested in a graphical approach to the 
problem in 1974. A prototype system was completed by 1975; however, the system s turn­around time was 
too slow because the graphical plotter was not located in the operating room. 2 This paper describes 
the revised computer graphics system presently used during stereotaxic procedures performed at the Neurosurgical 
Unit of the Toronto General Hospital. Compter facilities at the University of Toronto located near the 
hospital provide the central processors for the system. Two data communications terminals located in 
the operating room are linked OPERATING ROOM Figure 3 Components of the CASS computer system. The Gould 
plotter is driven by software routines on the IBM 14 via telephone to an IBM 370/165 computer (Fig. 3). 
A Tektronix 4014 computer graphics terminal is operated interactively in a graphical mode under the IBM 
software package TSO (Time Sharing Option). In the event of a hardware failure, an I.P. Sharpe 100 data 
communications terminal can be linked to an IBM 360/165 computer as a backup system. Operated under interactive 
APL (A Programming Language), the data from the operation can be processed offline on a Gould 5000 electrostatic 
plotter, and the results can be returned via courier to the operating room. The Gould plotter is also 
employed as a hardcopy unit to make a permanent record of the information plotted on the Tektronix 4014 
display screen. The software programmes to process the data are written in Fortran, and utilize a computer 
graphics package in which figures are represented as a series of digitized points consisting of an X 
and Y co-ordinate, and a pen control character. Sub­ routines were developed to scale, rotate and translate 
figures about any specified point. In addition, subfigures can be extracted by specifying boundary points, 
and such subsets can be plotted individually or also shaded as part of a larger figure. To correct for 
any misalignment of the stereo­taxic frame from an assumed rectilinear midline postion with respect to 
the brain, a unique math­ematical transformation is derived which relates the Leksell frame to the brain 
co-ordinate system.2 In this manner, the computer programmes can always translate any frame co-ordinate 
to the corresponding brain structure regardless of how the frame is attached to the patient's head. 
To correct for individual variation in dience­phalic structures, posed a more difficult problem. Since 
the intercommissural distance (AC-PC line) for 125 selected patients has ranged from 21 to 33mm, simply 
superimposing appropriately oriented diagrams of atlas templates over the midcommissural point may introduce 
an error in localization of up to 5mm. To compensate for this, serial sagittal sections from the Schaltenbrand 
and Bailey atlas4 which have been digitized and stored online in the computer, are modified by elongation 
or reduction along the template's AC-PC axis until it matches that of the patient. Where indicated, a 
second scaling factor can also be applied along the Y ­axis perpendicular to the AC-PC line based on 
measurements of dorsal thalamic height obtained from radiographic studies. To graphically illustrate 
the responses which are elicited by electrical stimulation, a protocol had to be developed to encode 
all possible res­ponses. As most responses are restricted to a specific anatomical region, storage of 
the evoked physiological data is accomplished with reference to six homunculus figurines subdivided into 
numbered body regions (Fig. 4). Two additional codes indicate unresponsive stimulation sites, or allow 
alphanumeric text to be substituted for a figurine. To complement such homunculi, a set of symbols was 
developed to describe the quality of the response -for example: P for paraesthesia, H for hot, TA for 
tremor arrest, and so on. To stand­ardize procedures on different cerebral hemispheres, responses are 
always referred to an ipsilateral ­contralateral orientation relative to the side of surgical procedure. 
Accordingly, a paraesthetic tingling in the left cheek during a right-sided thalamotomy (ie -a contralateral 
response) would be encoded as Figurine # 1, Region # 4, Quality -P. The interactive encoding and plotting 
of the evoked sensory responses is performed in several steps (Fig. 5). Initially, personal data on the 
patient such as name, age, sex, and diagnosisare  15  Figure 6 Figurine mapping for patient A.S. Triangles 
indicate unresponsive stimulation sites. The shaded areas represent the area to which the response was 
referred,and threshold current levels are proportional to the shading density. The predomi­nant responses 
are paraesthetic, tingling (P) responses. From the mapping, there appears to be an apparent anterior 
displacementof the evoked responses relative to the atlas template. Figure 7 Revised mapping for 
patient A.S. obtained by applying a 4mm shift directed posteriorly to all re­sponses. The paraesthetic 
facial responses are now centred about VC, and stimulation near the base of Vim arrested the nesting 
 tremor of the patient. Such a mapping is typical for stimu­ lation of the thalamus 12 mm lateral to 
the midline.  16  CONCLUSIONS collected. The frame co-ordinates for the anterior and posterior commissures(AC 
and PC) are entered permitting the derivation of the mathematical transformation relating the Leksell 
frame to the brain co-ordinate system. The neurosurgeon selects from the appropriate atlas template 
that portion which encloses the area to be stimulated, and this subtemplate is then enlarged on the 
Tektronix display screen. At the start of each trajectory the frame co-ordinates for the target site 
and the trajectory angles relative to the Leksell frame are entered. When a response is elicited, the 
site depth along the trajectory, the threshold stimu­ lation current and the encoded representation of 
the response are entered. The response is then plotted correctly positioned on the display screen 2 
 employing equations described previously.In this manner, a composite figurine mapping is built up 
which illustrates the stimulation sites and the elicited sensory responses. RESULTS From the figurine 
mapping, the neurosurgeon can ascertain whether the evoked responses match those which would have been 
anticipated on the basis of the anatomical structures depicted by the atlas template. That is, stimulation 
of specific res­ regions elicits characteristic, reproducible For instance, stimulation of the thalamic 
region termed nucleus ventrocaudalis (VCa,p) elicits a a paraesthetic, tingling sensation referred 
to discrete portion of the body. Stimulation of the inferior aspect of the area termed nucleus ventro­ 
intermedius(Vim), frequentlyarrests a Parkinsonian patient's resting tremor; and consequently this region 
constitutes the final lesion site. Other thalamic regions such as nucleus ventro-oralis(VO) are usually 
silent to stimulation. However, occasionally the reported responses do not match those anticipated at 
that particular site. As a result, the neurosurgeon is confronted with the problem of attempting to match 
a pattern of evoked responses to the atlas template, and recognizing what individual anatomical variations 
are responsible for the discrepancy. Such was the case for a patient A.S. with Parkinson's Disease who 
was operated upon in June, 1973. From the initial response mapping (Fig. 6), stimulation at the base 
of the area termed VOa appeared to arrest the patient's tremor (TA), and the paraesthetic(P) perioral 
responses appeared to be centred about Vim. Applying a 4mm shift directed posteriorly to all responses 
resulted in the transposed map which had been originally anticipated. (Fig. 7) Consequently, radiological 
localization had failed to demonstrate an apparent 4mm anterior displace­ment of the thalamic region. 
Had a lesion been made at the initial target site, the patient would have developed permanent numbness 
in his cheek. However, the lesion placed at the revised site confirmed by electrophysiological stimulation 
abolished the patient's hand tremor which has not recurred.  The revised computer system has now been 
in use at Toronto General Hospital for over ten months. Based on experience gained during this trial 
period, it has become apparent that such a computer graphics system is not only an invaluable aid in 
displaying electrophysiological data; but it enables the neuro­surgeon to localize intracranial lesion 
sites with greater accuracy than has been previously possible, and thereby decrease the morbidity associated 
with the procedure. REFERENCES Bertrand,A., Oliver, A., and Thompson,C.J. : 1. Computer display of 
stereotaxic brain maps and probe tracts. Acta. Neurochir. (Suppl.) 21 (1974), pp. 235-243. Hawrylyshyn, 
P.A., Rowe, I.H., Tasker,R.R.,and 2. Organ,L.W. : A computer system for stereotaxic Med. 6 (1976) 
neurosurgery. Comput. Biol. pp. 87-97. Peluso,F. and Gybels,J. : Computer calculation 3.  of the 
position of the side-protuding electrode tip during penetration in the human brain. Confin. Neurol. 34 
(1972) ,pp. 94-99. 4. Schaltenbrand,G. and Bailey, P. : Introduction to stereotaxis with an atlas of 
the human brain  ,Volume1.  Georg-Thieme, Stuttgart (1959) 5. Tasker, R.R. : Simple localization for 
stereo­encephalotomy using the portable central beam  of the image intensifier. Confin. Neurol. 26 (1965) 
,pp. 209-212.  6. Tasker, R.R., Rowe, I.H., Hawrylyshyn, P.A.,.  and Organ, L.W. : Computer mapping 
of brainstem sensory centres in man. J. Neurosurg. 44 (1976) pp. 458-464. ACKNOWLEDGEMENT This project 
was supported and made possible by a grant from the Toronto General Hospital Founda- I.H. Rowe tion. 
The authors would like to thank Dr. for his support and efforts in initiating the project.  17 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563862</article_id>
		<sort_key>18</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Association of graphic images and dynamic attributes]]></title>
		<page_from>18</page_from>
		<page_to>23</page_to>
		<doi_number>10.1145/563858.563862</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563862</url>
		<abstract>
			<par><![CDATA[Various approaches to explicit and implicit control of time and motion in procedural real-time graphic <i>packages</i> and languages are discussed and illustrated. The particular approach of independentty defining static objects and dynamic attribute is introduced and developed. The procedures which alter and manipulate basic objects at interactive run time, teamed "dynamic attributes," may be defined independently of objects as a function of time, input, and other variables. Attributes, once defined, <i>may be</i> associated with and dissociated from objects dynamically. Several objects may simultaneously have <i>the</i> identical attribute. A particular & association exists within its own zero-origin local time frame. Basic objects are static two-or three-dimensional <i>entities</i> in some <i>space.</i> Dynamic objects termed "images" may <i>be</i> recursively defined in teams oa basic objects and attributes. Objects and attributes are the basic building blocks enabling modular program construction. <i>The</i> notions presented here can <i>be</i> used as the basis for design of interactive graphic languages or oda the implementation of graphics packages. <i>An</i> experimental FORTRAN-callable package has <i>been</i> developed to test <i>these</i> notions.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[clock variable]]></kw>
			<kw><![CDATA[computer graphics]]></kw>
			<kw><![CDATA[concurrent programming]]></kw>
			<kw><![CDATA[dynamic image]]></kw>
			<kw><![CDATA[graphic language]]></kw>
			<kw><![CDATA[hard real-time]]></kw>
			<kw><![CDATA[slippage]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14094160</person_id>
				<author_profile_id><![CDATA[81100245011]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[S.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bergman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ben-Gurion University of the Negev, Beer Sheva 84120, Israel]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77037619</person_id>
				<author_profile_id><![CDATA[81406594456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kaufman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ben-Gurion University of the Negev, Beer Sheva 84120, Israel]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baecker, R. M. Picture-driven animation. AFIPS 1969 SJCC Proceedings, vol. 34 (1969), 273-288.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bergman, S. and Kaufman, A. A real-time graphics package. Ben-Gurion University of the Negev, Department of Mathematics, Technical Report MATH-122 (1975).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563300</ref_obj_id>
				<ref_obj_pid>563274</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bergman, S. and Kaufman, A. BGRAF2: a real-time graphics language with modular objects and implicit dynamics. Proc. SIGGRAPH '76 (1976) 133-138.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356624</ref_obj_id>
				<ref_obj_pid>356622</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Brinch Hansen, P. Concurrent programming concepts. Computing Surveys, vol. 5, no. 4 (December 1973) 223-245.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cardman, S. J. Time management in real-time animation/graphics environment. Proc. SIGGRAPH '75 (June 1975) 201-207.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563746</ref_obj_id>
				<ref_obj_pid>563732</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Csuri, C. A. Computer animation. Proc. SIGGRAPH '75 (June 1975) 92-101.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[DeFanti, T. A. The graphics symbiosis system. Real-Time Film Animation, Annual Report to the NSF, GJ-204 (1973) 5-115.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Digital Equipment Corporation. Picture book reference manual. Order no. DEC-11-GPBMA-A-D (1973).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Frailey, D. J. Timing features for systems implementation languages. Information Processing 74 (1974) 354-358.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Futrelle, R. P. GALATEA: interactive graphics for analysis of moving images. Information Processing 74 (1974) 712-716.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Futrelle, R. P. and Potel, M. J. The system design for GALATEA, an interactive real-time computer graphics system for movie and video analysis. Computers and Graphics, vol. 1 (1975) 115-121.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[IBM System/360 Operating System Graphic Programming Services for FORTRAN IV. IBM Systems Reference Library, program no. 360S-LM-537.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563740</ref_obj_id>
				<ref_obj_pid>563732</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[O'Brien, C. D. and Bown, H. G. IMAGE: a language for structured display programming. Proc. SIGGRAPH '75 (June 1975) 53-60.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>804725</ref_obj_id>
				<ref_obj_pid>800143</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Pfister, G. F. A high level language extension for creating and controlling dynamic pictures. Proc. ACM Symposium on Graphic Languages (April 1976) 1-9.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ASSOCIATION OF GRAPHIC IMAGES AND DYNAMIC ATTRIBUTES  S. Bergman and A. Kaufman Mathematics Department 
Ben-Gurion University of the Negev Beer Sheva 84120, Israel us approaches to expicit and of time and 
motion in ptoceduta.t eat-time  packages and Qanguages ate dtiscussed and itu&#38;t'tated. The paoticultar 
approach basic objects and att-ibute,. Objects and attbibuteA ate the basic The which atteA and maniputpate 
bhaic objects at inteAactive run time, teamed "dynamic att.ribute," may be defined independently of objects 
ad a 6unction of time, input, and otheA Attributes, once dedined, may be associatedwith and dissociated 
objects Sevetal objects may mimuttaneoulty have the identical atthibute. A paAticulta&#38; association 
exists within in­ degining static objects and dynamic att-ihute- is inntaoduced and developed. objects 
static two­ thAee-dimensional entities in some space. Dynamic objects teAmed "images" may be %ecwuAive­ 
defined in teams own zeAo-o'igin local time 6dame. dort design interactive graphic languages ot odaf 
 building blocks enabling moduta&#38;. prtoguam contstuction. The notions ptesented hete can be used 
the the implementation graphics packages. An these notions. FORTRAN-caleab.e package been developed to 
and grtaphics, gtaphic language, dynamic image,hatd clock variable, slippage, concuWAent putoganmming 
 CR 8.2 1. INTRODUCTION There are two organizational approaches to time and motion in procedural real-time 
graphics packages and languages. Explicit control of time and motion provides the programmer with timing 
and event facilities to maintain his dynamic scenario; im­plicit control, on the other hand, utilizes 
a sys­tem scheduler which is responsible for handling appropriate actions and dynamic transformations, 
freeing the programmer from synchronization, timing and frequency problems. Time and events can he handled 
in a manner similar to discrete simulation methods. A new implicit control notion, the object-attribute 
pair, is introduced inSection4. Attributes control the environment and the actions of objects as a function 
of time, input, and other variables. They may be associated with and dissociated from objects dynamically. 
Several objects may simul­taneously have the identical attribute. Section 5 discusses frequently used 
predefined attributes, while user definition of attributes is presented in Section 6. We employ a hypothetical 
structured language to illustrate a variety of concepts. Names and syn­tactic structures are mnemonic 
and, hopefully, self-explanatory. A FORTRAN-callablepackage [2] based on the notions presented has been 
developed and implemented. The package and several examples written with it are discussed in Section 
7.  Permission to make digital or hard copies of part or all of this work or personal or classroom use 
is granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to 18 republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Siggraph 
77, July 20-22 San Jose, California 2. TEMPORAL DYNAMICS There are two major approaches to time control: 
let the programmer do it explicitly (see, e.g., [8]) and let the system do it implicitly (e.g., [6]); 
the former method merely requires giving the programmer a few additional tools such as the ability to 
read a master clock and define timers. Doing things at the right time and synchronizing pseudoparallel 
processes then becomes his respon­sibility. This means that the "time" must be checked regularly, and 
processes must be initial­ized, terminated and altered according to scenario schedule, within the various 
procedural loops and routines of the program. The latter method allows the programmer to schedule actions, 
somewhat similar to the way it is done in some of the discrete simulation lang­uages. The "system" is 
then responsible for carry­ing out requests such as "at such-and-such a time, do this" or "at regular 
intervals, do that" or "change this 'continuously' according to such a function of time." The discrete 
simulation sys­tems handle such requests by placing future events on a time-queue and iteratively incrementing 
the system variable time to the next scheduled event. The processor handles the events one at a time. 
When two events occur simultaneously,one is given preference. "Waiting" for the next event merely means 
advancing the clock to its scheduled time. In a real-time environment this must be replaced by waiting 
for the actual time to elapse.  An alternate simulation approach is to discretize time into successive 
instances. Time is advanced repeatedly to the next instance and all events which must take place 'now' 
are activated. The analogous real-time approach is to check, at each clock-tick, which events must be 
immediately activated. Clearly, the major problem in (hard) real-time systems is slippage [10], wherein 
time advances faster than the appropriate processes can be performed (this is the "slow compile" slippage 
in [11]). If the programmer deals directly with time, slippage remains his responsibility. If the system 
perports to worry about time handling, it must do something about slippage. The spirit of real-time demands 
the philosophy "the show must go on" as opposed to, say, "better late than never." 3. EXPLICIT CONTROL 
OF TIME AND MOTION In order to exercise explicit control, a program must synchronize itself with a "clock." 
The clock concept is discussed at length in [3,9] and is shown to be an indispensable feature in real-time 
graphics [5]. A variable, say KLK, may be defined to be a clock by the dynamic declaration: cock  causing 
KLK to be incremented automatically each clock tick. Slower clocks may be geared down from some master 
clock by use of an additional para­meter, as in: clock  wherein the incrementation takes place each 
M master-clock ticks. Clocks may act as ordinary variables in every other way, and can be modified, tested, 
output, etc. Continuous motion (transla­ tion, rotation, etc.) may be simulated by discrete changes in 
position, angle, and so forth, synchro­ nized with time. In the following example, the update occurs 
each N ticks of clock KL: cock  KL :=  rotate KL N; Objects whose motions are independently determined 
by system states, inputs, time, etc., create pro­gramming difficulties. Time-dependent loops tend to 
overlap, code and procedure calls need to be' repeated in different loops or portions of loops, and in 
general, the source code tends towards un­readability. To illustrate this, we consider two objects and 
the following interaction associated with them at some particular time in a program: OBJECT-2 i6 "hit" 
with the tight-pen at any time, make disappeat. Cease motion the instantsome Let OBJECT-2 remain tatioonatvy 
until OBJECT-I i6 "hit" by the light-pen, at which time it begins to rotate DUR second6, and then stops. 
 moving OBJECT-1 horizontatty at constant met. There are three motion situations indicated, plus one 
waiting loop: (1) object-1 moves, (2)object-2 moves, (3)both move, and (4) wait for exit criterion. Coding 
this is not totally trivial in systems with explicit time control. The process may be simplified somewhat 
by combining loops 1-3 into a single block wherein Boolean variables control motion. In more complex 
situations, how­ ever, such a loop becomes overloaded with condi­tional statements. The following code 
reflects this situation. Boolean and  record the motion status of the objects while TIMER is a clock 
that can be started and stopped under pro­gram control. This code works nicely if nothing else is happen­ 
ing on screen. However, if other tasks are being executed (and displayed) simultaneously, and these 
continue to be executed after the exit-criterion has been met, their code must be duplicated:  or the 
entire code block must be placed as a condi­tional block into a larger synchronous loop. 4. IMPLICIT 
CONTROL OF TIME AND MOTION An interactive graphics procedure is comprised of two basically different 
processes executing simul­taneously: a time-dependentobject transforming process and an asynchronousprocedural 
and input­monitoring process. In view of complexities demon­ strated above, it is advisable to separate 
them program-wise. This may be accomplished by use of implicit control of temporal dynamics, and can 
be implemented as a set of system routines which per­ form programmer-definedtransformationsat regular 
 intervals for specified durations. The transfor­mations can be translation, rotation, zooming, or any 
other standard continuous object-modification desired. A call to such a special-purposeroutine should 
include among its arguments: object identi­ fication, motion parameters, scheduling and dura­ tion of 
motion, etc. A single call to such a rou­ tine can start the desired motion or transforma­ tion; thence 
the system can perform the appropri­ ate action at regular intervals, freeing the 19 program(mer) from 
synchronizationproblems. Pfister's daemons [14] demonstrate another ap­proach to implicit control of 
motion. Let an object be any graphic entity, and let an attribute be any time-and input-dependentproce­ 
dure specifying motion and other dynamic proper­ ties of an arbitrary object. An interactivereal­time 
graphics program can he described as a set of objects, a set of attributes, and a procedure which pairs 
objects and attributes as a function of time and input. Since objects and attributes are independentlydefined, 
an object may be pair­ed (associated) with different attributes at dif­ ferent times. An attribute, on 
the other hand, may be simultaneouslypaired with a number of ob­ jects.  An attribute procedure is a 
routine which computes, as a function of time and other variables, the dynamic properties of its currently 
associated ob­jects. The act of associating or pairing an object with an attribute relegates the responsibilityfor 
executing that attribute at "regular" intervals to a real-time system scheduler. The intervals should 
 be sufficientlysmall to produce the illusion of smooth motion (if the object is indeed moving), yet 
large enough to obviate slippage. Nominal interval size may be determined by an explicit frequencydeclaration 
or by some default value. When the processor becomes overloaded, interval sizes are uniformly increased 
by the scheduler. Similarly, degraded intervals are decreased toward their nominal value with falling 
processor load. 5. SYSTEM PREDEFINED ATTRIBUTES Three widely used attributes in graphics are lin­ ear 
translation, rotation and continuous scaling. It is convenient to predefine these (and possibly others) 
as standard routines. Let us call them move, twun and zoom, respectively. A continuous  linear motion 
may be imparted to object by the call:  begins moving with velocity vector (VELX,VELY), and continues 
for duration DUR. VELX and VELY can be passed by name,   or in any other way allowing later modification 
of their values with the motion of the associated ob­ ject changing accordingly without another explicit 
 call. The following sequence, for example, causes object 0B3 to reciprocate horizontally: wherein 
after delay DEL,  6. USER DEFINED ATTRIBUTES A second type of attribute is user defined. It is a programmer-writtenprocedure 
of the form: end ATTR; and can be associatedwith or dissociated from various objects. Such an attribute 
is never ex­plicitly called by the program(mer), a distinctly unusual characteristic of a procedure. 
When paired with an object, the attribute routine is called at regular intervals by a system scheduler 
trans­parent to the programmer, and the object is adjust­ed accordingly. Note that ATTR above is an arbi­trary 
name for an attribute routine, having zero or more formal parameters which are resolved at  association 
time. Objects and attributes may be associated by the call:  where OBJ and ATTR identify the associated 
pair. The association takes place after DELAY time, and lasts for DUR time thereafter. DUR and DELAY 
default to infinity and zero, respectively. Dis­ sociation may be explicitly caused by:  Let us again 
consider the example of the two mov­ ing objects. Instead of having simple linear motion, the two objects 
will now move in a slight­ ly more complex fashion:  will have a vertical sinusoidal motion superimposed 
on its linear horizontal motion; Object-2 will have its constant rotation replaced by a linearly decelarating 
rotation. The two attribute routines, WIGGLE and SLOWDOWN are given below. WIGGLE moves Object-l, controls 
all light-pen interaction, and is responsible for pairing Object-2 with its attribute (SLOWDOWN) upon 
a hit on Object-1.  (OTHEROBJ);  rotation an object continuously with a given angu­lar velocity for 
a given duration. are used in the following sequence to implement the previouslydiscussed example:  
 20  Several parameters are automaticallyknown to the attribute routine. They are implicit formal 
para­meters. The ones used above are: object which identifies the object upon which the attribute acts; 
 time which is the elapsed time since the association occurred;  which is the elapsed time since the 
last activation of the attribute upon object by the system. The main procedure is responsible for drawing 
the two static objects and subsequently pairing  WIGGLE(OBJECT2) );  The remainder of the work is 
done implicitly by the system. This approach is substantially different from the previous sequences not 
only in that the object motions were made more complex, but also in that the main procedure is free to 
perform any other process concurrentlywith the two-object motion after it has been initialized by the 
 The attribute is a very general construct, conti­nually executed and conditionallyperforming any graphic 
process whatsoever. Clearly, an attribute need not modify any of the standard dynamic proper­ties of 
an object at all. On the other hand, it may change other properties of an object, dissoci­ate itself 
from it, create or purge other objects, associate or dissociate other object-attribute pairs, and associate 
itself with another object. When an object is associated with an attribute, the system scheduler is 
faced with the problem of de­termining the frequency of execution of the attri­bute routine. If this 
routine causes continuous on-screen motion, the 20-30/sec. criterion is the lower frequency limit. On 
the other hand, if the procedure is expected to perform some change each second or two, frequent execution 
may be unneces­sary and wasteful of processor time. There is generally no way for the compiler or the 
system to determine optimal frequency (see, e.g. [7]), unless additional information is supplied by the 
program­mer (for instance, in a statement such as: (20); ). If this information is not sup­ plied, 
all attribute routines must be given equal priority, hastening the onset of slippage. In any case, 
when slippage occurs, attribute routines must be scheduled less frequently. Since the programmer does 
not know in advance if and when slippage will occur, his attribute routines must be frequency  and 
slippage independent. Thus, the time and parameters become very useful. In the  previous example, horizontal 
motion is defined by:  This is a frequency independent definition, where­as the alternate form: is 
frequency dependent, so that slippage will cause the "constant" velocity to decrease.  7. EXPERIMENTAL 
SYSTEM The FORTRAN language still serves as a prime access to interactive graphics, and is likely to 
continue in this capacity for some time to come. FORTRAN­callable graphics packages are often provided 
by the manufacturers (e.g., [8,12]) and in any case, are easy to construct. An experimental package [2] 
has been developed to test some of the notions presented here. It is implemented on the GT-44 (PDP 11/40) 
configuration, is FORTRAN-callable, and allows the user to create, manipulate,and trans­ form basic and 
compound 2D graphic entities. Vari­ables of type "clock" facilitate creation of time­dependent and synchronized 
processes. A special set of routines enables the object-attributepair­ing and dissociation, constitutingthe 
autonomous dynamics capability of the system. Thus, both ex­ plicit and implicit control of time and 
motion are made available for comparison. The user-definedattribute is simply a FORTRAN subroutine 
written by the programmer, and has the form: SUBROUTINE ATTR(OBJ,ITIME,IDELT,X,Y,ANGLE,SIZE)  The 
formal parameters of the attribute subroutine are equivalent to the implicit system parameters previously 
discussed:  All parameters may be elided if not mentioned in the attribute body. These implicit parameters 
are supplied by the system scheduler each time it calls an attribute routine. The transformation para­meters 
(X, Y, ...) are used by the scheduler for display recompilation calls whenever they are al­ tered by 
the attribute call. The next example is a FORTRAN program segment which allows the user to draw a dotted 
curve on the screen with the light-pen. The dots comprising the curve individuallyfade with time and 
disappear causing the illusion of writing with "disappearing" ink. The program utilizes the TRACK system 
routine which places a tracking symbol at point (X,V). returns its identification in SPOT. ASSOC pairs 
  the dot with attribute FADE, which subsequently purges the dot. Attribute FADE invokes system routine 
INTENS to set and decrease a dot's inten­ sity as a function of elapsed time since the pair­ 21  ing 
(since the dot's creation). The object­ attribute mapping is many-to-one,with all the currently existing 
dots being mapped to the single attribute FADE.  Note that the FADE subroutine does not save infor­ 
mation in local variables, for it may be called with reference to a number of objects interleaved in 
time (the motion descriptions in GALATEA [11] are also thus restricted). This drawback can be alleviated 
in languages which support reentrant code, for the system can create separate data areas for each object 
having a particular attribute. 8. EXTENDED IMAGE-ATTRIBUTESTRUCTURES We have demonstrated the utility 
of the notion of pairing static objects and dynamic object­ independent attributes in the creation of 
a graphic scenario. Even in FORTRAN, the use of this approach can considerablydimplify real-time graphics 
prog­ ramming by relegating to the system scheduler the task of controlling the time-synchronousor time­dependent 
loops in real-time. The notion can be extended in several ways in order to introduce hierarchicallydefined 
dynamic structures analo­gous to the single-level pairing/dissociation scheme. Let us call an object-attributepair 
an image. If we extend the associate operation to image-attribute pairs, we essentially allow multiple 
attributes. The statement:  pairs static object A and attribute X; whereas the additional statement: 
 pairs A (now a dynamic image) with attribute Y. Most graphic languages further permit construction 
of more complex entities from simpler ones (e.g., DeFanti's GROUP [7]), usually in a hierarchical fashion. 
If this is extended to what we termed images, we might allow: Q construct (R,S, ...); where R, ... 
are images, and is defined as a compound image. tions together allow the construction of dynamic tree-like 
images, wherein the subtrees themselves may have their own local dynamic attributes. In order to facilitate 
synchronizationand to allow programming the time-line in a non-procedural way, the ociate and can be 
used to prepare structures for subsequent execution and display, while new operations, serve to activate 
and halt the actual execution (i.e., display compilation) of a structure or substructure. 9. CONCLUDING 
REMARKS The notion of separation of static graphic entities from the procedures which manipulate them 
in real­time has been discussed. These object-attribute pairs are associated and dissociated by calls 
to system procedures. The processing required for currently associated pairs is carried on auto­nomously 
and concurrently by a system scheduling mechanism which is transparent to the programmer. The extension 
of the object-attribute notion to the general image-attribute structures has been sug­gested. This modular 
tree-like structure of dynamic images could be developed into a powerful tool in real-time design. Initial 
experience with the experimental FORTRAN package has indeed shown that modularity of real­time design 
is enhanced. However, there is a price in the choice of FORTRAN as a host language. Since reentrant code 
and dynamic storage allocation are not readily available, an attribute may not always he paired with 
more than one object simultaneously in a natural way. The object-attribute notion which is conceptually 
useful in graphics can be generalized to any inter­ active or real-time environment. Our object may be 
thought of as any set of internal variables representing some grouping of sensors and effect­ors. An 
associated attribute manipulates these variables in real-time. REFERENCES [1] Baecker, R. M. Picture-driven 
animation. (1969), 273-288. [2] Bergman, S. and Kaufman, A. A real-time graphics package. Ben-Gurion 
University of the Department of Mathematics, [3] Bergman, S. and Kaufman, A. BGRAF2: a real-time graphics 
language with modular objects and implicit dynamics. P&#38;oc. SIGGRAPH '76 (1976) 133-138. [4] Brinch 
Hansen, P. Concurrent programming concepts. Computing SuAvegJs, vol. 5, no. 4 (December 1973) 223-245. 
[5] Cardman, S. J. Time management in real­ time animation/graphics environment. '75 (June 1975) 201-207. 
 [6] Csuri, C. A. Computer animation. SIGGRAPH '75 (June 1975) 92-101. [7] DeFanti, T. A. The graphics 
symbiosis system. Reoa-Time Animation, Annual 22 Report to the NSF, GJ-204 (1973) 5-115. [8] Digital 
Equipment Corporation. Picture book reference manual. Order no. DEC-11-GPBMA-A-D (1973). [9] Frailey, 
D.J. Timing features for systems implementation languages. 74 (1974) 354-358. [10] Futrelle, R. P. 
GALATEA: interactive graphics for analysis of moving images. 74 (1974) 712-716. P. and Potel, M. J. The 
system design for GALATEA, an interactive real-time computer graphics system for video analysis. Computedu 
and vol. 1 (1975) 115-121. [12] IBM System/360 Operating System Graphic Programming Services for FORTRAN 
IV. Systems program no. 360S-LM-537. [13] O'Brien, C. D. and Bown, H. G. IMAGE: a language for structured 
display program­ '75 (June 1975) 53-60. ming.  [14] Pfister, G. F. A high level language extension for 
creating and controlling     
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563863</article_id>
		<sort_key>24</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Glide]]></title>
		<subtitle><![CDATA[a language for design information systems]]></subtitle>
		<page_from>24</page_from>
		<page_to>33</page_to>
		<doi_number>10.1145/563858.563863</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563863</url>
		<keywords>
			<kw><![CDATA[architecture]]></kw>
			<kw><![CDATA[database]]></kw>
			<kw><![CDATA[design]]></kw>
			<kw><![CDATA[engineering]]></kw>
			<kw><![CDATA[languages]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14023165</person_id>
				<author_profile_id><![CDATA[81100030127]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Charles]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Eastman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie-Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P195261</person_id>
				<author_profile_id><![CDATA[81100298086]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Max]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Henrion]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie-Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baer A., C. M. Eastman and M. Henrion, "A survey of geometric modelling systems", Institute of Physical Planning Research Report No 66, Carnegie Mellon University 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Baumgart, B. G., "A Polyhedron Representation for Computer Vision," Proceedings of the National Computer Conference, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Braid, I. C. and C. Lang, "The design of mechanical components with volume building bricks" COMPUTER LANGUAGES FOR NUMERICAL CONTROL,. J. Hatvany, ed. North-Holland Publishing Co. London, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Brun JM "EUCLID: Manual", Equipe graphique du LIMSI, B. P. 30, Orsay, France.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Chalmers, J., "The development of CEDAR" International Conference in Computers in Architecture, York, 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Eastman,C. and M. Henrion, "Language for a Design Information System", Institute of Physical Planning Research Report No. 58, Carnegie-Mellon University, February, 1976 (revised).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Eastman C, "The concise structuring of geometric data for CAD" in DATA STRUCTURES FOR PATTERN RECOGNITION AND COMPUTER GRAPHICS. A Klinger, H fu and T Kunii (eds) Academic Press 1976a.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Eastman, C. "General Purpose Building Description Systems", COMPUTER AIDED DESIGN, 8:1(January, 1976c) pp.17-26.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Eastman, C. and J. Lividini, "Spatial Search", Institute of Physical Planning Research Report No. 55, Carnegie-Mellon University, May 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Engeli, Max. "A language for 3D graphics applications" INTERNATIONAL COMPUTING SYMPOSIUM 1973, North Holland Press, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Hosaka, M., T. Matsushita, F. Kimura and N. Kakishita, "A Software System for Computer Aided Activities", Proceedings IFIP W.G.5.2 Conference on CAD Systems, Austin, Texas, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hoskins, E. M.,"Computer aids in building",COMPUTER AIDED DESIGN, J. J. Vlietstra and R. F. Weilinga (eds.) American Elsevier, N. Y. 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563295</ref_obj_id>
				<ref_obj_pid>563274</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Lafue, G. "Recognition of Three-Dimensional Objects From Orthographic Views", SIGGRAPH NATIONAL CONFERENCE PROCEEDINGS, ACM, N. Y., 1976, p.103-108.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Newell, M. and D. Evans. "Modeling by Computer", Proceedings of the IFIP W. G. 5.2 Conference on CAD Systems, Austin, Texas, February, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>362808</ref_obj_id>
				<ref_obj_pid>362759</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Newman, W. "Display Procedures" CACM 14,No 10 651 Oct 1971]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Production Automation Project "An introduction to PADL", TM-22, University of Rochester, NY 1974]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Shu, H. H., "Geometric Moleling for Mechanical Parts" 4th NSF/RANN Grantees' Conference on Production Research and Technology, Chicago, November 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. "Three Dimensional Data Input by Tablet", PROCEEDINGS OF THE IEEE, 62:64, (April, 1974).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Thornton, R., "MODEL: Interactive Modeling in Three Dimensions Through Two-Dimensiona Windows" unpublished, MS thesis, Cornell 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Brainin, Jack "Use of COMRADE in engineering design", 1973 National Computer Conference, AFIPS Press, Montvale NJ,1973]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 GLIDE: A LANGUAGE FOR DESIGN INFORMATION SYSTEMS Charles Eastman and Max Henrion Institute of Physical 
Planning, School of Urban and Public Affairs and Department of Architecture, Carnegie-Mellon University 
keywords: design, database, architecture, engineering, languages. CR Classifications: 3.20, 3.40, 4.22, 
8.2. 1. INTRODUCTION A primary means for evolving more computer software is through the embedding of 
higher level features into probl em-or i ented languages. To late, CAD (computer -aided design) systems 
have had to begin development from FORTRAN, PL/1 or language of similar level. Yet there are needs common 
to many CAD applications which could be provided in the language or system foundation from which they 
are developed. GLIDE (Graphical Language for Interactive DEsign) is an attempt to organize the commonly 
-needed database. features and operations for the design of physical systems into a high level computing 
environment. By "physical system" we mean artifacts such as buildings, ships and machines, that are made 
up of a components and in which spatial arrangement is an important concern. GLIDE is intended to provide 
an efficient computer representation for physical systems in sufficient detail for their design and construction. 
The provision of a complete and coherent model of 3-dimensional objects and their spatial arrangement 
offers many advantages over conventional specifications and drawings. Given a complete 3-dimensional 
spatial representation of the artifact being designed, the designer is guaranteed that all 2-dimensional 
projections generated from it will be consistent. Shape information, normally represented in drawings, 
can be integrated with functional and performance information so that application programs can access 
and manipulate both kinds, thout the manual translation now required for draw i ngs. These application 
programs can check data consistency, evaluate the design's structural, thermal or other properties, estimate 
cost, or add conventional details. Others can generate displays, construction drawings and numerical 
control tapes from the stored shape information, which will have guaranteed correspondence with the design. 
Many such programs already exist and more can be imagined for specific applications in different fields 
of des i gn. One can distinguish three levels of representation for 3-dimensional elements: Permission 
to make digital or hard copies of part or all of this work or personal or classroom use is granted without 
fee provided that copies are not made or distributed for profit or commercial advantage and that copies 
bear this notice and the full citation on the first page. To copy otherwise, to 24 republish, to post 
on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Siggraph 77, 
July 20-22 San Jose, California 1 An IMAGE that contains sufficient information for generation of graphics, 
possibly including hidden line or surface elimination. This usually consists of an unstructured set of 
planar or curved faces. 2 A SHAPE model represents elements as solid bodies, usually polyhedral. It is 
spatially complete, meaning that it has a closed, volume-containing surface which contains sufficient 
information to determine whether any point is inside or outside. For the shape sculpting operations of 
union, intersection and difference on spatial domains, such a representation is essential [3]. 3 An 
OBJECT model extends this shape model to include functional information, such as material, weight, rigidity 
etc. Thus shape may be only one attribute among many others which describe the object. There now exist 
a wide range of computer languages for 2-D graphics applications, implemented as subroutine packages, 
or as extended or entirely new languages. While many of these can and have been extended to deal with 
3-D IMAGES, only recently has there been work in developing general Shape models [1,17]. Most systems 
capable of full Shape modeling are controlled by a non-extendable interactive command language [2,3,8]. 
A few are imbedded in general procedural languages, both interpretive and compiled [4,10,11]. Several 
of these can store command strings on disk and in this way represent large physical system projects that 
can be repeatedly accessed and modified over a period of time. A few store information on disk in a run-time 
format, allowing interactive manipulation of large amounts of data Several large CAD systems also support 
object models with comprehensive non-spatial attributes, but whose shape models do not extend to general 
polyhedra [5,12,20]. In GLIDE, we have attempted to combine the most desirable mix of these features 
that would be useful as a high level environment for physical systems CAD. The authors are members of 
 a team at Carnegie-Mellon University that earlier implemented a prototype interactive design database 
called BDS (Building Description System) (8]. GLIDE incorporates many. of the principles developed in 
BDS, including the compact representation of a large number of complete shape models, the shape -manipulating 
operations of union, intersection and difference, and several methods for the user definition of shapes. 
It embodies those facilities in a general high-level language and extends them with constructs for making 
functionally complete object descriptions and for relating objects to each other. GLIDE is intended to 
combine the advantages of an interpreted command language for interactive design with those of a procedural 
programming language. It does not provide highly specialized programs for particular applications, but 
rather is a general language, with object modeling capabilities in a database environment that incorporates 
disk management facilities and specialized accessing schemes. It is intended to form a convenient basis 
for constructing a new generation of more powerful CAD applications. In this paper, we outline the conceptual 
approach taken in the design of GLIDE. We shall focus of the features which we consider to be of particular 
importance in the design of design information systems. The complete specification of GLIDE is available 
in [6]. It has been implemented on a under the TOPS-18 operating system. using the Bliss implementation 
language. Implementation is also planned for a PDP-11/34, under the UNIX operating system. Versions are 
anticipated for both storage tube and refresh display graphics. 2. USER ENVIRONMENT: In its development 
GLIDE was considered from two different perspectives: Firstly as a set of data types and commands for 
interactively defining, arranging and inspecting a design; and secondly, as a general high level language 
for extending the range of structures and operations available at the first level so as to meet the requirements 
of a particular application. From the first perspective, the language ought to be easily used by a designer 
with minimal computer experience. From the second perspective, it should provide good facilities for 
the experienced applications programmer, so as to allow easy extension of the capabilities of the As 
naive users of the system gain experience, they should be encouraged to expand their use of the more 
general features. While we do not see designers becoming programmers (or vice versa) overnight, we hope 
that such a system will allow the naive user to find the system useful with minimal learning and that 
as he or she demands more powerful capabilities, they can be easily learned in small increments. We see 
this as a way of reducing the gap between these classes of people. This is a prerequisite for the development 
of systems which are tailored closely to the requirements of individual designers and their practices 
and which incorporate valuable kinds of design knowledge. This is in contrast to most existing systems, 
which enforce a strict separation between the command language and the system implementation language. 
The requirements of interactive design dictate that GLIDE be interpretive. Each command entered by the 
designer is executed immediately so that its effects can be inspected. An important form of inspection 
is graphical; the user is able to view the spatial effects of his actions as they are made. Programs 
incorporating special operations relevent to a particular design field or to the practices of an organization 
also need to be entered as procedures and stored for subsequent use. These are checked syntactically 
as they are entered, a line at a time, by an incremental translator. The pre-translation of procedures 
requires that translation be independent of the particular state of the database and that any external 
data or procedures needed are linked at run-ti me. A design project will be developed over  indefinite 
period of time and many terminal sessions, requiring millions of words of storage. Thus a project, while 
under development, should exist in a run-time format directly available online. The GLIDE operating environment 
keeps a small subset of the database in core and the rest on disk, and the management and swapping of 
records is handled automatically without conscious intervention by the user. 3. BASIC FEATURES: GLIDE 
incorporates the basic features of a general purpose Algol-like language. These are fairly conventional 
and so we will not describe them in detail. They include the following: the simple data types of INTEGER, 
REAL, BOOLEAN and TEXT (i.e. character string); variables of these types mus't be declared before use 
and may be scalar or vectors; the standard arithmetic, comparative and logical operators; the single-value 
assignment operator; control structures including, the IF <bool> THEN e ELSE e, and FOR and WHILE loops; 
a hierarchical structure of blocks delimited by BEGIN and END, with dynamic declaration of local variables, 
and user-definable procedures. Flow of control can also be changed by the escape statements: LEAVE, EXIT 
and RETURN, for escaping from a BEGIN...ENO block, the body of a loop, and of a procedure, respectively. 
The language is "expression-oriented" that is, every statement returns a value and can be used as part 
of a higher level expression. The value of assignment is the value assigned. 25  value of an IF statement 
or block is that part of the last statement executed. Procedures may act as functions and return a value 
when cal led. The escape statements return the value of the expression fol lowing it to the construct 
from which they escape, eg. the value RETURNed by a procedure. Wherever a statement is treated as an 
expression, its type must match that expected by the context. As a database definition language GLIDE 
calso contains the means for creating record types for defining objects, their shapes and their relationships. 
The general record type for defining a class of objects is a FORM, whose instances are COPIES. There 
are also two special record types for defining shapes: TOPO for defining surface topologies, and POLY 
for defining polyhedral shapes. A SET consists of a collection of Copies or other Sets. Copies and Sets 
can be treated as equivalent in many contexts and the union of their types is an ITEM. These record types 
will be described in more detail. 4. FORMS AND COPIES: FORMS are user-defined complex datatypes somewhat 
analogous to the Record of PL/1 and Struct of Algol-68, or Record class or the Relation of database definition 
languages. In design databases it is usual to encounter families of objects that have many but not all 
properties in common. Examples might be a class of doors in a building which have similar shape hut different 
locations, finishes and handles; or a class of container vessels in a chemical process plant. In this 
situation it is convenient to define a FORM not only as a "schema" which defines the ATTRIBUTES of a 
class of objects, but also as a "prototype" which contains the initial default values for objects derived 
from it. For this reason the instances or occurences of a Form are known as its COPIES. To define a COPY 
it is only necessary to specify its Form and those Attribute values which differ from it. This allows 
more concise entry of data and is also used in the current implementation for achieving compact storage 
of data. The advantages of this organization will become especially apparent when we consider the spatial 
Attributes for shape and location. The functional properties of importance in different areas of design 
vary greatly. User defined Attributes are provided for representing these properties of an object. Attributes 
may be of any simple type, including vectors of fixed size, or any record type (actually references to 
records). Since the same Attribute name, eg. COLOR or MATERIAL, may be relevant to many different Forms, 
they are declared global rather than local to a particular Form definition. Attribute declarations are 
introduced by the keyword ATTRIB:  A Form definition consists of a block containing Attribute initializations 
and possibly other statements enclosed between BFORM and EFORM. (These block delimiters are intended 
to aid type checking, but for conciseness can be replaced by "(" and "I", as can the delimiters for all 
the other record definition blocks to be descr i bed. )  Copies are identified by subscripts appended 
to their Form. The Form in its role as "prototype" may also be treated as the zeroth Copy.] In the Copy 
definition the subscript may be specified or defaulted, as the integer after the previous highest. The 
Copy definition block delimiters are "I" and  Form identifiers and Copies are bound permanently to 
their definition and cannot be reass i gned. The bind operation is denoted by =, as distinct from the 
assignment operator However, the individual Attribute values can be modified and a Form or a Copy can 
be dynamically expanded by the addition of new Attributes. Note that changing a Form Attribute affect 
all Copies with the default value; but new individual values may be assigned to an Attribute of a Copy 
that was originally defaulted. These changes are achieved in a modification block, attached to the object 
name ith a ":": This dynamic extension of record formats is not allowed in most languages and it adds 
some complexities to implementation. However we feel it to be important in a database system oriented 
to interactive design, where simple structures may be created initially which are later refined and elaborated 
in ways that could not have been anticipated at the start of the process. It also allows set membership 
information to be added to objects incrementally without any prior restriction on the range of Sets. 
Attributes needed for a particular kind of analysis may also be appended to objects whenever the need 
is identified. Outside a definition or modification block an Attribute value can be accessed by the syntax: 
<attrib> OF <copy> Since the names of Forms and hence of Copies are permanently, bound it is frequently 
desirable to use a variable. to refer to such objects. These may be declared to be of type ITEM. An Item 
can be either a Form, a Copy or a Set of Items. An Item variable may be assigned and reassigned by the 
 operator.  S. PROCEDURES: Procedures serve both their conventional role in the development of code 
for application programs and as means to extend GLIDE as a high-level user-oriented command language 
adapted to particular design tasks. Accord ing I y, in addition to the conventional calling syntax with 
the parameters enclosed in parentheses; a syntax is provided. In this syntax the parentheses are omitted 
and alphanumeric separators can be used instead of commas. The type of a procedure and of its parameters 
are given in the declaration, together the seperators if any.  SHAPE DEFINIIION: Shape is an Attribute 
of particular importance for physical systems design. While Shape may represent a solid object it may 
also represent a void, such as the space in a room, or the envelope of a set of objects. It is represented 
in GLIDE by a record of type POLY, representing planar-faced polyhedra. A Form record may be associated 
with a Polyhedron-by binding it to the SHAPE Attribute of the Form. Copies of this Form will have the 
same Shape, possibly with parametric variations. The representation of a general needs a large amount 
of data and efficient means of entry are required. Below, we describe the language constructs for defining 
polyhedra. Several different methods can be used, each based on a partial description that can be created 
and named for later reference. The partial descriptions are related hierarchically, as shown in Figure 
1. This hierarchy facilitates the entry of information needed to define a Polyhedron and is also used 
in GLIDE as a means to greatly compact the storing of shape information [7]. We introduce the shape definition 
facilities in the approximate order in which they might be learned, from the simplest to the most complex 
to use, in order to emphasize the possibility of a gradual progression, as users become more familiar 
with the facilities. Thus in the later examples we shall show how to construct entities such as Topologies, 
which are earlier treated as primitives. 6.1 Copies: Given an existing Form with defined Shape, new 
objects are easily derived as Copies at different locations. Location consists of the system -defined 
Attributes: LX, LY, LZ, which define a translation, and AX, AY, AZ which define an orientation specified 
as rotations in degrees round the three axes. These can be initialized and accessed like other Attributes, 
but a more convenient syntax for location is: The transform is relative to the <item>, or if that is 
omitted, is relative to "world" axes. Omitted trailing values default to zero.  A regular arrangement 
of Copies can.be created the use of a FOR loop:  6.2 Parameter i zed Shapes: Any well-used system will 
have built up a large library of standard shapes which may suffice for simple applications, but clearly 
there must be means for creating new ones. One method is to use parameterized shapes, which are procedures 
that define and return a Polyhedron that is defined parametrically from within a class. A simple example 
is Cuboid, parameterized by length, width and height. Storing a catalog of parameterized Shapes has 
become a conventional technique in most CAD systems. Different classes of applications may be served 
by libraries containing different sets, eg. pipes for process plants, I-section beams for structural 
steel design, etc. GLIDE provides the means of defining new ones as procedures which create classes of 
Polyhedra. The shape of an object is specified by binding a Polyhedron record to the SHAPE Attribute 
within the Form definition.  6.3 Shape Operators: An extremely powerful method for constructing complex 
Polyhedra is by joining simpler ones together, or by subtracting one from another. The Shape operators 
that do this create a new Polyhedron, with a new Topology and Geometry. There are three to perform the 
union, intersection and difference operations on the spatial domains represented by the Polyhedra:  
example of their use is shown in figure 2. The various cuboids ir 2a were located interactively and subtracted 
from the centre one, with the resulting Polyhedron in 2b. The LAP operation is the ultimate test for 
spatial conflicts. Note that type coercion can occur from a Copy to its Shape and hence the above and 
other operations expecting a Polyhedron will also work with operands which are Copies of a Form.  6.4 
Defining a Polyhedron: A Polyhedron consists of a number of components: FACES, EDGES and VERTICES. Each 
Face and each Vertex consists of an ordered ring of Edges and each Edge contains two Vertices and adjacent 
Faces. The information associated with these components is divided into two parts: the TOPOLOGY and the 
GEOMETRY. Topology defines the number of these components and there interconnections. The GEOMETRY specifies 
their spatial position and physical dimensions. Note that here "topology" means the network of vertices, 
edges and faces of a polyhedral surface, which is not the quite the same as its use in the field of mathematics 
of that name. A Topology may be common to many different Polyhedra and so it can be entered independently 
from any particular one and referenced by rrame. See Figure 1. A Polyhedron definition is delimited by 
BPOLY and EPOLY (or "I" and "I"), and starts with the specification of a Topology, which defines the 
numbers of faces, edges and vertices and their connections. The Geometry is then specified by a set of 
statements which bind to the vertex coordinates (VX, VY and VZ) a value relative to the origin. These 
have the form:  <sublist> is a list of one or more vertex ind i ces. Those co-ordinates not mentioned 
default to zero.  28 After the creation of a Polyhedron, the system checks that the Vertex coordinates 
define planar Faces, and that the bounded domain is inside. A Polyhedron can be treated as a Form with 
only a Shape Attribute, and Copies can be made and moved, and other Attributes added. Defining a Topology: 
A Topology may be constructed by means of Euler operators, which create and link new Vertices, Faces 
and Edges. (They are named after Euler who showed that they are sufficient to construct any legal polyhedron. 
For a description of their use see [2,83.) These Euler operations and other statements are combined 
into a Topology definition block enclosed between BTOPO and ETOPO. BTOPO generates a primitive point 
Topology consisting of a single Vertex on a Face. Further Faces. Edges and vertices are added and linked 
by the following Euler operations:  F2, VI, V2) to merge two Faces Fl and F2 starting by merging VI 
on Fl and V2 on F2, and finally eliminating the two Faces. Thus it can create a Polyhedron with a hole, 
or merge two into one. Variables of type VERTEX, FACE and EDGE be declared within a block defining a 
Topology or Polyhedron, or as parameters of a new Euler procedure. The Faces,Edges and Vertices are uniquely 
numbered for each Topology in the order they are created. This index can be used to identify them, and 
thus type coercion can can take place from an integer to the expected subrecord type.  Other complex 
shapes may most easily be defined graphically, as for example in several programs which can construct 
a 3-0 shape from two or more 2-D pictures drawn on the tablet[13,18,19]. We regard these as a particular 
class of application program, which can be interfaced to GLIDE. Notice that the hierarchy of Polyhedron 
definition facilities, when combined with a procedural language and database features, gives the user 
a range of alternatives for storing information, both procedurally or as data. Thus a Polyhedron may 
be defined as a procedure and invoked only when it is needed, with only local declarations. Alternatively 
it may be stored as data permanently. Thus no particular bias is made with regard this sometimes hotly 
debated issue [14,151. The application programmer can select that means of storing information that best 
reflects the conditions regarding space, speed and needed information. 7.1 ACCESSING SHAPE INFORMATION: 
The Attributes of a Shape can be accessed in the same way as the other Attributes of an object, either 
within a modification block or as <attrib> OF <item>. Modification of these Attributes, however, is limited. 
The following Attributes describe the number of Topological components, the Vertex coordinates and the 
Face coefficients (which are computed from them):  The following system-supplied ' functions provide 
ways of accessing the topological relations: The NEXT functions produce the next following the the 
first argument in the ring, clockwise looking inwards on a Face and anti-clockwise round a Vertex. The 
OTHER function produce the other component to the first argument on the given edge. In the case that 
the first argument is null (index 0) they return any component of the requested type that is connected 
to the second argument.  7.2 FORMS WITH VARIABLE SHAPES: Shape Attributes may not be directly also 
alters the Shape. Thus by initial Il defining a Polyhedral geometry in terms of a set of Attributes, 
the Shape can be since they are bound at definition. However the vertex coordinates may be bound to a 
Real Attribute of the Form, and hence changing the value of the Attribute referred to by the  variable 
for each Copy.  By setting up a Form in the above manner, each of its Copies may have a cuboid Shape 
but with different dimensions. The initial values assigned to the Attributes are the Form's default 
ies.  By allowing copies of a Form to vary in this way, great convenience is allowed in the treatment 
of objects cut from standard stock. Al pipes or beams of a certain section may be Copies of the same 
Form, but with variable lengths, allowing quantities of materials to be conveniently aggregated. 8. SETS: 
The Set provides a way of referencing a number of objects together, allowing them to be treated as a 
single entity. Conceptually. a Set is an unordered list and it can contain objects and also other Sets. 
Thus multi-level hierarchies can be defined. All operations which take an Item for their argument can 
operate on a Set. A Set may be defined simply by a list of Items, between the delimiters BSET and ESET 
(or "I" and "I" again.) A list of several Copies of the same Form can be specified concisely by listing 
the index range as the subscript. The subscript ALL means all the Copies of the Form. An origin for rotation 
may be specified as the first statement:  Like other definition blocks a Set definition can contain 
general statements, and if of these evaluate to an Item, then that will be also placed in the Set. This 
provides a convenient means of collecting and accessing all the objects created or accessed during a 
part of a design session, and encourages (although it does not enforce) a hierarchical structure for 
organizing the design database.  Two special loop statements have been provided for accessing the members 
of a Set:  The name is implicitly declared as an with the scope of the loop body, which is executed 
for each successive Item. The difference between them is that FORMEM accesses on ly the top members 
of the set, whereas FORALL accesses all the objects at the level contained within sets within the set, 
recursively.     9. SPATIAL SEARCH: Accessing objects by their location in space is an important 
method of access to a representing a physical system. No general methods of database organisation are 
sufficient to perform this efficiently, but a number of special techniques have been developed to deal 
with it [9]. In Glide the function  will generate the Set (which may be empty) of objects in the vicinity 
of the given Polyhedron.  GRAPHIC DISPLAY: To obtain graphic output of the Shapes and arrangements 
of objects, two things are necessary: A specification of the VIEW and a specification of the DISPLAY 
SET. The View is a Copy of a system defined Form named VIEW, which contains the parameters needed for 
graphic display. This has a Shape consisting of a two vertex line, representing the reference point and 
view point. The reference point and line of sight of a View Copy is specified by its location and orientation. 
[The point of view can also be changed by the FROMX, FROMY and FROMZ Attributes.] Other Attributes control 
other parameters of the View. The default definition of the View is: GLIDE provides two special Item 
variables: LOOK and OSET. To LOOK the user assigns the required current View (or Set of Views if several 
simultaneous views are wanted as in the traditional three orthographic engi.neering drawings: front; 
side: birdseye);  OSET contains the current Set of Items to be displayed. Thus the basic commands can 
be defined as follows:  11. GRAPHIC INPUT: GLIDE contains special functions which return information 
from a graphics satellite process which can read data from graphical input devices such as digitiser 
or light pen. LOCA returns a 3-Dimensional location in project coordinates and and PICK returns a reference 
to an Item which has been selected on the display. MOVE PICK TO LOCA; In an environment with dynamic 
graphics these procedures pass control temporarily to the display process, which can allow considerable 
dynamic interaction before returning the final values to the GLIDE executer. These functions hopefully 
provide GLIDE programs with a degree of clevice -independence. 12. DECLARATIONS, BLOCK STRUCTURE AND 
SCOPES: It expected that multiple users will access a design database. It would be impractical to anticipate 
all the variable names to be used in some project. Also, it must be possible to define application procedures 
independent from the database contents. Some procedures, however, should be able to add new records directly 
to the database and provide names for them. Within this context, we believe that explicit declarations 
with local and global scope distinctions within a hierarchical block structure are the best means for 
allowing unambiguous referencing and efficient memory management. A design project may last over many 
sessions at the terminal. Conceptually the scope of a project corresponds with the outermost block This 
outer block begins at the initiation of a project and is the outer block level during a terminal session. 
Therefore entities declared at this top level are GLOBAL and continue to exist between sessions over 
the length of the project. The scope of the name of a variable or record is the range of code over which 
it can be referenced by that name. The default scope of declarations is Local to the block in which they 
appear. However it is possible to override the default local scope by prefixing the declaration as GLOBAL. 
In GLIDE, definition blocks for all kinds of records can contain general statements including declarations 
and are as much part of the scope block structure as BEGIN ... END blocks. Declarations are not constrained 
to be at the beginning of the block. Local variables of simple type (both scalar and vector) are allocated 
on a stack and hence are deallocated on exit from the block in they were declared. Records on the other 
hand are allocated on a heap, managed by the system. Even though they are no longer accessible by name 
after exit from a block in  they were declared as local, they may still referenceable via any Global 
Sets or Item variables to which they have been assigned. For example any Items created within a Set definition 
block wi I automatically be put into that Set. Garbage collection of such records is managed by keeping 
a reference count for each one, and deleting only when this falls to zero. FINAL REMARKS: We have described 
only the major features of GLIDE. Other constructs are provided for mov i ng Items, to change the coordinate 
axes for local detailing, for Copying Sets, and for input output of alphanumeric data. In adldition the 
Set type includes features to facilitate the of hierarchical and network database organizations. The 
language as we have descibed it here is a preliminary version, and it will evolve no doubt as feedback 
is gained from users, both designers and expert programmers. We expect GLIDE to be used as a laboratory 
for developing a variety of design information systems. Initial application areas under investigation 
include building design, with to a variety of performance analyses, and the design of chemical process 
plants. We have said little about the i Iemen tat ion and operat i ng env i ronmen t. these are particularly 
critical to an interactive database system, since speed and convenience are- essential if the full advantages 
of direct interaction are to be obtained. The system is modular and should allow investigation of alternative 
representation schemes. Thus the GLIDE interpreter could be interfaced with a standard database management 
system, or the shape modeling structures could be extended to include curved objects. In this expect 
to use it both in the development of new CAD applications, and also as an experimental tool for developing 
 forms of support software. This work was supported by the National Science Foundation, Division of Mathematical 
and Computer Sciences. REFERENCES: (1) Baer A., C.M. Eastman and M. Henrion, "A survey of geometric modelling 
systems", Institute of Physical Planning Research Report No 66, Carnegie Mellon University 1977. (2) 
Baumgart, B. G., "A Polyhedron Representation for Computer Vision," Proceedings of the National Computer 
Conference, 1975. (3) Braid, I.C. and C. Lang, "The design of  mechanical components with volume building 
bricks" COMPUTER LANGUAGES FOR NUMERICAL CONTROL,. J. Hatvany, ed. North-Holland Publishing Co. London, 
1973. (4) Brun JM "EUCLID: Manual", Equipe graphique du LIMSI, B.P. 38. Orsay, France. (5) Chalmers, 
J., "The development of CEDAR" International Conference in Computers in Architecture, York, 1972. (6) 
Eastman,C. and M. Henrion, "Language for a Design Information System", Institute of Physical Planning 
Research Report No. 58, Carnegie-Mellon University, February, 1976 (revised). (7) Eastman C, "The concise 
structuring of geometric data for CAD" in DATA STRUCTURES FOR PATTERN RECOGNITION AND COMPUTER GRAPHICS. 
A  H fu and T Kunii (eds) Academic Press 1976a. (8) Eastman, C. "General Purpose Building Description 
Systems", COMPUTER AIDED DESIGN, 8:1(January, 1976c) pp.17-26. (9) Eastman, C. and J. Lividini, "Spatial 
Search", Institute of Physical Planning Research Report No. 55, Carnegie-Mellon University, May 1975. 
  Engeli, Max. "A language for graphics applications" INTERNATIONAL COMPUTING SYMPOSIUM 1973, North 
Holland Press, 1974. (11) Hosaka, M., T. Matsushita, F. Kimura and N. Kakishita, "A Software System for 
Computer Aided Activities", Proceedings IFIP W.G.5.2 Conference on CAD Systems, Austin, Texas, 1976. 
(12) Hoskins, E.M.,"Computer aids in building",COMPUTER AIDED DESIGN, J.J. Vlietstra and R.F. Weilinga 
(eds.) American Elsevier, N.Y. 1973. (13) Lafue, G. "Recognition of Three-Dimensional Objects From Orthographic 
Views", SIGGRAPH NATIONAL CONFERENCE PROCEEDINGS, ACM, N.Y., 1976, p.103-108.  (14) Newell, M. and 
D. Evans. "Modeling by Computer", Proceedings of the IFIP W.G. 5.2 Conference on CAD Systems, Austin, 
Texas, February, 1976. (15) Newman, W. "Display Procedures" CACM 14,No  651 Oct 1971 (16) Production 
Automation Project "An introduction to PADL", TM-22, University of Rochester, NY 1974 (17) Shu, H. H., 
"Geometric Moleling for Mechanical Parts" 4th NSF/RANN Grantees' Conference on Production Research and 
Technology, Chicago, November 1976. (18) Sutherland,  "Three Dimensional Data Input by Tablet", PROCEEDINGS 
OF THE IEEE, 62:64, (Apri I ,1974). (19) Thornton, R., "MODEL: Interactive Modeling in Three Dimensions 
Through Two-Dimensiona Windows" unpublished, MS thesis, Cornell 1976. Brainin, Jack "Use of COMRADE 
in engineering design", 1973 National Computer Conference, AFIPS Press, Montvale NJ,1973 EXAMPLE: Be 
I ow is a simple example of some GLIDE code to generate the Spiral staircase shoi-n in the i lustration. 
It uses as primitives some of the procedures given previously in the text. "Spiral.step" is a parameterized 
shape procedure constructs a Polyhedron from three ents: "Plate" is the surface of the step, "support" 
is a bracket and "Collar" attaches' the assembly to the "centre" column, which is passed as a parameter. 
These are welded together with the shape operator, COMBINE, and then the "centre" column is CUT out of 
the "collar" so that it fits closely around it. The "spiral.stair" procedure computes the number of steps 
and exact riser height to make the total height and calls "Spiral.step" to create an appropriate step. 
Repeated Copies of this are made at successive locations, and the procedure the "centre" and all the 
steps and the centre as a Set. It constitutes a simple ling routine for creating a class of spiral staircases. 
The particular example illustrated is created as "stairl".  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563864</article_id>
		<sort_key>34</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[On the realism of digitally synthesized images]]></title>
		<page_from>34</page_from>
		<page_to>34</page_to>
		<doi_number>10.1145/563858.563864</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563864</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39040712</person_id>
				<author_profile_id><![CDATA[81100391172]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Martin]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Newell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Xerox Palo Alto Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ON THE REALISM OF DIGITALLY SYNTHESIZED IMAGES Martin E. Newell Xerox Palo Alto Research Center Abstract 
 The synthesis of continuous tone raster scan images has been the subject of considerable research effort 
over the past decade or so. Many algorithms have been developed during this period, and many significant 
advances have been made. Systems now exist which are capable of generating full color images of fairly 
complicated scenes, at rates high enough to support the illusion of smooth motion. Such systems have 
been commercially available for several years. Despite this glowing record, very few images have ever 
been produced which require more than a moment's study to reveal their synthetic origins. The great majority 
of images produced are little more than caricatures. While such caricatures are good enough to be genuinely 
useful in applications ranging from geometric design to pilot training, the goal of producing images 
indistinguishablefrom those produced by conventional photography ought to be closer than is apparently 
the case. This presentation reviews the major issues of relevance to the realism of synthetic images. 
The major outstanding problems are identified and some suggestions for their solutions are presented. 
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Siggraph 
77, July 20-22 San Jose, California 34 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563865</article_id>
		<sort_key>35</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Real time digital image generation]]></title>
		<page_from>35</page_from>
		<page_to>35</page_to>
		<doi_number>10.1145/563858.563865</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563865</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379959</person_id>
				<author_profile_id><![CDATA[81100433643]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nicholas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Szabo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Link Division, Singer Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Real Time Digital Image Generation Nicholas Szabo Link Division, Singer Corporation Abstract The 
first significant application of real time digitally generated raster images is in the area of simulation 
for pilot training. At present, digitally generated raster images are employed for the training of commercial 
airline pilots, military pilots, and astronauts. Real time image generation is a much more demanding 
task than performing the same with no predetermined time requirement. The former requires extremely high 
data rates since a complete image has to be computed in 1/30 of a second, and this image must typically 
contain a high degree of detail which can be displayed only on a 1000 line color display. Consequently, 
the computational speed requirements for these real time systems exceed by far the capabilities of any 
general purpose hardware. This implies that the overall image processor consist of a pipeline system, 
the elements of which perform coordinate transformation, clipping, projection, and continuous shading 
calculations. In addition to the above tasks, real time image generators must also be free of such effects 
as rastering and aliasing. This presentation will discuss the techniques used for real time image generation 
and some of the remaining challenges in this field. Permission to make digital or hard copies of part 
or all of this work or personal or classroom use is granted without fee provided that copies are not 
made or distributed for profit or commercial advantage and that copies bear this notice and the full 
citation on the first page. To copy otherwise, to republish, to post on servers, or to redistribute to 
lists, requires prior specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California 
35 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563866</article_id>
		<sort_key>37</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[High quality computer animation]]></title>
		<page_from>37</page_from>
		<page_to>37</page_to>
		<doi_number>10.1145/563858.563866</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563866</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P75662</person_id>
				<author_profile_id><![CDATA[81100160637]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Edwin]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Catmull]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[New York Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 High Quality Computer Animation Edwin E. Catmull New York Institute of Technology Abstract New York 
Institute of Technology is involved in producing animated films with very good image quality. We have 
extensive computer graphics facilities devoted solely to animation. This includes a number of full-color 
frame buffers and two line-drawing systems, together with a high-quality film recorder, video tape, and 
disk equipment. We also maintain a strong association with a conventional animation studio. Our images 
are created at high resolution (1500 lines). In order to achieve good quality we must use hidden surface 
algorithms that apply anti-staircasing techniques at high resolution; we have used Fourier window filtering 
for this purpose. We have taken great care to ensure film transmittance is exactly proportional to intensity 
values. In trying to build production animation systems, we have found the problem of manipulating large 
numbers of images, in excess of 100,000, to be one of our main problems. Pictures produced at NYIT will 
be shown during this presentation. Permission to make digital or hard copies of part or all of this 
work or personal or classroom use is granted without fee provided that copies are not made or distributed 
for profit or commercial advantage and that copies bear this notice and the full citation on the first 
page. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior 
specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California 37 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563867</article_id>
		<sort_key>38</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Interactive graphics an aid to health planning and decision making]]></title>
		<page_from>38</page_from>
		<page_to>41</page_to>
		<doi_number>10.1145/563858.563867</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563867</url>
		<abstract>
			<par><![CDATA[One of the major functions of State and Federal Public Health agencies is the collection and maintenance of large amounts of data. The utilization of this data for research and planning may be impaired by such factors as: lack of organization and accessibility of the data, users lack of knowledge of statistical and operations research techniques, inability to determine important variables from a large selection, and the need to present results in a form which is understandable and useful to the general public.This paper presents interactive graphics approaches which are designed to aid the public health planner and administrator through presentation of data in map and table form. Interactive graphics is a form of real time computing in which all or part of the input and output operations are handled through a graphics terminal. The systems described below present statistics for different civil divisions and allow the user to display and compare data from a large set of variables. These variables include locational data such as the position of emergency medical services, hospitals, cities and towns; quantities such as travel distance, travel time, service area, and service population; and summary statistics. The display is controlled either through light pen activated commands or the use of a "button board". The systems have been applied to problems in administrative area designation and emergency service placement.The use of interactive graphics allows the public health planner and administrator to handle large data bases with minimal expertise. Data may be reviewed quickly and useful variable selected. These systems also allow for the maximum use of the administrators experience and knowledge of the areas particular needs and qualitative factors by allowing direct interface to the data. These systems require a minimal amount of training to use, thus allowing interested public groups to use them to develop and compare different solutions to health planning and administrative problems.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[computer mapping]]></kw>
			<kw><![CDATA[decision making]]></kw>
			<kw><![CDATA[geographic data]]></kw>
			<kw><![CDATA[interactive graphics]]></kw>
			<kw><![CDATA[planning]]></kw>
			<kw><![CDATA[public health]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP310123300</person_id>
				<author_profile_id><![CDATA[81541970556]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Christopher]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Willard]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379950</person_id>
				<author_profile_id><![CDATA[81410592773]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jay]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Hamann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bryant, N. A. LUMIS: An interactive graphics display information system based on census DIME file technology. GBF/DIME, A Geographic Dimension for Decision Making. Conference Proceedings (October 30 and 31, 1975) p. 72.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Giloi, W. K., Messer, D. L., Savitt, S. L. GRAP: A Fortran subroutine package for interactive display programming. Technical Report 75-15, University of Minnesota, Mpls. (Aug., 1975).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Hass, A. Design considerations for a state health department information system. Am. J. Public Health 64:481-495 (June, 1974).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Sterling, T. D. The statistician vis a vis issues of public health. The Am. Statistician 27, 5:212-216 (December, 1973).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[U.S. Bureau of the Census. Census use study: data uses in health planning. Report No. 8, Washington, D. C., 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[U.S. Bureau of the Census. Census use study: GRIDS, a computer mapping system. Washington, D.C., 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[U.S. Bureau of the Census. Census use study: DIME, a geographic base file package. Washington, D.C., 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Interactive Graphics An Aid to Health Planning and Decision Making Christopher Willard Jay R. Hamann 
University of Minnesota ABSTRACT data. CR CATEGORIES: One of the major functions of State and Federal 
3.34, 3.59, 3.79, 3.89. 8.2 Public Health agencies isthe collection and maintenance of large amounts 
of data. The INTRODUCTION utilization of this data for research and planning may be impaired by such 
factors as: lack of The collection and analysis of public health organization and accessibilityof the 
data, users related data has been mandated by such federal lack of knowledge of statistical and operations 
laws as the Health Planning Act of 1974 (PL 93-641) research techniques, inability to determine and such 
state laws as the Minnesota statutes important variables from a large selection, and governing emergency 
medical care. The data the need to present results ina form which is available to the public health administrator 
and understandable and useful to the general public. planner covers a wide range of categories including: 
demographic data(number, type and This paper presents interactive graphics approaches location of health 
care personnel), location, size which are designed to aid the public health plan-and provided services 
of hospital facilities; ner and administrator through presentation of number of deaths by cause and area; 
environmental data inmap and table form. Interactive graphics health information; location and operating 
statis­isa form of real time computing inwhich all tics of emergency medical services (5). The or part 
of the input and output operations are sources of these data vary almost as widely as the handled through 
a graphics terminal. The systems data itself. Information may be found in such described below present 
statistics for different agencies as state health departments, public civil divisions and allow the user 
to display safety departments, emergency medical departments, and compare data from a large set of variables. 
state planning agencies, and state demographic These variables include locational data such agencies. 
Federal and private studies may also as the position of emergency medical services, prove useful (3). 
This data may not be fully hospitals, cities and towns; quantities such utilized for several reasons. 
Itmay not be as travel distance, travel time, service area, readily accessible since itexists inmany 
differ­and service population; and summary statistics. ent formats within a large number of agencies. 
The display iscontrolled either through Itmay not exist incomputer readable format, light pen activated 
commands or the use of a making computer-based analysis difficult. Health "button board". The systems 
have been department personnel may lack facilities with applied to problems in administrative area the 
appropriate analytic techniques such as designation and emergency service placement. statistical analysis 
or operations research. Despite years of lip service to the prepara- The use of interactive graphics 
allows the tion in statistics of most medical researchers public health planner and administrator to 
remains woefully inadequate, and almost no back­handle large data bases with minimal exper-ground inmathematics 
isdemanded of them (4). tise. Data may be reviewed quickly and These skills may be available within the 
state useful variable selected. These systems bureaucracy or through associated universities also allow 
for the maximum use of the adminis-or consulting firms, but lack of familiarity trators experience and 
knowledge of the areas with them may result inproblems amenable to particular needs and qualitative factors 
by analytic solutions not being attempted or allowing direct interface to the data. These analytic techniques 
being rejected altogether. systems require a minimal amount of training Underutilizationof data may also 
result from to use, thus allowing interested public groups an inability to properly handle the large 
number to use them to develop and compare different of variables associated with the health care solutions 
to health planning and administrative processes which are available to the decision problems. maker. 
The data management problems noted earlier may cause some information to go KEY WORDS AND PHRASES: unnoticed. 
Statistical techniques for the isola- Interactive graphics, decision making, public tion of important 
variables may not be readily health, planning, computer mapping, geographic available, may be inappropriate 
for particular Permission to make digital or hard copies of part or all of this work or personal or 
classroom use is granted without fee provided that copies are not made or distributed for profit or commercial 
advantage and that copies 38 bear this notice and the full citation on the first page. To copy otherwise, 
to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or 
a fee. Siggraph 77, July 20-22 San Jose, California applications, or may prove too unwieldly for effec­tive 
use. A final requirement of public health planning and administration isthat data and results of analysis 
must be presented and made available in a form useful to other government agencies and the general public. 
Results must be accessible to people with low levels of technical expertise, these results and the data 
they are derived from must be ina form which may be easily presented to and understood by the general 
public. HARDWARE One approach for giving public health planners and decision makers better control 
and under­standing of the data available to them is through interactive graphics; Interactive graphics 
is a form of real time computing in which all or part of the input and output operations are handled 
through a graphics terminal. The interactive graphics software discussed in this paper has been developed 
using the University of Minnesota's graphics computing facilities. The major hardware components are 
a CDC CYBER 74 com­puter connected through a time sharing link to a VARIAN -620/I mini-computer interfaced 
with an Information Displays Incorporated Input/Output Machine (IDIIOM) display system. The IDIIOM 
system isan intelligent time-sharing graphics terminal. Both graphics and normal time-sharing information 
istransmitted through a telephone line connection to the main computer (2). The IDIIOM cathode ray screen 
requires refreshing and consists of a 1024 by 1024 element grid. The screen may hold up to 4096 primitive 
graphics elements which may be either lines and/or characters. Input into the IDIIOM may be through 
a light pen, a teletypewriter,or a 32 key function keyboard ("button board"). Use of the IDIIOM system 
is limited by the time­sharing line speed and the refresh rate of the graphics screen. The IDIIOM system 
isaccessed through a FORTRAN-callablegraphics application package (GRAP). This package controls light 
pen and button board interactions, and causes the generation of displays. SOFTWARE The applications 
software developed as an aid to the public health planner and administrator has three basic parts: a 
data structure, a display generator/controller,and a user interface. Data isstructured based on a physical 
entity (county, hospital, town, or city, an emergency service, etc.) and the geographic location of 
the entity. A list of associated data for each entity may exist; for example, a county may have associated 
data regarding its area, population, number of hospital beds, number and type of health professionals, 
and number and causes of deaths; a hospital may have associated data regarding number of beds for different 
treatment categories, existence of specialized services, and accreditations. The structure isthus a hierarchy 
of entity types, entity geographic locations (which may be ordered or unordered), and list data associated 
with each entity. This structure aids indisplay generation and allows for quick processing of light 
pen or button board initiated requests. The display generator/control­ler generates the initial display, 
and modifies or creates new display, and modifies or creates other displays during the course of the 
run. Dis­ plays can show data inmap form, tables generated, and/or a list of control commands to be activated 
by the light pen. Hospitals, cities and towns, and emergency services are displayed intheir geographic 
location on the display map, with symbol codes used to indicate size, type, or service specialities. 
Numerical data may be displayed either on the map or intabular form. Screen size limits the number of 
numerical varia­ bles that may be displayed at one time, thus requiring a mechanism to allow the user 
to change the variables being displayed. The user interface processes user commands andcontrols the 
remaining software. Through the interface the user may build solutions to particular problems on the 
 screen or use the screen to display data. The interface may provide the calculation and display of 
estimates related to some problem. For example, the service area of a proposed emergency service or 
the use estimates for a new health facility may be displayed. APPLICATIONS The system described above 
has been applied to the problems of designation of health administrative areas, and emergency medical 
services location and evaluation. A brief description of these applications follows. a. Health AdministrativeAreas 
 Health administrative areas are subsections of a state or region which may be considered as an administrative 
unit responsible for planning and fund allocation. The division of states and regions into medical administration 
areas has been mandated by such legislation as the Comprehensive Health Planning Act of 1974. The interactive 
graphics approach used for area designation was to display a map of the region of interest showing counties 
and health data for each county twelve variables were used of which any three could be displayed at one 
time. The user adds or deletes counties to or from pro­spective administrativeareas (up to eight areas 
are allowed). The variable totals for each area are displayed intable form. Hospial location and size'information 
may also be displayed. The user works to designate administrative areas which are balanced with regard 
to the variables used, which meet established criteria, and which best fit the administrative and health 
needs of the region. b. Emergency Medical Services The location of new emergency medical services and 
the evaluation of the existing.emergency medical systems isa problem facing the health planner. This 
problem includes identification of underserved areas, evaluation of existing services, and some method 
for determining placement of new services. The interactive graphics approach to this problem included 
the display of the location of cities, towns, existing emergency services, and hospitals inmap form. 
Response areas for each service can be displayed 39 using either an absolute distance or grid travel 
time model. Inaddition, the average response distance, number, type, and severity of cases may be displayed 
for each service. The popu­lation and area for each city and town can be displayed. The user can review 
a large data base for evaluation purposes, or to determine underserved areas. The system can be used 
to determine identical locations for new emergency services by allowing the user to select hypo­thetical 
locations on the display with the light pen. Response areas for these points can then be generated, and 
utilization estimates of the proposal service calculated. USE OF SYSTEM Interactive graphics may aid 
health planners and decision makers inseveral ways. First, itallows the handling of large amounts of 
information with no knowledge of data base management or other data handling techniques. The user isnot 
 required to learn any computer language or pseudo language and can usually be taught to run the system 
in under twenty minutes. Second, the user isable to quickly review and compare a large number of variables 
and may select those variables which show the most relevance to a particular problem for further emphasis. 
Third, interactive graphics makes maximum use of the planner's and decision maker's experience and 
 knowledge of the area's particular needs and qualitative factors. Itallows dealing directly with the 
data. This qualitative information isof greater importance inthe health sector than in the business 
or industrial sector. Such factors as morbidity, and the effects and bene­ fits of health care are difficult 
or impossible to accurately quantify. When health care pro­ grams can be shown to have some effect, 
it is difficult to determinewhich factors or actions within the program were responsible for the effect 
and it ismore difficult to assign numerical values relating these factors to the overall effect. Inmany 
cases the public health department has neither the time, finan­ cial support, or expertise to carry 
out such analyses. Thus, public health departments must rely on the ability of their personnel to 
weigh qualitative information and relate it to the overall state of health of their areas. Fourth, 
interactive graphics aids the health planner and decision maker through its simplicity of use, which 
allows any public interest or research group to develop and compare different solutions to health planning 
and administrative problems. Since most public health decisions affect the general public directly, 
and many decisions require local support, it is important to involve local and public interest groups 
inthe decision-making process. Itisalso important to be able to support decisions ina manner which is 
easily understood by the general public, and it is important to convince the public of the wisdom of 
plans and decisions. The simplicity of the interactive graphics approach allows itto be usable by local, 
private and research groups to solve or evaluate problems on a "one shot" basis. Fifth, the mapping 
 techniques and geographic structuring of data used inthis approach are very helpful inhealth plan­ning. 
Precise geographic identification is particularlyimportant for the analysis of data about small areas, 
such as groups of blocks comprising locally designated special areas. These might include hospital service 
areas, air quality control regions, mental health catchment areas, and areawide health planning regions 
(5). Sixth, once a solution has been worked out on the screen itbecomes a relatively trivial matter 
to translate the results into hard-copymaps, tables and charts, for reports and presentations. The interactive 
graphics approach described above could be extended inseveral ways. First, the addition of an interface 
to statistical and operations research packages would allow the user to make more detailed analysis 
of the data while working with the graphics terminal. Second, the addition of a data base management 
 system would allow for quick entry of new data, large functional data bases, and improved report generation. 
Third, the use of windowing tech­niques would allow the user to work at different levels of geographic 
detail, and would allow greater amounts of data to be displayed at one time. Fourth, the approach could 
be used in conjunction with the existing Census Bureau geographic base file system: DIME (7)and computer 
mapping system: GRIDS (6)(1). The implementation of these extensions would lead to a generalized system 
which could be used on a wide variety of applications and problems. SUMMARY Interactive graphics can 
be used to aid the planning and decision making process within the public health sector. Itmeets the 
specific needs inthis sector inthat itdoes not require a high level of skill or technical expertise to 
arrive at solutions, and itcan be used to interface quantitativeand qualitative information into the 
decision-makingprocess. This approach best fits map-based problems involving data review and evaluation, 
site determination,and administrativedistricting. BIBLIOGRAPHY 1. Bryant, N. A. LUMIS: An interactive 
graphics display information system based on census DIME file technology. GBF/DIME, A Geographic Dimen­ 
sion for Decision Making. Conference Proceedings (October30 and 31, 1975) p. 72. 2. Giloi, W. K., Messer, 
D.L., Savitt, S. L. GRAP: A Fortran subroutine package for inter­active display programming. Technical 
Report 75-15, University of Minnesota, Mpls.(Aug., 1975). 3. Hass, A. Design considerations for a state 
health department information system. Am. J. Public Health 64:481-495 (June, 1974).  4. Sterling, T. 
D. The statistician vis a vis  issues of public health. The Am. Statistician 27, 5:212-216 (December, 
1973). 5. U.S. Bureau of the Census. Census use study: data uses in health planning. Report No. 8, 
40 Washington, D.C., 1970. 6. U.S. Bureau of the Census. Census use study:  GRIDS, a computer mapping 
system. Washington, D.C., 1972.  7. U.S. Bureau of the Census. Census use study:  DIME, a geographic 
base file package. Washington, D.C., 1972. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563868</article_id>
		<sort_key>42</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Computer graphics for facilities management]]></title>
		<page_from>42</page_from>
		<page_to>47</page_to>
		<doi_number>10.1145/563858.563868</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563868</url>
		<abstract>
			<par><![CDATA[By combining the gaming aspects of interactive, refreshed screen graphics with accurate cost data and realistic schedules, solid front end planning as well as control and monitoring through the life of the building can be achieved. This process enables the user to examine more alternatives in less time, to evaluate solutions against established criteria, to increase production and to design to cost. The development and manipulation of the graphic data and hardware will be explained through examples from housing, hospitals, industrial and commercial buildings.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[computer aided design]]></kw>
			<kw><![CDATA[cost control]]></kw>
			<kw><![CDATA[facilities management]]></kw>
			<kw><![CDATA[graphic data bases]]></kw>
			<kw><![CDATA[graphic symbols]]></kw>
			<kw><![CDATA[graphic system menus]]></kw>
			<kw><![CDATA[overlay drafting]]></kw>
			<kw><![CDATA[project management]]></kw>
			<kw><![CDATA[project scheduling]]></kw>
			<kw><![CDATA[refreshed screen graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379958</person_id>
				<author_profile_id><![CDATA[81100233091]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nancy]]></first_name>
				<middle_name><![CDATA[V.]]></middle_name>
				<last_name><![CDATA[Renfrow]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cost, Planning & Management International, Inc., Washington, D.C.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[de Armas, Emile. Computer-Aided Design&#8230;a First for the Veterans Administration. Proceedings for the International Council of Building Construction, W-65, National Academy of Science, May 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Perry, Dean Partners Inc. Computer Aided Design (1975). CPMI, 4045 Merle Hay Road, Des Moines, Iowa 50310.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Perry, Dean & Stewart. Application of Computer Aided Architectural Design for EM and EW Housing Projects, Fort Lee, Virginia. Book I Volume I (1975). U.S. Army Construction Engineering Research Lab. P.O. Box 4005, Champaign ILL 61820, Special Projects Division.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Perry, Dean & Stewart. Computer Aided Design Demonstration, Veterans Administration, Augusta Georgia. Veterans Administration Project No. 99-RO55. Final Submission Volume 1-6, 1975. V.A., Preliminary Planning, 810 Vermont Avenue, Washington, D.C. 20420.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Rowe, R. L., Newport, N. A. and Hildebrand, J. B. Preliminary Report, Eli Lilly and Company, Indianapolis, Indiana (April 9, 1975), 3-8]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 COMPUTER GRAPHICS FOR FACILITIES MANAGEMENT Nancy V. Renfrow Cost, Planning &#38; Management International, 
Inc. A Green International Company 1800 M Street NW Washington, D.C. 20036 Abstract By combining the 
gaming aspects of interactive, term and long term effects of construction must berefreshed screen graphics 
with accurate cost data examined. and realistic schedules, solid front end planning as well as control 
and monitoring through the life A major step toward this synthesis occurred whenof the building can be 
achieved. This process Green International bought Perry Dean Partner's enables the user to examine more 
alternatives in Computer Aided Design Division in Washington andless time, to evaluate solutions against 
establish-merged it with Cost, Planning and Managemented criteria, to increase production and to design 
International, a professional, computer-supported to cost. The development and manipulation of the project 
management firm in Des Moines, Iowa. Perrygraphic data and hardware will be explained through Dean's 
Computer Aided Functional Graphic Analysis examples from housing, hospitals, industrial and (CAFGA) and 
Architectural Criteria Data Base hascommercial buildings. already been integrated into all phases of 
designfrom site analysis through working drawings. Now Key Words and Phrases these programs would be 
associated with programsinvolving cost management and scheduling, there Project management, Computer 
Aided Design, Cost by providing the key participants comprehensivecontrol, Project scheduling, Overlay 
drafting, project control from inception through construct- Graphic symbols, Graphic system menus, Facilities 
ion. management, Graphic data bases, Refreshed screen graphics. Equipment Computing Reviews Classification 
The computer system currently used for graphicsconsists of a medium scale computer, the Digital 6.21, 
7.1, 7.2, 8.1, 8.2 Equipment Company's PDP 15/76 with a PDP 11 inter­ face to control the input/output 
bus. The "15" Introduction has 32K central core and is designed for the ded­icated user, that is to say, 
only one user on line Building management has become an increasingly at a time. Removable single platter 
disks are complicated responsibility of achieving the op-used on the two disk drives. One disk containstimum 
mix of the three variables: Cost, time and system information, the various utility and the space. The 
use of computer graphics for this graphic programs. The data disk on the other task will provide the 
owner and architect great-drive is interchangeable depending on the job er control over inventories and 
planning while since each project is stored separately. Magneticallowing the examination of numerous 
schemes in a tapes are used for long term storage and back up.smaller amount of time without sacrificing 
qual-These tapes can receive rough treatment and unlike ity design. the disks will maintain their integrity. 
As many of us already know, numerous aspects of The DECwriter is used to access the system and a project 
can be effectively handled by the com-program information. Once the program information puter with more 
alternatives being examined and is loaded into core, the user interacts with the more material investigated. 
This fact becomes computer through the refreshed alphanumeric dis­increasingly important because of the 
demands play screen, the refreshed screen which is a clients are making. They expect a greater number 
Cathode Ray Tube (CRT), and the spark pen and of issues to be examined and a broader range of sonic tablet 
in order to create, edit, store, ortechnology to be incorporated into design. Be-retrieve data. If documentation 
of the graphic cause of demands to know why or why not something data displayed on the CRT is needed, 
the user re­ was done, documentation of decisions isabsolutely quests a hard copy and the data is copied 
via the necessary. Because of inflationary pressures and dot printer or plotter. All data that is notlong 
lead time on purchases, decisions must be graphic is stored on our IBM 370/138 or accessed made promptly. 
Because of construction methods via a service bureau. such as fast tracking, irrevocable decisions must 
be lived with. Because of emphasis on energy Process conservation and environmental impact, both short 
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to 42 republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Siggraph 
77, July 20-22 San Jose, California Integral to this process of computer graphics is the philosophy of 
user oriented, non-technical approach to software design. These tutorial pro­grams require less than 
one hour of general indoc­trination. Since the graphic system was created for the designer, the proper 
use of itas a tool should aid-not-impede the designer. The user quickly finds that the real power of 
the computer lies in 1) producing a reuseable graphic data base thus reducing lead time on subsequent 
pro­jects, 2)controlling uniformity wherever needed inproducing drawings, 3) synthesizing large amounts 
of data rapidly and accurately,4) devel­oping historical data to compare with current data. The data 
ismanipulated by choosing the desired options listed on the menu right of the CRT. At this time, changes 
to the graphic data do not af­fect changes in the alphanumericdata. Also, these data bases are linked 
manually with common data such as equipment codes and CSI Divisions and are somewhat integrated. Each 
system addres­es a particular aspect of the project and then provides the necessary data for analysis 
inother areas. Soon these links would be suppressed from the user thus giving the appearance of a common 
 data base. Plan Optimization Data Bases Since the data base isthe foundation for effi­cient usage, 
the development of the alphanumeric data and graphic elements should be carefully ana­lyzed. Currently 
there are three alphanumericda­ta bases used for project management and more specificallyfacilities management. 
1)Architect­ural Criteria, 2) the Orr system of cost control and 3)Management Information and Control 
System (MICS). There isone graphic data base for facil­ ities management. The Architectural Criteria 
Data Base categories are general and can be modified depending on the building type to include unique 
situations. For example, the programming/planningdata base for hospitals would include special plumbing 
and equipment not found ina commercial space. The data base organization follows a random file add­ress 
structure. Modifications and adjustments may be accomodated by adding another category or an­ other ;tem 
to the list under the category. The type of information includes general description, quantities, dimensions, 
equipment descriptions and location, electrical data, HVAC etc. Cur­rently, it isbeing operated ina batch 
mode. The second data base accessed isthe Orr System of Cost Management which begins with the estab­ 
lishment of the initial budget and progresses interactively through the conceptual and design phases 
of the project translating concepts into realistic cost.projections. The purpose of Cost Management 
isto assure maximum value within the established cost parameter. This requires exami­ ning and weighing 
initial cost, life cycle cost and ultimate satisfaction. This isachieved by refining a cost model as 
more and more inform­ ation isavailable. Along with establishing a design concept and its relative 
cost, a third data base is used to de­  velop a time budget or master project schedule. This Management 
Information and Control System (MICS) processes complete, multi-level time/ cost models. More flexible 
than traditional sys­ tems, itallows summarizationof information, computation of interium critical milestone 
goals, and accurate computationof overlapping activi­ ties. Perhaps the most valuable program interms 
of solid, front end planning has been Plan Optimiza­tions. This program takes the quanitative inform­ation 
gathered from interviews and architectural criteria then translates it into two demensional graphic informationfor 
schematic planning. Ma­trices are developed to evaluate the germane areas of comparison which could include 
function­al relationships, light levels, traffic volumn and any othbr categories necessary for determin­ing 
the optimum organization for the facility. Each space iscompared to all other spaces and given a numerical 
score ranging from 1 to 6 based on importance. One matrix for each evaluation isused for control Thereafter 
all changes are automatically document­ed ina comparison matrix for further reference. Once the matrices 
are completed for all criteria to be examined,the program converts the spaces to bubbles which do not 
represent the final size or shape on the CRT. These bubbles are then manipul­ated i'nto the optimum plan 
on the CRT and may re­present buildings on a site, departments inan office, or rooms within a department. 
Each time the user rearranges the bubbles a comparison ma­ isdeveloped to denote deviations from the 
control assumption. The changes tell the user either the original value was wrong or perhaps personal 
opinion is trying to interferewith the original criteria values. When all the necessary diagrams have 
been produc­ ed, the user specifies that all bubbles should be changed to blocks of the appropriate 
size and shape and inthe configuration of the bubble dia­ gram desired. Again the user can manipulate 
the bubbles and request comparison matrices. The user continues to refine the diagram until " the optimum 
plan isproduced. Because of the ease and speed at which these diagrams can be produced, this process 
acts as a catalyst to the entire design process. The owner or end user who is intimately involved with 
the final space can use this tool as effectivelyas the designer. Ideally both would be working together 
as a team to evaluate the spaces. The next program to be used for further graphic refinement would 
be the two dimensional drafting The two dimensional graphic data is stored using program. Cartesian 
coordinates under a unique file name. Two Dimensional Data Manipulation The user interacts with the 
graphic symbols via the spark pen, CRT and the alphanumeric display. 43 The first items inthe menu are 
the zoom and pan options, unique to the refreshed screen. The con­trol buttons for planning left -right 
and up ­down are located below the screen. The in-out buttons are for zooming, or increasing or decreas­ing 
the scale of the screen image by half. Ifthe base scale for the data is1/8" = 1'0", "IN"will increase 
the image to 1/4" = and zooming "OUT" will increase the image to 1/16' = 1'0". At this time all the 
data on the screen would be visible. Interaction with the screen occurs when an option isselected from 
the menu and the origins of each separate graphic item on the screen begins to blink. By placing the 
cross hairs over the blink­ing box and touching down twice, the standard graphic symbol can be manipulated. 
While the box isblinking and before the user touches down the second time, the selection may be cancelled 
by moving the spark pen to the right and back into the menu area. The "Hard Copy" option transfers 
the data current­ly displayedon the screen to the printer for doc­umentation, thus giving a "Standard 
Copy" with a boarder. "Special Copy" contains special features: creating a file for output to a plotter, 
blowing up the Screen Image two times, omitting the draw­ing boarder, omitting the text, typing ina spe-' 
cial text height and omitting the grids. Inaddi­ tion, the hard copy can be stored for use in IMAGE 
program giving the user the virtually unlimited drawing enlargement or reduction. This program will 
be explained later inmore detail. "Move" enables an element to be moved from one lo­ cation to another. 
The user has designed his data so that frequently moved objects have their own origin (Blinking Box) 
and can be moved independ­ently of other subpictures. "Rotate" will turn the item inclockwise or count­er 
clockwise direction by the specifiedamount. The most commonly used degrees are shown, however, a special 
rotation can be typed. "Mirror" moves the object up -down -right or left of the origin. "Delete" allows 
unwanted graphic data to be re­moved from the screen but not from the data base itself. "Repeat" multiplies 
a given image and acts as a electronic template. The designer inputs a small amount of data once and 
lets the computer redraw itas many times as needed inany orientation. Think of the time saved and the 
number of altern­atives that can be developed. You can see how im­ and valuable it isto reuse data. 
The "Grids" option aids the user inmaintaining the design module. By selecting "Round on" the user is 
assured that the chosen module is adhered to by only allowing graphic elements or lines to fall on the 
grid. The option can be turned off when non-modular drawing is done. With "Calculate", area and distance 
can be deter­mined. By outlining a given area by pen pointing line segments, each length isaccepted and 
the to­tal is calculated. This function isideal for determining the area of irreqularlv shaped spaces 
or verifying conformityto program sizes. "Dist­ance" works ina similar manner only instead of enclosing 
a space, points along the length of the space are recorded. Again compliance to codes can  44 composite 
drawing. be verified. With "Add an SGE" previously stored standard grap­hic elements (SGE's) are retrieved. 
(See blocks numbered 1 and 2). "Fetch" calls up previously stored drawings for overlays and drawing 
production. Also, standard graphic symbols can be grouped ihto kits to be fetched and used as building 
blocks. "New Drawing" will clean the screen and enable the user to set a new scale add begin a new 
drawing. "Store Drawing" stores everything on the screen un­der the unique file name typed on the alphanumeric 
display screen. Ifinformation already exists un­der the given file name, the user can overwrite the 
old data with new data or type inanother unique name. This safeguard isfound on every option which permanately 
changes files. Therefore,many errors are eliminated by this reminder. It isthrough this process of 
adding, repeating, changing and storing data that working drawings are produced. The greater the repetition 
whether itbe building perimeter, cores, furniture or materials the faster the drawings are produced 
and the more time the designer has to investigate new ideas. Image Program The "Image" program, which 
was mentioned earlier in conjunction with hard copy, allows the user to ma­ nipulate entire drawings, 
not just portions of drawings, by overlaying or displacing drawings from a specified origin for output 
to a printer or to a storage screen. Itisthrough this program that all of the drawing sections are 
merged into one This feature enables the user to develop a single base plan and combine itwith any number 
of appro­priate overlay drawings. The furniture and parti­tions combine with the telephone layout for 
the phone company or the partitions overlay with the lighting plan for the lighting consultant. This 
allows specified layers to be reviewed by appro­ priate people. The combinations are endless. This procedure 
not only applies to plans but also to elevations where one floor is created and dis­ placed up, down, 
right or left of the origin to produce the entire facade. Wall sections and de­ tails are also developed 
inthis manner. (See blocks numbered 3, 4, 5,and 6). Another feature allows the same drawing to be printed 
with line weights suppressed there by pro­viding a screened architectural base plan for the mechanical 
engineers' flexible duct layout, with the engineers information highlighted. Once these overlayed drawings 
are produced,the needed copies are printed on the dot printer in strips which are spliced together. 
With output to a plotter, two objectives are met. One, the draw­ ing isreproduced on velum or mylar 
allowing flex­ ibility for further duplications. The other is that the plotter uses ink pens which allows 
for the introduction of colored lines of varying line weight. The building grid could be one color, 
the bases plan another color, electrical still another color. One drawing with a multitude of inform­ 
ation is legible because of the introduction of color. Inaddition, once the drawings are pro­ duced 
they can be used for check sets or present­ ation drawing just by varvinq the output device.  45 The 
program has still another feature, the scale option. By typing ina scaling factor, small size key plans 
and full size final drawings are produc­ed from the very same drawing. Enlarging a por­ tion of a wall 
section to be used on a detail sheet can be accomplished by typing the chosen scale. The combination 
of these options make this pro­gram a valuable production tool. Advantages The advantages of using 
the computer for facili­ties management and inventories are numerous. First, since the reuse of data 
isessential inthe cost effectiveness, this process of inputing the data once and reusing the same data 
each time re­modeling occurs saves the client money. Each time renovation occurs the client ispaying 
less for drawing production. Second, since the programs are interactive, the client can sit at the screen 
with the architect or engineer and examine altern­atives thus reducing review time. The computer becomes 
a catalyst for the entire decision making process. By being able to study more alternatives, it is hoped 
that better use can be made of availa­ble space and optimum solutions can be found so that the owner 
isnot paying for unused or misused space. By knowing realistic costs and schedules on top of that,the 
owner gets the most building for the money. Third, solutions can be evaluated against established criteria 
and restraints. Fourth, technical manpower can be reduced. Fifth, production can increase while maintaining 
a cons­tant personnel level. The practicality and economic feasibility of com­puter graphics has been 
seen time and time again by our office and clients in terms of manpower. One of the best examples of 
this has been Facilities Management overlays and inventories developed for the Office of the Comptrollerof 
the Currency. Through the use of this process they were able to cut 10 weeks off a normally 13 week process 
for their annual audit. A pilot study conducted by Eli Lilly on our system also resulted infavorable 
results as indicated in their preliminary report made after testing this system inorder to evaluate its 
potential use for their company. "As a medium for the test, process flow sheets were produced. A comparison, 
the con­ventional manual method versus the computer method, was made first on the basis of time required 
to do the task. A drawing taking 16 hours to complete manually coul'd be accomplished in 8 and one quart­er 
hours employing computer drafting. These sav­ings were achieved by individuals with essentially no experience 
in utilizing the system and with a preliminary data base that could be expanded and improved greatly. 
Equivalent time of 1/5 to 1/4 of the above are not unreasonableto expect with operator proficienty and 
a completely developed data base. The 57% savings inmanpower shown in experiment with experience and 
a fully developed data base should increase to an approximate 90% savings inmanpower necessary to produce 
finished drawings. An over-all system efficiency of 80% appears feasible. This would yieTd intime an 
increase inproductivity by 5.75 man years per year of use based on an 8 hour day. Lilly also concluded 
with an initial investment of $154,600 and based on an 8 hour day the net savings by the second year 
would be $39,600. By the third year, the savings would be $74,400. For 12 and 16 hour days, the savings 
would be greater. The most eff­icient use of the system comes from introducing the second or third shift. 
The initial investment remains constant as does the  niirrhaco  46 but the maintenance and supplies 
decrease while Control, coordination and communication will be production increases." Facilities Management 
isjust one way of using this graphics package and associated data bases. Potential applications are only 
limited by the user's imagination and skill. This same program isused to develop wall sections, elevations, 
pro­duction and assembly line flow charts, plant and warehouse layouts, and equipment and part design. 
Because of the high visual impact, interest and support for new design and construction approach­ es 
can be solicited through simulation. Future The graphics package described isnow completely workable 
and totally implimented. Work has now begun on the third effort involving a new genera­ tion of hardware 
with wider applications and use. When linked with heat lost/heat gain programs, this graphics package 
has the potential of becom­ing a energy conservation package. The user can "Fetch" wall sections; and 
by changing the compo­nents on the screen have the resulting heat lost calculated. A comparison could 
instantly be made between the use of a cavity wall versus brick veneer or three inches of insulation 
as opposed to six inches. A refinement of the existing package isplanned to associate the graphic symbols 
with the Architectu­ral Criteria data base inorder to produce a dyna­mic instantaneous update. This would 
enable the user to move a chair from one room to another or even delete an item and have the location 
and quantities automatically updated. Along with this option will be "Group Move" enabling a room to 
be moved as a whole unit, as well as, each individ­ ual part. Inorder to increase the usefullness and 
flexi­ bility, this standalone system will become a part of a network relying on a central computer 
for mass storage and mini-computers for remote input, manipulation and output. This would allow among 
 other options, the ability of the engineer to call up the drawing with the latest revisions as soon 
 as it isstored by the architect. Changes could be input by the architect or supervisor inthe field. 
Problems could be studied, solved and documented at the job site. Conclusion Itis important that control 
ismaintained from conceptual design through the life cycle of the facility inorder to insure the continuityof 
 proper, efficient and satisfactory use and main­ tenance of the building. Coordination iscriti­ cal 
due to the number of people involved inany project. Better communication ismandatory because of the 
likelihood that members of the project team could be miles apart. Quick access to data as well as ease 
with which drawings can be brought up to date isimportant inrenovations and retrofitting. 1.Rowe, R.L., 
Newport, N.A. and Hildebrand, J.B., Preliminary Report. Eli Lilly &#38; Company, Indianapolis, Indiana 
(April 9, 1975), 3-8. the key elements contributing to future successful endeavors. Computer graphics 
will play a signifi­cant role inbuilding and project management. References 1.de Armas, Emile. Computer-Aided 
Design...a First for the Veterans Administration. Proceed­ings for the International Council of Building 
Construction, W-65, National Academy of Science, May 1976. 2.Perry, Dean Partners Inc. Computer Aided 
Design (1975). CPMI, 4045 Merle Hay Road, Des Moines, Iowa 50310. 3. Perry, Dean &#38; Stewart. Application 
of Computer Aided Architectural Design for EM and EW Housing Projects, Fort Lee, Virginia. Book I Volume 
I (1975). U.S. Army Construction Engi­ neering Research Lab. P.O. Box 4005, Champaign ILL 61820, Special 
Projects Division. 4. Perry, Dean &#38; Stewart. Computer Aided Design Demonstration, Veterans Administration,Augusta 
Georgia. Veterans Administration Project No. Final Submission Volume 1-6, 1975. V.A., Preliminary Planning, 
810 Vermont Avenue, Washington, D.C. 20420. 5. Rowe, R.L., Newport, N.A. and Hildebrand, J.B. Preliminary 
Report, Eli Lilly and Company, Indianapolis, Indiana (April 9, 1975), 3-8  47
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563869</article_id>
		<sort_key>48</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Interactive analysis and display of tabular data]]></title>
		<page_from>48</page_from>
		<page_to>53</page_to>
		<doi_number>10.1145/563858.563869</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563869</url>
		<abstract>
			<par><![CDATA[A program for simple data analysis and report design is described. The design emphasizes flexibility, ease of use, and rapid interactive response. These considerations are discussed in relation to the choices that may be made in the analysis and display design process. The analysis may be directed and monitored at several points - data selection and calibration, binning, choice of data scaling, choice of graphic variable, and scaling of the graphic variable. Table rows and columns can be re-organized by operators such as ranking, sequencing and grouping, and re-computed from arithmetic combinations of existing rows and columns. Where the raw data represents different cases scored over the same attributes, profile tables can be computed in a systematic fashion. Interactive report design is supported by a variety of page layout and chart annotation directives, which can be used to embellish and adjust the default line, bar and pie charts. The program can be used interactively as well as driven from a prepared script, and uses a device independent graphic system. Although intended to be used primarily with a graphics terminal, at least half the actual use has been conventional report generation on both alphanumeric and graphic terminals.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[data analysis]]></kw>
			<kw><![CDATA[device independent graphics]]></kw>
			<kw><![CDATA[matrix displays]]></kw>
			<kw><![CDATA[report design]]></kw>
			<kw><![CDATA[tabular data]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379966</person_id>
				<author_profile_id><![CDATA[81100476980]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Benson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lawrence Berkeley Laboratory, Berkeley, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379936</person_id>
				<author_profile_id><![CDATA[81100388870]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bernard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kitous]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lawrence Berkeley Laboratory, Berkeley, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Austin, D. M., Kranz, S. G., and Quong, C. An overview of the LRL socio economic environmental demographic information system. LBL-3699. March, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bertin, J. Semiologie Graphique. Cauthier-Villars, Paris, (1967),69.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Gibson, T. A., and Ting, P. D. A new report generator. Proc. ACM-PACIFIC-75, San Francisco, Ca., (April 1975), 119-126.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[GRAFPAC Users Guide, Graphics Research Group, Lawrence Berkeley Laboratory, July 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Kitous, B. Interactive matrix displays and management information reporting - a feasibility assessment. (Ph.D. thesis) LBL-5310. (June, 1976), 118-120.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Mendelssohn, Rudolph C. The development and uses of table producing language. U.S. Department of Labor, Bureau of Labor Statistics, Report 435, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Nie,Norman, et al. Statistical Package for the Social Sciences , 2nd edition, McGraw-Hill, N.Y., 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563298</ref_obj_id>
				<ref_obj_pid>965143</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Schneider, Edward J., Barge, Sylvia, and Marks,Gregory A. Graphics for social scientists. Computer Graphics Vol. 10 No. 2 (Summer 1976), 125-131.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 INTERACTIVE ANALYSIS AND DISPLAY OF TABULAR DATA* William H. Benson Bernard Kitous Computer Science 
and Applied Mathematics Department Lawrence Berkeley Lahorato.ry Berkeley, California 94720 Abstract 
 A program for simple data analysis and report design is described. The design emphasizes flexibility, 
ease of use, and rapid interactive response. These considerations are discussed in relation to the 
choices that may be made in the analysis and display design process. The analysis may be directed and 
monitored at several points -data selection and calibration, binning, choice of data scaling, choice 
of graphic variable, and scaling of the graphic variable. Table rows and columns can be re-organized 
by operators such as ranking, sequencing and grouping, and re-computed from arithmetic combinations 
of existing rows and columns. Where the raw data represents different cases scored over the same attributes, 
 profile tables can be computed in a systematic fashion. Interactive report design is supported by 
a variety of page layout and chart annotation directives, which can be used to embellish and adjust 
 the default line, bar and pie charts. The program can be used interactively as well as driven from 
a prepared script, and uses a device independent graphic system. Although intended to be used primarily 
with a graphics terminal, at least half the actual use has been conventional report generation on both 
alphanumeric and graphic terminals. Keywords and phrases: tabular data, data analysis, report design, 
matrix displays, device independent graphics CR Categories: 3.50,3.53,8.2 Introduction Most people 
have trouble assimilating even small amounts of data in tabular format. It is widely recognized that 
the familiar graphic representations -bar charts, pie charts, line graphs -such as found in newspapers 
and magazines as well as technical journals are more effective  Permission to make digital or hard copies 
of part or all of this work or personal or classroom use is granted without fee provided that copies 
are not made or distributed for profit or commercial advantage and that copies 48bear this notice and 
the full citation on the first page. To copy otherwise, to republish, to post on servers, or to redistribute 
to lists, requires prior specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California 
and efficient in conveying relationships in the data. This paper describes a program (CHART) for simple 
data analysis and report design for presentation and publication. The basic goal is to represent numerical 
data tables in a graphic display format so that data analysis and report design can be done in a visual 
fashion. The program was developed for use in management information reporting. In this environment 
tables, graphs and charts are typically worked up and drawn by hand, or produced by custom programs 
with rigid formats designed for a particular report or application. Most of the considerations discussed 
by Schneider about the social science computing environment hold here. Reports must be clearly labeled 
and adjustable in format and capable of being displayed in a variety of graphic forms. Typical analysis 
tasks include grouping and ranking of rows and columns and computing totals, subtotals, averages and 
percents. A graphic software system for this purpose should be device independent and mask as much as 
possible technical details about programming languages, operating systems and hardware. Design framework 
A pragmatic approach has been taken towards meeting these needs. 1. Tabular data is entered either from 
the terminal or from a previously prepared script. Since there is not as yet a clean interface to a 
data base management system, it is not possible to describe the data in terms of variables in the data 
base, such as is done in report generation systems [3,6]. Consequently the tabular data is not considered 
to have additional structure beyond that of a rectangular array. Row and column labels are considered 
to be part of the table and occupy row and column positions. 2. The program is designed for interactive 
use. Users can experiment with different graphic representations, make adjustment to titles, labels, 
grids, etc., and perform simple analytic tasks. Since display features are specified independently 
of each other, modifications to a given display are made by a sequence of incremental changes. 3. The 
user communicates with the program in a language which resembles a kind of fractured English. A keyword 
directed syntax allows the user to converse in terse sentences composed from numbers and a small vocabulary 
of English words. Each sentence changes the state of the data values or the display and gives visual 
feedback. No graphic input is used. This implies that the program can be directed from a text file as 
well as from a terminal (including alphanumeric terminals). 4. Any display produced by the program 
is completely specified by a short list of sentences. The description may be saved on a script file 
so that the results from one session at the terminal can be the input to the next. The form of the 
 display can be saved independently and used with different data. (  5. A device independent graphics 
package is used. Any picture produced should look as similar as possible on different devices. Hardware 
characters are used to reduce plotting time. Since hardware characters vary in size from one device 
to another, plotting space for text is allocated in terms of character size. 6. Choices may be made 
throughout the analysis and design process. The analysis may be directed and monitored at many different 
points -data selection and calibration, binning, scaling statistical data to display data, choice of 
graphic variable and chart type, and scaling of the graphic -variable. Rows and columns of the table 
can be re-organized by operators such as ranking, sequencing and grouping, and re-computed from arithmetic 
combinations of existing rows and columns. Titles and row and column labels may be entered and positioned, 
bars, and pie slices shaded and labeled with data values, axes labeled, etc. There are format options 
for missing data and hierarchical labels. 7. A transcript of each session, minus the graphic output, 
is printed and routed to the system designer. This provides valuable information about patterns of usage, 
difficulties with the program, proposals for new features, and bugs. User comments entered at the terminal 
are seen in context. For the user, the last monitoring and consulting. Chart types The graphic forms 
which can be produced include matrix displays, bar charts, line graphs, pie charts, and tabular reports. 
 A matrix display is the direct representation of a numerical data table in graphic form. That is, the 
display looks like a matrix or table with rows and columns bhut where the numbers in each table cell 
have been mapped into a graphic variable. The graphic variable used is the variation of size (of circle, 
angle, a or horizontal or vertical bar). Bertin  has shown that any graphic variable (such as size, 
value shading, shape, color, orientation or texture) can represent categorical data and a few (texture, 
shading and size) can convey relations of order between items. However only variations of size can adequately 
 express quantitative relations (numerical ratios) between data items. Ratios could be estimated using 
value shading or texture although with much less spontaneity and precision. Each table cell is replaced 
by a graphic item such as a circle or bar. The numerical data is mapped into graphic items according 
to specific rules of scaling which can be modified by the user. The arithmetic sign is always preserved. 
Negative values are shown both by shading bars and circles, and extending bars in the opposite direction 
from positive bars. Since matrix displays preserve the positional characteristicsof a table, the user 
can return to the more familiar tabular format to re-interpret patterns observed in the display. To 
avoid clutter and improve perception of patterns in the data, labeled axes are normally omitted. When 
there is one or only a few rows or columns, a bar chart can support labeled axes, shaded bars, and 
values attached to the bars. Line graphs where curves from each row of the table are superposed and 
plotted to the same scale permit ready comparison of horizontal profiles. Pie charts show the division 
of a whole into parts. Conventional tabular reports have the advantage of familiarity and preciseness, 
and can be displayed on alphanumeric terminals lacking graphic capablilities. The interactive cycle 
 the terminal is seen as a cyclical process consisting of data selection and calibration, analysis, and 
display. An interactive session at thirty commands are saved and may be Data selection displayed 
in a brief history log. In addition to on-line access to part of the a Data selection begins with 
input of users' manual, users remote from the raw data table.. Tables are prepared in a computer center 
can he helped by expanding stylized tabular format similar to that the interaction to include on-line 
 49 used by SPSS [7], but more suitable for entry at the terminal. Column headers are entered first, 
followed by successive rows consisting of a label and a number in free field format for each column. 
A table may be entered at the terminal or from a previously prepared script. Once established, a table 
can be partitioned and attention restricted to a subset. A set or range of rows and columns may be 
 masked from sight and later restored in whole or in part. Individual table cells can he changed -for 
example erroneous data or outliers -and new rows and columns can be computed from arithmetic combinations 
of old ones. Since the raw data may need to be augmented or partially replaced in unpredictable ways, 
an interpreter for vector arithmetic computes arbitrary arithmetic expressions of row or column vectors 
element by element. For instance population densities could be calculated from a table of populations 
and areas for a set of regions. An auxiliary command backs up to the last table as it was originally 
entered. Analysis It is expected that one looks at raw data tables, time series data aside, primarily 
for size effects. For example table cells may be compared according to which is the largest, or rows 
put in rank order on the basis of a particular column. In many cases it may be inappropriate to compare 
the data on the basis of size, for example when the raw data is not homogeneous or when shape rather 
than size effects are of interest. Suppose several cities are to be compared on a cost of living basis. 
Table I shows consumer price indexes for major categories such as food, housing, etc. Figure IA gives 
a global idea of where costs are greatest. Fuel is high everywhere but all other costs are fairly 
similar. Here it would be useful to compare the relative deviations from the average for each category 
rather than comparing absolute index values. The relative deviations describe vertical profiles for 
each price index category. Figure 1B shows how much each city differs from the average. Negative differences 
are shown by shaded bars. Seattle and Honolulu are consistently below average; Washington D.C. and 
New York are above average in each column. The rest are mixed. Frequently, a table represents a set 
of different entities scored over the same attributes. Consider a cross tabulation of age distribution 
by county. Although counties may differ widely in population, they may be compared directly if the 
raw counts for each age group within a county are replaced by the percent each count is of the total 
county population. Similarly age groups could be compared across counties by taking percent of total 
in the  50 other direction:  The two operations illustrated, difference and proportion, can be combined. 
For example economic indicators are often described by percent change from previous month. The differences 
between consumer prices in successive months are divided by the earlier of each pair to compute rate 
of change profiles. Since obtaining profiles is an analytic step of general utility, profile tables 
can be derived from the raw data in a systematic fashion. There are two steps to the normalization process 
in which size effects cancel out to allow comparisons across attributes. 1) define a reference row 
or column 2) compare each row or column in the table to the reference Several choices are available 
for each step. The reference may be computed by summing or averaging over rows or columns. A particular 
row or column in the table may be designated, or a new one, such as a threshold, entered at the terminal. 
Or instead, for each row or column the previous one may be specified as the reference. Comparisons with 
the reference may be made either by taking differences, proportions, or first differences and then proportions. 
Typically each row, say, of the profile table is obtained from the corresponding raw data row by subtracting 
the row average or dividing by the row sum element by element. Several operators which manipulate entire 
rows and columns at a time can be used to re-organize a table. These include 1) ranking -the rows or 
columns can be ranked in ascending or descending order on the basis of a particular column or row. 2) 
permutation -a particular sequence of rows and columns can be specified; pairs of rows or columns can 
be switched. 3) grouping -the table can be partitioned into blocks by declaring groups of consecutive 
rows and columns. When plotted as a matrix display, bar chart, or tabular report the groups are shown 
separated by blank rows or columns. A reference row or column, for example, is shown in a group by itself 
set off from the rest of the table. In Figure 1A the row average is shown as a reference. Row and column 
categories are immediately recognized since the groups are perceived spontaneously as separate entities. 
Figure 1B shows cities grouped according to whether they are above average, below average, or mixed 
with regard to cost of living indicators. These operators are applied simultaneously to the profile 
table and the raw data table from which profiles have been derived. Thus a meaningful organization of 
a profile table can be interpreted back to the raw data, and vice versa. Display The data structure 
consists of a set of rectangular arrays, one each for the profile, raw, and display data tables. The 
numerical data in the raw or profile tables is mapped into display data normalized between 0 and 1 
in absolute value. These normalized values can be expressed directly by graphic items. The mapping is 
performed in several steps. At each step the user may intervene to choose from among a limited set 
of alternatives: 1) bin the data -this is a preliminary step to scaling. The data is distributed as 
equally as possible into however many bins are wanted, from one to the number of distinct data values. 
The distribution is adjusted so that tied values are always in the same bin. The average value is taken 
 within each bin. This step, which reduces data resolution, is optional. 2) scale the data -the numerical 
data values are scaled prior to being plotted by one of several transformations described below. All 
of the transformationspreserve the sign and relative order of the data values. Ranking preserves only 
the order of the data values. These are scaled in equal steps from the minimum to the maximum. The 
minimum takes the smallest graphic item and the maximum the largest, so that the entire range of the 
graphic variable is used. The intermediate values are equally distributed within this range in rank 
order. Ranking allows comparison of all data values even though disproportionately large values may 
be present. Relative scaling preserves intervals between values as well as order. Ratios are in general 
not preserved, since the zero value may not lie within the data range. This transformation may be 
misleading, but can be useful when extreme values are present or when zero would be an extreme value. 
The minimum is shown by the smallest possible graphic item and the maximum by the largest. Relative 
scaling uses the entire range of the graphic variable. However when the data range already includes 
zero, absolute scaling is used instead. Relative scaling is used in Figure 1A. The largest values are 
 recognized spontaneously. Absolute scaling extends the data range, if necessary, to include zero. This 
has the effect of preserving ratios 51 between graphic items, but may use only a part of the space 
available in each matrix cell to show the data variation. That is, the lower part of the range of the 
graphic variable may be unused. to the last two rules are usually made when a labeled scale is displayed 
on the chart. For absolute scaling the range is further extended to reach "pleasinr round numbers". Since 
users frequently want to specify ninimun, maximum and division points on a labeled scale, these parameters 
for relative scaling can he set directly. 3) select graphic item -horizontal bars, vertical bars and 
circles translate numerical data by size. Profiles along rows are typically shown by vertical bars; along 
coliinns by horizontal bars. The circle display is unbiased as to d-irection so that extrene data values 
are spontaneously perceived regardless of where they are in the table. line graphs, pie charts, and tabular 
reports are also specified at this point. If no graphic item has heen selected the normal graphic feedback 
from all but a few of the other commands is suppressed. 4) scale graphic variable -a further transformation 
can optionally be applied to the normalized display data to scale the graphic variable. Three functions 
are provided to enhance tie low, middle, or high ranges of the data values. [5] a) exponential base 
10 (Fechner's rule) to enhance the high end of the distribution b) square root -to enhance the low end 
c) a composite of the first two rules to enhance the middle range The interval [0,1] is mapped onto itself. 
Roth sign and order are preserved. These functions can be used to match perceived variation in the graphic 
variable with the actual variation in the data, or to distort the graphic variable so as to enhance discrimination 
in the region of interest while retaining a global picture of the data. Interactive report design An 
auxiliary program is available to interface with a data retreival system. This program processes a script 
identical in form to that used by CHARIT, replacing data descriptors by data elements but leaving all 
else unchanged. Since the form of a display can be saved (as command sentences) for use with new data, 
report design needs to he done only once for a set of similar data. In practice reports are usually produced 
in -several steps (1) design the report using typical data; (2) save the form of the display on a script; 
(3) replace the table values by descriptors in the data base using text  a editor; (4) run the auxiliary 
program to rewrite the script, substituting values from the data base for the data descriptors; and 
(5) run CH(ART using the rewritten script. The user has a choice of several standard graphic forms to 
represent a table and can experiment with different formats within each form. Since the program is oriented 
towards interactive use, it is expected that the report design process proceeds from a default standard 
display to the final design by a series of incremental changes. The display is accordingly so that the 
visual components may be modified independently of each other. The display is constructed from the outside 
in with titles surrounding row and column labels surrounding labeled scales. Individual title lines can 
he entered and positioned selectively at tie four outside edges of the display. Labels and labeled scales 
can be placed at the left, right, top, or bottom. The remaining space is used to display the data. Space 
for the titles, labels, and scales is allocated in terms of character size. This helps achieve device 
independence and recognizes the importance of text to the chart reader. Some other features that can 
be modified are grids, width and shading of bars, numerical formats, and placement of labels on line 
graphs and pie charts. Tabular data in the real world is often incomplete -parts of rows and columns 
may be empty because no data for these positions is available. The approach taken here is to key these 
positions to explanatory messages within the program and to display one or more characters from the 
message at the corresponding matrix cell. Asterisks, for example, could be displayed at empty cells and 
referred to a footnote, starting with an asterisk, which identifies or explains the missing data. The 
messages are implemented by assigning title lines to missing data. Empty table cells are filled from 
a list of distinguished numbers, too large to be confused with real data, where each number on the list 
corresponds to a particular title line. Numbers of this magnitude are uniformly treated as missing data 
and ignored in scaling and all other computations. These huge numbers may he entered by the user, or 
computed by the program. For example the calculation row3=rowl/row2 will result in no data for those 
positions where row2 has zeroes. Device independence The graphic systems environment consists of a variety 
of interactive terminals and off-line hard copy devices and a set of FORTRAN subroutine packages, one 
for each device type, which supports device independent displays. The subroutine packages, collectively 
known as are low level drivers 52 supporting standard graphic functions. These include plotting points, 
lines and characters, erase screen, and defining windows and viewports. These functions are described 
by identical parameters and calling sequences among the GRAFPAC modules. The module for each device 
interprets only the parameters supported for that particular device. For example, modules for devices 
with only one character size will ignore that specification. Each device is given a normalized plotting 
space from [0,1] in x and y so that pictures drawn within these limits are guaranteed to plot on any 
device. The applications program specifies a linear mapping from a data space to the normalized page 
space. A further mapping is made within each module to the raster space used by the particular device. 
 Characters and lines may be clipped to appear only within the viewport specified in the normalized 
page space coordinates. The system is efficient for interactive use since the display list (including 
 hardware characters) for each individual device type is generated directly. The device types required 
must be selected before program execution but only the corresponding modules need be loaded. There 
are mechanisms for switching between device types and between hardware and software characters during 
execution. An alternative approach to device independence is also supported. An intermediate file generated 
by a module for a virtual device can be interpreted by a post processor which has been linked with 
any of the other modules. Since pictures from the intermediate file can be plotted and overlaid in 
any order, page layout and composition could be approached in this way. No graphic input is used, 
avoiding the issue of device independence. Discussion The first design underestimated the role of text 
in favor of providing a variety of graphic forms. Since novel graphic forms do not seem to be readily 
 accepted, the most familiar graphic representationswere emphasized. Experience with users indicates 
several ways in which textual material is important. The data must be clearly identified. In a practical 
case employment data, which can be qualified with many conditions, often requires many words in each 
row and column label in addition to titles identifying the overall subject. Additional titles may be 
needed to guide interpretion of the graphic display. Use of hierarchical labels has helped reduce 
 the'quantity of text. Although graphic displays are effective and efficient in conveying relationships 
in the data, it still seens essential to be able to refer back to the numbers. Users may feel the need 
to validate or check the consistency of visual impressions, be able to verbalize results, or feel more 
secure with the precision of numerical data. Consequently attention is also given to the display of numbers 
as text. In particular, since matrix displays are a direct representation of a numerical table, one 
can be readily compared with the other. Although the program is intended to be used primarily'with 
a graphics terminal, at least half the actual use has been conventional report generation on both 
 alphanumeric and graphic terminals. In part this reflects greater familiarity with tabular reports 
and limited availability of graphic terminals. Here device independence has been especially useful. 
Since tabular reports are plotted rather than printed, they may be displayed on an alphanumeric terminal 
by using the corresponding GRAFPAC module. Future developments will emphasize integration into a larger 
information system [1]. References [1] Austin,D.11., Kranz,S.G., and Quong, C. An overview of the 
LRL socio economic environmental demographic information system. LBL-3699. March, 1975. [2] Bertin,J. 
Semiologie Graphique. Cauthier-Villars, Paris, (1967),69. [3] Gibson,T.A., and Ting,P.D. A new report 
generator. Proc. San Francisco, Ca., (April 1975),119-126. [4] GRAFPAC Users Guide, Graphics Research 
Group, Lawrence Berkeley Laboratory, July 1976. [5] Kitous,B. Interactive matrix displays and management 
information reporting -a feasibility assessment. (Ph.D. thesis) LBL-5310. (June, 1976), 118-120. [6] 
Mendelssohn, Rudolph C. The development and uses of table producing language. U.S. Department of Labor, 
Bureau of Labor Statistics, Report 435, 1975. [7] Nie,Norman, et al. Statistical Package for the Social 
Sciences , 2nd edition, tlcGraw-Hill, N.Y., 1975. [8] Schneider, Edward J., Barge, Sylvia, and 'larks,Gregory 
A. Graphics for social scientists. Computer Graphics Vol. 10 No. 2 (Summer 1976), 125-131. 53 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563870</article_id>
		<sort_key>54</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Anima II]]></title>
		<subtitle><![CDATA[a 3-D color animation system]]></subtitle>
		<page_from>54</page_from>
		<page_to>64</page_to>
		<doi_number>10.1145/563858.563870</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563870</url>
		<abstract>
			<par><![CDATA[An animation software system has been developed at The Computer Graphics Research Group which allows a person with no computer background to develop an animation idea into a finished color video product which may be seen and recorded in real time. The animation may include complex polyhedra forming words, sentences, plants, animals and other creatures. The animation system, called Anima II, has as its three basic parts: a data generation routine used to make colored, three-dimensional objects, an animation language with a simple script-like syntax used to describe parallel motion and display transformations in a flexible, scheduled environment, the Myers algorithm used in the visible surface and raster scan calculations for the color display. This paper discusses the requirements, the problems, and the trade-offs of such a system. An overview of research in the area is given as well as the design and implementation highlights of the Anima II system.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379964</person_id>
				<author_profile_id><![CDATA[81332502731]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ronald]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Hackathorn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Appel, A., Stein, A., Landstein, J. (1970). The Interactive Design of Three-Dimensional Animation, Proceedings of the Ninth Annual UAIDE Meeting.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Archuleta, Personal Communication with CGRG.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Baecker, R. M. (1969). Interactive Computer Mediated Animation. Dissertation, Massachusetts Institute of Technology.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>907204</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Baumgart, B. G. (1974). Geometric Modeling for Computer Vision. Dissertation, Stanford University. NTIS Report Number AD/A-002261.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Belady, L. (1970). TV Plus Computer Equals Videographics. Proceedings of the Ninth Annual UAIDE Meeting.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Blasgen, M. W., Gracer, F. (1970). KARMA: A System for Storyboard Animation. Proceedings of the Ninth Annual UAIDE Meeting.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360353</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F., Newell, M. E. (1976). Texture and Reflection in Computer Generated Images. Communications of the ACM, Vol. 19, No. 10.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360727</ref_obj_id>
				<ref_obj_pid>360715</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Braid, I. C. (1975). The Synthesis of Solids Bounded by Many Faces. Communications of the ACM, Vol. 18, No. 4.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Catmull, E. (1974). A Subdivision Algorithm for Computer Display of Curved Surfaces. Tech. Report UTEC-CSC-74-133, University of Utah.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360354</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Clark, J. (1976). Hierarchical Geometric Models for Visible Surface Algorithms. Communications of the ACM, Vol. 19, No. 10.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563746</ref_obj_id>
				<ref_obj_pid>563732</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Csuri, Charles (1975). Computer Animation, Proceedings of the Second Annual Conference on Computer Graphics and Interactive Techniques--SIGGRAPH '75.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Csuri, Charles A. (1977). 3-D Computer Animation. Advances in Computers. Academic Press, Inc., New York.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Davis, J. R. (1968). A Model Making and Display Technique for 3-D Pictures, Proceedings of the Seventh Annual UAIDE Meeting.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Elin, L. (1975). Synthevision: Serendipity from the Nuclear Age, Artist and Computer, edited by R. Leavitt, Harmony Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Elin, L. (1977). Presented at National Conference and Workshop on Electronic Music and Art, University of Buffalo, Suny.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Film --- "Walking Man," University of Utah.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Film --- "NASA Space Shuttle" General Electric.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Film --- "Sphere Eversion" N. Max.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Gattis, W., Watson, (1971). An Input Translator for Animation and Its Relationship to Key Position Character Animation. Proceedings of the Tenth Annual UAIDE Meeting.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Goldstein, R. (1971). A System for Computer Animation of 3-D Objects, Proceedings of the Tenth Annual UAIDE Meeting.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Gouraud, H. (1971). Computer Display of Curved Surfaces. IEEE Transaction on Computers.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>804727</ref_obj_id>
				<ref_obj_pid>800143</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Jones, B. (1976). An Extended ALGOL-60 for Shaded Computer Graphics. Proceedings ACM Symposium on Graphics Languages.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Lafue, G. (1975). Computer Recognition of 3-Dimensional Objects from Orthogonal Views. Research Report No. 56, Institute of Physical Planning, Carnegie-Mellon University.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Myers, A. J. (1975). An Efficient Visible Surface Program. Technical Report to the National Science Foundation, Grant Number DCR 74-00768A01.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563283</ref_obj_id>
				<ref_obj_pid>563274</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Myers, A. J. (1976). A Digital Video Information Storage and Retrieval System. Proceedings of the Third Annual Conference on Computer Graphics and Interactive Techniques--SIGGRAPH.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563736</ref_obj_id>
				<ref_obj_pid>563732</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Max, N., (1975). Computer Animation of the "Sphere Eversion," Proceedings of the Second Annual Conference on Computer Graphics--SIGGRAPH.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Negroponte, N. (1973). Recent Advances in Sketch Recognition. Proceedings of the National Computer Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>907365</ref_obj_id>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Newell, M. (1975). The Utilization of Procedure Models in Digital Image Synthesis, Ph.D. Dissertation, University of Utah.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Parent, R. E., Chandrasekaran, B. (1976). Moulding Computer Clay. Pattern Recognition and Artificial Intelligence. (C. H. Chen, Ed.) Academic Press, Inc., New York.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>642094</ref_obj_id>
				<ref_obj_pid>642089</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Staudhammer, J., Eastman, J. F. (1975). Computer Display on Colored Three-Dimensional Object Images. Proceedings of the Second Annual Symposium on Computer Architecture, pp. 23-27.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. E., Sproull, R. F., Schumacker, R. A. "A Characterization of Ten Hidden-Surface Algorithms," ACM Computing Surveys, Vol. 6, No. 1, pp. 1-55, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. E. (1974). Three-Dimensional Data Input by Tablet. Proceedings of the IEEE. Vol. 62, No. 4, pp. 453-462.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Watkins, G. S. (1970). A Real-Time Visible Surface Algorithm. University of Utah Technical Report UTEC-CSC-70-101.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Wein, M., Burtnyk, N. (1971). A Computer Animation System for the Animator. Proceedings of the Tenth Annual UAIDE Meeting.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563743</ref_obj_id>
				<ref_obj_pid>563732</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Wein, M., Burtynk, N. (1975). Computer Animation of Free Form Images. Proceedings of the Second Annual Conference on Computer Graphics and Interactive Techniques--SIGGRAPH '75.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Whitney, John, Citron, J. (1968). Camp-Computer Assisted Movie Production, Proceedings of the AFIPS Fall Joint Computer Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ANIMA II: A 3-D COLOR ANIMATION SYSTEM Ronald J. Hackathorn COMPUTER GRAPHICS RESEARCH GROUP THE OHIO 
STATE UNIVERSITY ABSTRACT An animation software system has been developed at The Computer Graphics 
Research Group which allows a person with no computer backgroundto develop an animation idea into a finished 
color video product which may be seen and recorded in real time. The animationmay include complex polyhedra 
forming words, sentences, plants, animals and other crea­ tures. The animation system, called Anima II, 
has as its three basic parts: a data generation rou­ tine used to make colored, three-dimensional objects, 
an animationlanguage with a simple script-like syntax used to describe parallel mo­tion and display 
transformations in a flexible, scheduled environment,the Myers algorithmused in the visible surface 
and raster scan calculations for the color display. This paper discusses the requirements,the problems, 
and the trade-offs of such a system. An overview of research in the area is given as well as the design 
and implemen­tation highlights of the Anima II system. 1. Introduction During the past several years, 
films from the Universityof Utah (16), General Electric Corp. (17) and by N. Max (18), illustrate that 
the abil­ ity to produce 3-D shaded object animationhas been a significant addition to the field of com­puter 
animation. Max's comment about his film, "Sphere Eversion," describes the basic feeling to­wards this 
type of animation: "The film produces a visualizationwhich could not have been achieved in any other 
medium, and could never have been animated by hand." (26) A 3-D animation system which uses a visible 
sur­ face algorithm to calculate the final displayed image must deal with severe time-space considera­ 
tions resulting from the increased complexity of both the data and the data handling algorithms, through 
all phases of the system. Traditionally, shaded object animation while producing high qual­ ity has 
been a difficult, slow and expensive proc­ ess as a result of implementationaltrade-offs among these 
various considerations. An animation software system has been developed by the Computer Graphics Research 
Group as an Permission to make digital or hard copies of part or all of this work or personal or classroom 
use is granted without fee provided that copies are not made or distributed for profit or commercial 
advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, 
to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or 
a fee. Siggraph 77, July 20-22 San Jose, California attempt to maximize the trade-offs involved in 3-D 
color animation. The goal has been to achieve the capability and image quality necessaryfor complex animationand, 
yet, maintainthe total system efficiencynecessary for a production ani­mation environment. Anima II 
is a computer animation system designed for the production of color, three-dimensional video tapes. It 
is aimed at the animator, educa­tor and artist who requires anything from a high volume of short color 
sequences for teaching pur­poses, to realistic key frame animation involving complex color objects and 
precisely timed life­like movements. The Anima II system provides an efficient environment for the creation, 
animation and real-time playback display of color-shaded polyhedra. The video output is directly connected 
to video recording equipment and a standard color television set. 2. Background Before discussing previous 
research in the area of 3-D shaded animation systems it is important to briefly discuss the requirements, 
the problems and the trade-offs which accompany the design and im­plementation of such a system. 2.1 
Requirements System and user requirements for 3-D shaded anima­tion can be classified into three factors 
deter­mining overall system performance. 2.1.1 Capabilities -A shaded animation system can be viewed 
as having three separate capabili­ ties. Each has a unique functionwithin the sys­tem and each has different 
problems.  Data Generation is the process of constructing a computer model representing the three-dimen­sional 
object or form that is to be animated. The type of data to be generated is determined by the type of 
visible surface algorithmused. Essentially,polygon-basedalgorithms need planar polygons while parametric 
surface algo­rithms need high-order patch equations. There have been many approaches to inputting of 
3-D polyhedra. These include dual data tablet dig­itizing (32), single data tablet (23,27), and geometric 
modeling (4,8,13,29).  Animation is the process of "giving life" to  the generatedobjects by specifying 
motions animation a visible surface algorithm using the which imitate the actions of the physical world. 
second method is capable of sufficient quality. These motions involve changes to an object's  position, 
orientation (rotation), size and shape. Also the concepts of acceleration, de­celerationand "path-following"are 
included as motion descriptions. The animator controls the motions of an object through a program or 
 "script" written in the syntax of the system's language. Key frame techniques implemented in several 
2-D/3-D line animation systems (3,6,19, 36), notablyby the Film Board of Canada (34, 35), have proven 
a most effectivemeans for specifying the motion dynamics (movement through time and space) of complex 
animation. The centralnotion of key frame animation is that an action of an object will change "from" 
some spatial state "to" a new state and that this action will range "from" some time frame within the 
sequence "to" a later frame. In this manner the user need only specify the spatial-temporalextremes 
and the in-between frames are calculatedby the language. As well as other responsibilities,the animation 
lan­guage must also control a visible surface algo­rithm in one manner or another.  Display and record 
techniques give the animation system the capabilityof viewing the animation during development and documentingthe 
final animation sequence. The most common method of dealing with the output from a visible surface algorithm 
is to photograph it frame by frame. The image output may be a sweepinghorizontal scan line on a refresh 
CRT, or may be buffered in a 2-D matrix memory with raster video dis­play. Anothermethod is to encode 
the visible surface algorithm's results and store this in­formation on an analogue (30), or digital (5, 
25) disk. The video sequence may then be read from the disk, decodedthrough a scan-line de­coder, and 
displayed in real time on a video monitor. A refresh CRT needs filters to pro­ duce color while a raster-scan 
displaywill typicallyhave color output.  2.1.2 Image Quality -The type of visible sur­face algorithmused 
by the system determines to a large degree the single (still) frame image qual­ ity produced. There has 
been much work in the area of visible surface algorithms, and no at­tempt is made here to present all 
the factors in­ volved. Basically, however, there are two types of algorithms, the first type of which 
calculate the intensities of a curvedvisible surface to the resolution of a single picture element. This 
type includes the "reflected radiation" algorithm of Magi (20), the recursivebivariate surface patch 
algorithm by Catmull (9), and (10,28). The second type, polygon-based,simply colors or shades in the 
faces of 3-D polyhedra. Here the Watkins (31, 33) and Myers (24)algorithms serve for examples. The first 
method inherently produces a smoother surface than the other and lends itself to the cal­culation of 
texture, patterns and reflections (7). Thus, for still frame images one typically insists on a visible 
surface algorithmusing the first method. However, for multiple frame (moving) images, motion contributes 
significantlyto qual­ ity. Indeed it may be argued that the quality of motion is the most significant 
contributor to the qualityof the animation. In any case, for 2.1.3 Efficiency -A general definition 
of effi­ciency is "the ability to produce without waste." In a computer environment,the most valuable 
re­source to prevent from wasting is computer time. In an animation environment the resource is people 
time. Efficiency in an animation system implies that all capabilitieswithin the system are easy to use 
and produce their desired results quickly. For example, the system is inefficient if people who have 
been trained in animationhave to be re­trained in mathematics and/or computer programming just so they 
may apply their previous knowledge in areas of color, form, composition, rhythm, flow and motion. Further, 
it is inefficient if an ani­ mator is forced to stop repeatedlyduring the pro­duction process, because 
of a slow turn-around time to see the results. To gauge efficiency at the system level (i.e. sys­tem 
responsivenessand system throughput) an ani­mator must question all phases of the system: How long will 
it take to make the data? How hard is it to describe the animation? How long will it take to calculate 
(turn-aroundtime)? How compli­cated is the final recording process and how long will it be to see the 
results? System efficiency in an animation environment can only be measured in terms of how long it 
takes and how hard it is for the animator to get an animation idea off of a storyboard and onto film 
or video tape. A system which provides direct interactionand fast feed­back gives an animator the freedom 
to experiment with the system and get a feeling for what kind of animation can be done.  2.2 Problems 
and Tradeoffs Fitting the algorithms used for producing,handling and displaying 3-D color data together 
into a uni­fied animation system causes problems which effect the system's total performance. The problems 
are due to fixed limits within the system determined by how much time, money and memorywas available. 
 Trade-offs occur as some features must be lost in order for others to be implemented. For example the 
amount of directly addressable mem­ory available determines how much data memory and instructionmemory 
can coexist. The size of the data space limits the complexity of the objects while instruction space 
can decide capability and faster response times since program overlay and task switch techniques can 
be avoided if all the programs are in main memory together. Another example is image quality and its 
relation­ ship to capability and efficiency. A high-order parametric surface equation realisticallydescribes 
a smooth curved surface and has an increase in image quality over shaded polyhedra. While it may not 
be difficult to generate, the data for this type of algorithmwithout a control language, pre­sents difficulties 
for the animator. The algorithm can also take a considerable amount of calculation time to generate 
the final pictures. For instance, there are some excellent results with Catmull's method that took 25 
minutes on a PDP 11/45 for a single picture (7). Calculationtime becomes im­portant in an animation sequence 
where one minute takes 1440 or 1800 frames (depending on film/video "encoding manually when additional 
artistic free­ recording). If polygon based shading algorithms are used, image quality drops but capability 
and efficiency increase (especially if the algorithm is efficient). Another trade-off in an animation 
system is the means of displaying the data and recording the fi­nal sequence. Film offers higher quality 
(resolu­tion and contrast ratio) compared to video, but must be chemically processed before the results 
can be seen. Video however, has the advantage that it can be immediately seen as it is being re­ corded 
and the video tape can be reused. Also color is a natural component in a video system whereas it must 
be added through filters for the film process.  It is often said that standard TV display of com­puter 
pictures is of low resolution because one sees the jaggies. This assumption is quite mis­leading and 
one should make a distinction between the inherent resolution of TV and computer gener­ated pictures. 
For instance, if a color TV camera is recording a rotating 3-D color cube (a real­world object) and it 
is displayed on the monitor viewed at a distance 5 times the height of the screen, then there will be 
no apparent jaggies. On the other hand a computed animation sequence of a similar colored cube rotating 
on the monitor also viewed from the same distance will usually have jaggies. The visible surface algorithm 
must com­pute the 3-D position, intensity, hue and satura­tion for each point generating the scan lines 
to display the picture. Typicallythere is a certain percentage of error in these calculations and the 
computational time required to overcome these er­rors can be lengthy. What one must consider are the 
trade-offs. While high picture quality is im­portant and desirable,what does it mean in the context of 
moving images and the bandwidth limita­tions of an NTSC signal? Vision research suggests that less picture 
resolution is necessaryfor mov­ ing images than static images.  2.3 Other Systems  Based on the literature 
to date, there have been many computer graphics facilities which have imple­mented either a technique 
for generating 3-D ob­jects, an animation language, or a visible surface algorithm. Two examples would 
be the Universityof Utah which produced the Watkins Algorithm (31,33), and Archuleta's work at Lawrence 
Livemore Labora­ tory (2)where he implemented a fast version of the Watkins Algorithm on a CDC 7600. 
However, only a few facilities have attempted to integrate these fundamental capabilities into one 
complete system for the expressedpurpose of animation.  2.3.1 An experimental3-D animation systemwas 
de­veloped at the IBM Watson Research Center by Appel et al. (1). This system produced output to a high 
 resolution microfilm recorder in the form of hidden line or shaded objects. A special "movie specifi­cation 
language" was used to control motion, chang­ing viewpoints of perspective and a remote light source capable 
of casting shadows. Efficiency in the system was increased by sharing program tasks among an IBM 360/67, 
a 360/91, and a 1130. 3-D data was entered into the system either by inter­actively picking points with 
an IBM 2250 or by dom is required." 2.3.2 Case Western Reserve University has a com­ puter system which 
can generate shaded perspective pictures in real time. This "Shaded Graphic Sys­tem" was developed for 
Case by Evans and Sutherland Corporation at a cost $400,000. It consists of a graphics processor driving 
a pipe­line of special purpose hardware for matrix multi­plication and shading. Sharing memory with the 
graphics processor is a PDP-11 with a 10 megabyte disk and an assortment of I/O devices. 3-D data is 
processed on a scan line by scan line basis by a hardware implementation of Watkin's hidden sur­face 
algorithm and sent to a shader which uses the Gouraud shading technique (21). The resulting im­age is 
displayed on a raster scan CRT for real­time display. A camera unit with color filters under computer 
control is used to produce computer animated films. Jones (22) describes a high level programming lan­guage 
he implemented for the Case system. It con­sists of a complete implementation, for the PDP of Algol-60with 
the addition of string vari­ ables, I/O facilities, and extensions for handling graphic shaded images. 
The primary purpose of this work was to facilitate the use of a custom­built system which can produce 
shaded images in real time. According to Jones one important ad­vantage of Algol was its block structure 
which Jones decided would lend itself quite nicely to the description of graphical structures. The con­sequence 
of this approach is that just as Algol itself is a way of talking about algorithms, the graphic-extendedAlgol 
is a way of talking about graphical data structures. Currently, the system requires 3-D data to be en­tered 
through a dual data tablet arrangement which means the animator must provide detailed drawings from several 
viewpoints (something most animators with their "sketchy" storyboards don't have readi­ ly available). 
But besides this and the lack of color in the system, the combination of Jones' ex­tended Algol-60 language 
and the powerful graphic display processor presents a good example of a general purpose 3-D real-time 
animation system. Most of the film "Sphere Eversion" was calculated with this system. 2.3.3 Credit should 
be given to Goldstein (20), Nagel, et al. (13) and Elin (14) for their pio­neering work in the area of 
3-D shaded animation with the Magi-Synthavision system. The unique visible surface algorithm uses curved 
patched sur­faces, but its approach is fundamentally different from others. "Rays" are fired from some 
point in space and traced to the first visible point on a 3-D object. The advantage of this technique 
is that since the rays are stopped at the first sur­ face encountered,no time is spent examining the 
parts of the model which would be normally hidden. The system is capable of generating data with a sophisticated 
"combinatorial geometry" technique (thus preventing the decrease in data generation capability, typically 
associated with parametric surface algorithms). Here, "the user specifies the geometry by establishing 
two tables. The first table contains the type and location of the bodies used in the geometric description 
(there are nine 56 component in the calculations for the final basic shapes). The second describes 
the physical region in terms of the bodies in table 1 and the display output. three Boolean operators, 
'+', '-', and 'or'. Each region has a unique region number and the bodies o Displaying and directly recording 
in real time, are numbered in the order of their occurence. The the color video sequence that was calculated 
terms of its re-and stored (in binary) on the system disk by model is completely described in gion number." 
the animation language. The input to the system also includes "the loca­ tion and characteristics of 
a camera (focal length and size of image plane), the direction from which the light is coming and a set 
of instructions called "Director's Language," which tells the com­ puter how to treat the objects (animatethe 
ac­tors) in the film." The calculated visible surface output is stored on magnetic tape. Using this tape 
as input a second pass through the computer is made to convert the region-intensitydata into color-intensity. 
The film process (based on color addition) requires that the output tape be made with three weighted 
red, green and blue frames for every one frame from the input tape. The tapes, in this form, are fed 
through a Data General Minicomputerto a pre­ cision CRT. The images are filmed through a com­ puter controlled 
color wheel (triple exposure-­ once for red, green and blue). The Magi-Synthavisionsystem has taken 
an excel­ lent approach to 3-D shaded animation with the use of "Combinatorial Geometry" and a "Directors 
Lan­guage" to control their calculated visible surface output. Unfortunately the system suffers from 
a lack of interaction, because to use these powerful facilities the animator must keypunch in the com­ 
mands to control both the data generation and ani­mation process. Also, calculation time is slow, ranging 
from 30 seconds a frame for extremely sim­ ple data, up to around 20 minutes a frame (15). 3. Anima II 
The animation software system has been implemented in a standard minicomputer environment (Diagram 1) 
with a PDP as the central processing unit. The CPU has 64 K of core memory (32 K of which contains the 
RSX ll-D operating system) and 32 K of MOS memory. In addition, the peripherals in­ clude: a 4096 x 
4096 Vector General refresh CRT with joystick, buttons and dials; a 44 mega-word (16 bit), "3330 type" 
moving head disk used as the system disk; a special purpose color, raster-scan decoder which serves 
as our real-time video inter­ face. The software in the animation system was written in assembly language 
to increase efficien­ cy (Diagram 2). The system, Anima II, supports an environment in which a user trained 
in areas other than computer programming, is capable of: Creating complex color polyhedra with a real­ 
time interactive geometric "modeling" routine. Writing an animation script describing parallel, keyframe 
motion dynamics controlling multiple objects.  Animating the script using a specially written animation 
language processor in which the Myers visible surface algorithm is the kernal While each of these areas 
have noteworthytheoret­ical and implementational features in and of them­ selves, what is significant 
about the Anima II system is the integration of these separate, com­plex processes into a complete system, 
which is both easy to use and efficient. Currently the Anima II system is supporting anima­tion projects 
in the areas of education, telecom­munication and art as well as research projects for astronomy, statistics 
and computer-aided design. 3.1 Data Generation The objects in the animation sequence are created with 
Parent's (29) interactive data generation pro­gram. The user views and interacts with the ob­jects in 
real time on a random scan CRT. Concave polyhedra are joined and intersectedto form com­plex shapes. 
The object can be bent or warped into  ANIMA II SOFTWARE  multiple shapes for animating later. Transparent 
 to the user is the data structure of the objects which consists of closed polygons forming closed convex 
or concave surfaces. The user is only aware of positioning two objects in some relation to each other, 
pushing a button, and either joining the two together or cutting one into the other. The proc­ess is 
accumulativeand can be repeated as often as necessaryto build the final object. The color of the objects 
can be specifiedwhen the user chooses his primitive objects (a green ball can cut a green hollow in a 
red cube) or individual faces may be selected and "painted." The data generation routine uses 32 K of 
MOS memo­ry for instruction and data space and uses 20 K of core memory for a device handler which buffers 
the display lists and refreshes the Vector General. The routine can handle up to 2500 unique edges. A 
user accustomed to the "sculpting and building" ap­proach of the routine can make an object in a very 
short time. This can range from 5-15 minutes for a simple shape such as a block letter, 2-3 hours for 
the frog and duck in Figures 1-12, and up to five hours for complex data like the "Jack-in-the- Box" 
shown in the video tape accompanyingthis presentation. These times also include the bending and warping 
process to make multiple shapes for in­terpolation (blending)in the language. A detailed presentationof 
the intersectionalgorithm used in the data generationroutine is being given at this conference by its 
author. 3.2 Script Once the 3-D objects have been created,the user controls the rest of the animation 
process through his script. The script is a story-boarded anima­tion idea, transcribed into a list of 
instructions written in the special descriptive syntax of the language. The language of the Anima II 
system of­fers a means of imitatingthe complex motions of "real" world objects by breaking each motion 
into simple, but preciselycontrolled changes through space and time. Language instructions are indi­viduallyscheduled 
to be active over a range of time during the animation sequence. When the in­structionhas reached its 
time limit, it can be re­scheduled to be active later in the sequence, or it can be removed from further 
consideration. An in­struction specifies key frame time parameters and it also describes key frame spatial 
transform para­meters. However only the extreme parameter which the instruction is changing to need be 
given, be­cause the language keeps track of where each object currently is. This saves animators from 
having to keep records on their own of what they have done so far in the script. They specify where they 
want to go "to," and the language calculateswhat the vec­tor should be to get there. This applies whether 
the transform affects position, rotation, size, shape, or path. Using this format, a combination of 
a "set" and a "change" scene directive can com­pletely control one simple motion as in the exam­ple: 
 position of some object to the point specified by X, Y, Z on the first frame of the sequence (coor­dinate 
and frame values can be given as numbers or symbolic variables)." "At the same time, change the position 
from the point where it was set, to a new point given by different X, Y, Z values and be there by frame 
number 100." The ability to schedule the language instructions allows the user to animate multiple objects 
with­out being concernedwith looping or programmatic flow control. This notion of parallel commands is 
quite different from the typical approach found in other graphics languages in which the animation is 
controlled by guiding an internal program address counter or pointer, into, through and out of a se­ries 
of transformation control loops. The photographs in Figures 1 through 12 are sev­eral of the extreme 
positions taken from an anima­tion sequence involving a duck, a frog and the meeting of the two. The 
first four stills show the duck in a head-down, head-up position as it takes a drink of water. What the 
photos can't show is the duck wadling, wagging his tail, flap­ ping his beak, as well as changing his 
orientation (turning to one side then the other) and moving through space--all at the same time. The 
sched­ uled commands in the script can be given quite di­ rectly to control the transformations needed 
for this type of animation. The animator works on mo­ tions independently,component by component. In 
 the case of Figures 5 to 9, the animator created the frog and then intuitively "bent" the legs and 
 arms into the extreme shapes that make up jumping and swimming. Then, in the script, the animator 
decides what the timing will be to get the frog to change realisticallyfrom one shape to another. When 
this is settled, the animator may decide on when to turn the frog during the sequence. After that, 
how should the frog be moved to give the ef­ fect it is swimming. Here, acceleration and de­ celeration 
can be controlledby the animator to improve the quality of motion. The introduction of the duck, as 
seen in Figures 10 to 12 presents no difficulty to the user. Commands animating the duck and frog are 
given directly, in parallel and with no regard to mutual interference. When an animator is satisfiedwith 
the actions of the objects, he has the option of controllingthe whole scene. Commands are used similar 
to conven­ tional animation terms such as pan, tilt, zoom and field, which change the relationship of 
the ob­ server to the objects. Other features of the ani­ lighting-control in the form of independent 
posi­ mation language include color, brightness, fades, tion and rotation of multiple light sources 
and the ability to calculate a single frame or short animation segment within the script.  3.3 Animation 
Language When the objects have been made and the motion de­scribed, the animator need only evoke the 
language to calculate the final video sequence. The lan­guage processor, designed and implementedby Hackathorn 
(12), follows the user written script. It compiles an animation file which contains all the object and 
color parameters needed by the vis­ible surface routines next in the production proc­ess. If, for example, 
the script describes a sequence animating thirty multi-coloredblock let­ters and lasting for twenty 
seconds (600 frames), then the compiled animation file will look like a sequential list of six hundred 
dynamicallychanging data structures, each defining the spatial and dis­ play parameters of a collection 
of colored surfaces for one frame. The program tasks for the animation language is di­vided into four 
routines: preprocessor, scheduler, interpreter,and compiler.  3.3.1 Preprocessor The preprocessingroutines 
are concerned primarily with building the data structure, but also with the keyword parsing of the script 
syntax. This routine is controlled first by the prescene directives then by the scene directives of 
the user written script. The prescene directives instruct the preprocessor in the building of the data 
structure for the en­tire animation sequence. The data structure in­ cludes:  Face and vertice information 
describing the three-dimensionalpolygonal surface of each ob­ject in the sequence. The different possible 
shapes that any object can change into. Group pointers for each object. Sub-group pointers within each 
object (object parts). Multiple "floating" light sources.  Multiple, three-dimensionalpaths through 
space, sharable by all objects. A separate color for the inside and outside of every face for every 
object. The animation language currently can control up to 128 objects, groups of objects, or possible 
object shapes, however, the real limiting factor in the maximumcomplexity of the system is the 32 K ad­dress 
space of the PDP-11/45 CPU. The animation language uses 32 K of MOS memory and 32 K of core memory. This 
allows 20 K of object data space (4000 to 5000 unique edges) and elsewhere a 16 K section for buffering 
shape vertices and path ver­tices (about 5300 points at 3 words each). If there is room in memory for 
the data, the language can control 128 objects, 128 shapes, 64 groups, 32 paths and over 500 command 
instructions. The preprocessor routine parses, interprets, and executes each of the prescene directives 
until it  comes to a SCENE START directive in the script. For the remainder of the script the data structure 
is fixed, no new objects can be added, and the rou­ tine parses nothing, but scene directives. Each scene 
directive gets parsed and converted into a "command block," kept as part of a data list in  memory. 
A command block has all the parametric and key frame (schedule) information in it that was given in the 
directive line. It also contains pointers into the data structure, plus a workspace area big enough 
to hold the unique motion values which will change from frame to frame.  3.3.2 Scheduler The scheduler 
is the first of three routines which are evoked for each frame. The scheduling routine is event driven 
by the start of each new frame. Every frame it:  Sequences through each command block in the list, compiled 
by the parser. Judges whether the command block is flagged ac­tive or inactive after a comparison of 
the key frame informationin the command block and the current system frame counter.  Updates the motion 
parameters in the workspace area if the command is active this frame.  The scheduler routine works 
double duty by both scheduling the command blocks and updating the unique motion information that each 
block carries. It is at this state that the concepts of "set" and "change" become important. A "set" 
command block holds its initial parameters through its time range within the animation process. However, 
a "change" block has a direction initially calculated as spe­ cified by the animator with a "change 
to" direc­tive. From the first frame of activity,the direc­tion (an increment in X, Y,' and Z) of the 
"change" block will be added to the block's own internal workspace memory. These incrementing(positive 
or negative) parameters get interpretedand executed as if they belonged to a "set" commandblock. This 
 information is used, with no further modifications, by the interpreterroutines in doing the actual transformations 
to the data structure.  Interpreter After the command blocks have been scheduled for the current frame, 
the interpreter finds each ac­tive command,determines the parameter type (rota­tion, position, size, 
color, shape, path, etc.), and performs the necessarymotion or display trans­ formations to the data 
structures. The key to the interpreter is that for each new frame, all command blocks scheduled active 
will start their transfor­mation on the original data. In this manner, both the order of the commands 
and the range of their schedule determines what transformationswill be done to the data on any given 
frame.  3.3.4 Compiler The compiler routine compiles a data file as op­posed to executable code. The 
routine calculates the color of each face, does perspectivetransfor­ mations, clips all faces not seen 
by the observer and builds an animation file containing a complete scene descriptionof every frame in 
the script. The color of a face is a product of the relation­ship between the current positions of the 
light sources and the plane of the face. The system has three light sources which it keeps as X, Y, 
Z points in space and allows them to be translated and rotated just like objects. The distance each 
of the light sources is from the face, decides a weighted brightness. From this relationship a value 
between 1 and 224 is determined. This value corresponds to a color palette made up of 224 en­tries, each 
entry describing a fifteen bit red,  green, blue hue combination. The color palette is logically organized 
into eight intensity-chroma sections with 28 entries (the first entry is the darkest color and the last 
entry is the brightest). When the object is created in the data generation stage, it is "colored" by 
assigning one of the eight intensity-chroma sections to each face. With the information supplied by 
the light source calcu­ lations the final offset into the color palette is produced. The scene has 
a user-specified observer position. Every object has its own "pictureplane." With this information,the 
compiler routine calculates perspective. Each frame, the vertices after being transformedby the interpreter 
are projected onto a picture plane. The 'Z' axis coordinates are un­ affected by the perspective so 
that depth compari­ sons may be done later by the objects in memory as one object. It checks which faces 
can still be seen and appends the animation file with:  The faces in the object that are displayable. 
The colors of the displayable faces. The transformedvertices for the current frame. Miscellaneous displayparameters 
i.e., z-clip­ ping plane position, and background color. When the last frame of the script has been 
com­ piled, what is left is a data file on the system disk ready to be turned into the final color video 
 sequence by the visible surface algorithm and a raster-scan conversionroutine. Up to this point the 
calculation time has been relatively short. The only major calculations in the language are the dot products 
and face normals needed for the light source equations. As a result, the language typi­cally calculates 
a 300 frame (10 second) sequence in under 5 minutes. Through the script the animator may request that 
the animation file on the disk be played back (in real-time) to the Vector General. Since the transformations 
of the objects are already com­ pletely defined for every frame in the sequence, the V.G. playback routine 
has no computationre­quirements. This makes for an excellent way of previewing the animation sequence 
to get an idea about the motions, but of course no color or lighting information can be displayed. If 
V.G. output is not specifiedin the script, the lan­ guage automaticallyevokes the visible surface. 
 3.4 Visible Surface Algorithm The visible surface routine of the Anima II system is a version of the 
Myers Algorithm. Full imple­mentation details of the original algorithm may be found (24), but for completeness, 
a brief descrip­tion of the algorithm, as it affects the animation process will be discussed. The program 
uses 32 K of MOS memory, containing a data space of 20 K. At the beginning of each new sequence, the 
program reads a list of faces from the animation file left by the language. Here we note that the language 
has described all the ob­jects in the animation sequence to appear as one to the visible surface routine, 
also that all polygons createdwith the data generationroutines have been reduced to triangles. For 
each frame and starting with the first, the procedure is as follows. The face's information is read in. 
This contains faces clipped out of view, backfaces removed optionallyby the animator, and color for each 
displayed face. Next the list of unique vertice is read in as well as miscella­neous information such 
as background color. The program checks each face against the face file for this frame and if it is 
to be displayed (not clipped or "back faces" removed) the face is added to a list of faces whose highest 
'Y' value is iden­ tical to that of the current face. When all faces have been checked for displayability,the 
algorithm begins producing the visible surface output. As is typical of linear to raster conversion 
and visible surface algorithms, a scan line at a time is proc­ essed. Starting at the highest of the 
512 scan lines, lines are processed one line at a time until all lines are processed. Each line is 
processed as follows. If the line contains no active faces (i.e., no face starts, crosses or ends on 
the line) it is ignored. If the list of faces starting on the line is not null then all of the faces 
on the list undergo a format conversion and are added to a list of active faces. If the list of active 
 faces is not null then each face on the list is processed, one face at a time, in whatever order the 
faces on the list are in, until each active face has been processed. Processing a face means processinga 
segment of a face, since one scan line at a time is processed. Thus the list of active faces can be 
thought of as a list of segments to process on a scan line. The first segment of the list is scanned 
(i.e., con­verted to points). The 'Z' (distance from the ob­server) and intensity values for each point 
are stored in the appropriate places in the ZVSLS (Z values scan line structure) and IVSLS (intensity 
values scan line structure) respectively. Both the ZVSLS and IVSLS consist of 512 locations, each lo­cation 
of which corresponds to a horizontalposi­tion on the output raster. At each horizontal po­sition the 
'Z'value of the new point is compared with the 'Z'value of the point in the ZVSLS. If the new 'Z' is 
closer to the observer then both the ZVSLS and IVSLS values at the current horizontal position are updated 
with the values from the new segment. If the new 'Z' is farther or equal then no updating occurs. After 
processinga segment the corresponding active face is updated for the next scan line. If the lowest point 
of the face has been passed then the face is removed from the list of active faces. After processing 
all faces on the list of active faces for a scan line the scan line is converted into run length encoded 
binary data and stored a scan line at a time on the system disk. Given a typical animation sequence 
which contains polyhedra of around 1000 edges and covering an area of about one quarter of our TV monitor, 
the visible surface and raster scan conversion calcula­tion of a 300 frame (10 seconds) sequence takes 
be­tween 5 to 10 minutes. If the complexity doubles, but the area remains the same then the same se­quence 
will take 7 to 12 minutes. However, if the area doubles and the complexity remains the same, the sequence 
will take 10 to 20 minutes.  3.5 Display and Record Currentlywe are using a standard broadcast televi­ 
sion as the viewing mechanism,a large capacity di­gital disk for image storage and broadcast video for 
the raster-scan format image representation. The broadcast video is not stored in compositeNTSC format, 
but rather is stored as run-lengths of par­ticular intensity-chromacombinationswhich are converted (in 
real-time) to compositeNTSC format for display. The use of run-length encoding is our response to the 
insufficiency of current computer technology to easily handle the large quantities of information implied 
by raster-format representation of dynamic images. For example, a raster-format dynamic image of 512 
by 512 resolution, 8 bits per resolvable element information content, 30 frames per second display rate 
and 30 seconds duration re­quires over 235 million bytes of storage. The im­plied data transfer rate 
(8 million bytes per sec­ ond) is prohibitivewithin our general purpose design strategy. This is due 
to the fact that although disks of over 200 million byte capacity are available, the transfer rate available 
is less than 2 million bytes per second. The run-length decoding and analog systems were constructed 
by Dr. John Staudhammer and his asso­ ciates (DIGITEC,Inc.; Box 5486; Raleigh, N. C. 27607). The analog 
system and rearend of the run­length decoding system are similar to an earlier system built under Staudhammer's 
direction. The decoding system converts our run-length format to that used in Staudhammer's earlier system. 
(30) A dynamic sequence is transferred from the disk to the TV according to the following scheme. A 32 
KB run-length buffer is divided into two 16 KB buffers for double buffering. A buffer is filled from 
the disk. While this buffer is being filled, informa­ tion to/from the disk controller from/to the CPU 
must be multiplexed with the data from the disk.  This multiplexing is automaticallyhandled by the UNIBUS 
priority arbitration unit. Fortunately, the quantity of control informationnecessary to run the disk 
is a small percentage of the quantityof  data being transferred. Also fortunate is the fact that the 
dual ported MOS main memory permits the instructions and associated data of the control program to 
be fetched simultaneouslywith the data being stored from the disk. Thus, there are vir­tually no memory 
cycles lost directly to the con­ trol program.  Information flowing into the run-length decoding system 
is buffered in an internal 32 KB MOS buffer before it is decoded. This is the reason that in­formation 
may be transferred from the MOS main mem­ory buffer into the decoding system with no concern for field 
or frame boundaries. More explicitly, since field and frame boundary informationis con­tained in the 
data, putting off decoding the data until after information transfer permits the data to be treated as 
a uniform stream. The calculations below are intended to give a quan­ titative indication of the capabilities 
of the sys­ tem. It should be noted that in order to provide the clearest calculations, minor overheads 
such as start of field instructions are ignored. The following calculations assume an average of one 
byte per run. This case is approachedfor images with (typically) fewer than 33 intensity-chroma combinationswithin 
a scan line and fewer than 25 within a field. The disk specifications are those of the manufacturer. 
Since the RJPO4 disk system is (relatively)the slowest part of the system, it determines the maximum 
performance level. For con­tiguously stored files (as video files have to be in this system) the disk 
can be read continuously at maximum possible speed with the exception that some time (7 milliseconds) 
is lost when changing cylinders. Since there are 19 tracks per cylinder and the disk requires 16.7 
milliseconds for one revolution,one cylinder can be ready every 317 milliseconds. Since 214,016 bytes 
are stored per cylinder, the average data transfer rate is 675 bytes per millisecond. Allowing 10 milliseconds 
for change of cylinder, 207,266 (214,016 minus 6,750) bytes can be obtained for every cylinder read. 
Note that the storage space "passed over" for change of cylinder is best wasted as an extra revolutionwould 
be required to retrieve it. Thus, the average data transfer rate is 654 (207,266di­vided by 317) bytes 
per millisecond. Since each TV frame lasts about 33 milliseconds,this is 21,582 bytes per frame. At one 
byte per run, this is 21,582 runs per frame. Since the disk has 411 cy­linders and the system is retrieving 
207,266 bytes per cylinder, there are 85,186,362 retrievable bytes. At a maximum of 21,582 runs per frame, 
this represents 3,947 frames. Since the data is contig­uous, any reduction in runs per frame directly 
translates into more frames. Thus, at 2,158 runs per frame there are 39,470 frames. (25) 4. Conclusion 
 The development of computer generated 'solid' ob­ject animation is changing the way an animator ap­proaches 
the documentation of an idea. Convention­al animation involves drawing and redrawing planar images on 
each frame throughout the entire se­quence. Image creation and image animation are very often the same 
process. But in a 3-D computer animation environment,the user first builds a col­ored object then animates 
it and these processes are separate. The approach of 3-D color animation is similar to that found in 
other disciplines such as Cinematography,Theatre and Choreography. Here actors or dancers are chosen 
and given their roles by a director who is responsible for the whole show. The approach is closer still 
to that of pup­pet animation in which the work if Jiri Trinka, Willis O'Brien (King Kong) and Jim Hensen 
with his Muppets serves as excellent examples. The implementationof such an animation system re­ quires 
balancing system requirements against the available resources, while at the same time keeping some 
notion of efficiencyin mind. Anima II, has been developed and implemented as one solution to the production 
of 3-D color animation. Each of the subsystems in Anima II have been especially design­ ed to both interact 
freely with a user and inte­ grate transparentlyinto a unified system. While sitting at one work station, 
a user of Anima II can create, animate and display 3-D colored objects, then directly record the animation 
onto standard video cassette tape. The system has limitations in  the areas of data complexity: 5000 
unique edges ACKNOWLEDGEMENTS per scene; and data transfer: limited mainly by the system disk which can 
transfer about 20,000 The Anima II system was designed and implemented bytes (1-3bytes per run-length) 
each video frame. by the Computer Graphics Research Group at The Currentlymethods are being explored 
to improve Ohio State University. Work on the project was these areas and the areas of image quality 
and to-performed by Charles Csuri (Director), Allan Myers, tal system throughput. Richard Parent, Timothy 
VanHook, Diana Rainwater, and the author. Funding for this project was pro­vided by NSF Grant DCR 74-00768. 
 REFERENCES 1. Appel, A., Stein, A., Landstein, J. (1970). The Interactive Design of Three-Dimensional 
Animation,Proceedings of the Ninth Annual UAIDE Meeting.  2. Archuleta, Personal Communication with 
CGRG.  3. Baecker, R. M. (1969). Interactive Computer MediatedAnimation. Dissertation,Massa­chusetts 
Institute of Technology.  4. Baumgart, B. G. (1974). Geometric Modeling for Computer Vision. Dissertation, 
Stan­ford University. NTIS Report Number AD/A­002261.  5. Belady, L. (1970). TV Plus Computer Equals 
Videographics. Proceedings of the Ninth Annual UAIDE Meeting.  6. Blasgen, M. W., Gracer, F. (1970). 
KARMA: A System for Storyboard Animation. Proceed­ings of the Ninth Annual UAIDE Meeting.  7. Blinn, 
J. F., Newell, M. E. (1976). Texture and Reflection in Computer Generated Im­ages. Communications of 
the ACM, Vol. 19, No. 10.  8. Braid, I. C. (1975). The Synthesis of Solids Bounded by Many Faces. Communications 
of the ACM, Vol. 18, No. 4.  9. Catmull, E. (1974). A Subdivision Algorithm for Computer Display of 
Curved Surfaces. Tech. Report UTEC-CSC-74-133,University of Utah.  10. Clark, J. (1976). HierarchicalGeometric 
Mod­els for Visible Surface Algorithms. Com­munications of the ACM, Vol. 19, No. 10.  11. Csuri, Charles 
(1975). Computer Animation, Proceedings of the Second Annual Conference on Computer Graphics and Interactive 
Tech- niques--SIGGRAPH '75.  12. Csuri, Charles A. (1977). 3-D Computer Ani­mation. Advances in Computers. 
Academic Press, Inc., New York.  13. Davis, J. R. (1968). A Model Making and Dis­play Technique for 
3-D Pictures, Pro­ceedings of the Seventh Annual UAIDE Meet­ing.  14. Elin, L. (1975). Synthevision: 
Serendipity from the Nuclear Age, Artist and Computer, edited by R. Leavitt, HarmonyPress.  63  15. 
Elin, L. (1977). Presented at National Con­ference and Workshopon Electronic Music and Art, University 
of Buffalo, Suny.  16. Film -"WalkingMan," Universityof Utah.  17. Film -"NASA Space Shuttle" General 
Electric.  18. Film -"Sphere Eversion" N. Max.  19. Gattis, W., Watson, (1971). An Input Transla­tor 
for Animation and Its Relationship to Key Position Character Animation. Proceed­ings of the Tenth Annual 
UAIDE Meeting.  20. Goldstein, R. (1971). A System for Computer Animationof 3-D Objects, Proceedings 
of the Tenth Annual UAIDE Meeting.  21. Gouraud, H. (1971). Computer Display of Curved Surfaces. IEEE 
Transaction on Computers.  22. Jones, B. (1976). An Extended ALGOL-60 for Shaded Computer Graphics. 
Proceedings ACM Symposium on Graphics Languages.  23. Lafue, G. (1975). Computer Recognition of 3- 
 Dimensional Objects from Orthogonal Views. Research Report No. 56, Institute of Phys­ical Planning, 
Carnegie-MellonUniversity.  24. Myers, A. J. (1975). An Efficient Visible Surface Program. Technical 
Report to the National Science Foundation,Grant Number DCR 74-00768AO1.  25. Myers, A. J. (1976). A 
Digital Video Infor­mation Storage and Retrieval System. Pro­ceedings of the Third Annual Conference 
on Computer Graphics and Interactive Tech-  26. Max, N., (1975). Computer Animation of the "Sphere 
Eversion," Proceedings of the Sec­ond Annual Conference on Computer Graphics --SIGGRAPH.  27. Negroponte,N. 
(1973). Recent Advances in Sketch Recognition. Proceedings of the National Computer Conference.  28. 
Newell, M. (1975). The Utilization of Proce­dure Models in Digital Image Synthesis, Ph.D. Dissertation,Universityof 
Utah.  29. Parent, R. E., Chandrasekaran,B. (1976).  Moulding Computer Clay. Pattern Recogni­tion 
and Artificial Intelligence. (C. H. Chen, Ed.) Academic Press, Inc., New York. 30. Staudhammer, J., 
Eastman, J. F. (1975). Com­ puter Display on Colored Three-Dimensional Object Images. Proceedings of 
the Second Annual Symposium on Computer Architecture, pp. 23-27. 31. Sutherland, I. E., Sproull, R. 
F., Schumacker, R. A. "A Characterizationof Ten Hidden- Surface Algorithms," ACM Computing Surveys, 
Vol. 6, No. 1, pp. 1-55, 1974. 32. Sutherland, I. E. (1974). Three-Dimensional Data Input by Tablet. 
Proceedings of the IEEE. Vol. 62, No. 4, pp. 453-462. 33. Watkins, G. S. (1970). A Real-TimeVisible Surface 
Algorithm. University of Utah Technical Report UTEC-CSC-70-101.  34. Wein,M., Burtnyk,N. (1971). A Computer 
Ani­mation System for the Animator. Proceed­ings of the Tenth Annual UAIDE Meeting.  35. Wein, M., Burtynk,N. 
(1975). Computer Anima­  tion of Free Form Images. Proceedings of the Second Annual Conference on Computer 
 Graphics and Interactive Techniques-- SIGGRAPH '75. 36. Whitney,John, Citron, J. (1968). Camp-Com­puter 
Assisted Movie Production,Proceed­ ings of the AFIPS Fall Joint Computer Conference.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563871</article_id>
		<sort_key>65</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[A color animation system]]></title>
		<subtitle><![CDATA[based on the multiplane technique]]></subtitle>
		<page_from>65</page_from>
		<page_to>71</page_to>
		<doi_number>10.1145/563858.563871</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563871</url>
		<abstract>
			<par><![CDATA[This paper describes an animation package currently under development at the Cornell Program of Computer Graphics.The basic algorithm employed is linear or non-linear interpolation between successive pairs of key frames. These key frames are composed of artwork input by the animator on a graphic tablet and displayed on either a black and white vector scope or a color halftone CRT. The initial working environment is two-dimensional, and the individual images are combined using a multiplane cel animation technique to produce depth and motion illusions. Real-time film previewing, utilizing an on-the-fly interpolation algorithm, provides the artist with instant playback of animated sequences.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[interactive computer graphics]]></kw>
			<kw><![CDATA[key-frame animation]]></kw>
			<kw><![CDATA[multiplane animation]]></kw>
			<kw><![CDATA[real-time animation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15037068</person_id>
				<author_profile_id><![CDATA[81100593780]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Marc]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Levoy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Catmull, Edward, (Personal conference at New York Institute of Technology), New York, (1976).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Defanti, Thomas, "The Graphics Symbiosis System", Real-Time Film Animation, annual report to the NSF, submitted by the Computer Graphics Research Group at Ohio State University, (1973), pp. 5-116.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Finch, Christopher, The Art of Walt Disney, Walt Disney Productions, (1975).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Gracer and Blasgen, "Karma: A System for Storyboard Animation", UAIDE, (1970), pp.210-224.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563875</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Greenberg, Donald P., "An Interdisciplinary Laboratory for Graphics Research and Applications", Proceedings of the Fourth Annual Conference on Computer Graphics, Interactive Techniques, and Image Processing (July, 1977).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Shoup, Richard, (Presentation of the SHAZAM animation system at the Third Annual SIGGRAPH Conference), Phila. Pa., (1976).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360357</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Wein, Marceli, "Interactive Skeleton Techniques for Enhanced Motion Dynamics in Key-Frame Animation", Communications of the ACM, Oct. 1976).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Wein, Marceli, and Lestor Burtnyk, "Computer Generated Key-frame Animation", Journal SMPTE, (March 1971), pp. 149-153.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.Siggraph 
77, July 20-22 San Jose, California A COLOR ANIMATION SYSTEM BASED ON THE MULTIPLANETECHNIQUE Marc 
Levoy Program of Computer Graphics Cornell University Abstract This paper describes an animation package 
currently under development at the Cornell Program of Computer Graphics. The basic algorithm employed 
is linear or non-linear interpolation between successive pairs of key frames. These key frames are composed 
of artwork input by the animator on a graphic tablet and displayed on either a black and white vector 
scope or a color halftone CRT. The initial working environment is two­dimensional, and the individual 
images are combined using a multiplane cel animation technique to produce depth and motion illusions. 
Real-time film previewing, utilizing an on-the-fly interpolation algorithm, provides the artist with 
instant playback of animated sequences. KEYWORDS: Key-frame Animation, Real-time Animation, Multiplane 
Animation, Interactive Computer Graphics COMPUTING REVIEWS CLASSIFICATION: 3.41, 8.2 I. Introduction 
 The last five years have seen the development of several sophisticated computer animation sys­tems. 
To review a fairly well established taxono­my, two general categories can be identified: language-drivensystems 
and picture-drivensystems. Each type offers certain advantages to the artist, although each contains 
certain inevitable draw­backs. These may be summarized briefly as fol­lows: Language-drivensystems: 
 Beginning with Kenneth Knowlton's pioneer pixellation films of the early sixties and con­tinuing up 
through the current research of the Ohio State University Group (2) and others, all language driven animators 
have in common a de­sire to achieve maximum flexibility in their animation environment through the provision 
of a wide repertoire of picture manipulation com­mands. By allowing the artist to specify any two-dimensionalor 
three-dimensional transfor­mation upon geometries in the working data space, these systems provide considerable 
free­dom for the\developmentof artistic scenarios. There are, however, distinct difficulties in this 
approach. First the generation of three­dimensional objects with sufficient ease and of adequate complexity 
to serve as artistic ele­ments in computer animation is a problem of con­siderable complexity in itself. 
Second, since the working environment of these animation sys­tems is manipulated and distorted according 
to commands entered on a computer terminal, the artist must acquire at least some familiarity with language 
syntax. Picture-driven,key-frame animation systems: In systems of this class the animator pre­pares 
selected images at key intervals in the sequence and sketches them on a graphic tablet. Interaction 
between the artist and his animation is purely pictorial, and picture generation pro­ ceeds from these 
key drawings instead of from programmed commands. By subdividing each sketch into discrete strokes, 
and from there into a large number of closely spaced points, the computer can be programmed to generate 
frames intermediate to the key drawings using a simple linear interpola­ tion algorithm. Several existing 
animation systems are based on this approach, including those developed by Wein (8) and Catmull (1). 
There are, however, major problems with key-frame animation. First, there must be a one-to-one correspondence 
of strokes between the two terminal sketches in a transformation. While this scheme provides a simple 
means for controlling the overall transfor­mation, certain classes of actions become ex­tremely difficult 
to achieve, such as large rota­tions of objects. Second, linear interpolation between two substantially 
disparate drawings in­variably results in the "collapsing phenomenon", wherein the lines of the drawing 
appear to dis­integrate and mingle chaotically during the course of the transformation. Wein has provided 
several excellent suggestions for alleviating these arti­facts of key-frame interpolation (7). A third 
impediment relates to the organization of timings in the key-frame method. By adopting an algorithm for 
animation wherein each transformationis planned separately, the problem of maintaining smooth transitions 
becomes critical. In most of the work produced to date the tempo of the key frames is highly apparent,and 
since continuity is essential, the key-frame method presents a defin­ite constraint in this area. Finally, 
a limita­tion is imposed by forcing the artist to inhabit an essentially two-dimensional world. While 
it is a simple matter of draftsmanship to produce a sta­tic image which successfully portrays depth, 
it is entirely a different problem to produce key-frame interpolations of objects that retain true per­spective 
throughout the transformation. This work has been partially sponsored by the National Science Foundation 
under grant humber DCR74-14694 entitled "Development of Computer Graphics Techniques &#38;Applications." 
 The Cornell Program of Computer Graphics is currently developing an animation system for even­tual use 
in a production studio environment. The system is basically designed on the key-frame model of computer 
animation, for which excellent descriptions can be found in (4) and (8). It also provides three-dimensional 
capabilities,. but, in order to prevent these additional degrees of free­dom from becoming too unwieldy, 
they are dispensed only in a carefully controlled manner, as des­cribed in the next section. II. THE 
CONCEPT OF MULTIPLANE ANIMATION In the animated cartoons of the 1920's, the backgrounds were designed 
strictly as static, two­dimensional backdrops. They lent a sense of place and scale to the animated characters 
in the fore­ground cel, but rarely dealt with the space be­tween these figures and their horizon. When 
Walt Disney began work in 1936 on his first feature-length film, Snow White, it became necessary to depict 
settings wherein the charac­ters were separated by vast distances from their backdrops. Carefully constructed 
perspectives could provide an impression of depth as long as the observer's viewpoint was static, but 
a very difficult problem arose when the script called for a zoom or a panoramic sweep. In order to simulate 
a movement of the imaginary observer to­ward a character in the foreground, the figure should enlarge 
in the field of view. This can be accomplished simply by bringing the camera closer to the animation 
platten. The background scene also increases in apparent size during the zoom, but at a much slower rate 
due to its greater dis­tance from the observer. If the background cel were kept flush with the foreground 
figure as it had always been in traditional animation, it would enlarge as rapidly as the foreground 
and the illusion of depth would be lost. This problem was solved by Disney with the aid of an awesome 
machine called a multiplane camera, shown in Figure la. Each layer of ani­mation is situated at a different 
distance from the camera and illuminated independently. Thus, to achieve a realistic zoom, each cel layer 
is moved toward the camera at a speed inversely pro­portional to its distance from the imaginary ob­server. 
The differential ratios in these rates determine the apparent position of each drawing plane in depth. 
This was and still is one of the cleverest devices ever to be used in animation. Unfortunately, each 
cel layer required several technicians to operate it, and for this reason it has been used sparingly 
since the first fea­ture films. Nevertheless, it represents an ex­cellent algorithm for generating animated 
se­quences of correct perspective and realistic three-dimensional motion from a set of essen­tially two-dimensional 
drawings (3). III. THE CORNELL ANIMATION SYSTEM 1. General organization: Figure 2 illustrates the layout 
of the anima­ tion package. It has been developed as a dual­display system, alternating between a black 
and white vector scope and a color halftone CRT. Figure 2: Schematic organization of the Cornell animation 
system, showing the interface between the vector and color graphic systems. For a com­plete description 
of the equipment configuration of the Cornell laboratory, refer to (5), also in this issue. Figure la: 
The multiplane camera stand used by Walt Disney in his productions of the 1930's.  Input of the artwork 
can be initiated from either device, depending upon the graphic medium selected by the artist. This process 
is entirely pictorial, and the primary input means is a gra­phic tablet and pen. The data then passes 
to the multiplane man­ipulation routines. Here, the sketches and paint­ings are combined into a multiplane 
animation environment analogous in concept to that used by Walt Disney. This segment of the animation 
pack­age operates exclusively on the vector display, since that device offers the best real-time capabilities. 
 At this stage, the data consists of a series of key frames specifying the exact state of the animation 
at selected intervals in the sequence. The final step is for the computer to perform the mathematical 
interpolation between these key frames, and to display the resulting sequence on one of the output devices. 
Two means for preview­ing are available to the artist, real-time black &#38;white playback or stop-frame 
color playback. The restriction of real-time playback to the vec­tor scope is due entirely to the limitations 
of available technology. After examining the anima­tion, the artist then has the option to refine either 
his artwork or the multiplane setup and then repeat the procedure. When the previewing finally yields 
satisfactory results, production filming may begin. For this purpose, each com­posite image is displayed 
one frame at a time on the color CRT and filmed using a permanently mounted 16mm camera. This process, 
although slow, is performed automaticallyby the computer and requires no user intervention. In the following 
sections, each of the three basic steps outlined above will be explained in detail, and examples will 
be provided for each stage of the process. 2. Building the two-dimensionalplanes: Each plane in the 
multiplane environment con­tains one animation sequence developed by the ar­tist. Several different animation 
techniques are provided, but all of them generate a continuum of two-dimensionalimages for that plane. 
 a) Key-frame interpolation of line drawings with linear output (Figure 3a)  The procedure for developing 
a key-frame sequence from line drawings is well known and has been des­cribed elsewhere (8). The final 
product of this method is a sequence of frames containing vector approximations of interpolated curves. 
This may be displayed on either a vector scope or a raster CRT. b) Key-frame interpolation of line drawings 
with color output (Figure 3b).  Utilizing a simple area-filling algorithm, conti­guous areas enclosed 
by the original line drawing can be flooded with colors from a "palette" and displayed on a color raster 
CRT, yielding an image similar in appearance to a traditionally opaqued animation cel. If a set of "seeds" 
to drive the area-filler is interpolatedalong with the profile lines, intermediate frames can be automatically 
generated with full color opaquing. When these frames are later superimposedover other sequences in the 
multiplane environment, multiple-cel opaqu­ing is effected. c) Static color backdrop (Figure 4a)  The 
rear planes in Disney's multiplane animations contained highly elaborate backgrounds, far too complicated 
to be viably animated. Many of them were oil paintings on glass plates, a nearly in­ credible combination 
of materials to handle, but one which allowed great variation in texture and tonal delicacy. As part 
of the Cornell animation system, a painting program has been developed in which the artist works with 
computer-generated analogies of traditional drawing implements, such as pens, brushes and washes. (This 
program is similar in design to the SHAZAM system of Xerox and its descendants in other graphics laboratories 
 (1) (6). Using this program, full color backdrops of considerable complexity can be achieved. d) Color-palette 
interpolation of static backdrops (Figures 5a &#38; 5b)  Although the complexity of painted backgrounds 
prohibits geometrical animation, there exists equally interesting possibilities in the interpo­lation 
of the color palette. For example, sup­pose that the artist colors a renderingof an imaginary temple 
in its nighttime array of blues and deep purples. Then, without repainting the basic figure, a sequence 
of palettes can be speci­ fied that depict the play of light and color in the hall as the sun rises. 
These palettes can finally be used by the computer as key frames from which an entire animated sequence 
of subtle chro­matic shifts can be produced. e) Back-projectionof three-dimensional simulation(Figures 
6a &#38; 6b)  Constrainingthe artist to inhabit an exclusively three-dimensional world has definite 
drawbacks. There are, however, instances in which three­dimensional simulation promises to yield the 
best backgrounds for a particular scenario. Archi­tectural settings exemplify stagesets that would not 
alter in shape, yet might be viewed from a variety of different angles during the course of an animation. 
The Cornell animation system pro­vides these three-dimensionalsimulation capabil­ities, although only 
in the following carefully structured manner. Attaining the correct arrange­ment of two-dimensionalanimation 
planes within a three-dimensionalstageset is analogous to the problem of combining animation and live-action 
filming in one sequence. Unless the spatial arrangementsare executed flawlessly, one of the media will 
"go flat", or seem to lose its perspec­tive depth. Figure 6a illustrates this difficulty. The simultaneous 
juggling of the two image types with respect to perspective alignment would be ex­tremely cumbersome 
to handle in this setup. One solution to this problem, and the one adopted for the Cornell animation 
system, is to separate the two media, compose one independently, then super­impose the other at a later 
stage. Specifically, the three-dimensionalsimulation is worked out  Figure 3a: Key-frame interpolation 
of line drawing -vector output  Figure 4a: Static color background displayed on color screen.   Figure 
5b: Combination of two-dimensional and three-dimensional animation, in morning colors. 68 Figure 6a: 
Direct combination of 3d and 2d animation Figure 6b: Back projected combination of 3d and 2d animation. 
 first, complete with camera angles and motion dy­namics. Then the resulting sequence is back-pro­jected 
as a continuum of two-dimensional images on the background plane of the multiplane environ­ment, as diagrammed 
in Figure 6b. Finally, the artist proceeds to develop his two-dimensional animation as a superimposition 
over the simulation sequence. In much the same way that traditional animation was executed to match a 
pre-recorded sound track, the multiplane animation in this ex­ample would be altered and refined to overlay 
a previously established background sequence. us­ing this. method, correct perspective and align­ment 
between the two media are virtually assured. The fountain and temple in Figures 5a &#38; 5b were combined 
in this manner, with the temple input as a two-dimensional painting and the fountain as a three-dimensional 
simulation. 3. Constructing the multiplane animation: Figure lb illustrates the geometrical struc­ture 
of the Cornell animator (compare to Figure la). The imaginary observer in this system de­fines a three-dimensional 
cone or frustrum of vision which is transpierced at carefully de­fined intervals with data planes. The 
two­dimensional raw animation sequences of the artist reside on these planes. By manipulating the object 
planes and obser­ver's position, the artist can choose the best views and sequences to tell his story. 
As Figures 7a &#38; 7b illustrate, the multiplane effects are achieved by translating the observer's 
position in any of the three directions or by tilting the line of sight in any of the three degrees of 
ro­tational freedom. In addition, translations, ro­tations and scaling functions may be specified for 
each plane in the environment for the possi­bility of interrelational movements among the cels of the 
composite. For the previous stages, some of the tech­niques described utilize a vector-drawing display 
while others depend on color raster graphics. For the next stage in the process however, all work must 
be representable on the vector scope. To provide this capability, an edge-finding algor­ithm can be utilized 
to generate a coarse vector approximation of those drawings created originally for the color display. 
This vector simulcrum, an example of which is shown in Figure 4b, contains substantially less information 
about detail and texture than its color genesis, but it is adequate for the task of arranging the planes 
in space and specifying the sequence dynamics. Interaction between the artist and the compu­ter is entirely 
pictorial, requiring no knowledge of programming or language syntax. Motion feed­back is immediate, in 
real-time and at full resol­ution, utilizing the fast vector drawing system. Throughout this process, 
the locations of the planes and observer are being constantly tracked, so that acceptable sequences can 
be replayed auto­matically and included in the final animation. Figure 7b: Manipulating the object planes 
in the multiplane editor. 4. Real-time previewing: The key to producing this fast continuous anima- 
One important feature in any animation system is the ability to preview animation sequences at cine projection 
speed (24 frames per second), or at least at standard animation speed (12 frames per second). In the 
Cornell system, real-time playback is achieved using the fast vector draw­ing display. For this purpose, 
the vector approx­imations of all color drawing is utilized. A hardware matrix processor is capable 
of handling in real-time whatever translationsand rotations may be specified for each plane in the environment. 
Unfortunately, however, the linear interpolations utilized in the key-frame sequences require substantial 
processing time since the cal­culations must be applied in software to each of the thousands of points 
in each sketch. These massive computations presently make real-time playback extremely difficult to achieve. 
 The possible programming strategies for achieving real-time playback of interpolatedse­quences fall 
into one of two categories:  1) Pre-calculated interpolation, in which the geometry of each intermediate 
frame is computed before the previewing begins and deposited on a large capacity, high speed mass storage 
device for subsequent playback. 2) On-the-fly interpolation, in which the geometry of each intermediate 
frame is computed by the host computer just prior to its display on the screen. The inherent disadvantages 
of pre-calculating the in-between frames and storing them on the disk are fairly evident. First, it incurs 
waiting time between the input and playback phases of the pro­cess. Second, it places an absolute limit 
on the number of frames that may be previewed at once, depending upon the particular storage medium. 
Third, any subsequent modifications to the anima­tion require that the entire sequence be recompu­ted 
before it may be previewed again. By using an intelligent graphics processor that is substantially independent 
from its host computer, sufficient computing power remains in the CPU to implement an on-the-fly interpolation 
scheme. Furthermore, utilizing algorithm and code optimization techniques, the computations necessary 
to perform simple linear interpolation can be diminished significantly from the basic formula. Three 
processes are actually involved in producing the continuous animation on the screen: 1) Loading of each 
pair of key frames from the disk. 2) Interpolation of the sketch data. 3) Matrix transformationand 
display of the intermediate frames. tion lies in the fact that each process is achieved by a separate 
part of the computer sys­ tem, operating in an asynchronous, multi-tasking environment. The three independent 
devices in­ volved are the mass storage controller, the CPU, and the display processor. These three 
asynchronouslyoperating devices are slaved to the previewer in the Cornell system using a network of 
pseudo-simultaneousco-routines executing in the central computer, as shown in Figure 8. At the start 
of key frame (n), the disk controller is instructed to begin transfer­ring the data for key frame(n+l) 
to a core buf­fer. At the same time that the disk transfer is triggered, interpolationcommences on the 
first plane of key frame (n). Whenthis plane is com­plete, the display processor is commanded to transform 
and display the plane. This is achieved by loading the plane's geometry into the display pipeline along 
with the matrices desired for translation and rotation. Meanwhile, the CPU is working on the interpolations 
for the second plane. When all planes have been computed and processed for display, work begins again 
for the next frame. By the time the entire key frame is exhausted, the disk operation is complete and 
the next key frame is ready for interpolation. Since the display processing operates faster than the 
interpolations, the critical path in­cludes all of the interpolations,but no other processes, as the 
diagram indicates. If by chance the work required to display a single frame is completed ahead of schedule, 
an internal clock delays the program for the proper interval of time. The work will never fall behind 
schedule, since before the playback process begins, each sketch has been subdivided only into a number 
of points that can be handled at 12 frames per second. For our present equipment configuration, this 
limit has been measured at about 2800 points, which allows sketches of far greater complexity than can 
be previewed using the pre-calculation method, due to disk-to-coretransfer speed limi­tations. Of course, 
sketches of considerable complexity take on a slightly coarser appearance due to this filtering/subdivisionalgorithm, 
but the results so far have been very satisfactory. For sketches containing an initial point count of 
under 5000, the filter-down is almost impos­sible to detect. Very seldom has any sketch pro­duced by 
the artists working on the Cornell sys­tem exceeded 7000 points, which makes the tech­nique viable for 
use in a production environment.  70 In addition to the real-timeplayback capa­ 2) The complex pixel-by-pixel 
computations bility, individual frames in the animated se­ required to generate a single frame of quence 
can be transferred to the color display color animation make real-time color pre­ for stop-frame examination. 
The image thus pre­ viewing very difficult to achieve. The sented to the artist looks exactly as will 
the only viable solution yet evolved for this final film, includingmultiple-cel opaquing and limitation 
is to compute each frame before­ full color shading. hand and store it on a video disk or stop­ frame 
video tape-recorder for subsequent IV. CONCLUSION playback in real-time. This paper has presented an 
overview of the 3) Most animation systems currently require key-frame computer animation system currently 
that the artist input his sketches manual­ under development at the Cornell Program of Computer Graphics. 
ly, using a graphic tablet and pen. This time-consuming extra step can be elimina­ ted through the use 
of a high-precision The basic algorithm employed is a linear in­ optical scanner. The edge-findingand 
terpolation between successive pairs of key frames. stroke identificationalgorithms necessary These key 
frames are composed of artwork input by the animator on a graphic tablet and displayed on for such a 
procedure pose complex problems in themselves, but if solved, promise to either a black and white vector 
scope or a color halftone CRT. The attributes of this animation further ease the labor burden on the 
animator. package are: V. REFERENCES 1) The initial working environment is two­dimensional, and any of 
the following graphic media may be used: 1. Catmull, Edward, (Personal conference at New York Institute 
of Technology), New York,(1976). a. Free-form line sketches. 2. Defanti, Thomas, "The Graphics Symbiosis 
Sys­ b. Line sketches with color infilling. c. Color paintings. tem", Real-Time Film Animation, annual 
report to the NSF, submitted by the Computer Graphics Research Group at Ohio State University, d. Two-dimensionalprojections 
of com­ (1973), pp. 5-116. plex three-dimensionalscenes. 3. Finch, Christopher,The Art of Walt Disney, 
2) These two-dimensionalimages are combined Walt Disney Productions, (1975). using a multiplane cel animation 
tech­ nique to produce depth and motion illu­sions. 4. Gracer and Blasgen, "Karma: A System for Story­board 
Animation", UAIDE,(1970), pp.210-224. 3) Real-time film previewing, utilizing an on-the-fly interpolation 
algorithm, pro­vides the artist with instant playback of animated sequences. 5. Greenberg, Donald P., 
"An Interdisciplinary Laboratory for Graphics Research and Applica­tions", Proceedings of the Fourth 
Annual Conference on Computer Graphics, Interactive Techniques, and Image Processing (July, 1977). 4) 
All interaction with the program is pic­torial in order to facilitate the use of 6. Shoup, Richard, (Presentationof 
the SHAZAM this system by the non-programmingartist. animation system at the Third Annual SIGGRAPH Conference), 
Phila. Pa., (1976). It is evident that numerous approaches have been taken to computer animation. This 
can be 7. Wein, Marceli, "Interactive Skeleton Techniques ascribed,to a large extent, to variations in 
artis­tic taste. There are, however, problems common to all animation systems which must be solved before 
for Enhanced Motion Dynamics in Key-Frame Animation", Communicationsof the ACM, Oct. 1976). they can 
be viably used for production work. These involve increasing the resolution, allowing for real time playback 
at this increased resolution, and providing a more efficient input system. 8. Wein, Marceli, and Lestor 
Burtnyk, "Computer Generated Key-frame Animation", Journal SMPTE, (March 1971), pp. 149-153. Future research 
in computer animation must address these issues, as described below: 1) Most currently available color 
frame buf­ fers are designed for the 512 x 512 nomi­ nal resolution of a video monitor. In order to obtain 
a satisfactory image for theater projection, a resolution of at least 2000 x 2000 is required. The enor­ 
mous data storage problems this implies, and the lack of any viable device for previewing such images, 
pose formidable problems for computer animation systems. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563872</article_id>
		<sort_key>72</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Real-time playback in animation systems]]></title>
		<page_from>72</page_from>
		<page_to>77</page_to>
		<doi_number>10.1145/563858.563872</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563872</url>
		<abstract>
			<par><![CDATA[A technique often employed in animated vector graphics involves the use of a real-time playback mechanism. This technique is an alternative when it is not possible to generate animation frames in real-time. Instead frames are compiled in advance at non-real-time rates, saved in secondary storage, and then played back at desired real-time rates. The basic design of such a playback mechanism will be considered, including discussions of synchronization, buffering, and blocking. Two special properties will be established for these systems: the conditions required to achieve real-time reversal in the direction of the playback sequence, and the existence of upstream/downstream effects, performance differences between directions in systems that are run "too fast."]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[animation]]></kw>
			<kw><![CDATA[blocking]]></kw>
			<kw><![CDATA[buffering]]></kw>
			<kw><![CDATA[playback]]></kw>
			<kw><![CDATA[real-time]]></kw>
			<kw><![CDATA[real-time reversal]]></kw>
			<kw><![CDATA[synchronization]]></kw>
			<kw><![CDATA[upstream/downstream effects]]></kw>
			<kw><![CDATA[utility programs]]></kw>
			<kw><![CDATA[vector graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P362656</person_id>
				<author_profile_id><![CDATA[81100352220]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Potel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Chicago, Chicago, Illinois]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>888547</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baecker, R. M. Interactive Computer-Mediated Animation. Ph.D. Dissertation, M.I.T., Project MAC-TR-61, 1969, Section III.B.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Burtnyk, N. and Wein, M. Computer-generated key-frame animation. J. Soc. Motion Picture and Television Engineers 80,3 (March, 1971), 149-153.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Burtnyk, N. and Wein, M. Towards a computer animating production tool. Proc. Eurocomp Conf., Brunel, UK, May, 1974, Online Pub. Co., 172-185.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Grogono, P. MUSYS - Software for an electronic music studio. Software - Practice and Experience 3,4 (Oct.-Dec., 1973), 369-383.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Hellerman, H. Digital Computer System Principles. McGraw-Hill, New York, 1967, Chapter 3.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>260999</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Knuth, D. E. The Art of Computer Programming, Vol. 1: Fundamental Algorithms. Addison-Wesley, Reading, Mass., 1968, Section 1.4.4.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Mathews, M. V. The Technology of Computer Music. M.I.T. Press, Cambridge, Mass., 1969, pp. 31-39.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Mercer, C. A. Buffering for sustained, high-speed transfers. Software - Practice and Experience 3,4 (Oct.-Dec., 1973), 351-354.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563283</ref_obj_id>
				<ref_obj_pid>563274</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Myers, A. J. A digital video information storage and retrieval system. Proc. SIGGRAPH '76, Computer Graphics 10,2 (July, 1976), 45-50.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M. Trends in graphic display design. IEEE Trans. on Computers 25,12 (Dec., 1976), 1321-1325.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M. and Sproull, R. F. Principles of Interactive Computer Graphics. McGraw-Hill, New York, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Potel, M. J. Analysis of Real-Time Frame Computation Systems. Ph.D. Dissertation, Committee on Information Sciences, University of Chicago, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563285</ref_obj_id>
				<ref_obj_pid>563274</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Potel, M. J. and Sayre, R. E. Interacting with the GALATEA film analysis system. Proc. SIGGRAPH '76, Computer Graphics 10,2 (July, 1976), 52-59.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Potel, M. J. and Sayre, R. E. Motion analysis with vector graphics. Proc. IEEE Workshop on Picture Data Description and Management, Chicago, Apr., 1977, IEEE Comp. Soc. 77CH1187-4C, 184-186.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 REAL-TIME PLAYBACK IN ANIMATION SYSTEMS M. J. Potel Department of Biophysics and Theoretical Biology 
and Institute for Computer Research The Universityof Chicago Chicago, Illinois 60637 A technique often 
employed in animated vector graphics involves the use of a real-time playback mechanism. This technique 
is an alternativewhen it is not possible to generate animation frames in real-time. Instead frames are 
compiled in advance at non-real-timerates, saved in secondary storage, and then played back at desired 
real-time rates. The basic design of such a playback mechanismwill be considered,including discussions 
of synchronization,buffering,and blocking. Two special properties will be established for these systems: 
the conditions required to achieve real-time reversal in the direction of the playback sequence, and 
the existence of upstream/ downstream effects, performance differences between directions in systems 
that are run "too fast." animation,blocking, buffering,vector graphics, playback, real-time, real-time 
synchronization,upstream/downstream effects, utility programs. CR Categories: 3.89, 4.41, 8.2 1. INTRODUCTION 
 A technique often employed in animated vector graphics environments involves the use of a real­time 
playback mechanism. In applications making use of three-dimensional transformations, hidden­ line removal, 
involved data generation or refer­ence, and the like, extensive amounts of computa­tion are required 
per animation frame. Frequently it is not possible to compile frames at the rates required for real-time 
presentation. In such cases an alternative is to compile all the frames in advance at non-real-time rates 
and save the display code for them in secondary storage, typically disk or tape. Then, a special system 
utility is used to play these frames back at the desired real-time rate, transferringthe display files 
from secondary storage into memory buffers for display by a standard refresh display proces­sor. This 
work is based on our use of a DEC PDP­11/40 with RK05 disk drives and a DEC VT-11 display processor. 
 Figure 1 -Simulation of D.discoideum aggregation The techniqueof real-time playback has been used in 
vector graphics animation since its classic description in the work of Baecker /1/. Animated vector graphics 
is still widely used, particular­ families of curves or time-dependentwire-frame  ly in scientific applications/14/. 
Various mathe­ surfaces, as in Figure 2. Similarly, an effective matical models and simulations can 
be computed yet simple way to plot the function z = f(x,y) is for considerable lengths of time and 
their re­ to make two-dimensionalplots of'z versus x and sults viewed at animation rates. For example, 
 animate through y. A natural generalizationof Figure 1 shows a multi-point display from a simu­ playbackmechanisms 
is to perform some amount of lation of aggregation in cellular slime molds. computation in real-time 
on the data being trans- Additionally,animation is a good way to view ferred, such as in key frame 
animation /2/ or in generation of graphical objects from parameteri­zed descriptions /13/.  not made 
or distributed for profit or commercial advantage and that copies bear this notice and the full citation 
on the first page. To copy otherwise, to 72 republish, to post on servers, or to redistribute to lists, 
requires prior specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California   Raster 
graphics animations, which can require great amounts of computation per frame, have also used the playback 
technique despite the inherently large data volume per frame. This has been accom­plished by reducing 
resolution /3/ and by using run-length encoding /9/. The eventual use of real­time scan conversion /10/ 
will make the situation much like for vector graphics. The playback tech­nique is also used in music 
generation systems, both in digital audio synthesis /7/ and computer control of music processors /4/. 
A corresponding input gatheringversion of this technique is also used. For example, in the case of high-speed 
 experiment monitoring,a real-time recording mechanism can absorb data for subsequent non-real­time analysis 
/8/. This paper will focus on the design of playback mechanisms for animated vector graphics. Speci­fically, 
a system model relating the key param­eters of the design to the hardware characteris­tics is given. 
Next, some of the subtleties of synchronizationand buffering between the second­ary storage and display 
processors are discussed. The problem of choosing buffer blocking factors in order to achieve basic 
system feasibilityis addressed using the system model. Finally,a basic algorithm implementingthis design 
is given. Two special topics are then studied for playback systems. The first concerns the problem 
of sup­porting real-time reversal in the direction of the playback sequence. The conditions charac­terizing 
this capability for different degrees of buffering are established. The second topic considersthe consequences 
of running playback at rates faster than the rates guaranteed by the system model. It is shown that 
this can easily result in upstream/downstreameffects, that is, anomalous differences between the frame 
rates achieved in the forward and reverse directions.  2. A SYSTEM MODEL The requirements of the playback 
applicationmay be expressed in terms of three quantities, repre­ senting the size, duration, and total 
number of animation frames. The animation frames will be thought to each have the same display file size 
consisting of D words (all parameters are summa­rized in Table 1). An upper bound on D follows from 
the display processor speed P (in words/msec) for the particular display instruction mix and the duration 
of the refresh R (in msec) as re­ quired by the phosphor type. That is, display of frames requires that 
 The animation frames are each to be shown for duration F (in msec). Typical values for F in the animation 
literature range from 1/30th to about of a second, and sub-real-time rates are also useful. Notice that 
F is not necessarily the same as the refresh duration R and shouldn't be less. The choice of these two 
values with respect to each other and an analysis of system perfor­mance when these values differ may 
be found in /12/. The total number of animation frames to be handled will be given as N. As might be 
supposed, the only system aspect leading to an upper bound on N is the total amount of secondary storage 
space S available for frames (in words). All the frames will fit in secondary storage provided  The 
secondary storage devices under consideration, both diskandtape, have in common the way in which operation 
time per request is frequently charac­terized /5/. Each request for data transfer, re­gardless of its 
length in words, first results in an overhead called seek time or latency. This time takes into account 
disk cylinder seek times, rotational latency, controller overheads, tape transport start/stop times, 
and the like. These amount to a complicated function in the small, but latency is usually abstracted 
to be a constant value L (in msec) per request, representing the worst-case value for all the delays 
possible. Secondly, after this latency time comes the actual transmissiontime of the data itself. This 
time is likewise a complicated function accounting for automatic intervening cylinder seeks, partial 
sec­tor use, and the like. But basically it is suf­ficient to consider transmissiontime to be given by 
dividing a constant worst-case transmission rate T (in words/msec) into the length of the data in the 
request. Thus, a request to transfer an animation frame of length D will be completed in duration L + 
D/T.  3. SYNCHRONIZATION AND BUFFERING In order to proceed with the system model, some details about 
interfacingthe system devices need to be -considered. A playback mechanism involves the transfer of data 
from the secondary storage device (for purposes of discussion, a disk) to the display processor. In theory 
this transfer could take place directly if the display processor could accept words at exactly the instantaneous 
rate of the disk. Since such complete synchronization is not generally possible, core memory is used 
to provide a buffer between the two devices. 73 The disk and display processors are capable of operating 
asynchronously. Each is considered a direct-memory-access (DMA) device, able to access core locations 
by stealing memory cycles, without interruptingthe central processor. However, the standard single-ported 
memory and bus architecture will require that two processors instantaneously mutually exclude each 
other in accessing core, in order to prevent a processor from reading a word partially written by another. 
Usually each de­ vice has sufficient internal buffering so that their relative DMA bus priorities are 
not impor­ tant. The mutual exclusion on the word level guaranteed by the bus may not be all that is 
required /11/. Often display processors use two word instruc­ tions, such as for long vectors, display 
jumps, and subroutine calls. Particularly if a (jump, address) pair is overwrittenor written over other 
 display code at exactly the wrong time, the dis­ astrous effect of transferringto some unexpected location 
can result. The required double word synchronization is often not achieved by typical display processor 
bus interfacing. A related prob­ lem arises when overwriting one display file with a longer one, so 
that the instantaneous state of the display file finds it without an end-of-dis­ play-file instruction. 
If all such problems were solved, any display file could be overwritten at any time by any other display 
file, and disk and display synchronizationconsiderationswould be simplified. Buffering techniques 
are used to resolve these difficulties in most operating systems design /5/. The buffering is to be sufficient 
to guarantee that both processors cannot access the same locations at the same time. The degree of buffering 
required follows from the non-uniformityof each processor's instantaneous transfer rate. In particular, 
the disk transfer operations are punctuatedby head seeks on cylinder boundaries and latencies at the 
start of each transfer request, so that the disk's instantaneous rate is higher than its average rate 
 (Figure 3). The display processor's instantaneous rate may also have non-uniformities,depending upon 
vector lengths, type of display instruction,and the like. The buffering must be sufficient to Table 
 -Parameters B -Blocking factor in frames per page C -Available core for buffers in words D -Display 
file size in words per frame F -Frame duration in msec L -Secondary storage latency in msec N -Total 
number of frames P -Display processor speed in words/msec R -Refresh duration in msec S -Secondary 
storage space for frames in words T -Secondary storage transmission speed in words/ msec overcome these 
momentary differences in processing speeds. With some care this may be achieved with a single buffer, 
where the two processors operate on buffer locations separated by appropriatedis­tances /8/. The total 
buffer size will be essen­tially the length of one display file plus an amount determined by the worst-casedeviation 
in processor speeds. This approachwill minimize the total amount of core required. If sufficient core 
is available, double buffering is the more standard approach /11/. Each processor is allocated a buffer 
of its own, the display pro­cessor reading from one buffer while the disk writes into the other. When 
the display processor  is to begin displaying the other buffer, assuming the disk transfer into it 
has been completed, the functions of the two buffers are switched. De­pending upon the organization 
of the display pro­ cessor, this switch may be accomplished instan­taneously or may have to wait until 
terminationof the final refresh of the old buffer. An analysis in Knuth /6/ can be used to show when 
double buffering is sufficient. If the computa­tion time between successive transfer initiations is always 
greater than the transfer time itself, then the system is compute-boundand double buf­ fering will suffice. 
On the other hand if trans­ fer time is always greater than computation time between transfers, then 
the system is I/O-bound and double buffering again suffices. More than two buffers are required when 
the two times vary in respective size. We desire an animation that displays frames of uniform duration 
F. Therefore, if transfer operations can be performed so that the system is compute-boundwith respect 
to F, then a double buffered system will work correctly in real-time. The next section concerns the problem 
of averaging out the disk fluctuationsto the amount requiredto guarantee this goal.  4. BLOCKING The 
technique of blocking involves transferring data in larger quantities per request in order to average 
seek times across more words of data /5/. 74 Thus, with a blocking factor of B frames per transfer, 
transfer operations require (L + BD/T)/B = L/B + D/T per frame. Blocks of B display frames will be 
called pages. Typical values of L alone may correspond to more than one typical animation frame duration 
F. Therefore, B must be sufficient­ ly large so that the effective transmission times per frame are 
always smaller than F, the condi­ tion required to make the system "compute-bound." This will be true 
provided  On the other hand, the degree of blocking is limited by the amount of core available for buf­ 
fers. If this amounts to C words, then assuming double buffering,B must be small enough so that all 
buffers fit in core, or  Condition (3) is also necessary for any higher num­ber of buffers to work, 
so double buffering re­ quires the least core to implement a given system. The above discussion has 
provided four conditions for playback system feasibility, expressing the adequacyof display processor 
speed (1), secondary storage size (2), secondary storage speed (3), and core size (4). One may notice 
that all four of these conditions provide upper bounds on D. This leads to the following characterizationof 
playback system feasibility. Theorem 1. A playback system is feasible if and only if (iff)  Notice 
that B is the only term that appears in more than one of the four terms in (5); all other terms are independent. 
If D is such that strict in­equality holds in (5), then B may take on a range of values, at least enough 
to overcome secondary storage seek effects but no more than allows buf­fers to fit in core. From condition 
(5), one ob­tains Corollary 1.1. If a playback system is feasible then  Suppose that for a particular 
system this Corol­lary indicates that a range of values for B is possible. Since by Theorem 1 display 
file size cannot exceed the minimum bound of the four, all larger bounds indicate system capabilities 
that will be underutilized. Thus, the possible values for B in Corollary 1.1 range from underutiliza­ 
tion of secondary storage speed for large B to underutilizationof core for small B. The latter alternative 
is often preferable in practice, as extra core can more readily be used for other purposes. The inequality 
in Corollary 1.1 can be used to derive an upper bound on display file size. Corollary1.2. A playback 
system is feasible only if This bound is achieved only when the minimum of the core size and transfer 
speed bounds is maxi­mized, and this occurs exactly when they are equal. If all four bounds of Theorem 
1 are equal to each other and D, then the playback system is said to be in balance. For a balanced system, 
strict equalities hold in (6) and (7). Further analysis of balance conditions may be found in /12/. 
 5. BASIC ALGORITHM The playback systen described thus far handle N total frames in B frame blocks 
called pages. Frame indices are numbered 0 to N-1 and page in­ dicies from 0 to M=Int(N-l/B). Any frame 
index k can be written uniquely as iB + j where i = Int (k/B) is the page index and j = k (Mod B) is 
the displacement of frame k into page i. Together with double buffering, this suggests the following 
 algorithm (see Figure 4). At every instant in  time, one buffer is to contain the current page i and 
the disk is to be transferring the next page i+l (or i-l if running in reverse) into the other buffer 
(let d=l for forward traversal, d=-l for reverse). The next page will be completely trans­ferred by the 
time it becomes current. This algorithm need not be evaluated continuously, but only on frame boundaries 
that are multiples of B. If the display processor cannot switch frames instantaneouslyon the desired 
frame boundaries, then frame boundaries will be consideredto be at the end of the last refresh in the 
frame. This algorithmmay be summarized as Algorithm P. On start-of-frame k, display frame  = k (Mod 
B) in buffer Int(k/B) (Mod2) and if j = 0 then initiate transfer of page i = Int (k/B) + d into buffer 
i (Mod 2).  75 6. REAL-TIME REVERSAL For some real-time animation applications it is desirable to be 
able to play frames back in both forward and reverse, for example /13/. Algorithm P will correctly perform 
playback in either given direction. However, for certain of these applica­tions it is of interest to 
achieve a design that will permit the direction of traversal to be re­versed at any instant in real-time. 
Usually the assumption must be made that it is not possible to cancel a transfer operation once it is 
initia­ted. In this case Algorithm P will fail. This section will characterize the conditions that permit 
real-time reversal, beginning with the following result. Theorem 2. A double buffered playback system 
is capable of real-time reversal iff  Proof. Multiplying through this expression by B gives BF/3 > L 
+ BD/T, so that this condition re­ quires that a complete page transfer operation must fit within a third 
of a page duration. First, a proof of necessity will be shown. Suppose that L + BD/T = Z > BF/3, and 
assume a forward traver­ sal is in progress. At the instant of the tran­ sition from page i to page i+l, 
the two buffers must contain exactly these two pages; call this point (see Figure 5). 1  As traversal 
proceeds toward the next page boun­dary t= t 1 + BF, the initiation of the transfer 2 of page i+2 must 
take place at some point t3 where t3 t2 -Z, with time enough to transfer page i+2. Moreover, page i+2 
must be written into the buffer that contained page i since some frame in page i+l is currently being 
displayed. Suppose now a rever­sal takes place at point t4 = t3 + h/2 where h = Z -BF/3. Then the transfer 
of page i+2 proceeds from t3up to t4 down to t3again, finishing at = 2BF/3 -Z < Z, that is, insuffi­cient 
time to prevent a page fault at time t1. point t5 = t-Z + h. If traversal in reverse continues, page 
i will be needed by point tl again. But the time remaining from point t 5 to point tl is t5 ­ 3 + BF 
-Z -BF/3 ­ = t3 -BF/3 ­ Next, sufficiency of the condition will be shown by giving an algorithm that 
handles arbitrary rever­sals. On start-of-framek, display frame k Mod B) in buffer Int(k/B) (Mod2). 
On (start­of-frame k + d*2BF/3), if k (Mod B) = 0 and trans­fer-not-in-progressthen initiate transfer 
of page i = Int(k/B) + d into buffer i (Mod2). Transfers are initiated exactly at the last third of a 
page duration in the direction of traversal. Once a transfer is initiated it should not be re­requested, 
for example, when several direction changes occur around the transfer initiation boun­dary. To prove 
this algorithm always works, notice that regardless of arbitrary reversals, once a transfer initiation 
boundary is reached then, again regardless of arbitrary reversals, the trans­fer of the next page in 
this direction will be com­pleted before it becomes current and also before reaching the transfer initiation 
boundary for the other direction. QED. Theorem 2 assumes double buffering. Suppose the possibilityof 
having more buffers is considered. Using the same technique as in Theorem 2, the fol­lowing Corollary 
may be shown. Corollary 2.1. A triple buffered playback system is capable of real-time reversal iff 
 A quadruple or higher buffered system is capable of real-time reversal iff  Notice that (10) is just 
the same as (3), the ori­ginal condition for simple real-time feasibility using any number of buffers. 
Theorem 2 and its Corollary show both buffering and blocking help achieve real-time reversal, though 
not with the same effect. One might ask what degree of buf­fering works best at implementingreal-time 
rever­ sal. Interestingly,the answer is given by Theorem 3. Quadruple buffering implements real­time 
reversal in less core than any other number of buffers. Proof. Suppose a given amount of core C is avail­able. 
Then if there are m buffers and display frames of length D, then there can be no more than C/mD frames 
per buffer. But then (8) becomes F > 6DL/C + 3D/T, while (9) becomes F > 9DL/2C + 3D/2T, and (10) becomes 
F > mDL/C + D/T for m buffers. Thus, (8) strictly implies (9) strictly implies (10) for m=4, and (10) 
for m > 4 strictly implies (10) for m=4. QED. 7. UPSTREAM/DOWNSTREAMEFFECTS The precedinganalysis 
of playback systems has made use of worst-case values for secondary storage latency and transmission 
times. Suppose a system is used to playback display frames of a substantial size, say 4000 words. Even 
for reason­ably fast disk transfer speeds of 10 usec/word, transfer alone proceeds at 40 msec/frame 
or 25 fps. This does not include any account of latency ef­fects, which may be considerable. Typical 
disk controllers implement sequential sector order so that whole rotations (about 40 msec) are lost between 
page transfer requests and additionally on every cylinder boundary. It is quite possible, then, that 
the frame rate guaranteed by the worst­case analysis is too slow for acceptable real-time animation. 
 76 a graphics image will get "coarser"in quality, but The temptation might be not to clock frames 
at the any average rate can be maintained. Conceivably, worst-caserate in this situation, but rather 
to push ahead when transfers complete in better than worst-case. Though for some frames the instanta­ 
neous frame rate could approach the transmission rate, other frames will be delayed by bad-case ef­fects, 
causing the frames to pass at a non-uniform rate. By the synchronization discussion of Section 3, one 
can see that the worst-case frame rate is the maximum uniform rate that can be guaranteed. Certain clever 
arrangements of data on a particular disk for special data lengths are possible but such methods are 
difficult to apply generally and intro­duce the complication of using non-sequential I/O operations. 
An interestingconsequenceof processing at faster than the maximum uniform rate is the appearance of 
upstream/downstreameffects. That is, at faster than the maximum uniform rate, a playback system will 
operate at different average speeds in the forward and reverse directions to an extent depen­ dent on 
page size. Often the effects can be dra­matic, 50 to 100% discrepancies,and either direc­tion can be 
faster. The existenceof these effects has its basis in the following result. Theorem 4. The maximum 
rate of page transfer from a secondary storage device (almost always) differs for forward and reverse 
directions of traversal. Proof. The proof will be informal. First, con­ sider the simpler case of a tape 
store. Reading forward Just requires one standard transfer time per page. But in order to read backwards, 
the tape must be moved backwards over page i, then backwards over page i-l, then forward over page i-l 
to read it. Thus, backwards traversals run (approximately) three times slower. Some tape drives have 
been designed specifically to read backwards as fast as forwards. For disk drives, every time a cylinder 
boundary is reached during a transfer, the disk head automati­cally advances forward in the directionof 
sequen­tial sector order. In readingbackwards across the disk, every automatic forward head movement 
must be undone with a backward head movement plus the nor­mal backward movement for the traversal. This 
may approachthe same three-to-oneratio as for tape. transfer of certain frames or pages could be skipped 
as required. But it is better to just store an appropriate subset of the frames on the disk and transfer 
those. Display is always of the frame closest in time of those available. Slippage is particularlyuseful 
in systems that compile frames in real-time, having the advantage that it can automaticallyadjust for 
varying amounts of computationper frame and variable frame rates. An analysis of performancedegradation 
in systems using slippage scheduling can be found in /12/. ACKNOWLEDGEMENTS I wish to thank Richard 
Sayre for suggesting a number of improvements, and Steven MacKay,whose simulations have been a source 
of much inspiration. REFERENCES /1/ Baecker, R.M. Interactive Computer-Mediated Animation. Ph.D. Dissertation,M.I.T., 
Project MAC-TR-61, 1969, Section III.B. /2/ Burtnyk,N. and Wein, M. Computer-generated key-frame animation. 
J. Soc. Motion Picture and Television Engineers 80,3 (March,1971), 149-153. /3/ Burtnyk,N. and Wein, 
M. Towards a computer animating productiontool. Proc. Eurocomp Conf., Brunel, UK, May, 1974, Online Pub. 
Co., 172-185. /4/ Grogono, P. MUSYS -Software for an electronic music studio. Software -Practice and 
Experience 3,4 (Oct.-Dec., 1973), 369-383. /5/ Hellerman, H. Digital Computer System Princi­ples. McGraw-Hill, 
New York, 1967, Chapter 3. /6/ Knuth, D.E. The Art of Computer Programming, Vol. 1: Fundamental Algorithms. 
Addison-Wesley, Reading, Mass., 1968, Section 1.4.4. /7/ Mathews, M.V. The Technology of Computer Music. 
 M.I.T. Press, Cambridge, Mass., 1969, pp. 31-39. /8/ Mercer, C.A. Buffering for sustained,high­speed 
transfers. Software -Practice and Experience 3,4 (Oct.-Dec., 1973), 351-354.  /9/ Myers, A.J. A digital 
video information storage and retrieval system. Proc. SIGGRAPH '76, Computer Graphics 10,2 (July, 1976), 
45-50. Superimposedon head motions are discrepancies due to rotation, which may favor either traversal 
direc­tion. After reading one page, the disk may be un­ able to read the next zero or more sectors, depen­ding 
on the disk design, due to controller latency. Sequential contiguous pages will be positionedso that 
from the end of each page plus this controller latency to the beginning of the next page will be some 
identical number of sectors less than a track; call this the forward displacement. Similarly there is 
a backward displacement. Whenever these two displacements are unequal, traversal will be faster in the 
direction with the smaller displace­ment. The two displacements will be equal only if exactly one or 
exactly two pages fit in one or more tracks. QED. A different approach to the problem of achieving 
higher frame rates is to skip frames in order to keep up, the technique of slippage /2,12/. Thus, /10/ 
Newman, W.M. Trends in graphic display design. IEEE Trans. on Computers 25,12 (Dec., 1976), 1321-1325. 
 /11/ Newman, W.M. and Sproull, R.F. Principles of Interactive Computer Graphics. McGraw-Hill, New York, 
1973. /12/ Potel, M.J. Analysis of Real-Time Frame Computation Systems. Ph.D. Dissertation, Committeeon 
Information Sciences, University of Chicago, 1977. /13/ Potel, M.J. and Sayre, R.E. Interactingwith 
the GALATEA film analysis system. Proc. SIGGRAPH '76, Computer Graphics 10,2 (July, 1976), 52-59. /14/ 
Potel, M.J. and Sayre, R.E. Motion analysis with vector graphics. Proc. IEEE Workshop on Picture Data 
Description and Management, Chicago, Apr., 1977, IEEE Comp. Soc. 77CH1187-4C, 184-186. 77  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563873</article_id>
		<sort_key>78</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[The buffalo crime mapping system]]></title>
		<subtitle><![CDATA[a design strategy for the display and analysis of spatially referenced crime data]]></subtitle>
		<page_from>78</page_from>
		<page_to>85</page_to>
		<doi_number>10.1145/563858.563873</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563873</url>
		<abstract>
			<par><![CDATA[This paper presents the design strategy for a crime information system with vast capabilities for production of and experimentationwith maps. Detailed disaggregated crime information from the city of Buffalo, New York forms the primary data base for the system. This series of crime files, together with socio-economic data from the Census, are integrated into a geographic information system denoted as the Crime Analysis and Research Package (CARP). The Buffalo Crime Mapping System as a part of CARP is a collection of data files and routines designed for versatile display and analysis of spatially referenced crime data. It deals with three types of information: crime, census, and spatial reference information containing various geometrical indices such as block group boundaries and centroids of statistical units. The boundary information is provided by a flexible arc structure. The three major data files are stored as random access files and are interfaced with various display procedures such as choropleth, graduated circle, and dot mapping programs. The user provides the system with a set of instructions as to the desired map type and its display parameters. A-driver routine then reads the map type instruction and calls the appropriate mapping routine. This mapping program then proceeds by reading the user parameters, accesses the necessary base files, and produces the final map. At its present stage, the system is batch oriented and does not provide for interactive and/or real-time communication features.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[cartographic data structures]]></kw>
			<kw><![CDATA[computer cartography]]></kw>
			<kw><![CDATA[criminal data processing]]></kw>
			<kw><![CDATA[geographic information system]]></kw>
			<kw><![CDATA[information retrieval]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P331878</person_id>
				<author_profile_id><![CDATA[81100307114]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kurt]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Brassel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[State University of New York at Buffalo, Amherst, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379949</person_id>
				<author_profile_id><![CDATA[81100616493]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jack]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Utano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[State University of New York at Buffalo, Amherst, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379961</person_id>
				<author_profile_id><![CDATA[81100646172]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Perry]]></first_name>
				<middle_name><![CDATA[O.]]></middle_name>
				<last_name><![CDATA[Hanson]]></last_name>
				<suffix><![CDATA[III]]></suffix>
				<affiliation><![CDATA[State University of New York at Buffalo, Amherst, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bertin, Jacques, 1967. Semiologie Graphique. Hague, Netherlands: Mouton. 426 pgs.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Brassel, K., 1975. "Efficient Visualization of Complex Data Sets" Progress Report of a Research Project, unpublished manuscript, 16 pgs.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bureau of the Census, 1970. Census Use Study, Report No. 4: The DIME Geocoding System, 38 pgs.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Hanson, Perry O., "A Geographic Information System for Criminal Research in Buffalo, New York", Proceedings of the Middle States Division, Assoc. of American Geographers, (8,1974) 51-55.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Hanson, Perry O., K. Brassel and J. J. Utano, 1977. A Crime Analysis Research Package (CARP): A Strategy for the Display and Analysis of Spatially Referenced Crime Data, Technical Papers R-77/4, Geographic Information Systems Laboratory, State Univ. of New York at Buffalo, 13 pgs.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hanson, Perry O. and Jack J. Utano, "The Utilization of Police Information Systems - A Research Strategy" forthcoming in Review of Public Data Use.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Laboratory for Computer Graphics and Spatial Analysis, Lab-Log, Harvard University, Graduate School of Design, January, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Peucker, T. K. and N. Chrisman, April 1975. "Cartographic Data Structures" in The American Cartographer, Vol. 2, No. 1, pp 55-69.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Rens, Frank, 1975. Private correspondence.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Tobler, Waldo, 1973. "Choropleth Maps Without Class Intervals?", Geographical Analysis, Vol.5, 262-265.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 THE BUFFALO CRIME MAPPING SYSTEM: A Design Strategy for the Display and Analysis of Spatially Referenced 
Crime Data* Kurt E. Brassel, Jack J. Utano, and Perry O. Hanson, III Geographic Information Systems 
Laboratory State University of New York at Buffalo Amherst, New York 14226 This paper presents the design 
strategy for a crime information system with vast capabilities for produc­ tion of and experimentationwith 
maps. Detailed disaggregated crime information from the city of Buffalo, New York forms the primary data 
base for the system. This series of crime files, together with socio­ economic data from the Census, 
are integrated into a geographic information system denoted as the Crime Analysis and Research Package 
(CARP). The Buffalo Crime Mapping System as a part of CARP is a collection of data files and routines 
designed for versatile display and analysis of spatially referenced crime data. It deals with three 
types of information: crime, census, and spatial reference information containing various geometrical 
indices such as block group boundaries and centroids of statistical units. The bound­ary information 
is provided by a flexible arc structure. The three major data files are stored as random access files 
and are interfaced with various display procedures such as choropleth, graduated circle, and dot mapping 
programs. The user provides the system with a set of instructions as to the desired map type and its 
display parameters. A-driver routine then reads the map type instruction and calls the appropriate mapping 
routine. This mapping program then proceeds by reading the user parameters, accesses the necessary base 
files, and produces the final map. At its present stage, the system is batch oriented and does not provide 
for interactive and/or real-time communication features. Key Words and Phrases: Geographic Information 
System, Computer Cartography, Cartographic Data Structures, Information Retrieval, Criminal Data Processing. 
CR Categories: 3.33, 3.39, 3.73, 3.74, 8.2 1. INTRODUCTION Information systems of all kinds are becoming 
more and more important, and their impact influence most spheres of human life. Data concerning population, 
economic structure, land utilization,pollution, and traffic (to mention but a few) are systemat­ically 
collected for the purpose of decision-making on various stages of political, scientific and private life. 
In order to profit from these ef­forts fully, these data must be made readily available in convenient 
form to possible users. To fulfill this information need, graphical repre­sentation techniques are highly 
favored, since people are able to overview, integrate and com­prehend a large amount of information when 
dis­played efficiently. This calls for development of automated representation techniques for the growing 
but often neglected quantity of public use data being collected. In this paper we attempt to present 
the design strategy for an information system with vast map­ ping capabilities for both production of 
and experimentationwith maps. Detailed disaggregated crime information from the city of Buffalo, New 
York forms the primary data base for the system. These series of crime files together with socio­ economic 
data from the Census Bureau are inte­ grated into a geographical information system, de­ noted as the 
Crime Analysis and Research Package (CARP), developed by the Geographic Information Systems Laboratory 
at the State University of New York at Buffalo (see Hanson, et al. 1977). This paper focuses upon a 
subset component of CARP, the Buffalo Crime Mapping System. This sys­ tem is designed for the development 
and implemen­ tation of current computer cartographic technology for the automated representationof 
complex phenomena associated with the geographical crime information system. In our presentationwe 
will first describe the nature of the crime information base and then dis­cuss the technological aspects 
of the structure and development of the Buffalo Crime Mapping System, before concluding with a look to 
its im­portance and future applications. 2. CRIME INFORMATION AND DISPLAY APPLICATIONS For the past 
six years, the Buffalo Police Depart­ment (NY) has compiled and maintained detailed incident and arrest 
records in machine-readable form. In order to appreciate the potential graphic applications of this 
crime information a brief analysis of the 'information dimensions' in this system is in place. The term 
information dimension is used here for a group of independent variables of similar quality (Compare Bertin, 
 1967). Each event in the crime file is described by: -Location: census tracts/block groups/blocks; precincts; 
street addresses; police code. not made or distributed for profit or commercial advantage and that copies 
bear this notice and the full citation on the first page. To copy otherwise, to 78 republish, to post 
on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Siggraph 77, 
July 20-22 San Jose, California -Time: hour, day, week, month, year. -Informationabout the offender 
(age,race,sex) -Information about the victim (age,race,sex) -Type of crime and classificationof offense 
 -Event status; offense-arrest-clearence,etc. To assess the informationwealth of maps that may be produced 
from the existing data material, each element of all non-locationalinformation dimen­sions may be mapped 
with respect to all location identifiers; some of these information dimensions are quite long (the crime 
file maintains informa­tion about more than 500 classifications of crimi­nal offenses). In addition, 
this number is magni­fied when these information dimensions are cross­referenced, thus permitting mapping 
of an element of one dimension that is qualified by any combina­ tion of items of other dimensions (e.g. 
map of burglaries by blocks on Saturdays, 4-6 p.m. involv­ing white male offenders). Considering this 
vast wealth of information that may be displayed by various mapping methods there exists an obvious 
 need for a systematic survey of the potential of computer cartography for such display contents of 
information systems. 3. THE BUFFALO CRIME MAPPING SYSTEM 3.1 Overview The Buffalo Crime Mapping System 
as part of the Crime Analysis Research Package (CARP) is a col­ lection of data files and routines designed 
for versatile display and analysis of spatially refer­ enced crime data. A system overview is given in 
 Figure 1. The system may be subdivided according to information type and functional steps where it 
 is dealing with three types of information: crime, census, and spatial reference information. The 
crime data have been discussed in the previous section. The bulk of the census data are pro­ vided by 
the 1970 federal census and refer to the Census Bureau statistical units (census tracts, block groups). 
The spatial reference in­formation consists of various geometrical indices such as block group boundaries 
and centroids of statistical units. The three functional steps of the system are data preparation, information 
storage, and the (applica­tion-) processing. The data preparationstep in­cludes functions such as data 
compilation (col­ lection, digitization) and file manipulations in various degrees of complexity. The 
information storage section consists of three major files. The Multiple Access Crime File (MACF)provides 
 a versatile storage of all single crime events. The Statistical Unit Attribute File (SUAF) in­ cludes 
crime and census data aggregated by block groups and census tracts: it is a location by variable matrix. 
The Topological Arc Reference File (TOPARF)is a versatile spatial reference file that allows for geometric 
manipulationsand mapping applications. All the essential files are either in an index sequential or 
random access file organization. In processingwe distinguish between data analysis and display functions. 
The. overall system is used as follows: Crime data are modified and put into the Multiple Access Crime 
 File. An aggregation program retrieves subsets of the modified crime information and places it into 
the location attribute file SUAF. Census and certain spatial reference data are also trans­ ferred into 
SUAF. The file TOPARF is created in some rather sophisticated steps from spatial reference information. 
Once created the three files are available for user processing. Data analysis as a rule makes use of 
disaggregated or aggregated crime and census information (MACF + SUAF) whereas mapping routines are 
in general based on aggregated crime/censusinformation (SUAF) and the spatial reference file (TOPARF). 
Further discussion of the system emphasizes the functions that are important for information display. 
The  79 several sections deal with the following struc­tural units outlined in Figure 1: -The Buffalo 
criminal data record structure; -Data aggregation and storage of thematic infor­ mation; -Organizationof 
the spatial reference file; -Display programs and interface to base files.  3.2 The Buffalo Criminal 
Data Record Structure  Figure 2 provides an overviewof the various modi­ fications performed to upgrade 
the utility of the crime information. The initial modification step in the system entails the reorganization 
of the logical file structure of the Buffalo Police Master Crime Files. Geocoding the crime files becomes 
the first step. The crime files were used as in­put to an address-coding,computer program package provided 
by Frank Rens of the Medical Center of the State Universityof New York at Buffalo (Rens, 1975). This 
particular software uses a GBF/DIME file to match the street name and number in the police files witha 
1970 census tract, block group, and block identifier. Once this address-coding process is complete, the 
crime records are com­patible with the 1970 census data.  Upon completion of the geocoding phase, the 
files still retain their sequential organization by chronological identification (CD) number. Two forms 
of random access file organizations, actual key and indexed-sequential,are used to restruc­ture the crime 
files into a more usable and man­ageable format. In an actual key structure, the crime records are stored 
and retrieved on the basis of a pre-determinedrelationship between the key of the record --the CD code 
--and the direct address of the disk location where the record is housed. A data record in the index-sequentialfile 
con­tains only the particular crime variable code and the actual key information (block number and re­cord 
number) that points to the actual complete crime record in the actual key data base. In addition, other 
index-sequentialfiles may be con­structed that contain keys identifying and link­ing crime records according 
to time of offense or street location to the crime data base. These subsidiary index-sequential files 
act only as table pointers to the actual key data base. To address the secondary file only a key derived 
from the data record (crime type, for example) is needed and immediatelythe appropriate position of the 
actual key file for extracting crime records that match the pre-specifiedkey is determined. To obtain 
these multiple access paths to the actual key data base, the laboratory utilized one additional key 
configuration associated with the index-sequentialfile organization. The feature contains a partial 
key option where the user is permitted to pass only a portion of the full crime key to one of the index-sequentialkey 
 files. By combining a number of specific crime variables to form one multiple index-sequential key 
file, extracting records based on a complete or partial collection of these crime keys may be achieved 
in a tractable manner. The augmented capability generated by this multi­ ple key organization equips 
the researcher with the flexibility to search the crime data base along three separate lines of inquiry. 
For in­ stance, the user may key on any or all of the three crime variables simultaneously. Whether 
it be burglary incidents within a certain time period along a specified street, burglaries dur­ ing 
a given time interval, or simply all burglary records, the user need only specify a partial or complete 
crime key to retrieve any of these types of queries in one access step. Given the overall system design 
of the Crime Analysis Research Package, the utility attributed to this initial data preparation stage 
becomes apparent. The eloquence of this data structure may be further illustrated in the following 
 example. Given the constructionof the actual key data file for the 1975 Buffalo crime file with a correspondingindex-sequentialkey 
file aligned by crime type, the researcher is able to call all the homocide records at a fraction of 
the CPU time it would require under a cumbersome sequential procedure. Here, the crime type code for 
homocide is first passed to the index-sequen­ tial key file. This file is immediately posi­ tioned to 
a contiguous subset of the index­ sequential file where the homocide keys reside. The block/record location 
that is appended to each key record is then retrieved sequentially from that section where the homocide 
records are stored and are, in turn, used as key location identifiers to point to and extract the appro­ 
priate homocide records from the actual key data file. The retrieved records form a subset sequential 
disk file. Thus, for the user inter­ ested in utilizing the Mapping System to generate choropleth maps 
of homocide in Buffalo, he is not burdened with addressing the entire crime data base; instead he works 
with a considerably smaller subset file which is then aggregated into a number  80 of statistical 
units according to user-opted crime conditions. This data aggregation compon­ ent is described next. 
 3.3 Data Aggregation and Storage of Attribute Information The Statistical Unit Attribute File (SUAF)is 
 created from crime and census information. Crime data are extracted first from the multiple access crime 
file MACF by user-opted crime keys and then the contents of the subset file are transformed to obtain 
frequency profiles of various crime variables for future mapping and data analysis (Figure 3).  The 
logical structure of SUAF represents a two­ dimensional matrix, location by variable, in random access 
format. In our current implementa­ tion, this random access matrix houses a number of crime and statistical 
variables (henceforth called attributes) by the various statistical units of the region in question. 
In the Buffalo case, the location dimension includes the city block groups, census tracts, precincts, 
and the total city. Given the particular random access structure used for SUAF, storage requirements, 
 in terms of disk space, are dynamically allocated so that the amount of variables housed in the file 
 is not restricted. Principal application of SUAF may be distinguished between three cases: 1) retrievalby 
attributes; 2) single call retrieval, and 3) retrieval by locations. A typical use of such a file in 
a map­ping environment is the retrieval of one variable, i.e. one information item for the units of 
the entire region (i.e. block groups or census tracts) for the productionof one map (e.g. choropleth 
map). For such an application it is desirable to be able to retrieve the user-requested information 
in a single read step. Other mapping routines may require single cell access in the location by variable 
matrix. Finally, a file user may also be interested in retrieving several or all variable values for 
one location. Besides crime and census information a number of geometrical indices are stored in SUAF. 
These indices, such as centroids, surface area, area perimeter, min-max x-y coordinates, inscribing and 
circumscribingcircles, etc., are also per­tinent to the statisticalunits. Another type of information 
in the SUAF file are various pointers such as hierarchical pointers to higher/lower level statistical 
units in SUAF itself, or point­ers to the geographic base file; the latter will be discussed in the next 
section. Raw frequency counts by statistical units repre­sent the basic information stored in SUAF. 
The user is now able to interface this file with the mapping and data analysis components of the system 
to obtain various maps of the frequency counts. In many applications, however, it is necessary to convert 
these new counts in some sort of standard­ized form to obtain more reliable representations of the data. 
Accordingly, the Lab has written a versatile procedure that is designed to perform various manipulations 
for any variable in SUAF (ratio, average, sum computations, etc.). The re­sults may then be stored as 
new attributes in SUAF. SUAF is thus a versatile storage file containing various types of attribute 
information for each of the pre-defined statistical units. Togehter with the spatial reference file, 
they represent the essential data source for all mapping procedures.  3.4 Organizationof the Spatial 
Reference File Spatial base files include all information neces­ sary for spatial allocation of thematic 
data via location identifiers. They should be organized in such a way as to minimize storage requirements, 
 maximize information content, and provide a multi­ tude of graphic applicationswith only a minimum 
of conversion manipulations. The TOPological Arc Reference File (TOPARF) forms the base file for the 
Buffalo Mapping System. TOPARF currently contains record descriptions for the block group and census 
tract outlines of the city; its topo­ logical properties allow for multiple use of this data structure 
including manipulations where neighborhoodfunctions are of importance (compare Peucker and Chrisman, 
1975). The block group and census tract outlines consist of straight line segments that are defined 
by a series of digitized points (x,y coordinates). Points that are members of one single polygon out­line 
(block group or census tract) are called cartographicpoints and points that are common to three or more 
polygon outlines are called topo­logical nodes. A chain of line segments joining two nodes is called 
an arc. TOPARF currently con­sists of approximately 1000 directly accessible records, each describing 
a unique arc. A direc­tion quality is assigned to the arcs, where they are interpreted as being directional 
vectors. The initial direction (forward, backward) of an 81 arc is assigned arbitrarily, but once defined, 
it has to be used consistently for the remaining re­ ference to that arc. Arcs and their associated 
arc records are illustrated in Figure 4, where the arcs are labelled by Arabic numbers, polygons (areas) 
by upper case letters, and nodes by Roman numerals. The record in Figure 4 describes arc 1. It is defined 
as being directed from a node I (start node or FROM node) to a node II (end node or TO node). Given 
this direction, arc 1 is separating polygon A (AreaLeft AL) from polygon B (Area Right AR). In addition, 
the record in­ cludes information regarding the neighboring arcs; these arcs are defined as being neighbors 
when they are delimited by the same start or end node of the present arc record. Four pointers are used 
to indicate the directional relationship of the present arc with its neighbors; they are de­ fined as 
being in a forward left (FL), forward right (FR), backward left (BL), and backward right (BR) direction. 
Finally, the arc record includes information on the number and x-y coor­ dinate values of the cartographic 
points. The arc pointers (FL,FR,BL,BR) point to other arc records in TOPARF in such a way as to permit 
a 'migration' along polygon outlines without the need of acces­ sing additional pointer or coordinate 
files.  Figure 5 gives an overview of the several files and procedures involved in creating the Buffalo 
Base File TOPARF. The base information for the topological reference file is a DIME file of the city 
of Buffalo(Bureauof the Census, 1970), and a file including segment coordinates of the same area. A 
first step connects the independent seg­ments of the Buffalo DIME file into chains of polygon outlines. 
The segment coordinates are then attached to these chains resulting in a coordinate chain file. A display 
routine MAPDIME allows for plotting any subdivision of the region on a separate sheet and labels the 
complete set of topological identifiers. From the edited chains the arc file TOPARF is created. The 
box labelled 'Digitizer' indicates the possibilities for other strategies to create a chain file in 
case DIME files are not already available. 3.5 Display Software and Their Interface to the Base Files 
 The logical structure inherent in any generalized or versatile mapping system should include at least 
rudimentary procedures for handling three basic components in automated map design: data  preparation, 
data manipulation, and mapping step capability. Systems containing all three design facets may be considered 
as a multiple step soft­ware package in contrast to single step mapping routines where data preparationand 
manipulation are evolved independentlyfrom the mapping system. In addition to this multiple step capability, 
automated mapping systems should usually include software facilities for the production of various types 
of maps. Such systems may be designated as multiple product systems as opposed to single product packages 
where, although the data genera­tion and manipulation components are incorporated into the system, the 
mapping package is able to produce only one kind of map (e.g. choropleth). The first two components of 
the Buffalo Crime Mapping System have been given thorough treatment in previous sections; this section 
focuses upon the mapping phase and highlights the multiple pro­duct facet of the system. The schematic 
relationship between the data base, the mapping software, and the system user is pro­vided in Figure 
6. It outlines the system's  82 of maps from a user's frame of reference. The user initially provides 
the system with a set of instructionsas to the desired map type(s) and its respective display parameters 
(the various types of mapping routines implemented and planned for the system are described below). 
Map parameters include user options such as map scale, shading symbolism, class interval determination,legend 
information, and the type(s) of data to be accessed from the data base. User instructionsmay be stacked 
and the system is designed for multiple map type production and multiple copy production in a single 
run. A driver program then reads the map type instruction and calls the appropriate mapping routine. 
This mapping program then pro­ceeds by reading the user map parameters, accesses the necessarybase files, 
and produces (a) final map(s). At its present stage, the system is batch oriented and does not provide 
for interactive and/ or real-time communication features. To assess the application capabilitiesof the 
 Buffalo Crime Mapping System, the range aind:type  of maps that may be produced is discussed. In general, 
potential map productions are a function of three major ingredients in any automated map production 
environment. Maps may be classified according to the data types they are designed for, the display 
devices used for their production, and the cartographic representationmethods chosen. DATA TYPES. As 
with most computerizedmapping packages, two sets of data, thematic and geometric, are used to generate 
maps in this system. However, since different types of maps may be produced given the several types 
of data in the two sets, the user is restricted to using particular data set combinations for map production. 
For instance, specific thematic aata (aggregated-disaggregated) require particular spatial-referencinginformation, 
 whereas certain geometric data (centroids-segments­area outlines) govern the kinds of thematic display 
possible. According to the kinds of data set interaction permissible in this system, the mapping programs 
 are designed to access the three data base files (MACF,SUAF,TOPARF)to extract the user-opted the­ matic 
and geometric information. In the present version, however, the user is responsible for creating any 
data set not already stored in the data base files. DISPLAY DEVICES. Plotter, line printer, and CRT 
 displays represent the primary output media used in automated mapping environments. The routines presently 
implemented in this system are designed for the CALCOMP 913 drum plotter. It permits high resolution 
vector representationsand color varia­ tion. Line printer programs may easily be incor­ porated in the 
system; however, additional hard­ ware devices are presentlynot available on the host computer. CARTOGRAPHICMETHODS. 
Given the availability of the respective software and the hardware capacity of the host computer, there 
is no restriction as to the implementationof any of the traditional cartographic techniques into the 
Buffalo Crime Mapping System. However, the thematic and geo­ metric data base requirements for a particular 
 mapping program must be compatible with those in our system. To illustrate computerized cartographicapplica­ 
tions we discuss here briefly the mapping software planned for implementation into the system.  83 
  Choropleth Mapping. The program retrieves a set of attributes from SUAF (one item for each stat­ 
istical unit), and the polygon outlines from TOPARF or an intermediate base file. This map­ping routine 
provides for title and legend infor­mation, a shading symbol mechanism,an algorithm to choose class 
intervals, and various output parameters. At present the program uses a modi­ fied version of Tobler's 
continuous shading algorithm (Tobler, 1974). It has been modified to provide more flexibility in assigning 
grey tones to variable values (Figure 7). Graduated Circle Maps. The program retrieves centroids and 
attributes from SUAF and repre­ sents one variable on one map. Options include titles and legends, minimum 
circle size, maximum circle size, density of circle symbol, type of base map (blockgroup outlines, 
census tract outlines; full lines or dashed). The graduated circles are shaded by concentric circles, 
where the radius increment can be chosen by a user option (Figure 8). Ring diagrams. The program maps 
two variables or a subset variable using the same algorithm as the graduated circle routine; one variable 
 defines the outside radius of the ring, the second an inner radius, the area between the inner and 
outer radius is shaded. A repetitive use for rings in different colors allows for multiple variable 
representation. Graduated rectangle maps. This program is used to map two or more variables over space. 
One variable defines the horizontal length of the rectangle, the other the height. Shading of the rectangles 
can be used to express a third -preferablynomi­nal -variable. Frame diagrams. The routine is a rectangular 
version of the ring diagrams. Attributes may be expressed by the horizontal and vertical dimen­ sions 
of the frame, or the frame width. Multiple concentric frames in different shadings and/or colors are 
possible. Graduated segmented circle maps (pie charts). Several attributes are used to define the overall 
size of a segmented circle and its subdivisions. The single sectors are represented in different shadings 
and/or color. The routine will also allow to map segmented rings rather than filled circles. A variation 
of this program allows for tilting the circle to an ellipse to produce a pseudo-3-d effect. The ellipse 
may then be lifted on a stem (height proportional to an additionalvariable) into the third dimension. 
 Point symbol mapping. Figurative symbols for inventory mapping may be graduated in size accord­ing 
to variable values. Includes an algorithm for optimum placement within the polygon in question. Contour 
mapping. A version of the program CONTUR (by F. Rens) will be implemented that access the variables and 
centroids in SUAF, interpolates a regular grid and constructs contour lines. 3-d mapping. A version 
of TRID (by F. Rens, modi­ 84 fied by C. Reed) is being implemented. The pro­ gram interpolatesa regular 
grid and displays traverses along column, rows, or diagonals. Op­tions include variation of viewing azimuth 
and height, horizontal and vertical scale, continuous or histogram version. As an alternative the pro­ 
gram CENVUE (Tobler, 1973) is considered to be interfaced to the system. Produces 3-d block dia­grams 
on a polyhedron (rather than grid) base. Fence maps. Attributes assigned to statistical units can be 
represented by a pseudo 3-d view of the area bound by a fence where the fence height is proportional 
to the variable value. Options include viewing direction, planimetric and verti­cal scale, etc. Dot 
maps. The mapping is based either on single crime events or on aggregated data. The dots are placed either 
at a location near the crime occur­rence or in random fashion within the block groups (or census tracts). 
The latter procedure needs a random dot placing algorithm which avoids super-positionof dots. Mapping 
of multiple variables in various colors is planned. Cartograms. Implementation of area distortion 
cartograms (Tobler) or non-contiguous cartograms is planned. Both will be based on the display of one 
attribute for each statistical unit. 4. CONCLUSIONS The Buffalo Mapping System as part of the Crime 
 Analysis and Research Package (CARP) will be a powerful tool to generate several types of maps for 
research and production purposes. At the present time it is being implemented on the CDC CYBER 173 
at the State University of New York at Buffalo. The Buffalo Criminal Data Record system is fully implemented 
where the Multiple Access Crime Files for the years 1971-1975 have been constructed. The data aggregation 
routines to­ gether with the aggregation file SUAF is opera­ tional. The spatial reference file TOPARF 
is available for mapping purposes in a preliminary form, and a number of the mapping routines have 
 been implemented. In essence, then, the data base structure is completed and present emphasis is on 
 implementing the mapping routines and extending the options of the currently operational display programs. 
 This paper has been concerned primarilywith the design concepts and the technological aspects of the 
present mapping system. Future concern, how­ ever, will not be directed to the particular technical 
structure of the system, but to its versatilemapping potential based on multiple in­ put and multiple 
display capabilities. This future research will provide for a systematic production and comparison 
of various types of maps using several cartographicmethods. After the stages of implementing the data 
base structure and incorporating the various mapping routines in the system, a phase of systematic 
 computer mapping will follow. That phase will not just be restricted to the physical production of 
maps but will include a thorough evaluation of these various products as far as design, read­ ability, 
and applicability is concerned. Such an evaluation will include surveys with various user groups. ACKNOWLEDGMENTS 
 The authors want to express their thanks to the Buffalo Police Department for their interest and cooperation 
in providing the data files. Mr. Frank Rens, Mr. Carl Reed, and Ms. Donna Peuquet have made some of 
their programs available to the system. Among the students who contributed through programming efforts: 
Bruce Eaton, Barry Glick, Wendy Ormont, and Tim Young. The latter also drew some figures of this report. 
The pro­ject has greatly benefited from suggestions by Dr. D. Marble. Their contributions are gratefully 
appreciated. The project has been supported through grants from the Research Foundation of the State 
of New York and the SUNY Buffalo Institu­tional Funds Committee. REFERENCES Bertin, Jacques, 1967. 
Semiologie Graphique. Hague, Netherlands: Mouton. 426 pgs. Brassel, K., 1975. "Efficient Visualization 
of Complex Data Sets" Progress Report of a Research Project, unpublishedmanuscript, 16 pgs. Bureau of 
the Census, 1970. Census Use Study, Report No. 4: The DIME Geocoding System, 38 pgs. Hanson, Perry O., 
"A Geographic Information Sys­tem for Criminal Research in Buffalo, New York", Proceedings of the Middle 
States Division, Assoc. of American Geographers, (8,1974) 51-55. Hanson, Perry O., K. Brassel and J.J. 
Utano, 1977. A Crime Analysis Research Package (CARP): A Strategy for the Display and Analysis of Spat­ially 
Referenced Crime Data, Technical Papers R-77/4, Geographic Information Systems Labora­tory, State Univ. 
of New York at Buffalo, 13 pgs. Hanson, Perry 0. and Jack J. Utano, "The Utiliza­tion of Police Information 
Systems -A Research Strategy" forthcoming in Review of Public Data Use. Laboratory for Computer Graphics 
and Spatial Analysis, Lab-Log, Harvard University, Graduate School of Design, January, 1977. Peucker, 
T.K. and N. Chrisman, April 1975. "Carto­graphic Data Structures" in The American Carto­grapher, Vol. 
2, No. 1, pp 55-69. Rens, Frank, 1975. Private correspondence. Tobler, Waldo, 1973. "Choropleth Maps 
Without Class Intervals?", GeographicalAnalysis, Vol.5, 262-265. 85  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563874</article_id>
		<sort_key>86</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[Trans-use of graphics in the study of transformations]]></title>
		<page_from>86</page_from>
		<page_to>89</page_to>
		<doi_number>10.1145/563858.563874</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563874</url>
		<abstract>
			<par><![CDATA[The TRANS system is a drill and practice system for the study of transformations of the plane. The system is designed for elementary school pupils (ages 8-10) who have studied the subject in the classroom environment. The system contains exercises on the terms: axis of reflection, reflection, translation and rotation. It is divided into several sections according to increasing difficulty. Each section contains a number of exercises with interesting geometrical shapes to arouse the pupil's attention and interest. The pupil's task is to designate the position of the axis of reflection in order to reflect, translate or rotate a shape to its final position. The pupil's main tool is the light pen. There are additional exercises in which the pupil is presented with a shape, an axis of reflection, and he has to find the reflected shape. The system contains a follow up of the successes and failures of the pupil. If necessary it advises the pupil or gives him hints. At the end of the exercise the pupil receives a grade.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[computer aided instruction]]></kw>
			<kw><![CDATA[computer graphics]]></kw>
			<kw><![CDATA[transformation of the plane]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379941</person_id>
				<author_profile_id><![CDATA[81100242562]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[E.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hefez]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Haifa, Mount Carmel, Haifa Israel]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379954</person_id>
				<author_profile_id><![CDATA[81100334292]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[L.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dror]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Haifa, Mount Carmel, Haifa Israel]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14181308</person_id>
				<author_profile_id><![CDATA[81100522323]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[P.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nesher]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Haifa, Mount Carmel, Haifa Israel]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Nesher, P. and Grossman, M. Intuitive approach to the teaching of isomorphic transformations. Investigation into education, School of Education, Haifa University, pp. 89-96, 6, (Feb. 1975), (in Hebrew).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Nesher P. and Grossman, M. Punch booklet for the teaching of isomorphic transformation. Israeli Ministry of Education (1975) (in Hebrew).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Phillips, J. M. and Zweyer, R. E. Motion Geometry, Book 1, Slides, Flips and Turns. University of Illinois Committee on School Mathematics (1969).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Seiler, B. A., and Weaver, C. S. Description of PLATO whole number arithmetic lessons. Computer-BasedEducation Research Laboratory, University of Illinois, Urbana, Illinois (June 1976).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Walter, M. Some mathematical ideas involved in the mirror cards. The Arith. Teacher (Feb. 1967), 116-125.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Williford, H. J. A study of transformational geometry instruction in the primary grades, Journal for Research in Mathematics Education 3 (4) (Nov. 1972).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Usiskin, Z. P. The effects of teaching euclidean geometry via transformations on students achievement and attitudes in tenth-grade geometry. Journal of Research in Mathematics Education. 3, (4) (Nov. 1972), 249-259.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Zahavi, N. Experiment in teaching geometry with the aid of transformations. Mathematics Department, Hebrew University, Jerusalem (Sept. 1973) (in Hebrew).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 TRANS-USE OF GRAPHICS IN THE STUDY OF TRANSFORMATIONS E. Hefez, L. Dror and P. Nesher University of 
Haifa, Mount Carmel, Haifa Israel The TRANS system is a drill and practice system for the study of transformations 
of the plane. The system is designed for elementary school pupils (ages 8-10) who have studied the subject 
in the classroom environment. The system contains exercises on the terms: axis of reflection,reflection, 
translation and rotation. It is divided into several sections according to increasing difficulty. Each 
section contains a number of exercises with interesting geometrical shapes to arouse the pupil's attention 
and interest. The pupil's task is to designate the position of the axis of reflection in order to reflect, 
translate or rotate a shape to its final position. The pupil's main tool is the light pen. There are 
additional exercises in which the pupil is presented with a shape, an axis of reflection, and he has 
to find the reflected shape. The system contains a follow up of the successes and failures of the pupil. 
If necessary it advises the pupil or gives him hints. At the end of the exercise the pupil receives a 
grade. Keywords: Computer Graphics, Computer Aided Instruction, Transformation of the Plane. CR Categories: 
3.32, 8.2 INTRODUCTION One of the reasons for developing the system is the difficulties encountered 
by the educators concerning the drill and practice of the study of transformation of the plane. A major 
difficulty in the drill and practice is the necessity of constant drawing and erasing of figures. Instructional 
aids such as punch booklets [1], [2] and mirror cards [5] are suggested for use to overcome this problem. 
Numerous educators deal with the teaching of transformations for junior high schools [7], [8] and for 
primary schools [3],[6].  The graphics system with its special features of simplicity of use, of visual 
chan­ging display, and of the use of the light pen is seen to be another suitable tool to overcome some 
of these difficulties. An interesting project [4] using graphics in teaching arithmatics is currently 
running under the PLATO system. The TRANS system is the first part of a wider Graphics Aided Instruction 
(GAI) research to exploit the advantages and potentials of the graphics system in education. The purpose 
of the system is to exercise and train elementary school pupils, ages 8-10, in the subject of axis 
of reflection, reflection, translation and rotation after they have learned the terms in the classroom. 
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior 86 specific permission and/or a fee. 
Siggraph 77, July 20-22 San Jose, California The system is programmedon the PDP 11/40, with the GT 44 
graphics system (includingthe light pen), a TTY, and a line printer. The programs are written in BASIC, 
using graphics subroutines contained in the RT 11 operating system. METHOD OF EXERCISE Each exercise 
divides the screen into five areas. (See Figure 1.) Area A gives a short explanation of the task to 
be performed. If the instructionsare too lengthy, they will be shown on a separate page. Area B will 
usually show two shapes. The original shape (I) and the shape to be arrived at by reflection, translationor 
rotation (II).  Area C contains only shape (I) which has to be moved to the position of shape (II) as 
shown in area B. The pupil indicates the axis of refle­ction by pointing with the light pen at the hori­zontal 
and/or vertical line shown in this area. The system's responses to his action are given in area C and 
area D. In area C the pupil receives a dashed line axis with the reflected figure (see Figure 2). Area 
D displays remarks such as "TRY AGAIN", "YOU ARE VERY CLOSE", "EXCELLENT YOU FOUND THE SOLUTION", "FIND 
THE FIRST AXIS", and evaluations of his success or his failure. Area E contains the emblem of the system 
and instructions for the continuationof the exercise such as STOP, CONTINUE, and RESTART. The STOP is 
for terminating an exercise at any stage. The CONTINUE allows the pupil to advance to the next exercise 
and the RESTART returns him to the beginning of the present exercise.  DESCRIPTIONOF THE PROGRAM The 
system is divided into several units beginning with simple reflections and continuing to more complex 
problems of trans­lation and rotation. The units are organized according to increasing difficulty of 
the material. In order to exercise and test the understanding of the material learned, the exercises 
cover different aspects of similar problems. The units consist of the following: 1. Exercise in Use 
of Light Pen Since the pupil is confronted with the computer and the graphics system for the first time, 
he is presented with an introduc­tion and exercise in the use of the light pen on the screen. 2. Finding 
the Axis of Reflection In the first unit the pupil has to solve several simple problems of reflection. 
Figure 2 displays an example of reflection around the vertical axis, where the pupil has to find the 
position of the axis of reflection. The unit also contains reflection exercises around the horizontal 
axis. 3. Drawing the Reflected Shape At his stage the pupil is given shape I, an axis of reflection 
and a set of points (see Figure 3). He has to draw the reflected shape II by connecting the appropriate 
points using the light pen and the tracking object. If he fails to draw the correct shape, the shape 
will flash, he will receive a message and he will have to restart the exercise.  Figure 3: Drawing a 
Reflection 4. Simple Translation This group of exercises contains reflections from the left to the 
right, the right to the left, upwards and downwards. The axes of reflection must be placed between the 
shapes I and II (see Figure 4). After locating the first axis, the system draws the axis and the reflected 
figure, and prints a message to the user "FIND THE SECOND AXIS". If he fails to locate the correct positionof 
the second axis, the axis and the reflected shapes are erased, leaving the first reflected shape. If, 
however, he wants to erase the first axis he has to point at RESTART.  87 5. Complex Translations 
In the more complex exercises of translation the pupil has to find the axes of reflection which have 
to be located to the right or the left of shapes I and II and not between them. To solve this exercise 
the two reflections have to be in opposite directions. Shape I and II are drawn close to each other in 
order to give the pupil enough freedom to choose the position of the axis of reflection (see Figure 
5). All the instructions and responses of the system are the same as those in the exercise of simple 
translation.  Figure 5: Complex Translation 6. Sequence of Axes of Reflection In this set of exercises 
the system displays the shape before and after the translation with the two corresponding axes of reflection. 
The pupil's task is to locate, using the light pen, the first of the two axes used to obtain the translation. 
The positions of the axes differ in each of the exercises; they may be to the left or to the right or 
between the shapes (see Figure 6). This time there is no room for trial and error; the pupil has to think, 
to be sure of himself and to be right the first time around.  7. Completion of a Shape by Several Reflections 
 Towards the end of the exercise the pupil receives several challenging exercises in which he has to 
draw a shape using several reflections. These exercises contain vertical and horizontal axes of reflection, 
as shown in figures 7 and 8.  Figure 8: Completion of a shape by vertical and horizontal axes. 8. Turns 
 The study and exercise of turns in the plane is the next stage of the development of the system. In 
order to arouse the pupil's interest in the next stage there are exercises on turns, as shown in Figure 
9. 88 REFERENCES  PILOT STUDY A pilot study of the present TRANS system has been carried out with 
a group of pupils, age 10, with the cooperation of their Mathematics teacher. The pupils first learned 
the principals of reflection, translation and turns in class, and then tried the exercises on the TRANS 
system without any practice in conventionalmethods. The pupils enjoyed the activity and showed an understanding 
of the material. They succeeded in answering the questions without any major difficulties. The minor 
difficulties that did appear stimula­ted changes in the programs. For example, it took the children a 
while to get accustomed to handling the light pen. FINAL REMARKS The value of the system is that it 
tests the child's comprehension of the mathematical concepts involved without any technical distraction. 
The pupil is free to concern himself only with the real mathematical problems because of the accuracy 
and speed of the computer. For educators the importance of the system is not only in the introduction 
of new and interestingmaterial, but also in the opportunity it affords for studying the Ways in which 
children comprehend and master new mathematical concepts. Therefore, the research and the development 
seems promising even though a wide spread use of the system is dependent on the high price of the graphics 
system. In the future the system will be expanded to include exercises on turns and on terms such as 
coordinate axis and coordinate points. For the latter purpose, the pupil will use the TTY as a data entry 
of numerical data.  Nesher, P. and Grossman, M. Intuitive approach to the teaching of isomorphic transformations. 
Investigation into education, School of Education, Haifa University, pp. 89-96, 6, (Feb. 1975), (in 
Hebrew). [2] Nesher P. and Grossman, M. Punch booklet for the teaching of isomorphic transfor­mation. 
Israeli Ministry of Education (1975) (in Hebrew).  Phillips, J.M. and Zweyer, R.E. Motion Geometry, 
Book 1, Slides, Flips and Turns. University of Illinois Committee on School Mathematics (1969). [4] 
Seiler, B.A., and Weaver, C.S. Description of PLATO whole number arithmetic lessons. Computer-BasedEducation 
Research Laboratory, University of Illinois, Urbana, Illinois (June 1976). [5] Walter, M. Some mathematical 
ideas involved in the mirror cards. The Arith. Teacher (Feb. 1967), 116-125. [6] Williford, H.J. A study 
of transformational geometry instruction in the primary grades, Journal for Research in Mathematics Education 
3 (4) (Nov. 1972).  Usiskin, Z.P. The effects of teaching euclidean geometry via transformations on 
students achievement and attitudes in geometry. Journal of Research in Mathematics Education. 3, (4) 
(Nov. 1972), 249-259.  Zahavi, N. Experiment in teaching geometry with the aid of transformations. 
Mathema­tics Department,Hebrew University, Jerusalem (Sept. 1973) (in Hebrew). 89 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563875</article_id>
		<sort_key>90</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[An interdisciplinary laboratory for graphics research and applications]]></title>
		<page_from>90</page_from>
		<page_to>97</page_to>
		<doi_number>10.1145/563858.563875</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563875</url>
		<abstract>
			<par><![CDATA[This paper describes the facilities and operation of the Program of Computer Graphics at Cornell University. A variety of graphic procedures are used for both input and output. The laboratory has the capability for producing dynamic vector displays and for generating full color images. Numerous research projects in a variety of disciplines which are actively using this multi-user graphics environment are presented.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P68459</person_id>
				<author_profile_id><![CDATA[81100196982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Greenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Forrest, A. R., "On Coons and Other Methods for Representation of Curved Surfaces", Computer Graphics and Image Processing, 1972, 1 (pp 341-359).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Johnson, T. E., "Sketchpad III, A Computer Program for Drawing in Three Dimensions", AFIPS Conference 1963.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563871</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Levoy, Marc, "A Color Animation System Based on the Multiplane Technique", Proceedings of the Fourth Annual Conference on Computer Graphics, Interactive Techniques and Image Processing, --- SIGGRAPH, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Newman, W., and Sproull, R., Principles of Interactive Computer Graphics, McGraw Hill, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>906872</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Riesenfeld, Richard F., "Applications of B-Spline Approximation to Geometric Problems of Computer-Aided-Design", Ph. D. Thesis, Syracuse University, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Sutherland, Ivan E., "Sketchpad: A Man-Machine Graphical Communication System", Lincoln Laboratory, MIT Technical Report No. 296, 1963.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360802</ref_obj_id>
				<ref_obj_pid>360767</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Sutherland Ivan E. and Hodgeman, G., "Reentrant Polygon Clipping", Communications of the ACM, Vol. 17, No. 1. Jan. 1974 (pp 32-42).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Sutherland, Ivan E., "Three-Dimensional Data Input by Tablet:, Proceedings of the IEEE, Vol. 62, No. 4, April 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Thornton, Robert W., "MODEL: Interactive Modeling in Three Dimensions Through Two-Dimensional Windows", M. S. Thesis, Cornell University, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563896</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Weiler, K., and Atherton, P., "Hidden Surface Removal Utilizing Polygon Area Sorting", Proceedings of the Fourth Annual Conference on Computer Graphics, Interactive Techniques and Image Processing - SIGGRAPH, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Weingarten, Nicholas H., "Computer Graphics Input Methods for Interactive Design", M. S. Thesis, Cornell University, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563882</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Wu, S., Abel, J., and Greenberg, D., "An Interactive Computer Graphics Approach to Surface Representation", Proceedings of the Fourth Annual Conference on Computer Graphics. Interactive Techniques and Image Processing - SIGGRAPH, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 AN INTERDISCIPLINARY LABORATORY FOR GRAPHICS RESEARCH AND APPLICATIONS by Dr. Donald P. Greenberg Program 
of Computer Graphics Cornell University This paper describes the facilities and operation of the Program 
of Computer Graphics at Cornell University. A variety of graphic procedures are used for both input 
and output. The laboratory has the capability for producing dynamic vector displays and for generating 
full color images. Numerous research projects in a variety of disciplines which are actively using this 
multi-user graphics environment are presented. Introduction An interdisciplinary laboratory has been 
established at Cornell University for: a) the development of computer graphics techniques, b) the utilization 
of these techniques to help solve various research problems, and c) the improvement of interactive design 
methodology. Using primarily digitizing tablets for the graphi­cal input tasks, the researcher may select 
any of several two dimensional or three dimensional input routines. These include volumetric input, serial 
sectioning, three dimensional input using two dimensional views, and extrusion methods. Display options 
include static or dynamic wire line draw­ings or full color static displays. Hidden line and hidden surface 
algorithms, based primarily on planar polygon descriptions are available. The initial graphics work 
has provided a catalytic effect for the stimulation of joint re­search projects. Present applications 
include research in structural engineering,geological sciences, water resources planning, pollution analysis, 
energy conservation, bio-medicine, archi­tecture and animation. A brief illustrationof some of these 
projects is presented. The large variety of projects has enforced the need for a general, rather thpn 
a discipline­specific approach to interactive graphics. Most of the graphic inputting, editing and display 
routines that have been developed can be inter­faced to either specialized applications programs or to 
each other. A brief description of these operating procedures as well as the equipment and facilities 
of the laboratory follows. This article is not intended to be an in­depth description of any aspect 
of interactive computer graphics. It is solely an overview of the objectives, operating procedures, 
and pro­gress of a new interdisciplinary computer graphics facility. For more detailed information on 
the hidden surface and surface representationpro­cedures or on the animation system, the reader is referred 
to other papers emanating from this laboratory and included in these proceedings.. Equipment and Facilities 
 The functional configuration of the graphics laboratory is shown in Figure 1. The major graph­ical components 
of the system are the E &#38; S "Picture System", the E &#38; S frame buffer, and two Tektronix storage 
tube displays. Two computers, a DEC PDP 11/50 and a PDP 11/34, are used to per­form all of the operations 
and control of the displays. The E &#38; S Picture System is a pipeline system which contains a picture 
processor, a refresh buf­fer, picture and character generators, and a pic­ture display and is capable 
of producing complex dynamic vector displays. The E &#38; S frame buffer is used for the pro­duction 
of the color images and has sufficient capacity to store one standard video frame (480 rows by 512 columns) 
of 8 bit pixels. For any image, each pixel can be translated into any of 256 possible colors by means 
of hardware lookup tables which provide 12 bit intensity levels for each of red, blue, and green. Output 
from the frame buffer can be directed to high resolution television monitors or to a large screen video 
projector. A 16mm motion pic­ture camera has been interfaced to the support processor for creation of 
stop frame motion pictures. The Tektronix 4014 display terminals are standard high resolution storage 
tubes with the capability for complex static and limited dynamic The operation of the laboratory is 
partially sponsored by the National Science Foundation under grant number DCR-14694 entitled "Developmentof 
Computer Graphics Techniques &#38; Applications." Permission to make digital or hard copies of part 
or all of this work or personal or classroom use is granted without fee provided that copies are 90 not 
made or distributed for profit or commercial advantage and that copies bear this notice and the full 
citation on the first page. To copy otherwise, to republish, to post on servers, or to redistribute to 
lists, requires prior specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California 
 image generation. A common graphics software package has been created which will drive both the dynamic 
and static display devices. Digitizing tablets serve as the standard, general purpose graphic input 
devices in the laboratory. Several tablets of varying sizes, ranging from a standard 11" x 11" tablet 
to a large 36' x 48" digitizing tablet have been interfaced either directly to the host processor, or 
through the display terminals. One transparent digitizing tablet allows for the digitizingof rear projected 
images. The host computer is a PDP 11/50 with 96K memory. It is interfaced to Cornell's IBM 370­168 
when larger memory capacity is required. A magnetic tape unit and two small disk units are also attached. 
The PDP 11/34 processor has been added to the laboratory equipment configuration primarily for the generation 
of color images. A large dual drive 80 megabyte Diva disk unit, DD-52, has been installed to improve 
the effi­ciency of the multi-user operating system and to store the large quantities of required picture 
information. Graphic Input Procedures In general, the characteristicsof an inter­active graphics environment 
can be described as consisting of three types of graphical operations: 1) The creation of the objects 
to be displayed. 2) The editing of the object description. 3) The generation of the displays. A typical 
user should be able to rapidly and precisely describe an object in two or three dimensions in addition 
to color and time. To this end, a comprehensive set of graphic input routines have been developed which 
can be adapted for most applications. Four different methods are provided for graphically inputtingspatial 
information. All of these methods rely on the availability of standard interactive graphic inputting 
and edit­ing procedures (4). The first graphical input approach consists of building up a complex environment 
from a set of predefined volumetric elements (2,6,11)(Figure2). The three-dimensionaldata required for 
the com­posite object description is obtained by inter­actively combining a set of primitive shapes and 
forms and by utilizing their original numerical definitions. To achieve these capabilities, the actual 
three-dimensionalcoordinates of the primi­tive objects are separated from the transforma­tional parameters 
that are applied to the data before display. This method permits multiple elements to be constructed 
from the same set of data and displayed many times with different transformations. It also allows for 
individual transformationalparameters to be altered without affecting those of any other object. To 
separate the coordinate data from the transformational data, two files have been established. The first 
con­ tains the actual untransformed three-dimensional coordinate data of the original primitive objects. 
The second file contains the transformational parameters for translation, scaling, and rotation in each 
of the three coordinate axes. These files are read from a mass storage device at the begin­ning of each 
work session and can be written back to storage if the user makes an alteration that needs to be saved 
for future sessions. The advantage of this approach is that it allows the creation of complex object 
descriptions with a minimal amount of data input and provides dynamic visual feedback using perspective 
images so that the researcher can work in three dimensions The major restriction is that the speed of 
the dis­ play may be limited by the referencing structure. This hierarchical process is particularly 
appli­ cable to analytical routines based on sub-elements such as structural finite element analyses 
or multi-zone energy simulations. A second and extremely promising method is to digitize three-dimensionalinformation 
into the computer using multiple sets of two-dimensional photographs (8,9). By identifying the appropriate 
 number of known reference points on a two-dimen­ sional drawing or photograph, it is possible to determine 
the mathematical transformation matrix that uniquely transforms the three-dimensional spatial data 
to the existing two-dimensional picture. If two drawings or photographs are available, and the matrices 
defining their pro­ jections can be established, the process just described can be inverted. The user 
can input the true three-dimensionalobject space informa­ tion by using a digitizing tablet and successively 
 identifying each point in the pair of photographs. When combined with dynamic displays of the object 
 as it is being defined, this procedure is a ver­ satile input method (Figure 3). There are two major 
restrictions. First, the process requires an existing set of photographs or drawings. Second, due to 
the inaccuracies of digitizing, powerful editing routines insuring planarity and automatic joining and 
aligning are necessary for practical usage. A third method is to define a set of serial cross-sections 
of an object and automatically combine these planar definitions to create the three-dimensional shape. 
All information is input in two-dimensional format. Normally the major constraint is the large amount 
of data required to accurately define amorphous shapes. For this reason, numerical procedures utilizing 
B-splines which can accurately represent these two-dimen­sional contours with compressed data have been 
implemented (1,5,12). Automatic webbing routines or lofting procedures using Cardinal splines can provide 
the three-dimensionalsurface interpola­ tion (Figure 4). Several applications, including the structural 
engineering finite element analysis project, are presently using this input method. Perhaps more important 
is the potential use of this approach to the entire field of medicine where information describing 
arbitrary, three­ dimensional objects is readily obtained in two­dimensional format. The last graphical 
input approach can be thought of conceptuallyas an extrusion method. A line can be generated from a point, 
a plane from a line, and a solid from a plane. In each case, the direction of the extension can be controlled 
and has a unique relationship to the original two-dimensionaldefinition. Elements can be created by digitizing 
on any two-dimensional plane, transformed into a three-dimensional element, and positioned appropriately. 
This process is particularly applicable to the field of archi­tecture. For example, a designer can create 
a three-dimensionalobject description by the ex­ trusion of a base plan or building cross-section (Figure 
5). Furthermore, by using the same graphic routines, the user can accurately and interactively describe 
details of the elevations. Although each techniquehas its unique advantages, the inputting procedures 
are even more powerful when these methods are combined.  Figure 2 -Primitives These displays were generated 
by a programwhich builds up complex objects from a set of primitive shapes. Two primitive elements, 
one duplicated twice, are combined to form a set of three (Figure 2a). Each set is tripled and the nine 
objects are displayed in Figure 2b (ProgramPRIMITIVES by Nicholas Weingarten). 92  Figure 3 -Three 
Dimensional Input from Two Dimensional Views Figure 3a shows the forming of polygons from established 
three-dimensional data points. The dashed lines indicate the polygon being formed. A bird's eye view 
of the completed house is shown in Figure 3b. The user can view the completely defined object from any 
observer position (Program MODEL by Robert Thornton). Figure 4 -Serial Sections Figure 4a shows the 
display of a television tower on a mountain that was described in less than a minute by tracing in the 
contours. The tower contours were subsequently "webbed" by connecting lines between contours to produce 
a more realistic surface (Program WIRE by Marc Levoy). The amorphous shape of Figure 4b was modeled by 
utilizing B-splines to represent the two-dimensional contours. Lofting was accomplished using Cardinal 
splines for the three-dimensional surface interpolation (Program SURF by Sheng Chuan Wu). Figure 5a 
shows an isometric view of the plan of a building digitized by an architect. "Rubber-banding" techniques 
were used to ensure that lines are straight and parallel. Figure 5b shows the building after the plan 
has been extruded to a preset wall height (Graphic Input Program by Harvey Allison.) Graphic Display 
Capabilities The display environment has the capability for generating dynamic black and white line drawing 
images. Views using any orthographic or perspective projection are easily obtained from any viewport. 
Static displays can be generated on any of the output devices, but complex dynamic displays necessitate 
the special­ized hardware of the vector display system. For editing, and non-dynamic display requirements, 
a graphic software package has been developed which operates on the storage tube terminals and simulates 
the powerful vector display system. Hard copy drawings are software gener­ated on a printer-plotter from 
the image descriptions. A unique graphics programming system has been implemented to generate the color 
displays. This system is designed to provide an environ­ment familiar to vector graphics researchers 
while maintaining flexibility for a variety of experimental approaches to using the frame buffer. The 
data required for the generation of the black and white vector displays can also be used for the creation 
of color images. Spe­cifically designed operators are provided for the creation of half tone color images, 
including commands for rendering dots, vectors, convex and concave polygons and run-length encoded scan 
lines. For three-dimensional environments, an efficient hidden line and hidden surface algor­ithm has 
been developed and is available to all system users (7,10). The approach is based on a two-dimensional 
polygon clipper which recur­sively subdivides the image into polygon-shaped windows until the depth order 
is established. The method is sufficiently general to treat concave polygons with holes. A major advantage 
to this approach is that, since it retains the polygon information, it is equally valid for both hidden 
line and hidden surface display. Subroutines for smooth shading, edge smoothing, reflectance and shadowing 
are also available when more realistic images are desired (Figure 6). Applications The following is a 
brief synopsis of some of the major application projects currently under inves­tigation. It is significant 
to note the diversity of the applications and their ability to use a variety of the graphic input and 
display routines. Since truly interactive graphics are not yet economical, our inter-disciplinary effort 
implies a potential cost-effectiveness for sophisticated graphics utilization. The graphics techniques 
have substantially enhanced the productivity and development of many of these projects even though, at 
their initiation, many of the routines were not fully developed. A. Structural Design A series of critical 
problems in structural mechanics exploiting the natural symbiotic rela­tionship between the highly effective, 
computa­tion bound, finite element stress analysis tech­nology on the one hand, and the visual, inter­active, 
dynamic computer graphic technology on the other, are being investigated. One project is concerned with'finite 
element grid optimization. The finite element analysis method is a means for analyzing structural be­havior 
by representing complex objects with a set of simple-shaped elements, i.e., triangles, quadrilaterals, 
etc. Structural equations are derived representing the contribution of each element to the total system 
response. Typically a dominant portion of the total cost for each analysis can be attributed to the input 
task of describing the structural geometry. Furthermore, badly chosen coarse element grids will not yield 
accurate solutions, but if large numbers of ele­ments are chosen, the input and computational times are 
excessive. A means must be found to reduce the input task and enhance the analytical solution techniques. 
To accomplish this, the following approach is being used. The structure is first auto­matically subdivided 
into a mesh interactively Figure 6 -Color Graphic Displays A color perspective image of a simulated 
house created using the extrusion system is shown in Figure 6a. Shadows are automatically generated using 
the hidden surface algorithm. A smooth-shaded, transparent object created with the serial section technique 
is shown in Figure 6b. (Doug Kay). The backgrounds of both figures were created by optical scanning techniques. 
94 selected by the analyst. The resulting gridwork is graphically displayed and revised as necessary 
 (Figure 7a). When all loads, support conditions and strength information has been graphically input, 
a complete structural analysis is per­ formed. The resulting stress distribution is then displayed in 
the form of iso-stress or iso-energy contours (Figure 7b). These contour lines are then used to create 
a more optimal gridwork. Although the finite-elementmethod is clearly an ideal approach for the analysis 
of arbitrary three-dimensionalstructures, its application has been hampered by the difficulty in generating 
the necessary digital descriptions of such structures. A second project involves developing a graphical 
method for the digitiza­tion, representation,and subdivision of arbi­trary three-dimensionalsurfaces. 
This enables the rapid and accurate analysis of forms ranging from architectural shell structures to 
biological structures such as a human skull. The method uses the lofting techniques previously described, 
where the serial section contours are represented by B-splines and the surface is interpolated with Cardinal 
spline functions (12). The pro­cedures used allow an accurate surface repre­sentation with only a small 
amount of data. The resulting surface can be interactively modified by the user until satisfactoryresults 
are ob­tained (Figure 4b). B. Animation A key-frame animation system has been developed which accepts 
free-form line sketches, free-form images, or two-dimensional projections of complex three-dimensional 
environments (3). The key-frames are drawn by the artist using a digitizing tablet and displayed on either 
the black and white vector scope or the color half­tone CRT. These two-dimensional images are combined 
using a multiplane cel animation technique to produce depth and motion illusions (Figure 8). The system 
allows real-time pre­ viewing by computing the in-between frames "on­ the-fly", thus providing the artist 
with instant playback of the animated sequence. All inter­action is pictorial, enabling the artwork to 
be easily edited. Several artistic films are currently being produced. C. Energy Conservation Although 
for several years, it has been possible to simulate the dynamic thermal behavior of buildings, the use 
of such simulations has not been widespread for several reasons. First, the cost of analysis has been 
excessive since a large number of man hours are required to accurately describe the building geometry. 
Second, the input requirements for the available programs are so rigid and detailed that they can not 
be used at the preliminary design stage when much of the information is not yet available. Inter­active 
computer graphics techniques can help alleviate both problems. A system allowing the graphic creation 
of complex three-dimensional building descriptions has been interfaced with multi-zone thermal analysis 
routines. Combinationsof primitive volumes are used to specify the building shell. The composition of 
each of the wall sections of the building are interactively specified and assigned to the appropriate 
planes (Figure 9). Windows and doors may be precisely located on any of the walls of the building. All 
of the required thermophysical characteristics of the building shell are automatically computed and used 
for the thermal analysis routines. The graphic procedures for defining the residential building have 
proven to be very flexible and efficient to use. D. Agricultural Tractor Accident Prevention Agricultural 
wheel tractors frequently operate on potentially hazardous terrain where overturning or other types 
of accidents occur. Up to 1000 deaths in the United States occur each year as the result of tractor 
accidents, of which two-thirds are the result of tractor overturns. The prevention of overturns, or 
at  Display of finite element grid interactively created by the analyst is shown in Figure 7a. Only 
the peri­meter contours were specified. The mesh, including the node numbering system was automatically 
created and serves as input for the analytical routines. After the stress analysis, isocontour lines 
are displayed and can be used to generate a more optimal finite element mesh (Programby Bob Haber and 
Mark Shephard).  Figure 8 -Animation Figure 8a shows a key-frame line drawing of a princess kissing 
a frog. Editing options at the artists' disposal are shown in the menu. A painted background scene for 
a multi-ccl environment is depicted in Figure 8b. (Program NEREUS by Marc Levoy, artwork by Jose Gelabert). 
 Figure 9 -Energy Conservation A composite wall section is interactively built up from a stored library 
of materials and the thermal characteristics are automatically computed (Figure 9a). The wall sections 
have been assigned to each plane and windows and doors have been attached to the thermal enclosure of 
the private residence shown in Figure 9b (Program GLAS by Rich Rogers). Figure 10 -Tractor Simulation 
The figures are graphic displays of a tractor approaching a roadside bank and turning over. The motion 
is predicted and displayed using a dynamic simulation model. Interactive graphic routines the tractor 
to be viewed from any vantage point (Program by Peter Atherton). tractor allow  96 least properly designed 
rollover protective struc­tures, will help protect the tractor operators. The general objectives of this 
research project are to develop dynamic computer simulations of agricultural tractor accidents to examine 
the many parameters of tractor design and terrain that influence accidents, in order to improve the safe­ 
ty and reliability of vehicles. To effectively comprehend the tractor motion, the mathematical simulation 
model has been combined with dynamic graphic display capability (Figure 10). The researcher can actually 
see the vehicle turn over, and visually as well as mathematically locate the actual point of impact. 
These graphic displays are being used, not only to study tractor dynamics and motion during accidents, 
but to develop an understanding of appropriate tractor operator actions to prevent accidents. Commentary 
 This paper has briefly described the input and display procedures, the operating configura­tion, and 
some of the research projects currently under investigation at Cornell's Program of Com­puter Graphics. 
Based on our two and one-half year experience, several statements can be made: 1. Almost all programminghas 
been imple­mented using FORTRAN IV under the RSX-11M multi­user operating system. Although FORTRAN has 
en­abled us to interface with many analytical rou­tines in the published literature, a higher level language, 
with recursive and interruptable capa­bilities, would prove to be much more flexible for the coding and 
debugging of interactive graphics software.  2. The mini-computer environment has proven to be generally 
satisfactory. By using efficient matrix inversion techniques, the normal limita­tions on problem size 
can be overcome. Relative­ly large scale numerical problems have been suc­cessfully analyzed in structural 
mechanics, opti­mization and energy analyses. The time require­ments are not excessive. The major restrictions 
arise from the 16 bit word size limiting the amount of core storage available to a single task (32k) 
and the precision available for cer­tain display calculations.  3. Both dynamic vector displays and 
color raster displays demand substantial amounts of data throughput; a requirement which can severe­ly 
hamper a multi-user environment. By using independent display processors (the PDP 11/34 and the E &#38; 
S picture processor, Figure 1) the total system resources can be more effectively utilized.  4. A graphics 
software package has been developed to generate images on the storage tube terminals. This package simulates 
the commands and hardware capabilities of the fast vector display. Not only has this enhanced productivity, 
particularly in the development of new graphics programs, but it can provide remote users with more powerful 
graphic display capabi­ties.  5. Each application project relies on gra­ phic input using either the 
dynamic display, the color display, or both. These projects have been developed by programmers with expertise 
in their own field but with only limited experience in graphics. Our ability to provide these research­ers 
with a comprehensive set of graphic utilities that can be easily interfaced to their analysis programs 
has proven invaluable. References 1. Forrest, A.R., "On Coons and Other Methods for Representationof 
Curved Surfaces", Computer Graphics and Image Processing,  1972, l(pp 341-359).  2. Johnson, T.E., 
"Sketchpad III, A Computer Program for Drawing in Three Dimensions", AFIPS Conference 1963.  3. Levoy, 
Marc, "A Color Animation System Based on the Multiplane Technique", Proceedings of the Fourth Annual 
Conference on Computer Interactive Techniques and Image Processing, -SIGGRAPH, 1977.  4. Newman, W., 
and Sproull, R., Principles of Interactive Computer Graphics, McGraw Hill, 1973.  5. Riesenfeld, Richard 
F., "Applications of B-Spline Approximationto Geometric Problems of Computer-Aided-Design",Ph.D. Thesis, 
Syracuse University, 1973.  6. Sutherland, Ivan E., "Sketchpad: A Man-  Machine Graphical Communication 
System", Lincoln Laboratory, MIT Technical Report No. 296, 1963.  7. Sutherland Ivan E. and Hodgeman, 
G., "Reentrant Polygon Clipping", Communications of the ACM, Vol. 17, No. 1. Jan. 1974 (pp 32-42).  
8. Sutherland, Ivan E., "Three-DimensionalData Input by Tablet:, Proceedings of the IEEE, Vol. 62, No. 
4, April 1974.  9. Thornton, Robert W., "MODEL: Interactive Modeling in Three Dimensions Through Two- 
Dimensional Windows", M.S. Thesis, Cornell University, 1976.  10. Weiler, K., and Atherton, P., "Hidden 
Surface Removal Utilizing Polygon Area Sorting", Proceedings of the Fourth Annual Conference on Computer 
Graphics, Interactive Techniques and Image Processing -SIGGRAPH, 1977.  11.. Weingarten, Nicholas H., 
"Computer Graphics Input Methods for Interactive Design", M.S. Thesis, Cornell University, 1977. 12. 
Wu, S., Abel, J., and Greenberg, D., "An Interactive Computer Graphics Approach to Surface Representation",Proceedings 
of the Fourth Annual Conference on Computer Graphics. Interactive Techniques and Image Processing -SIGGRAPH, 
1977.
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563876</article_id>
		<sort_key>102</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[A practical approach to implementing line printer graphics]]></title>
		<page_from>102</page_from>
		<page_to>106</page_to>
		<doi_number>10.1145/563858.563876</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563876</url>
		<abstract>
			<par><![CDATA[The capability of generating graphical images on a line printer is very desirable. Many ad hoc special purpose implementations exist that satisfy the needs of particular users. A single general purpose line printer graphics capability, however, compatible with widely distributed Calcomp pen plotter software, could eliminate the need for many special purpose implementations. An implementation approach is described for a set of subroutines which are designed to minimize storage requirements to maintain a complete graphical image. The software has been widely accepted in university, government, and industry environments to augment and occasionally replace pen plotting facilities.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[computer graphics]]></kw>
			<kw><![CDATA[interactive graphics]]></kw>
			<kw><![CDATA[line printer graphics]]></kw>
			<kw><![CDATA[line printer plotting]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379951</person_id>
				<author_profile_id><![CDATA[81547152956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Rumsey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Harris Corporation in Dallas, Texas]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14149558</person_id>
				<author_profile_id><![CDATA[81547878256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Roger]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Walker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Texas, Arlington]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bronson, Richard, "Submatrices and Partitioning", Matrix Methods, p. 16. Academic Press, Inc. 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Knuth, Donald E., "Information Structures", The Art of Computer Programming, Vol. 1, pp. 240-258. Addison-Wesley, Inc. 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280635</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Knuth, Donald E., "Sorting by Insertion", The Art of Computer Programming, Vol. 3, pp. 99-100. Addison-Wesley, Inc. 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Programming Calcomp Pen Plotters, California Computer Products, Inc., 305 North Muller Street, Anaheim, California, 92803. June, 1968.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Rees, Paul K., "Rotation", Analytic Geometry, pp. 91-93. Prentice Hall, Inc. 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Rumsey, John R., Roger S. Walker, Line Printer Plotting, NTIS Publication PB-248-996, August 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Williams, Gary, Roger S. Walker, Technical Report CSP-76-1, University of Texas at Arlington, January 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>361264</ref_obj_id>
				<ref_obj_pid>361254</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Williamson, Hugh, "Hidden Line Plotting Program", Communications of the ACM, pp. 100-103. February, 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A PRACTICAL APPROACH TO IMPLEMENTING LINE PRINTER GRAPHICS John R. Rumsey and Roger S. Walker ABSTRACT 
The capability of generating graphical images on a line printer is very desirable. Many ad hoc special 
purpose implementations exist that satisfy the needs of particular users. A single general purpose line 
printer graphics capability, however, compatible with widely distributed Calcomp pen plotter software, 
could eliminate the need for many special purpose implementations. An implementation approach is described 
for a set of subroutines which are designed to minimize storage requirements to maintain a complete graphical 
image. The software has been widely accepted in university, government, and industry environments to 
augment and occasionally replace pen plotting facilities. Key words and phrases: line printer graphics, 
line printer plotting, computer graphics, interactive graphics. CR Categories: 1.52, 3.20, 3.51, 3.53, 
4.22, 4.34, 4.40, 510 INTRODUCTION Many special purpose line printer graphics implementations exist, 
each tailored to the needs of a particular user. The imple­mentation of a general purpose line printer 
package is usually costly in terms of the memory required to maintain a complete image of a graphical 
representation. The number of line printer page images that must be maintained can become quite large. 
Minimization, therefore, of the data structure required to main­tain the image is important for a successful 
implementation. The techniques described herein attempt to minimize the storage required to construct 
an image. CHARACTERISTICS OF LINE PRINTER PLOTS Intuitively, it would seem that there would be differences 
between the techniques used to generate a graphical represen­tation of data on a line printer as opposed 
to generating the same representation on an x-y incremental plotter, regardless of the compatibility 
of the respective subroutine calls. To distinguish some of the differences, first consider the format 
by which characters are printed by a line printer. The resolution of a point on a printed plotting surface 
is one print position. The y axis increment is the center to center distance between characters on adjoining 
rows. This increment in the y axis will vary depend­ing on the line printer that is being used. Generally, 
a line printer may print either six, eight, or ten lines per inch. The y axis incre­ment, therefore, 
could be .166, .125, or .1 inches. The lack of symmetry in the character positioning, therefore, requires 
that the x and y axes have different scaling to insure that the y axis length will not be physically 
larger than the x axis when y = f(x) = x. John Rumsey is a lead systems engineer at Harris Corporation 
in Dallas, Texas and Dr. Walker is chairman of the Computer Science Department at the University of Texas 
at Arlington. The research was funded by the Urban Mass Transportation Administration, U. S. Department 
of Trans­portation. Permission to make digital or hard copies of part or all of this work or personal 
or classroom use is granted without fee provided that copies are not made or distributed for profit or 
commercial advantage and that copies bear this notice and the full citation on the first page. To copy 
otherwise, to 102 republish, to post on servers, or to redistribute to lists, requires prior specific 
permission and/or a fee. Siggraph 77, July 20-22 San Jose, California Another consideration is the format 
of the line printer page. Any coordinate position on the page is a function of integer values. This, 
coupled with the relatively large axis increments, represents the only major limitation in line printer 
plotting. Consider a vector that is to be plotted. The points that represent the vector will not necessarily 
be printed at the coordinate axis position that would result if the vector were plotted on a real axis. 
The point may not exist on the integer-valued coordinate axis. The point, therefore, may be plotted above, 
below, or on, the exact coordinate position. In most cases, this does not repre­sent a severe limitation. 
A vector of arbitrary slope may be plot­ted with the points falling on or near the real-valued vector 
coordinate. A minimal storage representation, therefore, of a least path generation of real-valued vectors 
on an integer-valued coordina­ted plane with appropriate scaling and implicit ordering, is central to 
the successful implementation of line printer graphics software. MINIMIZATION OF THE DATA STRUCTURE A 
data structure for accumulating a graphical image which is to be printed can be generated by maintaining 
an image of each printed page. In this environment, however, the size of the data structure could grow 
unreasonably large because the number of pages that may be required is essentially unlimited. The limits 
on the x and y axes are virtually unrestricted. For most graphical representations of data, the density 
of the plotted points is much lower than the density of coordinate positions available for plot­ting 
the representation. Consequently, the size of the data structure can be significantly decreased if only 
the actual data points that represent the linear elements of the plot are main­tained by the data structure. 
Consider that a plotted graphical representation actually consists of a finite set of vectors. But a 
vector is a linear function y = f(x). If each element of the plot can be defined in terms of a linear 
function then why is it neces­sary to represent every point of the element (i.e., linear function). It 
therefore appears that each linear function which describes an element of the plot may be represented 
in the data structure by two nodes; the initial coordinate point and the final coordi­nate point of the 
linear element. Observe that if (n) elements are to be represented, then (2n) nodes are required. The 
structure, however, can be reduced further. If given an initial coordinate position and a set of linear 
functions, then a continuous function can be created by assigning the first coordinate position of fl 
to the initial coordinate position. Thereafter, assign the first coordi­nate position of linear function 
fi to the last coordinate position of fi-1. Thus, the set of linear functions that describe the contin­uous 
function can be represented by maintaining the initial position and the subsequent fi-1 positions. Therefore, 
given (n) linear elements that describe a continuous function, the function can be represented with (n+1) 
nodes in the data struc­ture. This compares favorably with (2n) nodes if each element is treated independently. 
THE DATA STRUCTURE An algorithm, however, is necessary for finding the values SEGMENTING of i and j; 
otherwise the concept is of little use. The following One important point that must be investigated when 
defining the data structure is the format by which data is printed by a line printer. Note that all data 
required for the current line of print must be available. This implies that all of the data to pro­duce 
the plot must be available at print time (this, of course, is the primary incentive for reducing the 
size of the data structure) and the data must be represented in the data structure such that the functional 
values being printed on the current line are the maximum unprinted values along the x axis being represented. 
This normally indicates that all of the data would have to be sorted with respect to the functional values. 
The efficiency of the PLOT subroutine could be increased if the number of nodes that had to be placed 
in order could be minimized. The data structure that is defined, therefore, must not only be minimal 
in size but it must be generated by an algorithm that is a function of the ordering requirement of the 
data. Consider the following description of the development of a data structure to accomplish these goals. 
During the discussion, note that pointers are used to define the data. STRIPi is a set of pointers that 
define the highest levels in the data structure. This level of the structure contains all of the nodes 
that define an X interval or alternately and X "strip" of the data to be printed. Similarly, PAGEj is 
a set of pointers that define the second highest level in data structure. This level contains the nodes 
that define a single page of data within STRIPi. It should be noted that the set of ordered pairs (STRIPi, 
PAGEj) uniquely define each printer page of the plot. One final distinguishing characteristic of the 
continuous functions that describe the plot data on any unique ordered pair (STRIPi, PAGEj) must be established. 
Since the plotted data may range over several pages, it is necessary to define where a function crosses 
a page boundary. The continuous functions that describe the plot, however, are represented in linear 
ele­ments. But only the initial and final coordinate positions of these linear elements are stored in 
the data structure. Thus, either of the end points or one of the intermediate points of the linear element 
may cross a page boundary. In the data structure, a page boundary crossing by a linear element will be 
indicated by identifying the node corresponding to the initial coordinate position of the affected linear 
element. Each point generated by this linear element will be checked to determine the exact page boundary 
point. After the page boundary point has been determined, the final coordinate position corresponding 
to the linear function will be set to this boundary value. This node will then be flagged to indicate 
an initial position on a new page. Similarly, a new node on the current page will be inserted follow­ 
ing the initial node of the linear element that described a bound­ary crossing. This node will be flagged 
to indicate a terminal point on the current page. The coordinate value contained in the node will be 
set to the boundary value. If a continuous function begins or ends on the page being processed, the initial 
or end point is identified exactly in the same manner as a boundary. These boundary and initial conditions 
are determined as calls to the PLOT subroutine are received. For example, if the end of a function is 
specified, the current node and the node correspond­ing to the previous call are each flagged to indicate 
the termi­ nation of the previous function and the initiation of the sub­sequent function. The pointers 
i and PAGEj referenced in the discussion above defined a data structure that contained the functional 
values for the plot. The functional values could range greatly; therefore, STRIP i could represent many 
pages. A PAGEj pointer described a particular page within a unique STRIPi. Thus, an ordered pair (STRIPi, 
PAGEj) describes each unique page to be printed. Using these pointers in the conceptual design of the 
PLOT subroutine has aided the preliminary definition of a minimized data structure for representing the 
graphical data. theorem provides a solution: This is a particularly useful result because it can be 
used to deter­mine the value of i and j for STRIPi and PAGEj without knowing the number of strips or 
pages nor the submatrix location. This is exactly what is required since the number of strips and pages 
that will be generated by any particular plot is not known by the subroutine during the time that the 
data structure is being generated and values are needed for i and j. A closer evaluation of the results 
of the theorem is required if it is to be applicable in this situation. The theorem assumes the standard 
definition of a matrix A (i.e., row major order). This is not exactly what is needed. A careful evaluation 
of the definition of STRIPi and PAGEj as the ordered pair (STRIPi, PAGEj) reveals a matrix of printer 
pages where i and j specify column major order of the submatrices (i.e., in printer pages). In the results 
of the theorem the values of i and j should be exchanged. In addition, the variable specified in the 
results of the theorem must have a more meaning­ful representation for this particular problem. The actual 
matrix A of interest is composed of submatrices that represent line printer pages. The value of the ordered 
pair (M,N) is known since these values are identical to the x-y coordinate position supplied in a call 
to PLOT referenced to an origin of (0,0) and represented in line printer integer coordinate values. These 
values of M and N are: where XPAGE and YPAGE have been corrected for origin and FACT is the scale factor. 
This allows a value for the coordinate pair (i, j) to be derived in terms of line printer pages: LIST 
BLOCKING FACTOR The STRIPi and PAGEj pointers play a key role in defining a minimized data structure 
to represent the data to be plotted. The data structure, however, should be organized such that an implicit 
ordering of the data is achieved within the structure itself to eliminate the need for a time consuming 
explicitly defined sorting algorithm that must be applied when the data is printed. These pointers provide 
the first level of this implicit sort. Since STRIPi and PAGEj are an ordered pair that define the page 
within the plot on which the point in question must be located, the data ordering is already half accomplished. 
The most efficient method of utilizing these points as an ordered pair is to allow them to locate the 
list head pointer for a linked list. The linked list indicated by a particular STRIPi and PAGEj contains 
the plot data for that page. A linked list, of course, must consist of entries with a data value or group 
of data values that are interconnected by means of link nodes. It would be inefficient to link every 
node in the list because of the amount of storage that would be required for the links, since the list 
length can be long. A more suitable method in this application is to define a block of nodes, then construct 
the linked list by linking the blocks. The size of the block that is to be linked is termed the blocking 
factor. A block­ing factor of one requires substantial storage overhead because of the number of link 
nodes required. Using the linked block structures, however, there is also an additional storage overhead. 
On the average, one-half of the block size will be lost for each linked list. But for long lists, the 
storage lost per list in the last block is extremely small percentage of the total list length. An optimum 
block size, however, can be found for a linked list of n nodes. This is shown by the following theorem. 
If n data items are to be stored in each of m linked lists and each linked list is constructed of k blocks 
of capacity j words (including one link node) and an average loss per list of one-half a block size, 
then the storage required for each list 1 . {6] can be minimized by selecting a blocking factor of If 
alternate nodes in the list are utilized as links then storage utilization as indicated by the above 
theorem becomes ineffi­cient with long lists. The list does not have to be too long as the following 
demonstrates. Assuming a linked list that contains 100 data nodes, the storage required for the list 
and its links if every node is linked is: Optimizing the block size, however, produces a more favorable 
result. Therefore storage required is A comparison of 114 locations to 200 locations is most favor­able. 
An extended parameter is used to set the block size in the PLOT subroutine. DATA STRUCTURE MAP An overall 
description of the theory behind the implementa­tion of the data structure for describing a graphical 
representa­tion has been provided in the preceding paragraphs. A description of the physical implementation 
of the structure is now in order. Figure 1 provides an illustration of a memory map for the data structure. 
The user is required to pass the PLOT subroutine a storage area before plotting can commence. The upper 
bound of the area is used as the base address for calculating the list pointer locations from the ordered 
pair (STRIPi, PAGEj). There are three nodes assigned for management of each list as indicated in Figure 
1. (1) Current Buffer Address This node contains the buffer address of the last entry stored in this 
list. (2) Active Block Number  This node contains the block number where the current buffer address 
is located. (3) List Head Pointer This node points to the buffer address for the first node of the linked 
list for this page. The list pointers are allocated from the top of the buffer while linked blocks are 
allocated from the bottom of the buffer. An attempt to store a list pointer on or below the top of the 
last linked block allocated or an attempt to allocate a link list node on or above the last list pointer 
results in a 'Plot Call Array Size Exceeded' error condition. Subsequently, the size of the structure 
required for maintaining a representation of the data is calculated and this information is provided 
with the error message. GENERATING POINTS ON A LINEAR FUNCTION The exact representation of the data structure 
has been defined, together with the sets of pointers that describe the organization of the structure; 
it is now proper to describe an algorithm that will generate the points to be plotted. The set of coordinate 
positions stored in the structure represent the linear functions that constitute the continuous plotted 
functions. There­fore, the points that will be generated by the PLOT subroutine are the points that lie 
on each linear element. 104 The initiation of generating the plot image occurs when a plot call is received 
that indicates the end of the generation of the data structure and the beginning of the access cycle. 
During the generation of the data structure, the maximum values for i and j (PAGEj) are calculated, thus 
there are (i) (j) pages in the plot. To access the data for each page of the plot until all pages have 
been accessed is accomplished with the set of ordered pairs: For any given page(m, n), the points that 
lie on each linear element of the plot data for the page must be generated since the nodes that are maintained 
in the data structure only represent the beginning and ending points of a continuous concatenation of 
linear elements that describe a function. In addition, as mentioned earlier, the last node of a function 
is flagged, thus ending the function. The points on each element of a function (other than those describing 
the linear elements), therefore, are not represented in the data structure. These points must be generated 
by the PLOT subroutine. Consider that a linear ele­ment may have any slope, but the resulting printed 
representa­tion may have to consist of several noncontinuous sequences to most accurately approximate 
the linear element. This results because the initial and final coordinate values of the linear function 
represent a real-valued function, but the only co­ordinate values available for representation of the 
linear element on a line printer page are integer-valued coordinates. The points that must be generated, 
therefore, must represent the real-valued element as nearly as possible on an integer-valued coordinate 
plane. This may be considered as the inverse function of a first degree least squares curve fit. A unique 
solution to this problem is available if a delta-x and a delta-y value are generated so that the ith 
point on a linear element is described as follows: The obvious difficulty, of course, is the calculation 
of the delta-x and delta-y values.These values must be a function of the beginning and ending coordinates 
of the linear element and a function of the integer value of the coordinate grid. In addition, the X 
and Y integer grid values may be different and indeed they are in this case with a line spacing of six 
lines per inch and a character spacing of ten lines per inch: There are three cases that must be considered 
in the calculation of the delta-x and delta-y values. The first case occurs when the slope of the linear 
element as determined by (X1, Y1) and (Xn, Yn) is zero. For a slope of zero we have: The second case 
occurs when the slope approaches infinity. The third case, however, is not as apparent. The linear element 
described by (X1, Y1) and (Xn, Yn) can be considered as the radius (R) of a right triangle with the X 
axis length equal to I Xn -X1 Iand the Y axis length equal to I Yn -Y1 Ias indicated below in Figure 
2.  Now to ensure that a point is generated for all coordinate values required to represent the linear 
element on the integer­valued axis, the minimum projection must be selected and the delta-x and delta-y 
values follow: Choosing x-increment = 1/ICOLS and y-increment = 1 provides the proper delta-x and delta-y 
values for the line printer plot. One of the most interesting results of this method is that the values 
of delta-x and delta-y need only be calculated once for a linear element. Each point on the element is 
then calculated by a simple addition. The derivation above described a method for finding each point 
on a linear element after the proper delta-x and delta-y values are established. During the print cycle 
of the PLOT sub­routine, each blocked link list is accessed through the STRIPi and PAGEj pointers and 
the points for each linear element are generated using the initial and final coordinates of the linear 
element. A two dimensional array is maintained that describes a single printer page such that one byte 
is allocated for each print position. As each point on a linear element is generated, the X and Y values 
are used as indexes into this byte-valued page image. As previously mentioned, the STRIPi and PAGEj pointers 
effectively provide the first phase of the ordering of the data to be printed. The ordering was a page 
oriented ordering. The second phase of the ordering occurs here when a point is placed in the byte-valued 
page image array and the final ordering for that point is complete. The ordering of the data is thus 
accom­plished by an implicit two phase address calculation sort [3]. The sort is not explicitly implemented 
but it is derived by the nature of the data structures. The byte-valued page image array is refreshed 
for each page of the plot, thus the pages are each uniquely constructed. EXAMPLE PLOTS The following 
examples illustrate some of the capabilities of the set of subroutines described in the preceding pages. 
Figure 3 was generated by the HIDE [8] algorithm for producing hidden line plots on a Calcomp pen plotter. 
The graph illus­trated in Figure 4 is representative of a plot using the SCALE, LINE, and AXIS subroutines. 
The contour map in Figure 5 is an example of a practical use of Calcomp compatible line printer plotting. 
The implementation of the contour program [7] was aided by the ability to generate plots quickly and 
economically.  REFERENCES 1. Bronson, Richard, "Submatrices and Partitioning", Matrix Methods, 2. Knuth, 
Donald E., "Information Structures", The Art of Computer Programming, Vol. 1, pp. 240-258. Addison-Wesley, 
Inc. 1973. 3. Knuth, Donald E., "Sorting by Insertion", The Art of Computer Programming, Vol. 3, pp. 
99-100. Addison-Wesley, Inc. 1973. 4. Programming Calcomp Pen Plotters, California Computer Products, 
Inc., 305 North Muller Street, Anaheim, California, 92803. June, 1968. 5. Rees, Paul K., "Rotation", 
Analytic Geometry, pp. 91-93. Prentice Hall, Inc. 1970. 6. Rumsey, John R., Roger S. Walker, Line Printer 
Plotting, NTIS Publica­tion PB-248-996, August 1975. 7. Williams, Gary, Roger S. Walker, Technical Report 
CSP-76-1, University of Texas at Arlington, January 1976. 8. Williamson, Hugh, "Hidden Line Plotting 
Program", Communications of the ACM, pp. 100-103. February, 1972. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563877</article_id>
		<sort_key>107</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[A simple approach to computer aided milling with interactive graphics]]></title>
		<page_from>107</page_from>
		<page_to>111</page_to>
		<doi_number>10.1145/563858.563877</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563877</url>
		<abstract>
			<par><![CDATA[This paper describes CAMILL, a system for computer aided milling of ship hull models defined with interactive graphics. The major hardware components of CAMILL are a mini-computer based refresh display and a three axis numerically controlled milling machine. For hardcopy documentation there is a large flatbed plotter. The two major software components are an interactive display program and a cutting program. The interactive display program is the human interface and provides capabilities for creating and modifying the ship design. The cutting program is executed in an intelligent terminal interfaced to the milling machine. The data used by the cutting program is generated by the display program and stored on a magnetic cassete tape. This cassette is transferred to the intelligent terminal for use by the cutting program. The main function of the cutting program is to direct the milling of the desired ship hull.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P333857</person_id>
				<author_profile_id><![CDATA[81100347503]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Satterfield]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[U. S. Naval Academy, Annapolis, Md.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77046865</person_id>
				<author_profile_id><![CDATA[81406599257]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Francisco]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rodriguez]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[U. S. Naval Academy, Annapolis, Md.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39030986</person_id>
				<author_profile_id><![CDATA[81100174598]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Rogers]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[U. S. Naval Academy, Annapolis, Md.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A Simple Approach to Computer Aided Milling Permission to make digital or hard copies of part or all 
of this work or personal or classroom use is granted without fee provided that copies are not made or 
distributed for profit or commercial advantage and that copies bear this notice and the full citation 
on the first page. To copy otherwise, to republish, to post on servers, or to redistribute to lists, 
requires prior specific permission and/or a fee.Siggraph 77, July 20-22 San Jose, California with Interactive 
Graphics Steven G. Satterfield Francisco Rodriguez David F. Rogers Computer Aided Design and Interactive 
Graphics Group U. S. Naval Academy Division of Engineering and Weapons Annapolis, Md. 21402 ABSTRACT 
 This paper describes CAMILL, a system for computer aided milling of ship hull models defined with interactive 
graphics. The major hardware components of CAMILL are a mini-computer based refresh display and a three 
axis numerically controlled milling machine. For hardcopy documentation there is a large flatbed plotter. 
The two major software components are an interactive display program and a cutting program. The interactive 
display program is the human interface and provides capabilities for creating and modifying the ship 
design. The cutting program is executed in an intelligent terminal interfaced to the milling machine. 
 The data used by the cutting program is generated by the display program and stored on a magnetic cassete 
tape. This cassette is transferred to the intelligent terminal for use by the cutting program. The main 
function of the cutting program is to direct the milling of the desired ship hull.  Computer Specialist 
Electronics Engineer Professor of Aerospace Engineering &#38; Director of CADIGG I. INTRODUCTION numerically 
controlled (NC) milling. The emphasis of CAMILL is ship hull design This paper describes CAMILL, a and 
the automatic milling of a ship hull system for computer aided milling of models. Testing of a ship 
model in a three dimensional objects defined with towtank is comparable to testing an interactive graphics. 
CAMILL is intended airplane model in a wind tunnel. Even to be a simple approach to the problems though 
the primary product produced by of combining interactive graphics and CAMILL is ship hull models, the 
ideas and 107 techniques used are general enough for production of a wide range of three dimensional 
objects. The major hardware components of CAMILL are an interactive refresh graphics system and a numerically 
controlled three axis milling machine. The graphics system is an Evans &#38; Sutherland Computer Corporation 
PICTURE SYSTEM, driven by a Digital Equipment Corporation PDP-11/45. User interaction with the graphics 
system is primarily through the use of function switches, The actual control dials and a tablet. milling 
of the ship hulls is performed with a Pratt and Whitney TRIMAC XV computerized numerically controlled 
three axis milling machine. To supplement the milling machines control panel and act as a front end processor, 
a Tektronix 4051 Graphic System has been interfaced to the TRIMAC mini-computer controller. For obtainina 
high resolution hard copy plots at various stages of the design process, there is a large (4'x8') XYNETICS 
flat bed plotter which is controlled off line by magnetic tape. The traditional approach to automatically 
milling a ship hull isthrough part programming. Part programming is similar to graphics programming in 
that it consists of a high level language such as APT (Automatic Programmed Tools) which is oriented 
to numerically controlled machines. Machine independence of the APT program is maintained with a machine 
dependent "Post Processor . The Post Processor converts the machine independent output of the APT program 
into machine dependent code. This approach is satisfactory when the overhead of writing a specific APT 
program may be spread over large numbers of the same part. However, in the area of ship design, only 
one model of a particular design is normally needed. Thus, the traditional approach requires that the 
user also become an APT part programmer. The approach taken with CAMILL is to use interactive graphics 
as the human interface. This approach allows the ship designer to concentrate on designing the ship rather 
than on the details of APT ----r programming. The two major software components consist of an interactive 
display program and a cutting program. The graphics program uses the Picture System to allow the ship 
designerto create and manipulate lines which represent the ship hull design. When the design is ready 
for milling, a data file is generated which transferred by is magnetic tape to the cutting program. The 
cutting program is executed in the 4051 and directs the milling process through the TRIMAC controller. 
This on-line cutting is another variation from the traditional approach, which is to produce a paper 
tape from the APT-post processor combination. This paper tape is then read by the NC machine controller 
to perform the milling. II. DISPLAY PROGRAM The PICTURE SYSTEM driven by the PDP-11/45 is a general purpose 
interactive graphics system for the display of two and three dimensional objects. A brief summary of 
the PICTURE SYSTEM specifications is given below. Driven by PDP-11/45 32k memory. 21" Picture display 
screen. Hardware matrix processor for performing translation, rotation, perspective. Hardware clipping 
in three dimensions. Hardware character generator. 16k Refresh buffer. Digitizing tablets and pen (11"x11" 
and 30"x40"). 8 Analog to digital control dials. 16 Digital function switches. Software support for FORTRAN. 
Since the primary purpose of CAMILL is ship hull design, the display program is oriented toward use by 
naval architects. The basic design of a ship hull can be described by three sets of lines. The three 
sets are the body lines, the water lines, and the buttock lines. Body plan lines (also called station 
lines) are the vertical lines representing the hull shape of various sections along the length of the 
ship (see Figure 1). Water lines are horizontal contour lines along the depth of the ship (see Figure 
2). Buttock lines are also contour lines except they are vertical and along the length of the ship (see 
Figure 3). The body plan lines and their spacing along the ship s longitudinal axis are assumed to be 
fundamental to the design of the ship. This assumption allows the other two types of lines to be automatically 
generated from a set ofbody plan lines. The display program also has the capability of generating a three 
dimensional view of the hull. This 3-D view may be either perspective (see Figure 4) or orthographic. 
The display program provides the designer with capabilities for displaying and modifying the three types 
of lines. This interaction is done through the tablet and menu selection. User interaction with the 3-D 
view is provided through use of the dials to perform 108 rotation and translation about and along the 
X, Y, Z axes. An additional dial is used to control sectioning which allows the display of a thin slice 
of the 3-D hull. BODY LINES  accomplished by making a large scale plot. The XYNETICS plotter allows 
drawings up to 50 inches by 89 inches. Thus, to verify a set of lines, the designer need only select 
a set of lines and initiate the creation of a plot file. The plot file is later transferred to magnetic 
tape and plotted at the desired scale. By plotting the lines at a large scale, any irregularities in 
the smoothness or fairness of the lines will be much more apparent than when viewed on the refresh display. 
CAMILL BUTTOCK LINES CREATE I  DELETE ADD PT Figure 1: Body plan lines. WATER LINES CAMILL Figure 
2: Water lines. The body plan lines may be entered as points from an external file, directly digitized 
from the tablet or generated abinitio using B-spline curves. From the data points, a smooth curve is 
generated which represents the desired line. The curve can then be manipulated using the polygon points 
which generate the B-spline curve. Since B-spline techniques are used throughout the CAMILL display program, 
the storage requirements are reduced by storing only the polygon points. The B-spline polygon points 
also 109 provide convenient "handles" for interactively manipulating the various ship lines. As a particular 
design nears completion, the designer may want to verify the correctness or fairness of the lines. This 
verification can be K-l\\ \  Figure 3: Buttock ines. CAMILL  PERSPECTIVE XTRN 0 YTRN 0 ZTRN -4i i% 
65 XROT 90 YROT 0 ZROT 9 Figure 4: 3-D perspective. When the design is complete, thedisplay program 
can be directed to create a "milling file". The milling file isessentially the path to be followed bythe 
cutting head of the NC millingmachine. The milling file is transferredby a magnetic tape cassette to 
the 4051processor which directs the actualcutting. The contents of the millingfile is primarily the water 
lines. These lines provide a straight forwardtechnique for milling the ship hulls.The technique is to 
sort the linesaccording to depth and cut the hullupside down. The display program mustperform two functions 
in creating themilling file due to limitations in memorysize-of the 4051 and the sequentialnature of 
the 4051 cassette tape. The first function is to sort the water lines according to depth. The accuracy 
of thefinished product is determined by thenumber of water lines put into the milling file. Therefore, 
the second function is to generate enoughintermediate waterlines to produce thedesired accuracy. III. 
CUTTING PROGRAM The TRIMAC milling machine and theTektronix 4051 are the two main hardware components 
that execute the cuttingprogram. The cutting program has threemajor functions. First, it acts as a "Post 
Processor" by converting themilling file into TRIMAC machinecommands. Second, the cutting programuses 
the machine commands to actuallydirect the cutting of the model hull.Third, the cutting program assists 
themill operator in machine setup andprovides him with additional controlduring the milling process. 
A brief summary of the NC machinespecification is shown below. Travel Capacity:Table Travel -X axis, 
54" ( 1371 mm)Carriage Travel -Y axis,28" (711 mm)Vertical Slide Travel -Z axis,24" (609 mm). Accuracy: 
.001" or (0.0254mm). Resolution (smallest step):0.0001" or (0.001 mm). Paper tape input ofmachine commands. 
 A brief summary of the Tektronix 4051capabilities is shown below. Storage tube graphicscapabilities. 
BASIC programming language. Serial interface (RS232). Institute of Electronic and Electrical Engineers 
(IEEE),General Purpose Interface Bus (GPIB). Cartridge Magnetic Tape (DC300). The hardware interface 
between the TRIHAC controller and the 4051 is accomplished by replacing the standardpaper-tape reader 
with an interface tothe General Puroose Interface Bus (GPIB) of the 4051. The effect of this connection 
is to use the GPIB to simulate the normal paper tape input of theTRIMAC. By this simulation, nomodification 
of the standard NC machine -hardware or software is needed. Figure 5 shows the hardware configuration. 
 Figure 5: TRIMAC/4051 Hardware configuration. The process of converting thedisplay graphic curves (milling 
file) toNC machine commands must consider certain physical restraints. Since a cuttingtool can not be 
infinitesimally small,the path of the tool (cutter path) andthe graphic curve are not the same. Thepoint 
on the cutter tangent to thesurface (point of contact of the cutterand work surface) varies as the cutter 
ismoved along a curved surface. Therefore,the cutting program makes allowances forthese variations so 
that the point on thecutter tangent to the work surface willdescribe the desired line to be cut. Another 
factor is that there are not an infinite number of paths available 110 when positioning the cutting tool 
befbre IV. SUMMARY a cut. In positioning the cutter for a new cut, the cutter and spindle assembly 
 cannot be allowed to hit the work or any clamps used to hold the work. To solve this problem, the 
cutting of the ship hull is done along water lines with the ship upside down. This method of cutting 
 offers the least interference, longer continous cuts, and no repositioning of the model during the 
cutting operation. During execution of the cutting program, the 4051 is the "master" while the NC mill 
operates in a block-by-block "slave" mode. In block-by-blockmode the NC mill inputs one block that contains 
the coordinates of one point, executes that block and waits for more instructions from the 4051. The 
program begins by helping the mill operator with setup procedures. The setup information displayed for 
the operator consists of the overall dimensions of the model to be cut, the "set point", and the number 
of water lines. The overall dimensions assist the operator in positioning and selecting the block of 
material to be used. The "set point" is used to initially position the tool and define the coordinate 
system in reference to that location. The number of water lines is used as a guide to selecting the number 
of rough cuts and the types of tools. Next the operator enters physical milling parameters such as 
the feed rate, spindle speed, dimensions of material to be used, and cutter diameter. The feed rate 
is the speed at which the cutter head (tool) moves relative to the work. The spindle speed is the speed 
at which the tool rotates. Since all waste material cannot be removed in one pass, several rough cuts 
are needed. The number of rough passes will be determined by the size of the material used to produce 
the model, and the diameter of the cutter. Cutter diameter is also used to compute the actual cutter 
path to compensate for the point at which the cutter is tangent to the work. For each water line, 
successive cuts are made until all stock material has been removed. When the setup is completed the 
 operator gives the start command via the keyboard. After commanding the NC machine to start running, 
the 4051 inputs the coordinates from the milling file stored on its magnetic tape cassette, converts 
them into the NC machine code, and outputs the machine code to the NC mill. After the right side is 
cut along a water line the 4051 reflects the line and the left side is cut. This reflection is possible 
since the assumption is made that ship hulls are symmetrical. After cutting each half line the cutter 
is moved clear of the work in order to be repositioned for the next cut. The approach used in the 
CAMILL system is to fully integrate interactive graphics and NC milling for a particular area of interest. 
By limiting the area of interest to hull design, the display program is designed such that the user need 
not become involved with graphics or part (APT) programming. The use of interactive graphics as the human 
 interface allows the user to work with familiar terms and concepts. The addition of the intelligent 
terminal to the TRIMAC controller provides an interactive "firmware" post processor for on-line milling. 
It also provides the NC mill operator assistance by extending the standard operator console. This assistance 
is provided during both the setup procedures and the milling process. Thus, the cutting program forms 
the bridge between the display program and the NC mill controller. 111  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563878</article_id>
		<sort_key>112</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[GPGS]]></title>
		<subtitle><![CDATA[a device-independent general purpose graphic system for stand-alone and satellite graphics]]></subtitle>
		<page_from>112</page_from>
		<page_to>119</page_to>
		<doi_number>10.1145/563858.563878</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563878</url>
		<abstract>
			<par><![CDATA[GPGS is a subroutine package offering powerful and versatile support for passive and interactive vector graphics, for time-sharing, batch, and stand-alone minicomputer systems. The package is computer, language, and operating system, as well as display device independent. Its key purpose is to allow for transportabiliit of programs and programmers by providing easy to learn, high level features. The applications programmer writes his program once and then executes it on any supported graphics equipment without recompiling or relinking it. Device-independence was implemented by dividing GPGS into a device-independent part invoked by the applications programmer, and internal, "device drivers", one per display device. Like the GSPC "Core System" whose design it influenced, GPGS is a general purpose package. It has a subset of graphics facilities to handle output of line and character primitives with attributes such as line style and character size, and input from interaction tools such as lightpens, keyboards, valuators, and function keys. It also supports 2D and 3D viewin transformationss for clipping and window to viewport mapping, and coordinate transformations.Unlike the GSPC Core System, GPGS also includes a set of basic features for modelling objects which allows definition of device independent masters called seudo picture segment. These are distinguished from normal, device (DPU) dependent pictur segments into which primitives and their attribute-value settings are ordinarily compiled. These masters may be instanced subject to affine transformations (translate, rotate, and scale) to create a typical master-instance hierarchy. The hierarchy may be stored in a disk based library or compiled into a normal picture segment for output to a display device.The images of objects stored in device dependent picture segments may be transformed on the display surface by v port (image) transformations. These typically allow use of hardware transformation capabilities for dragging or tumbling object images.Host/satellite graphics is accommodated by having the device independent part of GPGS in the host and splitting the device drivers across host and satellite. At the source code level it therefore makes no difference on which.configuration a program will be executed.Among the existing implementations are versions written in assembler for the IB 360/370 and the PDP 11, in both stand-alone and satellite mode, and under a variety of operating systems. They support plotters, storage tubes, and high performance refresh displays. FORTRAN based implementations exist for the Univac 1108, the PDP 10, and a Harris minicomputer.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[device independent graphics]]></kw>
			<kw><![CDATA[graphics subroutine package]]></kw>
			<kw><![CDATA[interactive graphics]]></kw>
			<kw><![CDATA[satellite graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379952</person_id>
				<author_profile_id><![CDATA[81100359544]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[L.]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Caruthers]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Nijmegen, Nijmegen, The Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP48024843</person_id>
				<author_profile_id><![CDATA[81343507365]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[van den Bos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Nijmegen, Nijmegen, The Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40027084</person_id>
				<author_profile_id><![CDATA[81452592989]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[van Dam]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Brown University, Providence, Rhode Island]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[IBM - Graphics Subroutine Package (GSP) for FORTRAN IV, COBOL, and PL/I; form GC27-6932.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Woodsford, P. A., The Design and Implementation of the GINO 3-D Graphics Software Package, Software - Practice and Experience, Vol. 1 (October 1971), p. 335.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Caruthers, L. C., and van Dam, A., GPGS User's Tutorial, Informatica, Faculty of Science, University of Nijmegen, The Netherlands, October 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Groot, D., Hermans, E., Caruthers, L. C., and Schwartz, J., GPGS Reference Manual, Rekencentrum, T. H. Delft and Informatica, Faculty of Science, University of Nijmegen, The Netherlands, May 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[SIGGRAPH GSPC, First Report on Graphics Standards, Proceedings of SIGGRAPH 77, San Jose, July 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Skaland, M., Zachrisen, M., High-Level Graph-Plotting Routines for GPGS-F, Preliminary Specifications, RUNIT Report, University of Trondheim, Norway, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>804734</ref_obj_id>
				<ref_obj_pid>800143</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Wallace, V. L., The Semantics of Graphic Input Devices, Proceedings ACM Symposium on Graphic Languages, 26-27 April 1976, Miami Beach, Florida, pp. 61-65.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>804731</ref_obj_id>
				<ref_obj_pid>800143</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Foley, J. D., Picture Naming and Modification: An Overview, Proceedings ACM Symposium on Graphics Languages, 26-27 April 1976, Miami Beach, Florida, pp. 49-53.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[GPGS-F User's Guide, RUNIT Computer Centre, University of Trondheim, Norway, September, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 GPGS A Device-independentGeneral Purpose Graphic System for Stand-alone and Satellite Graphics  van 
Dam J. van den Bos Informatica/CcmputerGraphics Group Program in Computer Science Faculty of Science 
Brown University University of Wijaegen Providence, Rhode Island ABSTRACT GPGS is a subroutine package 
offering powerful and versatile support for passive and interactive vector graphics, for time-sharing, 
batch, and stand-alone minicomputer systems. The package is computer, language, and operating system, 
as well as display device independent. Its key purpose is to allow of programs and programmers by providing 
easy to learn, high level features. The applications programmer  device-independent part invoked by 
the applications programmer, and internal, 0device  writes his program once and then ezecutes it on 
any supported graphics equipment without or relinking it. Device-independence uas implementedby dividing 
GPGS into a one per display device. Like the GSPC "Core System" whose design it influenced, GPGS is 
a general purpose package. It has a subset of graphics facilities to handle output of line and character 
primitives with attributes such as line style and x and function keys. It also supports 2D and 3D window 
to viewport mapping, and coordinate transformations.  These are distinguished frca normal, device (DPU) 
dependent ERiceUr segments into which primitives and their attribute-value settings are ordinarily compiled. 
These masters may be instanced subject to affine transformations (translate,rotate, and scale) to create 
a typical master-instance hierarchy. The hierarchy may be stored in a disk based library or compiled 
into a normal picture segment for output to a display device.  Unlike the GSPC Core System, GPGS also 
includes a set of basic features for modelling objects which alloas definition of device independent 
masters called picture . The images of objects stored in device dependent picture segments may be transformed 
on the display surface by These typically allow use of or tumbling object images. Host/satellitegraphics 
is accommodated by having the device independent part of GPGS in the host and splitting the device drivers 
across host and satellite. At the source code level it therefore makes no difference on which.configurationa 
program will be executed. Among the existing implementationsare versions written in assembler for the 
IBE 360/370 and the PDP 11, in both stand-alone and satellite mode, and under a variety of operating 
They support plotters, storage tubes, and high performance refresh displays. based implementations exist 
for the Univac 1108, the PDP 10, and a Harris minicomputer. Keywords and Phrases: interactive graphics, 
device independent graphics, graphics subroutine package, satellite graphics CR Categories: 8.2, 4.29 
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Siggraph 
77, July 20-22 San Jose, California   112 1 INTRODUCTION GPGS offers high level graphics support easily 
accessible to high level language programs. The subroutine call mechanism has been employed in preference 
to new language primitives as the easiest extension mechanism. Thus any (mini) computer with FORTRAN 
is a possible candidate for a GEGS implementation. GPGS interfaces to the operating system and handles 
all ccmmunications and data conversion problems for passive and interactive physical devices. The resulting 
environment and device independent graphics application programs may be transported without change (given 
 identical The design started as a joint effcrt of the Universities of Nijmegen and Delft, with consulting 
provided by Cambridge University. It was meant to supersede  such device dependent packages as for 22_0»s 
and Calcomp's well  GSP Cambridge and several other locations in the O.K., experience with machine 
and device known plotting subroutines. independent graphics had already proved successful, with the 
Cambridge GINO-3 [2] system. Rather than reiapleoent GINO for new hardware being acquired by all three 
Universities, it was decided to provide more extensive facilities and improve begun in  1971 on an 
IBH with a PDP-11/45 PDP-11/45 in standalone aode at Delft. In  satellite at Nijmegen and on a Parallel 
the graphics group at the computing center at the University of in Norway, made an ANSI PORTRAN implementation 
fcr the Univac 1108 of a large subset of GPGS. Their GPGS-F is based on the Delft PDP implementation. 
Additional versions of GPGS exist in countries as fax apart as Germany and India (the latter on a PDP 
10); the official version is being licensed at nominal cost. Altogether the system runs in production 
in several dozen installations. 2 GIOBAL   primary GPGS design decision was to create a instead of 
a new graphics language cr graphics extensions to an existing language. A subroutine package is easier 
to design and implement than language extensions, simpler for programmers to learn, and easily extended 
by adding more subroutines. The ease of implementation also allowed for more efficient assembler language 
implementations on different computer systems. The obvious disadvantage of a subroutine package is its 
limited, awkward syntax. The subroutines included in GPGS were chosen to be just far enough removed 
from the hardware to provide device independence and still allow the applications programmer to control 
the hardware of an advanced CRT display reasonably efficiently. An additional guideline for choosing 
which features to include in GPGS was to make the package general and rich [3, 4]. At the same time, 
the design would be modular, to minimize the cost of learning and using a limited subset of the full 
system. The features included are those required or generally useful for implementing a powerful graphics 
"Core System" Unlike the designers of the GSPC Standard, the GPGS designers felt a basic modelling component 
to be generally useful as well: both subsystems are overviewed in Sections 4 and 5. The graphics subsystem 
includes line and text output primitives and their attributes (line style, intensity, character size, 
etc.), 2D and 3D windowing  and clipping, and perspective and projections. The modelling subsystem 
allows specification of an object as a hierarchy of previously defined picture segments, with inclusion 
of picture segments controlled by placement (instancing) transformations (translation, rotation, and 
scale) and a transformation stack. The hierarchy is always compiled to a single device dependent picture 
segment for output purposes. To aid viewing and/or modelling, (clipped) images of objects may be post-transformed 
on the display surface with hardware facilities for dragging or tumbling, using Provisions for more 
specialized facilities such as hidden-line removal, data structure support beyond n-level segment hierarchy, 
and animation were not included. Note that GPGS is a rich, stand-alone package with over a hundred subroutines, 
which may have special purpose packages built on top. GPGS-F, for example, supports a high level plotting 
package (6]. When designing the subroutines themselves, the key concept was simplicity. The mnemonic 
name of a subroutine indicates what its function is, and what type of 113 entity it operates on; for 
example, means select SELLIB(I) means select library I. Each  subroutine has as few arguments as 
 GPGS supplies reasonable default values to allou the unsophisticated user to have to learn only a few 
calls.   To avoid having to urite and load a complete device dependent package for each output device 
on uhich a picture is to be displayed, GPGS as a device independent package has a common, shared device 
independent part and as many device dependent device (to be loaded at execution time) as there are devices 
for that implementation (see figure 1)o To the applications programmer this means in that he can write 
his graphics program once and use it uith different graphics devices without changing the source code 
or relinking his program.  The applications programmer defines objects in user coordinates as Ejiclte 
composed of primitives (picture These include lines and text and previously defined sub-objects pseudo 
 He then specifies of objects (images) to be plotted on an idealized output device. In reality, the device 
independent part of GPGS uses the setting of the vie transformation parameters (including type of projection 
if 3D. clipping vieuport) to compile a (clipped) device independent image of the object. This intermediate 
form is then further mapped by a specific device driver onto a of an actual output surface.  include 
plotters, microfilm storage tube displays and steered beam CRT refresh displays. By specifying "normalized 
device coordinates" which are fractions of actual physical dimensions of the displaysurfaces, the applications 
programmer need not be concerned about real device dimensions and can dram device independentpictures 
in user coordinates.  DEVICE  The idealized device concept is also appropriate for describing the GPGS 
scheme for handling input from the console operator. Unlike most other high level packages which are 
primarily oriented touards plotters and storage tubes with limited input capability, GPGS designed to 
handle powerful refreshed s with a wide variety of input tools such as lightpens, joysticks, tablets, 
and compatibility from simple displays to pouerful ones is achieved automatically since GPGS handles 
the superset of facilities of the most powerful commercially available vector displays. compatibility 
from more complex to simpler graphics devices is provided through sigulatiPo of higherlevel (harduare) 
facilities carried out bydevice drivers. For exaaple, a lightpen may be simulated with cursor crosshairs, 
a dial with a keyboarded value, etc. In this way, an applications program oay still run essentially 
unchanged on a simple device, but with an altered slower) operator interaction. The GPGS idealized 
device includes all the basic input devices proposed by Ballace It supports the following single  
input tools: refresh clock, alphanumeric lightpen for picking, and alarm. It also has at least one tool 
in each of the following classes of function switches, dials (1 tracking cross and data tablet (2 dimensions), 
and joystick (3 Each single tool or class of tools (including the simulated ones) returns appropriate 
information to the applications program in a specific format; function switches return their dials return 
fractions 0 and  the lightpen returns a name stack, etc.   MANAGEMENT the segment has been defined. 
The segment as a whole is the GPGS unit of As part of solving the problem of interfacing graphics programs 
to the operating envircnment, GPGS performs applications prcgrau requested manipulations of the following 
graphics resources: graphics devices with their associated drivers, picture buffers, and picture libraries. 
The sanipulations include initialize, select, clear, release, and status inquiry. Output buffers and 
devices nay be sequentially selected as the current one; multiple input tools may be simultaneously enabled. 
Pictures may be stored off-line in picture libraries which are controlled by the applications programmer 
much in the same way as the device and buffer resources. Indeed libraries can be thought as extensions 
of buffers. Thus one can build a picture on disk rather than using a core buffer, and subsequently either 
send the picture directly from the library to a storage tube, or overlay a piece of the applications 
program to create a refresh buffer. Libraries are therefore particularly useful for making large pictures 
on small computers, or saving standard menus or standard drawing symbols (picture parts). To allow the 
applications program to find the properties and status of its currently allocated resources, and to retrieve 
previously established attribute settings, GPGS has inquiry facilities for returning execution environment 
information to the applications program. Inquiry can be used by an optionally specified applications 
program subroutine which receives control on the occurrence of an error condition. E ITS.__I PCTOIR_SGgEBTS, 
  Using GPGS, an applications programmer specifies an object as a ccllection of output primitives called 
ntug-. defined by manipulating an idealized drawing stylus in a 2D or 3D user coordinate system. Among 
the picture elements are individual lines and polyline sequences, character strings, and markers (special 
characters used for point r  plotting). like line style and width, character size and spacing, color, 
intensity, or blinking are used to modify the output characteristics of these basic picture elements. 
All picture elements and their attribute-value specifications are collected in one or more named picture 
egetial. Individual elements in the picture segment may not be altered after manipulation, for purposes 
of deleting or extending its set of elements as a logical unit. To alter the contents of a segment the 
programmer has to regenerate it. The only other manipulation of a picture segment allowed is to change 
its associated segment attributes (visibility, lightpen sensitivity (pickability), and viewport transformations). 
These attributes are global for the picture segment and may be changed any time after the creation of 
the picture segment has begun and before it has been deleted. Objects specified to GPGS as picture segments 
are compiled by device independent GPGS and the appropriate device driver into display device dependent 
code. This display file (for refreshed displays) will typically be a chain of buffers, each linearly 
segmented into picture segments. Each segment contains a header where the segment attributes are stored 
for subsequent modification. 4.2 VIEHING TRANSFORnATIONS  To produce one or more "snapshots" or views 
of an object on an output device(s), the applications programmer first sets the proper viewing transformation 
conditions' and then defines the object as one or more picture segments. For 3D, he specifies the type 
of projection to be used (perspectiveor axonoaetric), a window and a viewport. The window is a rectangle 
in 2D, or a parallelepiped or rectangular pyramid in 3D, determining the limits of the user coordinate 
space in which the object is defined that will be displayed (if clipping is enabled). the portion of 
the display surface on which the contents of the window are going to be mapped on. Viewport boundaries 
are specified device independently in fractional normalized device coordinates. As explained in Section 
2.2, the picture elements in each picture segment are successively passed through the GPGS viewing transformation 
pipeline where they are (optionally)clipped to the boundaries of the window, and then mapped to the viewport 
by a device driver which produces actual device dependent coordinates. Viewport Transformations are 
a facility introduced by GPGS primarily for refresh displays to take advantage of hardware facilities 
for translation (most displays  115 support relative vectors), or even 2D or 3D rotation (via hybrid 
cr digital transformation hardware) Since typical transformation hardware affects only DPC it can be 
 used only after the entire device independent viesing transformation pipeline described above has 
been applied to produce DPO code consisting of clippedpicture elements mapped to a viewport. The picture 
segment contains in its header instructions to load transformation registers. The vieuport transformation 
changes only these instructions in the header. As an example, in the simple case of 2D translaticn (for 
dragging) using relative coordinates, the picture segment of relative DPU primitives have an initial 
absolute move it its header. It should be noted that even for DPU°s  lacking transformation hardware, 
viewport transformations are a limited but efficient facility because they affect a clipped image 
of an object, with typically many fewer picture elements than the original object bad, Thus  the console 
 operator can select a piece of his object using the viewing transformation pipeline thereafter manipulate 
it on the screen with vieuport transformations, rather than with the more expensive viewing transformation 
pipeline.  If the user has a hierarchical object data may mirror this application oriented hierarchy 
in device independent  GPGS definitions of pseudo These may be inserted as many times as desired in 
a normal picture segment. they may be arbitrarily nested,,  ith a classical master/instance reference 
scheme, including the ability to use translation, and scale transformations to properly place a subpicture 
instance in a higher level one.  High level facilities for stacking, saving, and restoring 4 x homogeneous 
coordinate transformations  exist, as as pre- Bell for and post-oultiplying for matrix composition 
and matrix vector multiplication, Pseudo picture segments, ouch like macros, may be copied directly 
(subject to the instancing transformation) as they are specified inside the higher level (pseudo) picture 
segment, or this inclusion may be postponed until an entire hierarchy is built up and then is instanced 
in a real picture segment. Thus an entire device independent hierarchy, with all (pointer) references 
and transformations may be stored as a standard symbol in a library.  While GPGS allots the definition 
of a hierarchy of objects as a tree of pseudo picture segments, they must ultimately be  compiled 
to a linearly segmented displayIn order· to allow mapping (correlation) from picture elements on the 
display surface to the original application data structure from which they were derived, n-level naming 
for picking/correlation is supported. within named picture segments, picture elements may be given unique 
names as part of their and may additionally be grouped with another unique name using These group names 
may be nested to reflect the original hierarchy, and will be returned as a name hierarchy (stack) by 
the correlation mechanism. Note that GPGS only supports a single level of device dependent picture segmentation 
for manipulation purposes, but at least allows hierarchical If the hierarchymust be preserved for manipulation 
of individual subobjects, each should be compiled to its own picture segment, to be individually highlighted, 
deleted, or transformed. FACILITIES The approach to provide the programmerwith hardware or simulated 
interaction tools such as lightpens, keyboards,joysticks and function keys explainedin Section 2.3. To 
support these tools, the device driver will sample or be interrupted by each tool to see if it has been 
used by the operator. It does this independent of (possibly asynchronous to) the device independent part 
of GPGS and the applications program. To communicate this asynchronous activity (i.e.,  to simulate 
tool interrupts) to the applications program GPGS maintains a PIFO  interrupt queue. The device driver 
fills the queue with event reports, which the application program can interrogate using the IBUAIT function, 
at its convenience.  The applications program calls the INBAIT function with a list of identifiersof 
the tools that it wishes to accept information GPGS then looks at the interrupt queue to see if the 
console operator has used any of the specified tools. If he has, the tool identifier and the event report 
for that tool is returned to the applications program,  The interrupt queue can be polled for any past 
tool activity or the applications  program can into a go wait state to be tool as a of the time parameter. 
If the time parameter is positive, GPGS will return to the applications program either when the time 
expires or the console user uses a requested tool, If the time parameter is zero, information is returned 
from a tool only if the console user had used the tool prior to the call to INUAIT,  otherwise GPGS 
returns immediately without providing any tccl information. If the time parameter is negative, INBAIT 
returns to the applications program only after the console user uses one of the tools in the list. Though 
not all iuplementations currently support INIAIT is designed to wait for informaticn frcm more than one 
display at the sane time. The gueueing discipline used by GPGS is to allow each tool of each initialized 
device to make at most one entry at a time in the interrupt queue common to all GPGS devices. Thus the 
first interrupt from a tool stays in the queue until it is either passed to the applications or flushed 
by INWAIT because it was not requested by the applications program. The entire interrupt queue may also 
be cleared (flushed) by the applications program. when INHAIT returns to the applications program it 
gives tack the information from only one tool. So allow the applications program to sample tcol values 
without using the more expensive INRAIT interrupt queue mechanism, GPGS has the REATOL  subroutine 
which has a tool identifier as parameter and returns information in the same format as INEAIT.  6 SATELLLTEI_ 
Pi fED2Si!_QoUESTIONS Standard implementations of GPGS were visualized either fcr a host or dedicated) 
suffi- ciently powerful to run the entire applications procram and its environment, or for a host/satellitesystem 
where the application would run on the host and the satellite would need to be only sufficiently powerful 
tc implement an terminal capable of supporting local graphics housekeeping. genuine "cooperative distributed 
to processing" between host and The satellite processor in GPGS therefore only holds the part of a 
device driver that deals directly with the physical device ccnversion, tool interrupt handling, and 
viewport transformaticns). The communication between the host and the satellite is in the fcro of messages 
between two parts of a driver. The primary consideration in designing the satellite support to get the 
best response tine pcssible for the console user. Typically, the determining factor  on time is the 
opportunity for (dispatching) of the program on the multi­programmed host processor. with this in mind 
it is clear that the response time (and link traffic) is optimized by minimizing the total number of 
messages having as small a number of large messages as possible. Each picture segment that is created 
must be sent to the satellite for display. To minimize the number of messages it is better to send the 
whole picture segment after it has been closed rather than sending each picture element in a separate 
message to the satellite. The situation for interaction is less advantageous than for sending picture 
segments because each request must be sent to the satellite as a separate message, and the reply from 
the satellite is, of course, another message. Each message requires operating system intervention for 
I/O, and potential loss of execution control, with the need for subsequent redispatching. Interaction 
is therefore likely to be slow on a busy host. Another question in designing satellite support is why 
the division between host and satellite code was put inside the driver. This leaves the whole work of 
the device independent picture processing pipeline to be done by the host processor. Although it would 
be possible to put some part of the pipeline (say, clipping) on he satellite, it would probably violate 
the goal of minimizing message traffic. For example, if a small window would result in very few lines 
to be displayed, it would be very inefficient to send the entire (set of) segment(s) to the satellite 
for local clipping. Splitting the pipeline between any of the other stages of processing simply adds 
additional overhead the total processing by gathering the half-processed picture elements into a message 
on the host which must be split apart again for further processing on the satellite. Given our assumptions 
about the limited power of the satellite, the best strategy is thus to create complete device dependent 
(clipped) picture segments on the host and send them to the satellite for display and local manipulation 
(e.g., changes in segment attributes or viewport transformations). 7  Transportability of highly interactive 
programs through device independence has been achieved with GPGS. Plotter programs can make the sane 
picture on a storage tube and on a refresh CRT, with only minor variation due to character font, etc. 
 117 Programs which use all the interaction tools of a 3D Vector General display can be debugged (with 
somewhat painful simulation) on a simple storage tube with  But in order to allow this, the plotter 
or only cursor crosshairs and a keyboard. storage tube programs have been forced to abide by the same 
picture creaticn and manipulation rules as a refresh CBT  program.  In our experience in writing device 
drivers we have seen that a driver for a simple output device like a plotter or line printer is very 
easy to write, while the driver for an interactive device, though much more work, is certainly simpler 
than creating a whcle new package and conversion interfaces for other devices. Simulating interacticn 
tools and viewport transfcrmaticns for devices lacking adequate hardware is the hardest job. Making 
a new driver is usually a matter of modifying the lowest level of some existing driver.  Full assembly 
language implementationsexist for PDP 11 (under RSX, PT-11, and Unix operating systems) and for IBM 360/370 
-PDP 11 and Onix)  satellite systems. The GPGS-F ANSI subset implementation supports Tektronix 4010-4015 
and Kingmatic plotters Currently the following graphics devices are supported by the assembly language 
versions: stand-alone:  Vector General on PDP 11 GPGS was designed without general data structure 
support and as a highly modular package in which sophisticated features such as input tool simulation, 
viewport transformations, and device independent picture hierarchies are optional code segments, loaded 
only when needed. This has resulted in basic packages which take little memory space and run quickly. 
with a basic driver (no tool simulaticn) for the Tektronix 4014(4015), the RT-11 version of device independent 
GPGS and device driver takes a total of only words of PDP 11 storage, less than the batch system nucleus. 
A 370 system with PDP 11 satellite and full 3D Vector General display takes 32k bytes for device independent 
GPGS, the 370 portion of the device driver, and a picture segment buffer. far as performance is concerned, 
for highly interactive (not much computation) applications programs on the IBE implementation, the CPU 
utilization and response time are comparable to that of text editing programs.   The following comments 
pertain to how "general purpose" GPGS has proven to be,that is, how easy it is to write applications 
programs. For computer-aideddesign programs, where a fairly low level interface is needed along with 
multipledevices (interactive CRT and plotter),GPGS has proven to be very effective. GPGS has the primitives 
needed for makingstatic data plots but it does not have anyutilities to draw graphs. Therefore, a set 
of graphing routines to go on top of GPGS has been designed [6]. Applications that have proven to be 
unreasonableto attempt with GPGS have had to do with a picture which oust be structurally changed in 
real time in response to console operator input. Due to the requirement that a picture segment must 
be completely rebuilt each time it is changed, even if the building of the next version of the picture 
is overlapped with the displaying of the previous version, it is difficult to achieve real time changes 
with anything but the simplest of pictures. Where a device has transformation hardware, however, a program 
accessing this hardware through GPGS can produce real time motion of arbitrarily complex picture parts. 
 From our experience to date we can conclude that for satellite use with GPGS, a fairly simple satellite 
processor is sufficient. a PDP-11/10 is probably sufficient for all satellite work required by the current 
design. The amount of memory required by the satellite is determined by the amount of picture that can 
be refreshed flicker-free by the graphics device. A very high speedcommunications link (600K baud) is 
certainly nice for GPGS because it means that picture segment (message) length really isn't much of a 
factor in the response time. Even with a slower communications link, say 9600 baud, GPGS satellite support 
would still be useable. Because all decision making must be done by the applications program as to how 
to respond to the interactive tools, the limiting factors for the response of GPGS satellite graphics 
are the speed with which the applications program can be dispatched on the multiprogrammed host  message 
 and the speed  transmission.  GPGS has largely achieved its original design goals of being a device 
independent, easy to use subroutine package to allcw program portability. GPGS provides applications 
programs with access to multiple, diverse graphics devices through the same subroutine calls. The GPGS 
design has been shcwn to be implementable alike, on small and large computers with an implementation 
effort required from one to four or five man-years as a function of the language operating system support, 
number and sophisticationof device drivers, etc. The FORTRAN implementation took approximately one man-year 
for device independent GPGS and simple device drivers. coded GPGS is the only generally available graphics 
system that prcvides high level support for the whole range of devices from plotters to high perfcrmance 
vector displays, with device independence for both output and input facilities. Because of this, GPGS 
has had a significant influence on the design of the GSPC Core System. Many people have contributed 
their efforts to the design, implementation, and critique of GPGS. we list them here with their present 
and/or former affiliations: Ed Anson, tan Bergercn, Jan van den Bos, Steve Carmcdy, Caruthers, Marty 
Michel, Martin Mueller, John Dave Rice, Julie Schuartz of University; Andy van Dam of and Broun Universities 
(U.S.A.);  Thijs, Guns van der Wal, Peter Dik Groot, Lex Hensels, Edwin Hermans, Delft University; 
Charles Lang  and Peter icodsford of Cambridge University; Dick Newell, Martin Nevell, and Tom Sancha 
of the Cambridge Computer Aided Design Center. The helpful revievs of this paper by Ingrid Carlbom, 
Dan Bergeron, and Jim Foley are also much appreciated. REFERENCES 1. IBM -Graphics Subroutine Package 
(GSP) for FORTRAN IV, COBOL, and PL/I; form GC27-6932. P.A., The Design and Implementation of the GINO 
3-D Graphics Software Package, Software ­and Experience, Vol. 1 (October 1971), p. 335. 2.  3. Caruthers, 
L.C., and van Dam, A., GPGS User's Tutorial, Informatica, Faculty of Science, University of Nijmegen, 
The Netherlands,October 1975.  4. Groot, D., Hermans, E., Caruthers, L.C., and Schwartz, J., GPGS Reference 
Manual, Rekencentrum, T.H. Delft and Informatica, Faculty of Science,  University of Nijmegen, The Netherlands, 
May 1977. 5. SIGGRAPH GSPC, First Report on Graphics Standards, Proceedings of SIGGRAPH 77, San Jose, 
July 1977. High-Level Graph-Plotting Routines for GPGS-F, Preliminary Specifications, RUNIT Report, 
University of Trondheim, Norway, 1976.  6. Skaland, M., Zachrisen,  7. Wallace, V.L., The Semantics 
of  Graphic Input Devices, Proceedings ACM Symposium on Graphic Languages, 26-27 April 1976, Miami 
Beach, Florida, pp. 61-65. 8. Foley, J.D., Picture Naming and Modification: An Overview, Proceedings 
 Symposium on Graphics Languages, 26-27 April 1976, Beach, Florida, pp. 49-53.  9. GPGS-F User's Guide, 
RUNIT Computer Centre, University of Trondheim, Norway, September, 1975. 119 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563879</article_id>
		<sort_key>120</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[Moving, computer-generated images via integral holography]]></title>
		<page_from>120</page_from>
		<page_to>120</page_to>
		<doi_number>10.1145/563858.563879</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563879</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379939</person_id>
				<author_profile_id><![CDATA[81547572356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Vickers]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lawrence Livermore Laboratory, Livermore, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379944</person_id>
				<author_profile_id><![CDATA[81100075810]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[G.]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Smith]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lawrence Livermore Laboratory, Livermore, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14089722</person_id>
				<author_profile_id><![CDATA[81332511887]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[S.]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Levine]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lawrence Livermore Laboratory, Livermore, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379953</person_id>
				<author_profile_id><![CDATA[81100540888]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[L.]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Cross]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Multiplex Company, San Francisco, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 MOVING, COMPUTER-GENERATED IMAGES VIA INTEGRAL HOLOGRAPHY* D. L. Vickers**, G. S. Smith**, S. R. Levine**, 
and L. G. Cross*** It is not often that a new medium for displaying three-dimensionalcomputer-generateddata 
comes along, so when one does, it is bound to spark a good deal of interest. Such a medium, known as 
the integral holo­gram, combines the reality of holographywith the animation of movies. Like a cylinder 
hologram, the inte­gral hologram, when rotated, will show all sides of a holographic image. However, 
unlike an ordinary cylinder hologram, as the cylinder-shapedintegral hologram is rotated, the image inside 
can grow, move, deform, or even disappear. In fact, the image can do anything a motion picture image 
can do because an integral hologram is made from a 35-mm black-and-whitemovie. Each frame of a 1080-frame 
movie is transformed by a laser and the appropriate optics into a slit holo­ gram 24 cm high and 0.7 
cm wide. These slit holograms are slightly overlapped on holographic film which is wrapped around a 
40-cm diameter clear plastic cylinder for viewing. When the holographic film is illumina­ ted by an ordinary 
100-watt light bulb from below, an observer looking into the cylinder can see the objects originally 
on the movie film as holographic images floating inside. The motion and detail of the holograph­ ic 
images is very similar to that in the original movie film, but what was a black-and-whitemovie image 
 becomes a rainbow-coloredholographic image. An ordinary light bulb can be used in place of a laser 
to "unlock" the integral hologram because of the optics used when exposing the hologram and because each 
slit hologram is made from a two-dimensionalobject--a frame of the 35-mm movie. Since two-dimensionalrather 
than three-dimensionalobjects are used, the intermodulationnoise is reduced, allowing integral holograms 
to appear much brighter than -heir laser­ illuminated counterparts. Color in the image of an integral 
hologram is a result of the diffraction effect of the holographic film on the white light. Applicationof 
integral holograms to the fields of art and advertising is obvious; their potential effect on the fields 
of education and science is an exciting prospect. One can imagine the educational impact of showing students 
an integral hologram of two molecules. As the hologram is rotated, the mole­cules could rotate and at 
the same time combine according to the laws governing some chemical reaction. Already integral holograms 
have proven to be very valuable in trying to show complex relationships in time and space. For example, 
we have discovered that some subtle motions which are imperceptible in computer­generated movies can 
be shown distinctly and clearly on integral holograms by simply rotating the hologram rapidly. With 
movies as input, integral holograms can show photographic and computer-generateddata super­ imposed. 
In fact, all the tricks of photography can be applied. At the time of this symposium, researchers at 
Lawrence Livermore Laboratory have produced over 16 tech­nical movies from which integral holograms have 
been made. Of these, 14 were computer-generatedmovies. Subjects of the LLL holograms span many areas 
including chemistry, crystallography,biomedicine, laser fusion, magnetic fusion, and electromagneticfield 
study. As a visual aid for technical presentations, an integral hologram is hard to beat, though they 
are somewhat bulky to transport. A new, smaller version of the integral hologram has recently been introduced 
by the Multiplex Company, currently the only producer of integral holograms. This smaller integral hologram 
should ease the portability problem somewhat. The future hides many important possibilities for integral 
holography. Because the holographic image is a composite of many slit holograms, there is some distortion 
in the image whenever there is motion in the original movie film. An LLL student employee has made progress 
in solving this problem by predistorting the 35-mm movie. Other areas of future interest are the production 
of an integral hologram with true color and from a movie sequence longer than 1080 frames. Perhaps one 
day it may even be possible to eliminate the 35-mm movie from the production sequence and expose the 
holographic film directly from a COM device. These paragraphs serve as an expanded abstract for a more 
comprehensive paper on the subject: D. L. Vickers, G. S. Smith, S. R. Levine, and L. G. Cross, "Two Unusual 
Three-DimensionalDisplays," Transactions of the American CrystallographicAssociation,vol. 12, pp. 85-101, 
Clemson University, Clemson, South Carolina, (January1976). The Computing Reviews classificationnumber 
for this abstract is: 8.2; the key words are: holography, cylinder hologram, integral hologram, laser, 
three-dimensionaldisplay, and computer­ generated movies. Permission to make digital or hard copies 
of part or all of this work or personal or classroom use is granted without fee provided that copies 
are not made or distributed for profit or commercial advantage and that copies bear this notice and the 
full citation on the first page. To copy otherwise, to 120 republish, to post on servers, or to redistribute 
to lists, requires prior specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563880</article_id>
		<sort_key>121</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[A Fortran IV program to draw enhanced graphic characters]]></title>
		<page_from>121</page_from>
		<page_to>127</page_to>
		<doi_number>10.1145/563858.563880</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563880</url>
		<abstract>
			<par><![CDATA[A FORTRAN subroutine SYMBEL is described which enables the drawing of the enhanced graphic characters of Dr. A. V. Hershey on any digital plotting device. Output is by linkage to an external subroutine PLOT. The program operates on any computer with integer binary arithmetic and at least a 30 bit word length.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379957</person_id>
				<author_profile_id><![CDATA[81100232325]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[N.]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Wolcott]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Bureau of Standards, Washington, D. C.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379942</person_id>
				<author_profile_id><![CDATA[81100508521]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[F.]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[McCrackin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Bureau of Standards, Washington, D. C.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. V. Hershey,ComputerGraphics and Image Processing,Vol l.,pp 373-385 (1972)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[N. M. Wolcott and J. Hilsenrath,NBS Special Publication 424,"Tables of Coordinates for Hershey's Repertory of Occidental Type Fonts and Graphic Symbols", U. S. Government Printing Office, 1976]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A FORTRAN IV PROGRAM TO DRAW ENHANCEDGRAPHIC CHARACTERS N.M. Wolcott and F.L.McCrackin National Bureau 
of Standards, Washington,D.C.,20234 ABSTRACT. A FORTRAN subroutine SYMBEL is described which enables 
the drawing of the enhanced graphic characters of Dr. A.V. Hershey on any digital plotting device. Output 
is by linkage to an external subroutine PLOT. The programoperates on any computer with integer binary 
arithmetic and at least a 30 bit word length. of INTRODUCTION. The enhanced graphic characters Dr. 
A. V. Hershey (1), (2)are suitable for use on pen plotters or computer output microform devices. Although 
the character representations were available locally at the National Bureau of Standards for some time, 
usage was limited because of the lack of an easily used FORTRAN implementation. Dr. Frank McCrackin of 
N.B.S. suggested a linkage similar to that of the subroutine SYMBOL used by many plotter manufacturers, 
and in fact wrote a preliminary version of the current routine. This version relied on machine dependent 
code and so was not readily transportable. Some time later it occurred to the authors that it might be 
possible to modify the original program so that itwould be entirely ASA FORTRAN IV and hence available 
for use on a variety of computers. II. FORTRAN PROBLEMS. There are two main problems in preparing a 
FORTRAN program for the Hershey characters. One is storage of the data to describe the characters, and 
the other is the uniform handling of various internal computer character sets. The first problemwas 'solved'by 
representingthe data as decimal integers less than 2**30 so that the integers would accomodatea variety 
of computer word lengths. This 30 bit implementationallows the packing of two (x,y) pen instructions 
per computer word so that a can satisfasctorysubset of the Hershey characters be described in a BLOCKDATA 
subprogramof about 500 cards. The problemof character recognition was solved by limiting textual input 
to the 47 FORTRAN characters. The internal codes for these characters are identified on the first pass 
through the subroutine. Ten additional non-FORTRAN characters are used for control information. These 
characters may vary from computer to computer, but will be constant for a given installation. The problem 
of character recognition also involves partial word accesses. Permission to make digital or hard copies 
of part or all of this work or personal or classroom use is granted without fee provided that copies 
are not made or distributed for profit or commercial advantage and that copies bear this notice and the 
full citation on the first page. To copy otherwise, to republish, to post on servers, or to redistribute 
to lists, requires prior specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California 
Access to a bit string in a computer word was providedwith the use of a FORTRAN FUNCTION: IFLD(N1,N2,WORD) 
which retrieves bits N1 through N2 of WORD, when the bits are numberedfrom the right. The subroutine 
is accessed by a FORTRAN subroutine III. DESCRIPTION OF THE SUBROUTINE.  In order to provide compatibility 
across computers, textual input is limited to the 47 FORTRAN characters, that isA-Z,blank,0-9,and + 
­/= ( ) , $. 'A set of ten non-FORTRAN characters are used as control characters. (These non-Fortran 
characters are set up in a DATA statement and may be varied by local option). The implementor provides 
in one DATA statement the word length and character length in bits for his computer. One other line of 
code must be modified depending on whether one's or two's complement integer arithmetic is performed 
in the local computer. These are the only two local items of information required for implementation. 
The program uses two auxiliary subroutines:  returns in XL the length of TEXT This isuseful to the user 
for centering and alignment information. STRIN(I,TEXT) a function which returns the i'th word of TEXT. 
Itisused only internally in SYMBEL. The UNIVAC 1108 implementation for the control codes follow. The 
default option is for Simplex Roman Upper Casa letters, similar to that of an engineeringlettering set. 
 121  REFERENCES (1)A.V.Hershey,ComputerGraphics and Image Processing,Vol l.,pp 373-385 (1972) (2)N.M.Wolcott 
and J.Hilsenrath,NBSSpecial Publication 424,"Tables of Coordinates for Hershey's Repertory of Occidental 
Type Fonts and Graphic Symbols", U. S. Government Printing Office, 1976   123 124  125 126 127 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563881</article_id>
		<sort_key>128</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[Machine-independent metacode translation]]></title>
		<page_from>128</page_from>
		<page_to>130</page_to>
		<doi_number>10.1145/563858.563881</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563881</url>
		<abstract>
			<par><![CDATA[Many systems implement plotter device-independent computer graphics by having a system plot package which outputs a plotter-independent code (here called metacode) and having a translating driver for each plotter which uses this code as input. The translator for this code can often be run with greatest efficiency on the computer which hosts the plotter. In NCAR's configuration, various computers will drive different plotters, making a portable metacode translator a desirable tool. Constructing a metacode translator which can drive the simplest devices and yet provide the potential to use sophisticated plotter hardware features is a stimulating challenge. The design and implementation of such a translator are described.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[device-independent graphics]]></kw>
			<kw><![CDATA[metacode translation]]></kw>
			<kw><![CDATA[portability]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP31051983</person_id>
				<author_profile_id><![CDATA[81450594467]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wright]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The National Center for Atmospheric Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Ryder, B. G. "The PFORT Verifier," Computer Graphics, Vol. 4, No. 4 (1974), 359-377.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Wright, T. "A Schizophrenic System Plot Package," Computer Graphics, Vol. 9, No. 1 (Spring 1975), 252-255.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>988001</ref_obj_id>
				<ref_obj_pid>988000</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Wright, T. "SIGCHR--A Portable Character Generator," Computer Graphics, Vol. 10, No. 4 (Winter 1977).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 MACHINE-INDEPENDENTMETACODE TRANSLATION Thomas Wright The National Center for Atmospheric Researcht 
 Abstract: Many systems implement plotter device-independent computer graphics by having a system plot 
package which outputs a plotter-independentcode (here called metacode) and having a translating driver 
 for each plotter which uses this code as input. The translator for this code can often be run with 
 greatest efficiency on the computer which hosts the plotter. In NCAR's configuration,various computers 
will drive different plotters, making a portable metacode translator a desirable tool. Constructinga 
metacode translator which can drive the simplest devices and yet provide the potential to use sophisticated 
plotter hardware features is a stimulating challenge. The design and implemen­ tation of such a translator 
are described.  Device-independentcomputer graphics are imple­mented at NCAR by using metacode [2]. 
This device­ independent instruction set is produced on each of the computers in NCAR's network where 
user pro­grams execute, such as the Cray-1, the Control Data 7600, the general purpose satellites, or 
the high performance graphics satellite (see figure l).tt Translationof the metacode is done on the 
various computers where the individual graphics devices re­side. The general purpose satellites translate 
metacode into instructionsfor a microfilm recorder. The Control Data 7600 uses metacode to produce in­structions 
for its microfilm recorder. The high performance graphics satellite translates metacode into instructions 
for its display. Various com­puters can translate metacode, producing output tapes for off-line plotters. 
 t The National Center for Atmospheric Research is sponsored by the National Science Foundation. tt At 
this writing, the hardware configuration is only partially implemented, but this introduc­tion assumes 
the ultimate configuration. Permission to make digital or hard copies of part or all of this work or 
personal or classroom use is granted without fee provided that copies are not made or distributed for 
profit or commercial advantage and that copies bear this notice and the full citation on the first page. 
To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific 
permission and/or a fee. Siggraph 77, July 20-22 San Jose, California When enormous volumes of instructionsare 
to be translated, an inflexible machine language program is used to translate the metacode. The high 
speed microfilm device on the 7600, for example, cur­rently averages several hundred instructions per 
second around the clock. This makes a small, fast metacode translator very important. There is, however, 
a need for another type of translator. A portable translator makes some efficiency sacri­ fices to achieve 
other goals. Because it is port­able, the translator is easily moved from one host computer to another. 
Because it can reduce high level constructs to low level ones, the least sophisticated plotters can be 
supported. Because the code has clearly marked interface points, a new plotter can be added to the system 
with a small effort.  The translator is written in PFORT [1], a portable subset of FORTRAN. A verification 
program was used to check that the translator adheres to this stand­ard. When moving the translator to 
a new computer, the implementor sets certain machine-dependentcon­stants and supplies FORTRAN-callable 
functions for shifting and masking (IAND, IOR, ISHIFT). The translator assumes that positive integers 
are stored in binary and that the host's default length integer variables have 16 or more bits. Perhaps 
a word on portable FORTRAN is in order. The syntactic constraints of PFORT tend to be an irritant rather 
than an obstacle. Standards which are little known to many FORTRAN users include: o when initializing 
an array with a DATA state­ment, each element of the array must be individ­ually listed before the first 
slash (as in DATA A(1),A(2),A(3),A(4),A(5)/5*0/).  o mixed modes of real and integer are not per­mitted 
(as in A = A+I).  o if a routine references two other routines which share a named COMMON block, the 
calling routine must also share that named common block.  o DATA statements referring to named common 
blocks can only appear in BLOCK DATA routines. These and other standards are checked using the PFORT 
verification program.   The main program of the translator contains a lo­ cation for the implementor 
to set various param­ eters, checks these parameters, and repeatedly invokes a routine which translates 
the metacode for one picture until all the metacode is exhausted. To prevent errors in transportingthe 
translator, the parameters which are to be established by the implementor are originally initialized 
to disal­ lowed values, and a run-time check is made to see that the implementorhas set the parameters 
to reasonable and consistant values. The routine which processes a picture's worth of metacode uses 
four lower level packages. Three of these--a character generator,a dashedline package, and the plotter 
interface--are discussed in later sections. The fourth supplies the metacode in chunks of a size which 
is easily digested by the translator. For the metacode in use at NCAR, these chunks are 16 bits long. 
 Portable extraction of 16-bit bytes from a bit stream must be carefullyhandled. The routine for this 
task assumes that a bit stream can be read into and accessed from an integer array completely filling 
each individual word except for possibly the last word used. This is true on nearly all machines (possible 
exceptions include 16-bit mini­computers reading from seven-track tape drives and long-word-lengthmachines 
with short integer reg­isters, such as a Cray-1). Further, the code as­sumes that default length integers 
are some mul­tiple of four bits in length. Four packets of four bits each are extracted using shifts 
and masks from the current word being used from the buffer. For each packet, a test is made to see if 
all the bits have been obtained from the current word. If a new word is needed, a test is also made to 
see if an end-of-file is encountered. This must be done with compiler-dependentcode. When four' packets 
have been obtained, they are shifted and OR'd together to form a 16-bit byte.  The metacode used at 
NCAR has high level constructs which allow the use of important hardware features often available on 
sophisticated plotters. The two most important constructs are for drawingchar­ acters and for specifying 
dashed line patterns. For plotters with hardware characters and hardware dashed lines, instructionscan 
be formed from the metacode which uses these features. For plotters without these capabilities, these 
constructs must be reduced to lower level constructs (pen move­ ments) to emulate character generation 
and dashed line formation. The portable generation of characters on a plotter is an interesting problem 
[3]. When translating metacode, the problem is simplified because the characters are in a known character 
code and are in a known position in the input string. In NCAR's metacode, characters are in ASCII and 
are stored in order, one per 8-bit byte. Each ASCII charac­ter is used to form an index to an array of 
point­ers to the digitizations of the characters. Each digitization is used to form the individual strokes 
that make up each character. Even with only the 46 PFORT characters implemented, initializing the pointers 
and digitizations with standard DATA statements consumed about 250 statements. The portable generation 
of software dashed lines is not a complicated problem when working with metacode because of the restricted 
nature of the input. A version of NCAR's simplest software dashed line package was easily integrated 
into the portable metacode translator without any special portability problems. Other constructs, 
such as color and intensity, cannot be reduced to simple pen movements. To take advantage of these capabilities, 
extra code can be added by the implementor at places marked in the translation program to perform the 
desired function. 129 InteAdacing  All plotting is handled through one routine. When establishing 
the parameters for the translator, the implementor specifies whether the translator should produce integer 
or floating point coordin­ates and the range for these coordinates. Two basic methods exist for interfacing 
to the plotter. A small subset of the vendor-supplied software for the plotter can often be used to 
form the plotter's instructions. All scaling, labelling, and so on, will already be resolved, so only 
the lowest level line drawing routine need be referenced. This can provide a clean, efficient interface 
to the plot­ ter if the vendor's software is highly modularized. Unfortunately, this is rarely the case. 
 Alternatively,a description of the plotter's hardware instruction set can be used as a basis for writing 
code to directly formulate instruc­ tions for the plotter. This is generally more work for the implementor 
than using vendor soft­ware, but often results in a smaller, more effi­ cient interface. For more sophisticated 
plotters, the forming of software characters and software dashed lines can be replaced by interfaces 
to hardware capabili­ ties for these functions.  A portable metacode translator has been implement­ 
ed and functions on several computers with a vari­ ety of plotters. The code is about 1100 state­ments, 
of which about one-third are comments. Various techniques for making the program easily transportable 
and flexible are described. The code has been implemented on IBM, Control Data, and PDP computers; plotters 
supported include Tektronix, CALCOMP, FR-80, and dd80.  [1] Ryder, B.G. "The PFORT Verifier," Computer 
Graphics, Vol. 4, No. 4 (1974), 359-377. [2] Wright, T. "A Schizophrenic System Plot Package," Computer 
Graphics, Vol. 9, No. 1 (Spring 1975), 252-255. [3] Wright, T. "SIGCHR--A Portable Character Generator," 
Computer Graphics, Vol. 10, No. 4 (Winter 1977). 130
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563882</article_id>
		<sort_key>131</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[An interactive computer graphics approach to surface representation]]></title>
		<page_from>131</page_from>
		<page_to>131</page_to>
		<doi_number>10.1145/563858.563882</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563882</url>
		<keywords>
			<kw><![CDATA[computer graphics]]></kw>
			<kw><![CDATA[finite element input methods]]></kw>
			<kw><![CDATA[lofting]]></kw>
			<kw><![CDATA[splines]]></kw>
			<kw><![CDATA[three-dimensional surface representation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P263323</person_id>
				<author_profile_id><![CDATA[81100658168]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sheng-Chuan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell University, Ithaca, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P142660</person_id>
				<author_profile_id><![CDATA[81100320367]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Abel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell University, Ithaca, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P68459</person_id>
				<author_profile_id><![CDATA[81100196982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Greenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell University, Ithaca, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 AN INTERACTIVE COMPUTER GRAPHICS APPROACH TO SURFACE REPRESENTATION by Sheng-Chuan Wu and John F.Abel 
 Department of Structural Engineering and Donald P. Greenberg Program of Computer Graphics Cornell 
University Ithaca, New York 14853 Key Words and Phrases : Computer Graphics, three-dimensional surface 
representation,splines, lofting, finite element input methods CR Categories: 3.20, 3.23, 3.34, 8.1, 
8.2 ABSTRACT An interactive computer graphics method has Among the features of this system are algor­been 
developed for the rapid generation of arbi-ithms which enable interactive modification of the trary 
shaped three-dimensional surfaces. The B-spline representation of the sectional curves. method isa synthesis 
of spline theory and algor-Standard editing routines for manipulation are ithms, an interactive means 
for man-machine com-included. Thus, both the flexibility for initial munication, and software for static 
or dynamic shape design or the adjustment capability to match graphics display. existing forms are provided. 
 The basic technique employed isa modified At all stages of the process, the spatial in­lofting method 
inwhich sectional curves are formation isgraphically displayed to the user. represented by uniform B-splines 
and the surface The efficiencies necessary for this interaction is interpolated between sections by Cardinal 
are obtained by the use of difference equations splines. The sectional curves need not be parallel which 
enhance the speed of the repetitive calcula­and may consist of any combination of open or tions. closed 
curves. A convenient method isincluded for introducing and controlling cusps. An inver-Complex surfaces 
can be created by the combin­sion procedure isincorporated which enables a ation of a number of shapes 
that have been separately B-spline curve to be automatically generated generated and automatically joined. 
The system has which closely approximates a digitized or pre-been successfully interfaced to a variety 
of analy­defined curve. tical routines for structural, medical and graphical applications. This work 
has been sponsored by the National Science Foundation grant, ENG75-17400, entitled "Interactive Computer 
Graphics inStructural Mechanics."  Permission to make digital or hard copies of part or all of this 
work or personal or classroom use is granted without fee provided that copies are not made or distributed 
for profit or commercial advantage and that copies 131 bear this notice and the full citation on the 
first page. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires 
prior specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563883</article_id>
		<sort_key>132</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[Visual interaction with overhauser curves and surfaces]]></title>
		<page_from>132</page_from>
		<page_to>137</page_to>
		<doi_number>10.1145/563858.563883</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563883</url>
		<abstract>
			<par><![CDATA[The method of parabolic blending for curve and surface interpolation originally conceived by A. W. Overhauser is applied to the interactive free-form design of three dimensional objects. A significant advantage of the algorithm is the user-oriented control of surface shape that is achieved because one interactively manipulates only coordinates on the design surface, as opposed to parametric slopes or design points.The algorithm is demonstrated using an interactive 3D design system that executes in a dual-minicomputer refresh graphics environment without special 3D hardware. The system provides high level data generation commands and direct visual interaction with structured 3D data using a multi-purpose 3D cursor and shaping tool. Objects composed of points, lines, curves and surfaces of different forms may be interactively created and manipulated.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[curves and surfaces]]></kw>
			<kw><![CDATA[interactive graphics]]></kw>
			<kw><![CDATA[three dimensional interaction]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379947</person_id>
				<author_profile_id><![CDATA[81100357473]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Brewer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Purdue University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39027260</person_id>
				<author_profile_id><![CDATA[81100103058]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Anderson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Purdue University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>889976</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Coons, S. A. Surfaces for computer-aided design of space forms. Project MAC, M.I.T. (June 1967).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Armit, A. P. Computer systems for interactive design of three-dimensional shapes. Ph.D. Thesis, University of Cambridge Computer Lab (November 1970).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bezier, P. E. Emploi des Machines a Commande Numerique, Masson et Cie, Paris, France (1970).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>906872</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Riesenfeld, R. F. Applications of B-spline approximation to geometric problems of computer-aided design. Ph.D. Thesis, Syracuse University (1972).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360329</ref_obj_id>
				<ref_obj_pid>360303</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Clark, J. H. Designing surfaces in 3-D. CACM 19, 8 (August 1976), 454-460.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Overhauser, A. W. Analytic definition of curves and surfaces by parabolic blending. Scientific Research Staff Publication, Ford Motor Company (May 1968).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>575646</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Rogers, D. F. and Adams, J. A. Mathematical elements for computer graphics. McGraw-Hill, Inc. (1976), 133-138.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1024276</ref_obj_id>
				<ref_obj_pid>1024273</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Brewer, J. A. and Anderson, D. C. Techniques for interactive three dimensional design. To be published in the proceedings of the ACM/SIGGRAPH Workshop on "User-Oriented Design of Interactive Graphics Systems". Pittsburqh, PA. (October 1976).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>908302</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Brewer, J. A. Three Dimensional Design by Graphical Man-Computer Communication. Ph.D. Thesis, Purdue University (May, 1977).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 VISUAL INTERACTION WITH OVERHAUSER CURVES AND SURFACES J.A. 1 and D.C. Anderson2 Purdue University 
 The method of parabolic blending for curve and surface interpolation originally conceived by A.W. Overhauser 
isapplied to the interactive free-form design of three dimensional objects. A significant advantage of 
the algorithm isthe user-oriented control of surface shape that isachieved because one interactively 
manipulates only coordinates on the design surface, as opposed to parametric slopes or design points. 
 The algorithm isdemonstrated using an inter­ active 3D design system that executes ina dual­ minicomputerrefresh 
graphics environment without special 3D hardware. The system provides high level data generation commands 
and direct visual interaction with structured 3D data using a multi­ purpose 3D cursor and shaping 
tool. Objects com­of points, lines, curves and surfaces of different forms may be interactively created 
and manipulated. Keywords and Phrases: curves and surfaces, three dimensional interaction, interactive 
graphics CR Categories: 8.2, 4.13, 3.26 1. Introduction Curve and surface algorithms for interactive 
computer-aided design have received ever increasing attention during the past decade. One of the earliest 
and best known methods of surface des­cription for free-form surface design was reported by Coons [1] 
in 1967. Coons' method was applied with success in numerous three-dimensional (3D) design systems including 
Armit's Multi-Patch System [2]. Inthese early systems, the user was forced to assign numeric values to 
parametric derivatives at patch boundaries to control shape. The mathematicallyuninitiated user was obviously 
at a disadvantage. Permission to make digital or hard copies of part or all of this work or personal 
or classroom use is granted without fee provided that copies are not made or distributed for profit or 
commercial advantage and that copies 132 bear this notice and the full citation on the first page. To 
copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific 
permission and/or a fee. Siggraph 77, July 20-22 San Jose, California Algorithms which allow more intuitive 
control of shape by the user were introduced by Bezier [3] and Riesenfeld [4] in 1972. These methods 
require the user to construct a network of control or design points. The network only remotely resembles 
the surface being designed since design points which control parametric derivatives do not lie on the 
surface itself. Clark [5] reported dissatis­faction with Riesenfeld's B-spline patches inhaving to work 
with points remote from the design surface. A lesser known parametric curve description was introduced 
by Overhauser [6] in1968 inan internal research report at Ford Motor Company. Overhauser's formulation 
isrepeated by Rogers and Adams [7]. The uniqueness of Overhauser's method of parabolic blending stems 
from the fact that­parametric derivatives are not used as boundary conditions for curve segments. Coordinate 
points which lie on the spline-like curves and surface patches make up the boundary conditions. The pri­mary 
purpose of this paper isto describe the simple but flexible user interface afforded by the Overhauser 
technique. The software system [8,9] used by the authors isdesigned to provide a user-oriented, free-form 
design environmentwhere various curve and surface algorithms can be evaluated. A 3D cursor and a planar 
shaping tool are used to shape and edit objects consisting of lines and other geometric representations. 
Visual creation and editing of nodes are two important uses of the 3D shaping tools. Relative movement 
of a "mouse" (an input device consisting of two circular potentiometers that roll and slide on a flat 
surface) causes the 3D tools to move. Strikes on a five-fingered key­set (afunction keyboard ineffect) 
alter the 3D direction of tool movement. A cursor or tool is never given more than two degrees of freedom 
so that the user will not become disoriented. The user, therefore, moves the tools ina plane or on a 
line parallel to a given axis. An associative transformation structure pro­vides both rapid display 
processing and flexible data generation capabilities. Keyboard input is processed by an interactive interpreter,allowing 
high level directives which are particularlyuseful to automatic data generation. 2. Formulation of an 
Overhauser Curve for Fast Substitutingeqs. (2)into eq.(l) yields, Computation The Overhauser method 
can be expressed as follows: and eqs. (6)into eq. (9)we get,   Figure 1*, p passes through points P,,P2, 
and P,;  where r, s and t are parameters and c, p and q are vectorial expressions for curves. As shown 
in q passes through P2, P3 and and c passes through 2 and P3. Ifp and q are second degree polynomials 
(parametric quadratics),  (whereB and C are matrices) and r,s and t are related ina linear manner, 
 the resulting curve c (see Figure 1) is a parametric cubic:  The purpose of the following development 
is to express the matrix A of eq. (4)interms of the coordinate points P,, P2, P3 and P,. By arbitrarily 
 assigning parameter values at points P,, 2, P3 and the relationship among parameters (eqs. (3)) may 
be specificallydefined. Assuming,  we get from eqs. (3),  Expressing the matrix B of eq. 2 interms 
of P,, P2 and P3   By substituting eq. (7)and eq. (8)into eq. (10), the result is   133 which iseq. 
(4)where  The parametric cubic, c(t) of eq. (14), isnow in a form which can be transformed prior to 
generating an incremental trace along the curve for display. 3. First Derivative Continuity Assume 
now that a sequence of points is threaded together as shown in Figure 2 such that each group of four 
adjacent points form an Over­hauser curve between the two interior points of the group. Itcan be easily 
shown that first para­metric derivative continuity ismaintained at nodes where two such Overhauser curves 
are joined. In fact, assurance of first derivative continuityis independent of the form of the curves 
p(r) and q(s).  Figure 2 A Sequence of Overhauser Curves Ifa discontinuityinthe first derivative is 
desired, for example at point P of Figure 3, points off the blended curve, as indicated by P and PB, 
may be added. These off-curve points can be used to shape the blended curve similar to Bezier's design 
points.  Figure 3 Forming a Discontinuity in First Derivative The curve formulation of section 2 also 
allows two points which define an Overhauser curve to be coincident as shown inFigure 4. This means that 
 which inany case yields a discontinuity infirst derivative at point P4. End-points of a sequence of 
points may, therefore, point PA, point PB or both PA and PB of Figure 3 may coincide with point coincide 
with the second and second-to-last points. Inthis case all points inthe sequence may lie on the curve. 
 4. Surface Patches A mesh of points interconnected by the method of parabolic blending can be used 
to form a surface as indicated inFigure 5. Various interpolation schemes can be used to define the interiors 
of sur­face patches. As suggested by Overhauser [6], sets of four points on "parallel" curves of the 
mesh (see points PA, PB, PC and inFigure 5)may be used to form a parabolic "blend" across an interior 
 patch (see the patch formed by points 6, 7, and Pi, inFigure 5). The "traces" could also be calculated 
in the opposite parametric direction or the two traces averaged if desired. Inany of these schemes the 
interior shape of a patch depends on the positions of sixteen adjacent points as indicated in Figure 
5.  134 Eq. (16) can be rearranged in a more manageable form: where Q is a matrix of coefficients 
which depend on twelve adjacent coordinate points as shown in Figure 6. The bi-cubic patch, F(u,v) of 
eq. (17), isnow ina form which can be transformed prior to generating incremental traces over the interior 
of the patch for display.  5. Curve and Surface Interaction As indicated inthe Introduction, the authors' 
 environment for sketching and visually editing 3D geometry involves a five-fingered keyset for issu­ing 
commands by touch with one hand. The other hand holds the mouse which isused to move a 3D cursor or 
tool inthe display scene. The user may work inany orthographicor perspective view he desires. The string 
of parabolically blended curve seg­ ments shown inFigure 7was created by indicating the position of each 
new point on the original curve with the 3D cursor. As each new point is added to the string, a keyset 
strike commands that a parabolic blend be formed with the three previous points. Later, when editing, 
another keyset com­mand "attaches" the nearest node to the cursor. Unaffected curve segments and points 
are displayed at a lower intensity on the screen. Affected por­tions of the scene are "dragged" with 
the cursor.  and P5 while tangents at P2 and P6 remain unaffected. As previously stated in section 3,continuity 
through the first parametric derivative isautomatically maintained at all points on the curve. If the 
change incurvature at particular points (see 3 and Ps of Figure 8)is to be relatively severe, new points 
such as PA, PB, and desired shape. ifrelative distances between design points along the curves vary too 
greatly, spurious wiggles as indicated inFigure 9may result. This is a problem commonly encountered with 
piece-wise parametric cubic splines. The displacement of a single point affects its four neighboring 
curve segments as indicated in Figure 7. The displacementof point 4 alters tan­gents at points 3, may 
be introduced to achieve a   defined by sketching or pointing to three or more points with the 30 cursor. 
The direction of move-ment of a plane is by default parallel to its nor-mal. Figures llb and llc show 
a curve with para-bolically blended segments which has been reshaped by an infinite plane tool parallel 
to the x-z plane. Intersection calculations involve only the tool and node points on the curve. The affected 
curve seg-ments are dragged and tend to take on the shape of the tool as new points are encountered. 
Figure 12 Effect Point of in Displacing a Patch Mesh One (a) (b) (b) Figure 13 Effect of an Infinite 
Planar Tool on Patches (cl Figure 11 Reshaping Overhauser Curves with a Planar Tool Editing a Patch 
Mesh. The displacement of single points in a surface patch mesh is accom-plished in exactly the same 
manner as described for curves. Normally twelve adjacent patches are affected by the displacement of 
a single point com-mon to four patches as indicated in Figure 12. The effect of using an infinite plane 
as a shaping tool is shown in Fiaures 13a and 13b. A tool with a bounded plane iace produced the result 
shown in Figure 14. Figure 14 A Planar Tool with a Bounded Face 136 Overhauser curves and surfaces are 
efficiently 6. Conclusions altered with the planar shaping tool. The cylinder shown in Figure 15 has 
walls defined by eight Over-The little used and undeveloped method of para-hauser patches. The 3D cursor 
in Figure 15 has bolic blending has been revamped and demonstrated assumed an attitude parallel to a 
previously to be of importance to interactive shape design. defined inclined plane. In that attitude 
the cur-The method provides an especially simple and com-sor was converted'to a planar tool. Figures 
15b fortable user interface primarily since the and 15c show the activated planar tool moving designer 
deals only with coordinate points on the parallel to the vertical axis and into the body of design surface. 
Shape control with nodes melds the cylinder. As boundary points of the patches well with the concept 
of the 3D cursor and shaping are encountered, they are attached to the planar tools in a dynamic environment. 
Since the use of tool. The resulting truncated cylinder is shown the shaping tools is based on intersection 
tests in Figures 15d and 15e. with boundary nodes alone, efficient intersection detection and interaction 
is possible. The use of more than one algorithm for curve and surface description seems to have practical 
potential. For example, the Overhauser method could be advantageously used in preliminary shape definition 
where the desisner miqht work with shaping tools. While general shapes can be quickly created with this 
method, certain areas may require deformations not easily achieved with Overhauser patches. Those areas 
could then be converted to compatible Coons patches to gain the required flexibility. 7. References 1. 
Coons, S. A. Surfaces for computer-aided design of space forms. Project MAC, M.I.T. (June1967). (a) (b) 
2. Armit, A. P. Computer systems for interactive design of three-dimensional shapes. Ph.D. Thesis, University 
of Cambridge Computer Lab (November 1970). 3. Bezier, P. E. Emploi des Machines a Commande Numerique, 
Masson et Cie, Paris, France (1970). 4. Riesenfeld, R. F. Applications of B-spline approximation to 
geometric problems of com-puter-aided design. Ph.D. Thesis, Syracuse University (1972). 5. Clark, J. 
H. Designing surfaces in 3-D. CACM 19, 8 (August 1976), 454-460. 6. Overhauser, A. W. Analytic definition 
of curves and surfaces by parabolic blending.  (cl (d) Scientific Research Staff Publication, Ford Motor 
Company (May 1968). 7. Rogers, D. F. and Adams, J. A. Mathematical elements for computer graphics. McGraw-Hill, 
Inc. (1976), 133-138. 8. Brewer, J. A. and Anderson, D. C. Techniques for interactive three dimensional 
design. To  (e) be published in the proceedings of the ACM/ SIGGRAPH Workshop on "User-Oriented Design 
of Interactive Graphics Systems". Pittsburqh, PA. (October 1976): -. --- 9. Brewer, J. A. Three Dimensional 
Design by Graphical Man-Computer Communication. Ph.D. Thesis, Purdue University (May, 1977). Figure 15 
Truncating a Cylinder 137
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563884</article_id>
		<sort_key>138</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[A system for sculpting 3-D data]]></title>
		<page_from>138</page_from>
		<page_to>147</page_to>
		<doi_number>10.1145/563858.563884</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563884</url>
		<abstract>
			<par><![CDATA[A major research area in 3-D computer graphics is the inputting of complex descriptions. This paper describes our current attempt at solving that problem: creation of a sculptor's studio-line environment in which the user is provided with various tools to shape, cut and join objects. The emphasis of the implementation has been on naturalness and habitability. The issues involved in designing such a system, especially in a minicomputer-based color raster-scan animation environment, are discussed. The basic algorithms are described in some detail and a fast efficient implementation of a hidden-line algorithm is explained.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P242699</person_id>
				<author_profile_id><![CDATA[81100414668]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Parent]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University Research Center, Columbus, Ohio]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Chandrasekaran, B.; Parent, R. "Moulding Computer Clay - Steps Toward a Computer Graphics Sculptors' Studio," Pattern Recognition and Artificial Intelligence, Academic Press, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Defanti, T. A. "The Graphics Symbiosis System --- An Interactive Minicomputer Graphics Language Designed for Habitability and Extensibility," Ph.D. Thesis, The Ohio State University, 1973. Also technical report, Computer Graphics Research Group.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Gillenson, M. L.; Chandrasekaran, B. "A Heuristic Strategy for Developing Human Facial Images on a CRT," Pattern Recognition, Vol. 7, 1975, pp. 187-196.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. E. "Three-Dimensional Data Input by Tablet," Proc. of the IEEE, Vol. 62, No. 4, April 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Thorton, R. W. "MODEL --- Interactive Modeling in Three Dimensions Through Two-Dimensional Windows," Master Thesis, Cornell University, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Lafue, G. "Computer Recognition of Three-Dimensional Objects from Orthogonal Views," Carnegie-Mellon University, Institute of Physical Planning, Research Report No. 56, September 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Shirai, Y.; Tsuji, S. "Extraction of the Line Drawings of 3-Dimensional Objects by Sequential Illumination from Several Directions," Second International Joint Conference on Artificial Intelligence, London, September 1971.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Baumgart, B. G. "Geometric Modeling for Computer Vision," Stanford University, Department of Computer Science, available from NTIS as AD-A002, October 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360727</ref_obj_id>
				<ref_obj_pid>360715</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Braid, I. C. "The Synthesis of Solids Bounded by Many Faces," CACM, Vol. 18, No. 4, April 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Yoshimura, S.; Tsuda, J.; Hirano, C. "A Computer Animation Technique of 3-D Objects with Curved Surfaces," Proc. of the 10th Annual Meeting of UAIDE, Los Angeles, October 1971.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Davis, J. R.; Nagel, R.; Guber, W. "A Model Making and Display Technique for 3-D Pictures, Proceedings of the 7th Annual Meeting of UAIDE, San Francisco, October 1968.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. E.; Sproull, R. F.; Schumacker, R. A. "A Characterization of Ten Hidden-Surface Algorithms," ACM Computing Surveys, Vol. 6, No. 1, 1974, pp. 1-55.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Encarnacao, J. L. "A Survey of and New Solutions to the Hidden Line Problem," Proc. Interactive Computer Graphics Conference, Delft, Holland, October 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Loutrel, P. "A Solution to the Hidden Line Problem for Computer-Drawn Polyhedra," IEEE Trans. Computers, March 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360357</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Burtyk, N.; Wein, M. "Interactive Skeleton Techniques for Enhancing Motion Dynamics in Key Frame Animation," Comm. Association for Computing Machinery, Vol. 19, No. 10, October 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Myers, A. J. "An Efficient Visible Surface Program," Technical Report, Computer Graphics Research Group, The Ohio State University, July 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A SYSTEM FOR SCULPTING 3-D DATA Richard E. Parent Computer Graphics Research Group* The Ohio State 
University Research Center 1314 Kinnear Road Columbus, Ohio 43212 A major research area in 3-D computer 
graphics is the inputting of complex descriptions. This paper describes our current attempt at solving 
that prob­lem: creation of a sculptor's studio-line environ­ment in which the user is provided with various 
tools to shape, cut and join objects. The emphasis of the implementationhas been on naturalness and habitability. 
The issues involved in designing such a system, especially in a minicomputer-based color raster-scan 
animation environment, are discussed. The basic algorithms are described in some detail and a fast efficient 
implementation of a hidden-line algorithm is explained. 1. INTRODUCTION A major problem in three-dimensionalcomputer 
 graphics is that of making available to the computer descriptions (or "models") of complex objects 
in a form suitable for various graphics manipulations. This paper represents an updated report of the 
research presented in (1). Some of the issues involved in the design of an inter­ active minicomputer-based3-D 
data generation system are discussed,as is our current attempt at the creationof a sculptor's studio-like 
 environment, in which the "sculptor" can create complex 3-D objects in the computer, as if moulding 
a piece of clay. The data generated is used by the ANIMA II system to create animation sequenceswhich 
can be played in real time to a color video monitor. There are two typical approaches to the 3-D data 
generationproblem. In one, the objective is to recreate an existing object by constructinga definitionof 
it in the graphics system by some means. This requires digitizing the surface of  personal or classroom 
use is granted without fee provided that copies are not made or distributed for profit or commercial 
advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, 
to 138 republish, to post on servers, or to redistribute to lists, requires prior specific permission 
and/or a fee. Siggraph 77, July 20-22 San Jose, California the object and inputting the coordinates of 
each point desired. In the other approach, the object definitionis directly "created" or synthesized 
in the machine. In this case, the resultant object definition need not correspond to any physical counterpart, 
but rather, is specified for its visual attributes only. Of course, in practice one might adopt stances 
intermediate to these polarities such as reading in some "primitive" objects and then synthesizing more 
complex objects out of the primitive ones. Our work in data generation is heavily influenced by the fact 
that, historically, the Computer Graphics Research Group (OGRG) at The Ohio State University has had 
as one of its aims for its graphics systems ease of use by artists and other non-programmers. Thus, 
the graphics language, Graphics Symbiosis System or GRASS (2), could be learned by persons with little 
computer background in a short time to create two-dimensional figures of nontrivial complexity. The WHATSISFACE 
system (3), developed at the CCRC enabled nonartists and nonprogrammersto draw on the CRT a facial 
image with remarkable likeness to a target photograph. The ANIMA II language currently in use at CCRG 
 allows the nonprogrammer to easily specify complex time-dependent motions in 3-D for producing color 
 animation sequences. In this historical context, we were naturally led to the notion of opening up 
 the possibilities of the computer as a medium of expression for sculptors and animators of three­ dimensional 
objects. 2. APPROACHE TO 3-D DATA GENERATION Elsewhere (1), we have discussed in detail various attempts 
at solving the data generation problem. Suffice to say, there can be no one solution to the problem of 
generating 3-D data. Inputting the description of a particular object one has at hand requires different 
techniques from synthesizing an object in the machine. Objects occurring in engineering and architectural 
applications could be Primitive Object Input described by simpler techniques than free-form objects occurring 
in art contexts. These tech­ niques necessarily place more of a burden on the user (4,5,6) usually in 
the form of preparing special 2-D projections of the data to be input, or on special hardware (7,8) such 
as scanning devices. Systems which allow the user to completely specify the object desired (2,9,10,11)have 
typicallybeen severely restrictive in the class of objects describable or difficult to use. Any approach 
to data generationmust also take into account the internal representationof objects and the class of 
objects to be handled. Baumgart (8) presents an excellent survey of the different rep­resentationsthat 
have been proposed and their relative advantages and disadvantages. We have chosen the planar polyhedral 
representation because it lends itself to hidden-lineremoval, visible surface shading and other graphics 
processing. However, since our aim is to "sculpt" interactively even objects which are only moderatelycomplex 
con­ceptually can take on a quite complex polyhedral representation (e.g. a sphere). This fact places 
a great demand on the efficiencyof all of the under­lying routines. For instance, the standard imple­mentations 
of hidden-line eliminationroutines become quite inefficient. As a result, we have written a powerful, 
fast, extremelyefficient hidden-line eliminationroutine which is briefly described in Section 7. 3. 
COMPUTi GRAPHICS SCULPTOR'S STUDIO Hardware The CPU is a PDP-11/45 with 96K 16-bit words of memory, 
out of which 64K is magnetic core and 32K is MOS. In addition, an 88 megabyte disk as well as several 
disks of 2 megabytes each are available. The display is a Vector General with 4096 x 4096 addressablepoints. 
The peripheralsinclude a joy­stick, 16 functionbuttons, sonic pen and 10 dials, all of which are used 
to interact with the system. Command Language When he is sculpting, a sculptor's natural mode of thinking 
is in terms of transforming a lump of clay in front of him by operating on it by means of various tools. 
It is possible to design a command language in which the graphics sculptor can specify what transformationshe 
wants done on the object on the screen. We believe that for our aims, vis., to give maximumopportunitiesfor 
the sculptor to be creative by letting him operate in a mode most compatible to his thinking,this kind 
of command language is unnatural. We should not force him to think in terms of numerical coordinates 
etc., but rather to feel as if he is operating on the object as directly as possible. For this reason,we 
make extensive use of the dials and functionbuttons. Scaling, rotating, translating, joining, intersect­ing, 
choice of "tools" etc., will be done by the sculptor by means of these analog devices or func­tion buttons. 
The system still provides the sculptor with a "language" to communicate with it, but this is not a conventional 
command language. The system provides the user with certain primitive objects, the sculptor might desire 
to generate his own primitive object. This can be done by select­ ing the sonic pen input routine in 
which the sculptor draws an orthogonalprojectionof the object desired. The system then forms the cylin­ 
drical extension of the projectionforming a 3-D object. This object can then be used as is, or another 
projectionof the object may be drawn with resulting cylindrical extension,and the two 3-D objects intersectedat 
appropriate orientation forming an object with orthogonalviews consistent with the two drawn. If the 
user consistentlyuses certain higher-level primitives, i.e., objects which he has sculpted using the 
system's primitives,it is a simple matter to save these and then substitute them for the system's primitive 
objects during subsequent data generationsessions. Related to this is the abilityby which a user may 
work on a "sculpture" but not complete it, even save it and then retrieve it the following day or the 
following week and finish his creation. The Scenario The scenario envisioned can be typified as follows. 
 The sculptor either starts with a polyhedral object provided to him by the system or a primitive object 
 created by him by the methods described in the pre­ vious section. In this case the sculptor is making 
 a whale and thus selects a polyhedral approximation to a sphere. By means of dials the user can rotate, 
position and then scale the sphere along any axis to the appropriate size for the head and body. With 
group warp, the user can form the tail sectionby positioningand then attaching a cursor to a surface 
point and, in this case, pulling the point out (Fig. 1). An interpolationroutine pulls neighboring 
points proportionally. How many points to warp in the group and the weighting functionare selected 
on dials. The eyes are added simply by joining a cylinder (polyhedralapproximation, of course) which 
has been scaled, rotated and trans­ lated appropriately. The mouth is formed by using a wedge as a cutting 
tool. This can now be tempor­ arily stored away so that the sculptor can create the fins. In this case 
the tail fin is a low­ resolution sphere which is scaled and then cut with a wedge (Fig. 2). The side 
fins are half of the tail fin which have been scaled down more. The resulting object appears in Figure 
3, which has been made from the primitive objects shown in Figure 4. The sculptor,however, is also 
an anima­ tor who wishes to use the whale in a sequence swim­ ming. For this he must now make the whale 
in the extreme positions of swimmingso that the in­ between positions can be interpolatedby the anima­ 
tion language. The user does this by bending the tail section and the side fins. He can bend the tail 
by drawing a "skeleton" through the whale. The system maps the surface points of the whale onto the 
line segments of the skeleton. After the control points of the skeleton are repositionedby the animator/sculptor,the 
system remaps the surface points onto the skeleton maintainingtheir relative positions with respect 
to the skeletal line segments (Figs. 5 &#38; 6). Figure 1 Figure2 140 The sculptor can also, if necessary, 
fashion his own tools to do specific kinds of cutting, because after all, all the tools are "objects" 
and all operations of one object on another can be executed by the intersectionroutine. It should be 
noted that as these operations are being done, the objects appear in the wire-frame mode (i.e., with 
hidden lines not deleted). This is due to the fact that the data structures for the input to the hidden-lineprocessing 
routines are generated by a preprocessingroutine which is not resident in memory except when specially 
called for. In order to increase the interaction,we have opted to do the sculpting operations in the 
wire­frame mode, since the basic algorithms do not need this preprocessing. However, at any time, the 
sculptor can have the hidden-line eliminated ver­sion on the screen to increase his perceptual com­fort 
before deciding on where to cut or how to shape the object. Another aspect of the system is that the 
sculptor, after a sequence of shapings, can go back to an earlier part of the sequence that he has saved 
on a LIFO stack, if he happens not to be satisfiedwith the current state of his sculp­ture. We next 
give brief descriptions of the basic algo­rithms. The intersection, warping and bending algorithms are 
explained in Sections 4, 5 and 6, respectively. Hidden-line processing in a minicom­puter environment 
has been generally slow, however, fast efficient hidden-line implementations are essential for many 
applications. Our hidden-line processingroutine is described in Section 7.  THE INTERSECTION ALGORITHM 
 The intersection algorithm,as noted earlier, is an important part of the sculptor's studio. It oper­ates 
on two overlapping closed polyhedra,say 01 and 02, and can calculate any of the four resulting polyhedra: 
the object defined by the intersection of 01 and 02, that defined by their union and either of the two 
objects formed when using one polyhedronto cut into the other. Although intersectionalgorithms are not 
new, the one presented here is an advancement in generality over others found in the literature. Braid 
(9) describes two types of "addition" for two objects. Besides planar polyhedra,Braid also handles cylin­drical 
surfaces when certain conditions are met (e.g. two curved surfaces cannot intersect). The first type 
of addition is the fusing of two objects when they meet at juxtaposed flat faces. The second type of 
addition is the actual intersection of two objects as long as one object is a (possi­bly transformed) 
cube or cylinder. Cutting or joining is treated as a property of an object in that a "negative" object 
cuts and a "positive" object joins to another positive object. Baumgart (8) describes an algorithm which 
seems to be based on geometric principles similar to ours, but the data structures and actual algorithmare 
different. Further, his algorithm imposes the re­striction that the objects intersected have convex polygons 
for faces. This not only makes the objects more visually complex but since the basic computation in calculating 
the intersection is comparing each edge against each face for inter­section, the operations required 
are increased. Our algorithmimposes no such restriction and is quite general. The data structure which 
is common to all of the routines is organized as a list of faces. Organi­ zation by faces facilitates 
the recording of pro­perties of faces such as color, planar equation, the object the face belongs to, 
the subpart of the object the face belongs to, etc. Each face defini­ tion consists of a face header 
(FH), followed by a list of pointers to the vertices' coordinates (VP) as they appear clockwise when 
viewing the face from the "front" with the first vertex pointer repeating at the end of the list. Betweeneach 
two vertex pointers in the face definitionthere is an edge header (EH). Thus, a triangle's definitiontakes 
 the form: FH,VP 1, EH, VP2, EH, VP3, EH, VP1. In the implementationeach item is one word long. Notice 
that vertice pointers and headers alternate throughout the entire data structure since the face header 
for the next face follows immediately after the last vertex pointer of a preceeding face. The high 
order bit of a header indicates whether it is a face header or an edge header. The face header contains 
color information,object membershipspec­ ification and an offset into a work area where the planar equation 
and pointers to linked lists for intersections and new edges are kept during the intersection calculation. 
The edge header contains a bit indicating whether it is the first or second occurrence of that edge. 
If it is the second occurrence, the remaining bits are a pointer back to the edge header of the first 
occurrence. The remaining bits of the header of the first occur­rence of an edge are a pointer to a linked 
list of the intersections already found for that edge dur­ing the intersection calculation. The vertex 
pointers merely point into a list of coordinate triples. The algorithm uses the fact that the resulting 
object will have faces which are either portions of faces or entire faces of either 01 or 02. Each face 
of both objects must be compared against the other object (i.e., the object that the face is not a part 
of) to determine exactly what portions of the face lie inside of the other object. Once this is done 
for each face, the type of operation desired dictates which portions (those inside versus those outside 
of the other object) will be included in the final object and they completely define the final object. 
For example, if 01 cuts 02 the resultant object consists of those portions of faces of 01 which are inside 
of 02 together with those portions of faces of 02 which are outside of  As is readily apparent, the 
major issue is the organizationof the edge-face intersection informa­tion during the actual intersection 
calculation. The data structure described allows for efficient organization of partial results obtained 
during the calculation. Faces and edges can be searched for efficiently and simply yet the data is compact 
which is a major consideration when working in a  partition. 142 In order to simplify the description 
of the algo-rithm, let UB define by Fij, the j-th face of Wect Oi, and by 33, the k-th edge of Pace Fije 
The algorithm can now be infomally described as Pollovs: MAIN: For i = 1, 2 and all j, give eubroutine 
Al the Pace Pij and information about the type of operation desired. At the conclusion of MAID, all the 
Paces and portions oP Paces belonging to the reeulting object will have been generated. Al: Given face 
Pij, for Pij and P,, u+i and all v, give eubroutine A2 the Paces Fij and Fuv. A2 com-pares the two Pace6 
to find edges of intersection yd to find the intereection points along the edgeseij while noting vhether 
the edge is "going into" or "coming out of" the Pace Fw at that point. When Pace F~J has been compared 
against all Paces Fw (i.e., all poeeible values of v) those portions of Pace Pi lying imide (or outside, 
depending on the operat il on) can be defined in teram of old edge segments of the e$j and the new edgee 
generated by the face-Pace intersections (see Diagram 1). ----new edges --l l l edge segments of results 
in either: or cl depending on operation. Diagram 1. Face-Object Intereection Calculation. AS: Given Paces 
Fij and Fuv for e$j and F, for all k, and for e&#38; and Fi. for all RI, thie calcu-lates the coordinates 
of Al e point of interrection between the edge and the Pace if such a point exiets and sets up an inforlgation 
structure relat-ing the edge, the intersection point aud an indica-tion of which vertex of the edge is 
In "front" of the Pace. The planar equation of tbe Pace is cal-culated so that it reflects the Pact that 
Paces are deilned by a clockwise list of vertices if one looke at the Pace fron the "front." All the 
inter-section pointe generated, say pl, . . .,pa are sorted. They will be collinear and n even (seeDiagram 
2). 'Paire (pi, pi+l), i odd, define edges that belorg to the nev object. At the conclusion of A2 the 
algorithm will have available new edges as well 88 information that will be ueed by Al to generate segment6 
of edges of the original objects which are to be included in the resultant object. ----new edges / / 
 Diagram 2. Face-Face Intersection Calculation. Figure 7a and b show two primitive objects: a sphere 
and a cube. Piwee 8 through 11 show the Pour results obtainable Prom the intersection routine: the joining 
of the two (Figure 8), the intersecting of the two (Figure 9), the spherecuttiug the cube (Figure 10) 
and the cube cutting the sphere (Figure ll). Figures 12 and 13 show example objects created using the 
eyetern. Fiswe 7a. Figure p. 143 Figure 8. Figure 12. Figure 9. Figure 13. 5. wARPIlGAlmR1Tm Figure 10. 
The ability to warp an object ie the ability to re-poeition a single point, or a group of points,independent 
of the reet of the object. As provided here, the user poeitione a cursor near the point to be warped, 
and then at the prese of a button, can pick up the point and move it ae he moves the cur-8or. The user 
can also specify, by meant?. of a dial how many adjacent points to vsrp along with the Initial point. 
Th0 adjacency of a particular pointie epeclfled by the fewest number of edgee which must be traversed 
from the lnltial point to reach the particular point. Also specified on a dial 16 the selection of a 
velghting function to use on the adjacent points being warped, giving the illuelon of elasticity. The 
weighting functions poesessee the attribute of being both easy to implement and visually what one vould 
like to see. Figure ll. If I (positive) le the adjacency Indicator, points B or less edgee away from 
the initial vlllbe warped along with the initial point.repreeentB the delta movement in the X-axis tlon 
of the initial point and k (-64<k<63,example) Ia the weighting function eelector, all point If d, dlrec--for 
a 144 locates a point relative to a skeletal edge. dI along the X-axis where:point I edges away from 
the initial point will be Figures 5 and 6 show a simple example of skeletal warped bending.  6. BENDING 
ALGORITBM Bending, as implementedhere, is similar to the idea discussed by Wein (15) in controlling 
motion by key frame animation. In both, the basic prin­ciple is to alter the shape of an already existing 
 object. Wein's skeletal representation"provides a definitionof some coordinate space within which the 
image, described in relative coordinates, is distributed." The relative coordinates are based on a 
polygonal mesh over which the object is de­fined. This requires either an irregular mesh to be defined 
over the object or the object to be distorted over a regular mesh. The skeleton used'inbending is, 
conceptually, merely a collectionof (possiblyconnected) 2-D edge segments which a 3-D object is mapped 
onto. There is no interferencecaused by multiple uncon­ nected skeletons. This skeletal bending also 
 easily lends itself to implementationin three­ space, if one is willing to programthe mathema­ tics. 
Not only is the skeletal bendingpowerful, but at the same time it is easy for the user to employ since 
all he must be concernedwith is drawing and manipulating the skeleton itself as opposed to a coordinate 
grid. Because of the interactive nature of the implementationthe user can repeatedlyrepositionpoints 
in the skeleton and remap the surface until the correct amount of The time taken for the alteration 
is attained. initial mapping is required only once. Ease-of-use stems from the fact that the system 
automaticallymaps each surface point to a skele­tal edge segment. This is accomplishedby first calculating 
"dividing" lines along the skeleton. These are lines which bisect the angle made at each skeletal edge-edge 
junction (a perpendicular is used at the ends of the skeleton). For each surface point, it is first determinedwhich 
skele­tal edges are possibilitiesfor mapping. The surface point must lie between the dividing lines of 
a skeletal edge (and the dividing lines have not crossed each other) for that edge to be con­sidered 
a possibilityfor mapping. For all such possible skeletal edges, the perpendiculardistance from the surface 
point to the infinite line con­taining the skeletal edge is calculated and the closest skeletal edge 
is used for the mapping. The actual mappingconsists of an indication of which skeletal edge is being 
used, the perpendicular distance as explained above and shown as distance l in Diagram 3, the length 
of the line parallel to the skeletal edge which passes through the surface point and lies between the 
dividing lines (d2 in Diagram 3), and the positionof the surface point in Diagram 3). This completely 
 on that line (d3  7. HIDDEN-LINEPROCESSING IN A MINIC(XPUTER ENVIRONMENT Sutherland et. al. (12) 
and Encarnacao (13) give surveys of available hidden-line elimination algo­ rithms. Our hidden-line 
routine is based on Loutrel's algorithm (14) which employs what is called the path-of-edges technique. 
Though some changes have been made to the algorithm,mainly in the handling of special cases and the treatmentof 
boundaryvertices, we omit a detailed discussionof the algorithm in view of the easy availabilityof (14). 
Instead, we discuss the special considera­tions arising out of the fact that the implementa­tion was 
to be close to real time (here meaning refresh of 30 frames per second and update less than one second 
per frame) in a minicomputer environment. In our system, clipping in X and Y directions is provided 
and if desired, the scene can be displayed in perspective. All transformations are done by are software. 
In addition,the following features noteworthy. First, it is interactive. The user is provided with a 
joystick, various dials and buttons for interactingwith the program. Dials control rotation, placement 
of the picture plane (for the perspective calculation)and scaling. The joystick is used for three-dimensionaltranslation. 
Func­ tion buttons provide for, among other things, trans­ formation speed changes, temporaryhalt, specifica­ 
tion of scene or object for transformation,and exit. The second feature is the speed of process­ ing, 
obtained by programmingin assembler and per­ forming all computations in integer arithmetic. Third, 
is the ability to transform (rotate and translate) independently each object in the scene as well as 
transforming the entire scene. The limitations are two-fold. First, because of the size of the data structures 
used, the routine is restricted to handling less than nine hundred edges. This still allows for reasonably 
complex models. Second, due to the use of integer arith-metic on a 16-bit word machine, overflow and 
under- flow errors occur at times. These, however, are usually few and far between and appear only as 
occasional flashes in normal operation. The routine resides in a 32K partition and con- sists of two 
parts. The first part is the pre-processor which builds the data structures needed by the second part 
to efficiently calculate the visible edge segments. These data structures are built separately for each 
object and an object list is maintained. The requirement of real-time or close to real-time operation 
when the objects are being manipulated imposes the requirement that the preprocessor output should be 
basically indepen-dent of the vertex position data. Thus, the data structures have information about 
faces, edges and objects with respect to one another, and not with respect to the user, and refer to 
the vertices, not by their coordinates, but by pointers to them. Further, in order to minimize cumulative 
inaccura-cies because of integer arithmetic, the positiondata are recomputed for each dial setting. An 
arbitrarily chosen "initial" position and size are operated on by transformation matrices whose para-meters 
are set by the dial information. Figures 14 and 15 give an idea of the results ob-tainable by the program. 
Figure 14a represents a 615-edge scene with hidden lines drawn, while Figure lkb is the same scene with 
hidden lines removed. Processing time was approximately nine ' seconds. Figure 15 shows an Sl-edge scene 
with four objects, the time taken for this being about 0.1 second. It should be mentioned that edges 
are counted only once, not once for each face they appear in. These timings compare favorably with the 
five seconds required by Loutrel's implemen-tation on a CDC 6600 for a 20+edge object. Figure 14a. Figure 
lkb. Figure 15. 8. 3-D PAIDT Once our color video playback system became opera-tional, it was obvious 
that it would be useful if the data generation system could make multi-colored objects. In order to keep 
the data generation interactive, however, it was necessary to retain the wire-frame representation of 
the objects. Thus, the user has no visual feedback of color in-formation during the generation process, 
other than being able to selectively display only those faces of a certain color on a particular object. 
Introducing color into the data generation system was facilitated by the fact that the data was already 
organized by faces. Three bits were set aside in the face header to specify color. When an object is 
input to the system, the user has the option of setting the color bits in each face header to a specific 
color, or he may leave them the way they are set. The intersection algorithm maintains the color information 
with those portions of the faces kept in the resulting object. Thus, a cutting operation leaves the color 
of the cuttingobject wherever that object cuts into the other object. This provides a very easy and natural 
means by which the user can build or sculpt a multi-colored object. The second method of coloring an 
object to speclf-ically pick out a face with a cursor and leave a particular color on that face. When 
the face is picked, the color bits in the face header are set according to three function buttons. Albeit 
this can be a bit tedious, it provides the significant ability of painting color designs on an object. 
 9. CONCLUDING RMARKS  It is hoped that the preceding discussion has given the reader a fair idea of 
the issues involved in the problem of generating3-D data and of the merits of our attempt at a solution. 
The reader should especially note the kinds of human interactionpermitted. The system has been tail­ored 
for use in generatingcolored objects for animation and the operations available to the user reflect 
this. Almost all of the limitations of the system stem from the 16-bit word length of the machine: the 
 limit on complexity (about 2600 edges), inaccuracy in numerical calculations (anoccasional problem), 
 necessity for overlay structure of the program. A 32-bit minicomputerwould solve many problems. Once 
allowing for the handling of greater complex­ity, however, the interactivenessof the system, and therefore, 
the naturalness of use would deteriorate with the higher-complexityobjects. ACKNOWLEDGEMENTS The author 
wishes to thank Professor Charles Csuri and the ComputerGraphics Research Group for pro­viding the facilities 
and a stimulatingenviron­ment. I would also like to personallythank NSF Grant DCR 74-00768. I am indebteded 
to Ron Hackathorn for some of the data generationand photography. REFERNCES 1. Chandrasekaran, B.; 
Parent, R. "Moulding Computer Clay Steps Toward Computer -a Graphics Sculptors' Studio," Pattern Recogni­ 
tion and Artificial Intelligence, Academic Press, 1976. 2. Defanti, T. A. "The Graphics Symbiosis System 
-An InteractiveMinicomputerGraphics Language Designed for Habitabilityand Exten­sibility," Ph.D. Thesis, 
The Ohio State University,1973. Also technical report, Computer Graphics Research Group. 3. Gillenson,M. 
L.; Chandrasekaran,B. "A Heuristic Strategyfor DevelopingHuman Facial Images on a CRT," Pattern Recognition,Vol. 
7, 1975, Pp. 187-196. 4. Sutherland,I. E. "Three-DimensionalData Input by Tablet," Proc. of the IEEE, 
Vol. 62, 4, April 1974.  5. Thorton, R. W. "MODEL -InteractiveModeling in Three Dimensions Through Two-Dimensional 
Windows," Master Thesis, Cornell University,  1976. 6. Lafue, G. "Computer Recognitionof Three- Dimensional 
Objects from Orthogonal Views," Carnegie-MellonUniversity, Institute of Physical Planning,ResearchReport 
No. 56, September 1975. 7. Shirai, Y.; Tsuji, S. "Extractionof the Line Drawings of 3-DimensionalObjects 
by Sequen­tial Illumination from Several Directions,"  Second InternationalJoint Conference on Arti­ficial 
Intelligence,London, September 1971. 8. Baumgart, B. G. "GeometricModelingfor Computer Vision," Stanford 
University,Depart­ment of Computer Science, available from ETIS  as AD-A002, October 1974. 9. Braid, 
I. C. "The Synthesis of Solids Bounded by Many Faces," Vol. 18, No. 4, April 1975. "A Com­ 10. Yoshimura, 
S.; Tsuda, J.; Hirano, C. puter Animation Technique of 3-D Objects with Curved Surfaces," Proc. of the 
10th Annual Meeting of UAIDE, Los Angeles, October 1971.  "A Model   Davis, J. R.; Nagel, R.; Guber, 
W.  Making and Display Technique for 3-D Pictures, Proceedings of the 7th Annual Meetingof UAIDE, San 
Francisco,October 1968.  12. Sutherland,I. E.; Sproull,R. F.; Schumacker,  R. A. "A Characterizationof 
Ten Hidden- Surface Algorithms,"  ComputingSurveys, Vol. 6, No. 1, 1974, pp. 1-55.  13. Encarnacao, 
J. L. "A Survey of and New Solu­  tions to the Hidden Line Problem," Proc. Interactive ComputerGraphics 
Conference, Delft, Holland, October 1970. 14. Loutrel, P. "A Solutionto the Hidden Line  Problem for 
Computer-DrawnPolyhedra," IEEE Trans. Computers, March 1970.  15. Burtyk, N.; Wein, M. "InteractiveSkeleton 
Techniques for EnhancingMotion Dynamics in  Key Frame Animation," Comm. Associationfor ComputingMachinery,Vol. 
19, No. 10, October 1976. 16. Myers, A. J. "An Efficient Visible Surface Program," Technical Report, 
Computer Graphics Research Group, The Ohio State University, July 1975. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563885</article_id>
		<sort_key>148</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[Ways of structuring data within a digital cartographic data base]]></title>
		<page_from>148</page_from>
		<page_to>157</page_to>
		<doi_number>10.1145/563858.563885</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563885</url>
		<abstract>
			<par><![CDATA[The National Mapping Program includes the activities for providing basic map data and a family of general-purpose maps. The U.S. Geological Survey is developing a Digital Cartographic Data Base (DCDB) within the National Mapping Program to include such features and reference systems as the public land survey network, State and county boundaries, transportation systems, and hydrography. Although the public land survey network is administered by the Bureau of Land Management, it is included as a DCDB component because of its relationship to almost all cultural development beyond the thirteen original States. Such data included in DCDB have no legal status and are intended for display and map reference only. The interrelationship of these categories, particularly of the first three, requires care in structuring the digitized data so that valuable time is not wasted in producing cartographic spaghetti. This paper presents some ideas about structuring the components of DCDB.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379940</person_id>
				<author_profile_id><![CDATA[81100419371]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dean]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[Edson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[U.S. Geological Survey, Menlo Park, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379946</person_id>
				<author_profile_id><![CDATA[81100384849]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[Y. G.]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[U.S. Geological Survey, Menlo Park, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Departmental Manual, Department of the Interior, March 30, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Data Access Descriptions, 1970 Census Geography: Concepts, Products, and Programs, U.S. Department of Commerce, Bureau of the Census, DAD No. 33 (Series CG-3), August 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Digital Cartographic Data Base--Preliminary Description, Office of Research and Technical Standards, Digital Applications Team, U.S. Geological Survey, Reston. July 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Edson, Dean T., Lee, George Y. G., Land-line Survey Data Within a Digital Cartographic Data Base, in Proceedings of the 37th Annual Meeting, American Congress on Surveying and Mapping, March 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 WAYS OF STRUCTURING DATA WITHIN A DIGITAL CARTOGRAPHIC DATA BASE Dean T. Edson George Y. G. Lee U.S. 
Geological Survey 345 Middlefield Road Menlo Park, California 94025 BIOGRAPHICAL SKETCH INTRODUCTION 
Dean Edson, a Californian, began his career The National Mapping Program, a Geological in mapping with 
the Corps of Engineers during Survey responsibility within the Department of WWII. He Joined USGS in 
1947 and worked in all the Interior has been established to serve the phases of mapping in the Western 
States, including basic cartographic data needs of the United States. both field surveys and photogrammetry. 
In the The program includes the activities for making austral summer of 1962-63, he was a member of a 
basic cartographic data and a family of general­survey team establishing map control in Antarctica. purpose 
base maps available to users. Most of On assignment to the research staff, he helped the features shown 
on the maps, such as roads, build the computer service division of USGS, buildings, relief, streams, 
lakes, and shorelines, including purchase of a large computer. Since are identified as base categories 
of map data. then he has been particularly associated with Other map data of public value are to be incorpor­automated 
techniques in cartography, organizing a ated but identified as nonbase categories. The symposium in Reston, 
Va., in December 1974, and Geological Survey is responsible for the base serving for several years as 
the U.S. represen-categories of data for the National Mapping tative on Commission III, Automation in 
Cartog-Program and will collect and make the data avail­raphy, International Cartographic Association. 
able in forms that contribute to timely and He is currently Chief, Branch of Cartography, in efficient 
use. In the past, the USGS cartographic the Western Mapping Center of USGS. data base has been exclusively 
graphical, in the form of topographic map sheets. However, with George Lee, a civil engineer currently 
the ever-increasing demand for cartographic data assigned to the Branch of Cartography, Western in machine-readable 
form and the rapid growth in Mapping Center, is working on digital applica-automated cartography, USGS 
is developing a tions in practical cartography. He received a Digital Cartographic Data Base (DCDB) as 
a part B.S. in engineering mathematics and an M.S. in of the National Mapping Program. photogrammetry 
from the University of California, Berkeley in 1973 and 1974. He is a member of DCDB DEVELOPMENT the 
American Society of Photogrammetry. The base data categories of the National ABSTRACT Mapping Program 
include reference systems. Although the Public Land Survey (PLS) network is The National Mapping Program 
includes the excluded from base category status, PLS activities for providing basic map data and a family 
of general-purpose maps. The U.S. Geological Survey is developing a Digital Carto­ graphic Data Base 
(DCDB) within the National Mapping Program to include such features and reference systems as the public 
land survey net­work, State and county boundaries, transportation systems, and hydrography. Although 
the public land survey network is administered by the Bureau of Land Management, it is included as a 
DCDB component because of its relationship to almost all cultural development beyond the thirteen original 
States. Such data included in DCDB have no legal status and are intended for display and map reference 
only. The interrelationship of these categories, particularly of the first three, requires care in structuring 
the digitized data so that valuable time is not wasted in producing cartographic spaghetti. This paper 
presents some ideas about structuring the components of DCDB. not been ignored, particularly since the 
topogra­ phic base maps include a cartographic represen­ tation of PLS. The areas and boundaries defined 
by PLS are the responsibility of the Bureau of Land Management. DCDB will include corner and closing-point 
data and monument data in addition to boundary lines and enclosed areas where the data are avail­able. 
Land grant areas, such as those in Louisiana and California, and new protracted survey data will also 
be included as required. All data will carry codes indicating accuracy of the coordinates, agency source, 
and year field checked. Section-corner data will include type of monument and method of map location 
if avail­able. It must be emphasized that even though USGS includes PLS data in the DCDB, the data have 
no legal validity, either explicit or implicit. Responsibility for legal description and position Permission 
to make digital or hard copies of part or all of this work or personal or classroom use is granted without 
fee provided that copies are not made or distributed for profit or commercial advantage and that copies 
bear this notice and the full citation on the first page. To copy otherwise, to 148 republish, to post 
on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Siggraph 77, 
July 20-22 San Jose, California of section corners remains with the Bureau of Land Management. PLS data 
in the DCDB will be solely a digital representation of the graphically displayed network on standard 
topographic maps. Another base category concerns State and county boundaries, specifically the boundaries 
of the 50 States and the county boundaries within each State. One approach will be to describe States 
and counties as areas enclosed by boundary lines and define the boundary lines as to type (State, county) 
and feature identificationwhere the lines correspond to physical features, such as rivers or highways. 
The areas will be des­cribed by FIPS codes, and access to the data will be through the FIPS codes or 
geographic coordinates. The next closely related category is the transportation network. This category 
could contain primary elements, such as roads, railroads, and poweCilines and pipelines. The type of 
road will need to be considered--limited access, heavy duty, medium duty, light duty, and unimproved. 
 Several classifications for roads are in use, and it will be a goal of DCDB to identify and integrate 
them. The DCDB will also need to provide for the recording of single and multiple track standard­gage 
railroads and selected pipelines and power­lines. The last category to be studied is surface hydrography. 
The category normally includes all perennial drains, intermittent drains longer than 600 meters, and 
perennial open water with a mini­mum dimension of 15 meters. DATA STRUCTURE The concept of the DCDB 
is to be an integrated data base directed not only at map production but also at direct application to 
problem solving. The development is beginning to focus on organi­zation, entry, maintenance, access, 
and display of digital cartographicdata as a user product. The potential benefits will only be realizable 
if the data are structured (organized)in a way that meets the system objectives. One objective of the 
DCDB will be to provide easy data entry, access, and retrieval. Since it is to be an active, working 
data base, the data must be organized so as to minimize massive searches for data access, updating, and 
retrieval. In 1970, a Geographic Base File was developed by the Census Use Study, sponsored by the Bureau 
of the Census, using a technique called Dual Independent Map Encoding or DIME. The geographic base file, 
commonly referred to asGBF/DIME, is characterizedby an editing capability that improves the accuracy 
of the files. The principle underlying the GBF/DIME files is derived from graph theory. Each street, 
river, railroad, tract, municipal boundary, or other feature that bounds a census block can be con­sidered 
as one or more straight line segments. Curved streets and similar features can be divided into series 
of straight line segments. Where streets or other features intersect or change direction, node points 
are identified. Figure 1 illustrates street segments and nodes. A GBF/DIME file is built up in a street­segment 
routine in which each segment record con­tains the appropriate codes for both sides of a street between 
two nodes. Uniquely identifying each segment, each node, and their geographic relationships provides 
a descriptionthat can be checked by computer for accuracy. USGS has tested some aspects of the DIME 
system in the first efforts to collect digitized PLS data. In considering topological structure, we find 
that the relatedness of features can be expressed in two-dimensionalspace by the inter­sections or junctions 
of like or unlike features. These intersections or junctions, in the DIME notation, are defined as nodes. 
In the context of PLS data, if each node is assigned some sort of identification and has a spatial reference, 
such as geographic coordinates, then a group of points forms a topological framework to which other 
data can be related. The PLS could then be a building block for other categories, such as State and county 
boundaries. Figure 2 illustrates nodes identified in a land-net. In DIME notation, the digitizing record 
does not merely contain infor­mation about a single feature, such as a section corner, but instead the 
individual features are coded with their topological relationshipsto other features. In the digitizing 
record (fig. 2), we see that the land line will be digitized as line segments. Each segment carries identifiers 
for a pair of nodes at the ends and a pair of polygon features for the sides. The advantage in digitizing 
in DIME format is that the DIME struc­ture allows for topologicallybased file verifi­cation by computer. 
 The digitizing records are bulky. Moreover, because the file will be fragmentary, directories linking 
segments together into a complete PLS unit are almost as large as the file itself. Hence, in a data reduction 
phase, the digitizing record will be processed to form a section directory and a coordinate directory 
(fig. 2). These two directorieswill be the data base record. The data base structure of PLS will become, 
in fact, a point directory file, with the result of im­proving retrieval and area-computation operations. 
As a result of using DIME notation, feature data need not be digitized more than once, thus elimi­nating 
the messy process of editing coordinate pairs common to several sections. The .data structure for State 
and county boundaries is expected to be much like that of the PLS system. However, a chain directorymust 
be included for handling a string of related points that define a feature from node to node; these 
 are called chains. Figure 3 illustrates the chain identifier for a string of points between nodes. 
 A chain therefore represents a line segment between two nodes. In general, any random line can be 
defined by a chain. With points, nodes, and chains defined, the structure for transportation and hydrographic 
features is simple. Networks of roads and drains, which can be identified as networks, will appear in 
a network directory as two specific types, a branch network for hydrographic features and block networks 
for transportation features. The 149 directory will permit important name identifiers, such as Interstate 
and State route numbers, to become descriptors for data retrieval. (See fig. Similarly, name identifiers, 
such as those of drainage basins and major river networks, will be descriptors for data retrieval in 
the surface hydrography category. Figure 5 illustrates points, nodes, and chains used to define point 
and line features in a drainage network. The data base structure is summarized in fig. 6. Note that coordinate-level 
information of the several categories is retrieval through directories that also link the categories 
to each other. It is important to understand that points, chains, and chain groups can be shared by almost 
any number of features. This structuring tech­nique will enable potential users to obtain copies of the 
point, chain, and node data and establish their own higher order directories for special use without 
redigitizing the basic data. RETRIEVAL METHODS Digital and graphic data in the DCDB will be made available 
to users through the National Cartographic Information Center (NCIC). Requests will be handled by a combination 
of index graphics of approximate coverage over geographic areas and detailed computer data base search 
and retrieval routines. Identification of subsets of the data base, by both locational and feature criteria, 
may be derived from the DCDB. Digital data will be collected in files with each file containing information 
for one carto­graphic unit (CU). For the present, a CU will consist of a 7.5-minute quad sheet. Although 
USGS has chosen that format as the CU, the DCDB will be designed with enough flexibility to accom­modate 
other formats on retrieval. For example, if the user required PLS data in township format, then as many 
as four CUs may be needed to complete one township. (See fig. 7.) Through the use of directories, data 
can be retrieved for reformat­ting into townships. The processing to merge the separate data sets is 
aided by the false corners that appear in adjacent CUs. Similarly, the need to plot particular sections 
or irregular sections is simple with this data structure. Area groups, such as counties, States, and 
sections, established in a way similar to networks; that is, a complete closed area is identified at 
the chain-group level, county or land grant. These smaller units can then be aggregated into States, 
national parks, management areas, or whatever the user requires. SUMMARY The Digital Cartographic Data 
Base (DCDB), to be developed and maintained by the U.S. Geol­ogical Survey, will be a standardized source 
for base categories of digital cartographic data, principally for the United States. The DCDB will provide 
selected cartographic data in digital format to meet known requirements and organized to expand and evolve 
as users gain experience with digital data and refine their requirements. Inclu­ded among base map categories 
will be Public Land Survey (PLS) data. Although the digital PLS have no legal status but represent in 
numerical forms the surveys as shown on topographic maps, they can be used for computations, statistical 
analyses, graphical outputs, and other user requirements. A pilot project will also include data for 
State and county boundaries, transportation networks, and surface hvdrography. REFERENCES Departmental 
Manual, Department of the Interior, March 30, 1976. Data Access Descriptions, 1970 Census Geography: 
Concepts, Products, and Programs, U.S. Department of Commerce, Bureau of the Census, DAD No. 33 (Series 
CG-3), August 1973. Digital Cartographic Data Base--Preliminary Description, Office of Research and Technical 
Standards, Digital Applications Team, U.S. Geol­ogical Survey, Reston. July 1975. Edson, Dean T., Lee, 
George Y. G., Land-line Survey Data Within a Digital Cartographic Data Base, in Proceedings of the 37th 
Annual Meeting, American Congress on Surveying and Mapping, March 1977.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563886</article_id>
		<sort_key>159</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[An extensible approach to imagery of gridded data]]></title>
		<page_from>159</page_from>
		<page_to>169</page_to>
		<doi_number>10.1145/563858.563886</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563886</url>
		<abstract>
			<par><![CDATA[A program offering a variety of cartographic techniques for mapping gridded data is described. Dot-distribution maps, several forms of contour maps and screen-toned maps are currently implemented for plotter and vector CRT. The structure and logic of the program is discussed and illustrated. The approach requires only local access to a data grid in a paging environment, allowing large data sets to be manipulated. Maps output may be plotted at any scale, irrespective of the size of the plotting device. Additional graphic techniques and output devices are readily accommodated, and will become even more so when full virtual memory is implemented. Possibilities for image overlay are discussed and illustrated, and plans for data overlay are outlined.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[analytic hill-shading]]></kw>
			<kw><![CDATA[cartography]]></kw>
			<kw><![CDATA[contour mapping]]></kw>
			<kw><![CDATA[device independence]]></kw>
			<kw><![CDATA[dot-distribution mapping]]></kw>
			<kw><![CDATA[gridded data]]></kw>
			<kw><![CDATA[halftone imagery]]></kw>
			<kw><![CDATA[inclined contour mapping]]></kw>
			<kw><![CDATA[spatial analysis]]></kw>
			<kw><![CDATA[spatial gradients]]></kw>
			<kw><![CDATA[thematic mapping]]></kw>
			<kw><![CDATA[vector graphics]]></kw>
			<kw><![CDATA[virtual graphics]]></kw>
			<kw><![CDATA[virtual memory]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379945</person_id>
				<author_profile_id><![CDATA[81100427201]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Geoffrey]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dutton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Harvard University, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Calcomp (California Computer Products, Inc.). General Purpose Contouring Program. Company Publication, Anaheim, California (1968).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Chrisman, N. and White, D. Programming for Transportability: A Guide to Machine Independent Fortran. Laboratory for Computer Graphics and Spatial Analysis, Harvard University (1977), 40 pp.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Coulthard, W. J. Contouring a Grid: Program Description UBC CNTOUR). Computing Centre, U. of British Columbia, Vancouver, B. C., Canada (1969).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>367688</ref_obj_id>
				<ref_obj_pid>367651</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Dayhoff, M. O. A Contour-map Program for X-ray Crystallography. Communications, Association for Computing Machinery, Vol. 6, (1968).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Dutton, G. DOT.MAP User's Guide. Laboratory for Computer Graphics and Spatial Analysis, Harvard University, Cambridge, Mass. (1977), 40 pp.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Morrison, J. L. Changing Philosophical-Technical Aspects of Thematic Cartography. The American Cartographer, Vol. 1, No. 1 (1974), pp.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Muehrcke, P. Thematic Cartography. Commission on College Geography, Resource Paper No. 19, Association of American Geographers (1972), 66 PP.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Murray, F. W. A Method of Objective Contour Construction. The Rand Corporation-, Santa Monica, California (1968).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Oberlander, T. M. A Critical Appraisal of the Inclined Contour Technique of Surface Representation. Annals, American Association of Geographers, Vol. 58, (1968), pp. 802-813.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Peucker, T. K. and Chrisman, N. Cartographic Data Structures. The American Cartographer, Vol. 2, No. 1 (1975), pp. 55-69.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Peucker, T. K., Tichenor, M. and Rase, W. The Computer Version of Three Relief Surfaces. Display and Analysis of Spatial Data. NATO Advanced Study Institute, John Wiley, New York (1975), pp. 187-197.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Robinson, A. H. and Thrower, N. J. W. A New Method for Terrain Representation. Geographical Review, Vol. 47 (1957), pp. 507-520.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Robinson, A. H. and Thrower, N. J. W. On Surface Representation Using Traces of Parallel Inclined Planes. Annals, American Association of Geographers, Vol. 59 (1969), pp. 600-603.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Rosenfeld, A. Picture Processing by Computer. Academic Press, New York 1969).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Tobler, W. R. Data Display and Presentation. Index paper in environmental information systems, R. F. Tomlinson, (ed.), IGU/COGDSP Publication, University of Saskatchewan Press, Saskatoon, Canada (1970).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Tomlinson, R. F. (ed.). Geographical Data Handling. International Geographical Union Second Symposium on Geographical Information Systems, Ottawa, Canada (1972), Vol. 2, Ch. 11.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 An Extensible Approach to Imagery of Gridded Data Geoffrey Dutton Laboratory for Computer Graphics 
and Spatial Analysis Harvard University Cambridge, MA 02138 U.S.A. A program offering a variety of cartographic 
techniques for mapping gridded data is described. Dot-distribution maps, several forms of contour maps 
and screen-toned maps are currently implemented for plotter and vector CRT. The structure and logic of 
the program is discussed and illustrated. The approach requires only local access to a data grid in a 
paging environment, allowing large data sets to be manipulated. Maps output may be plotted at any scale, 
irrespective of the size of the plotting Additional graphic techniques and output devices are readily 
accommodated, device. and will become even more so when full virtual memory is implemented. Possibilities 
for image overlay are discussed and illustrated, and plans for data overlay are outlined. Key words: 
Thematic mapping, contour mapping, inclined contour mapping, dot­distribution mapping, analytic hill-shading, 
halftone imagery, vector graphics, device independence, gridded data, virtual memory, virtual graphics, 
spatial gradients, spatial analysis, cartography CR Categories: 3.14, 3.23, 3.39, 3.53, 3.56, 3.59, 
3.79, 4.19, 4.22, 4.49, 8.2 1.0 OVERVIEW 1.1 Introduction The work described in this paper was  initiated 
some three years ago with the idea of exploring the cartographic repre­sentation of gridded data. At 
that time (and much more so today) many topographic and statistical data grids were employed as geographic 
data bases, and were also generated from other data for mapping purposes. Their display was generally 
 performed by line printers, and occasion­ally by specialized plotting programs. Although there was no 
evident clamor for software of such a nature, it seemed potentially rewarding to attempt to con­sistently 
automate a variety of tradi­tional and innovative cartographic tech­niques applicable to gridded data. 
 Digital spatial data and computer graphics hardware are more ubiquitous now, but the amount of transportable, 
user-oriented display software available to graphically exploit these resources is still limited. Two-dimensional 
matrices of numbers representing maps were perhaps the first cartographic data structure. Though their 
 utility is a subject of controversy (10), data grids continue to proliferate rapidly, even if satellite 
imagery is excluded from the count. Gridded data are enormously bulky, even when cleverly compressed. 
For archival purposes, far superior data struc­tures exist for spatial data. Efficient and information-rich 
encodings for point, area and surface data have been de­vised and implemented in prototypical in­formation 
systems. Peucker and Chrisman (10) offer a thorough and readable sum­mary of data structures of interest 
to cartography. Permission to make digital or hard copies of part or all of this work or personal or 
classroom use is granted without fee provided that copies are not made or distributed for profit or commercial 
advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, 
to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or 
a fee. Siggraph 77, July 20-22 San Jose, California Despite these advances, many years may elapse before 
the expediency of grid­ded data is eclipsed by more sophisticated techniques. This will come to pass 
only when the creation and maintenance of a so­called topological data base is as easily managed as 
that of gridded data. The latter, for all its limitations, is never­theless easily generated, transported, 
compared, displayed and conceptualized. Due to the high internal redundancy of grids of numbers, images 
of them can be detailed and rich using localized rela­tional and graphic transformations. This means 
that data access need not be global in scope, and that even overlay of gridded data sets can be accomplished 
with limited memory and inexpensive algorithms. What is reported on here is an ongoing attempt to expedite 
graphic display and analysis of such data as inexpensively yet flexibly as possible. The demands on the 
operating environment are fairly modest; a Fortran compiler, 128K bytes of memory, interac­tive execution 
capability, and a vector­addressable graphic output device. An experimental vehicle for these  concepts 
has been developed and is avail­ able for field testing, a program called DOT.MAP (5). Its name derives 
from the initial version, which rendered matrices  representing spatial data as dot-distri­ bution 
maps. Now also capable of plotting the same data as several forms of contour maps and as raster-shaded 
maps under in­ teractive control, the program can be used to create images with a wide range of textures. 
Although created with carto­ graphic applications in mind, the program's spectrum of graphic possibilities 
can be applied equally to image data, instrument read-outs, and even tabular statistics. Recognizing 
certain limitations in the control structures and data handling techniques used in DOT.MAP, a successor 
to it is being programmed which will offer greater possibilities for symbolism con­ data recoding and 
transformation, cosmetic legends, and most importantly comparative study of datasets. To be known as 
MIRAGE, it will embody DOT.MAP's capabilities in a virtual disk environment managed with directories. 
The directories will be extensible to handle as many data types as evolving capabilities may require. 
Data from matrix input, through graphic and textual legends, to bit-maps output to raster displays, and 
all other types will be all paged from disk as required by the state of the program. Maps themselves 
will be data types, can be catalogued and then referenced for inclusion in later maps. Inclusion may 
be analytically driven or performed as graphic overlay and inset of independent map components. The 
remainder of this paper summa­rizes features incorporated into DOT.MAP, attempting to satisfy the curiosity 
of a large spectrum of graphic researchers, and goes on to outline its projected enhance­ment as MIRAGE. 
Graphic examples have been given as much space as possible, forcing this exposition to be an overview 
rather than a treatise. Discussion of the pro­posed architecture for MIRAGE is intended as a point of 
departure, in order to sti­mulate critical comment and suggestions. Readers interested in specific algorithmic 
details should contact the author, as well as readers who would like to experiment with the DOT.MAP program 
itself, or even­tually with MIRAGE.  1.2 Summary of Operation Matrix data input to DOT.MAP (as row 
vectors) are blocked into pages of a ran­dom-access work file. The size of a page is fixed when the program 
is installed, and is normally chosen to optimize disk I/O under whatever constraints may be dic­ tated 
by the operating system. In the environment, for instance, where binary files are allocated storing at 
most one record per disk block, regardless of the length of records, page size should be a multiple of 
the block size (128 words). Other environments present equally arbit­rary constraints to random-access 
files under Fortran. It is not difficult to alter the program's page size, should this be necessary. 
 Figure 1 describes logical flow be­tween the principle procedures of DOT.MAP. Optional procedures are 
enclosed in dashed boxes. This flow of control is typical of "set-go-do" data processing; command assignment 
is followed by an input phase, then a processing phase. Inter­action with users occurs only in the com­mand 
phase, with confirmation required  before graphic output actually commences. Interactive control mechanisms 
in the com­mand phase are fairly extensive, however, and include: *Matrix statistics reports *Help messages 
*Numeric symbolism "preview" -Matrix interrogation and cell  ·Parameter assignment and switch­ Command 
status reports  editing tutorial sessions The command language for DOT.MAP cur­rently is a relatively 
primitive keyword language having a limited verb-object syntax, where "verbs" are imperative key­words 
or action modifiers for the "objects" which follow them in two-word "sentences" typed by the user. There 
are 44 keywords, all 1, 2, 3 or 4 letter words or mnemonics. Assignment of parameters is indicated by 
typing a keyword (if eligible for assign­ment) without a preceding verb. Prompts are then issued to the 
user to solicit required parameters or to provide documen­tation.  160 Familiarity with the command 
language and program capabilities can be gained through interaction with tutorial files. The program 
may be used to generate as well as to read tutorials for specific purposes, such as to provide on-line 
in­ struction for students in a cartographic laboratory, or to convey technical consi­ derations for 
specialized applications of the program. Three graphic processors, each a sub­routine which generates 
symbolism of a particular type, perform data representa­tion. Each runs through a row of values to fill 
a swath with symbolism on the display. The shading processor alone generates all screen addresses needed 
for the output; the random-dot processor and the contour processor both extract coor­ dinates for symbols 
out of tables. The tables contain normalized addresses of all possible symbol coordinates a cell may 
contain, and are generated just prior to mapping. Using tables -or fonts -re­duces the computational 
complexity of generating symbolism; because the display is generated locally and sequentially, cell 
by cell, it is possible to pre-assign all possible symbolism locations to an idealized cell. These coordinates 
are then selected by the symbolism processor, appropriate offsets added to locate the symbols in the 
proper display cell, and then plotted directly.  1.3 Size Limitations No limit is enforced to the size 
of maps that may be commanded. Maps of great physical extent can be produced by the pro­gram, regardless 
of the size of the plot­ting instrument. All maps in which either dimension exceeds the limits of the 
plot­ting space will be partitioned into sec­tions, which are plotted in succession. This is, of course, 
more expensive in terms of data accesses but is mainly paid for by a reduction of resolution (incremental 
 addressability). As the area of a mapped cell increases, the minimum distance be­tween addressable points 
on the plot also increases. It so happens that this will occur automatically when the number of contour 
lines crossing a cell edge would increase over 80. At some point the roughness of the raster will become 
objec­tionable, but this may be well above the size of the largest maps one would normally make. The 
user is free to set the reso­ lution to be larger than the minimum that a particular map demands. Matrix 
dimensions, on the other hand, cannot be unlimited. The number of cells that the program can map at once 
has a current ceiling at 250,000, no more than 500 rows or 500 columns. The column The  limitation 
is the critical factor.  program handles data as row vectors which have arrays limited to 500 columns. 
Only three such vectors are ever handled at once, requiring that the program have 1500 words of data 
space for matrices. Another 2000 words are actually employed to buffer these active vectors. The limitation 
on rows is entirely superfluous. It merely exists to avoid encouraging excesses. 1.4 System Interfacing 
 Obviously no program which performs plotting can be considered to be "hardware­independent". Certain 
graphic output de­vices are sufficiently widespread that their plotting protocols have become de facto 
standards for graphic output (CaTcomp plotters and Tektronix CRT displays in par­ticular), but even 
when these conventions are adhered to in programs their implemen­tation is frequently careless. Similar 
considerations apply to interfacing with external files of any sort. Whether files are sequential, random-access, 
formatted or binary, mainframe operating systems differ widely in the conventions used for acces­sing 
information stored on external devices. Even as simple an operation as a file REWIND has different semantics 
from system to system, and conventions for file decla­ration have no standardizationwhatsoever. It has 
thus been made a policy by the Laboratory for Computer Graphics and Spatial Analysis, not only for DOT.MAP 
but for all recent software, to isolate all system-specific interfaces into replace­ able modules which 
may be tailored to ag­ree with local protocols. This means that there are only one or two.Fortran state­ments 
for each device-specific function to be found in a program, isolated in a well­ documented subroutine. 
Modifications of these are readily accomplished at user sites without the tedious necessity of examining 
all routines in a large program. The graphic driver for DOT.MAP incor­porates calls to both Tektronix 
and Calcomp library routines, and utilizes a rather basic subset of them, making substitution of other 
plotting devices extremely straightforward. In addition, an output option exists which creates a densely 
formatted sequential file of plotting com­mands, in the form of (x-coordinate,y­ coordinate, operation 
code), using Calcomp codes. These files are transportable, and may be displayed on a variety of plotting 
devices by writing an extremely simple program to read them and issue appropriate plotting calls. Though 
sometimes bulky, these plot files are much more compact than what plot tapes usually contain, and thus 
provide a convenient medium for ar­chival storage of graphic output in machine­ readable form. "Software-independence"means 
that a  standardized subset of a widely implemented high-level language is used throughout a program. 
The Laboratory has chosen Fortran as its medium of exchange, and has attemp­  ted to restrict its use 
to the ANSI-recog­ nized subset of that language. A few exceptions to this practice still prevail, either 
due to gaps in standardization (end­of-file tests, for example), or to encour­age (but not require) site 
implementation of assembly-level routines rather than their Fortran equivalents. Certain basic utility 
subroutines can be vastly more efficient when coded in assembly language rather than Fortran, and these 
have also been modularized to allow easy substitution at user sites. For a detailed exposition of the 
prin­cipal issues confronting transportability of Fortran, see Chrisman and White (2).  2.0 GRAPHIC 
CAPABILITIES 2.1 Random Dot Symbolism This option generates dot-distribution maps, and of those incorporated 
into the program is the easiest form of symbolism to calculate (but may still produce lengthy plots). 
Once for each map re­quiring it a dot font is established as an array of randomized x-y coordinates. 
Each possible location for a dot in a normalized cell is generated sequentially, and then shuffled into 
a pseudo-random order within this array. The array is of fixed maximum length, hence there is an upper 
limit to the number of dots any cell can contain. As mentioned above, this limit is currently 500 dots. 
Should a cell have more screen addresses than 500, due to the scale of the map, a minimum resolution 
(distance between adjacent points) is calculated to limit the number of possible points per cell to 500 
or less. If necessary, such changes in resolution occur automatically, beyond user control. Rarely, however, 
will resolution be forced to rise above seven plotter increments, and this is not far from the limit 
of visual resolution (depending on the physical size of dots on the map). fact, when using a plotting 
device capable of addressing 200 points per inch, a dot font of 500 points with a 7-step resolution 
allows cells to be about 3/4 of an inch square (360 mmd), a rather large size for a unit cell. Adjacent 
dots  in such a cell would be 0.035 inches apart (0.89 mm). To completely blacken -such a cell, a rather 
large spot size would be needed, but considering the scale of representation (a 50 x 50 cell matrix would 
produce a map over one yard square at such a scale) large dots would be required in order to be visible 
at re­production scale. The program does not provide for set­ ting the size of dots except as a hardware 
function of certain terminals. Dot size can be set on plotters by selecting an appropriate nib for the 
pen.  2.2 Contour Symbolism Contour mapping procedures in DOT.MAP are constrained-by the self-imposed 
neces-sitv to restrict calculations to a small locality and moving the locality through the matrix in 
ordered scans. Only a cell's immediate (8-cell)neighborhood is thus available for computin the location 
of contour segments. This 4 unless several data passes are made) effectively precludes contour smoothing, 
as the resultant isa-rithms are not maintained as objects (strings of coordinates). The smoothness of 
isarithms is thus highly dependent upon the density of grid points-and the con-tinuitv of variation of 
z-values within a localilty. Individual contour segments tend to be one-quarter to one-half the length 
of the unit cell, which usual.ly produces isarithms which appear to curve continuously, except near local 
extrema, where diamond-shaped contours may appear. Figure 3 shows DOT.MAP's contour represen-tation of 
an island's terrain. Cell edges have been drawn along the shoreline to illustrate the resolution achieved 
with this 75 x 75 cell grid. The method is similar to that of Murray (8), in that it connects cell edges 
at interpolated points with straight seg-ments, but is table driven, rather than using a decision tree. 
Unlike Dayhoff's (4), Coulthard's (3) or Calcomp's (1) methods, there is no array searching to follow 
isarithms from start to finish. Nor does the present method decompose cells into two or more triangles 
as Dayhoff and Coulthard do. Instead, each cell is decomposed into four quadrants (rectan<:!es) having 
an origin at that cell's center, as described below. Rectangular partitioning still leaves the local 
geometry over-de-fined, potentially causing erroneous decisions at saddle points, but also re-duces the 
area affected by a factor of four. Saddle point ambiguity can be re-moved by deciding to plot contour 
segments around the rising (or falling) slopes of the saddle. This requires a partial sort of local elevations. 
Work is in progress to implement this in a way that can avoid many of the unnecessary calculations such 
a procedure might generate. In calculating isarithms, values are assumed to be located at points centered 
in each cell's display area. In order to calculate where an isoline enters and leaves a cell, it is necessary 
to be able to estimate a value anywhere along the edge of a cell. Thus the first step is to interpolate 
values at the cell peri- meter. For this purpose the 8 neighboring values are averaged with the center 
(ref- erence) cell. If, however, all values .in the neighborhood fall enti.rely in one contour-interval, 
the cell is skipped over, as it will contain no symbolism. If the converse is true there still may be 
no contours to draw, but further analysis is required. 163 The next step requires interpolation of 
values to the corners and edge centers of the reference cell. These values are. arithmetic averages of 
the reference cell's value and (for corners) the 3 other cells touching the corner, or (for edges) the 
cell sharing the edge with the reference cell. Figures 4a-4d illustrate the inter­polation process in 
a nine-cell neighbor­hood. Figures 4c and 4d represent the partitioning of the reference cell. As the 
diagram shows, the result of interpo­lation is to divide the reference cell into 4 quadrants, with a 
value allocated to each corner. The center value is the ori­ginal reference cell value, the others are 
interpolations. This quartered cell has 12 edges, and a certain number of "slots" exist along each of 
them through which a contour line might pass. Each such slot represents one or more screen increments, 
whatever the resolution has been set to be. Storage constraints limit the number of slots along a quadrant 
edge to about fifty. Using the two values terminating the edge, each edge in turn is evaluated for crossing 
contours. If so, a length­ratio is computed to find the slot nearest to where contours cross and a corresponding 
word in an array is marked with the inte­ger level of that contour line. A parallel array contains (pre-calculated) 
x-y coor­dinates for each slot. After all 12 edges have been evaluated, points where contours cross edges 
are paired using a table which identifies all legitimate pairs of edges (there are 36 such pairs). The 
order of evaluating edges, currently arbitrary, could be made sensitive to the inflection point problem 
mentioned above. Each time a pair of edges both contain markers for the same contour level, the normalized 
x-y coordinates of each marked slot are read from their array, and offset to the current display cell 
origin. The segment is plot­ted, and the markers in the array slots are made negative. If the level marker 
for either endpoint already was negative, the point is used but the marker is zeroed. Discarding twice-used 
markers effec­tively precludes the appearance of bifur­cating contour lines. Due to the use of a font 
containing normalized x-y coordinates of the slots, many calculations are avoided and accurate registration 
of con­tour segments is possible. The analogue between this procedure and the one em­ployed for creating 
random dot symbolism should be apparent.  2.3 Inclined Contour Representation An inclined contour 
map is one in which the planes which intersect the data terrain to produce contours are not hori­zontal. 
This technique is also known as the Orthogonal Relief Method (12). When angled intersections are made 
with a sur­face, closed contours begin to open, grow more densely spaced, and eventually orient themselves 
as parallel undulations across the map. Once tilted, contours are no longer isarithms. Though they yield 
no specific elevation readings, inclined contours have the advantage of modeling surface relief. The 
"front" and "back"  of hills are shaded differently, removing the visual ambiguity from which most isa­rithmic 
maps suffer. Hills and dales be­come explicit in their relationships, but planimetric relief is preserved, 
unlike block diagram representations of surfaces. If horizontal contours are also desired, they may 
be overlaid with a set of in­clined contours. Figures 5 and 6 demon­strate the inclined contour output 
of DOT.MAP, the latter being overlaid with horizontal contours. 2.35 Inclined Contour Method A direct 
implementation of the Ortho­gonal Relief Method turns out to be quite difficult. Tracing the intersections 
of an inclined plane with a data terrain is computationally tedious, and requires special logic to deal 
with surface-specific features such as ridges, courses and passes. Such difficulties are largely circumvented 
by simply tilting the data terrain itself and then performing a nor­mal contouring procedure. A z-offset 
is defined for each grid cell, based on the x and/or y coordinates of the cell and the angle of inclination 
for the contours. Adding this offset to each cell generates a tilted plane on top of which the data now 
sit. Isarithms plotted on this sur­ face are equivalent to inclined contours; orthogonal relief is displayed 
yet the contouring procedure is still performing its usual task of interpolating isarithms at fixed 
z-intervals. An analytic expo­ sition of this method is well summarized in Peucker et al (11), following 
Robinson and Thrower (13). For further discussion see Oberlander (9).  2.4 Hatched ("fuzzy") Contours 
 Tobler (15) has suggested that isa­ rithms should be displayed as variable­ width bands rather than 
with lines of uniform thickness. The purpose of this would be to communicate the degree of precision 
with which individual isarithms can be located, a sort of graphic confi­ dence interval. This concept 
is discussed and illustrated by Muehrcke (7). Briefly, the logic is that the data to be contoured, 
 whether originally given in gridded form or as spot elevations, will contain measurement error. Uncertainty 
concerning the true elevation at any control point is geometrically translated into planimetric uncertainty 
about where contours in that locality should lie. Where local slope is steep, little horizontal displacement 
due to vertical error will result; where slopes are gentle the same vertical error has a more variable 
planimetric component. This principle has been used by Rosenfeld (14) in picture processing applications 
to depict gradients. His method, although extremely simple and effective, demands that a z-value be 
available for every ad­ dressable point on the output graphic, and in practice requires a raster-addressable 
 (i6). output device such as a matrix printer. This approach is discussed in Tomlinson An approximation 
of Tobler's idea has been implemented in DOT.MAP, which uses the existing contouring procedure. Results 
so far are unpolished, but arres­ting and capable of refinement. The method simply involves calculating 
segments isarithms in the normal way, and then rotating each contour segment by ninety degrees about 
its center, scaling the rotated vector, and plotting it. Scaling is done with reference to a matrix of 
slopes, derived beforehand by the program from the input data and appended to the work file. At maximum 
slope, a segment's length is one unit of resolution; at mini­mum slope, a segment will grow to one-half 
the minor cell dimension. The result is relative uniformly spaced parallel seg­ments (called "fuzz" in 
the command lan­guage) which if dense enough begin to resemble hill-shading (Figure 7). In­clined contours 
could also be represented with the same technique. This has not been attempted, but deserves exploration. 
  2.5 Band Shading The graphic quality of isarithm symbolism depends heavily on the smooth­ness of 
the data it is used to represent. If the data terrain is not relatively con­tinuous in its spatial variation, 
its re­presentation using isarithms may be both inappropriate and unsuccessful. In addi­tion, maps which 
display only isarithms (horizontal, not inclined contours) may be visually ambiguous, yielding no apparent 
distinction between rising and falling slopes. Labeling contours with numeric values is the usual way 
of providing such information, but this facility requires either a sophisticated algorithm for auto­matic 
label placement or an interactive labeling facility allowing manual interven­tion to accomplish this. 
 A much easier solution to isarithm identification involves shading the areas between isarithms. The 
overlay of shading and contours makes relative relief explicit, and if a key to shading symbolism is 
pro­vided, permits quantitative evaluation of surface elevations. An example of this technique is Beckwith's 
contour map of U.S. population densities, a portion of which appears in Morrison (6), but the screen 
tones were manually applied, though the contours themselves were generated auto­matically. A shading 
facility has been incorpora­ted into DOT.MAP which permits such over­lay to be accomplished by computer, 
simul­ taneously with the generation of contour symbolism. Maps may also be produced with shading as 
the only symbolism. The primary type of shading has been called Band Shading by the author, and is constructed 
 by plotting continuous horizontal lines, vertical lines, or both across the map, letting the width of 
each line (or band) vary in proportion to the value of cells that the band traverses. The results are 
essentially the same as those yielded from photomechanical (half-tone) line tech­niques, or from video 
imagery. The amount and range of tonal variation can be user­specified, within the limits established 
by the image size and resolution currently in effect. The resolution of such images (lines per inch) 
can be high, given an accurate plotting device and a sufficient­ly dense grid of data. Naturally, the 
smaller the matrix dimensions are, the smaller the physical size of the map must be to maintain a given 
degree of resolu­tion. The technique of generating shading bands is simple and inexpensive (especially 
when bands are horizontal), yet can be closely controlled by the user. As band thickness is varied by 
plotting parallel vectors spaced at the resolution limit currently being enforced, variations in density 
are perforce quantized within obvious limits. One band will be plotted per row and/or column of data, 
and the number of shading graduations possible is thus limited to be equal to or less than the appropriate 
cell dimension on the map, divided by the incremental resolution (minimumdistance between adjacent 
vectors) then allowed.  Figures 8, 9, and 10 illustrate Band Shading, first overlayed with conventional 
 isarithms, then with inclined contours and  finally without any other symbolism. In Figures 8 and 
9 horizontal shading is em­ ployed, and has been constrained to vary from roughly ten to seventy percent 
black­ ness, so that underlying contours remain visible. Figure 9 is particularly inte­ resting, as 
the interaction of the horizon­tal shading bands and the inclined contours generates a moire pattern. 
The interfer­ence pattern creates alternating light and dark zones which take on the appearance of virtual 
isarithms. These are not true isarithms, as they are not constructed by connecting points of equal elevation. 
Note, however, that the bands grow narrow on steep slopes and wide on gentle slopes, thus communicating 
gradient information in a way analogous to but graphically distinct from the fuzzy contour method discussed 
above. Figure 10 simply displays the same data rendered with crossed bands of shading alone. This symbolism 
is perhaps the most appropriate type in DOT.MAP's repertoire for representing nominal data, and ways 
to classify such data will be incorporated into MIRAGE.  3.0 DESCRIPTION OF MIRAGE 3.1 Current Objectives 
 The cartographic representations of gridded data described above have proven viable and extensible as 
implemented in DOT.MAP. That program's control structure (in particular its keyword command lan­guage, 
parameter storage, and data access techniques) embody certain limitations prohibiting the handling of 
multiple data sets. To capitalize on the inherent power of DOT.MAP's techniques, a general re­vision 
of its architecture is in progress, to be implemented as MIRAGE. Little will change in the graphics module, 
except to access data using a ring, rather than a rolling buffer for data access, but the command module 
will be completely revised, and directory-driven paging environment established for all data types handled 
by the program.  3.2 Data and Directory Structure There are about eight types of data which can reside 
on MIRAGE's memory pages, plus several subcategories of these. All data are managed by a directory which 
it­self is virtual; the directory is unnec­essary during map execution, and its page space is freed for 
matrix data. The data types include:  directory itself language lexemes symbolic constructs  The directory 
entries vary in length according to the nature of the data they describe. The minimum entry (such as 
for lexeme data) consists of just a disk ad­dress for the data. Directory entries for matrix data are 
larger, summarizing the matrix storage location, size and value statistics. Although the directory can 
be paged, it is not likely that more than one page will be required except in the most lengthy and complicated 
executions of MIRAGE. Command language lexemes are coded in DATA statements and embedded in a tree data 
structure. This allows.efficient parsing of commands given in verbose or short form by the user (or a 
command file). Additionally, a user may define during execution new lexemes which are symbolic for numerical 
or alphabetic constants which the user may wish to reference. These lexemes are added to the tree dyn­amically, 
and exist until the program ter­minates (but may be written out as files to preserve the definitions). 
The lexical data is page-resident, for it is not required at all times. During mapping, in particular, 
the language module is dormant. Symbolism fonts, on the other hand, need exist only during mapping, 
and need not be saved on disk following a map. Depending on the amount of matrix data needed for a given 
map and the number of symbolism types to be displayed, several fonts may be swapped onto and off of a 
single page, and thus reside on disk temporarily. Such paging can generally be avoided. 3.3 Analytic 
Capabilities MIRAGE will let users interactively define a highly detailed graphic represen­tation of 
matrix data, choosing from many possible nuances of symbolism, and to com­pare two sets of data on a 
cell-by-cell basis. This comparison may be purely visual, accomplished by overlay of symbo­lism, or may 
be arithmetic or logical. In the latter cases, the user can' define a transformation in the form of a 
state­ment function to manipulate data and para­metric constants. The expression evaluator is part of 
the command language module, which parses the user's function into a command stack controlling a subroutine 
callable for value transformation. Of the one hundred or so parameters associated with any given map, 
users will rarely assign more than ten or twenty, letting the rest default to initial values or to values 
determined by other para­meters. The parameters for the current map are not page-resident, hence fairly 
ephemeral. However, any map worthy of note may be preserved by transferring its parameters to virtual 
memory. To do this, the user merely assigns a symbolic name to the map currently defined. This name and 
a disk address are stored in the direc­tory and the map parameters written to a block of storage. Later, 
this map may be recalled by name, displayed, altered and saved again under the same or a different name. 
The parameters of a current state can also be written out as a character­formatted command file for use 
at a later date. Command files are created by the "show" processor of the language module. This processor 
displays the value of a variable in response to the user's command "SHOW (PARAMETER NAME)". This processor 
can also assemble a file of statements that mimic user commands, useful for tu­torial purposes and debugging, 
as well as allowing a map's recreation. The ability to parametrically summa­rize and reconstitute any 
reasonable num­ber of map images should encourage experi­mentation with graphic overlay of such images. 
An overlaid map is specified simply by a tuple of symbolic names, each of which identifies a map previously 
 created and preserved under that name. 4.0 CONCLUSIONS A variety of cartographic techniques applicable 
to gridded digital data have been automated. Some of these have been implemented in an experimental 
interactive program for cartographic display. This program is being modified to allow more possibilities 
for data representation and analysis, particularly logical, arithmetic and graphic overlay of gridded 
map data. These implementations are designed to be relatively installation-independentand have user-oriented 
command languages using English-like syntax. Their applications include stand-alone use as cartographic 
teaching aids, map production for publi­cation, and analytic/display modules with­in the framework of 
a geographic informa­ tion system. BIBLIOGRAPHY [1] Calcomp (California Computer Products, Inc.). General 
Purpose Contouring Program. Company Publication, Anaheim, California (1968).  [2] Chrisman, N. and 
White, D. Program­ming for Transportability: A Guide to Machine Independent Fortran. Laboratory for Computer 
Graphics and Spatial Analysis, Harvard University (1977), 40 pp.  [3] Coulthard, W.J. Contouring a 
Grid: Program Description UBC CNTOUR).  Computing Centre, U. of British Columbia, Vancouver, B.C., 
Canada (1969).  [4] Dayhoff, M.O. A Contour-map Program for X-ray Crystallography. Communi­cations, 
Association for Computing Machinery, Vol. 6, (1968). [5] Dutton, G. DOT.MAP User's Guide. Laboratory 
for Computer Graphics and Spatial Analysis, Harvard University, Cambridge, Mass. (1977), 40 pp.  [6] 
Morrison, J.L. Changing Philosophi­cal-Technical Aspects of Thematic  Cartography. The American Carto­Vol. 
No. 1 (1974), pp.  [7] Muehrcke, P. Thematic Cartography. Commission on College Geography, Resource 
Paper No. 19, Association of American Geographers (1972), 66 PP.  [8] Murray, F.W. A Method of Objective 
 Contour Construction. The Rand Cor­poration-, Santa Monica, California (1968).  [9] Oberlander, T.M. 
A Critical Apprais­  al of the Inclined Contour Techn'ique  of Surface Representation. Annals, American 
Association of Vol. 58, (1968), pp. 802-813.  [10] Peucker, T.K. and Chrisman, N. Car­tographic Data 
Structures. The American Cartographer, Vol. 2, No. 1 pp. 55-69. [11] Peucker, T.K., Tichenor, M. and 
Rase, W. The Computer Version of Three Relief Surfaces. Display and Analy­sis of Spatial Data. NATO 
Advanced Study Institute, John Wiley, New York (1975), pp. 187-197.  [12] Robinson, A.H. and Thrower, 
N.J.W. A New Method for Terrain Representa­ tion. Geographical Review, Vol. 47 (1957), pp. 507-520. 
 [13] Robinson, A.H. and Thrower, N.J.W. On Surface Representation Using Traces of Parallel Inclined 
Planes. Annals, American Association of Geographers, Vol. 59 (1969), pp. 600-603.  [14] Rosenfeld, 
A. Picture Processing by Computer. Academic Press, New York  [15] Tobler, W.R. Data Display and Presen­tation. 
Index paper in environmental information systems, R.F. Tomlinson, (ed.), IGU/COGDSP Publication, University 
of Saskatchewan Press, Saskatoon, Canada (1970).  [16] Tomlinson, R.F. (ed.). Geographical Data Handling. 
International Geo­graphical Union Second Symposium on Geographical Information Systems, Ottawa, Canada 
(1972), Vol. 2, Ch. 11.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563887</article_id>
		<sort_key>170</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[Automated contour mapping using triangular element data structures and an interpolant over each irregular triangular domain]]></title>
		<page_from>170</page_from>
		<page_to>175</page_to>
		<doi_number>10.1145/563858.563887</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563887</url>
		<abstract>
			<par><![CDATA[Surface display techniques, including contour mapping, usually use an interpolant when data values are on a rectangular grid; but when values are irregularly located some form of assumed or estimated distance-weighting function is often used to estimate the "influence" of data points at other locations. If moving average (or some other) techniques are then applied, slopes may be zero at data points; extrema may fall at data points exclusively; or surfaces may not pass through data points.An alternative method is proposed whereby a map area is automatically divided into suitable triangular domains with a data point at each vertex. Surface estimation and contour plotting are then performed independently for each triangle using a measured or best-fit plane associated with each data point. The approach requires the utilization of three non-original aspects: 1) the derivation of a local homogeneous "area" coordinate system for any arbitrary triangle; 2) the construction of a data-structure linking each triangular domain with its three neighbouring triangles and three associated data points, and 3) the use of a "conforming" triangular finite-element interpolating function.Use of the first two of these concepts permits the economic generation and optimization of a triangular mesh from a set of data points. Optimization criteria used to define the "best" triangular partition are described in some detail, along with computer timing for this step. Use of the first and third concepts permits the interpolation of a smooth surface over the whole map area even though each triangular element is estimated and plotted independently. The requirements for a suitable interpolating function are discussed, and an interpolant is suggested that preserves elevation and slope at each data point as well as elevation and slope continuity between domains. Extrema need not be located at data points but are constrained by their associated planes. Contour line segments are produced by division of each triangle into N<sup>2</sup> sub-triangles, elevation estimation at each resulting node, and linear interpolation and plotting withing each sub-triangle. Resolution is then a function of N and local data point density. Extension of the method to higher dimensions is briefly discussed.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[cartography]]></kw>
			<kw><![CDATA[contour mapping]]></kw>
			<kw><![CDATA[finite elements]]></kw>
			<kw><![CDATA[graphical data structures]]></kw>
			<kw><![CDATA[homogeneous coordinates]]></kw>
			<kw><![CDATA[interpolation]]></kw>
			<kw><![CDATA[partitioning]]></kw>
			<kw><![CDATA[points]]></kw>
			<kw><![CDATA[random data]]></kw>
			<kw><![CDATA[surface display]]></kw>
			<kw><![CDATA[triangular elements]]></kw>
			<kw><![CDATA[triangular mesh]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379937</person_id>
				<author_profile_id><![CDATA[81100509961]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Gold]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Alberta, Edmonton, Alberta, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379965</person_id>
				<author_profile_id><![CDATA[81100155635]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Charters]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Alberta Environment, Edmonton]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P379948</person_id>
				<author_profile_id><![CDATA[81100368739]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ramsden]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Alberta Research, Edmonton]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bengtsson, B. F. and Nordbeck, S. Construction of isarithms and isarithmic maps by computers. B. I. T. 4, (1964), 87-105.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Feuerbach, K. W. Grundriss zu analytischen Untersuchungen der dreieckigen Pyramide. Nuremburg, 1827.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Frenkel, Y. and Gill, D. An algorithm for contouring random data without gridding. Israeli J. Earth Sciences 24, (1975), 56.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Gold, C. M. Triangular element data structures. The University of Alberta Computing Services Users Applications Symposium Proceedings, Edmonton, (May 1976), 43-54.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Gold, C. M. Surface estimation from irregularly spaced data points using an interpolant over irregular triangular domains. Geological and Mineralogical Associations of Canada Program with Abstracts 1, (May 1976), 84.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Heap, B. R. Algorithms for the production of contour maps over an irregular triangular mesh. N. P. L. report NAC 10, (1972).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Irons, B. M. A conforming quartic triangular element for plate bending. Int. J. Num. Meth. Eng. 1, (1969), 29-46.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[McLain, D. H. Drawing contours from arbitrary data points. Computer J. 17, (1974), 318-324.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[McLain, D. H. Two dimensional interpolaticn from random data. Computer J. 19, (1976), 178-181.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Peucker, T. K. Computer Cartography: Commission on College Geography resource paper no. 17, Association of American Geographers, Washington D. C., (1972).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Pitteway, N. I. K. Computer graphics research in an academic environment. Datafair 73 Conference proceedings 2, (1973), 471-478.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Rhind, D. A skeletal overview of spatial interpolation techniques. Computer Applications 2, (1975), 293-309.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Sampson, R. J. SURFACE II Graphics System. Series on Spatial Analysis no. 1, Kansas Geological Survey, Lawrence, Kansas, (1975).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[SCA. MCS - Mapping Contouring System. Scientific Computer Applications Inc., Tulsa, Oklahoma, (1970).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Zienkiewicz, O. C. The Finite Element Method in Engineering Science. McGraw Hill, London, (1971).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Automated contour mapping using triangular element data structures and an interpolant over each irregular 
triangular domain.  Gold, Dept. of Geology, University of Alberta, Edmonton, Alberta, Canada T6G 2E1, 
 T.D. Charters, Alberta Environment, Edmonton, J. Ramsden, Alberta Research, Edmonton. Key words: Contour 
mapping, triangular elements, interpolation, graphical data structures, finite elements, triangular 
mesh, cartography, surface display, homogeneous coordinates, random data points, partitioning CR Categories: 
3.14, 3.74, 5.13, 8.2 Abstract Surface display techniques, including contour mapping, usually use an 
interpolant when data values are on a rectangular grid; but when values are irregularly located some 
form of assumed or estimated distance-weighting function is often used to estimate the "influence" of 
data points at other locations. If moving average (or some other) techniques are then applied, slopes 
may be zero at data points; extrema may fall at data points exclusively; or surfaces may not pass through 
data points. An alternative method is proposed whereby a map area is automatically divided into suitable 
triangular domains with a data point at each vertex. Surface estimation and contour plotting are then 
performed independently for each triangle using a measured or best-fit plane associated with each data 
point. The approach requires the utilization of three non-originalaspects: 1) the derivation of a local 
homogeneous "area" coordinate system for any arbitrary triangle; 2) the construction of a data-structurelinking 
each triangular domain with its three neighbouring triangles and three associated data points, and 3) 
the use of a "conforming" triangular finite-element interpolating function. Use of the first two of 
these concepts permits the economic generation and optimization of a triangular mesh from a set of data 
points. Optimization criteria used to define the "best" triangular partition are described in some detail, 
along with computer timing for this step. Use of the first and third concepts permits the interpolation 
of a smooth surface over the whole map area even though each triangular element is estimated and plotted 
independently.The requirements for a suitable interpolating function are discussed, and an interpolant 
is suggested that preserves elevation and slope at each data point as well as elevation and slope continuity 
between domains. Extrema need not be located at data points but are constrained by their associated planes. 
Contour line segments are produced by division of each triangle into sub-triangles, elevation estimation 
at each resulting node, and linear interpolation and plotting withing each sub­triangle. Resolution is 
then a function of N and local data point density. Extension of the method to higher dimensions is briefly 
discussed. Conventional contour mapping techniques Computer programs using traditional surface estimation 
methods to produce contour maps follcw a fairly standard procedure. First cf all a suitable rectangular 
grid is superimposed over the map area, and an elevation estimate made at each grid node. Estimation 
techniques vary widely, but usually consist of selecting n neighbouring data points, evaluating an inverse 
distance weighting function for each (giving less weight to more distant points), and then calculating 
a weighted average for the values obtained from these data points. Once the grid node values are obtained, 
straight line (or, occasionally, curved) contour segments are obtained for a desired contour value by 
interpolation from the values at the corners of each rectangle.  Several problems remain with this One 
is the use of an assumed arbitrary distribution function such as Permission to make digital or hard 
copies of part or all of this work or personal or classroom use is granted without fee provided that 
copies are not made or distributed for profit or commercial advantage and that copies bear this notice 
and the full citation on the first page. To copy otherwise, to 170 republish, to post on servers, or 
to redistribute to lists, requires prior specific permission and/or a fee. Siggraph 77, July 20-22 San 
Jose, California where d is the distance of the data point from the grid point whose value is to be 
determined. An excellent discussion of distance weighting functions is given in [8]. Another difficulty 
occurs in the definition and collection of the "neighbouring"data points. This does not necessarily 
mean "closest" since it is desirable that the points surround the location under examination.Collection 
and testing of the data points is frequently expensive since there is no intrinsic structure defining 
neighbouring points if they are arbitrarily located. Depending on the weighting method used there may 
be breaks in the surface when a data point enters or leaves the collection of neighbours. This will 
occur if the weighting of the point has not reached zero when it is rejected from the set of neighbours. 
Further problems are that the grid size defines the final resolution irrespectiveof data point distribution; 
interpolation of contour segments in a rectangle is not always unique or trivial due to the saddle point 
problem; and fairly extensive bookkeeping may be required in order to string all the contour segments 
together for plotting.  element data structures Triangular element data structures are of considerable 
help in several of these cases. They may be visualized very simply as a set of irregular triangles, superimposed 
on the map area, with a data point at each vertex. Each triangle is an element in the data structure, 
with pointers to the three adjacent triangles and the three associated data points (Fig. 1). A data structure 
of this type that was defined manually rather than automatically  described in [6].  Local coordinates 
 In order to understand the benefits of this structure it is first necessary to comprehend its construction 
and properties. The concept underlying all the others is the availability of a lccal homogeneous coordinate 
system associated with each triangle (Fig. 2a). Thus an arbitrary point P at location (xp,yp) may be 
located with reference to a particular triangle with vertices at the points i=1, 2, 3 (numbered anticlockwise) 
by re=(area  of sub-triangle i)/(total area of reference triangle). This is the solution of the system 
of linear equations: In addition, if planar interpolation of elevations is required, as illustrated 
in Fig. Zb. This coordinate system was first devised by Feuerbach [2] in 1827 for tetrahedra and variations 
on it were extensively used by geometers of that century. Each of these three coordinates has the value 
0 when p falls on the base line i and 1 when p falls on a line parallel to base line i but passing through 
the opposite vertex i. The three coordinates sum to unity, hence any two define the third. Thus all three 
coordinates are positive if p falls within the triangle, and if p falls outside, the signs of the coordinates 
indicate the direction to go locking for a circumscribing triangle. Data structure generation It is 
clear from Fig. 2c that, if a data structure relating adjacent triangles exists, a search algorithm 
is easily devised to start at any arbitrary triangle and search through a set of adjacent triangles 
until the one enclosing the unknown point is located. This in itself suggests a method for generating 
such a data structure. A "universal" triangle, large enough to enclose the map area, is first generated. 
The data points are inserted one at a time and the circumscribing triangle is identified.  171 This 
is then divided into three new triangles with the new point at a vertex of each, and all pointers are 
then updated (Fig. 3a). Data structure optimization The resulting mesh of triangles is continuous 
over the map area but the triangles produced may have undesirable shapes. An optimization routine is 
then used to test each triangle against each of its neighbours. The quadrilateral thus formed, if convex, 
may be divided in two ways, and it is the purpose of the optimization criterion to choose one of them. 
If the current division is inadequate then the two triangles are switched and the data structure pointers 
updated as in Fig. 3b. This procedure is repeated until an entire pass through the data structure produces 
no changes. By the judicious setting of flags the optimization of even a few thousand triangles "in core" 
remains an economic proposition, the insertion and optimizationof 1129 data points requiring 0.22 and 
1.92 seconds respectively on an Amdahl 470/V6 computer. Fig. 4 (solid line) illustrates the rate of convergence 
of the iterative optimization. Very close to one third of the previously unverified triangle pairs are 
switched on each iteration, and hence the number of iterations approximates3 ln(T) where T is the number 
of triangles. This is a worst­ case condition since the dashed line shows the convergence rate for a 
second batch of data points inserted after the first set has been optimized. This approach seems to have 
considerable economic advantages over the methods of [3] and [9] in which the mesh is built up agglomeratively 
from some nucleus by testing all neighbouring points to find the one most suitable to be added at a 
specific mesh location. An obvious question remains-what is our optimization criterion? Bhind [12], 
in his excellent 1975 review of spatial interpolation techniques states his ignorance of any "fundamentallysound, 
cheap and easily applied partitioning theory". He does however mention an Israeli firm's approach of 
a single pass through the lattice to minimize the total length of the triangle sides, as well as a commercial 
package [14] which use the "best overall approximation to equilateral by choosing the partition of 
the previously mentioned quadrilateral with the shortest diagonal. This however proves to be somewhat 
unsatisfactory as very thin triangles could sometimes be produced. A more satisfactory criterion turned 
out to be the maximization cf the minimum triangle height (perpendicularto the proposed diagonal of the 
quadrilateral). Fig. 5 illustratesthe difference between the two criteria. The minimum diagonal criterion 
produces the left-hand triangle: however, the height of this triangle measured perpendicular to the relevant 
diagonal is the smallest of the four possible triangles, and hence this partition is rejected. This criterion 
can be shown to be related to the "optimal partition" of Pitteway (11] as quoted in It is, of course, 
sometimes advantageous to modify or build the triangulation by hand. This provides the facility to modify 
the surface on the basis of additional information, such as  172 continuity of valleys and ridges, which 
is normally difficult to build into the mapping program. A good description of this problem under the 
heading of "surface specific points" is contained in  with triangular elements Once the data structure 
has been generated its benefits in contour mapping, for example, become apparent. The problem of identifying 
the neighbouring data points for any arbitrary location is readily solved. Its three immediate neighbours 
form the vertices of the circumscribing triangle and, if desired, the three additional vertices from 
the three adjacent triangles may be included. This approach forms a very happy combination of the requirementsfor 
neighbours to be both close to and surrounding the unknown. If a simple contouring method is sufficient, 
each triangle may be considered to generate a plane passing through the three data points, as in [1]. 
The surface is readily contoured, the volume integral underneath is easily calculated, there is no difficulty 
defining the domain in which a given set of data points define the surface, and the resolution of the 
final map is a function of the local data point density. The surface is, of course, discontinuous 
in the first derivative across triangle boundaries and its contour lines are therefore angular. Fcr 
many applications, especially where the data point distribution is very dense and/or the final product 
required is the elevations at the nodes of a grid, this is an extremely efficient technique. Slope 
information at data points Alternatively, conventional contouring techniques could be used to produce 
a grid of values, merely using the triangular element data structure for collection of neighbouringdata 
points. This would, however, neglect several advantages of the triangle approach. Therefore, in this 
paper a method has been devised to interpolate within a triangle using the local coordinate system 
of Fig. 2. In this approach, a best-fit plane, constrained to pass through the data point, is estimated 
at each datum location. The surface is then estimated for each triangular domain in turn using only 
the three planes at the vertices. These three planes may be expressed in a form compatible with the 
triangular coordinate system as Elj, the elevations of each of the three planes i at each of the three 
vertices j. If field measurement of the slope at data points is available (for example with dipmeter 
readings from drill holes) this may be used instead of the estimated best-fit plane. Use of slope information 
greatly increases the information content of the surface. It is suggested in [8] that the use of x and 
y slopes as well as the elevation information at n data points is approximately equivalent to 2.5n 
data points with elevations alone. This approach was also used in the SURFACE II contouring package [13], 
although in both cases interpolation was made onto a square grid. Requirementsof an interpolating function 
 each triangle an equation can be developed using the local coordinate system and the nine values for 
a surface possessing certain specified properties. These properties are similar to the surface properties 
for any contouring method. The first is that the surface passes through the three data points -a condition 
not met by many moving average and gridding methods. The surface should also possess the measured or 
estimated slope at each data pcint. This condition is rarely met in conventional contouring programs, 
and with moving average techniques the slope at data points may be zero. It follows from this that extrema 
should be free to occur between data locations. This is the case with global polynomial methods, although 
the values may be unreasonable. The SURFACE II program achieves flexibility of extrema locations by weighting 
the estimate produced by a best-fit plane at each data point. A fourth requirement is that the surface 
is continuous between domains. For triangulation techniques this domain is obviously defined as the triangle. 
For conventionalmethods the definition is less obvious, but in fact it is the region of the map where 
a particular set of "neighbouring" data points are used to estimate the surface. Failure to give a point 
a zero weight before it leaves this set results in unexpected breaks in the surface and kinks in the 
contour lines. A last requirement is that the slope of the surface is continuous between domains, providing 
smooth contour lines across domain boundaries. McLain [5] and Gold (6] attempted to meet all these criteria 
by using a weighted average of plane or quadratic curves associated with the triangle vertices. Zienkiewicz 
[15], p. 175, shows that slope continuity between triangles is not possible with this approach. In the 
 173 same reference, however, a suitable "shape function" is suggested that is used in engineering finite 
element analysis. The non-conforming triangle" as Irons [7] calls it is a weighted average (using area 
coordinates) of the individual coefficients of the planes associated with the vertices of a triangle. 
This interpolating function may, for convenience, be expressed in terms of the previously-definedcoefficients 
Ei',;. It possesses the correct elevation and slope at the data points but may not provide exact continuity 
of slope between triangles. Zienkieuicz provides an empirical function to correct for any small discrepancies 
in slope. The resulting interpolant satisfies all the previously-statedrequirements and is economical 
to use. Contour mapping with the interpolant  In order to plot the surface each main triangle is divided 
into 2 equal sub-triangles and Zp calculated at each node. Linear interpolation of contour segments within 
each sub-triangle is straightforward since no saddle-point problem exists once the basic triangulation 
has been defined. The resolution of the resulting map is a function of N and the local data point density. 
Fig. 6 is a contour map, produced using this approach, of the z-component of the earth's magnetic field 
sampled at 26 sites in Alberta, from the work of J.  Bannister of the Institute of Earth and Planetary 
Physics, University of Alberta. Fig. 7 shows a plot of the function z=sin(x)sin(y), in the first case 
where the slopes at data points are known mathematically and in the second case where the slopes are 
estimated from the neighbouring points. At least one commercial organization is known to use somewhat 
similar techniques for contour napping but details of its methods are proprietary and hence remain unknown 
to the authors.  Extension into higher dimensions McLain [9] suggests the possibility of interpolation 
in higher dimensions but unfortunately the authors have found no interpolating function that guarantees 
slope continuity between domains. Simple planar interpolation however is both useful and direct: it is 
necessary merely to generalize the mesh construction for higher dimensions. In n-dimensional space a 
simplex (i.e. the simplest polyhedron cf that dimension) has n«1 vertices and hence n+1 local coordinates,each 
involving ni1 order determinants. Insertion of new data points into a universal simplex is therefore 
direct. Optimization of the data structure, however, has to be rephrased. An adjacent pair of n-dimensioned 
simplices will have n vertices around their common face, and tuc independent vertices. The alternative 
structure is to connect these two independent vertices, producing n simplices around this central axis 
like the segments of an orange. This alternative is only possible if the simplex pair is convex. If 
this condition is met the optimizationchoice is between the simplex pair and the n-simplex "orange" and 
either set may be switched to the other on the basis of the maximized minimum height optimization criterion. 
It is interesting to note that maximizing the minimum height is one of the few possible criteria in 
higher than 2-dinensioned space, since minimizing the diagonal is meaningless and maximizing the minimum 
volume is of little benefit when the number of simFlices is not the same for both alternatives. Conclusions 
and acknowledgements The authors believe that the approach outlined here has several advantages in terms 
of flexibility, economy and the properties of the surface produced. Future enhancementscould easily include 
slope calculations, automatic hill shading, storage of multiple surfaces (for example, geological contacts) 
and volumetric and areal calculations. In contrast with many methods the ideas used (i.e. breaking the 
 region into triangles, obtaining the slopes at each data point and bending triangular plates to conform 
to these) are easy to comprehend, if not always easy to implement, and hence the casual user should not 
receive any unpleasant surprises in the form of outrageous costs or surface shapes along with his desired 
 map. The authors would like to gratefully acknowledge the Department of Computing Services, University 
of Alberta, for making computing and plotting facilities available, as well as Mr. Frank Dimitrov, 
Department of Geology, for assistance with the drafting. References [1] Bengtsson, B.F. and Nordbeck, 
S. Construction of isarithms and isarithmic maps by computers. B.I.T. 4, (1964), 87-105.  Feuerbach, 
K.W. Grundriss zu analytischen Untersuchungen der dreieckigen Pyramide. Nuremburg, 1827. [3] Frenkel, 
Y. and Gill, D. An algorithm for contouring random data without gridding. Israeli J. Earth Sciences 
24, (1975), 56. Gold, C.M. Triangular element data structures. The University of Alberta Computing Services 
Users Applications Symposium Proceedings, Edmonton, (May 1976), 43-54. Gold, C.M. Surface estimation 
from irregularly spaced data points using an interpolant over irregular triangular domains. Geological 
and Mineralogical Associations of Canada Program with Abstracts 1, 84. [6] Heap, B.R. Algorithms for 
the production of contour maps over an irregular triangular mesh. N.P.L. report NAC 10, (1972). [7] 
Irons, B.H. A conforming quartic triangular element for plate bending. Int. J. Num. Meth. Eng. 1, (1969), 
29-46. [8] McLain, D.H. Drawing contours from arbitrary data points. Computer J. 17, (1974), 318-324. 
 [9] McLain, D.H. Two dimensional interpolaticn from random data. Computer J. 19, (1976), 178-181. [10] 
Peucker, T.K. Computer Cartography: Commission on College Geography resource paper no. 17, Association 
of American Geographers, Washington D.C., (1972). [11] Pitteway, N.l.K. Computer graphics research 
in an academic environment. Datafair 73 Conference proceedings 2, (1973), 471-478. [14] SCA. MCS - Scientific 
Computer Applications Sampson, R.J. SURFACE II Graphics System. Series on Spatial Analysis no. 1, Kansas 
Geological Survey, Lawrence, Kansas, (1975).  Rhind, D. A skeletal overview of spatial interpolation 
techniques. Computer Applications 2, (1975), 293-309. Inc., Tulsa, Oklahoma, (1970). [15] Zienkiewicz, 
O.C. The Finite Element Method Engineering Science. (1971).  175 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563888</article_id>
		<sort_key>176</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[Dynamic modeling]]></title>
		<page_from>176</page_from>
		<page_to>176</page_to>
		<doi_number>10.1145/563858.563888</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563888</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP309818300</person_id>
				<author_profile_id><![CDATA[81536846656]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Warnock]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Evans and Sutherland Computer Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563889</article_id>
		<sort_key>177</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[A system for interactive definition and depiction of sculptured surfaces]]></title>
		<page_from>177</page_from>
		<page_to>177</page_to>
		<doi_number>10.1145/563858.563889</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563889</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP31041269</person_id>
				<author_profile_id><![CDATA[81100414792]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ken]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Knowlton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bell Laboratories]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A System for Interactive Definition and Depiction of Sculptured Surfaces Ken Knowlton Bell Laboratories 
 Abstract An interactive 3-D design system has been constructed in which surfaces of objects are defined 
in terms of many thousands of tiny "blobs" of surface area. These blobs, defined as to size, color, and 
xyz position, are sorted in depth and fed into a frame buffer back­to-front to yield a realistic hidden-surface-removed 
picture of the object(s). A 3-D wand, knobs, and buttons serve to point into the space and perform a 
variety of operations for defining and manipulating objects. Emphasis is on ease of user specification 
of positions, parts of objects, and operations. Permission to make digital or hard copies of part or 
all of this work or personal or classroom use is granted without fee provided that copies are not made 
or distributed for profit or commercial advantage and that copies bear this notice and the full citation 
on the first page. To copy otherwise, to republish, to post on servers, or to redistribute to lists, 
requires prior specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California 177 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563890</article_id>
		<sort_key>178</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[Towards a unified approach to 2-D picture manipulation]]></title>
		<page_from>178</page_from>
		<page_to>178</page_to>
		<doi_number>10.1145/563858.563890</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563890</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P242985</person_id>
				<author_profile_id><![CDATA[81100366482]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Shoup]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Xerox Palo Alto Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Towards a Unified Approach to 2-D Picture Manipulation Richard G. Shoup Xerox Palo Alto Research Center 
 Abstract This talk describes a new architecture for creating and manipulating 2-D raster scanned images. 
This special-purpose hardware, called Aurora, manipulates images in the form of digital video point streams 
from a variety of sources (including its own memory) and can drive raster scan devices such as CRT monitors, 
 scanners, etc. It uses a single, simple metaphor for all 2-D point array picture manipulations, thus 
allowing a consistent implementation scheme for everything from text images to freehand painting to high­resolution 
printing image generation. This new design has grown out of the following collection of thoughts: 1. 
In general, a picture is an ongoing process ,not a state This is the opposite of the usual view of frame 
buffers, digital "bit maps", and dynamics done by sequences of still pictures.  2. At any instant, however, 
the current state of the picture process can be represented by a 2-D array of colored points--a point 
array --which is often raster  scanned into a point stream which recirculates through the system.  
3. A "display controller" usually touches every point in the image once per frame time, so why not use 
that ongoing process to do some operations on the resulting point stream picture?  4. A great many of 
the common operations we wish to do in creating and manipulating pictures are simple functions which 
can be done on a point-by-point basis (cursors, freehand painting and drawing, text composition, masking, 
merging and overlaying, transparency and translucency, TV special effects, etc.). These operations can 
be implemented by appropriately combining two or more point streams.  The talk will describe this architecture 
in general terms and discuss some simple examples and preliminary results from a prototype system. Permission 
to make digital or hard copies of part or all of this work or personal or classroom use is granted without 
fee provided that copies are not made or distributed for profit or commercial advantage and that copies 
bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on 
servers, or to redistribute to lists, requires prior specific permission and/or a fee. Siggraph 77, July 
20-22 San Jose, California 178 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563891</article_id>
		<sort_key>179</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>33</seq_no>
		<title><![CDATA[A query language for a network data base with graphical entities]]></title>
		<page_from>179</page_from>
		<page_to>185</page_to>
		<doi_number>10.1145/563858.563891</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563891</url>
		<abstract>
			<par><![CDATA[A generalized high level query language has been developed for use with a network data base, as defined by the CODASYL DBTG report. Of particular interest is the capability of manipulating graphical entities with this language. The system was developed to supportan offshore oil lease information project where one must formulate queries pertaining to proximity of graphical entities. To facilitate such requests new relational operators were defined and implemented. Thus compound Boolean expressions can be formed which involve graphical as well as non-graphical criteria. Since one goal of the information system is to produce selectively colored maps via an FR80 microfilm recorder, the query language syntax provides the user with a comprehensive thematic cartography capability. The query language is designed to isolate the user from the underlying network structure of the data base. In order to accomplish this generalized pathfinding and accessing algorithms had to be developed. Pathfinding is facilitated through an adjacency matrix involving all record types in the data base, while accession is controlled by examining the local owner-member relation for current record types. Besides querying, the system provides the usual complement of data base management system functions, i.e. deletion, updating, reporting, etc.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[DBTG model]]></kw>
			<kw><![CDATA[cartography]]></kw>
			<kw><![CDATA[computer graphics]]></kw>
			<kw><![CDATA[data base]]></kw>
			<kw><![CDATA[data management]]></kw>
			<kw><![CDATA[graphical entities]]></kw>
			<kw><![CDATA[network model]]></kw>
			<kw><![CDATA[query language]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP42052391</person_id>
				<author_profile_id><![CDATA[81332520985]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Phillips]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Michigan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Joyce, J. D. and Oliver, N. A. "REGIS --- A Relational Database Manager with Graphics and Statistics," Research Publication GMR-2009, Research Laboratories, General Motors Corp., Warren, Mich. (Jan. 1976).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Senko, M. E. "DIAM TI with FORAL LP: Making Pointed Queries with a Light Pen," IBM Thomas J. Watson Research Center, Yorktown Heights, N.Y. (1976).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Phillips, R. L. and Cederquist, G. N. "A Specialized Programming Language for Analysis and Display of Water Quality Data," Fifth International CODATA Conference, Boulder, Colo. (June 1976).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Mantey, P. E. et al. "Information for Problem Solving: The Development of an Interactive Geographic Information System," Proc. IEEE Int. Communications Conf., Seattle, Wash. (June 1973).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Williams, R. and Giddings, G. M. "A Picture Building System," IEEE Transactions on Software Engineering, Vol. SE-2, No. 1 (March 1976) 62-66.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Go, A., Stonebraker, M., and Williams, G. "An Approach to Implementing a Geo-Data System," Proc. Workshop on Data Bases for Interactive Design, Waterloo, Canada, ACM, Inc. (Sept. 1975).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Phillips, R. L. "Computer Graphics in Urban and Environmental Systems," Proc. IEEE, Vol. 62, No. 4 (April 1974).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Eastman, C. M. Proc. 1975 ACM SIGGRAPH - SIGMOD Workshop on Data Bases in Interactive Design, Waterloo, Ontario (Sept. 1975).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[CODASYL Data Base Task Group, April 1971 Report, ACM, New York.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Hershey, E. A. and Messink, P. W. "A Data Base Management System for PSA Based on DBTG 71," ISDOS Working Paper No. 88, University of Michigan (July 1975).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Bandurski, A. E. and Jefferson, D. K. "Enhancements to the DBTG Model for Computer-Aided Ship Design," Proc. Workshop on Data Bases for Interactive Design, Waterloo, Canada, ACM, Inc. (Sept. 1975).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Bonczek, W. D., Haseman, W. D., and Whinston, A. B. "Structure of a Query Language for a Network Data Base," Tech. Rept., Krannert School, Purdue Univ., West Lafayette, Ind. (July 1975).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>509402</ref_obj_id>
				<ref_obj_pid>509383</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Deheneffe, C. and Hennebert, H. "NUL: A Navigational User's Language for a Network Structured Data Base," Proc. Int'l Conf. on Management of Data, Washington, D.C. ACM, Inc. (June 1976).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Heindel, L. E. and Roberto, J. T. LANG-PAK-An Interactive Language Design System, American Elsevier, New York (1975).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A QUERY LANGUAGE FOR A NETWORK DATA BASE WITH GRAPHICAL ENTITIES Richard L. Phillips The University 
of Michigan ABSTRACT A generalizedhigh level query language has been developed for use with a network 
data base, as defined by the CODASYL DBTG report. Of particular interest is the capabil- The system was 
developed to ity of manipulating graphical entities with this language. supportan offshore oil lease 
information project where one must formulate queries per­taining to proximity of graphical entities. 
To facilitate such requests new relational operators were defined and implemented. Thus compound Boolean 
expressions can be formed which involve graphical as well as non-graphical criteria. Since one goal of 
the infor­mation system is to produce selectively colored maps via an FR80 microfilm recorder, the query 
language syntax provides the user with a comprehensive thematic cartography cap­ability. The query language 
is designed to isolate the user from the underlying network structure of the data base. In order to 
accomplish this generalized pathfinding and accessing algorithms had to be developed. Pathfinding is 
facilitated through an adjacency matrix involving all record types in the data base, while accession 
is controlled by examining the local owner-member relation for current record types. Besides querying,the 
system provides the usual complement of data base management system functions, i.e. dele­ tion, updating, 
reporting, etc. Key Words and Phrases:' query language, data base, data management, network model, DBTG 
model, graphical entities, computer graphics, cartography. CR Categories: 3.70, 3.74, 8.2 1. INTRODUCTION 
 1.1 Graphics in Data Base Interrogation recognized by several investigatorsl,2,. The usefulness of 
interactive com­puter graphics as an aid to interrogat­ing large data bases, has recently been 3 Especially 
in those data bases where there are natural graphical attributes the postulation of queries and display­ 
ing their results is greatly facilitated with computer graphics. Situations where geographical attributes 
are asso­ciated with data base entities are ideally suited to the variety of manipu­lations that can 
beperformed. A recent survey of the uses of computer graphics in large scale urban and environmental 
information systems was reported by 7 Phillips. In all systems surveyed the data bases contained items 
with natural geographical attributes. Graphics proves to be useful in the display of base maps upon 
which is superimposed representationsof the data base  interrogation. Thematic cartography is especially 
useful in this case. Not only data bases with geographical attributes can benefit from the use of 8 
 computer graphics. The work of Eastman for facilitating the building design pro­cess is notable in 
this regard. Interac­tive graphics is useful here not only for initially constructing the items in the 
data base, but, as is the case with other large scale information systems, graphics provides a window 
into the data collection and makes it feasible for an investigator to examine dozens of data relationships 
in a short period of time.  1.2 The Oil Lease Data Base System During the period from October 1954 
to July 1975, the federal government has leased over 2,500 tracts off the Gulf and Pacific coast to some 
200 oil and gas companies for development. The leasing Permission to make digital or hard copies of 
part or all of this work or personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that copies bear this notice and the full 
citation on the first page. To copy otherwise, to 179 republish, to post on servers, or to redistribute 
to lists, requires prior specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California 
 Figure 1. Schema Diagram for Oil Lease Data Base.  activity has increased in the last fewyears and 
is expected to continue to grow. How these federal lands have been developed and how the companies have 
fared from their investments is of great interest. The data from the lease sales and data on subsequent 
production is contained in the lease, pro­duction, and revenue data bases managed by the U.S. Geological 
Survey. Los Alamos Scientific Laboratory is under contract to the USGS to provide statistical analyses 
 and graphical displays of these data, in response to requests from the USGS as forwarded by members 
of Congress. To accomplish these tasks a data base manage­ment system has been developed which allows 
operations on the graphical attributes of the data as well as providing conventional querying capabilities. 
Graphical tech­niques are used interactively,to manipu­ late this data base, and passively, to produce 
high quality colored maps which represent the results of querying activity. As will be discussed later 
new graphical relational operators must be defined in order to formulate queries which are either totally 
or partially graphical in nature. 180 1.3 Selection of Data Manipulation Techniques The concept of 
managing graphical attributes in a data base system is rela­tively new. Commercial data base manage­ment 
systems that are supplied by mainframe vendors or software houses do not recognize the existence of graphical 
entities. 5 Williamsand Go6 have implemented graph­ics-oriented systems which are based on a relational 
data model, but the basic software is experimental and not widely available. The network DBTG9 data model, 
however, appears to offer as much flex­ibility as does the relational model, while the hierarchicalmodel 
does not easily lend itself to describing the topological rela­tions among graphical entities. For the 
present study a host language network-type data base management system was selected. The oil lease data 
base is implemented in ADBMS10 , a system developed by the ISDOS project at The University of Michigan. 
ADBMS implements a subset of the CODASYL-DBTG specificationsand, being a host language system, it provides 
low level subroutine calls for its data manipu­lation language. This means that to imple­ment a high 
level query language, one must develop strategies for traversing the net­work schema and accessing specified 
data items. This paper, then, deals with the developmentof the interactive program necessary to interface 
to the low level ADBMS routines. This consists of the com­mand language and its associated interface 
and the subroutines which manipulate the ADBMS facilities. Because the network data model per­mits the 
definition of such general rela­tionships among entities, it is difficult to develop a high level query 
language that permits a casual user to pose unam­biguous yet powerful queries. Languages for traversing 
network data bases have been developed and Deheneffeby 12 I3 , but their systems all require that the 
user be familiarwith the underlying schema to make effective use of the system. Moreover, none of the 
systems treat the manipulation of graphical entities. 2. THE QUERY LANGUAGE  2.1 Graphical Operations 
 There are several requirements for the use of computer graphics in the manipulation of the oil lease 
data base. These can be identified as a) Passive Display This results from a query based on either 
graphical or nongraphical attri­butes and requires that a map be produced showing the locations of the 
leases  involved in the query. This is a straight-forwardrequirement and can be accomplishedby relating 
a data base key for a lease to a string of map coordinates. Color keying or shading for the production 
 of thematic maps can easily be done aswell, since once a lease has been identified, map production 
will proceed outside of the data base system. b) Operations Related to Geographic Neighborhood There 
are many cartographically oriented queries that can be formed. Neighborhoodqueries are common and can 
be exemplified by the following: i) Find all leases within five miles of Galveston, Texas. ii) Find 
all leases inside a three mile limit from Houston to Galveston. iii) Find all leases belonging to 
 company A that are within twenty miles of lease B.  For queries of this type, place director­ies have 
to be part of the data base, that is, coordinates must be provided for Galveston, the mouth of the Rio 
Grande, etc. In addition, coast line and political boundary data must be an integral part of the data 
base. c) Adjacency Operations Another requirement is to answer queries regarding adjacent leases. These 
might be of the form i) Find all leases adjoining lease A. ii) Find all leases adjoining the coast 
line of Louisiana from city A to city B. iii) Find all leases belonging to company A that are not 
surrounded by those belonging to company B.  These queries imply that information re­ garding the identity 
of leases on either side of a boundary line segment must be stored in the data base. In order to facilitate 
graphical  queries, two relational operators have been defined. They are denoted as .ADJ. which is 
used to indicate adjacency and .NGH. which is used to indicate neighbor­ hood attributes. Thus, one 
could form a query which has an element of the form entity.ADJ.entity,which indicates that an adjacency 
condition must exis-t for the entities on either side of the operator in order to satisfy the query. 
 2.2 Query by Pointing An obvious use of interactive graphics for interrogation of a graphically oriented 
data base is to allow the user to point at locations or areas on a map which show some 181 or all of 
the entities of the data base. Thus the user could outline a collection of leases and ask for production 
information or company ownership. This operation per­mits processes such as spatial aggregation prior 
to applying statistical procedures. Pointing can be used in conjunctionwith traditional alphanumeric 
querying in order to allow a user to satisfy his requests as efficiently and quickly as possible.  2.3 
Thematic Map Production Once the user of the oil lease data base has isolated a collection of leases 
for which a high quality map is to be produced, he can use the facilities of the query language to control 
the produc­tion of this map. With the plot command the user can indicate that only leases are to be 
displayed, or leases with surround­ing geographical features such as coast lines, county boundaries, 
etc., are to be plotted. Moreover, the system provides a syntactically rich thematic map production sublanguage 
which allows the specification of multiple colors and shading patterns for the leases which are displayed. 
Suit­able defaults are provided for any attri­butes the user does not wish to specify. He may, for example, 
issue the command  PLOT STATE FIRMNAME= SUN OIL COMPANY,YELLOW  182  These commands are typical of 
those which will produce final maps of the results of the query. 2.4 Query Language Syntax The query 
language for the oil lease data base system was developed with the facilities of LANG-PAK14 , an interac­tive 
design system developed at Bell Laboratories. This system allows the flexibility necessary during the 
develop­ment phase to try a variety of command grammars and to test them prior to imple­mentation to 
determine if they provide the querying power that is necessary for the final language. Once the query 
language has been determined, LANG-PAK provides utilities that are used in the application program for 
parsing, number conversions, tracing, etc. A summary of the syntax of the oil lease query lan­guage is 
shown below. Note: The following notation conventions are used in the prototype of the query language 
commands. lower-case -represents a generic type which is to be replaced by an item supplied by the user. 
 upper-case -indicates material to be used verbatim in the command. brackets [ ] -indicates that ma­terial 
within the brackets is optional. braces { } -indicates that the material within the braces represents 
choices, from which exactly one must be selected. The choices are separated by vertical bars i. ellipsis.. 
.-indicates that the preceding syntactic unit may be repeated. Some Generic Types database -the name 
of a data base file record -a data record type item -a data base item type variable -a user-assigned 
vari­ able name relop -a relational operator, such as .LE., .EQ., .GT., .ADJ., etc. expression -an 
arithmetic expres­sion involving data base item types, constants, defined variable or functions of any. 
 function -a univariate or multi­variate function such as SQRT, LOG, EXP, MEAN, SIGMA, etc. criterion 
-a selection criterion for searching the data base. From previous definitions a criterion has the form 
 expression relop expression attribute -a color specification or shading pattern to be used in map production. 
 Command Prototypes OPEN -database SHOW -{ALL RECORDS record[,record]...} FIND -record [[WITH]criterion[logop 
criterion]...] ALSO -[WITH]criterion[logopcriterion]... PRINT -{record expression[,expression]...} 
 LET -variable = expression ADD -record DELETE -record criterion [logop criterion]... ALTER -record 
item = expression [,item = expression]... PLOT -{LEASEIAREAISTATE}[[criterion] [attribute]...] 183 
 3. SATISFYING A QUERY Once the user has issued a request to the oil lease data base system, and the 
request has been verified as syn­tactically and semantically correct, that request must be mapped into 
calls to the low level subroutines that manipu­late the ADBMS network data structure. Some terminology 
pertinent to network systems will be necessary. A data base is organized as a col­lection of records 
of different types. A record is a grouping of items that have some relationshipto one another. The overall 
structure of the data base is determined by the linkages that exist between records, a property established 
by the data definition. Figure 1 is a diagrammaticrepresentation of what is essentially the data definition 
for the oil lease data base. The rectangles represent records with the labels being arbitrarily assigned 
mnemonic names. The arrows joining the re.cords are called sets and represent allowable relation­ships 
among records. The sets that begin and end on the same record are related to a master record called SYSTEM. 
 Satisfying the user's request is a two-step process. The first is path­finding, i.e. mapping the user's 
request onto the structure of the data base. The second step is generalized accessing of the appropriate 
records in the data base by calling upon the utilities provided by ADBMS. Pathfinding is the process 
of deter­mining linkages between record types that appear in the users original query. Sup­pose the user 
has formed the query FIND FIRM OILP > 1000 The item OILP upon which the search is based is contained 
in record PROD. For every record occurrence of PROD, for which OILP > 10000 is satisfied, one must retrieve 
the corresponding FIRM record and place it in a current goal record list. The algorithm that determines 
the path from PROD to FIRM is based upon an adjacency matrix which represents all possible paths between 
all record types in the data base. The adjacency matrix that corresponds to the data'structure depicted 
in Fig. 1 is shown in Fig. 2. The matrix is square and its dimensions depend upon the number of record 
types in the data base, 14 in the current ex­ample. Each record or node in the net­work structure, is 
assigned an arbitrary number. In this case the ordinal posi­tion of the record definition in the schema 
description. The graph which is represented by the adjacency matrix is undirected but the edges, nevertheless, 
 have values of +1 and -1 assigned to them. These values indicate whether the record is owned by or 
is the owner of the record at the other end of the graph edge. This information is necessary to carry 
out generalized accessing of the data base. Using information provided by the pathfinding algorithm, 
the generalized accessing module calls upon the appropriate subroutines in the proper order to retrieve 
the data implied by the query. Which subroutines to call, and in what order to call them depends upon 
the owner­member relation that was discovered during the pathfindingoperation. Generalized accessing 
is complicated by the presence of artificial records that must be defined for a network schema (e.g. 
LSENUB in Fig. 1) to allow many-to-many relationships to exist in the data base. Information is pro­vided 
by the pathfinding algorithm which allows the generalizedaccessing algorithm to resolve the intent of 
the query and retrieve the proper number of records in their proper order. 4. EXAMPLES OF QUERIES AND 
THEIR RESULTS 4.1 The Data Base The data base being used for system evaluation contains only 477 tracts 
and 25 leases, all located off the coast of Louisiana. The entire data base and sur­rounding geographic 
features can be dis­played by the two commands: FIND LEASE PLOT STATE  Default scaling and shading 
density is used to produce the map shown in Fig. 3. By issuing the command PLOT AREA ACRES < 3000 
4, ACRES > 3000 8 Fig. 4 is produced, showing the same 25 leases but with scaling appropriate to the 
 areas which define the 477 tracts and shading to distinguish between those with area less than 3000 
acres and those larger than 3000 acres. 184 REFERENCES 1. Joyce, J.D. and Oliver, N.A. "REGIS- A 
Relational Database Manager with Graphics  and Statistics," Research Publication GMR-2009, Research 
Laboratories, General Motors Corp., Warren, Mich. (Jan. 1976).  2. Senko, M.E. "DIAM TI with FORAL LP: 
Making Pointed Queries with a Light Pen," IBM Thomas J. Watson Research Center,  Yorktown Heights, 
N.Y. (1976). 3. Phillips, R.L. and Cederquist, G.N. "A Specialized Programming Language for Analysis 
and Display of Water QualityData," Fifth International CODATA Conference, Boulder, Colo. (June 1976). 
 4. Mantey, P.E. et al. "Information for Problem Solving: The Development of an Interactive Geographic 
InformationSystem," Proc. IEEE Int. CommunicationsConf., Seattle, Wash. (June 1973).  5. Williams, R. 
and Giddings, G.M. "A Picture Building System," IEEE Transac­tions on Software Engineering,Vol. SE-2, 
No. 1 (March 1976) 62-66.  6. Go, A., Stonebraker, M., and Williams,G. "An Approach to Implementing 
a Geo-Data System," Proc. Workshop on Data Bases for  Interactive Design, Waterloo, Canada, ACM, Inc. 
(Sept. 1975).  7. Phillips, R.L. "Computer Graphics in Urban and Environmental Systems," Proc. IEEE, 
Vol. 62, No. 4 (April 1974).  8. Eastman, C.M. Proc. 1975 ACM SIGGRAPH -SIGMOD Workshop on Data Bases 
in Interactive Design, Waterloo, Ontario  (Sept. 1975).  9. CODASYL Data Base Task Group, April 1971 
Report, ACM, New York.  10. Hershey, E.A. and Messink, P.W. "A Data Base Management System for PSA Based 
on DBTG 71," ISDOS Working Paper No. 88, University of Michigan (July 1975).  11. Bandurski, A.E. and 
Jefferson, D.K. "Enhancementsto the DBTG Model for Com- puter-Aided Ship Design," Proc. Workshop  on 
Data Bases for Interactive Design, Waterloo, Canada, ACM, Inc. (Sept. 1975).  12. Bonczek, W.D., Haseman, 
W.D., and  Whinston, A.B. "Structure of a Query Language for a Network Data Base," Tech. Rept., Krannert 
School, Purdue Univ., West Lafayette, Ind. (July 1975).  13. Deheneffe, C. and Hennebert, H. "NUL: A 
Navigational User's Language for a Network Structured Data Base,' Proc. Int'l Conf. on Management of 
Data, Washington, D.C. ACM, Inc. (June 1976).  14. Heindel, L.E. and Roberto, J.T. LANG-PAK-An Interactive 
Language Design System, American Elsevier, New York (1975).   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563892</article_id>
		<sort_key>186</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>34</seq_no>
		<title><![CDATA[GEO-OUEL]]></title>
		<subtitle><![CDATA[a system for the manipulation and display of geographic data]]></subtitle>
		<page_from>186</page_from>
		<page_to>191</page_to>
		<doi_number>10.1145/563858.563892</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563892</url>
		<abstract>
			<par><![CDATA[This paper briefly summarizes the implementation of GEO-OUEL, a special purpose geographic information retrieval and display system. Basically, it is a rather small "front end" to a powerful general purpose relational data base system, INGRES, implemented at Berkeley. Also discussed are the problems that were discovered during the implementation of the original proposal (presented at the 1975 ACM SIGMOD/SIGGRAPH Workshop in Waterloo, Ontario) and the corrective steps taken. Lastly, experiments are described which indicate the performance penalty paid for this "front end" approach and the savings in development time realized.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P379963</person_id>
				<author_profile_id><![CDATA[81540656656]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Berman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Berkeley, Ca.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43125340</person_id>
				<author_profile_id><![CDATA[81337493529]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stonebraker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Berkeley, Ca.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Macri, P., "BUDS: The Berkeley Urban Data System," Electronics Research Laboratory, University of California, Berkeley, Memorandum M412, November, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Christiani, E. J., et. al., "An Interactive System for Aiding Evaluation of Local Government Policies," IEEE Transactions on Systems, Man, and Cybernetics, vol. SMC-3, no. 2, Mar. 1973, pp. 141-146.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Mantey, P. E., et. al., "Information for Problem Solving: The Development of an Interactive Geographic Information System," IEEE Conference on Communication, vol. II, Seattle, Washington, June 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Parker, J. L., "Information Retrieval with Large Scale Geographic Data Bases," Proc. 1971 ACM-SIGFIDET Workshop on Data Description, Access and Control, San Diego, Ca., Nov. 1971.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Depta, D. J., and Irwin, G. M., "FIRS II - Design Require- ments Component," Weyerhauser Company, Woods Product Information Systems, Tacoma, Wash., March, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Go, A., Stonebraker, M., and Williams, C., "An Approach to Implementing a GEO-DATA System," Proc 1975 ACM SIGGRAPH-SIGMOD Workshop on Data Bases in Interactive Design, Waterloo, Ontario, September 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Held, G., Stonebraker, M., and Wong, G., "INGRES - A Relational Data Base System", Proc 1975 NCC, Anaheim, California, May 1975]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>320476</ref_obj_id>
				<ref_obj_pid>320473</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Stonebraker, M. R., Wong, E., Held, G. D., and Kreps, P., "The Design and Implementation of INGRES", ACM Transactions on Data Base Systems, Vol. 1, No. 3.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>362685</ref_obj_id>
				<ref_obj_pid>362384</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Codd, E., "A Relational Model of Data for Large Shared Data Banks," CACM 16, (June 1970).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Held, G. and Stonebraker, M., "Storage Structures and Access Methods in the Relational Data Base Management System, INGRES," Proc. ACM-PACIFIC-75, San Francisco, Ca., April 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Youssefi, K., et. al., "INGRES Reference Manual -- Version 6", Electronics Research Laboratory, University of California, Berkeley, Memorandum No. ERL-M579, April, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Ritchie, D. M., "C Reference Manual," Bell Telephone Labora- tories, Murray Hill, New Jersey, Jan. 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>361061</ref_obj_id>
				<ref_obj_pid>361011</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Ritchie, D. M. and Thompson, K., "The UNIX Time Sharing System," CACM, Vol 17, No. 7, pp365-375, July 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 GEO-OUEL A System for the Manipulation and Display of Geographic Data* by Richard R. Berman and Michael 
Stonebraker Department of Electrical Engineering and Computer Sciences University of California, Berkeley, 
Ca. ABSTRACT This paper briefly summarizes the implementation of GEO-OUEL, a special purpose geographic 
information retrieval and display system. Basically, it is a rather small "front end" to a powerful general 
purpose relational data base system, INGRES, implemented at Berkeley. Also discussed are the problems 
that were discovered during the implementation of the ori­ginal proposal (presented at the 1975 ACM SIGMOD/SIGGRAPH 
Workshop in Waterloo, Ontario) and the corrective steps taken. Lastly, experiments are described which 
indicate the per­formance penalty paid for this "front end" approach and the savings in development time 
 realized. I. INTRODUCTION The capability for graphical display of data (especially data that has spatial 
characteristics)has been recognized as a valuable component of information retrieval sys­tems. Applications 
which could utilize a graphical facility include those interrogating spatial demand data (e.g. requests 
for police services, fire department services, etc.), network or grid data (e.g. automobile flows on 
streets or highways, water and solid waste distribution) and data involving partitions of a geographic 
area (e.g. census tracts, school districts, election districts, etc.).  Several such geo-data systems 
currently exist including BUDS [1], GADS [2,3], NISP and FIRS [5]. All are special purpose information 
retrieval and display facilities requiring their own query language and internal data structures for 
data. In a recent paper [6] we sketched an implementation proposal for GEO-OUEL which offers comparable 
facilities to the above systems. GEO-OUEL differs dramatically in its implementation approach as it is 
constructed on top of a powerful relational data base management system, INGRES [7,P]. This approach 
has the following features: 1) All geographic data (including maps) are treated as relations. Hence, 
the full power of the available relational data sublanguage, OUEL, can be used to manipulate geographic 
data. 2) Because of 1), most features needed in a geo-data system can be implemented easily by INGRES. 
Very little special code is required as most tasks can be turned into interactions in the data sublanguage. 
 3) Because no special purpose data manipulation functions are required and because graphics code is 
economized, GEO-OUEL contains substantially less code than compar­able systems. Hence, system development 
time is reduced. 4) Because OUEL is not tailored to geographic data, a performance penalty may be incurred. 
 GEO-OUEL is now fully operational and considerable user reaction has been recorded. In this paper we 
briefly review the original proposal appearing in [6]. Then we indicate some of the problems with the 
original design and how they were corrected. These problems centered around poor performance. Lastly, 
we discuss some experiments performed to docu­ ment the viability of our "front end" approach. As noted 
above we expect to pay a perfor­mance penalty compared to that offered by a special purpose system. This 
should be offset  Permission to make digital or hard copies of part or all of this work or personal 
or classroom use is granted without fee provided that copies are not made or distributed for profit or 
commercial advantage and that copies bear this notice and the full citation on the first page. To copy 
otherwise, to 186 republish, to post on servers, or to redistribute to lists, requires prior specific 
permission and/or a fee. Siggraph 77, July 20-22 San Jose, California oy a substantial reduction in the 
amount of code which we needed to write and a consequent reduction in the software cost of making the 
system operational. Our experiments indicate approximate numbers for the performance penalty and the 
reduction in software cost. II. REVIEW OF GEO-OUEL IMPLEMENTATION PLAN A basic entity in GEO-QUEL is 
a map. Intuitively,a map is a collection of:  Points and lines are the obvious spatial construct. A 
line group is simply a collec­ tion of lines. A polygon is a special case. of a line group with the 
obvious meaning. Lastly, zone is another term for polygon. Line groups are required so that structures 
such as transportation networks can be Maps are dis­ represented. Polygons are required for partitions 
of a geographic area. New York joint collections of polygons comprising an entity. (Such an entity 
might be City which is composed of several polygons.) A map is stored in the INGRES data base system 
as a relation containing the following AOD is a domains: X1, Y1, X2, Y2, PLZTYPE, GRAPHCHAR, INTENSITY, 
GROUPID, ZONEID, AOD. These domains may be used for infor­ shorthand for any other domains that may 
be present. So a map is simply a relation of mation that is associated with a point, line, or zone. 
the form: RELNAME(X1, Y1, X2, Y2, PLZTYPE, GRAPHCHAR, INTENSITY, GROUPID, ZONEID, AOD)  PLZTYPE -indicates 
whether the tuple corresponds to a point, a single line, a line The notion of "center" segment in a 
line group or zone, or the center of a zone. is used for the MAP and SHADE commands as discussed below. 
 If not null the point will be GRAPHCHAR -applies to tuples of type point only. represented by the character 
in GRAPHCHAR. INTENSITY -indicates the display screen intensity of the tuple. Points and lines are 
degen- GROUPID -indicates what line group this.tuple belongs to. erate line groups. ZONEID -indicates 
what zone the current tuple belongs to. As far as INGRES is concerned, a map relation is indistinguishable 
from any other kind of relation. Moreover, there can be an arbitrary number of such maps. An example 
of a sim­ ple map is shown in Figure 1. It might be noted that a certain amount of duplication is present 
in Figure 1. This normalized [9] (i.e. whose is motivated by the desire to have map relations that 
are domains are not themselves relations) and by a desire to store a map as a single relation so that 
it can be easily manipulated in ways to be discussed presently. Clearly note, however, that our data 
base system, INGRES, can compress relations of desired to achieve economy of storage. [10]. Maps may 
be likely candidates for storage by the access method that accomplishes this. Besides an arbitrary number 
of map relations there are three special relations which graphics software manipulates. These are discussed 
in detail in [6]. Basically one, MAPRELATION, is used to store the scale and center of each map for display 
purposes, and, two, DSPTEMP and MENU, hold the relation that is currently being displayed. by using 
the data Maps can be manipulated either by special GEO-OUEL commands or We now indicate the available 
graphics manipulation language, OUEL, supported by INGRES. commands. MAP relname [ON domain] MAP displays 
a map with respect to the center and magnitude found in MAPRELATION. If the 'domain' chosen will be displayed 
appropriately over ON option is used, the value of the the centroid of a zone or on a line group or 
 point. The centroid is the point specified 187  as the "center" of a zone. This domain must be in 
the relation 'relname'. The ON option is useful not only to indicate data of a geographic nature but 
also to display zone-id's when necessary (for example, census tract numbers on a census tract map). 
SHADE relname WITH domain = <graphchar or line> [SHADE DENSITY = k] SHADE first executes the MAP command. 
Then considering only zones completely within the portion of the map which will fit on the screen, characters 
will be drawn whose density is proportional to the value of for a shade the given domain polygon. The 
character is specified by graphchar. If the shade density option is omitted, the unit spacing of char­acters 
defaults to 1. The user can optionally choose her/his own value (perhaps so a map can be compared with 
a previous one). The option "line" uses a similar algorithm to draw diagonal lines through zones whose 
perpendicular distance is inversely proportional to the value of the domain of interest. LINEGRAPH relname 
ON domain WITH {domain = graphchar)  POINTGRAPH relname ON domain WITH {domain = graphchar} For LINEGRAPH 
and POINTGRAPH, the first domain specified will serve as the x axis. Each domain thereafter will be a 
y axis. Each. point is first plotted or drawn according to the graph character specified for that domain. 
The GRAPH command draws line segments connect­ ing points belonging to the same domain. CENTER relname 
AT x , y WITH MAGNITUDE xmag, ymag CENTER updates values in MAPRELATION and thereby changes the "window" 
which will fit on the screen. SAVEMAP relname SAVEMAP makes a permanent relation out of the current 
display relation (DSPTEMP). We now indicate examples of the additional manipulation that can be done 
using the INGRES data manipulation language, OUEL. A complete description of QUEL appears in [11]. Suppose 
the simple map indicated in Figure 1 is in a relation called MAP. -Form a new map MAP1 having only the 
zones from MAP RANGE of M is MAP RETRIEVE INTO MAP1(M.ALL) WHERE M.PLZTYPE = "z" -Overlay MAP with 
a second map MAP2 RANGE OF M2 IS MAP2 APPEND TO MAP(M2.ALL) 188 -Delete all the points out of MAP 
 RANGE OF M IS MAP DELETE M WHERE M.PLZTYPE = "p" Obtain a subset of a map one of whose data domains 
satisfies a qualification - RANGE OF M IS MAP RETRIEVE INTO NEWMAP(M.ALL) WHERE M.datadomain = something 
 -Perform a simple-minded windowing RANGE OF M IS MAP RETRIEVE INTO NEWMAP(M.ALL) WHERE M.X1>lowerlimit 
AND M.X2< upperlimit AND M.Y1>lowerlimit AND M.Y2< upperlimit Adding data domains to a map (assuming 
a relation DATA exists and that a mechanism "con­ - necting -id" is present to associate tuples in DATA 
with tuples in MAP) RANGE OF M IS MAP RANGE OF D IS DATA RETRIEVE INTO NEWMAP(M.ALL, D.desired-data)WHERE 
D.connecting-id = M.connecting-id It should be clearly noted that the entire power of QUEL is available 
to form the DATA relation in which the user is interested. S/he need not be limited to "precanned" or 
"preextracted" data. The user manipulates maps using an interactive terminal monitor for the INGRES data 
 INGRES also supports an interface [8] to the general purpose programing base system. language "C" [12,13] 
The additional GEO-QUEL graphics commands are written in "C." As noted in [6] the GEO-OUEL implementation 
plan was to turn the graphics commands primarily into INGRES commands leaving as little "C" code as possible 
to write. III. PROBLEMS WITH THE ORIGINAL PROPOSAL [6]. This approach proved effec- GEO-QUEL was implemented 
initially as suggested in tive in reducing the implementation time and keeping small the amount of code 
written. However, this implementation produced a system that was prohibitively slow. The underly­ing 
performance problem was that many things which could be done easily and efficiently in "C" were nevertheless 
done using INGRES, which was slower. The original proposal called for two special relations (DSPTEMP 
and MENU) to hold the In this way all GEO-OUEL functions would first manipulate current contents of 
the screen. these two relations and then call one device dependent routine, DISPLAY, which converted 
 The rationale was a centralization of the device the two relations into a display list. the ability 
to do essentially all graphics manipulation in INGRES. dependent code and Moreover, the contents of 
the screen was available at any time for manipulation in QUEL. The performance penalty for the original 
approach was substantial. There was, of extra overhead of creating and filling these relations. In addition, 
such course, the things as the scales for LINEGRAPH and POINTGRAPH were calculated using INGRES and 
entered Hence, into this relation. Later they were recalled and converted to a display list. INGRES 
was being used for tasks that could be done trivially (and much faster) in "C" with the added overhead 
of going through an intermediate'form (calculation -> relation -> display list). Because of these performance 
problems, GEO-OUEL was extensively modified with the objective of performing all manipulations in "C" 
that would not result in a large increase in implementation cost. Specifically, the change that was made 
was to remove the DSPTEMP and MENU relations from the control flow. All commands now compile a display 
list directly without going through an intermediate form. This alteration to the implementa­tion approach 
is less complicated than it seems. The process of compiling a display list hasn't changed; only the intermediate 
buffering has been removed. Instead of retrieving data from a map, interpreting it, storing it in the 
temporary relations and'then display­ing it, the data is now retrieved, interpreted, and then displayed 
directly. As a conse­quence, SAVEMAP now saves a display list representation of the screen rather than 
a rela­ tional representation. a result of this There was no real decentralization of the device dependent 
code as change. The device dependent drawing routines are the same ones that were called by the old DISPLAY 
command. Changing devices necessitates rewriting these routines in either the original approach or the 
new approach. The calling conventions for these routines are Moreover, sufficiently general so as to 
support most kinds of existing display devices. INGRES is still used to store all geographic data and 
to perform many manipulations. On 189 the other hand, there is no longer a relation corresponding to 
the contents of the screen. Several changes were also made in the command language or its effect. For 
example, the SHADE command will shade zones in a map.on..up to four data-domains. The SHADE algo­rithm 
operates on all zones which are not completely out of the viewing area. The line option mentioned in 
the original proposal was not implemented but is currently under con­ sideration for a future version. 
 LINEGRAPH and POINTGRAPH have been extended to allow the user to optionally specify what endpoints s/he 
wants for the axis of the. graph. Also, the user can specify up to ten y-coordinate domains to plot 
against the one.x-domain, each one being plotted with a dif­ferent character. In the case of LINEGRAPH, 
the points of an x-y domain pair are con­nected so that up to ten unique connected lines are drawn. 
Two new commands have been added, WIPE and HISTOGRAM. WIPE is a mechanism to clear the display list 
(i.e. the screen). This is not automatically done at the start of a com­mand. HISTOGRAM produces a 10 
cell histogram of a data domain and certain other statisti­cal information including variance and standard 
deviation. The totality of these changes significantely reduced the runtime of GEOQUEL. The performance 
gain realized was between 10 and 20.times faster than the original implementa­tion. The system is now 
approximately as fast as it can be made and still remain a "front end" which has no storage structures 
of its own but relies on INGRES to store all geo­graphic data. After this redesign and tuning we felt 
it advantageous to run comparisons between the updated GEO-OUEL and what might be expected from a special 
purpose geo-data system. These are described in the next section. IV. COST EFFECTIVENESS OF A "FRONT 
END" To compare GEO-OUEL with a special purpose geo-data system we ran a "mock-up" of GEO-OUEL, attempting 
to ascertain a lower bound for the performance of a geo-data system in our environment. This "mock-up" 
consisted of the GEO-QUEL front end with INGRES absent. Data that GEO-OUEL would normally request from 
INGRES was stored in normal files, and the code was modified to retrieve the data from.these files. 
The development cost for the software is summarized in Table 1. Since it is reason­able to assume that 
a user of a special purpose system would-want most of the power avail­able in INGRES, then most of the 
INGRES code would be required for such a system. Using the total of columns 2 and 3 in Table 1 as an 
approximation of the cost for a special pur­pose system, we see that our "front end" approach (column 
2 only) required 16% of the source code, 13% of the object code, and 2-3% of the development cost of 
a special purpose system.  We turn now to the performance comparison. Table 2 shows the time consumed 
by three different commands for both the mock-up and GEO-OUEL. The last column indicates the per­formance 
penalty for using GEO-QUEL. These commands were made with no other activity present on our PDP-11/70 
system. Note that this penalty is only a factor of 2-4. The authors feel that this penalty is an. upper 
bound on the penalty of our "front end" approach. Moreover, a large part of the penalty is probably accounted 
for by the fact that INGRES must run as multiple processes [8] because of its size. This necessi­tates 
passing commands and data between processes through the UNIX interprocess communica­tions facility [13]. 
Since the mock-up runs as a single process it incurs no 190  communication overhead. However, a real 
special purpose system would be much larger than the mock-up and would necessitate at least some communication 
overhead. In summary, the authors feel that a factor of 30-40 in software development costs in exchange 
for a factor of 2-4 in performance is often an advantageous exchange. Further­even more, given the trends 
in hardware and software costs, this exchange should become more beneficial in the future.  V. REFERENCES 
 The Berkeley Urban Data System," Electronics Research Laboratory, [1] Macri, P., "BUDS: University 
of California, Berkeley, Memorandum M412, November, 1973.  Christiani, E. J., et. al., "An Interactive 
System for Aiding Evaluation of Local Government Policies," IEEE Transactions on Systems, Man, and Cybernetics, 
vol. SMC­3, no. 2, Mar. 1973, pp. 141-146. [3] Mantey, P. E., et. al., "Information for Problem Solving: 
The Development of an Communication, vol. Interactive Geographic Information System," IEEE Conference 
on II, Seattle, Washington, June 1973.  Parker, J. L., "Information Retrieval with Large Scale Geographic 
Data Bases," Proc. 1971 ACM-SIGFIDET Workshop on Data Description, Access and Control, San Diego, Ca., 
Nov. 1971. "FIRS II -Design Require-ments Component," Wey­ [5] Depta, D. J., and Irwin, G. M., erhauser 
Company, Woods Product Information Systems, Tacoma, Wash., March, 1974.  and Williams, C., "An Approach 
to Implementing a GEO-DATA Go, A., Stonebraker, M., System," Proc 1975 ACM SIGGRAPH-SIGMOD Workshop 
on Data Bases in Interactive Design, Waterloo, Ontario, September 1975. "INGRES -A Relational Data Base 
System", Held, G., Stonebraker, M., and Wong, G., Proc 1975 NCC, Anaheim, California, May 1975 and 
Kreps, P., "The Design and Implementa- Stonebraker, M. R., Wong, E., Held, G. D., tion of INGRES", ACM 
Transactions on Data Base Systems, Vol. 1, No. 3. (June [9] Codd, E., "A Relational Model of Data for 
Large Shared Data Banks," CACM 16, 1970). [10] Held, G. and Stonebraker, M., "Storage Structures and 
Access Methods in the Rela­ tional Data Base Management System, INGRES," Proc. ACM-PACIFIC-75, San Francisco, 
Ca., April 1975. Electronics Research al., -- Laboratory, University of California, Berkeley, Memorandum 
No. ERL-M579, April, 1977. [11] Youssefi, K., et. "INGRES Reference Manual Version 6", [12] Ritchie, 
D. M., "C Reference Manual," Bell Telephone Labora-tories, Murray Hill, New Jersey, Jan. 1974. No. 7, 
 [13] Ritchie, D. M. and Thompson, K., "The UNIX Time Sharing System," CACM, Vol 17, pp365-375, July 
1974. 191 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563893</article_id>
		<sort_key>192</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>35</seq_no>
		<title><![CDATA[Models of light reflection for computer synthesized pictures]]></title>
		<page_from>192</page_from>
		<page_to>198</page_to>
		<doi_number>10.1145/563858.563893</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563893</url>
		<abstract>
			<par><![CDATA[In the production of computer generated pictures of three dimensional objects, one stage of the calculation is the determination of the intensity of a given object once its visibility has been established. This is typically done by modelling the surface as a perfect diffuser, sometimes with a specular component added for the simulation of hilights. This paper presents a more accurate function for the generation of hilights which is based on some experimental measurements of how light reflects from real surfaces. It differs from previous models in that the intensity of the hilight changes with the direction of the light source. Also the position and shape of the hilights is somewhat different from that generated by simpler models. Finally, the hilight function generates different results when simulating metallic vs. nonmetallic surfaces. Many of the effects so generated are somewhat subtle and are apparent only during movie sequences. Some representative still frames from such movies are included.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[computer graphics]]></kw>
			<kw><![CDATA[graphic display]]></kw>
			<kw><![CDATA[hidden surface removal]]></kw>
			<kw><![CDATA[shading]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P131722</person_id>
				<author_profile_id><![CDATA[81100294395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Blinn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>360353</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F. and Newell, M. E. Texture and reflection incomputer generated images. Comm ACM 19, 10(Oct 1976), 542-547]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bui-Tuong Phong. Illumination for computer generated images. Comm ACM 18, 6(June 1975) 311-317]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Catmull, E. A. Computer display of curved surfaces. Proc. Conf. on Comptr. Graphics. May 1975 (IEEE Cat. No. 75CH0981-1C)11-17]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Gilpin, F. H. Effect of the variation of the incident angle on the coefficient of diffused reflection. Trans. Illum. Eng. Soc. Vol 5, 1910 854-873]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Middleton, W. E. K. and Mungall, A. G. The luminous directional reflectance of snow. J. Opt. Soc. Am. 42, 8(Aug 1952) 572-579]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Torrance, K. E. and Sparrow, E. M. Polarization, directional distribution, and off-specular peak phenomena in light reflected from roughened surfaces. J. Opt. Soc. Am. 56, 7(Jul 1966) 916-925]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Torrance, K. E. and Sparrow, E. M. Theory for off-specular reflection from roughened surfaces. J. Opt. Soc. Am. 57, 9(Sep 1967) 1105-1114]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Trowbridge, T. S. and Reitz, K. P. Average irregularity representation of a roughened surface for ray reflection. J. Opt. Soc. Am. 65, 1975) 531-536]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 MODELS OF LIQrHT REFLECTION FOR CO1PUTER SYNTHESIZED PICTURES James F.Blinn University of Utah ABSTRACT 
Inthe production of computer generated pictures of three dimensional objects, one stage of the calculation 
isthe determinationof the intensity of a given object once its visibility has been established. This 
is typically done by modelling the surface as a perfect diffuser, sometimes with a specular component 
added for the simulation of hilights. This paper presents a more accurate function for the generation 
of hilights which isbased on some experimental measurements of how light reflects from real surfaces. 
Itdiffers from previous models in that the intensity of the hilight changes with the direction of the 
light source. Also the position and shape of the hilights issomewhat different from that generated by 
simpler models. Finally, the hilight function generates different results when simulating metallicvs. 
nonmetallic surfaces. Many of the effects so generated are somewhat subtle and are apparent only during 
movie sequences. Some representative still frames from such movies are included. Key Words and Phrases: 
computer graphics, graphic display, shading, hidden surface removal. CR Categories: 3.17, 5.12, 8.2 
 INTRODUCTION Inproducing computer generated pictures of three dimensional objects, two types of calculat­ion 
must be performed. The first, and most popularlydiscussed, isthe hidden surface problem; determining 
which object is visible where on the screen and what isthe normal vector to the object at that point. 
The second isthe intensity calculation; given the normal vector and the position of the light sources, 
what is the proper intensity for the corresponding spot on the picture. Very simple models are typically 
used which simulate ideal diffuse reflectors. This uses the, so called, Lambert's law which states that 
the surface will diffuse incident light equally in all directions. Differences in intensity.are then 
 caused by the different amounts of incident light per unit area interceptedby portions of the surface 
at various angles to the light source. This will be proportional to the cosine of the angle between the 
normal to the surface, N, and the vector to the light source, L. This cosine Permission to make digital 
or hard copies of part or all of this work or personal or classroom use is granted without fee provided 
that copies are not made or distributed for profit or commercial advantage and that copies bear this 
notice and the full citation on the first page. To copy otherwise, to 192 republish, to post on servers, 
or to redistribute to lists, requires prior specific permission and/or a fee. Siggraph 77, July 20-22 
San Jose, California isevaluated by computing the dot product of the two vectors after normallizingthem 
to a length of 1. Ifthis dot product isnegative it indicates that the viewer ison the opposite side of 
the surface from the light source. The intensity should then be set to zero. Inaddition, some constant 
value isusually added to the intensity to simulate the effects of ambient light on the surface. This 
assumes that a small amount of light falls on the surface uniformly from all directions in addition to 
the main point light source. The integral of this ambient light from all directions yields a constant 
value for any normal direction. The net function is:  This model is simple to compute and quite adequate 
for many applications. SIMPLE HILIGHT MODELS A more realistic lighting model was intro­duces by Phong 
[2] as part of a technique for improving the appearance of images of curved surfaces. The function makes 
use of the fact that, for any real surface, more light is reflect­ ed in a direction making an equal 
angle of inci­dence with reflectance. The additional light reflected in this direction isreferred to 
as the specular component. Ifthe surface was a perfect mirror light would only reach the eye if the surface 
normal, N,pointedhalfway between the source direction,L, and the eye direction, E. We will name this 
direction of maximum hilights H, where  For less than perfect mirrors, the specular compo­nent falls 
off slowly as the normal direction movesaway from the specular direction. The cosine of the angle between 
H and N is used as a measure of the distance a particular surface is away from the maximum specular direction. 
The degree of sharp­nesssof the highlights is adjusted by taking this cosine to some power, typically 
50 or 60. Thenet Phong shading function is then: d = max(0,N.L) s = (N*H)= i=p,+dpd+sp s where i 
= percieved intensity p,= proportion of specular reflection s = amount of specular reflection cl= measure 
of shininess of surface other values as defined above In addition, when simulating colored surfaces, 
there is a different intensity value for each primary. These. should be calculated by scaling only the 
diffuse and ambient components by the color of the object. The highlights then appear desaturated or 
white. TORRANCE- SPARROW MODEL The reflection of light from real surfaces has been the subject of much 
theoretical and experimental work by physicists Is], [6] and illumination engineers [4]. The experimental 
results generally match the Phong shading function but some differences do arise. The main one is the 
fact that the the specular bump, represented by the parameter p, above, varies with the direction of 
the light source. Also the direction of peak specular reflection is not always exactly along H. In 1967 
Torrance and Sparrow [7] derived a theoretical model to explain these effects. The match between their 
theoretically predicted functions and experimen­ tally measured data is auite imoressive. In this section 
we derive the Torrance-Sparrow highlight function in terms of the vectors N, L, H and E, all of which 
are assumed to be nonnallized. The surface being simulated is assumed to be composed of a collection 
of mirror like micro facets. These are oriented in random directions all over the surface. The specular 
component of the reflected light is assumed to come from reflection from those facets oriented in the 
direction of H. The diffuse component comes from multiple reflections between facets and from internal 
scattering. The specular reflectionis then a combination of four factors:  D is the distribution function 
of the directions of the micro facets on the surface. G is the amount by which the facets shadow and 
mask each other. F is the Fresnel reflection law. Each of these factors will now be examined in turn. 
The light reflected specularly in any givendirection can come only from the facets oriented to reflect 
the light in that direction. That is,the facets whose local normal vectors point in the direction of 
H. The first term in the specular reflectance is the evaluation of the distribution of the number of 
facets pointing in that.direction. The distribution used by Torrance and Sparrow was a simple Gaussian: 
DI = ,-bCd2 Dz is the proportionate number of facets oriented at an angle CI from the average normal 
to the surface. The factor cz is the standard deviation for the distribution and is a property of the 
surface being modelled. Large values yield dull surfaces and small values yield shiny surfaces.We are 
interested in the number of facets pointing in the direction of H so the angle a here is cos (N-H). 
Since the intensity is proportional to the number of facets pointing in the H direction, we must take 
into account the observer sees more of the surface area when the surface is tilted. The increase in area 
is inversely proportional to the cosine of the angle of tilt. The tilt angle is is the angle between 
the average surface normal, 0; ;d the eye, E. This explains the division by Counteracting this effect 
is the fact that some of the facets shadow each other. The degree to which this shadowing occurs is called 
the geometrical attenuation factor , G. It is a value from 0 to.1 representing the proportionateamount 
of light remaining after the masking or shadowing has taken place. Calculation of G assumes that the 
micro facets exist in the form of V shaped grooves with the sides at equal but opposite angles to the 
average surface normal. We are interested only in grooves where one of thesides points in the specular 
direction H. For differing positions of the light source and eye oosition we can have one of three cases 
illustrated in Figure 1. Case a No interference Case b Y$J !f> Some of the reflected light is intercepted 
 Note that the vectors L and E do not necessarily lie in the plane of the figure (i. e. the plane containing 
N and H). We can see this by consid­ering a top view as in Figure 2.   Then we note that  Since the 
angles of the triangle must sum to 21 we have  to the symmetry of the groove and the comple­mentarityof 
d and a  Plugging these into the expressionfor sinf  p -p Since Ep isthe projectionof B onto the N,H 
plane then N-E =N-E and H-E =H-E so that  Examining the diagram for Gc we see that it is the same as 
that for b but with the roles of L and E exchanged.Thus  For a particular situation, the effective 
value of G will be the minimum of Ga, Gb and G . The final factor in the specular reflection isthe 
Fresnel reflection. This gives the fraction of the light incident on a facet which is actually reflected 
as opposed to being absorbed. This is a function of the angle of incidence on the micro facet and the 
index of refractionon the substance. It is given by  The interesting thing about this function is that 
it has a substantially different form for' metallic vs. nonmetallic sub­stances. For metals, corresponding 
to large values of n, F(O,n) isnearly constant at 1. For non­metals, corresponding to small values of 
n, it has a more exponential appearance, starting out near zero for 0=0 and going to 1 at C=T/2.  = 
FACET DISTRIBUTIONFUNCTIONS One thing in the above model can be improved upon. This is the facet distributionfunction. 
 measure of This function takes an angle, a, and a the shininessof the surface and computes the proportionate 
area of facets pointing in that direction. The angle a isthe angle between H and N; we can evaluate 
its cosine as (N-H).  The Phong model effectivelyuses the dis­tributionfunction of the cosine raised 
to a power.  The Torrance Sparrowmodel uses the standard Gaussian distribution alreadymentioned.  A 
third functionhas been proposedby They showed that a Trowbridgeand Reitz [8]. very general class of 
surface propertiescould be generated by modelling the microfacets as ellipsoids of revolution. This leads 
to the distributionfunction  Where c3 is the eccentricityof the ellipsoids and is 0 for very shiny 
surfaces and 1 for very dif­ fuse surfaces. Each of these functions has a peak value of 1 at a=0 (for 
facets pointing along the average surface normal) and falls off as a increases or The rate of fall 
off is controlledby decreases. the values cl, c2 and 3. Incomparing the functions it is necessary 
to specify this rate in a uniform unit. A convenient such unit is the angle at which the distributionfalls 
to one half. In terms of this angle, B, the three coefficientsare:  Ifthese three functions are plotted 
with equal it can be seen that they are very values of similar in shape. However, since there is some 
 as well as theoretical justification experimental for D3 and since it is the easiest to compute, it 
is the one we shall choose. COMPUTATIONAL CONSIDERATIONS There are several observationswhich can be 
made to speed up the computationof the hilight function. does not change within a frame the function 
D3 can be calculated using the intermed­iate values (calculated once per frame): If A simplificationwhich 
isoften made isto that the light source is at infinity. Thus assume the vector L is a constant for each 
point of the as being far picture. We may also model the eye away from the object so that E = (0 0 -1). 
This allows the calculationof the direction of H to be done once per change in light direction. It ispossible 
to avoid a potential division by zero when computing G by combining it with the term 1/(N-E) and finding 
the minimum of Ga, Gb and Gc before doing the divisions:  CnMPARISON WITH PHONG SHADING Now that we 
have derived this hilight functionwe should compare it with the Phong function to see where and by how 
much they differ. Figure 5 shows a plot of the amount of light re­ as a result of an incident flected 
from a surface ray at 30 degrees from the surface normal. The a particular direction distance of the 
surface in from the center represents the amount of light reflected in that direction. The incoming 
ray is from the right. A vector pointing to the left at the speculardirection isshown for reference. 
 The hemispherical portion of the function isthe. diffusereflection; equal amounts in each direc­ tion. 
The bump isthe specular reflection.. For this angle of incidence the functions.arealmost identical. 
Figure 6 shows the same function for an incident ray at 70 degrees. Note that the specular bump ismuch 
larger for the Torrance  Phong Model Torrance-Sparrow Model Figure 5 Comparison of Phong and Torrance-Sparrow 
reflection distributions for incident light at 300 from normal Sparrow function and not in quite the 
same direct­ion. This indicates that the new function will be materially different only for shallow angles 
of incident light and that the specular reflection will be much higher there. This may be verifiedby 
the simple experiment of holding a matte sheet of paper edge on to a light and noting that it looks quite 
shiny. Figure 7 shows images of an object made using the two hilight functions with both an edge-on lighting 
direction and a front-on direc­tion. Figure 7a simulates an aluminum metallicsurface using the experimentally 
measured parameters : p, = .4 pd= .6 n = 200 cg = .J 5 Figure 7b simulates a Magnesium Oxide ceramic 
(a standard diffuse reflector) using the experimental parameters: p, = .667 pd = .333 n = 1.8 cg = .35 
Note that the ceramic looks quite diffuse for light hitting it almost perpendicularly and very specular 
(even more. so than. the aluminum) for light hitting it almost tangentially. VARYING SURFACE SHININESS 
In [1] and [3] a technique for mapping texture patterns onto. bicubic surfaces was described. The object-was 
defined as a bipara­meteric surface and the parameter values were Phong Model Torrance-Sparrow Model 
Figure 6 Comparison of Phong and Torrance-Sparrow reflection distributions for incident light at 70 from 
normal Phong Torrance-Sparrow Both Models Essentially Same Edge Lit Front Lit Figure ?a Simulation of 
Aluminum Surface Phong Torrance-Sparrow Both Models Essentially Same Edge Lit Front Lit Figure 7b Simulation 
of Magnesium Oxide Surface Figure 8 Surface shininess varying as a functionof two different texture 
patterns used as input to a texture function which scaled the diffuse component of the reflection. Thisform 
of mapping is good for simulating patternspainted on the surface but attempts to simulate bumpy surfaces 
were disappointing. This effectcan, however, be better approximated by using thesame texture mapping 
approach applied to thelocal surface roughness cg. If c3 is going to change from place to placeon the 
surface we must worry about nonnallizationof the D, function. In its original derivation t in [8] Da 
differed from that shown here by afactor of c3'. This additional factor was included here as a normallizing 
constant to makeD3(0)=1. Since, now, c3 is varying across thesurface, we wish to use a constant normallizingfactor 
based on its minimum value over the surface. The texture modulated distribution function should then 
be: c3 = Cmin + (l-cmin) t (",v) I C min " D3 = cos2a(cs2-l)+l I wheret(u,v)=texture value Figure 
8 shows some images made with various texturing functions. CONCLUSIONS The Torrance-Sparrow reflection 
model differsfrom the Phong model in the inclusion of the G, Fand l/(N*E) terms. This has a noticable 
effect primarily for non-metallic and edge lit objects.The use of the D3 micro facet distribution function 
provides a better match to experimentaldata and is, happily, easier to compute than D1 or D2. This savings 
effectively offsets theextra computation time for G and F yielding ahilight generation function having 
a high degreeof realism for no increase in computation time. REFERENCES 1. Blinn, J. F. and Newell, M. 
E. Texture and reflection incomputer generated images.Comm ACM 19, 10(Oct 1976), 542-547 2. Bui-Tuong 
Phong. Illumination for computergenerated images. Comm ACM 18, 6(June 1975)311-317 3. Catmull, E. A. 
Computer display of curvedsurfaces. Proc. Conf. on Comptr. Graphics.May 1975 (IEEE Cat. No. 75CH0981-1C)11-17 
 4. Gilpin, F. H. Effect of the variation of the incident angle on the coefficient of diffusedreflection. 
Trans. Illum. Eng. Soc. Vol 5, 1910 5. Middleton, W. E. K. and Mungall, A. G. The luminous directional 
reflectance of snow. J. Opt. Soc. Am. 42, 8(Aug 1952) 572-579 6. Torrance, K. E. and Sparrow, E. M. 
Polarization,directional distribution, and off-specular peakphenomena in light reflected from roughenedsurfaces. 
J. Opt. Soc. Am. 56, 7(Jul 1966)916-925 7. Torrance, K. E. and Sparrow, E. M. Theory foroff-specular 
reflection from roughened surfaces. J. Opt. Soc. Am.. 57, 9(Sep 1967) 1105-1114 8. Trowbridge, T. S. 
and Reitz, K. P. Averageirregularity representation of a roughenedsurface for ray reflection. J. Opt. 
Soc. Am. 65, 1975) 531-536  854-873
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563894</article_id>
		<sort_key>199</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>36</seq_no>
		<title><![CDATA[Line generation for incremental and raster devices]]></title>
		<page_from>199</page_from>
		<page_to>205</page_to>
		<doi_number>10.1145/563858.563894</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563894</url>
		<abstract>
			<par><![CDATA[The characteristics,properties and generative sequences of line generation algorithms for incremental and raster devices are summarized and the mappings from one into the other are discussed. Extensions to the basic algorithms to exploit a greater variety of possible operations in the basic hardware set of incremental devices and also to cater for various types of curve are summarized.A new method of partitioning based upon derived code sequences and code patterns is presented and is shown to lead to significant code sequence compression (more than 40%) in the majority of cases, and more importantly a significant overall reduction of between 20% and 43% in the total central processor usage. Algorithms for encoding the sequences are presented.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[curve drawing]]></kw>
			<kw><![CDATA[incremental plotters]]></kw>
			<kw><![CDATA[line tracking]]></kw>
			<kw><![CDATA[partitioning]]></kw>
			<kw><![CDATA[raster devices]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P231877</person_id>
				<author_profile_id><![CDATA[81100553088]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Earnshaw]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Leeds, LEEDS, LS2 9JT, ENGLAND U.K.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Boothroyd, J. Private Communication.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Boothroyd, J. and Hamilton, P. A. Exactly reversible plotter paths. Australian Computer Journal, Vol. 2, No. 1 (1970), 20-21.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bresenham, J. E. Algorithm for computer control of a digital plotter. IBM Systems Journal, Vol. 4, No. 1 (1965), 25-30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>550359</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Dijkstra, E. W. A Discipline of Programming. Prentice-Hall, EnglewoodCliffs, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Earnshaw, R. A. Graph Plotting in Algol 68-R. Software-Practice and Experience, Vol. 6, No. 1 (1976), 51-60.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>270146</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Knuth, D. E. The Art of Computer Programming-Vol. 2, SeminumericalAlgorithms, Addison Wesley Publishing Company, 1969, 293-338.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Pitteway, M. L. V. The impact of computer graphics. Nature, Vol. 235 (January 14, 1972), 83-85.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Pitteway, M. L. V. Algorithm for drawing ellipses or hyperbolae with a digital plotter. Computer Journal, Vol. 10 (1967), 282-289.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Stein, J. J. Comp. Phys., Vol. 1 (1967), 397-405.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Stockton, F. G. Algorithm 162, Comm. ACM 6, 4 (1963).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Thompson, J. R. Straight lines and graph plotters. Computer Journal, Vol. 4, No. 3 (1964), 227.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 LINE GENERATION FOR INCREMENTAL AND RASTER DEVICES R. A. Earnshaw Centre for Computer Studies University 
of Leeds LEEDS LS2 9JT ENGLAND U.K. Abstract The characteristics,properties and generative sequences 
of line generation algorithms for incremental and raster devices are summarized and the mappings from 
one into the other are discussed. Extensions to the basic algorithms to exploit a greater variety of 
possible operations in the basic hardware set of incre­mental devices and also to cater for various types 
of curve are summarized. A new method of partitioning based upon derived code sequences and code patterns 
is presented and is shown to lead to significant code sequence compression (more than 40%) in the majority 
of cases, and more importantly a significant overall reduction of between 20% and 43% in the total central 
processor usage. Algorithms for encoding the sequences are presented. Key Words and Phrases: line tracking, 
incremental plotters, raster devices, partitioning,curve drawing. .CRCategories: 4.9, 5.19, 8.2 1. 
Introduction the facilities of devices containing a greater variety of possible operations in the basic 
set The use of an incrementalplotter involves the (Boothroyd [1]) or even to draw certain types of generation 
of a sequence of movements corresponding curve (Pitteway [7,8]). to "best possible straight lines" at 
some stage in the generation of the picture to be drawn. This These will be summarized in the following 
sections: arises due to the fact that elemental pen movements can usually only be made in a finite number 
of 2. Line Generation by Sequences directions and thereforepictures that contain lines at orientations 
other than those of the basic 2.1. The Bresenham Sequence set must represent these by an approximation 
con­sisting of a permutation of the appropriate basic Consider the point (r,q) in Fig. 1. movements. 
 Raster devices utilise similar information for the drawing of lines; in this case each point on the 
raster closest to the theoretical line will be obtained and displayed. The process of obtaining such 
point sequences corresponding to all the lines required is identical to that described above, with the 
omission of movement code selection. In this case the points can be recorded in a bit map representing 
the raster. Linear interpolationmay be done by hardware or software, and for the latter there are numerous 
well known algorithms for the generation of these movements or location of the next position in such 
a way as to minimize the maximum deviation from the straight line join; some of the earliest being those 
of Stockton [10], Bresenham [3], Thompson [11], and Boothroyd and Hamilton [2j. What is not always so 
readily appreciated is the relationship between these algorithms or the various ways in which the algorithms 
may be extended to exploit Permission to make digital or hard copies of part or all of this work or 
personal or classroom use is granted without fee provided that copies are not made or distributed for 
profit or commercial advantage and that copies bear this notice and the full citation on the first page. 
To copy otherwise, to 199 republish, to post on servers, or to redistribute to lists, requires prior 
specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California  Otherwise r+r+l, q+q+l 
and the new condition is Sr + 2(b-a) < which constitute the Bresenham recursive relation [3].  For 
example, the Bresenham sequence for the move­ment from (0,0) to (10,3) is as follows:-  2.2. The PartitioningAlgorithm 
 The generation of the minimum sequence may be con­ sidered as an algorithm for partitioninga set of 
 elements, where the elements are commands to per­ form either axial or diagonal incremental move­ ments 
to produce the optimal straight line sequence. Given two non-negative integers m,n (not both zero) 
then -  Where a = axial movement, d = diagonal movement. Thus although the values of S generated by 
partit­ ioning are different to those of the Bresenham sequence, the movements generated are the same. 
 It can now easily be shown that the Thompson sequence can be mapped into the Bresenham sequence by 
means of a linear relation. For the Thompson sequence the value of S(r, ) = (r-q)b -q(a-b) since at (r,q) 
we have performed q diagonal move­ments of "weight" -(a-b) and (r-q) axial movements of "weight" b. 
  which can be mapped directly into equation (1) for the value of S( corresponding to the Bresenham 
 ) sequence. 2.3. Extensions to the Basic Algorithms Greater variety of basic movements The spectrum 
of possible movements in the basic set can be extended by the addition of further inter­mediate vector 
movements (e.g. 24 vector mode). A method for exploitation of these additional move­ments arises from 
the consideration of the algor­ithms discussed previously from yet another point of view. Considering 
the progress that the basic 8-vector algorithm makes for axial or diagonal movements respectively gives 
the following result:­  where each a. is either -m or +n and the sequence  {a.} is so chosen that maxISkl 
is the least possible (Thompson [11]).k This is accomplished by choosing ak+l to be +n or -m depending 
on whether 2S + n-m is negative or positive. Given S then k  which gives the following algorithm 
in terms of the variables a and b used in 2.1.  The partitioningsequence for the movement from (0,0) 
to (10,3) is as follows:- If na = number of steps in x direction and nb = number of steps in y direction 
Then from (0,0) to (x,y)  Total number of steps = na + nb = x = a = Number of diagonal steps = nb 
= y b i.e. x = a and x = b in the basic algorithm. Thus a(=na+nb) is the total number of elements in 
the set while b is the number of elements in the diagonal subset. Consider the two types of sector shown 
in Fig. 2. For Sector 1: Progress in the x direction by na + 2nb = x Progress in the y direction by 
nb = y (units are those of the 'fine grid').  200 The above approach was first proposed by Boothroyd 
 [1], and may be extended to cater for all sectors and all possible combinations of long or short vectors 
where a given direction has more than one possible movement. Extensions to curves Line generation using 
the methods previously des­ cribed has two principal advantages over ad hoc methods. Firstly, the generation 
of the incre­ments for the line involves only one add operation and tests at each stage. Secondly, the 
algorithms can be implemented using economical amounts of storage. With two further addition operations 
it is possible to generate ellipses or hyperbolae or spirals (Pitteway [7,8]). Two more additions are 
required for display devices which do not accept incremental commands, and two further tests are required 
to detect possible changes of sector. 3. Line generation by compression Repeated Codes The occurrence 
of sequences of repeated movements (e.g. see sequence in section 2.1) in the overall sequence of movements 
corresponding to a partic­ular line suggests scope for compression of such repetitions into a single 
entity. This enables the total amount of information to be transmitted to the actual device to be reduced, 
or alternative­ly, if backing store is used for intermediate storage of the information, this gives reduction 
 in the total space needed for this purpose. Of course, if the information is to be transmitted to the 
device directly, it could be argued that complete compaction into the original destination coordinates 
should be the first choice rather than an intermediate compression and subsequent re­generation, and 
delay the line generation process until the output to the actual device. This of course suggests immediate 
exploitationfor devices where line generation is done entirely by hardware. However, the former approach 
was investigated for the case of a spooling system on to disc and was found to lead to unexpected results. 
 From the observation of graphs alone it is clear that certain constructs are frequent components of 
larger pictures and these constructs consist in the main of repetitive sequences. Examples of these are 
border, arcs and characters, especially where the latter are produced by generationof points taken from 
an individual raster frame (e.g. 10x6). A series of jobs producing output on the incre­mental plotter 
were analysed in detail to determine the proportion of the total information containing sequences of 
repeated identical codes. Two such analyses are shown in Fig. 3; the proportion of distinct codes (i.e. 
those corresponding to a 'repeated sequence' code count of 1) being also given to enable a comparison 
to be made. Clearly a significantproportion (61% in picture A; 85% in picture B) of the total space occupied 
by the code information is occupied by sequences of two or more identical movement codes.  It is apparent 
that long sequences of identical movement codes are produced by movements in the X or Y directions alone, 
or along any diagonal, whereas shorter sequences are produced during line tracking in any other direction. 
The former can be measured on the resulting picture, but the latter can only be determined by a detailed 
analysis of all the movement codes corresponding to the picture. This last was the method adopted for 
the results presented here.  201 One way of implementingthe compression is to re­present repeated sequences 
as shown in Fig. 4. The * indicates that the following four characters are to be taken as representinga 
repeated sequence; each character being, say, six bits. The partic­ ular movement code to be repeated 
is held in the top six bits, and the number of times it is to be repeated in the remaining eighteen bits. 
The latter will usually be sufficient to cater for the longest possible sequences. With a represent­ation 
such as this, sequences with greater than five identical codes can be compressed, giving a saving of 
20 and 51% respectivelyfor the two jobs shown in Fig. 3 (the actual space occupied by sequences with 
greater than five identical codes being 28% and 59% respectively of the total code information). Wide 
variation in the results from individual jobs is due principally to the picture elements con­stituting 
the graph. For example, many pictures include the drawing of axes and a border, thus the smaller the 
picture, the greater the proportion of the code sequence for these items. Picture A corresponds to a 
total of 1738539 codes, whereas picture B corresponds to a total of 74554 codes. In order to obtain 
a more accurate estimate of the savings achieved by compressing identical codes in sequence, a large 
range of pictures were analysed. Out of 12308570 codes 38% of the space occupied by these codes consisted 
of sequences containing more than five identical codes. Replacementof these by repetition encoding yielded 
a saving of 26% in the space occupied by the original codes. Reduction of the space to hold the repetition 
 count from, say 18 bits to 12 bits in order to compress sequences with greater than four identical 
 codes, with the consequent inability to cater for the longer but less frequent sequences resulted in 
 an additional saving of about 1%. In addition, the extra central processor time needed to compress 
 sequences of five identical codes implies that such a representation offers only marginal advan­ tage, 
and would only be chosen where store was at a premium. An indication of the distribution in the repetit­ 
ion sequences over the various codes was obtained from an analysis of pictures A and B shown in Table 
I, the major proportion of the possible saving thus arises from the codes corresponding to movements 
in X or Y directions only, particularly for the longer sequences. The additional central processor 
time necessary to perform the compression was 25% of that previous­ly required to generate the uncompressed 
sequence, and there was a small increase by the processing required to perform the expansion before output 
to the device. Although this enhancement caters for repeated codes in sequence, it does not cater for 
repeated code sequences (i.e. patterns) generated, for example, by tracking movements within areas 
between principal and diagonal axes, unless the particular pattern contains more than five ident­ ical 
codes in sequence, in which case some econ­ omisation is possible using the method previously described. 
In such cases as these, maximum compression can only be obtained by replacing the code in the representation 
previously discussed by the particular code sequence (i.e. pattern) which is to be repeated a given number 
of times.  Table I Distribution of Code Sequences over the various codes Repeated code sequences 
As for the Bresenham line tracking algorithm, attention may be initially concentratedon the first quadrant; 
other directions being effectively catered for by symmetry. If the direction of the line to be drawn 
lies along the diagonal (i.e. the number of steps in the x direction (N ) is equal to the number of x 
 steps in the y direction (N )) or along the axis (i.e. N = 0), then the movement can be encoded directly 
using the representation described in the previous section. x If the line to be tracked from A to B 
(Fig. 5) involves a value of N of 1, then clearly the diagonal movement will be made at the mid-point 
(or within one increment)of the axial distance from A to B (say, N ) intervals.  202 Hence, the sequence 
to be repeatedcould be based upon the x movement, this being repeated at least L(N -1)/2J times; and 
once again this can be encoded directly at the generation stage. If N > 1 and (N /N ) is an integer, 
then this re­ to the above,Yexcept that the whole sequence is repeated N times. Thus, rather than represent­ing 
repeated codes, greater savings can be achieved by repeating the pattern corresponding to (N /N ) intervals. 
  If N > 1 and (N /N )is not an integer, then the pattern to be repeated needs to be calculatedin more 
detail as it is not necessarily regular. In this case, an axial movement is performedif  otherwise a 
diagonal movement is performed.  where p1,p ...etc. are primes and i,j are non­negative integers, then 
(N /N )can be reduced to its simplest form by obtaining the divisors of N and N which cancel out. The 
product of these divisors gives the number of times the basic pat­ tern (given by the simplest form of 
(N /N ))is to be repeated. This is the greatest common divisor, given by  min(i ,j ) which may be obtained 
 P p without factoring N and N (which is a relatively slow process) by using eYther Euclid's method 
 (Knuth[5], Dijkstra [4]) or a more efficient var­iant (Stein [8]) which does not use the division operation. 
The efficiency of this part of the al­gorithm is clearly crucial to the overal efficiency of the method; 
the larger the greatest common div­isor, the greater the extent of the repetition. As an example of 
the way in which a given sequence can repeat, consider the case of N = 22 and N = 60. This reduces to 
the pattern for the interval N = 30 (N = 11) which can be repeated again for the interval N = 30 to 60. 
Fig. 6 shows x the line tracking sequence for the interval, N , to 30. The sequence of movements is 
thus  (where a represents an axial movement and b repres­ents a diagonal movement) which (apart from 
the end) involves a repetition of aab or ab, not unexpected -  of the original line (N /N = 2.727). 
 in view of the (gradient) y  Fig. 6. Line tracking sequence for N = 30 and N = 11. y  In order 
to decide which movement (or sequence of movements) to take next in any given position, it was not possible 
to determine this (for a case such as the above) in terms of the patterns so far completed only, although 
clearly it would have been advantageous to be able to do so. A calculation in the form of that in equation 
(3) must be performed. In order to cater for compression of this inform­ation a different form of encoding 
to that used for repeated codes must be used. One possible form is shown in Fig. 7.  Fig. 7. Encoding 
for repeated patterns In order to investigate line generation by means of repeated patterns, numerous 
pictures (three of which are shown in Figs. 8, 9 and 10) using only straight lines were used. Figs. 8 
and 10 contain a good selection of lines of different lengths and orientations. The information corresponding 
to the straight lines was encoded using the two methods previouslyoutlined. Repeated identical codes 
 (e.g. for lines in axial or diagonal directions) were catered for as a 'pattern'of one code, although 
in these cases the encoding was one character greater than that for the same line by encoding as a repeated 
code (no terminating symbol being used in the latter). Table II shows the three jobs run under the various 
systems, the time for the generation and encoding of the 203  lines was added to that for the subsequentdecoding 
 (typically< 1 second) in order to give an overall figure correspondingto line generation. All in­creases 
or decreases are with respect to the standard system using the unmodified Bresenham algorithm [3]. 
  It is clear that the encoding of repeated patterns gives even greater improvement in the compression 
of the total information for the graph than the encoding of repeated codes, and more importantly, gives 
a significant decrease (20-40%) in the overall central processor time needed to generate the lines 
for the graphs. The variation in this figure for the individual graphs examined (Table II) is clearly 
due to the extent to which the lines constituting the graph correspond to repeated patterns. For these 
three graphs the mean compression for repeated codes was 40% and for repeated patterns was 54%. Although.the 
compression for graph B was higher for repeated'codes than for repeated patterns, this is not particularly 
sig­ nificant. The information corresponding to the graphs in Figs. 8, 9 and 10 was encoded so that 
both repeated patterns and also repeated codes within them were catered for. This gave additional savings 
of 11%, 31% and 5% respectively,in the space required for the total information, compared to that required 
 for the encoding of repeated patterns only. This reduction therefore reflects the additional saving 
 brought about by encoding repeated codes. One further area examined was that of curve drawing. The 
analysis of the code information for a graph containing curves (Fig. 11) showed that (excludingthe 
drawing of the border) the compres­ sion of repeated codes (> 5 identical codes in sequence gave a saving 
of 19% in the total space occupied by the code information (17894 codes). This corresponds principallyto 
the drawing of the  204 curves. A more detailed analysis of 6058552 codes References corresponding 
to curve drawing information only, gave a saving of 17% by the compression of more than five repeated 
codes in sequence. The results of the analysis of the coding for Fig. 11 are therefore not unrepresentative 
of the general overall savings that can be made for curves.  4. Conclusions Line tracking by compressionof 
repeated patterns gives a significant compression of the informa­tion requiredfor the graph (-49%) for 
those cases using straight lines only, and more importantly, gives a significant decrease (~20-40%) 
in the overall central processor time needed to generate the lines. To use these algorithms for raster 
devices involves the utilisation of the movement sequence to select (andrecord) the next 'printingposition' 
(i.e. point on the raster). Alternatively,it may be possible to omit the matrix for the raster, and 
 across those pattern sequences relevant to the particular row of the raster being displayed. This 
would necessitate keeping a record of those lines (stored as pattern sequences) which inter­ sect a 
given row of the raster and their points of intersection, so that these positions can be accessed and 
displayed as the row is scanned. This process would be repeated for successive rows. These algorithms 
have been incorporatedinto a general purpose graphics system [5]. The algorithms presented in this 
paper can readily be extended to cater for incremental plotters with more than eight vector modes. 
 1. Boothroyd, J. Private Communication.  2. Boothroyd, J. and Hamilton, P.A. Exactly reversible plotter 
paths. Australian ComputerJournal, Vol. 2, No. 1 (1970), 20-21.  3. Bresenham,J. E. Algorithm for computer 
control of a digital plotter. IBM Systems Journal, Vol. 4, No. 1 (1965),  25-30.  4. Dijkstra, E.W. 
A Discipline of Programming. Prentice-Hall,EnglewoodCliffs, 1976.  5. Earnshaw, R.A. Graph Plotting 
in Algol 68-R. Software-Practiceand Experience, Vol. 6, No. 1 (1976), 51-60.  6. Knuth, D.E. The Art 
of ComputerProgramming- Vol. 2, SeminumericalAlgorithms, Addison Wesley Publishing Company, 1969, 293-338. 
 7. Pitteway, M.L.V. The impact of computer graphics. Nature, Vol. 235 (January 14, 1972), 83-85.  
8. Pitteway, M.L.V. Algorithm for drawing ellipses or hyperbolae with a digital plotter. Computer Journal, 
Vol. 10  (1967), 282-289.  9. Stein, J. J. Comp. Phys., Vol. 1 (1967), 397-405.  10. Stockton, F.G. 
Algorithm 162, Comm. ACM 6, 4 (1963).  11. Thompson, J.R. Straight lines and graph plotters. Computer 
Journal, Vol. 4, No. 3 (1964), 227.  205 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563895</article_id>
		<sort_key>206</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>37</seq_no>
		<title><![CDATA[Raster-scan hidden surface algorithm techniques]]></title>
		<page_from>206</page_from>
		<page_to>213</page_to>
		<doi_number>10.1145/563858.563895</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563895</url>
		<abstract>
			<par><![CDATA[Two new techniques are presented for reducing the number of depth calculations in hidden surface elimination. Two new algorithms using the techniques are compared with three existing algorithms and it is shown by examples that the new techniques reduce the number of multiplications involved in the depth calculations. A technique for increasing the parallelism of operations is also presented. This allows the calculation to be done more rapidly in hardware and is particularly useful for generating line drawings rather than the usual TV raster scan images in the common raster-scan hidden surface algorithms.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P330584</person_id>
				<author_profile_id><![CDATA[81100294055]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Griffith]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hamlin]]></last_name>
				<suffix><![CDATA[Jr.]]></suffix>
				<affiliation><![CDATA[ICASE, NASA Langley Research Center, Hampton, Va.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40029539</person_id>
				<author_profile_id><![CDATA[81332500218]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[William]]></middle_name>
				<last_name><![CDATA[Gear]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Science Department, University of Illinois, Urbana, Ill.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Sutherland, Ivan E., Robert F. Sproull, Robert A. Schumacker, "Sorting and the Hidden-Surface Problem", Proceedings National Computer Converence 1973, p. 685-693.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>362739</ref_obj_id>
				<ref_obj_pid>362736</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bouknight, W. J., "A Procedure for Generation of Three-Dimensional Half-Toned Computer Graphics Presentations", Communications of the ACM, (13,9), September, 1970, 527-536.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Romney, G. W., G. S. Watkins, D. C. Evans, "Real-Time Display of Computer Generated Half-Tone Perspective Pictures", IFIP, 1968, 973-978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Watkins, G. S., "A Real-Time Visible Surface Algorithm", Computer Science Department, University of Utah, UTECH-Csc-70-101, June 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Erdahl, Alan C., "Displaying Computer Generated Half-Tone Pictures in Real Time", Computer Science Department, University of Utah, RADC-TR-69-250, 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 RASTER-SCAN HIDDEN SURFACE ALGORITHM TECHNIQUES Griffith Hamlin, Jr. ICASE, NASA Langley Research Center, 
Hampton,Va. 23665 and C. William Gear Computer Science Department, University of Illinois, Urbana, Ill. 
 Two new techniques are presented for reducing the number of depth calculations in hidden surface elimination. 
Two new algorithms using the techniques are compared with three existing algorithms and it is shown by 
examples that the new techniques reduce the number of multiplications involved in the depth calculations. 
A technique for increasing the parallelismof operations is also presented. This allows the calculation 
to be done more rapidly in hardware and is particularly useful for generating line drawings rather than 
the usual TV raster scan images in the common raster-scan hidden surface algorithms. I. INTRODUCTION. 
Several hidden surface algorithms from the literature have been classified by Sutherland et  According 
to his classification scheme, the two algorithms described here belong with a group of three algorithms 
which are depth priority, point sampling algorithms which work with image space data. Like these other 
three algorithms[2,3,4], the algorithms described here produce a raster scan output in which the scene 
is scanned by a sequence of horizontal planes in order to generate the projection of the information 
in each plane onto the corresponding scan line as shown in FIGURE 1. Sutherland et al.[1] observed that 
all hidden surface algorithms exploit some form of coherence of the data as the basis for efficiently 
computing the rendering. All of the scan-line algorithms exploit scan-line coherence: the property that 
the set of edges intersected by two adjacent scan-lines is nearly the same. Scan-line algorithms also 
exploit point-to-point coherence along each scan-line: the property that the ordering in X and Z of edges 
on two adjacent scan lines are nearly the same. The difference between all these scan-line algorithms 
lies in the way each takes advantage of point-to-point coherence along each scan-line. The two algorithms 
described here exploit the fact that if it is assumed that polygons cannot intersect, then the relative 
depths cannot change, and the only times when it is necessary to perform new depth calculations are when 
the order in the list of active edges changes. The second algorithm presented here also uses a form of 
object coherence across edges to infer the visibility of a plane connected-at an edge to another plane 
whose visibility has already been computed.  This report was prepared as a result of work performed 
under NASA Contract Number NAS1-14101 while both authors were in residence at ICASE, NASA Langley Research 
Center, Hampton, Va. 23665 Permission to make digital or hard copies of part or all of this work or 
personal or classroom use is granted without fee provided that copies are not made or distributed for 
profit or commercial advantage and that copies bear this notice and the full citation on the first page. 
To copy otherwise, to 206 republish, to post on servers, or to redistribute to lists, requires prior 
specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California In all of the schemes 
to be discussed, the scene is composed of a number of plane convex polygons in three dimensions. The 
two new techniques described assume that these polygons are non-intersecting and do not overlap one another 
cyclically, although both techniques could be modified to compute intersections. The non-intersecting 
polygon assumption is reasonable in many environments. For example, the polygons might represent the 
surface of a solid body, such as an aircraft. Since two solid bodies cannot both occupy the same space, 
polygons on their surfaces could not intersect, although they might share sides in common. Many aircraft 
drawings used for all manner of aeronautical design and testing are examples of such drawings. They abound 
at the NASA Langley Research Center where these hidden surface algorithms were developed. The two new 
techniques introduced below use the following ideas: 1. In each scan line, a recursive method is used 
to process the polygons which insures that overlapping polygons are processed in order of the distance 
from the observer. Visible polygons are numbered in such a way that the relative depth of any two overlapping 
polygons will be remembered for all future scan lines. This stored relative depth information is the 
heart of this algorithm's exploitation of point-to-point coherence along each scan line.  2. When the 
order of the Active Edge List changes, the visibility of polygons after the change can often be deduced 
from the visibility before the change and an examination of the type of the edges involved in the change. 
All edges are classified as left or right depending on whether they are on the left or right side of 
a polygon as seen by the viewer. Edges which are both left and right are classified as middle edges. 
  These two techniques have been programmed, and the two algorithms are described below. Both techniques 
are useful for any scene described by planar convex polygons. The second appears to be superior when 
the scene is composed of curved surfaces approximated by adjoining planar polygons, such as descriptions 
of aircraft fuselages, wings, etc., used for structural and aerodynamic analysis as mentioned above. 
 The next section summarizes the processing common to all scan-linealgorithms studied. The following 
two sections describe the two algorithms in some detail. Section 5 discusses a technique for generating 
the raster output in parallel with visibility computations. The final section presents some experimental 
results which compare the operation counts for all scan-line algorithms studied for several scenes composed 
of from 41 to 480 polygons. 2. BASIC ALGORITHM FEATURES. The work is broken up into two stages: preprocessing 
and visibility computation. This not only allows for some parallelism, but also increases the possibility 
for incremental computation. All scan-line algorithms studied do the rotation (and perspective transformation 
if desired) in the preprocessing stage. This can be performed incrementally. Next they sort the vertices 
by the Y coordinates. A bucket sort is used here with a variable sized bucket for each scan-line. Next, 
all algorithms except the Watkins[4] algorithmcompute coefficients A, B, and C for each polygon so that 
the polygon lies in the plane Z=AX+BY+C. If the polygon is 'edge on' to the viewer, it is dropped from 
further consideration. These coefficients can also be computed incrementally. Another step in preprocessing 
involves computing the inverse of the slope of each polygon edge in the scene. This is computed as dx/dy 
which indicates the change in X in the movement from one scan line to the next. (Horizontal lines require 
some special handling dependent on the details of the algorithm implementation.) During the visibility 
computation, an Active Edge List of all edges intersected by the current scan line is maintained. This 
list is sorted in order of the X coordinates of the intersectionof the edges with the current scan line. 
When the scan line is advanced by increasing Y to the next higher value, these X values must be updated 
by adding dx/dy to them. This requires resorting the Active Edge List between the visibility processing 
of each scan-line. Since the Active Edge List is presumably almost sorted, a variant of the bubble sort 
provides a rapid method. Each algorithm studied performs visibility computations upon the Active Edge 
List in its own unique way.  3. DESCRIPTION OF ALGORITHM "STACK". Algorithm "STACK" employs the first 
technique to reduce depth calculations. As described in the previous section, the input polygons are 
sorted according to the first scan-line in which they appear and a sorted Active Edge List is maintained 
at each scan-line. When the end of the sorted polygon list is reached and the Active Edge List is empty, 
the algorithm terminates. Two entries are made in the Active Edge List for each polygon, corresponding 
to the two points at which the scan ray enters and exits the polygon as it scans the current scan line 
from left to right. Each entry consists of four values: the X coordinate of the edge at this scan line 
(X), the inverse of the slope of this edge (dx/dy), the Y value of the last scan line intersecting this 
edge (Yend), and the number of the associated polygon (P). Referring to FIGURE 2, the processing of 
an  individual scan line begins with the first (leftmost) edge in the Active Edge List. The polygon 
entered at this edge is declared to be the CURRENT polygon and procesing begins on it. To process a polygon 
means to scan the Active Edge List data which lies within the left and right boundaries of the polygon 
and determine when (if ever) the polygon becomes visible. This is done by using a pointer into the Active 
Edge List which keeps track of the position of the scan ray as it advances from edge to edge. The processing 
done at each edge falls into one of several cases which are describedbelow and specified in appendix 
A by a PL/I-like description of the STACK algorithm's scan line processing.  When the pointer encounters 
the right edge of the CURRENT polygon, processing is terminated on that polygon. At this time the algorithm 
saves with the CURRENT polygon the ordinal number representing when the CURRENT polygon was processed 
(i.e., three is saved if the CURRENT polygon is the third polygon on this scan line for which processing 
has been terminated). This number will called be the rank of the polygon. Since the algorithm causes 
the frontmost polygon of overlapping polygons to have its processing terminated first, the rank of two 
overlapping polygons may be used on the next scan line to indicate their relative depths. Ranks of 
two non-overlapping polygons are meaningless. Therefore, before using ranks, the algorithm checks the 
left and right X values of the edges of the polygon stored during processing of the previous scan line 
to insure that the two polygons overlapped. After ranking a polygon, the stack is popped and processing 
is resumed on the polygon saved at the top of the stack. It now becomes the CURRENT polygon. When this 
occurs the Active Edge List pointer jumps back to the position it had when the polygon was pushed onto 
the stack. This may cause the algorithm to deviate from a strict left to right processing order. The 
algorithm remembers the rightmost X-value for which output has been produced. If, after a pop of the 
stack, the Active Edge List pointer jumps to the left, no output is generated until it again reaches 
this rightmost value. If, before exiting the CURRENT polygon, the Active Edge List pointer encounters 
another polygon which hides the CURRENT polygon, processing of the CURRENT Polygon is suspended, the 
Active Edge List pointer is pushed onto a stack, and processing is started on the newly encountered polygon, 
which has become visible. If, before exiting the CURRENT POLYGON, the Active Edge List pointer encounters 
the right edge (exit) of a polygon, the algorithm marks that polygon. If that polygon is at all visible, 
it will have been pushed onto the stack. When it is later popped off the stack the mark will cause the 
 algorithm to immediately rank it and pop another polygon from the stack. If, on the other hand, the 
polygon is completely invisible, it will not have been pushed onto the stack. In this case the mark 
will have the effect of deleting the polygon from further processing on the current scan line. This eliminates 
some Z-depth calculations involving this polygon. Instead of ranking such invisible polygons, the algorithmsaves 
with each of them the number of the polygon that was visible when the invisible polygon was entered 
by the scan ray. This information may save Z-depth calculations on subsequent scan lines. 4. DESCRIPTION 
OF ALGORITHM "CROSS" Algorithm CROSS employs the second technique. In this algorithm the fundamental 
elements in the representationof the data are the vertices. Each vertex consists of its coordinates X, 
Y, and Z plus some pointer information generated in the algorithm. Edges consist of a pair of vertices 
plus information generated in the algorithm. Polygons consist of an (ordered) list of edges. The usual 
preliminary processing is used to compute the coefficients of the planes of the polygons, to order 
the vertices by their Y-values, and to construct lists of edges connected to each vertex. In this case, 
edges are said to begin on a vertex if their end with the lowest Y value is on that vertex. They end 
on the vertex with the highest Y value. Two lists are constructed for each vertex, a list of those 
edges ending on a vertex and a list of those beginning on a vertex. The list of beginning edges is 
ordered by the slope of the edges so that at higher Y values the edges will be in a left to right order. 
The list of ending edges is unordered. It is used to remove edges from the Active Edge List when the 
 vertex is encountered. This saves testing each active edge to see if it has ended.  4.1 EDGE CLASSIFICATION 
 Because edges can be 'shared' between two or more polygons, it is possible for an edge be to the left 
or right edge of more than one polygon. However, it is convenient if we associate a unique left and-right 
polygon with each edge. Therefore, the algorithm creates enough copies of edges so that no edge is 
a left or right edge of more than one polygon. It is also necessary to avoid making more than one copy 
of an edge a 'middle' edge (because the non intersectinghypothesis could be violated). During part 
of the preprocessing, the edges are classified as L, M or R and copies are created if necessary. At 
the same time, a pair of pointers is created for each edge indicating its unique left and right polygons. 
At this time, the left polygon of a left edge is null, and similarly for the right polygon of a right 
edge. During the scanning, these unused positions will be used for storing pointers to the next visible 
polygons when the edge is active and visible. Thus, for any active visible edge, the left pointer will 
always contain the polygon on the left which is visible, and similarly for the right pointer. When 
an edge is put in the Active Edge List, pointers are stored with the polygon so that any polygon under 
the scan line has pointers to its  208 left and right edges. (This is the reason for the restriction 
to convex polygons.) The X position of each edge is recorded in the Active Edge List, along with the 
edge type (L, M, or R), its visibility (V=visible, I=invisible) and pointers to the left and right polygons 
mentioned above. The list must be updated each time a vertex is encountered or two active edges cross. 
 A Crossing List, sorted by Y-value, is maintained to describe the crossings of two adjacent Active Edges. 
It contains an entry for each pair of edges in the Active Edge List that cross unless those edges are 
incident on the same vertex or part of the same polygon. The Crossing List must be updated each time 
the Active Edge list is changed.  4.2 VERTEX PROCESSING When a vertex is encountered all edges ending 
on the vertex are removed. The vertex can be marked visible if any of these edges are visible, otherwise 
it is invisible. Its position in the Active Edge List is given by the position of the removed edges. 
If there are no edges to remove, the visibility of the vertex and its position in the active edge must 
be calculated. Its position is determined by searching through the active edge list sequentially. Its 
visibility is determined by computing the depth of the visible polygon at that point. (This polygon is 
known by looking to the left or right in the list.) Next, all edges begining at the vertex are  added 
to the Active Edge List and the crossing points to their left and right are calculated and added to the 
Crossing List if necessary. If the vertex is invisible, there is nothing else to do. If it is visible, 
the visibility of each new edge must be computed. This is necessary because several polygons could start 
from a vertex, and these could obscure some of the edges. The visibility is determined by comparing the 
edge depth with the depth of the currently visible polygon on the left. If the visible polygon does not 
pass through the vertex under consideration, this requires a straightforwarddepth calculation and comparison. 
If the polygon does pass through the vertex, the comparison is done using the coefficients of the polygons 
and the slope of the added edge. Anytime a middle edge is added its visibility is determined by seeing 
if its left polygon is the currently visible polygon. In addition,when a visible right edge is added, 
a search must be made to find the next visible polygon on the right. This is done using the search described 
in the next section, except when this is the last edge from the vertex. In that case, the next visible 
polygon can be determined by looking to the right in the Active Edge List.  4.3 CROSSING ANALYSIS The 
principal feature of the visibility computation is the classification of crossing types. Each active 
edge is in one of the six states LV, MV, RV, LI, MI, or RI. This gives a total of 36 possibilities for 
the crossing of a pair of adjacent edges. These are shown in Table I below. (The first edge is the edge 
with the smaller X value.) A pair of edges that cross are handled by switching their positions in the 
active edge list and then executing the action described in TABLE I below. For example, when an RV edge 
crosses an MV edge, the edges switch and the middle edge becomes invisible. The only other action needed 
is to update the right polygon pointer of the RV edge. Its new value is the right polygon pointer of 
the middle edge.  Blank entries indicate no action, otherwise: -Make first edge invisible  -Make second 
edge invisible C1 -If the second edge is in front of the polygon visible to the left of the first edge, 
make second edge visible. (Cases a, b, and c are  distinguished later). C2 -Compares the depths of 
the polygons to the left and right of the first and second edges respectively. The one with the forward 
 polygon remains visible. C3 -The same as C1 with first and second, and left and right interchanged. 
E -'Error' condition because the edges belong to the same polygon. The crossing can be ignored. TABLE 
I  The left polygon pointer of a left edge that is visible after the crossing calculation (and similarly 
for right edges) may have to be updated. In all but two cases, the pointer is available in the other 
edge. In these two cases,  and C3c it is necessary to search to find the polygon that is now visible 
between the two edges. This search is done by processing the active edge from left to right looking for 
the edge under consideration while recording entries and exits from polygons. When the edge under consideration 
is reached, it is known which polygons span the intersection point. Their depths must be calculated, 
and the most forward chosen as the new visible polygon. Thus, of the 32 cases that can occur in TABLE 
I, 21 of them require no action, four of them require a simple change of visibility and the changing 
of a pointer, and seven cases require a depth comparison of two polygons. In addition, two of the last 
seven cases require a search and possibly several depth calculations in those cases that the visibility 
changes.  4.4 PREPROCESSING In addition to the preprocessing described in section 2, this algorithm 
must do the following: Edge Process Each edge is examined. Its end points are placed in ascending order 
and a pair of chains is constructed from each vertex through the edges so that from each vertex it is 
possible to find the set of edges that end on the vertex and the set of edges that start on the vertex. 
The set of edges that start on the vertex are sorted in ascending order of their slopes so that they 
will be in the correct left to right order in the Active Edge List when they are entered there. Polygon 
Edge Label CoefficientsA, B, and C of the plane of each polygon are found by solving a system of three 
linear equations derived from three adjacent vertices on the polygon. The determinent of this system 
(which is available as a byproduct) indicates whether the polygon is being processed in the clockwise 
or counter-clockwisedirection. This information is used in two ways. The first is an option to ignore 
rear polygons. If this option is used, polygons must be specified in clockwise order when viewed from 
the exterior of the body. A counter-clockwiseprojection in the X-Y plane indicates that the polygon should 
be dropped. If the polygon is not dropped, its edges are examined in sequence. The combination of the 
direction of rotation and the direction of the edge (up or down) indicates whether the edge is a left 
or right edge. It is marked accordingly in the list of edges, and the 'name' of the polygon on the left 
or right of the edge is stored in the edge list. If the edge is already marked as being of the same type, 
a duplicate edge is created. The edge of the rear polygon is saved as the duplicate edge (which is distinguishable 
in the edge list), so that the picture generation can simply ignore visibility tests on duplicate polygons. 
The front edge is easily found by finding the edge attached to the polygon with the largest value of 
the parameter A in the case of left edges, or the smallest value in the case of right edges. If the edge 
has been marked as of the other type (e.g. R when the new type is L) it is simply marked as M. 5. PARALLEL 
GENERATION OF RASTER AND LINE DRAWING TECHNIQUE. Since there is no visibility change from One scan line 
to the next until a new vertex is encountered or until two edges in the Active Edge List change places, 
the Active Edge List can be updated from one scan line to the next by additions only. There is no need 
to test for changes of position. Indeed, there is no need to generate the state of the Active Edge List 
for each scan line, only for those on which a change occurs. The Y value of the next change can be found 
from the minimum in the Crossing List and the next entry on the sorted vertex list generated in preprocessing. 
It was found that the amount of arithmetic involved in computing the intersections was less than the 
amount of work involved in additions and tests used to generate successive scan line Active Edge Lists. 
In this technique, a separate processor can be generating the state of the Active Edge List for each 
scan line by additions and generating the raster output. Such a display generator was described by Erdahl[5] 
in 1972. It appears that algorithm CROSS produces the proper type of input required by Erdahl's display 
processor, i.e., a sequence of visible edge segments sorted by the initial scan line on which they appear 
and then sorted by the X-values of the intersection with the scan line. The visibility computation can 
proceed by advancing to the Y value of the next change. As implemented, even the X values of the active 
edge were not updated except when there was a change of visibility. This was partly in order to allow 
line drawings to be generated easily, but also because it was found that the X coordinates of active 
edges were not needed very often, so that the additional work in calculating intersections from the data 
available was more than offset by the reduction in the number of times that the calculation of the X 
value had to be made. Each active edge contained its last calculated X value and the corresponding Y 
value in the implementation. 6. COMPARISON OF SEVERAL ALGORITHMS The two algorithms described here, 
along with three other scan-line algorithms [2,3,4] were implemented in FORTRAN on a PRIME-300 minicomputer. 
Each of these implementations counted the number of tests, stored data accesses, multiplications or divisions, 
and additions required by that part of the calculation unique to each algorithm. The counts do not include 
preprocessing and other calculations done the same way by all scan line algorithms. TABLE II gives the 
operation counts for four pictures representativeof those tested. These four are shown in Appendix C. 
The counts included all processing done on each individual scan line (the unique part of all of these 
algorithms), the processing done in keeping the Active Edge List sorted in left-to-right order, and the 
preprocessing done in calculating the coefficients of the plane of each polygon. The counts do not include 
other preprocessing done in reading the input polygons or sorting them in order of the Y coordinate 
of their topmost vertex. This Y-sort is performedby all algorithms tested and so could be omitted from 
the counts. Also, the updating of the X values in the Active Edge List after processing each scan line 
was done by all algorithms and so was not counted. In assigning counts to each portion of each algorithm 
it was assumed that a moderate amount of data could be placed temporarily in registers with essentially 
 instantaneous access. For this reason no storage accesses are included for incrementing indices and 
 other control pointers. In assigning additions and multiplications,no additions to program loop counters 
or other such programming functions were included. Such operations are very much implementation dependent, 
not an integral part of the algorithm, and so were omitted entirely. Some of the algorithms studied 
can handle more general input data, e.g. concave and intersecting polygons. This adds some complexity 
to these algorithms not present in the two algorithms described here. -In an attempt to collect data 
on the various algorithms that could be more meaningfullycompared, our implementations of these algorithms 
removed such complexities and restricted the input data to convex non-intersecting polygons in all cases. 
On all but the Watkins algorithm this simply removed a  210 special case needed for intersecting polygons. 
In the Watkins algorithm, it eliminated one of three possible outcomes of looking at overlapping polygon 
segments on a sample span. Also, the Watkins algorithm wae designed to accept input vertices with a precision 
greater than one raster point and this fact is used in tests to determine when two polygons overlap. 
Our input data contained vertices that were rounded off to the nearest raster point. This sometimes caused 
the Watkins algorithm to think that two adjacent polygons overlapped (by one raster unit), causing some 
extra calculations.  6.1 Operation Counts. The preprocessing calculations consist of calculating plane 
equations of each polygon and Y-sorting the polygons. The plane equations of the polygons are calculated 
in the form Z=AX+BY+C by all algorithms except the Watkins algorithm. If N is the number of polygons, 
then our gaussian elimination implementation of this calculation added 17N multiplications, 11N additions, 
3N tests, and 9N memory references to the operation counts given in TABLE II. The Watkins algorithm keeps 
the Z value of each edge of each polygon at each scan line. This means that a dz/dy value must be added 
to these Z values before processing each scan line. The Z value of any polygon at any X position along 
a scan line is calculated when needed as a linear interpolation of the Z values at the left and right 
edges of the polygon. Each Z value is initially set to the Z coordinate of one endpoint. All processing 
done the same way by all algorithms tested was not counted in the data of TABLE II. This common processing 
consisted of: 1. The Y-sort of the input polygons.  2. Adding polygon edges to the Active Edge List 
from the top of the Y-sorted polygon list at each scan line.  3. Updating X by dx/dy for each entry 
in the Active Edge List at every scan line.  Sorting the Active Edge List on the X coordinate of each 
edge was done by all algorithms, but it was done a bit differently by algorithm "CROSS" due to its different 
data representationof image data. Thus this sort was counted in the data of TABLE II. All algorithms 
used a bubble sort. The scan line processing done by each algorithm is quite dependent upon how the 
polygons in the data overlap each other. This makes the number of operations hard to compute precisely, 
even just to the highest order. For algorithm "STACK" the number of each type of operation required by 
the various stages of this processing is given as comments in the PL/I-like description of the algorithm 
in Appendix A. For an image with N polygons, each of which intersects an average of K scan lines, the 
main DO loop of appendix A will be executed approximately 2NK times per image. Most of the arithmetic 
(and all of the multiplicationsand divisions) is done when calculating relative depths of pairs of polygons. 
This calculation is done only once for each unique pair of overlapping polygons in which one polygon 
 is visible. We observed in our images that the number of depth calculations was between 2N and 3.5N 
(3.3N average). This agrees with statistics of Watkins[4] showing that at any (X,Y) position there are 
usually no more than 2 or 3 overlapping polygons. For algorithm CROSS, if we assume that the scene is 
composed of M "sheets" of joined quadrilaterals,where each sheet contains n**2 quadrilaterals, then we 
have about (n**2)M vertices, 2(n**2)M edges, and (n**2)Mpolygons. If the sheets are behind one another 
rather than visibly disjoint, the worst case occurs, and CROSS is called about 2(n**2)(M**2) times because 
each edge intersects about M other edges. This figure could be doubled in an extreme case. For this example, 
the number of crossing computations (to determine the Y value for entry in the crossing list) is also 
about 2(n**2)(M**2). These account for the bulk of the arithmetic operations, taking 5 multiplications, 
1 division, and 6 additions. If we take M to be n (that is, the figure has order of (n**3)=N edges, vertices, 
and polygons distributed in three dimensions, we see that the speed is proportional to n**4 or N**(4/3). 
 For all pictures combined, the two algorithms described here performed fewer multiplicationsand additions 
than any of the three algorithms obtained from the literature. In the case of algorithm STACK, this was 
sometimes accomplished at the expense of increased testing of previously stored data. Algorithm CROSS 
can be used for raster or line drawings, and makes efficient use of connectivity information. Consequently 
it appears to be faster than many other techniques. However, it uses considerably more storage than other 
techniques because of the large number of pointers. (The present implementation uses about 40 16-bit 
integers and 12 32-bit floating point values per 4-sided polygon. However, it is an experimental version 
with an unnecessary number of pointers to allow any variation to be tried. A better implementation could 
reduce this to approximately 22 16-bit integers and 9 32-bit floating point values per 4-sided polygon.) 
 AlgorithmMemory Tests Mult/Div Additions CONE PICTURE-331 Polygons STACK 259686 131112 9783 23752 CROSS 
79723 22680 5639 8753 Bouknight 242524 85682 48787 61471 Romney 261167 91720 36233 48917 Watkins 345671 
262095 54599 130615 CYLINDERPICTURE-235 Polygons STACK 298237 156147 7767 23913 CROSS 86229 22090 4000 
11950 Bouknight 273648 95549 55295 71173 Romney 291893 99956 36569 52447 Watkins 382588 308619 72607 
169599 BOTTLE PICTURE-41 Polygons STACK. 70503 36788 1289 5459  212  References  [1] Sutherland, 
Ivan E., Robert F. Sproull, Robert A. Schumacker, "Sorting and the Hidden-Surface Problem", Proceedings 
 National Computer Converence 1973, p. 685-693. [2] Bouknight, W.J., "A Procedure for Generation of 
Three-DimensionalHalf-Toned Computer Graphics Presentations",Communications of the ACM, (13,9), September, 
1970, 527-536. [3] Romney, G.W., G.S. Watkins, D.C. Evans, "Real-Time Display of Computer Generated 
Half-Tone Perspective Pictures", IFIP, 1968, 973-978. [4] Watkins, G.S., "A Real-Time Visible Surface 
Algorithm", Computer Science Department, University of Utah, UTECH-Csc-70-101, June 1970. [5] Erdahl, 
Alan C., "Displaying Computer Generated Half-Tone Pictures in Real Time", Computer Science Department, 
University of Utah, RADC-TR-69-250, 1972.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563896</article_id>
		<sort_key>214</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>38</seq_no>
		<title><![CDATA[Hidden surface removal using polygon area sorting]]></title>
		<page_from>214</page_from>
		<page_to>222</page_to>
		<doi_number>10.1145/563858.563896</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563896</url>
		<abstract>
			<par><![CDATA[A polygon hidden surface and hidden line removal algorithm is presented. The algorithm recursively subdivides the image into polygon shaped windows until the depth order within the window is found. Accuracy of the input data is preserved.The approach is based on a two-dimensional polygon clipper which is sufficiently general to clip a concave polygon with holes to the borders of a concave polygon with holes.A major advantage of the algorithm is that the polygon form of the output is the same as the polygon form of the input. This allows entering previously calculated images to the system for further processing. Shadow casting may then be performed by first producing a hidden surface removed view from the vantage point of the light source and then resubmitting these tagged polygons for hidden surface removal from the position of the observer. Planar surface detail also becomes easy to represent without increasing the complexity of the hidden surface problem. Translucency is also possible.Calculation times are primarily related to the visible complexity of the final image, but can range from a linear to an exponential relationship with the number of input polygons depending on the particular environment portrayed. To avoid excessive computation time, the implementation uses a screen area subdivision preprocessor to create several windows, each containing a specified number of polygons. The hidden surface algorithm is applied to each of these windows separately. This technique avoids the difficulties of subdividing by screen area down to the screen resolution level while maintaining the advantages of the polygon area sort method.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[graphics]]></kw>
			<kw><![CDATA[hidden line removal]]></kw>
			<kw><![CDATA[hidden surface removal]]></kw>
			<kw><![CDATA[polygon area sorting]]></kw>
			<kw><![CDATA[polygon clipping]]></kw>
			<kw><![CDATA[shadowing]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P161253</person_id>
				<author_profile_id><![CDATA[81100217340]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kevin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Weiler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell University, Ithaca, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P332877</person_id>
				<author_profile_id><![CDATA[81100484386]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Atherton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell University, Ithaca, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>806007</ref_obj_id>
				<ref_obj_pid>800196</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Appel, A., "The Notion of Quantitative invisibility and the Machine Rendering of Solids", Proceedings ACM National Conference (1967), pp. 387-393.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Atherton, Peter R., "Polygon Shadow Generation", M. S. Thesis, Cornell University, Ithaca, N. Y. (1977), (forthcoming).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>362739</ref_obj_id>
				<ref_obj_pid>362736</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bouknight, W. J., "A Procedure for Generation of Three Dimensional Half-toned Computer Graphics Representations", Comm. ACM, 13, 9 (Sept. 1970) pp. 527-536.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>362921</ref_obj_id>
				<ref_obj_pid>362912</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Galimberti, R., and Montanari, U., "An Algorithm for Hidden-Line Elimination", Comm. ACM, 12, 4, (April 1969), pp. 206-211.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563875</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Greenberg, Donald P., "An Interdisciplinary Laboratory for Graphics Research and Applications", Proceedings of the Fourth Annual Conference on Computer Graphics, Interactive Techniques and Image Processing - SIGGRAPH, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Myers, A. J., "An Efficient Visible Surface Program", CGRG, Ohio State U., (July 1975).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569954</ref_obj_id>
				<ref_obj_pid>800193</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Newell, M. E., Newell, R. G. and Sancha, T. L., "A Solution to the Hidden Surface Problem", Proceedings ACM National Conference, (1972), pp. 443-450.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Roberts, L. G., "Machine Perception of Three-Dimensional Solids", MIT Lincoln Laboratory, TR 315, (May 1963).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Schumacher, R. A., Brand, B., Gilliand, M. and Sharp, W., "Study for Applying Computer Generated Images to Visual Simulation", AFHRL-TR-69-14, U. S. Air Force Human Resources Laboratory, (Sept. 1969).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360802</ref_obj_id>
				<ref_obj_pid>360767</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. E., and Hodgman, G. W., "Reentrant Polygon Clipping", Communications of the ACM, Vol. 17, No. 1, (Jan. 1974), pp. 32-42.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. E., Sproull, R. F., and Schumacker, R. A., "A Characterization of Ten Hidden Surface Algorithms", ACM Computing Surveys, Vol. 6, No. 1, (Mar. 1974), pp. 1-55.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Warnock, J. E., "A Hidden Surface Algorithm for Computer Generated Halftone Pictures", Dept. Comp. Sci., U. of Utah, (1969).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Watkins, G. S., "A Real-Time Visible Surface Algorithm", Comp. Sci, Dept., U. of Utah, UTECH-CSC-70-101, (June 1975).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Weiler, Kevin J., "Hidden Surface Removal Using Polygon Area Sorting", M. S. Thesis, Cornell University, Ithaca, N. Y. (1977), (forthcoming).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 HIDDEN SURFACE REMOVAL USING POLYGON AREA SORTING by Kevin Weiler and Peter Atherton Program of Computer 
Graphics Cornell University Ithaca, New York 14853 ABSTRACT A polygon hidden surface and hidden line 
removal algorithm is presented. The algorithmrecursively subdivides the image into polygon shaped windows 
until the depth order within the window is found. Accur­acy of the input data is preserved. The approach 
is based on a two-dimensionalpolygon clipper which is sufficiently general to clip a concave polygon 
with holes to the borders of a concave polygon with holes. A major advantage of the algorithm is that 
the polygon form of the output is the same as the polygon form of the input. This allows entering previously 
calculated images to the system for further processing. Shadow casting may then be performed by first 
producing a hidden surface removed view from the vantage point of the light source and then resubmitting 
these tagged polygons for hidden surface removal from the position of the observer. Planar surface detail 
also becomes easy to represent without increasing the complexity of the hidden surface problem. Translucency 
is also possible. Calculation times are primarily related to the visible complexity of the final image, 
but can range from a linear to an exponential relationshipwith the number of input polygons depending 
on the particular environment portrayed. To avoid excessive computation time, the implementation uses 
a screen area sub­division preprocessor to create several windows, each containing a specified number 
of polygons. The hidden surface algorithm is applied to each of these windows separately. This technique 
avoids the diffi­culties of subdividing by screen area down to the screen resolution level while maintaining 
the advantages of the polygon area sort method. COMPUTING REVIEWS CLASSIFICATION: 3.2, 4.9, 4.40, 4.41 
 KEYWORDS: Hidden Surface Removal, Hidden Line Removal, Polygon Clipping, Polygon Area Sorting, Shadowing, 
Graphics INTRODUCTION A new method for the computation of visible Many visible surface algorithms have 
been surfaces for environments composed of polygons developed, each with unique characteristicsand is 
presented. The output of the method is in capabilities. A survey presented by Sutherland the form of 
polygons, making it useful in a var­ et al [11] provides a method of categorization iety of situations 
including the usual display as well as a statistical comparison of many of applications. The primary 
components of the the polygon based algorithms. method consist of a generalized algorithm for Their classification 
divides the algorithms polygon clipping and a hidden surface removal into three types: object space, 
image space and algorithm. The polygon clipper is sufficiently list-priority algorithms. The "object 
space" general to clip a concave polygon with holes to methods perform the hidden surface computations 
the area of a concave polygon with holes. The for potentially visible polygons within the hidden surface 
algorithm operates on polygon environment to an arbitrary precision usually input which has already been 
transformed and limited only by machine precision. The "image clipped to the final viewing space. The 
X and space" methods are performed to less resolution Y axis of this viewing space are thus parallel 
and determine what is visible within a prescribed to the display surface and the Z axis is parallel area 
on the output display, usually a raster dot. to the line of sight. The "list-priority"algorithms work 
partially in each of these two domains. Permission to make digital or hard copies of part or all of this 
work or personal or classroom use is granted without fee provided that copies are not made or distributed 
for profit or commercial advantage and that copies bear this notice and the full citation on the first 
page. To copy otherwise, to 214 republish, to post on servers, or to redistribute to lists, requires 
prior specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California The performance 
of "object space" methods (Roberts [8], Appel [1], Galimberti [4]) and "list­priority" methods (Newell, 
Newell and Sancha [7], Schumacher [9]) is dependent on the complexity of the environment. Since all of 
these algorithms make comparisons between items (objects, polygons, edges), the number of sorting steps 
required can rise exponentially with the number of input items. However, the computational time is independent 
of the resolution or size of the image. In contrast, the "image-space" algorithms make polygon to screen 
area comparisons (Warnock [12], Watkins [13], Bouknight [3], and depth map or Z-buffer algorithms). Therefore, 
the number of sorting steps is possibly linear with the num­ber of input polygons, but can vary exponentially 
with the resolution required. The algorithm presented qualifies as an ob­ject space algorithm since all 
of its calculations are performed to arbitrary precision. The sorting methods used include a preliminary 
partial depth sort, an x-y polygon sort, and a conclusive depth sort which may involve recursive subdivision 
of the original area. The algorithm probably most closely resembles the Warnock (image space) algorithm 
in its method of operation. The major difference between them is that the Warnock algorithm performs 
the x-y sort by screen area, while the new algorithm does the x-y sort by polygon area. Polygon area 
coherence across the surface of the polygon is preserved as much as possible thereby reducing the number 
of lateral sorts required. Both algorithms use the techniques of recursive sub­division when necessary. 
The Warnock algorithm will subdivide until a solution or a preset resolution level has been reached. 
The new algorithm continues to subdivide only until the proper depth order has been established. Computation 
times of the new algorithm vary with both environmental complexity and the visible complexity of the 
image, and partially depend on the validity of the initial depth sort. For an environment consisting 
of a number of polygons entirely obscured by a single forward polygon, with a correct initial depth sort, 
the number of lateral comparisons required is linearly related to the number of input polygons. For environ­ments 
where every polygon may be partially ob­scured, but is visible as one piece, the number of lateral comparisons 
is related to one half the square of the number of input polygons. If few polygons are entirely obscured 
and many are split into several visible pieces, the relation­ship to the number of input polygons can 
be worse than n2. In practice, the relationship is usually better. Additions to the algorithm as described 
later may be used to limit the effects of exponential growth rates. The characteristics of the algorithm 
allow several options not always available in existing approaches. Of particular importance is the capability 
for generating perspective images with shadows. Translucency and surface detailing are also possible. 
 Because the output of the algorithm is in the form of polygons as opposed to a raster for­mat, and because 
the output data does not overlay itself on the image plane, the algorithm effec­tively solves for hidden 
lines as well as hidden surfaces. Additional line visibility information can also be stored to enhance 
CRT displays by eliminating double brightness lines. HIDDEN SURFACE ALGORITHM In general, the algorithm 
selects a polygon shaped area in the x-y plane from the vantage point of the observer and solves the 
hidden sur­face problem in that area completely before going on to any other area. This area may itself 
be subdivided recursively if there is an error in the initial depth sort. Output from the algorithm never 
overlaps on the x-y plane since each visible area has had all polygons behind it removed. The algorithm 
proceeds from front to back across the transformed object space, producing portions of the final image 
along the way and temporarily reversing direction only when an initial depth sort error is detected. 
The hidden surface algorithm involves four steps: a) a preliminary rough depth sort, b) an x-y polygon 
area sort to the area of the currently most forward polygon, c) a depth sort by removal of polygons behind 
the current forward polygon, and d) a conclusive depth sort by recursive subdivision when necessary. 
The initial sorting step attempts to place the list of input polygons into a rough depth priority order, 
from those closest to the ob­server to those furthest away. Any reasonable criterion for a sorting key, 
such as ordering on the nearest Z value of each polygon, is acceptable. This step is not mandatory but 
greatly increases the efficiency of the algorithm in later stages. The initial depth sorting operation 
is only performed once at the beginning of processing and is not repeated. The first polygon on the 
sorted input list is then used to clip the remainder of the list into new lists of polygons inside and 
outside of the clip polygon (Figure 2). In essence, this x-y clipping subdivision is equivalent to lateral 
area sorting. The process now examines the inside list and removes any polygons located behind the current 
clip polygon since they are hidden from view. Next, if any remaining polygons on the inside list are 
located in front of the clip polygon, an error in the initial depth sort has been discovered and the 
algorithm recur­ sively subdivides the region of interest by repeating the clipping process with the 
offending polygon as the clip polygon and the current inside list as the input list (Figure 3). Finally, 
when the recursive subdivisionhas been completed, the inside list is displayed and the algorithm repeats 
the entire process using the outside list as input. The process is continued until the outside list 
is exhausted. It is important to note that the clip poly­gon actually used as the clipping template 
is a copy of the original polygon rather than several pieces of its remainder. While keeping a copy of 
the original increases the storage require­ments, the number of clipping edges and the num­ber of clips 
to perform can be minimized. In this way computation time can be substantially reduced. After obscured 
polygons have been removed and before recursive subdivision, a check must be made for the case of cyclic 
overlap where a single polygon lies both in front of and behind a polygon (Figure 4a). A stack is kept 
of poly­ gon names which have been used as clipping poly­gons for this screen area, but have not finished 
processing because of recursive subdivision. If the algorithm is ready to make a recursive sub­division 
because a polygon is in front of the current clip polygon, a check is made to see if the name of that 
polygon is on the stack. If it is, a case of cyclic overlap exists and no addi­ tional recursion is 
necessary since all material behind that polygon has already been removed. This cyclic overlap condition 
occurs as a result of clipping to the original copy of polygons instead of their remainders. The reduction 
in the number of clips required outweighs the dis­advantage of the simple check required for cyclic overlap. 
Note that another case of cyclic over­lap involving several polygons is implicitly handled by the algorithm 
(Figure 4b).  POLYGON CLIPPING ALGORITHM Two dimensional polygon clipping is central to the hidden 
surface removal approach presented. If only convex polygons were allowed in a scene, clipping a scene 
by the convex areas of the polygons could quickly yield non-convex areas and holes (Figure 2). Thus even 
for a restricted environment, a polygon clipper capable of hand­ling concave polygons with holes is necessary. 
 A clipping algorithm capable of clipping concave polygons with holes to the inside portion of a convex 
area has been described by Sutherland and Hodgman [10]. The algorithm has the merit of simplicity and 
is particularly useful for screen subdivision and viewbox clipping. A modified version of this algorithmwould 
clip polygons to a plane and create output polygons on each side of the clipping plane. This version 
could be used to clip to the borders of a convex polygon yielding intact inside and outside polygons 
if the planar clip was applied against each edge of the convex clipping polygon. The entire exterior 
space would then be clipped by infinite planes; however, the effects of each border clip would not be 
localized and many new exterior polygons would be created. Since this is undesirable in a situ­ation 
where computational complexity may increase greatly with the number of polygons, another method of clipping 
has been developed which mini­mizes the number of polygons created during the clipping process (Figure 
5) [14]. The polygon clipper presented is a general­ized x-y polygon clipper which is capable of clipping 
a concave polygon with holes to the borders of concave polygons with holes. Clipping is performed to 
the borders of the clip polygon. The polygon which is clipped is the subject polygon. Any new borders 
created by the clipping of the subject polygon to the area of the clip poly­gon need only be identical 
to portions of the borders of the clip polygon. Using this concept, no new edges not already present 
in either the clip or subject polygon need be introduced and the number of output polygons from the process 
can be minimized. While the clip is a two­dimensional clip, depth information can be pre­served in all 
output for use by hidden surface calculations. The creation of new polygons due to inter­sections of 
the boundaries of the clip and sub­ject polygons is performed by partial transver­sals of both boundaries. 
If the outside borders of the subject polygon are followed in a clock­wise direction, the borders of 
the newly clipped output polygons can be found by making a right turn at each place the two polygons 
intersect. The process continues until the starting point is arrived at again (Figure 6). The inner or 
hole borders of the subject polygon must be followed in a counter-clockwisemanner in order to use this 
right turn rule. Note that the borders of the clip polygon used to complete the new polygons must be 
traversed twice, once in each direction. Additional techniques are necessary to deal with cases where 
the borders of the clip polygon do not intersect with borders of the subject poly­gon but lie completely 
inside the area of the subject polygon.  217  A more detailed description of the clipper follows: 
A polygon is defined as an area enclosed by a series of edges consisting of straight lines. These edges 
may touch upon one another at single non-contiguous points. There are no intrinsic limits as to the number 
of edges or holes a poly­gon may have. Contours are the edges or bound­aries of a polygon. The term main 
contour refers to the exterior boundaries of a polygon, while hole contour refers to the interior boundaries 
of a polygon. The algorithm represents a polygon as a circular list of vertices, one list for the main 
contour and one list for each of the holes. The vertices of the main contour are linked in clockwise 
order and the holes in counter-clockwise order. Using this order, as one follows along the chain of vertices 
of a polygon, the outside is always to the left while the interior of the polygon is always to the right 
(Figure 7). The clip polygon remains the same after the clipping process as before. The subject polygon 
may be fragmented by the clipping process. The results of the clipping process are two lists of polygons, 
one of polygons inside the clip polygon area and one of polygons outside the clip polygon (Figure 2). 
The clipping process is as follows: 1. The borders of the two polygons are compared for intersections. 
At each intersection a new false vertex is added into the contour chain of each of the two polygons. 
The new ver­tices are tagged to indicate they are intersec­tion vertices. A link is established between 
each pair of new vertices, permitting travel between two polygons wherever they intersect on the x-y 
plane. If care is taken in placement of intersections where the subject and clip polygon contours are 
identical in the x-y plane, no degenerate polygons will be produced by the clipping process. 2. Contours 
which have no intersections are now processed. Each contour of the subject polygon which has no intersections 
is placed on one of two holding lists. One holding list is for contours inside of the clip polygon; the 
other is for contours outside of it. Clip poly­gon contours outside of the subject polygon are ignored. 
Clip polygon contours inside of the subject polygon in effect cut a hole in the sub­ject polygon, producing 
two new contours. In this case two copies of the clip polygon contour are made (one in reverse order); 
one copy is placed on each of the holding lists.  3. Two lists of intersection vertices found on all 
of the subject polygon contours are formed. The first list contains only those intersections where the 
clip polygon border passes to the outside of the subject polygon (from the point of view of the subject 
polygon this occurs whenever the clip polygon passes to the left) (Figure 7). The second list contains 
those intersections where the clip polygon bor­  der passes to the inside (to the right). These two 
types of intersections will be found to alternate along any given contour and the number of intersections 
will always be even. This means only one determination of intersection type is necessary per contour. 
 4. The actual clipping is now performed (Figure 8): a) An intersection vertex is removed from the first 
intersection list to be used as a starting point. If the list is exhausted, the clipping is complete; 
Go to step 5. b) Follow along the subject polygon vertex chain until the next intersectionis reached. 
 c) Jump to the clip polygon. d) Copy the chain of polygon vertices until the next intersectionvertex 
is reached. e) Jump back to the subject polygon. f) Repeat steps "b" to "e" until the starting point 
has been reached. At this point the contour of a new inside polygon has just been closed. The outside 
polygons can be created by a second pass if the contour vertex chain is double­linked (bi-directional). 
This is accomplished by starting at intersectionvertices from the second intersection vertex list and 
following the reverse links during traversal of the clip polygon. Otherwise the contours of the outside 
polygons must be closed during the first pass. This can be done by making a second copy of the vertex 
chain during the clip polygon traversal (step 4d) in reverse order and attaching its "loose" ends to 
the unused intersection points at its begin and end locations. A second pass is still needed to find 
out where these outside contours are. All polygons created are placed on the proper holding lists.  
5. All holes on the holding lists are attached to the proper main contours. There are several methods 
of determining which polygons are hole contours. The conceptually simplest method is to test directionalityof 
the contours since main contours will always be clockwise and hole contours will always be counterclockwise. 
A more efficient method is based on using the highest of a precedence of types of intersections located 
on a contour. The types used in this precedence are related to the cause of the inter­section, such as 
a main contour intersecting a hole contour, a hole contour intersecting a hole contour, etc. The clipping 
process is now complete. EXTENSIONS Several extensions to the hidden surface algorithm allow greater 
versatility and effi­ciency. Of those described below, surface detail, shadowing, and screen subdivision 
have been implemented. Surface Detail Polygons that describe information such as color differences 
or designs within the bound­aries of a planar polygon are referred to here as surface detail. Since they 
do not affect the boundaries of the polygon to which they belong, they cannot affect hidden surface 
calculation and should not be included in it. Instead, whenever a polygon is output from the hidden surface 
computations, the surface detail be­longing to the original source of that polygon is clipped to the 
area of the output polygon. Any of the surface detail within the bounds of the output polygon is then 
output at this time. This technique can greatly simplify the hidden surface problem for those situations 
in which surface detail might have otherwise been speci­ fied as regular polygons involved in the hidden 
 surface removal process. Shadowing The polygon area sort approach lends itself to the generation of 
shadows because the output of the algorithm is in the form of polygons which are suitable for further 
processing. Shadow creation is then reduced to the prob­lem of producing a hidden surface removed view 
of a scene from the position of the light source. Visible polygons from this point of view are transformed 
back to the original space and are treated as surface detail of a lighter shade on their source polygons. 
After this initial shadowing, a normal hidden surface removed view can be taken from any viewpoint to 
create a correctly shadowed scene. Multiple light sources may be represented using the same process. 
 Since full machine precision of the output is possible, this particular technique shows promise of being 
useful not only for display purposes, but also for engineering applications such as energy analyses related 
to solar heat gain [2]. Translucent Polygons Translucent polygons can be represented with a slight 
modification of the depth culling por­tion of the algorithm. When a translucent poly­gon becomes the 
clip polygon, polygons which are behind it should not be removed, but instead tagged and identified as 
being obscured by that particular translucent polygon. When a polygon is obscured by several translucent 
poly­gons, the effect can be accumulated. Since dis­play output is not made for a given area until after 
the hidden surface removal process for that area is complete, images can be correctly rendered. Partial 
shadows and shades cast by translucent planes would be handled by the shadowing process in the same manner 
as normal shadows. Screen Subdivision Reducing the exponential rate of the number of sorting steps 
required for visible surface computation is'highly desirable. Some mechanism for dealing with large numbers 
of polygons or polygons with large numbers of edges which exceed the capacity of main storage should 
also be pro­ vided. The benefits of the polygon area sort approach should be maintained. By taking 
the approach of a Warnock style screen area subdivision, the image can be divided into areas each containing 
a specifiedmaximum number of polygons. Each of these areas can then be processed by the hidden surface 
removal system separately. This method keeps the number of polygons within storage capacities, while 
effectively reducing the number of lateral sort­ing steps to an almost linear relationshipwith the number 
of polygons. This is accomplishedby reducing the range of the exponential growth factors of the hidden 
surface removal to the maximum number of polygons allowed within each screen subdivision. The overall 
number of lateral sorting steps for hidden surface re­moval is then almost linear to the number of polygons. 
The screen subdivision process itself follows an n log n growth rate. Note that it is possible that 
the polygons can also be subdivided along the Z axis if their depth exceeds the specified limit. An 
example would be a large number of screen-sizedpolygons parallel to the display. Two methods can be 
used to deal with this case. The first solution, valuable only for hidden surface removal, uses a technique 
similar to the frame buffer overlay technique of Newell, et al [7]. The image is subdivided along the 
Z axis into several "boxes" of space containing a specific number of polygons. The boxes are ordered 
from back to front and each box is separ­ately solved. The results are output to a frame buffer in order, 
with the results from each succeeding box overlaying previous results. This technique, while sufficient 
for most display pur­poses and quicker than the one presented in the next paragraph, loses some of the 
advantages of the polygon area sort algorithmand cannot pro­ duce fully shadowed images or hidden line 
 removed images. A more general solution is to divide the scene by Z subdivisions into boxes as before. 
 The farthest box is then solved, and the solution of this last box is treated as surface detail on 
 the plane of a distant polygon parallel to the screen and with the same x-y limits as the box (such 
surface detail, while associated with the "backdrop" plane for hidden surface removal, can still maintain 
all depth information for three dimensional output)(Figure 9). This newly created polygon is then added 
to the next to last box and that box is solved. The process repeats until all of the boxes have been 
solved. The techniques of surface detail and of consoli­dation (describedlater) are used here to reduce 
 the numbers of polygons involved in the hidden surface problem. This solution has the same effect 
as the first method visually, but is different in that no external overlay techniques are used in order 
that the solution be entirely expressed in terms of polygons. This difference in the two solutions illustrates 
one of the pri­mary differences between the Newell, et al, approach and the hidden surface algorithm 
pre­ sented here. Consolidation While the hidden surface algorithm takes advantage of polygon area 
coherence, even greater gains can be achieved by taking advantage of object coherence where several related 
polygons obscure objects behind them [11]. An eiample is the case where solid objects are represented 
as a series of polygons. Consolidation can be accomplished by creat­ing a new silhouette polygon exactly 
encompassing all the polygons of the group. Individual com­ ponent polygons can then be represented 
as sur­ face detail of the new polygon (Figure10). This technique is particularly valuable for convex 
 polyhedra,where it is known that the component polygons do not overlap each other after removal of 
the backward facing polygons. The advantage of consolidation is that one polygon replaces several polygons 
in the hidden surface computations, thus reducing the number of polygon clips and depth tests required. 
 Furthermore,since the number of sorting steps required is related to the number of polygons, any method 
of reducing the number of polygons  220 offers the greatest potential in reducing overal CONCLUSION 
computation time. A hidden surface and hidden line removal IMPLEMENTATION algorithm using polygon area 
sorting has been presented. A generalized polygon clipper, The hidden surface and hidden line removal 
capable of clipping concave polygons with holes system described has been implemented at Cornell's to 
concave polygons with holes, is incorporated Laboratory for Computer Graphics [5]. The pro­ allowing 
polygon format to be maintained for gram was written in FORTRAN IV and runs on a both the input and output. 
Calculation times PDP 11/50 with a floating point processor under are primarily related to the visible 
complexity the RSX-11M operating system. The available dis­ of the final image. play equipment includes 
both static and dynamic vector displays, as well as a video frame buffer Inherent characteristics of 
the polygon and color monitor. Some sample photographs of area sorting algorithm give rise to both posi­several 
environments are shown in Figures 1 tive and negative features. Disadvantages are and 11. the relative 
complexity of the clipping and the need to render polygons separately as con-The system was designed 
as a flexible sub­ trasted to generating the output on a scan line routine package for use in a variety 
of applica­ basis. Advantages include flexible polygon tions programs. Complete matrix transformation, 
representations which can provide for the viewbox clipping, and backplane removal facili­ creation of 
complex environments and arbitrary ties are provided. Once the input data has been output precision. 
Perhaps the primary advan­defined in an input data file it may be repeatedly tage is the similarity between 
the output and transformed for an unlimited number of views as input forms, enabling shadow generation 
and specified by a matrix file. A filming capability surface details to be treated in a manner for the 
generation of long sequences of images consistent with the entire hidden surface is also provided. removal 
process. The system is organized as four separate tasks including the user's task, a data prepara­tion 
task, the hidden surface removal task, and a monitor task. This system reduces the com­plexities of user 
interface requirements and increases the flexibility of the runtime con­figuration in terms of sequential 
or concurrent execution and of core usage. All communication between tasks is limited to file access 
and system messages. System dependent functions are contained only in top level control routines in each 
task. The user task is not required to be aware of the details of the configuration or that any file 
system exists; all interaction takes place through interface routines provided by the hidden surface 
removal system. Sufficient information is provided in all output files so that any file may be displayed 
on any vector or raster output device without prior knowledge of the contents of the output file.  
ACKNOWLEDGEMENTS 13. Watkins, G.S., "A Real-Time Visible Surface Algorithm", Comp. Sci, Dept., U. of 
Utah, The research is part of a project sponsored UTECH-CSC-70-101, (June 1975). by the National Science 
Foundation under a grant number DCR74-14694 entitled "Development of Compu­ 14. Weiler, Kevin J., "Hidden 
Surface Removal ter Graphics Techniques and Applications" (Dr. Using Polygon Area Sorting", M.S. Thesis, 
Donald P. Greenberg, Principle Investigator). Cornell University, Ithaca, N.Y. (1977), The authors wish 
to particularly thank Ted Crane (forthcoming). and David Bessel for their work in the implemen­ tation 
of the color display system. REFERENCES 1. Appel, A., "The Notion of Quantitative invisibility and the 
Machine Rendering of Solids", Proceedings ACM National Conference (1967), pp. 387-393. 2. Atherton, Peter 
R., "Polygon Shadow Generation", M.S. Thesis, Cornell University, Ithaca, N.Y. (1977), (forthcoming). 
3. Bouknight, W.J., "A Procedure for Generation of Three Dimensional Half-toned Computer Graphics Representations", 
Comm. ACM, 13, 9 (Sept. 1970) pp. 527-536. 4. Galimberti, R., and Montanari, U., "An Algorithm for Hidden-Line 
Elimination", Comm. ACM, 12, 4, (April 1969), pp. 206-211. 5. Greenberg, Donald P., "An Interdisciplinary 
Laboratory for Graphics Research and Appli­ cations", Proceedings of the Fourth Annual Conference on 
Computer Graphics, Interactive Techniques and Image Processing -SIGGRAPH, 1977. 6. Myers, A.J., "An Efficient 
Visible Surface Program", CGRG, Ohio State U., (July 1975). 7. Newell, M.E., Newell, R.G. and Sancha, 
T.L., "A Solution to the Hidden Surface Problem", Proceedings ACM National Conference, (1972), pp. 443-450. 
8. Roberts, L.G., "Machine Perception of Three- Dimensional Solids", MIT Lincoln Laboratory, TR 315, 
(May 1963). 9. Schumacher, R.A., Brand, B., Gilliand, M. and Sharp, W., "Study for Applying Computer 
Gen­ erated Images to Visual Simulation", AFHRL­ TR-69-14, U.S. Air Force Human Resources Laboratory, 
(Sept. 1969). 10. Sutherland, I.E., and Hodgman, G.W., "Re­ entrant Polygon Clipping", Communications 
of the ACM, Vol. 17, No. 1, (Jan. 1974), pp. 32­ 42. 11. Sutherland, I.E., Sproull, R.F., and Schumacker, 
R.A., "A Characterization of Ten Hidden Sur­ face Algorithms",ACM Computing Surveys, Vol. 6, No. 1, (Mar. 
1974), pp. 1-55. 12. Warnock, J.E., "A Hidden Surface Algorithm for Computer Generated Halftone Pictures", 
Dept. Comp. Sci., U. of Utah, (1969). 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563897</article_id>
		<sort_key>223</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>39</seq_no>
		<title><![CDATA[A graph-theoretic real-time visible surface editing technique]]></title>
		<page_from>223</page_from>
		<page_to>228</page_to>
		<doi_number>10.1145/563858.563897</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563897</url>
		<abstract>
			<par><![CDATA[Efficient visible surface (hidden surface) algorithms must make use of information about the structure of the environment, constraints on viewpoint locations and the coherence between successive views in a sequence. Here the visible surface problem is posed as a problem in graph theory. A new technique based on 'updating cut-sets in a graph is presented as a means to streamline the culling of back faces during visible surface computations. The technique can be used for general environments that contain some convex polyhedra. Since the method saves the most computation when convex polyhedra having many faces appear in the environment, it is particularly appropriate for handling geodesic domes and polyhedral approximations to spheres. A direct extension for nonconvex polyhedra is suggested.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[back face]]></kw>
			<kw><![CDATA[computer graphics]]></kw>
			<kw><![CDATA[convex polyhedra]]></kw>
			<kw><![CDATA[culling]]></kw>
			<kw><![CDATA[cut-set]]></kw>
			<kw><![CDATA[geodesic domes]]></kw>
			<kw><![CDATA[graph theory]]></kw>
			<kw><![CDATA[hidden surface]]></kw>
			<kw><![CDATA[surface editing]]></kw>
			<kw><![CDATA[visible surface]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40027409</person_id>
				<author_profile_id><![CDATA[81100450825]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Tanimoto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Connecticut, Storrs, CT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Jones, C. B., A new approach to the "hidden-line" problem. Computer Journal Vol. 14, No. 3, (Aug. 1971), pp. 232-237.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. E., Sproull, R. F., and Schumacker, R. A., A characterization of ten hidden-surface algorithms. Computing Surveys Vol. 6, No. 1, (March 1974), pp. 1-55.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Schumacker, R. A., Brand, B., Gilliland, M. and Sharp, W., Study for applying computer-generated images to visual simulation. AFHRL-TR-69-14, U.S. Air Force Human Resources Laboratory (Sept. 1969).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Warnock, J. E., A hidden-surface algorithm for computer-generatedhalftone pictures. Computer Science Dept., University of Utah, TR 4-15 (June 1969).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Roberts, L. G., Machine perception of three-dimensional solids. MIT Lincoln Laboratory, TR 315 (May 1963).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Watkins, G. S., A real-time visible surface algorithm. Computer Science Dept., University of Utah, UTECH-CSC-70-101, (June 1970).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Loutrel, P. P., A solution to the hidden-line problem for computer-drawn polyhedra. IEEE Trans. Comput. C-19, 3, (March 1970) p. 205.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>362921</ref_obj_id>
				<ref_obj_pid>362912</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Galimberti, R. and Montanari, U., An algorithm for hidden line elimination. Comm. A.C.M. Vol. 12, No. 4, (April 1961), pp. 206-211.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>362739</ref_obj_id>
				<ref_obj_pid>362736</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Bouknight, W. J., A procedure for generation of half-tone computer graphics representations. Comm. A.C.M. Vol. 13, No. 9, (Sept. 1970) p. 527.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Bramall, R., Three dimensional data display with hidden line removal. TR CSRG-12, University of Toronto. (April 1972).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360354</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Clark, J. H., Hierarchical geometric models for visible surface algorithms. Comm. A. C. M. Vol. 19, No. 10 (Oct. 1976) pp. 547-554.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Tanimoto, S. L., An iconic/symbolic data structuring scheme, Pattern Recognition and Artificial Intelligence, Academic Press, N. Y. 1976, pp. 452-471.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Cheston, G. A., Incremental algorithms in graph theory, Techn. Rept. No. 91, University of Toronto, Dept. of Computer Science (March 1976).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Newell, M. E., Newell, R. G., and Sancha, T. L. A new approach to the shaded picture problem. Proc. ACM National Conf., 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Busacker, R. G. and Saaty, T. L., Finite Graphs and Networks, McGraw-Hill, N. Y., 1965.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>907365</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Newell, M. E., The utilization of procedural models in digital image synthesis. Ph.D. dissertation, Computer Science Dept., University of Utah, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A GRAPH-THEORETIC REAL-TIME VISIBLE SURFACE Steven L. Tanimoto U-157 University of Connecticut  Storrs, 
CT ABSTRACT Efficient visible surface (hidden surface) al­ gorithms must make use of information about 
the structure of the environment, constraints on view­point locations and the coherence between successive 
 views in a sequence. Here the visible surface pro­blem is posed as a problem in graph theory. A new 
 techniquebased on' updating cut-sets in a graph is presented as a means to streamline the culling of 
back faces during visible surface computations. The technique can be used for general environments that 
contain some convex polyhedra. Since the meth­od saves the most computation when convex polyhedra having 
many faces appear in the environment, it is particularlyappropriatefor handling geodesicdomes and polyhedral 
approximations to spheres. A direct extension for nonconvex polyhedra is suggested. KEYWORDS: visible 
surface, hidden surface, back face, culling, cut-set, geodesic domes, convex polyhedra, graph theory, 
computer graphics, sur­ face editing CR CATEGORIES: 3.41, 5.32, 8.2 I. Motivation and Introduction 
 One of the most fascinating applications of com­ puters is the production of pictures of imaginary 
environments. In order to make the pictures look realistic however, many technical challenges must 
be met, not the least of which involves improving the method by which the visible parts of the envir­ 
onment are determined. Much work has been done on this problem and yet we still do not have systems 
 powerful enough to generate the imagery let alone any of the imagination that goes into a sequence 
of images such as the film Fantasia. With goals of that level, undoubtedly computer graphics research­ 
ers will be working for many years. This paper re­ presents one small effort toward that goal. Permission 
to make digital or hard copies of part or all of this work or personal or classroom use is granted without 
fee provided that copies are not made or distributed for profit or commercial advantage and that copies 
bear this notice and the full citation on the first page. To copy otherwise, to 223 republish, to post 
on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Siggraph 77, 
July 20-22 San Jose, California 06268 An interestingclass of visible surface (or hidden surface) problems 
is typified by one where the system has some "knowledge" beforehand of -­  he likelihoods chat given 
parts of an environment will be visible at a given point in time. Several visi­ ble surface algorithms 
in the past have used a priori visibility constraints to gain efficiency. For example, for computing 
views inside a simula­ "house", the system can be told in advance that the interior of the bathroom 
is never visible from the living room (after [1]). Furthermore, many methods make the assumption that 
the interiors of closed objects will never be visible. Several algorithms have taken advantage of "coherence" 
ten­  dencies in various data sets during visible surface computation. These have included scan line 
to scan line coherence of object intersectionlocations, point to point coherence of intensity, frame 
to  frame coherence for the set of visible entities, etc. [2]. Coherence may be viewed as a class of 
 constraints. Visibility constraints may be divided up into static and dynamic types. Static constraints 
cull out from the set of potentially visible entities some or all of those which for some reason will 
 never be visible, or static constraints may assign a priori probabilities of visibility to the enti­ 
ties. The notion of dynamic visibility constraints constitutes a generalizationof that of static ones. 
Dynamic constraints have the form "If <condition> then face f is visible with probability p". When 
the condition involves the location of the viewpoint we have a viewpoint-based constraint. An example 
of this would be the precomputationof priorities of linearly separable clusters (after Schumacker [2,3]) 
and the associationof these pri­ orities with each of a number of viewpoint regions. A scheme following 
this approach has been implemen­ ted by Jones. Jones' method concerns itself with only a subset of the 
environmentat any one time. In his system a graph data-structure,given to the  II. Background 3 Let 
Erepresent 3-dimensional Euclidian space. 3 Any plane divides Einto two Half-spaces. A closed half-space 
is a half-space together with the dividing plane. The intersectionof a finite number of closed half-spaces 
is a convex Polyhedron if it is bounded (no half-lines-arewholly contained with­ facts can easily be 
shown: The intersectionof a convex polyhedron with a half-space is a convex polyhedron (note that the 
empty set is the "trivial polyhedron"). If P is any intersectionof half­spaces then P is a convex set. 
 These definitions of on-view and off-view faces are analogous to the characterizationof "back faces" 
provided in [2]. In the list-priority by computing the predicate S * (v-vp)'N. > 0 algorithms [2] of 
Newell et al [14] and especially of Schumacker [3], the detection of on-view faces is a critical time-consumingstep 
in the computa­tion of a frame. Although this can be done simply 1 for each frame, this can be bad 
when there are a large number of faces and the time between frames should be small. One simple way 
to reduce the number of on-view tests required uses position-basedvisibility con­straints. As an example 
consider an environment made up primarily of rectangular parallelopipeds (see figure 1) in different 
locations and orienta­ 224 tions. By storing the decision tree shown in fig­ure 2, a savings can be 
realized. When faces likely to be on-view with respect to the viewpoint tend to be tested first, the 
savings approaches 50 percent. With a uniform likelihood assumption, the expected number of predicate 
computationsper parallelopiped is 4.769 out of the standard 6. While the savings using this decision 
tree are not dramatic, they do indicate that savings are possible. Much more dramatic savings are possible 
using a class of graph-theoreticdynamic visibility con­straints based on frame-to-frame coherence. III. 
Graph-theoreticformulation In order to achieve significant savings in the computation of the on-view 
predicates in a sequen­tial views problem, we pose the visible surface problem as one of finding a certain 
cut-set in a graph. Let P be a convex polyhedron (as defined previously) having nondegenerate faces f.,i=l,...,n. 
Then the face graph G=(N,E) for P has a node for each f. and an edge between two nodes whenever their 
faces share an edge. (Context will differen­ tiate graph-theoreticedges from geometrical edges). For 
example, figure 3 shows a sample P and figure 4 shows its corresponding G. If the set of nodes N of 
G is partitioned into two nonempty sets W and W' = N-W, then the set of edges joining W with W' is 
known as a cut-set [15]. It is easy to see that for any convex polyhedron P and external viewpoint 
vp the nodes of G that correspond to on-view and off-view faces of P with respect to vp form such a 
partition of N. Thus the set of all edges con­ necting an on-view face node to an off-view face node 
constitute one cut-set of G. Thus the cut­ set divides G into two connected components, one whose nodes 
correspond with on-view faces and a­ nother for off-view faces. This cut-set may easily be obtained 
by computing the on-view predicate for each face. Now by using frame coherence constraints we show 
how cut-sets for many-faceted polyhedra can be updated for a new viewpoint with very few new on-view 
predicate computations. A cut-set for the graph of figure 4 is shown in figure 5. With an incremental 
change in the viewpoint there will either be no change in the cutset or a "small" one. The cut-set 
may be updated by testing nodes incident on cut-set edges. If the component to which a node belongs 
changes during the update, it is then necessary to check any unchecked neighbors of that node. This 
will insure the correctness of the update even when the viewpoint changes drasti­ cally. Generally, 
the number of nodes to be checked is about twice the number of cut-set edges. Let us now discuss the 
technique in greater de­ tail. The cut-set is represented as follows. The edges of the current cut-set 
are stored in a list. The order is immaterial. Implicitly associated with each cut-set edge is the 
information indica­ ting which of its incident nodes represents an on­ view face and which represents 
an off-view face. In a separate table of nodes the on-view/off-view information is repeated but for 
all nodes, not just those on the cut-set edges. Each node also carries a flag indicating whether a 
new on-view predicate computationhas been done for it or not. Starting with the first edge on the list, 
the predicate is computed for each of the two nodes. If there is no change in the status of these nodes 
then these nodes are simply checked (flag set) and the process is repeated for the next edge of the cut-set. 
However if the status of either node changes, several steps are taken. Let A and B re­ present the two 
nodes, where A was on-view (off­ view) and B was off-view (on-view)with respect to vp. If A is now off-view 
(on-view)with respect to vp' the edge AB is deleted from the cut set and A is pushed onto a stack so 
that later a depth­ first search can be initiated from A to find addi­ tions to the cut set. The depth-first 
searches from nodes on the stack do not begin until all the cut-set edges have been considered. In 
the depth­ first search (from A initially, but from a general X in the recursive procedure), each unchecked 
 neighbor Y of X is tested and if on-view (off-view), the edge YX is added to the cut-set; if Y is off­ 
view (on-view), the search continuesrecursively from Y. After these searches are complete, the cut-set 
has been updated. The efficiency of this technique derives from the gradualness of the viewpoint motion 
or object motion. An average face of the polyhedron has a low probability of changing status. Furthermore 
 the changes that do occur tend to happen right a­ long the cut-set so that time spent in the depth­ 
first searches is very small. When the number of faces on the polyhedron gets very large, it can be 
seen that the fraction of faces that need to be tested on update ap­ proaches zero percent of the total. 
This follows from the assumption that the number of faces a­ round a great circle of an approximated 
sphere is proportional to the circumference while the total number of faces is proportional to the 
surface area. Since this method achieves a savings where large convex polyhedra are to be displayed 
at a succession of viewpoints and/or a succession of object positions and rotations, its appropriate­ 
ness depends on several factors. If the environ­ ment neither contains any convex polyhedra nor ob­ jects 
constructed from convex polyhedra, then the method is inapplicablein its current form. If the environment 
consists of only one convex poly­ hedron, then this method alone is sufficient to determine visible 
surfaces (except for "clipping" [2]). On the other hand, when the environment con­ tains some convex 
polyhedra this method may be used to speed up the culling of back faces within a larger system. Since 
a prime goal here is to mini­ mize the number of on-view predicate computations to be done, small systems 
where multiplicationis slow may benefit most from this. Finally, because savings are greatest where 
the environment consists of many-faceted polyhedra, this method may be pro­ grammed as a subroutine 
[11,16] to be invoked es­ pecially for geodesic domes or planar approxima­ tions to spheres. Savings 
can be estimated easily. Suppose we are displaying a "geodesic sphere" whose radius is roughly 10 "face-widths". 
The approximate total number of faces for this polyhedron is then 1256 based on a 2 surface area. The 
number of faces to be tested during an update is about 125, assum­ 4. Warnock, J. E., A hidden-surfacealgorithm 
for ing that the cut-set corresponds with a great cir­ computer-generatedhalftone pictures. Compu­ cle 
on the polyhedron. Note that this is the worst ter Science Dept., University of Utah, TR 4-15 case; this 
is the largest cut set possible and (June 1969). occurs when the viewpoint is very far away from the 
object. The 125 is obtained by multiplying the 2rr 5. Roberts, L. G., Machine perception of three­ cut-set 
edges on the great circle by 2 face tests dimensional solids. MIT Lincoln Laboratory, per cut-set edge. 
Even with this worst case assump- TR 315 (May 1963). tion, 90 percent of the tests have been eliminated 
for this polyhedron. 6. Watkins, G. S., A real-time visible surface algorithm. Computer Science Dept., 
University It should be noted that the method can be ex­ of Utah, UTECH-CSC-70-101, (June 1970). tended 
directly for updating on-view faces for non­ convex polyhedra. The main added complications are 7. Loutrel, 
P. P., A solution to the hidden-line that the partition into on-view and off-view sub­ problem for computer-drawn 
polyhedra. IEEE graphs now involves members which (1) may not be Trans. Comput. C-19, 3, (March 1970) 
p. 205. connected subgraphs of G and which (2) have com­ ponents that can shrink to nothing or grow "out 
of 8. Galimberti,R. and Montanari, U., An algorithm nowhere" within a component of the other member, 
for hidden line elimination. Comm. A.C.M. from one view to the next. In order to detect the Vol. 12, 
No. 4, (April 1961), pp. 206-211. "birth" of a cluster of these nodes, it is neces­ sary to know the 
maximum number of clusters that 9. Bouknight, W. J., A procedure for generation can occur (as the viewpoint 
changes), and to search of half-tone computer graphics representations. for the emergence of these clusters 
if any are Comm. A.C.M. Vol. 13, No. 9, (Sept. 1970) missing. If the objects have high maximum numbers 
p. 527. of these clusters (that is, the "concavity com­ plexity" of the objects is high), it will be 
im­ 10. Bramall, R., Three dimensional data display possible to realize much savings with the cut-set 
with hidden line removal. TR CSRG-12, Univer­ method alone. sity of Toronto. (April 1972). If concave 
parts of polyhedra are treated 11. Clark, J. H., Hierarchicalgeometric models separately by the canonical 
one-test-per-face for visible surface algorithms. Comm. A.C.M. method, savings may still be realized 
for the re- Vol. 19, No. 10 (Oct. 1976) pp. 547-554. maining convex portion(s). 12. Tanimoto, S. L., 
An iconic/symbolicdata IV. Conclusion structuring scheme, Pattern Recognition and Artificial Intelligence, 
Academic Press, N. Y. Efficient visible surface algorithms must make 1976, pp. 452-471. use of information 
about the structure of the en­ vironment, constraints on viewpoint locations and 13. Cheston, G. A., 
Incremental algorithms in graph the coherence between successive views in a se­ theory, Techn. Rept. 
No. 91, Universityof quence. A new technique based on updating cut- Toronto, Dept. of Computer Science 
(March sets in a graph has been presented as a means to 1976). streamline the culling of back faces during 
visi­ ble surface computations. The method is most 14. Newell, M. E., Newell, R. G., and Sancha, T. L. 
appropriate when convex polyhedra having many A new approach to the shaded picture problem. faces appear 
in the environment. Proc. ACM National Conf., 1972. Acknowledgment 15. Busacker, R. G. and Saaty, T. 
L., Finite Graphs and Networks, McGraw-Hill, N. Y., 1965. The author would like to thank Professor Theo 
Pavlidis of Princeton University for several valu­ 16. Newell, M. E., The utilization of procedural able 
discussions related to this problem. models in digital image synthesis. Ph.D. dissertation,Computer Science 
Dept., Univer- References sity of Utah, 1975. 1. Jones, C. B., A new approach to the "hidden­ line" problem. 
Computer Journal Vol. 14, No. 3, (Aug. 1971), pp. 232-237. 2. Sutherland, I. E., Sproull, R. F., and 
Schumacker, R. A., A characterization of ten hidden-surfacealgorithms. Computing Surveys Vol. 6, No. 
1, (March 1974), pp. 1-55. 3. Schumacker, R. A., Brand, B., Gilliland, M. and Sharp, W., Study for applying 
computer­ generated images to visual simulation. AFHRL-TR-69-14,U.S. Air Force Human Resources Laboratory 
(Sept. 1969).  A decision tree to reduce the number of on-view predicate computations required for the 
rectan­gular parallelopiped. One tree may be used for Each path an arbitrary number of these objects. 
corresponds with one plausible combinationof visible faces. 227 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563898</article_id>
		<sort_key>229</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>40</seq_no>
		<title><![CDATA[General clipping on an oblique viewing frustrum]]></title>
		<page_from>229</page_from>
		<page_to>235</page_to>
		<doi_number>10.1145/563858.563898</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563898</url>
		<abstract>
			<par><![CDATA[An algorithm is presented which clips on a non-rotated viewport positioned anywhere on the viewport plane relative to the viewing vector. This is a generalization of the traditional three-dimensional clipping algorithm in which the viewing vector intersects the viewport at its center. This traditional algorithm is shown to be a special case of the general algorithm. Also shown is that both orthogonal box clipping and perspective pyramid clipping can be accomplished using the same algorithm with only a slight increase in complexity. Finally, the ability to perform switch-controlled hither and yon plane clipping is described. It should be noted that with this general clipping algorithm no separate clipping operation is required for two-dimensional operations since they can be handled as an orthogonal projection from an arbitrary default Z-plane onto the viewport plane.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[clipping]]></kw>
			<kw><![CDATA[computer graphics]]></kw>
			<kw><![CDATA[orthogonal projection]]></kw>
			<kw><![CDATA[perspective projection]]></kw>
			<kw><![CDATA[viewing frustrum]]></kw>
			<kw><![CDATA[viewing pyramid]]></kw>
			<kw><![CDATA[viewing vector]]></kw>
			<kw><![CDATA[viewport]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P242795</person_id>
				<author_profile_id><![CDATA[81100117553]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Puk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sandia Laboratories, Albuquerque, New Mexico]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M. and Sproull, R. F. Principles of Interactive Computer Graphics. McGraw-Hill Book Company, New York (1973). {N & S}]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Puk, Richard F. Expanding the graphics compatibility system to three-dimensions. Computer Graphics and Art, Vol. I, No. 1 (Feb. 1976). {Puk}]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360802</ref_obj_id>
				<ref_obj_pid>360767</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. E. and Hodgman, G. W. Reentrant polygon clipping. Communications of the ACM, Vol. XVII, No. 1 (Jan. 1974), pages 32-42.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 GENERAL CLIPPING ON AN OBLIQUE VIEWING FRUSTRUM Richard F. Puk Sandia Laboratories* Albuquerque, New 
Mexico Abstract An algorithm is presented which clips on a non-rotated viewport positioned anywhere 
on the viewport plane relative to the viewing vector. This is a generalization of the traditional three­dimensional 
clipping algorithm in which the viewing vector intersects the viewport at its center. This traditional 
algorithm is shown to be a special case of the general algorithm. Also shown is that both orthogonal 
box clipping and perspective pyramid clipping can be accomplished using the same algorithm with only 
a slight increase in complexity. Finally, the ability to perform switch-controlled hither and yon plane 
clipping is described. It should be noted that with this general clipping algorithm no separate clipping 
operation is required for two-dimensional operations since they can be handled as an orthogonal projection 
from an arbitrary default Z-plane onto the viewport plane. Key Words and Phrases: clipping, viewport, 
computer graphics, viewing vector, viewing pyramid, viewing frustrum,orthogonal projection, perspec­ 
tive projection. CR Category: 8.2 Introduction Traditional 3-D line clipping algorithms have assumed 
that the viewing vector intersects the viewport perpendicularly at its center. Indeed, the widely used 
Sutherland-Cohen 3-D clipping algorithm in Newman and Sproull [N &#38; S, page 252] makes this assumption. 
Such a symmetric view of the clipping operation could lead to some efficiencies during implementation. 
However, as will be seen, it is possible to incorporate many of these efficiencies into a more general 
algorithm.  provided under contract from the Energy Research and Development Administration. Permission 
to make digital or hard copies of part or all of this work or personal or classroom use is granted without 
fee provided that copies are not made or distributed for profit or commercial advantage and that copies 
Several advantages may be obtained by allowing clipping on an arbitrary rectangular viewport whose 
sides are parallel to the X and Y axes of the eye coordinate system. One of the most important of 
these is the capability of handling either orthogonal or perspective projections with the same algorithm. 
This removes the redundancy of maintaining separate box clippings and perspective clipping routines. 
 Since orthogonal projections are handled, 2-D vectors can be clipped against the appropriate window 
 boundaries by assuming some arbitrary third component value for each 2-D vector and then processing 
it as a 3-D vector. This algorithm also facilitates appli­ cations in which the view site is on an 
object different from the scene being drawn. In architectural applications, for example, a viewer 
there is a window. The scene through might be looking at a wall in which the window can easily be clipped 
or viewed. Although it may be argued that this might most appropriately be an application requiring 
a general hidden surface removal process, a reasonable amount of such work can be accommodated whenever 
the extra data organization and computational require­ments inherent in hidden surface removal are not 
available or desirable. Background Traditional clipping algorithms work as indicated in Figure 1. Note 
that the viewing vector intersects the view­port plane perpendicularlyat the center of the viewport rectangle. 
The algorithm in Newman and SproUll [N &#38; S; page 252] consists of coding and testing each end point 
to identify whether a line is to be clipped, and then the solving one or more of four parametric equations 
to calculate the intersection boundaries. The conditions that must be met for a point to be visible are 
[N &#38; S; page 250J  bear this notice and the full citation on the first page. To copy otherwise, 
to republish, to post on servers, or to redistribute to lists, requires prior 229 specific permission 
and/or a fee. Siggraph 77, July 20-22 San Jose, California  For convenience, the eye coordinates (Xe, 
ye, are transformed into clipping coordinates  prior to applying the clipping algorithm. The algorithm 
then checks to determine if the parts are outside the pyramid [N &#38; S; pa.ge 251] by comparing for 
 A line can be defined by its two end points and thus can be represented by  If we associate the subscript 
1 with the end point outside the viewing pyramid when clipping on a particular plane, the intersection 
points of the line and the pyramid can be calculated from one or more of the following parametric equations 
[N &#38; S; pages252-253]. General Algorithm Deviation In developing an algorithm for clipping to an 
arbitrary viewing pyramid, it was necessary to re-evaluate the conditions for line visibility. Inequality 
[1] applies only in the special case of the viewing vector being perpendicular to and through the center 
of the viewport. In the general case, a point will be visible if it is within a pyramid defined by the 
intersections of the four bounding lines of the viewport rectangle at the viewport plane [Figure 2]. 
This can be expressed as 230 Although it is possible to apply a temporary Ze transformation to pre-divide 
by a when perspective clipping is being performed it will be shown later that a must be modified when 
orthogonal (box) clipping is performed. The conditions for a line'being outside the viewing pyramid 
can be identified  Sutherland-Cohen code as described in [N &#38; S; page 251] is determined using 
the inequations above. If a line is to be clipped on either end, the points are arranged to insure that 
(Xe ye, ze) is outside the viewing pyramid. The intersection of the line with the plane it intersects 
can then be re-calculated by computing the value of a parametric equation and then use proportional 
equations to find the coordinate component values of the intersection point. Let be the eye coordinates 
of the point outside the viewing pyramid and  be the eye coordinates of the point inside the viewing 
pyramid. Also  be the boundary values of the pyramid at the viewport where  Parametric equations can 
now be expressed as  First it is necessary to convert back to eye coordinates:   231 The numerator 
and denominator are  The numerator and denominator are multiplied by -1:  The sign of the Ze-related 
terms is associated with b to obtain:  Note that in the Newman and Sproull equations, the value b is 
always an absolute value referring to half the width of the screen. If, instead, the  factor is considered 
to refer to the Xmi boundary location, the following is obtained:  which is identical to [9]. The inter­section 
equations of [6] are identical to equations [10] by substitution of appro­priate Uij terms. In the same 
manner, the Xmax plane clipping equations [5] can also be shown to be  Convert back to eye coordinates: 
 Again noting that b refers to width, the sign (which is positive this time) can be associated with 
the b term. The  factor can be considered to refer to the boundary location to get: 232 which is 
also identical to equation [9]. The verification for Y can be shown in a similar fashion. Orthogonal 
Projection Clipping The preceding section describes clip­ ping to a viewing pyramid. This is what is 
required for clipping when perspective projections are being used. = --. The resulting Orthogonal projections 
are the equiva­lent of perspective projections when the viewpoint is at "pyramid" becomes a viewing 
parallel­epiped as shown in Figure 3. The projection of any point onto the view­ port plane is independent 
of the value of Ze. That is, X and Y components need only be compared to the X and Y boundaries of the 
viewing parallelpiped to determine if a point is visible. The conditions that determine invisibility 
  This condition will be met if a = Ze whenever orthogonal clipping is to be accomplished. If the term 
a' is defined as follows: then the test for invisibility for both perspective and orthogonal clipping 
becomes the same as inequalities [8] with a' substituted for a. Similarly, a new parametric equation 
can be derived which will handle both perspective and orthogonal clipping:  Hither and Yon Clipping 
 It is sometimes desirable to view only those lines between one plane perpen­dicular to the viewing 
vector and another. This facility has become known as hither and yon clipping. The plane nearest the 
viewpoint is called the "hither" plane and that farthest from the viewpoint is called the "yon" plane. 
Frequently, the hither plane corresponds to the viewport plane, but this need not be the case. The resulting 
viewing solid becomes a frustrum whether the projection is orthogonal or perspective (Figure 4). Clipping 
at the hither and yon planes can be accomplished in a manner similar to that required for the other four 
planesof the viewing frustrum. A convenient means of providing this clipping operationis simply to consider 
it a problem of orthogonally projecting in three-dimensions from one side the contents of the originalviewing 
solid into the viewing frustrum clipping at the hither and yon planes. If Z-axis clipping is viewed in 
this manner, the technique described above can be easilyextended to perform the requisite computations. 
 Note that in both orthogonal and perspective clipping for the entire line, the projection for Z clipping 
is handled as an orthogonal projection. By 123] expressing the parametric equation in a more general 
form, clipping at the hither and yon planes can use the same equation as those required for clipping 
on the X and Y boundaries of the viewing frustrum: 233 It should be noted that the value of m when 
clipping on Z boundaires could just as well be 2 which would project in the Y direction instead of 
the X direction. Since the resulting intersection with the Z plane is the same, projection was chosen 
arbitrarily to be in the X direction. Implementation The technique described above has been implemented 
and tested. It has now been imbedded in the latest experimental version of 3-D GCS [Puk]. A listing 
of the algorithm is included in Appendix A. Although implemented on a CDC 6600 computer system, it uses 
only ANS Fortran and has been transported to a Honeywell 635 computer. It is apparent from reading the 
listing that the clarity of the algorithm could be increased if it were to be recoded in a more powerful 
recursive block structured language. Summary The clipping of lines in three-space is now no longer 
restricted to the special 234 case of the viewing vector intersecting the viewport at the center. Implementa­ 
tion of the algorithm should require little or no increase in computation facilities over the algorithm 
in Newman and Sproull while providing the additional capability of box (orthogonal) clipping and 2-D 
windowing. Although this algorithm does not provide a general polygon clipping facility [Sutherland and 
Hodgmanl it also avoids the additional complexity of such algorithms for those applications not requiring 
a hidden surface removal facility. References 1. Newman, W. M. and Sproull, R. F. Principles of Interactive 
Computer Graphics. Book Company, New York (1973). [N &#38; S]  2. Puk, Richard F. Expanding the graphics 
compatibility system to three-dimensions. Computer Graphics and Art, Vol. I, No. 1 (Feb. 1976). [Puk] 
 3. Sutherland, I. E. and Hodgman,  G. W. Reentrant polygon clipping. Communications of the ACM, 
Vol. XVII,No. 1 (Jan. 1974), pages 32-42.  235
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563899</article_id>
		<sort_key>236</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>41</seq_no>
		<title><![CDATA[Optimal surface reconstruction from planar contours]]></title>
		<page_from>236</page_from>
		<page_to>236</page_to>
		<doi_number>10.1145/563858.563899</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563899</url>
		<keywords>
			<kw><![CDATA[continuous tone displays]]></kw>
			<kw><![CDATA[contour data]]></kw>
			<kw><![CDATA[serial sections]]></kw>
			<kw><![CDATA[surface reconstruction]]></kw>
			<kw><![CDATA[three-dimensional computer graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP43128728</person_id>
				<author_profile_id><![CDATA[81339500019]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[H.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fuchs]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Texas at Dallas, Richardson, Texas]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43126507</person_id>
				<author_profile_id><![CDATA[81100539349]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Z.]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Kedem]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Texas at Dallas, Richardson, Texas]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39036974</person_id>
				<author_profile_id><![CDATA[81100307396]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[S.]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Uselton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Texas at Dallas, Richardson, Texas]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 OPTIMAL SURFACE RECONSTRUCTION FROM PLANAR CONTOURS H. Fuchs, Z. M. Kedem, and S. P. Uselton The 
University of Texas at Dallas Richardson, Texas 75080 Abstract In many scientific and technical endeavors, 
a three-dimensionalsolid must be reconstructed from serial sections, either to aid in the comprehensionof 
the object's structure or to facilitate its automatic manipulation and analysis. This paper presents 
a general solution to the problem of constructinga surface over a set of cross­sectional contours. This 
surface, to be composed of triangular tiles, is constructed by separately determining an optimal surface 
between each pair of consecutive contours. Determining such a surface is reduced to the problem of finding 
certain minimum cost cycles in a directed toroidal graph. A new fast algorithm for finding such cycles 
is utilized. Also developed is a closed-form expression, in terms of the number of contour points, for 
an upper bound on the number of operations required to exe­cute the algorithm. An illustrative example 
which involves the constructionof a minimum area surface describing a human head is included. Key Words 
and Phrases: Surface reconstruction,contour data, serial sections, three-dimensional computer graphics, 
continuous tone displays. CR Categories: 8.2, 5.32, 5.25. Permission to make digital or hard copies 
of part or all of this work or personal or classroom use is granted without fee provided that copies 
are not made or distributed for profit or commercial advantage and that copies bear this notice and the 
full citation on the first page. To copy otherwise, to republish, to post on servers, or to redistribute 
to lists, requires prior 236 specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563900</article_id>
		<sort_key>237</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>42</seq_no>
		<title><![CDATA[A homogeneous formulation for lines in 3 space]]></title>
		<page_from>237</page_from>
		<page_to>241</page_to>
		<doi_number>10.1145/563858.563900</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563900</url>
		<abstract>
			<par><![CDATA[Homogeneous coordinates have long been a standard tool of computer graphics. They afford a convenient representation (for) various geometric quantities in two and three dimensions. The representation of lines in three dimensions has, however, never been fully described. This paper presents a homogeneous formulation for lines in 3 dimensions as an anti-symmetric 4x4 matrix which transforms as a tensor. This tensor actually exists in both covariant and contravariant forms, both of which are useful in different situations. The derivation of these forms and their use in solving various geometrical problems is described.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[computer graphics]]></kw>
			<kw><![CDATA[geometric calculations]]></kw>
			<kw><![CDATA[homogeneous coordinate's]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P131722</person_id>
				<author_profile_id><![CDATA[81100294395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Blinn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Newman, W. and Sproull, R. Principles of Interactive Computer Graphics, McGraw-Hill, 1973, pp. 467.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Hodge, W. V. D. and Pedoe, D. Methods of Algebraic Geometry, Cambridge University Press, 1968, pp. 286.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ABSTRACT Homogeneous coordinates have long been a standard tool of computer graphics. They afford 
a convenient representation for various geometric quantities in two and three dimensions. The representationof 
lines in three dimensions has, however, never been fully described. This paper presents a homogeneous 
formulation for lines in 3 dimensions as an anti-symmetric4x4 matrix which This tensor actually transforms 
as a tensor. exists in both covariant and contravariant forms, both of which are useful in different 
situations. The derivation of these forms and their use in solving various geometrical problems is described. 
 Key Words and Phrases: geometric calcula­tions, homogeneous coordinate's, computer graphics CR Categories: 
3.15, 5.14, 8.2 INTRODUCTION We will assume the reader is somewhat famil­iar with the homogeneous representationof 
points and planes in 3 space. A good introductionmay Briefly, a point is represented be found in [1]. 
 as as a four component vector, usually written A HOMOGENEOUS FORMULATION FOR LINES IN 3 SPACE James 
F. Blinn University of Utah  The dot product of a point (row)vector and a plane (column)vector is proportional 
to the distance from the point to the plane.  A special case of this is the fact that, if the dot 
product is zero, the point lies in the plane. If the dot product is non-zero, we can find the actual 
distance by the following means. Construct a three dimensional vector of unit length per­ (A B C) = (a 
b c)/ pendicular to the plane. 2+ bZ + c2. Scale it up by D and add it to the position of the point. 
 We should then have a point on the plane.  Since this point is on the plane, its dot product with 
the plane vector will be zero. We now have an equation which can be solved for D.  Any non-zero multiple 
of this row vector rep- The "real" components resents the same point. of the point may be discovered 
by dividing by the fourth component to obtain the three compo­nents:  The sign of D indicates which 
side of the plane the point was on. It can be ignored if only the distance is required. An object defined 
in terms of homogeneous points may be transformed by multiplicationof its points by a 4x4 matrix. A 
plane is representedas a four component Any combination of scaling, translation, rotation, column vector: 
 and perspective distortionmay be represented by the matrix T.  To determine the coordinates of a plane 
after it has undergone the same transforma­ tion we must pre-multiply by the inverse of T. vector rep- 
 Any non-zero multiple of this column The first three compo­ resents the same plane.  nents describe 
a vector normal to the plane and Thus the dot product of the transformed point and the fourth is related 
to its distance from the plane is the same as the dot product of the orig­origin. inal point and plane. 
The relationshipof a Permission to make digital or hard copies of part or all of this work or personal 
or classroom use is granted without fee provided that copies are not made or distributed for profit or 
commercial advantage and that copies bear this notice and the full citation on the first page. To copy 
otherwise, to 237 republish, to post on servers, or to redistribute to lists, requires prior specific 
permission and/or a fee. Siggraph 77, July 20-22 San Jose, California point lying on a plane is preserved. 
 Suppose we are given three points and we wish to determine the components of the plane vector through 
them. That is, we wish to solve for a, b, c, d in the equation:  Consider a fourth point not in the 
plane of the other three. Its dot product with the desired plane vector will then be non-zero. We will 
call it q. The resulting equation is then:  This equation may be solved by multiplying both sides by 
the adjoint of M. The adjoint is the transpose of the matrix formed from the co-factors of the original 
matrix. The co-factor of an element of a matrix is found by erasing the row and column containing the 
element and computing the determinant of the remaining smaller matrix, finally flipping the sign if the 
sum of the row and column indices of the element is odd. Thus the co-factor of the x4 term of M is: 
 The product of a matrix and its adjoint is the identity matrix times the determinant of the original 
matrix. The product of the adjoint with the right side of the equation is just q times the right hand 
column. Our equation is now:  Now, since any non-zero multiple of a plane vector represents the same 
plane, we can neglect the q and det M terms above. Finally, note that the co-factors do not contain any 
compo­nents of the arbitrarilychosen fourth point. This whole process can be representedin a short­ hand 
notation:  This is simply a generalizationof the more famil­iar shorthand notation of the cross product 
of two vectors in ordinary three space. The only problem that could arise is if the matrix M were singular. 
This only occurs if the three original points are co-linear, whereupon there is no solution. In this 
case, the four co-factors are all zero. We can take the appearance of four zeros when looking for a plane 
through three points as an indication that the three points were co-linear. There is a similar mechanism 
for determining the point of intersectionof three planes. That is, the homogeneous coordinates of the 
point of intersection is:  Again, the appearance of four zeros when solving for the point of intersection 
indicates that the three planes to not have a single common point. They, in fact, intersect on a line. 
 THE HOMOGENEOUS LINE REPRESENTATION We shall now construct a homogeneous rep­resentation of lines in 
3D taking the form of a 4x4 matrix we shall call L. It will have the property that any scalar multiple 
of it represents the same line. In addition, if a point vector is multipliedby L, a result of four zeros 
indicates that the point is on the line. The inspiration for this formulation comes from the Grassmann 
coordinate systems described in [2].  First re-consider the problem of finding the plane through three 
points. If the four co­factors in the solution are all zero then the three points were co-linear. We 
can re-interpret this as a condition upon a third point which will make it co-linear with two others. 
Thus for two given points P1 and P2, a third point is co­linear if:  238 intersection of the line with 
the plane:  we can write the four equations in matrix form:  The above anti-symmetricmatrix is then 
our desired line representation,L. Any non-zero multiple of L will still represent the same line. If 
a point is multiplied by L and four zeros result then the point is on the line. Furthermore, if the point 
is not on the line, the four coordinates obtained will be the same values obtained if all three points 
were solved for their common plane. That is, they will be the components of the plane common to the 
point and the line:  We need only to transpose the row vector to get the plane vector in its more familiar 
column format. There is an analagous process for generating the matrix representing the line formed 
by inter­ secting two planes. Given planes 1 and 2, the condition that a third plane contains their 
line of intersection is:  That is, the four equations must be satisfied:  The matrix K is an anti-symmetricmatrix 
which is a homogeneous representationof the line of inter­section of the two planes. Any non-zero multiple 
of K represents the same line. The product of K and any other plane vector will yield four zeros if 
the line is contained in the plane. If the line is not contained in the plane then the product will 
yield the homogeneous coordinates of the point of We need only to transpose the point vector to get 
 it in the more familiar row form. There is one somewhat surprising fact, however. For a given line, 
the matrix L formed by two points on the line is not the same as the matrix K formed by two planes 
intersectingon the line. We will now show this. THE DUAL LINE REPRESENTATION We first take note of 
another interpretation of the matrix L. Since each column yields a zero when multiplied by a point oh 
the line we can think of it as a plane containing the line. Similarly each row of K can be thought 
of as a point on the line which it represents. Thus L consists of four planes containing the line rep­resented 
by L and K consists of four points on the line represented by K. Let us take any three planes of L and 
attempt to find the point common to them. Since we know that the planes intersect, not at a single point, 
but at a line we expect to get four zeros.  In order to make x=y=z=w=0, as we know must be the case, 
we are forced to the conclusion that either s=q=p=0 or pu-qt+sr=0. By a similar operation on other choices 
of columns of L we find that the latter choice is correct, Thus, to reiterate, for any matrix L constructedfrom 
two point vectors to represent the line connecting them, the six coordinates will always satisfy the 
relation:  Given this relation we can construct the following matrix product:  The middle matrix is 
just L. The product is all zeros either identically or by virtue of relation 239 (*). How can we interpret 
the left hand matrix? Since each row multiplied by L yields four zeros each row must be a point on the 
line. The left hand matrix must then be the same as K, that is, four points on the line stacked into 
a 4x4 matrix. The matrix K thus contains the same numbers as the matrix L, they are just arranged differently. 
We can now match the names of the coordinates with their values if calculated as the intersectionof two 
planes:  Thus the homogeneous representationof a line exists in two dual forms generated by joining 
two points and by intersecting two planes. The six coordinate points generated in each case satisfy equation 
(*). DISTANCE MEASUREMENTS To further increase intuitive feel for the meaning of these six coordinates 
let us see where a given line intersects the plane at infinity. We multiply the K form of the line with 
the plane at infinity and get:  The intersection is the point at infinity (-s -q -p 0). That means 
that the 3D vector (s q p) points parallel to the line. Now let us determine the plane containing the 
line and the origin. We multiply the L form of the line with the origin and get:  This means that the 
3D vector (-r t -u) points perpendicular to this plane. The dot product of these two vectors is zero: 
this is just relation (*). Thus (s q p) lies in the plane containing the line and the origin. If we 
 compute the cross product of the two vectors we will get a third vector which is perpendic­ular to 
the line and pointing directly toward it.  By making use of (*) it can be shown that the length of T 
is  We can now compute the perpendiculardistance, D, from the origin to the line. Place the normalized 
T at the origin and scale it up by the factor D. We should now be at the point on the line which is closest 
to the origin.  Multiplying out and solving for D we get:  This is the perpendiculardistance from the 
origin to the line L. TRANSFORMINGLINES A homogeneouspoint is transformed by post­multiplyingby a 4x4 
matrix. A homogeneous plane is transformedby pre-multiplyingby the inverse of the point'transformationmatrix. 
We shall now derive the process whereby a homogeneous line is transformed. This procedure should preserve 
dot products just as the plane transformation does. That is, given the relationship:  we wish the transformed 
quantities to also satisfy the relationship:  We can express the primed point and plane in terms of 
the unprimed by  Combining these  Comparing this with the original point, line, plane relation we can 
state that a solution is:  Matrices which represent quantities which trans­form in this way are called 
tensors. In addition, since the transformationmatrix used is the inverse of the point transformationmatrix, 
it is a contra-varianttensor. By applying the analagous process to the K form of the line we get  This 
is another tensor. This time the trans­formation matrix is the same as the point trans­formation matrix 
so it is a covariant tensor. INTERSECTING LINES We have so far examined the problem of whether a point 
is on a line and whether a line is in a plane. There remains the question of whether two lines intersect, 
and, if so, where. 240 This can be solved by taking the point form of one line and multiplying it by 
the plane form of the other.  Each row of 1, being a point of line 1, will generate a plane through 
that point and through line 2. If the two lines intersect, each of these will be the same plane. The 
plane containing the two lines. Likewise each column of L2, being a plane containing line 2, will generate 
a point at the intersectionof that plane and line 1. If the two lines intersect, each of these will be 
the same point, the point of intersectionof the lines. Thus each row of N is a plane vector for the plane 
common to the lines. Each column of N is a point vector for the intersectionof the lines. N is the outer 
product of the point and the plane:  Since the point of intersectionalways lies in the plane of intersectionthe 
inner product will be zero. This can be calculated as the trace of N. In terms of the components of 
K 1 and L2 the trace of N has the value  Note the similarity to relation (*). For lines which do not 
intersect (skew lines) the trace of N will be proportional to the perpendicular distance between them. 
This can be seen in the following manner. First consider the cross product of the direction vectors of 
the two lines.  This vector will be perpendicular to both lines. A plane having (s3 q3 p3) as its (a 
b c) compo­nents will be parallel to both line 1 and line 2. We can find the particular such plane which 
contains line 1 by solving for di in  The perpendicular distance between the two planes and the perpendicular 
distance between the lines is  If the trace is zero, the lines intersect. If the trace is non-zero, 
the perpendicular distance is as shown. What, then, are the six homogeneous coordinates for the line 
along which this distance is measured? We already have the direction of the line as (S3 q3 3 It remains 
to find r3, t3, and U3. This can be accomplishedby using the three facts that line 3 intersects line 
1, line 3 intersects line 2, and the coordinates of line 3 must satisfy relation (*).  These three 
equations may then be solved for r3, t3,and u3.  CONCLUSION The line representationdeveloped here can 
be used to solve many geometric problems in three dimensions. Its form, however, does lead to much redundant 
calculation for many problems of interest. Its main use may therefore be as a conceptual tool to generate 
formulas for desired geometrical quantities which are then simplified based on other knowledge of the 
problem. REFERENCES 1. Newman, W. and Sproull, R. Principles of InteractiveComputer Graphics, McGraw-Hill, 
1973, pp. 467.  2. Hodge, W.V.D. and Pedoe, D. Methods of Algebraic Geometry, Cambridge University Press, 
1968, pp. 286.   This yields four equations all of which can be shown to have the common solution 
 Similarly, the plane parallel to line 1 which contains line 2 has  The perpendicular distance of each 
of these planes to the origin is 241 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563901</article_id>
		<sort_key>242</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>43</seq_no>
		<title><![CDATA[Shadow algorithms for computer graphics]]></title>
		<page_from>242</page_from>
		<page_to>248</page_to>
		<doi_number>10.1145/563858.563901</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563901</url>
		<abstract>
			<par><![CDATA[Shadows are advocated for improved comprehension and enhanced realism in computer-synthesized images. A classification of shadow algorithms delineates three approaches: shadow computation during scanout; division of object surfaces into shadowed and unshadowed areas prior to removal of hidden surfaces; and inclusion of shadow volumes in the object data. The classes are related to existing shadow algorithms and implementations within each class are sketched. A brief comparison of the three approaches suggests that the last approach has the most appealing characteristics.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[computer graphics]]></kw>
			<kw><![CDATA[hidden-surface removal]]></kw>
			<kw><![CDATA[raster displays]]></kw>
			<kw><![CDATA[shading]]></kw>
			<kw><![CDATA[shadows]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P86300</person_id>
				<author_profile_id><![CDATA[81100447047]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Franklin]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Crow]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Texas at Austin, Austin, Texas]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>806007</ref_obj_id>
				<ref_obj_pid>800196</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Appel, A., The Notion of Quantitative Invisibility and the Machine Rendering of Solids, Proceedings ACM 1967 National Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Appel, A., Some Techniques for Shading Machine Renderings of Solids, 1968 SJCC, AFIPS Vol. 32.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Appel, A., On Calculating the Illusion of Reality, IFIP 1968.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>362739</ref_obj_id>
				<ref_obj_pid>362736</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bouknight, W. J., A Procedure for the Generation of 3-D Half-Toned Computer Graphics Presentations, CACM, Vol. 13, no. 6, Sept. 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bouknight, W. J. and Kelley, K., An Algorithm for Producing Half-Tone Computer Graphics Presentations with Shadows and Moveable Light Sources, 1970 SJCC, AFIPS Vol. 36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Bui Tuong Phong and Crow, F. C., Improved Rendition of Polygonal Models of Curved Surfaces, Proc. of the 2nd USA-Japan Computer Conf., 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360354</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Clark, J. H., Hierarchical Geometric Models for Visible Surface Algorithms, CACM, Vol. 19 no. 10, Oct. 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Crow, F. C., The Aliasing Problem in Computer-Synthesized Shaded Images, Dept of Computer Science University of Utah, UTEC-CSc-76-015, March 1976. (abridged version to appear in CACM)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569954</ref_obj_id>
				<ref_obj_pid>800193</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Newell, M. G., Newell, R. G. and Sancha, T. L. A Solution to the Hidden-Surface Problem, Proceedings of the 1972 ACM National Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Newell, M. G., The Utilization of Procedural Models in Digital Image Synthesis, Department of Computer Science, University of Utah, UTEC-CSc-76-218, Summer 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. E., Polygon Sorting by Subdivision: A Solution to the Hidden-Surface Problem, Unpublished, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. E., Sproull, R. F. and Schumaker, R. G., A Characterization of Ten Hidden-Surface Algorithms, Computing Surveys, Vol. 6, No. 1, March 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SHADOW ALGORITHMS FOR COMPUTER GRAPHICS Franklin C. Crow University of Texas at Austin Austin, Texas 
 ABSTRACT Appel [3] and then Bouknight and Kelley [5] have Shadows are advocated for improved comprehension 
demonstratedsolutions to the shadow problem which and enhanced realism in computer-synthesized are discussed 
in this paper in the context of a images. A classification of shadow algorithms de­ classificationscheme 
for shadow algorithms. lineates three approaches: shadow computation Three classes of solution are currently 
identifi­ during scanout; division of object surfaces into able (there may be further undiscovered classes). 
shadowed and unshadowed areas prior to removal of Appel, Bouknight and Kelley have shown solutions hidden 
surfaces; and inclusion of shadow volumes of one class and algorithms suggesting the other in the object 
data. The classes are related to two classes have been proposed but not yet imple­ existing shadow algorithms 
and implementations mented. within each class are sketched. A brief compari­ son of the three approaches 
suggests that the last The first class of algorithm,demonstrated by approach has the most appealing characteristics. 
Appel, Bouknight and Kelley, detects shadow boun­ daries as the image is produced by a raster-scan. KEY 
WORDS AND PHRASES: computer graphics, hidden- The edges of cast shadows are found by projecting surface 
removal, shadows, shading, raster displays potential shadowing polygon edges onto the surface being scanned. 
Shadow edges thus formed are then CR CATEGORIES: 8.2 projected onto the image plane. Upon crossing a 
shadow edge, the color of a scan segment is changed appropriately. INTRODUCTION A second class of algorithm 
involves two passes A major deficiency in most computer-synthesized through a hidden-surface algorithm,or 
perhaps a shaded images to date has been the lack of sha­ single pass through each of two differing algo­ 
dows. Although shadows are unneeded when the rithms. The first pass distinguishes shadowed and light 
source is coincident with the eyepoint, a unshadowed surfaces and divides partially shadowed fact which 
was used to advantage in many early surfaces by determininghidden surfaces from a implementations,many 
of the more pressing appli­ viewpoint coincident with the light source. The cations for realistic images 
(eg. spacecraft dock­ colors of shadowed surfaces are then modified and ing and aircraft landing simulators) 
require sun­ a second pass operates on the augmented data from lit images. Quite realistic images of 
scenes the observer's viewpoint. which should contain shadows are now made, but the success of these 
images relies on the assump- The third class of shadow algorithminvolves cal­ tion of a diffuse light 
source such as a cloud­ culating the surface enclosing the volume of space masked sun. swept out by the 
shadow of an object, its umbra. The umbra surface is then added to the data and There are situations 
in which shadows can be im­ treated as an invisible surface which, when pier­ portant. A cast shadow 
may make an important ced, causes a transition into or out of an object piece of equipment virtually 
invisible under ac­ shadow. tual conditions even though it shows clearly in a simulation without shadows. 
Applications of A more complete explanation of the three classes computer graphics to architectural siting 
prob­ follows with suggested implementationsin each lems and environmental impact investigations class. 
These will be preceded by remarks on could require the calculation of shadows for modeling of the light 
source and followed by an evaluating the need for airconditioningor the attempted comparison of the practical 
difficulties availabilityof solar energy. Most importantly, in implementing the three approaches. shadows 
provide valuable positional information; the shadow cast by one object on another can clarify otherwise 
ambiguous spatial relation- MODELING THE LIGHT SOURCE ships. Moreover, shadows pose an interesting problem; 
they should receive more attention than Light sources are generally modeled as either they have been 
getting. points or directions. However, an actual light Permission to make digital or hard copies of 
part or all of this work or personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that copies bear this notice and the full 
citation on the first page. To copy otherwise, to republish, to post on servers, or to redistribute to 
lists, requires prior 242 specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California 
 source has a finite size, a perhaps irregular shape and a definite position in space relative to the 
objects to be represented. Light sources of finite size cast shadows involving an umbra and penumbra. 
The umbra is that part of the shadow space which receives no light from the source; the penumbra, that 
part which receives light from some part of the source but not all of it. Thus there is a dark central 
area to any such shadow sur­ rounded by a border area in which a smooth change from shadowed to unshadowed 
takes place. For an irregularly shaped light source the penumbra could be approximated by a linear variation 
in shade over a strip of fixed width around the periphery of any umbra. Calculating a penumbra can be 
ex­pected to significantly increase the effort neces­ sary to represent shadows. Therefore, a point 
light source or one infinitely far removed (speci­ fied by a direction only) will be assumed. Shadow 
boundaries are determined by projecting the silhouette of one object onto another. The type of projection 
which may be used is dependent on the position of the light source. The easiest light source for which 
to calculate shadows is one that is infinitely far removed since shadow boun­ daries may be found by 
an orthographic projection. On the other hand, the calculation of shadow boun­ daries for a light source 
which has a position in the object space varies in difficulty with the lo­ cation. If the source lies 
outside the field of view, shadow boundaries can be calculated by using the same sort of perspective 
projection used for image display. However, when the light source lies within the field of view, different 
methods must be used. Since the conventional perspective transformation is accurate only for a limited 
 field of view, either the space must be divided into sectors radiating from the light source, in which 
the perspective transform can operate, or more complicated three-dimensionalgeometric meth­ ods must 
be used. Projective transforms provide convenience and efficiency. However, it is always possible to 
 define shadow boundaries in the object space by using the light source position and the object silhouette 
to define a surface and then calculat­ ing the intersection of that surface with other objects. CLASS 
ONE: SHADOW COMPUTATIONDURING SCANOUT Appel [2,3] and then Bouknight and Kelley [5] have shown methods 
for rendering shadows which calcu­late shadow boundaries while scanning the image. Appel detects shadow 
boundaries by extending his notion of quantitativeinvisibility. Quantitative invisibility is a count 
of the number of surfaces hiding a vertex (polygonal objects are assumed). Therefore, a line segment 
is visible only if all points on it have a quantitative invisibilityof zero. Changes in quantitative 
invisibilityalong a segment are detected by Appel's hidden surface algorithm and only the visible portions 
are drawn. This method yields a line drawing. Shadowed surfaces are determined during a scanning procedure 
which is also used to shade the line drawing. The scan is executed by generating "cut­ting" planes through 
the eyepoint which intersect  Figure 1: ABE defines a "cutting plane" in Appel's algorithm. Edges of 
polygon 1 are projected onto polygon 2 to form shadow boundaries which are then projected onto the image 
plane. the picture plane in equally-spacedhorizontal lines (fig. 1). A set of scan segments is defined 
by the intersection of visible lines and a cutting plane. The quantitativeinvisibilitywith respect to 
the light source (previously computed for all visible vertices) is then used to determine those segment 
parts which lie in shadow. Further detail is available in Appel's publications [1,2,3]. Bouknight and 
Kelley developed a similar method for shadow detection [4,5]. However, they en­ joyed an advantage in 
that their hidden-surface algorithmwas already based on a scanning process. A secondary scan was used 
to detect shadow boun­ daries calculated by projecting edges upon the surfaces being scanned. The primary 
scan followed a raster pattern in image space which generated the secondary scan, the corresponding 
path across the visible surface in object space. Therefore, shadow edges occurred where edges of other 
poly­ gons projected onto a secondary scan segment. A procedure for finding all polygons which could 
 cast shadows on a given polygon was used to dimin­ ish the edge-projectioncomputation. This routine 
 transformed all polygons to a pseudo-spherical coordinate space with its origin at the light source. 
Polygons were then tested for overlap and a linked list was formed for each polygon, enab­ ling the 
other polygons which might cast shadows on it to be easily found (In figure 1, polygon 2 would be linked 
to polygon 1). An expansion of this overlap test leads to the second class of algorithms as will be 
seen below. The general approach exemplifiedby Bouknight- Kelley can be analyzed as two basic operations: 
 (1) the shadow priority ordering of polygons and  (2) the calculation of projected shadow boundar­ies. 
It is worth noting that these two opera­tions are independent of the hidden surface algo­rithm used for 
display and this could be applied to virtually any polygon-based algorithm.  Many variations on the 
Bouknight and Kelley algo­ rithm can be developed. For example, the compu­ tation for their pseudo-spherical 
overlap test grows as the square of the number of polygons. It would thereforebe advantageous to divide 
the viewable object space into sectors radiating from the light source position. This would allow all 
 polygons in a sector to be sorted to a shadow priority order without reference to other sec­ tors. 
Shadow priority determination requires a special sort such as the one used by Newell et al [9]. The 
behavior of this algorithm (also obey­ ing an N-squared growth law) is discussedby Sutherland et al 
[12]. Under favorable conditions, sectorization can change the N-squared growth law of the Bouknight- 
 Kelley (or Newell et al) priority scheme to a linear growth law. The growth of the sectored scheme 
is proportionalto S (N/S)**2 where S is the number of sectors and N is the number of poly­ gons (as 
long as the general distribution of poly­ gons in space remains similar). If N/S is held constant by 
increasing the number of sectors pro­ portionallywith the number of polygons, the priority stage obeys 
a linear growth law. How­ ever, this growth rate is complicatedin the limit by the fact that when sectors 
become so small that a high percentage of polygons overlap sector boun­daries, the effectivenumber of 
polygons increas­es. This is due to the fact that a polygon over­ lapping two sectors must be considered 
in both. However, the potentiallinear growth rate makes this an attractive approach both here and in 
the design of sectorable algorithms in general. The second basic operation, the calculation of shadow 
boundaries, requires a process akin to clipping. The polygon under considerationmust be used as a window 
against which polygons of a high­er priority are clipped. The growth rate of this operation is proportional 
to the product of the number of edges in shadowed polygons and the num­ber of edges in higher priority 
polygons, again an N-squared growth rate. However, sectorization can again provide an overall linear 
growth rate under favorable conditions. (It should be noted that the linked list used here by Bouknight 
and Kelley is in some sense an optimized sectorization.) Two factors can substantiallyreduce the constant 
of proportionalityin the growth law: (1) shadow cal­ culation need only be carried through for visible 
polygons and (2) the calculation may terminate when a polygon is discovered to be completely shadowed. 
 In closing this section, it should be reemphasized that in all shadow algorithms, a large amount of 
 computation can be saved by considering only the silhouette of a shadowing object instead of each of 
its polygons individually. This restricts searching to only those edges which cause visible shadow 
boundaries. A SECOND CLASS: THE TWO-PASS APPROACH It would appear that a hidden-surface algorithm 
could be used to detect which surfaces are hidden from the light source as easily as those which are 
hidden from the eye. However, to be useful, the algorithm must yield information which can be used 
to generate an image, as seen from the eyepoint, in a subsequent pass. This restriction limits the 
class of applicable algorithms. Sutherland, Sproull and Schumaker proposed that hidden-surface algorithms 
could be divided into object-space algorithms and image-space algorithms [12]. This distinction turns 
out to be important since the determination of shadow boundaries must be made in object space so that 
the resulting in­ formation can be merged into the data to be sent to the display algorithm. Thus image-spacealgo­ 
rithms which depend on the limited resolution of the display medium to ease the determination of hidden 
surfaces are inappropriate for this appli­ cation. The algorithms characterizedby Sutherland et al 
[12] as operating strictly in object space all suffer from discouraginggrowth laws (computation increasingwith 
the square of the amount of data). Furthermore,where polygons are considered, they are not treated as 
entities but broken into indi­vidually treated sides. To create shadows, the polygons must be treated 
as entities so that they may be divided by shadow boundaries and returned to the data base as smaller 
polygons to be fed to the display algorithm. Eliminating the object­space algorithms leaves the algorithm 
shown by Newell, Newell and Sancha [9]. This algorithm provides many useful techniques for splitting 
 polygons and determining overlap but the eventual determination of what part of which surfaces are 
hidden is done by overwriting in image space. Sutherland has proposed another algorithm which is more 
applicable to the problem [11]. Using clip­ping techniques, a binary sort is executed sending polygons 
and parts of polygons lying on one side of a line out on one stream and those lying on the other side 
off on a different stream. Such a pro­cess is, of course, exactly what is needed for determining divisions 
between shadowed and unsha­dowed parts of surfaces. Furthermore, Suther­land's algorithm holds the promise 
of a reason­ able growth rate. Since the algorithmoperates by recursive subdivision of the viewed space 
via a 2-dimensional binary sort of the data, an N log N growth law may be achievable. Sutherland also 
proposed improvementsbased on considering only "contour" edges in the subdiv­ision process. Contour edges 
are those edges which separate frontfacing and backfacing polygons at those places where the surface 
curves behind itself or else edges which lie at the extremes of the surface, for surfaces which don't 
close on themselves [1]. Thus any area lying within the bounds of a set of contour edges for a single 
sur­face can be treated as a unit assuming that the bounded surface is the frontmost surface in the bounded 
area. Clark has proposed a general scheme for approach­ing hidden-surfacealgorithms which involves re­cursive 
descent through a hierarchical data des­cription [7]. The combination of this approach with Sutherland's 
notion of clipping to contour edges appears to hold promise for an interesting shadow algorithm. If environmental 
restrictions are imposed so that objects must be broken into linearly separable sub-objects and groups 
of such objects may also be linearly separated, then an algorithm may be implemented along the following 
lines. The first step of this algorithm would use sort­ing techniques akin to those of Newell, Newell 
and Sancha to establish a front to back priority ordering of the surfaces under consideration. The hierarchical 
approach proposed by Clark may be superimposed to first order otjects or groups of objects, then to establish 
an order within such objects or groups. Newell has recently suggested an algorithm for sorting objects 
to a depth prior­ity which could be applied here [10]. Note that, for purposes of shadow detection, 
the silhouette of an object may be used to define a "blot", or anti-window,under a perspective pro­jection. 
Anything lying within the blot and far­ther from the light source is clearly in shadow. Therefore, the 
algorithm can proceed by augmenting a collection of blots using the silhouette of each convex sub-object 
in turn. Moving away from the light source, surfaces hidden by the blot are marked as shadowed. Other 
surfaces contribute the unshadowed portion of their silhouettes to the collection and are themselves 
clipped into shadow­ ed and unshadowed portions. Finding object silhouettes for polygonal objects is 
eased by a data structure providing links be­tween adjacent polygons. Such a structure is de­tailed in 
[6,8]. Since the silhouette is formed solely from the contour edges and all contour edges on a convex 
surface must lie on the silhou­ette, the determinationof the silhouette consists of finding the closed 
loop of contour edges. Strings of contour edges may be formed straight­ forwardly. First, all polygons 
must be tagged as frontfacing or backfacing from the light source point of view. Secondly, the neighbor 
polygons for each frontfacing polygon must be checked; where backfacing adjacent polygons are found, 
the associated edge must be tagged as a silhouette edge. Lastly, silhouette edges may be linked to­ 
gether by using the adjacent frontfacing polygons to search for additional silhouette edges connect­ 
ed to a known silhouette vertex. For a convex object, a single such string of edges will form the silhouette 
(fig. 2).  By using the scheme proposed by Clark, the calcul­ ation of some object silhouettesmay be 
avoided. Following the hierarchical division of the data (groups, objects, sub-objects), tests using 
 "bounding boxes" may be used to determine which groups may overlap from the light source point of 
view. The bounding box is defined by the range of the object vertices over height and width (fig. 3). 
Any time the bounding box of an object is found to lie totally within the silhouette of an object of 
higher priority, the first object is in shadow. Similarly, if the bounding box of a convex object (consistingof 
a single sub-object) fails to over­ lap any others then the object is clearly not in­volved in any shadows. 
In these cases, there is no reason to compute the silhouette. The shadow algorithmmay be driven by 
the hierar­ chical organizationof the data. Thus groups of objects may be processed in priority order, 
clos­ est group first. Within each group, objects will be treated in priority order and within each 
ob­ 245 ject, sub-objects will be treated in priority order. Overlap tests can first determine whether 
groups may interact. If so, the bounding boxes must be passed to the next lower level of the hierarchy. 
Overlap tests are then applied to the objects within the group and finally to the sub­objects of each 
object. If the bounding box of a sub-object overlaps none of the bounding boxes passed down through the 
hierarchy, it may be ig­nored. Otherwise its silhouette is computed.  Having computed the silhouette 
of the highest priority sub-object for which it was required, intra-object shadow boundaries may be computed. 
This can be done by clipping the polygons of lower priority sub-objects to the silhouettes of higher 
priority sub-objects. If any lower priority sub-object is completely shadowed, it may be tagged as such 
and ignored in subsequent overlap tests. Partially shadowed sub-objects are clipped into shadowed and 
unshadowed portions; partial silhouettes are then computed based only on the unshadowed portion. Completely 
unshadowed sub-objects merely have their silhouettes calcul­ated. As the algorithm works its way down 
the priority­ordered list of objects, a minimal set of convex blots is built up, each blot with an associated 
bounding box. As lower priority objects are treated, they will first be clipped by the higher priority 
blots then the remaining polygons will be used to compute partial silhouettes to be added to the set 
of blots. It may be useful to include a provision to absorb a set of blots into a single one in the case 
where a lower priority sub-object is large enough to provide an envelop­ing silhouette. However, the 
overhead in check­ing for this case may well prove to outweigh the benefits. Where several groups of 
objects overlap, an ex­tremely large set of blots is likely to have been built up by the time lower priority 
groups are treated. To avoid undue growth of computation, the set of blots and untreated data should 
be sectored so that spatially separate areas may be treated independently. Using the information provided 
by the bounding boxes, sectorizationbe­comes trivial. It may even be advantageous to resector several 
times as the collection of blots develops. Also, sectoring based on the bounding boxes of lower priority 
objects would al­low blots which will no longer be needed to be dis­carded. Of course this approach 
depends heavily on a well­conditioned environment (convex sub-objects). It is not clear whether (1) the 
algorithm could be easily extended to the general case and (2) whether data generation and object modelling 
techniques could be forced to always deliver such well-condi­tioned data. In general, the testing sequences 
described above will increase in cost with the square of the number of objects involved. However, the 
division of the data into a hierarchical arrangement and the use of sectoringwhen the number of blots 
getslarge should minimize the number of necessary tests. Again it must be pointed out that if the light 
source lies in or near the field of view from the eye position, the space will have to be sectored for 
shadow de­termination so that perspectiveprojections may be used. This approach counts heavily on the 
ease of determiningbackfacing and frontfacing polygons and on overlap tests both of which are much more 
easily done after a perspective transform. Once the shadowed polygons have been determined, any hidden-surface 
algorithm may be used to gener­ate the eyepoint image from the augmented data. Therefore, an advantage 
to the two-pass approach is that the process of defining shadows is totally in­dependent of the later 
process of picture genera­tion; the shadow process may run concurrently in pipeline with the picture-generationprocess. 
Note that, given two processors, there is little point in making the shadow detection algorithm more 
ef­ficient than the display algorithm if they are to be run separately and concurrently. Also, given 
a static environment and a fixed light source, sha­ dows need be computed only once for a large num­ber 
of eyepoint positions. In that situation, the efficiency of the shadow algorithm becomes much less important. 
 THE THIRD CLASS: PROJECTED SHADOW POLYGONS Shadows may be defined by the projection of edges onto surfaces 
as in the first and second classes or they may be defined by the volume of space they encompass. The 
last class of shadow algorithm in­cludes shadow volumes in the hidden-surface compu­tation by adding 
their surfaces to the data. As­suming a polygonal object, the shadow surface is given by planes defined 
by contour edges and the light source position. Each such edge defines a polygon whose boundaries are 
the edge itself, the two lines defined by the light source position and the endpoints of the edge and 
the bounds of the field of view (fig. 4). The sense of the polygon must be maintained so that the near 
surface of a shadow volume (frontfacing polygons) may be dis­ tinguished from the far surface (backfacing 
poly­ gons). Thus the polygons facing the light source plus the set of projected shadow polygons for 
an object define its shadow volume. Shadow polygons may be treated just like the rest of the data when 
applied to a scanning hidden-sur­ 246  face algorithms; only the shading for visible sur­faces must 
handled differently. Shadow polygons are themselves invisible, thus they do not count in the determinationof 
visibility. However, the depth order of shadow surfaces and visible surfaces determines shadowing. A 
frontfacing shadow surface puts anything behind it in shadow while a backfac­ing shadow surface cancels 
the effect of a front­facing one. For example, a post or column might cast a shadow surface consisting 
of a single poly­gon pair. Any surface lying between those two sha­dow polygons would be in shadow while 
surfaces ly­ing in front of or behind both polygons would be shaded normally. If the frontmost shadow 
surface is backfacing, then everything in front of it is in shadow; if the rearmost shadow surface is 
frontfacing, then ev­erything behind it is in shadow. These cases can occur where the eyepoint is in 
shadow or a surface casts a shadow over a large part of the field of view. Therefore, surfaces are shadowed 
whenever they lie in front of a backfacing frontmost shadow polygon or the surface depth count is such 
that more frontfacing than backfacing shadow polygons have been pierced. Shadow boundaries are formed 
where a visible surface intersects a shadow poly­gon. Modificationof a scanning hidden-surfacealgorithm 
 to handle shadow polygons involves changing only the inner loops where shading must be calculated. 
 Two properties of shadow polygons may be used to simplify computation. First, shadow polygons are 
invisible. Therefore, scan lines involving only shadow polygons may be ignored. Second, shadow polygons 
formed by projection of contour edges can­not intersect one another (as long as a single light source 
is used). Therefore the depth order­ ing of such polygons is constant. Using a scanning algorithm of 
the Bouknight variety (see [4,12] for detailed views of this type of al­gorithm) shadow polygons may 
be treated just as other polygons through the y-sort and x-merge pro­cedures. Scanning algorithms generally 
require maintaininga depth-sorted list of all scan seg­ments which would be pierced by a ray from the 
eye­ point through the current position on the scanline. Shadow polygons will frequently cause quite 
lengthy scan segments greatly increasing the average depth complexity over an image. As Sutherland 
et al [12] pointed out, increased depth complexity may well severely hamper the performance of scanning 
algo­ rithms. Shadow polygons, however, need be considered only under certain circumstancesduring the 
production of scan segments. The fact that shadow polygons may not intersect allows profitable use of 
scanline to scanline coherence. The depth ordering of sha­dow polygons will change only when new polygons 
are added or old ones deleted as the scan moves down the image. Thus the process of rebuilding and up­dating 
the depth-sorted list of shadow polygons can be largely eliminated. The list need only be built where 
object segments occur. Therefore, a scanline with no object segments can be ignored. Since the depth 
ordering doesn't change, it will only be necessary to calculate the depth to a shadow sur­ face when 
it must be compared to the depth of a visible surface. The priority list of shadow polygons need only 
be searched when the visible surface in the image changes. Once it is discovered which shadow poly­gons 
bound the currently visible surface (in depto then only those polygons need be checked for pos­sible 
intersections. Therefore, although there may be considerable depth complexity due to shadows, a depth 
complexity of two to three shadow surfaces should be all that really affect computing time. However, 
many of the images made today have an av­erage depth complexity of less than three. Thus a significant 
increase in the time needed for the scanning process may result from the addition of shadow polygons. 
However, this effect may prove to be less significant as more highly complex en­vironments are attempted. 
 A COMPARISON OF THE THREE CLASSES Comparisons can be made with respect to the addi­tional difficulty 
involved in representing shadows using each of the above approaches. Three bases 247 for comparison 
are used: the additional data stor­ age required; the additional computation required; and the difficulty 
of the necessary additional software. A scanning hidden-surfacealgorithm is assumed for this discussion. 
 At first glance only the second and third classes of algorithm appear to require additional data storage. 
The two-pass approach requires that sur­ faces be split along shadow boundaries, or at least that shadow 
boundaries be included in the data; the shadow polygon approach requires the storage of perhaps numerous 
shadow polygons. However, neither of these two classes requires the entire scene description to be available 
for the hidden­ surface calculation; backfacing surfaces and data lying outside the field of view may 
be discarded. On the other hand, the first class of algorithm requires that all object data be available 
in its original form at all times so that projected shadow boundaries may be calculated during scanout. 
use as temporary Therefore, the space left over for storage by later stages of the hidden-surface It 
must be con­ algorithm is severely reduced. cluded that the two-pass approach requires least additional 
storage, shadow polygons require some­what more and calculation of shadows during scanout  requires 
by far the most. Assuming that it will always be more efficient to use only silhouettes for calculating 
shadow bound­aries, the projected shadow polygon approach ap­ pears to cause the smallest increase in 
necessary computation. The definition of shadow polygons is straightforwardonce silhouette edges are 
found, and the additional computation in the scanning pro­cess is minimized by taking advantage of the 
spec­ial properties of shadow polygons. Furthermore, both other approaches require methods which obey 
less desirable growth laws. Shadow calculation during scanout requires additional computation to determine 
which surfaces may cast shadows on each other and then requires the calculation of the lines separating 
shadowed and unshadowed areas by operations on the object-space data. Bouknight and Kelley reported 
roughly doubled computation time to include shadows in very simple scenes. The two-pass approach, in 
its turn, requires an addi­tional solution of the hidden-surfaceproblem. However, since only silhouette 
edges need to be considered, the first pass should be simplified. The complexity of the additional 
software required also appears to be smallest for the projected sha­dow polygon approach. Algorithms 
of both thefirst and second classes require significant new soft­ ware. However, it could be argued that 
once a suitable hidden-surface algorithm is available for the two-pass approach, the software for the 
first pass is just a subset of that needed for the second pass and thus no additional software is needed. 
 situation in which a scanning hidden-sur- Given a face algorithm is available, it appears that the 
shadow polygon approach offers the best solution. However, starting from scratch, there is no clear­cut 
best choice. Certainly there is much to be learned by implementingan algorithm of any class.  ACKNOWLEDGEMENTS 
The ideas expressed herein arose, for the most part, in conversations with colleagues while at the University 
of Utah. In particular, Ivan Suth­ erland suggested to me the notion of projected shadow polygons and 
also provided valuable com­ments on an earlier draft of this paper. REFERENCES The Notion of Quantitative 
Invisi­bility and the Machine Rendering of Solids, Pro­ceedings ACM 1967 National Conference. [1] Appel, 
A., [2] Appel, A., Some Techniques for Shading Machine Renderings of Solids, 1968 SJCC, AFIPS Vol. 32. 
 [3] Appel, A., On Calculating the Illusion of Re­ality, IFIP 1968. [4] Bouknight, W. J., A Procedure 
for the Genera­ tion of 3-D Half-Toned Computer Graphics Present­ations, CACM, Vol. 13, no. 6, Sept. 
1970. W. J. and Kelley, K., An Algorithm  [5] Bouknight, for Producing Half-Tone Computer Graphics 
Present­ations with Shadows and Moveable Light Sources, 1970 SJCC, AFIPS Vol. 36. Bui Tuong Phong and 
Crow, F. C., Improved Ren­ [6] dition of Polygonal Models of Curved Surfaces,  Proc. of the 2nd USA-Japan 
Computer Conf., 1975. [7] Clark, J. H., HierarchicalGeometric Models for Visible Surface Algorithms, 
CACM, Vol. 19 no. 10, Oct. 1976. The Aliasing Problem in Computer­ [8] Crow, F. C.,  Synthesized Shaded 
Images, Dept of Computer Science University of Utah, UTEC-CSc-76-015,March 1976. (abridged version to 
appear in CACM) [9] Newell, M. G., Newell, R. G. and Sancha, T. L.  A Solution to the Hidden-Surface 
Problem, Proceed­ings of the 1972 ACM National Conference. [10] Newell, M. G., The Utilization of Procedural 
Models in Digital Image Synthesis, Department of Computer Science, University of Utah, UTEC-CSc­76-218, 
Summer 1975. [11] Sutherland, I. E., Polygon Sorting by Sub­division: A Solution to the Hidden-SurfaceProblem, 
 Unpublished, 1973. [12] Sutherland, I. E., Sproull, R. F. and Schu­maker, R. G., A Characterizationof 
Ten Hidden- Surface Algorithms, Computing Surveys, Vol. 6, No. 1, March 1974.  248 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563902</article_id>
		<sort_key>249</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>44</seq_no>
		<title><![CDATA[Computer art for computer people - a syllabus]]></title>
		<page_from>249</page_from>
		<page_to>254</page_to>
		<doi_number>10.1145/563858.563902</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563902</url>
		<abstract>
			<par><![CDATA[Given the present state of the art, it is easier to introduce and teach computer art to people who have some background in computer science. Although there are many art-oriented systems for non-programmers, a study of the work of these artist-students reveals that their final products do not surpass the work of programmer-artists. Experience in working with artists and non-programmers during the past seven years has repeatedly shown that computer people, with special guidance and instruction, can and do produce professional looking computer art works that rival and often surpass the works of intermediate to advanced artists who engage in this new medium. However, working with Computer Science people poses unique requirements. Although they produce professional looking works within one semester, their orientation is dominantly practical, and often they will abandon their artistic efforts after the conclusion of their course of study, to aim at more practical, job-oriented skills. This paper describes in detail the course objectives, and includes a listing of lecture/discussiontopics, and offers the reader a schedule of week-by-week presentations and explorations for development in laboratory sessions.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[computer art]]></kw>
			<kw><![CDATA[computer art in media]]></kw>
			<kw><![CDATA[design derivation exercises]]></kw>
			<kw><![CDATA[effective art techniques]]></kw>
			<kw><![CDATA[personal computer art]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP309989700</person_id>
				<author_profile_id><![CDATA[81536908356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Grace]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Hertlein]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California State Univ., Chico, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Hertlein, G., "The Programmer as an Artist," Proceedings, A Day of the Computer Arts, NCC&E, New York City, N. Y., June, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[, "The Artist and Computer Art," Proceedings, CCUC/3, Computers in the Undergraduate Curriculum, Georgia State University, Atlanta, Georgia, June, 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[, "The Microfilm Plotter and Computer Art," Proceedings, CCUC/6, Computers in the Undergraduate Curriculum, Texas Christian University, Fort Worth, Texas, June, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[, "Computer Art - A New Course Offering for General Education," Proceedings in the Undergraduate Curriculum, CCUC/8, Michigan State University, East Lansing, Michigan, June, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Franke, Herbert, "Art of the Technical World," Computer Graphics and Art, Volume 1, No. 1, February, 1976, p. 10-11.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hertlein, G., "A Beginning Science of Art," Proceedings, A Day of the Computer Arts, NCC&E, New York City, N. Y., June, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Snow, C. P., The Two Cultures, "Rede Lecture," London, 1959.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Exhibition, CCUC/3, Georgia State Univ., Atlanta, Georgia, June, 1972. ICCH/I, Univ. of Minnesota, Minneapolis, Minn., July, 1973. NCC&E, New York City, N. Y., June, 1973. , CCUC/5 Washington State Univ., Pullman, Washington, June, 1974. Exhibitions A, B, C, Academic Year 1974-75, General U. S. Distribution.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[August Issues, Computers and People, 1974, 1975, 1976, Art Editor, including various papers, articles, since 1970. Volume 1, Numbers 1 - 4, Computer Graphics & Art, Editor, 1976. Vol. 2 in process.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[A Day of the Computer Arts, NCC&E, June, 1973, New York City, N.Y., Special Art Proceedings. Catalog, ICCH/2, International Conference of Computers and the Humanities, Univ. of So. California, April, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Mueller, Robert E., Inventivity, New York: John Day, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Naughton, John; McGowen, Clement; Horowitz, Ellis; Brown, John R., "Session: Structured Programming - Concepts and Definitions," Computer, June, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>578130</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kernighan and Plauger, Elements of Programming Style, New York City: McGraw-Hill, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Hertlein, G., "The Importance of Art Design Techniques and Material Development - Their Effects in Achieving Art Quality in Computer Art," Computer Graphics and Art, Vol. 2, No. 3, August, 1977 -- "Week-by-Week Syllabus, Computers and People, Vol. 26, No. 8, August 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[, "Computer Art: Steps Towards a Measurable Analysis," Computers and People, May, 1974, Vol. 23, No. 5, p. 13-17.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[op. cit., /3/ and Franke, Herbert, "On Producing Graded Black and White or Color Graphics in Combination with a Photographic Technique," Leonardo, 1974, p.333-335.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Computers and the Humanities, Joseph Raben, Editor, Queens College, Flushing, N. Y.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Permission to make digital or hard copies of part or all of this work or personal or classroom use is 
granted without fee provided that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.Siggraph 
77, July 20-22 San Jose, California COMPUTER ART FOR COMPUTER PEOPLE -A SYLLABUS Grace C. Hertlein Associate 
Professor Department of Computer Science California State Univ., Chico Chico, California 95929 ABSTRACT: 
Given the present state of the art, it is easier to introduce and teach computer art to people who have 
some background in computer science. Al­though there are many art-oriented systems for non­programmers,a 
study of the work of these artist-stu­dents reveals that their final products do not sur­pass the work 
of programmer-artists. Experience in working with artists and non-programmersduring the past seven years 
has repeatedly shown that computer people, with special guidance and instruction, can and do produce 
professionallooking computer art works that rival and often surpass the works of in­ termediate to advanced 
artists who engage in this new medium. However,working with Computer Science people poses unique requirements. 
Although they pro­ duce professional looking works within one semester, their orientation is dominantly 
practical, and often they will abandon their artistic efforts after the conclusion of their course of 
study, to aim at more practical, job-oriented skills. This paper describes in detail the course objectives, 
and includes a list­ing of lecture/discussiontopics, and offers the reader a schedule of week-by-week 
presentationsand explorations for development in laboratory sessions. Key Words: computer art, effective 
art techniques, personal computer art, design derivation exercises, computer art in media. Computing 
Reviews category number: 3.4, 3.41. BACKGROUND In 1970 a group of computer art courses were introduced 
by the author as part of the Department of Computer Science curricular offerings: 1. Beginning Computer 
Art for the Programmer /1/  2. Advanced Computer Art for the Programmer  3. Beginning Computer Art 
for the Artist/Non­programmer /2/  4. Advanced Computer Art for the Artist/Non­programmer  Since that 
time the author has taught computer art to hundreds of students from varied disciplines and class levels, 
ranging from Freshmen and Sopho­mores to Master of Fine Arts graduates. /3/ This experience of working 
with diverse types of people has resulted in specific changes in the teaching of computer art. In order 
to "take students where they are," and to enable them to grow in areas of interest and benefit to them, 
some of the above cour­ses have been eliminated, and new offerings substi­ tuted. /4/ Each semester, 
for the past seven years, the author has conducted midterm and final (end of the term) evaluations by 
students of syllabi for the teaching of computer art. As a result of this con­tinued two-way communication,these 
courses now of­fer specific modules of instruction that have proved useful and stimulating over a period 
of time. They form a foundation of emphases that have been retained primarily because of effectiveness,transportability, 
and interest. This paper discusses in detail a thoroughly class­tested computer art course for Computer 
Science people. The course objectives are discussed, as well as the means by which these objectives are 
attained. Bene­fits for Computer Science people are listed in detail. The paper lists lecture/discussiontopics. 
A week-by­week plan for the course is available at no cost from the author. It is hoped that this tested, 
practical approach of teaching Computer Art for Computer People will be useful to other institutions, 
and that it will become a viable curricular offering of Computer Science De­partments in other universitiesand 
colleges. THE BRIDGE OF ART AND SCIENCE The teaching of computer art is a bridge that unites "Art 
and Science." /5/ There are variations in the dominance and subordinance of these elements of Art and 
Science, depending upon the practitioner, the instructor. /6/ Educated in the humanities,the author 
initially placed a dominance on the art aspects of computer art. Teaching as a faculty member of Com­ 
puter Science (rather than Art), and working with hun­ dreds of scientifically-orientedstudents afforded 
a change in attitude, attained perhaps by propinquity. In essence, communication with Computer Science 
people re-programmed the author. At times the new interdisciplinary area of compu­ter art appears to 
be in limbo, and one lives on the "bridge" of Art and Science, rather than on the adja­cent land on either 
side of that bridge. Art depart­ments find the subject too technical. Computer de­partments find the 
area too artistic. They say, "It is not all Computer Science." However, in time, the land between the 
two seemingly opposing ideas of Art 249 and Science /7/ will be developed, and computer art will become 
an accepted, useful, known academic area. NEEDS OF COMPUTER SCIENCE PEOPLE The Computer Science major 
and/or minor has a practical, logical mind that poses unique curricular requirements. There are, however, 
broad ranges of talents and capacities in these students, because of the breadth of the discipline. 
Working with the Curriculum Planning Committee of the department afforded many insights into the "real" 
needs of these students. Many professional curriculum planners do not consider sufficiently the "nature 
of the material" of the students, and seek to form the students in their own image, ra­ther than perceiving 
course offerings that fit the specific parameters of a given discipline and its resultant "programming." 
 In teaching computer art courses for technical people, it was often evident that they were intense­ 
ly interested in the programmingaspects of an artis­ tic problem, and that they were equally interested 
 in practical applications --not just art. Thus working with Computer Science people poses unique challenges, 
in order to reach and hold these stu­ dents. The course then becomes a scientific, logi­ cal approach 
to the creation of art, wherein princi­ ples are sought, and analyses result in precise statements about 
varied aspects of art and creativi­ ty. CHANGES IN CONTENT AND APPROACHES As a result of student evaluations 
of the course, many changes in content and approaches occurred. Stu­ dents asked for shorter lectures, 
with longer discus­ sion periods. The author utilizes a fast half-hour presentation, followed by equal 
discussion/develop­ ment with students. Repeatedly, they asked for more structure in the course, more 
specific assignments, as in other Computer Science offerings. They wanted principles, not recipes. 
They wanted to be part of the planning. In addition, students requested a "har­ der" course, with introduction 
of far more material, more assignments, and firm deadlines. They were not (as Art majors) accustomed 
to a free rein and open­ ended assignments. Computer Science people still experience diffi­ culty in 
parallel-processingthe diverse ideas re­ quired in this course. In other Computer Science classes, work 
proceeded from the simple to the com­ plex, and an assignment was completed before going on to the next 
focus. In this course, several as­ signments run parallel, are interdependent,and completion dates are 
not in unison. Although the beginning courses afforded excel­ lent results artisticallyand programmatically,the 
 advanced courses repeatedly did not produce work that was consudered sufficiently "advanced" by the 
 author, and they were discontinued. However,mater­ ial formerly presented in two semesters is now given 
 in one faster, more difficult course. Integration of interdisciplinarygraphics research and art ma­ 
terials was made part of the exposure course. Stu­ dents how feel they are learning about computer art 
 and gaining an exposure to useful Computer Science techniques. Further, this course serves as an intro­ 
duction to advanced courses in software development and systems displays. THE OUTPUT OF COMPUTER SCIENCE 
PEOPLE Experience in working with hundreds of students has shown that ComputerScience people will produce 
professional-lookingworks consistently in one se­mester, given special guidance and instruction in the 
principles of computer art, /8/ and that their work often surpasses and rivals the work of profes­sional 
computer artists. This has been noted by the comments of thousands of viewers who have seen their work 
in national and international exhibitionsof computer art. The author's experience as Art Edi­ tor for 
Computers and People, as Editor of Computer Graphics and Art, and as chairman of national and international 
art exhibitions /9/ haslallowed scru­tiny of thousands of art works from all over the earth. Further, 
experiences in editing graphics periodicals on computer art /10/ have afforded a familiaritywith new 
artists entering this field, and great familiaritywith the newest techniques. Having access to the newest 
slides of computer art, innumerable catalogs and illustrations, allows presentationof these materials 
in class situations. Students are frequently able to study first-hand new works from overseas, and it 
is common practice to take newly-arrived works to class for enjoyment and analysis. In this way, students 
are able to gain exposure to the most diverse and advanced techniques in computer art. During the academic 
year 1974-75, three con­ current monthly showings of student art consisting of seventy graphics per 
showing were distributed in exhibitions throughout the United States. The exhi­ bitions were made up 
of half student works, half instructor works. The concurrent touring shows were sponsored by Art, ComputerScience, 
and Learn­ ing Resource Departments. The opportunity of shar­ ing their work through exhibitions added 
motivation for these students to produce highly satisfying works of computer art. It is not uncommon 
for these stu­ dents to achieve a personal collection of aesthetic computer art that has meaning for 
them for many years after they have completed the course, and they become computer professionals. 
THE BENEFITS OF A TECHNICAL ART COURSE Some of the benefits of a technically-oriented computer art course 
are briefly discussed: 1. Brainstorming -Experience in brainstorming is achieved in the areas of designing, 
programming, and writing. A cooperative atmosphere that is non­threatening is stressed, and helpful information 
is exchanged in specific laboratory brainstorming sessions. 2. Inventivity -Increased ability to produce 
quickly and spontaneouslyalternatives in designing, programming,writing, material developedment, is at­tained 
by emphasis on inventivityas a "natural" gift or quality. /11/ Inventivityin art, program­ming, problem-solvingis 
analyzed, and augmented by laboratory assignmentsand additional outside class­work. 3. Verbalization-Encouragement 
and develop­ 250 ment of increasedabilitiesto achieve facility in finding and expressing words to describe 
objective and subjective situations and reactions is empha­ sized. In using the computer in the humanities, 
greater precision in identifyingartistic problems and solutions is necessary. Programmerscan quick­ly 
develop verbalization skills with practice, and there is a great need to speak and write, in addi­ tion 
to designing computer systems and programming solutions to problems. 4. Writing Skills -Research, editing, 
wri­ting skills are highlighted throughout the semes­ter. Assistance is given in researching a chosen 
 interdisciplinary (not art) graphics application topic, outliningthe area, and in developmentof a sound 
researchpaper. Special laboratory assis­tance is given in writing, rewriting, and finaliz­ing the definitivegraphics 
research paper. 5. Working Alone and in Team Situations - Experience in working alone to produce personal 
works is emphasized,then augmented by a two-week  period of working on a team project. The need for 
both types of productionis emphasized.  6. Programmatic Growth -Reviewing previous programming experiences 
is accomplishedearly in the semester, and known material is integrated with a new system to achieve art 
graphics. (FORTRANis  a prerequisite to this course.) A study of alter­native methods of programming 
is stressed. An in­troduction to Structured Programming is given and integrated with later subroutine 
development. /12/ 7. Principles of Programming-A text by Ker­nighan and Plaugher /13/ is used in a lecture/discus­ 
sion session. The elements of programming style are thoroughlyreviewed'anddiscussed with students. 8. 
Software Development -The latter two areas are integrated with an analysis of varied ap­proaches to graphics 
software development. Graphic needs of varied disciplinesare reviewed, followed by assignmentsin writing 
new.multi-purpose subrou­tines to be used by other people. New subroutines are written in a clear, understandablemanner 
that  accords with the present system.  9. Appreciation for Diversity -Acknowledg­ment of the need 
for varied approaches to design­ing, programming, final development is explored  in group critiques 
in these areas. MinimizingNIH (Not Invented Here) is emphasized,with an exposure in which there is a 
keen appreciation for the varied ways in which people program and produce art. 10. Appreciation of Self 
as a Creative Person - An analysis of creativity is conducted throughout the semester, and a study of 
the elements of crea­tivity in varied disciplines is intensely reviewed. Students "learn by doing" that 
each person is capa­ble of the creative process, and a strong sense of self-affirmationis attained by 
the majority of par­ticipants. Repeatedly,students reveal that their renewed appreciation for "self" 
carries over into other classes, and in their personal relationships. Summary -It is the author's opinion 
that the emphases discussed in this section are valuable to Computer Science people in their professional 
and personal lives, focusing on the "Art of Living" and the art of doing, achieving, inventing,and 
problem-solving. The students who emerge from such a course is more inventive, more flexible, more communicative, 
and they are, in turn, more innovative computer professionals. Most important, in using the computer 
to cre­ate personal art, students have the experience of using their most important tool, the computer, 
for creative self-expression. They are aided in this expression by the techniques of computer science, 
and their perceptions of what a computer can and cannot do are heightened by this experience. The computer 
can be and is an aid to creativity. THE ARTISTIC OBJECTIVES OF THIS COURSE The art aspects of this 
course are discussed at length in a recent paper, "The Importance of Art Design Techniques and Material 
Development -Their Effects in Achieving Art Quality in Computer Art." However, a very brief discussion 
of the artistic objectivesof this course follows: 1. The Ability to Observe -The first weeks focus on 
"learning to see" patterns and forms in the environment. This emphasis on observation and analysis is 
integrated with the next objective, Design Derivation Exercises. Students repeatedly state that they 
observe and appreciate the world around them much more after taking this course. 2. Design Derivation 
Exercises.-Heavy empha­sis is placed on learning to input designs from any source, to process the designs 
through the specific exercises developed by the author, and then to choose those that are personally 
satisfying. /14/ A list­ing of these ideas is given: (1) Minimalization; (2) Explorationof Opposites; 
(3) Addition Vs. Subtraction; (4) Positive Vs. Negative Space;  (5) Symmetry Vs. Asymmetry; (6) Simplicity 
Vs. Complexity; (7) Subjective Vs. Objective Reac­tions.  3. Personal Computer Art -Hundreds of slides 
are shown throughout the semester, along with actual art works, and illustrations from periodicals and 
 art catalogs. They are reviewed and discussed by the group. Students use the Art Checksheet (from "Stylistic 
Analysis of Computer Art" /15/ to achieve the experiences that result in identification of a personal 
direction in computer art. 4. Analysis and Definition of Art -Paradoxi­ cally, although one cannot totally 
define art, many elements of art are measurable and definable. In computer art, designing, programming, 
and executing art become artistic problems to be solved. Art Analysis Forms developed by the author 
(an out­growth from the Art Checksheet) are used to faci­litate this analysis and verbalization of art. 
 5. Connotations of Design -Specific forms of computer art lend themselves to known forms of developmentand 
do not lend themselves to others. These are identified and listed. Specific princi­ples of design are 
sought in brainstorming ses­ sions. Very often as a result of this (and other sessions), new techniques 
and ideas are discovered. 6. Connotationsof Color -Introduction to color and its use is given in a lecture/demonstra­ 
251 art are studied purely for color, along with actual tion early in the semester. Slides of computer 
 large works of art. Exercises help to determine personal preferences of color. 7. Art Materials and 
Their Use -Lecture/ demonstrations on art materials are begun in the second week, and students begin 
running on art pa­pers at that time, proceeding towards personal art, working from the simple to the 
complex. 8. Photographic Materials and Related Pro­ cesses -The author's first experiences in photo­graphic 
manipulation of computer art began in 1973 and have continued since that time. Sugges­tions for further 
development of photographic tech­niques is given in a paper, "The Microfilm Plotter and Computer Art." 
/16/ Students are introduced to a quick exposure of photographicmanipulations during week five, and the 
semester concludes with heavy emphasis on transparent sheet film (Kodalith) and Diazo use. (These techniques 
are discussed in detail in the microfilm paper.) 9. Final Presentation of Work -This material is fully 
described in the Material Developmentpaper, discussed briefly and referenced earlier as citation /14/. 
Briefly, computer art may take many final forms of presentation. Two lecture/demonstrations of media 
combinationsare given. Modular sculpture, textiles, editions of serigraphs, overlays, water­colors, 
oil paintings, as well as plotter graphics result. Film manipulations,combinations of photo­ graphic 
media are very popular. 10. Sharing of Final Products -An important part of the course is looking at 
the work of others, discussingnew ideas, and enjoying the artistic di­ versity of the group. Often, 
student shows of art work are held, informally, and others are invited for these friendly end-of-the-semesterreviews. 
 All art works are photographed by the instructor, to to add to the slide file. General Comments on Lecture/Laboratory 
Sessions -Each week contains one one-hour lecture that allows for discussion and development of ideas. 
Four hours of additional laboratory work are required, and in these laboratorysessions, varied programming 
and designing exercises take place, wherein the student gains in-class experience to complete outside 
assign­ ments. In-class experienceof every module of in­ struction is necessary, together with a precise 
de­ finition and affirmation of the assignment by students. Integrationof designing,programming,running 
art work, versity,Atlanta, Georgia, June, 1972. manipulating work photographically --all occur in pho-/3/ 
, "The Microfilm Plotter and laboratory sessions. At times, special week-end tographicworkshops are held. 
 There is a great deal of parallel processing required during each class, since the technical as­pects 
are explored during each class, as well as programmatically developed. Each class period of two hours 
has two or three focal points. To faci­litate greater understanding of the materials pre­sented each 
week, students receive a ditto sheet outlining the objectives, presentations,exer­cises and assignments 
for each week. Often these are handed out a month in advance. order to understand this integration 
of the varied elements of this course, a listing of topics is given, week by week. Originally, the author 
intended to include a definitive week by week plan as an appendix. However, because of space, it has 
been deleted in this paper. Readers interested in the definite plan may write the author for a copy. 
 SUMMARY The course outlined has proved to be a practi­cal addition to the Computer Science Curriculum.It 
provides technical experiences, research in inter­disciplinary graphics, software development, and in-depth 
computer art experiences. This course is tailored for upper division Computer Science majors and/or minors. 
It is not suitable for General Education students, nor for Art majors, because of its technical emphases. 
 At the present time, a new syllabus is being class-tested by the author, titled Technical Com­ munications. 
It includes speaking, writing, and listening skills for Computer Science majors and minors. When fully 
tested, the writing module in this course (ComputerArt for Computer People) will be modified, and the 
writing element lessened. In its place, greater emphasis on art software de­ velopment will be substituted. 
 For the Computer Science faculty interested in adapting such a course, the author recommends a re­view 
of the references listed, as well as the Visual Arts Bibliographies of the well-known periodical, Computers 
and the Humanities. /17/ Because it is an interdisciplinary course, embracing Art and Science, it may 
be introduced as a team-taughteffort by interested, talented faculty. The most important ideas gained 
are flexibility, inventivity, programmatic growth, along with a re­newed appreciationfor one's self, 
and for the creative potential of man and the computer. REFERENCES /1/ Hertlein, G., "The Programmer 
as an Artist," Proceedings, A Day of the Computer Arts, NCC&#38;E, New York City, N. Y., June, 1973. 
 /2/ , "The Artist and Computer Art," Proceedings, CCUC/3, Computers in the Un­dergraduateCurriculum, 
Georgia State Uni­ Computer Art," Proceedings, CCUC/6, Compu­ters in the Undergraduate Curriculum,Texas 
ChristianUniversity, Fort Worth, Texas, June, 1975. "Computer Art -A New Course Offering for General 
Education," Proceed­ings in the Undergraduate Curriculum, CCUC/8, Michigan State University, East Lansing, 
Michigan, June, 1977. /5/ Franke, Herbert, "Art of the Technical World," Computer Graphics and Art, Volume 
1, No. 1, February, 1976, p. 10-11. (See next page for concluding references.) 252 /6/ Hertlein, G., 
"A Beginning Science of Art," Proceedings,A Day of the Computer Arts, NCC&#38;E, New York City, N. Y., 
June, 1973. /7/ Snow, C. P., The Two Cultures, "Rede Lecture," London, 1959. /8/ Exhibition,CCUC/3, 
Georgia State Univ., Atlanta,Georgia, June, 1972. ,ICCH/I, Univ. of Minnesota, Minnea­polis, Minn., July, 
1973. ,NCC&#38;E, New York City, N. Y., June, 1973. ,CCUC/5 WashingtonState Univ., Pullman,Washington, 
June, 1974. ExhibitionsA, B, C, Academic Year 1974-75, General U. S. Distribution. /9/ August Issues, 
Computers and People, 1974, 1975, 1976, Art Editor, including various papers, articles, since 1970. 
Volume 1, Numbers 1 ­4, Computer Graphics &#38; Art, Editor, 1976. Vol. 2 in process. /10/ A Day of the 
Computer Arts, NCC&#38;E, June, 1973, New York City, N.Y., Special Art Proceedings. Catalog, ICCH/2, 
International Conference of Computers and the Humanities, Univ. of So. California,April, 1975. /11/ Mueller, 
Robert E., Inventivity,New York: John Day, 1974. /12/ Naughton, John; McGowen, Clement; Horowitz, Ellis; 
Brown, John R., "Session: Structured Programming -Concepts and Definitions," Computer, June, 1976. /13/ 
Kernighan and Plauger, Elements of Programming Style, New York City: McGraw-Hill,1974. /14/ Hertlein, 
G., "The Importance of Art Design Techniques and Material Development-Their Effects in Achieving Art 
Quality in Computer Art," Computer Graphics and Art, Vol. 2, No. 3, August, 1977 --"Week-by-WeekSyllabus, 
Computers and People, Vol. 26, No. 8, August 1977. /15/ ,"Computer Art: Steps Towards a Measurable Analysis," 
Computers and People, May, 1974, Vol. 23, No. 5, p. 13-17. /16/ op. cit., /3/ and Franke, Herbert, "On 
Producing Graded Black and White or Color Graphics in Combination with a Photo­graphic Technique," Leonardo, 
1974, p.333­335. /17/ Computers and the Humanities, Joseph Raben, Editor, Queens College, Flushing, N. 
Y. APPENDIX A The following is an abbreviated listing of lectures and topics, for week-by-week presentation. 
(For detailednotes on lectures and topics, please write the author.) I -Lecture: History of Computer 
Art Laboratories: (1) Slides of Computer Art; (2) Review of FORTRAN IV Programming; (3) Beginning Graphics 
Programming; (4)Be­ginning Designing. II. Lecture: Design Derivation Laboratories: (1) Library Research 
-Design; (2) Design Derivation Exercises -with Brain­storming; (3) Introductionto RESTORE Sub­routine; 
(4) Actual Examples of Computer Art. III. Lecture: Creativity/Inventivity Laboratories: (1) Film, "Why 
Man Creates" by Bass; (2) Demonstrationof Art Materials; (3) Introduction to RANDOM and MIRROR Sub­routines; 
(4) Color Exercises. IV. Lecture: InterdisciplinaryGraphics Applica­tions Laboratories: (1) Library 
Research -Inter­disciplinary Graphics; (2) Art Material In­troduction; (3) Introduction to ROTATE and 
RADIATE Subroutines; (4) Open Lab Period.  V. Lecture: PhotographicManipulation of Compu­ter Art -Techniques, 
Ideas Laboratories: (1)and (2) Double Lab Session,  Photography Lab; (3) Finished Graphics Vs. Exercises; 
(4) Open Lab Period.  Lecture: A Science of Art Laboratories: (1) Planning Graphically; (2) Introductionto 
SERIAL and RFLECT Subroutines; (3) Introduction to Varied OFFSET Subroutines;  (4) Open Lab Period. 
  VII. Lecture: Writing A Techical Paper Laboratories: (1) and (2) In-depth Work on Manuscripts; (3) 
Programmatic Review of Routines Introduced Thus Far; (4) Open Lab Period.  Lecture: Graphics Hardware, 
Software, Languages, Interactive Vs. Passive Systems Laboratories: (1) Brainstorming,Discussion, Graphics 
Capabilities Here; (2) Midterm Self- Evaluation Form; (3) Sharing of Work Artis­ tically; (4) Sharing 
of Work Programmatically. Portfolio of all work handed in at this time. IX. Lecture: Overviewof Remaining 
Subroutines-- General Review Laboratories: (1) Brainstorming,Analysis of Subroutine Needs; (2) Subroutine 
Writing Session; (3) Introduction to Cufit Subrou­tine; (4) Open Lab Period.  X. Lecture: Principles 
of Programming  Laboratories: (1) Programmatic Review of the Art Manual; (2) The Augmented Module Ap­proach; 
(3) Art Materials -Mass Production Running Methods and Participation Running;(4) Open Lab Period. XI. 
Lecture: Structured Programming,Concepts and Definitions Laboratories: (1) and (2) Analysis of Papers 
from Computer; (3) Group Work for Two Weeks; (4) Open Lab Period. XII. Lecture: Serigraphy, History, 
Techniques - How to Make a Silkscreen Laboratories: (1) and (2) Demonstrations, 253 How to Finish a 
Silkscreen; How to Develop Ulano Film for Direct Photosilkscreening; Silkscreeningon Plexiglas, Paper, 
Cloth, Diazos; (3) Self-PlanningSession -Al­ternatives for Finishing the Semester; (4) Group Project 
Work. XIII. Lecture: PhotographicMedia Combinations, including an Introductionto Diazos Laboratories: 
(1) Alternatives to Program­ming -Examination of New Student Subroutines; (2) ContinuedDiscussion of 
Latter; (3)and  (4) Sharing of Group Project Work.  XIV. Lecture: Diazochromes,Varied Graphic Arts 
Processes, Media Combinations Laboratories: (1) and (2)Making Silkscreens; (3) Making Diazos; (4) How 
to Use a Copy Camera for Varied Purposes. XV. Lecture: Final Presentation Forms-Ideas, Possibilities 
Laboratories: (1) Measuring,Matting -Get­ ting Ready for Student Art Show; (2)Matting; (3) and (4) Diazos, 
PhotographySession. XVI. Lecture:FinalsWeek -Self-EvaluationForm; Display Art Work; Discuss Favorite 
Works; Have Work Photographedby Instructor; In­formal Feedback on the Course; Make an Ap­pointment with 
Instructor to Review Portfolio. OPTIONAL EXPERIENCES AND ACTIVITIES 1. Sketch outdoors, deriving designs 
from nature, the environment, departing from source designs.  2. Visit a manual art exhibition. Analyze 
art forms, reasons for positive and negative re­sponses. Use Art Checksheets.  3. Guest Speaker from 
Geography -uses of graphics in cartography -introductionto the system.  4. Film, "ComputerGraphics and 
Medicine" -fol­lowed by discussion.  5. Guest Speaker from Overseas, lecturing on computer-aided sculpture. 
 6. Introductionto 3-D programming.  7. Meet with a Computer Art General Education Class, comparing 
work, ideas, attitudes, etc.  8. Guest Lecturer, Computer Graphics in Mathema­tics.  9. Exploring possibilities 
of Graphics in Basic, or an alternative easy system.  10. Guest Speaker, ComputerGraphics in Simulation. 
 11. Guest Speaker, Holography -Laser Graphics and Computer Music demonstration.  12. Learn how to 
put up an art exhibit. Discuss favorite works artistically and technically.  13. Brainstorming -the 
"ideal graphics system" -­components, capacities, etc.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>563903</article_id>
		<sort_key>255</sort_key>
		<display_label></display_label>
		<article_publication_date>07-20-1977</article_publication_date>
		<seq_no>45</seq_no>
		<title><![CDATA[Automated display techniques for linear graphs]]></title>
		<page_from>255</page_from>
		<page_to>260</page_to>
		<doi_number>10.1145/563858.563903</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=563903</url>
		<abstract>
			<par><![CDATA[The development of display procedures for drawing pictures of linear graphs is described. The facility to model relationships pictorially has led to the use of graph theoretic techniques in many different applications. While computers normally work with a numeric representation of a graph such as its incidence matrix, manual transformation of such representations into pictures is a tedious process. An interactive graphics system has been developed which, through a combination of heuristic techniques and semi-automatic procedures, creates visual representations of graphs with a minimum of user intervention. The resultant pictures display mirror-image and rotational symmetries that occur within the graph. This very general approach of displaying symmetry in graphs has proven useful in studies of several classes of graphs. However, the system is primarily a research tool designed for use by mathematicians and graph theorists. Difficulties entailed in adapting the display procedures to more specific application areas are discussed.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[automorphism group]]></kw>
			<kw><![CDATA[computer graphics]]></kw>
			<kw><![CDATA[graph theory]]></kw>
			<kw><![CDATA[linear graph]]></kw>
			<kw><![CDATA[symmetry]]></kw>
			<kw><![CDATA[visual representation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP31036887</person_id>
				<author_profile_id><![CDATA[81100313994]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[Brien]]></middle_name>
				<last_name><![CDATA[Maguire]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Regina, Regina, Saskatchewan, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Chang, Manning and Metze. Fault Diagnosis of Digital Systems. Wiley, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Faulkner, Gary Bruce. Recursive Generation of Cyclically K-Connected Cubic Planar Graphs. Ph. D. Thesis, Department of Combinatorics and Optimization, University of Waterloo (1971).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Friedman, Daniel P., Dickenson, David C., Fraser, John J., and Pratt, Terrence W. GRASPE 1.5: A Graph Processor and its Applications. Department of Computer Science, University of Houston (1969).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Hurwitz and Citron. GRAF: Graphic Additions to FORTRAN. Proceeding SJCC 1967, 553-558.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[IBM System/360 Component Description IBM 2250 Display Unit Model 1. Form A27-2701-2, IBM Data Processing Division, White Plains, N. Y.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Tutte, W. T. How to Draw a Graph. Proceedings London Mathematical Society 13 (1963), 743-767.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>363899</ref_obj_id>
				<ref_obj_pid>363872</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Unger, S. H. GIT-A Heuristic Program for Testing Pairs of Directed Line Graphs for Isomorphism. Comm. ACM 7, 1 (Jan. 1964), 26-34.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Weyl, Herman, Symmetry. Princeton University Press, 1952.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Wolfbert, Michael S. An Interactive Graph Theory System. Moore School Report No. 69-25, University of Pennsylvania (June 1969).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 AUTOMATED DISPLAY TECHNIQUES FOR LINEAR GRAPHS R. Brien Maguire Computer Science Department University 
of Regina Regina, Saskatchewan, CANADA Conversion of numeric data into pictures can The development 
of display procedures for drawing pictures of linear graphs is described. be a tedious trial and error 
process of drawing and redrawing pictures in order to achieve a suit- The facility to model relationships 
pictorially has led to the use of graph theoretic techniques able effect. A rough picture is drawn and 
then redrawn repeatedly, moving vertices and edges in many different applications. While computers 
until the result appears satisfactory or more of­ normally work with a numeric representationof a ten 
until one runs out of time, paper or patience. graph such as its incidencematrix, manual trans- Graph 
processing systems which allow the user to formation of such representationsinto pictures is draw and 
manipulate graphs on a graphic display a tedious process. An interactive graphics system has been developed 
which, through a combination of facilitate this process [9]. However, the user must still draw the pictures 
himself. All such heuristic techniques and semi-automaticprocedures, systems do to aid in drawing the 
pictures is to creates visual representationsof graphs with a provide a very expensive eraser. What 
is needed minimum of user intervention. The resultant pic­ is a way to use the power of the computer 
to pro­ tures display mirror-imageand rotational symmet­ duce these pictures from a non-pictorial represen­ 
ries that occur within the graph. This very gen­ tation of the graph with minimal user interaction. 
eral approach of displaying symmetry in graphs has proven useful in studies of several classes of We 
have attempted to program a computer to do graphs. However, the system is primarily a re­search tool 
designed for use by mathematiciansand just that. Some of the problems involved in com­puter generation 
of pictures of graphs are discus­ graph theorists. Difficulties entailed in adapt- The implementationof 
a semi-automatedsys­ ing the display procedures to more specific appli- sed. tem for manipulating graphs 
which, through a com­ cation areas are discussed. bination of heuristic techniques and semi-automa­tic 
procedures, generates visual representations Key Words and Phrases: computer graphics, of graphs is 
described. This system allows a user graph theory, linear graph, automorphism group, to request the 
computer to draw pictures of a symmetry and visual representation graph. The computer can produce these 
pictures without aid from the user, although in practice CR Categories: 4.31, 4.9, 5.32, 8.2 the user 
will direct the operation of the system as well as performpostediting of the pictures. 1. Introduction 
 2. Graphics Support graph theoretic techniques to model relationships which are best represented as 
pictures. Electri-An interactive graphics system called GSYM, cal networks, chemical structures, computational 
for Graph SYMmety, was developed to aid in invest­igating visual representationtechniques for A wide 
variety of applicationareas employ models and communication networks are examples of GSYM allows a 
user to create, manipulate graphs. applicationareas where graph theoretic approaches and display graphs 
using an IBM 2250 Graphic Dis­ have been used. One reason for this is the number L tool designed solely 
for investigatingthe prob play Unit [5]. GSYM is a special graphics display  of algorithms and techniques 
available for manipu­ lating the graph models. Equally important, how­ lems involved in using a computer 
to generate vis­ ever, is the fact that the structure of the graphs ual representationsof graphs. It 
should not be can be represented pictorially.  confused with existing graph processing languages as 
it is not a programming language per se Efficient computer manipulationof graphs re­ although it does 
provide macro-likecommands for quires that they have a numericaldata representa­ or adjacencymatrices 
operating on graphs in certain situations. It tion. However, incidence also contains a list processing 
subsystem,but is and other numeric representationsof graphs usual­ly have little meaning for humans. 
Therefore, the not primarily intended to be a list processing tool. engineer or mathematician attempts 
to translate the numeric results of his programs into pictures, seeking to obtain a deeper insight and 
understand-2.1. System Operation ing of the properties and structure of the results. GSYM was designed 
to be used by individuals Permission to make digital or hard copies of part or all of this work or such 
as mathematiciansand graph theorists that personal or classroom use is granted without fee provided that 
copies are not made or distributed for profit or commercial advantage and that copies bear this notice 
and the full citation on the first page. To copy otherwise, to republish, to post on servers, or to redistribute 
to lists, requires prior 255 specific permission and/or a fee. Siggraph 77, July 20-22 San Jose, California 
would have little, if any, experience with compu­ters. The goal was to create a computer tool that could 
provide researchers with further insight into the structure of their graph theoretic models. However, 
we had to entice, for the most part, non­computer users to leave their offices and journey to the graphic 
display. The display, of course, was inconvenientlylocated in the basement of the Mathematics and Computer 
building behind the closed doors of the Computer Centre. Thus, there was con­siderable pressure to make 
GSYM very easy to use. For example, we had to avoid the usual hurdles for a novice of learning awkward 
syntax rules for some programming language and being forced to stumble through a maze of job control 
language. GSYM operates on what has been termed 'inter­acttion by anticipation' in that the interactive 
system attempts to guide the user through the se­quence of events that causes a particular operation 
to be performed. The possible operations the user may initiate at any given moment are displayed and 
the user selects one of the current options using a light-pen. The system is said to be in the 're­set' 
state when the option list illustrated in Fig­ure 1 is displayed. Once a basic option is select­ed, all 
the possible suboptions are given. After choosing the ADD option, for example, the user sel­ects the 
element to be added to the graph from the list in Figure 2. If a vertex was being added, the system would 
request the user to position the ver­tex on the screen using a light-pen. A similar process is followed 
for all opera­tions. That is, GSYM displays a list or menu of the options available to the user at the 
moment and awaits the user's response. This type of format not only guides the user but also eliminates 
the possibility of system error owing to invalid user input. In order to reduce the frequency of user 
error the option lists contain a brief instructive note defining the nature of the current operation 
and the user action required. Moreover, should the user change his mind or wish to cancel an operation 
in the middle of a command sequence he may return to the reset state simply by pushing a programmed function 
key. Thus, the system is very forgiving, encouraging inexperienced users to become profi­cient in its 
operation through actual 'hands-on' experimentation. These features are especially im­portant since as 
a research tool, GSYM is intended primarily for graph theorists and mathematicians. Such users understandablyhave 
little patience with the rigidity and poor man-machine interfaces that more experienced computer users 
seem to have accep­ted as the norm. The wide variety of available operations in­cludes addition, deletion 
and alteration of graph entities. The graphs are composed of vertices, edges and arrows. An arrow is 
always associated with an edge, that is, an undirected edge becomes a directed edge when the user adds 
an arrow (dir­ection) to the edge. Move, rotation and transla­ tion commands manipulate the form of the 
graph as currently displayed on the screen. The user is able to move vertices, edges and arrows about 
the screen or, if he wishes, he may translate the whole graph. The rotation command rotates a graph 
about any point in the 3-dimensional cube in which it is defined. This cube corresponds roughly to the 
housing of the 2250 display screen. 2.2. GSYM Facilities GSYM provides all of the graph manipulation 
 operations allowed by earlier systems [91. It al­ so allows the user to associate lists of proper­ ties 
with vertices and edges. This facilitates the implementationof graph theoretic algorithms which operate 
on vertex and edge properties. The user is also able to create lists of vertices and edges by selecting 
list elements with a light-pen. This simple list-processingsubsystem is adequate for most graph theoretic 
routines which operate on sets of graph elements. In anticipationof future expansion to allow command 
lists to be interpreted by the system, GSYM has a 'macro mode' whereby the user types in macros, containing 
all the informa­ tion required by the system to perform the next operation. For example, to add a vertex 
one wou.d  type: ADD V,(vertex coordinates),'label',(labelcoordin­ates),propertylist. From an execution 
time standpoint macro mode is very efficient, but it requires a more knowled­geable user and more user 
time in order to type the command. However, a user written program run­ning under the GSYM system may 
control the opera­tion of the system by directing commands in the form of macros to the system. An ENQUIRE 
option permits users to quiz the system at any time con­cerning the current status of a graph, its proper­ties 
and any graph related entities such as list pointers. It is also possible to have this infor­mation sent 
to a line printer for later reference and examination. The user is able to save graphs on secondary 
storage and restore them later. Both the graph and the current status of the system are stored so that 
when a graph is restored the display as well as the data base associatedwith the graph is re­created. 
This feature allows the user to save dis­plays created by visual representationroutines and recover them 
at any time. The graphs are stored as members of a file directory which the user creates before saving 
any graphs. There is no limit to the number of direc­tories a user may have. In order to switch from 
one directory to another it is simply necessary to reference the new directory. Each graph in a dir­ectory 
is given a name when saved and may be re­named or replaced by another graph. The user does not become 
involved in the actual detailed crea­tion and manipulation of the files containing these graphs. In particular,it 
is not necessary to know any command language statements for creat­ing new files or referencing old files. 
All such file operations are handled dynamically by GSYM and are transparent to the user. The same stan­dard 
control language is used to run GSYM regard­less of what files will be used. The typical GYSM user is 
not likely to possess this knowledge and is unlikely to be inclined to acquire it in order to use the 
system. Since GSYM is intended for designing and test­ing representation schemes, it has the ability 
to call user programs into execution. This feature has also been used to provide several special fun­ctions 
such as reading graph descriptions from in­put files, debug tracing of GSYM and smoothing  256 edges 
drawn with the light-pen. Although this fea­ture is intended for testing visual representation routines, 
it is possible to incorporate any type of graph theoretic routine. For example, a program to calculate 
Hamiltonian paths could use the GSYM list processing subsystemto create lists representing any such paths 
in a graph. Space in the display processor's memory has been reserved to allow user programs to create 
their own displays if needed. All system functions for manipulatingand interro­gating a graph or its 
associated data base are available to user programs through the macro facil­ity. The result is that it 
is a very simple matter to incorporatenew representation routines. The user is isolated from the details 
of display file and data base manipulation.  2.3. Picture Format The display screen layout for graphs 
in GSYM was designed in view of the effect it would have on pictures drawn by visual representationroutines 
running under GSYM. Several screen layout problems and some of the steps taken to solve or avoid them 
are considered below. Vertices and edges are displayed as points and straight lines, their natural representation. 
Arrows represent directions on directed edges and may be positioned anywhere along a directed edge. The 
positive and negative ends of an edge are indi­cated by arrow orientation. There are eight possi­ble 
orientations corresponding to the eight major points on a compass. The screen of a display unit is a 
two-dimen­sional entity and is therefore limited to two-dim­ensional pictures. If GSYM restricted itself 
to planar graphs with all visual representations being planar maps, such a two-dimensionaldisplay system 
would be quite adequate. However, GSYM is intended for use with both planar and non-planar graphs. While 
this did not preclude the possibility of gen­erating pictures of non-planar graphs with inter­secting 
edges, a more serious problem was the ques­tion of how to display multiple edges between ver­tices in 
a two-dimensionalsystem. Thus, restrict­ing GSYM to a two-dimensional coordinate system would severely 
constrain users' visual representa­tions. For example, it would not be possible to generate a picture 
of a graph as a three-dimension­al object and this is a natural representation for many graphs. For these 
reasons all GSYM graphs are defined using a three-dimensionalcoordinate system. An edge is displayed 
as a straight line join­ing the x and y coordinates of the Cartesian (x,y,z) coordinates of its end-vertices. 
This re­presentation implies that the user may need to ro­tate the graph in order to see more than just 
one of its faces. The GSYM rotation facility allows the user to rotate a graph about any point in the 
cube in which the graph is displayed.  There is one exception to the rule of three­dimensionalgraph 
entities, a special two-dimen­sional edge called a 'light-pen' edge. The user may specify that he wishes 
to draw a freehand represen­tation of an edge using the light-pen. The edge is then displayed as a sequence 
of short straight line segments tracing the path of the light-pen. Light­ pen edges solve the display 
problem caused by sev­eral edges being incident to the same pair of ver­tices since these edges may be 
drawn as curved lines. However, the primary importance of this feature is that it allows the user a wide 
range of choices in altering visual representations pro­duced by the computer. Straight line edges can 
be replaced by curved edges which the user feels im­prove the picture. 3. Visual Representation Techniques 
 Our initial interest in computer generated representationsof graphs was the result of an attempt to 
create pictures of a class of cubic, cyclically 4-connected graphs produced by Faulkner For every region 
size n > 6 in this class of graphs there exists a graph consisting of two pol­ygons of n -2 edges each 
such that every vertex in one of the polygons is adjacent to exactly one vertex in the other polygon. 
These graphs can be drawn as concentric polygons or rings of quadrila­terals as illustrated in Figure 
3. The ring structurewas used as a basis for representationsof more complicated graphs in the class. 
The ring structure is allowed to contain pentagons, hexagons and larger polygons. Once the ring structure 
is complete the remaining edges, if any, can easily be added to the interior of the ring. Figure 4 shows 
a 25 region graph. This display procedure produced reasonable pictures; however, excessive computer time 
was often neces­sary to calculate the ring structures. Moreover, the pictures could not be altered by 
the user. Finally, the representationroutine was suited only to the one class of graphs. This lack of 
flexibility led directly to the development of GSYM and its use in the investigation of alterna­tive 
representationtechniques.  3.1. Symmetry The most apparent and the most interesting feature of the 
pictures produced by this first re­presentation routine was the frequent repetition of symmetry between 
elements of the graph. Sym­metry, particularlymirror-image symmetry, occurs repeatedly in nature and 
in man's own creations. Weyl gives an excellent discussion of the nature of symmetry and its use in art 
and architecture through the ages [8]. The possibility of portray­ing symmetries in graphs suggested 
using the auto­morphisms of a graph as a basis for creating pic­tures of the graph. The cycles in an 
automorphism mapping of a graph can be interpreted visually as mirror-image and rotational symmetries. 
 Calculation of the automorphism mappings of most graphs is a long computational task. Heur­istics have 
been used to determinewhether graphs are isomorphic [7]. Similar heuristics were derived to calculate 
the automorphismmappings of a graph. Vertex valencies define an initial par­tition of the vertex set 
of a graph. Additional tests such as the number of vertices in each neighbourhood of a vertex and the 
number of poly­gons through a vertex are then used to attempt to refine the partition. Numerous such 
heuristics were investigatedbefore selecting a set of heur­istics which worked well with most graphs. 
 257 The amount of computation time required obtain the automorphisms depended on the heuristic tests 
and parameters applied to the graph. Experimenta­tion with different tests and parameters on the same 
graphs indicated that a combination could usu­ally be found that reduced the computation consider­ably. 
In order to make the calculation of the auto­morphism mappings feasible, the heuristics were im­plemented 
under GSYM. The operation of the heur­ istics could then be monitored on the display. The user interactswith 
the system by dynamically ini­tiating and halting heuristics and varying parame­ters. Using this interactiveapproach 
it became practical to calculate automorphisms to use in gen­erating visual representationsof a graph. 
Differ­ent heuristics were easily implemented and tested as user programs under GSYM. The vertex set 
parti­tion was handled using the list processing subsystem in GSYM. 3.2. General Representation Routine 
 Our first translation of the automorphisms of a graph into pictures was a very general representa­tion 
routine. This routine attempts to handle all classes of graphs without any additional information about 
the graphs beyond the symmetries in the auto­ morphismmappings. Vertices fixed, that is, mapped onto 
themselves by an automorphism, are displayed as axes of sym­ metry around which are placed mirror-image 
vertex pairs, vertices interchangedby the automorphism. Automorphisms with cycles of one or two vertices 
be­ come the mirror-image symmetries of Figure 5. Cy­cles of more than two vertices are treated as rota­tional 
symmetries. Each rotation is placed in a different plane in the three-dimensionalcube in which GSYM graphs 
are defined. Figure 6 illustrates an example of rotational symmetry. This approachtends to produce 
rather cluttered pictures as graphs become more complex. Poor place­ment of the mirror-imagevertices 
or the rotations also has the same effect. Postediting facilities were therefore implemented to allow 
the user to modify and improve the generated pictures. The user may stop the representationroutine at 
any point, modify the picture produced so far, and then allow the routine to continue to add further 
mirror­image and rotational symmetries. The user also con­trols the placement and size of the rotational 
sym­metries. Finally, the user may edit symmetries as a unit. For example, moving a vertex in a mirror­image 
symmetry causes its correspondingvertex to move so as to maintain the original symmetry. This semi-automateddisplay 
process produces representa­tions of comparable quality to those generated by hand and does so in a 
fraction of the time and ef­fort required to draw the same graphs manually. The above approach has the 
fault that the qua­lity of the pictures produced varies with the auto­morphism mapping used. Automorphismswith 
rela­tively few fixed vertices generally produce the best displays. A large number of vertices on an 
axis of symmetry obscures the structure of the graph because all the edges joining these vertices form 
a single line on the display. Moreover, large graphs or graphs with a large number of symmetries may 
require considerablepostediting before a sat­isfactory picture is produced. The reason is that this representation 
routine uses only the symmetry information given by the automorphismmappings of the graph in order 
to display the graph. While the routine displays all the symmetries it lacks a frame around which to 
group these symmetries. The advantage of this approach is that the routine may be used with moderate 
success with many classes of graphs. The disadvantage is that this approach does not allow for situations 
where users are in­ vestigating problems where the graphs involved share common properties and structures. 
 3.3. Tree Representation Trees are a class of graphs found in many app­lications. Trees also possess 
a high degree of known structure in that all vertices in a tree can be defined in terms of their distance 
from the cen­tre or bicentre of the tree. Finally, the general symmetry routine, in ignoring the fact 
that a graph was a tree, produced pictures that rarely even hinted at the tree structure of the graph. 
It was apparent that the acceptabilityof the pic­tures produced by this general approach was provi­sional 
on the user not having a preconditioned idea of what the resultant picture should portray. Not wishing 
to abandon the symmetry approach, a tree representationroutine was designed which, in addition to the 
automorphism symmetries, consi­ dered the tree structure of the graph in the pic­ tures generated. Mirror-image 
and rotational sym­ metries were combined with vertex distance from the centre or bicentre of the tree 
to produce pic­ tures such as the one illustrated in Figure 7. Distance from the centre or bicentre 
determines the level at which a vertex is placed. Mirror­ image and rotational symmetries are considered 
in ordering vertices on each level so as to illustrate the symmetry. The result was a representation 
 routine that generates excellent pictures of trees and requires little or no postediting of the gen­ 
erated display. 4. Discussion The pictures produced by the representation routines have been encouraging, 
even though the original objective of using a computer to automa­tically produce pictures of graphs has 
only part­ially been met. The representationmethods tested required user postediting of the pictures. 
How­ ever, the need for postediting was considerably reduced when the representationroutines consider­ 
ed more of the structure of the graph than the elementary automorphismmapping symmetries. The two representationroutines 
discussed above are radically different in nature. The first is totally naive about the structure of 
the graph while the other knows everything about it. Few classes of graphs lend themselves so well to 
a visual portrayal as do trees. However, just as with the development of specialized programming languages, 
we anticipatea parallel development in the creation of visual representation routines -a proliferation 
of specialized routines intended for specific classes of graphs or particular applica­ tion areas. These 
routines would be based on properties that, when interpreted visually, deter­mined the layout of the 
graph. For example, one such property is planarity. All planar graphs can be embedded in a single plane 
without intersectingedges. Tutte gives an 258 algorithm for drawing such a graph in the plane [6]. 
 Unfortunately,Tutte's algorithm tends to produce pictures where a large number of edges are drawn within 
a very small area. As a result, for most practical purposes, the algorithm proves to be un­ satisfactory. 
 The GSYM system in combinationwith the repre­sentation routines is designed as a tool for graph theorists. 
It provides a means whereby a graph thoerist can easily investigate the structure of a graph or class 
of graphs in which he is interested. The representation routines should also prove use­ful for communicating 
information on classes of graphs between researchers. At present all that could be made available is 
a list of the numeric representationsof the graphs. However, the repre­sentation routines could produce, 
in a systematic fashion, pictures of the graphs as well. Applied use of automated representationproce­dures 
will require the implementation of more specialized routines than those describedhere. However, applications 
should be possible wherever structural symmetry in modellingrelationships is important. For example, 
in the area of fault diagnosis functional simulation is one technique for digital fault simulation With 
this method a digital system compused of modules M1, M2,...,M is to be simulated. Overall system behaviour 
is to be determined using the assumption that there are faults in only certain of the modules. The remain­ 
ing modules need not be simulated at the gate level. It is only necessary to compute the output of these 
modules as a function of their input. If such a system were defined as a graph, then a representa­ tion 
routine could display the symmetries in the system. These pictures would indicate which modules should 
or should not be simulated in detail. For example, if modules M. and M. form a mirror-image pair, then 
if module Mi is not being simulated at the gate level the mirror-imagesymmetry implies that neither 
should module M. be simulated at the gate level. That is, the symmetry in the system could help determine 
how to set up the simulation tests.  259  References 1. Chang, Manning and Metze. Fault Diagnosis 
of Digital Systems. Wiley, 1970.  2. Faulkner, Gary Bruce. Recursive Generation of  Cyclically K-Connected 
Cubic Planar Graphs. Ph. D. Thesis, Department of Combinatorics and Optimization, University of Waterloo 
(1971). 3. Friedman, Daniel P., Dickenson, David C., Fraser, John J., and Pratt, Terrence W. GRASPE 
1.5: A Graph Processor and its Appli­cations. Department of Computer Science, University of Houston (1969). 
 4. Hurwitz and Citron. GRAF: Graphic Additions to FORTRAN. Proceeding SJCC 1967, 553-558.  5. IBM 
System/360 Component Description IBM 2250  Display Unit Model 1. Form A27-2701-2, IBM Data Processing 
Division, White Plains, N.Y.  6. Tutte, W. T. How to Draw a Graph. Proceed­ings London Mathematical 
Society 13 (1963), 743-767.  7. Unger, S.H. GIT-A HeuristicProgram for Test­ing Pairs of Directed Line 
Graphs for Isomor­phism. Comm. ACM 7, 1 (Jan. 1964), 26-34.  8. Weyl, Herman, Symmetry. Princeton University 
Press, 1952.  9. Wolfbert, Michael S. An Interactive Graph  Theory System. Moore School Report No. 
69-25, Universityof Pennsylvania (June 1969). 260  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1977</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
</content>
</proceeding>

<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>08/05/2012</start_date>
		<end_date>08/09/2012</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[Los Angeles]]></city>
		<state>California</state>
		<country></country>
	</conference_loc>
	<conference_url></conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES382</series_id>
		<series_title><![CDATA[International Conference on Computer Graphics and Interactive Techniques]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>2341931</proc_id>
	<acronym>SIGGRAPH '12</acronym>
	<proc_desc>ACM SIGGRAPH 2012 Art Gallery</proc_desc>
	<conference_number>2012</conference_number>
	<proc_class>conference</proc_class>
	<proc_title></proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn13>978-1-4503-1675-0</isbn13>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>2012</copyright_year>
	<publication_date>08-05-2012</publication_date>
	<pages>93</pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<abstract>
		<par><![CDATA[<p>The annual SIGGRAPH conference has been consistent in presenting juried artwork since 1982. This tradition has prompted a steady appearance of art-based scholarly research at the event, and in 2008 the conference added Art Papers to its art programs while renewing the collaboration between ACM SIGGRAPH and Leonardo/ISAST. Since then, the 2009, 2010, and 2011 Leonardo/ISAST Special Issues have expanded our capacity to attract, review, and publish the state of the art in digital art and design.</p> <p>This year marks the 30th anniversary of SIGGRAPH Art Gallery (In Search of the Miraculous, here introduced by Osman Khan) and the fourth edition of SIGGRAPH Art Papers. We take great pride in bringing you five new art papers that demonstrate compelling art and design practices in solid conceptual frameworks.</p>]]></par>
	</abstract>
	<publisher>
		<publisher_id>PUB27</publisher_id>
		<publisher_code>ACMNY</publisher_code>
		<publisher_name>ACM</publisher_name>
		<publisher_address>2 Penn Plaza, Suite 701</publisher_address>
		<publisher_city>New York</publisher_city>
		<publisher_state>NY</publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>10121-0701</publisher_zip_code>
		<publisher_contact>Bernard Rous</publisher_contact>
		<publisher_phone>212 869-7440</publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url>www.acm.org/publications</publisher_url>
	</publisher>
	<sponsor_rec>
		<sponsor>
			<sponsor_id>SP932</sponsor_id>
			<sponsor_name>ACM Special Interest Group on Computer Graphics and Interactive Techniques</sponsor_name>
			<sponsor_abbr>SIGGRAPH</sponsor_abbr>
		</sponsor>
	</sponsor_rec>
	<categories>
		<primary_category>
			<cat_node/>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
	<ccc>
		<copyright_holder>
			<copyright_holder_name>ACM</copyright_holder_name>
			<copyright_holder_year>2012</copyright_holder_year>
		</copyright_holder>
	</ccc>
</proceeding_rec>
<content>
	<section>
		<section_id>2341932</section_id>
		<sort_key>10</sort_key>
		<section_seq_no>1</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Art papers]]></section_title>
		<section_page_from>322</section_page_from>
	<article_rec>
		<article_id>2341933</article_id>
		<sort_key>20</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>08-05-2012</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[<i>Translation</i> + pendaphonics = movement modulated media]]></title>
		<page_from>322</page_from>
		<page_to>329</page_to>
		<doi_number>10.1145/2341931.2341933</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=2341933</url>
		<abstract>
			<par><![CDATA[<p><i>Translation</i> is a multimedia dance performed on a vertical wall filed with the projected image of a lunar surface. Pendaphonics is a low-cost, versatile, and robust motion-sensing hardware-software system integrated with the rigging of <i>Translation</i> to detect the dancers' motion and provide real-time control of the virtual moonscape. Replacing remotely triggered manual cues with high-resolution, real-time control by the performers expands the expressive range and ensures synchronization of feedback with the performers' movements. This project is the first application of an ongoing collaboration between the Motivational Environments Research Group at Arizona State University (ASU) and STREB Extreme Action Company.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P3734338</person_id>
				<author_profile_id><![CDATA[81435602025]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Byron]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lahey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Arizona State University, Tempe, Arizona]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[byron.lahey@asu.edu]]></email_address>
			</au>
			<au>
				<person_id>P3734339</person_id>
				<author_profile_id><![CDATA[81366590839]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Winslow]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Burleson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Arizona State University, Tempe, Arizona]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[winslow.burleson@asu.edu]]></email_address>
			</au>
			<au>
				<person_id>P3734340</person_id>
				<author_profile_id><![CDATA[81504687977]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Elizabeth]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Streb]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[STREB Extreme Action Company S. L. A. M., Brooklyn, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[F. A. R. @ ASU: Future Arts Research at Arizona State University, futureartsresearch.asu.edu/, accessed March 21, 2012.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Skriver Hansen, Pendaphonics installation at Platform4, 2008, www.platformart.net/pendaphonics_demo.htm, accessed March 21, 2012.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[A. Schmeder, A Portable Pendaphonics Rig, cnmat.berkeley.edu/user/andy_schmeder/blog/2009/05/31/portable_pendaphonics_rig, accessed March 21, 2012.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. Overholt, et al., Pendaphonics, art installation at the International Conference on New Interfaces for Musical Expression, Carnegie Mellon University, Pittsburgh, 2009.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1517701</ref_obj_id>
				<ref_obj_pid>1517664</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. Skriver Hansen, et al., "Pendaphonics: A Tangible Pendulum-based Sonic Interaction Experience," <i>Proceedings of the 3rd International Conference on Tangible and Embedded Interaction</i> (New York: ACM, 2009) 153--160.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. Freed, et al., "Musical Applications and Design Techniques for the Gametrak Tethered Spatial Position Controller," <i>Proceedings of the 6th Sound and Music Computing Conference</i>, Porto, Portugal, 23--25 (2009).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Gametrak, en.wikipedia.org/wiki/Gametrak, accessed January 7, 2012.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cycling 74, cycling74.com, accessed January 7, 2012.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[OpenFrameworks, www.openframeworks.cc/, accessed January 7, 2012.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[E. Streb, <i>Streb: How to Become an Extreme Action Hero</i> (New York: The Feminist Press at CUNY, 2010) 83.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[CUNYMedia, "Streb: How to Become an Extreme Action Hero," 2010, www.youtube.com/watch?v=pOAHYF-WtBM, accessed March 21, 2012.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[R. E. Kaufman, "A Family of New Ergonomic Harness Mechanisms for Full-Body Natural Constrained Motions in Virtual Environments," <i>3D User Interfaces</i>, 2007, 10--11 (2007).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[F. Yang &amp; Y. Pai, "Automatic Recognition of Falls in Gait-slip Training: Harness Load Cell Based Criteria," <i>Journal of Biomechanics</i> Vol. 44, No. 12, 2243--2249 (2011).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>240808</ref_obj_id>
				<ref_obj_pid>240806</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[C. Davies &amp; J. Harrison, "<i>Osmose</i>: Towards Broadening the Aesthetics of Virtual Reality," <i>ACM SIGGRAPH Computer Graphics</i> Vol. 30, No. 4, 25--28 (1996).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Motion tracking, 3D scanning, and eye tracking solutions from Polhemus, www.polhemus.com, accessed March 15, 2012.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Motivational Environments, STREB BRAVE, video-recorded conversation between Elizabeth Streb and Winslow Burleson, 2009, vimeo.com/17161251, accessed March 21, 2012.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[E. Streb, excerpt from Dancers Defy Gravity, KJZZ 91.5 FM, November 7, 2009.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Wii, www.nintendo.com/wii, accessed January 10, 2012.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Translation + Pendaphonics = Movement Modulated Media Byron Lahey, Winslow Burleson, Elizabeth Streb 
ABSTRACT Translation is a multimedia dance performed on a vertical wall filled with the projected image 
of a lunar surface. Pendaphonics is a low-cost, versatile, and robust motion-sensing hardware-software 
system integrated with the rigging of Translation to detect the dancers motion and provide real-time 
control of the virtual moonscape. Replacing remotely triggered manual cues with high-resolution, real-time 
control by the performers expands the expressive range and ensures synchronization of feedback with the 
performers movements. This project is the first application of an ongoing collaboration between the Motivational 
Environments Research Group at Arizona State University (ASU) and STREB Extreme Action Company. Introduction 
Translation (aka Run Up Walls) is a multimedia performance in which dancers explore movement possibilities 
availed by the low-gravity environment of the lunar surface. Realizing this experi­ence does not require 
a mission to the moon. Instead, the dancers ascend a vertical wall with the assistance of custom-designed 
harnesses and rigging. A video projection fills the wall with a lunar surface that moves and rotates 
in response to the dancers movements. A musical soundtrack composed by David Van Tieghem amplifies the 
atmosphere and augments the sound of the dancers as they walk, run, leap, tumble, and slam into the surface 
of the wall. Background F.A.R. (Future Arts Research at Arizona State University) director Bruce W. Ferguson 
explains the program s mission: F.A.R. has initiated a new model for arts institutions by supporting 
artists whose action research generates new forms of knowledge, using one of our specific areas which 
resonate with the Phoenix community [1]. F.A.R. sponsored and organized an exploratory visit to connect 
the STREB Extreme Action Company with the Motivational Environments Research Group at ASU to plan the 
nature of shows, venues, production logistics, speaking engagements, and community outreach events. A 
meeting was held in which members of our research group met with performance organization principals 
and discussed their research agendas. A deep and synergistic excitement emerged from the mutual philosophy 
of learning by doing, rapidly prototyping solutions, and going beyond what is currently possible, linking 
science, engineering, art, and human experience with interac­tion design and dance. Plans soon evolved 
to form a close collaboration that has extended for the past three years. Discussions of a wide range 
of sensing technologies and interaction modalities were advanced, iterations of wireless magnetic sensors 
were explored to trigger sonic events, discussions of more robust motors and bearings for one of the 
performance company s existing dance apparatuses were had. A rich series of meetings, prototyping sessions, 
and improvisations, involving dancers, engineers, artists, musicians, and graduate student visits to 
the STREB Lab for Action Mechanics in Brooklyn, New York, and workshops at an ASU theater ultimately 
led to the project described herein, which was one of the pieces for the STREB Extreme Action Company 
s subsequent touring show. Translation Background Translation is one of many performances created by 
Elizabeth Streb s company that explores human movement with physical apparatuses that generate forces 
and provide obstacles and opportunities for movement that has more in common with circus acrobatics than 
traditional dance on a flat stage. Dancers perform­ing Translation wear harnesses that allow them unrestricted 
rotational movements while being lifted off the ground. The rigging from the top of the wall to the harnesses 
places the anchor points at the top of the wall such that when the dancers bodies are parallel to the 
floor with their feet on the wall, there is minimal force between the dancers feet and the wall. In this 
configuration, the wall becomes the floor for the dancers, with a simulated gravitational force that 
is proportional to the dancer s distance from the wall (Figures 1 and 2). Pendaphonics Background Dan 
Overholt, Anne-Marie Skriver Hansen, Winslow Burleson, and Camilla Nørgaard Jensen invented Pendaphonics 
for an interactive art installation in 2008 [2]. Pendaphonics is a combination of hardware and software 
that allows physical pendulum devices to control audio, video, and other actuators based on the movement 
of the pendulum bob. The first performance of Pendaphonics took place at Platform 4 gallery in Ålborg, 
Denmark, and featured eight Pendaphones (interactive pendulum devices) (Figure 3). Visitors were invited 
to collaboratively activate the art and performance space, both sonically and visually, by manipulating 
the pendu­lums. The natural periods of the pendulums provide rhythmic consistency when they are allowed 
to swing or orbit freely, but no con­straints were placed on the nature of the interactions. Participants 
could freely move the pendulum bobs by hand, pluck on the string like a bass, or pass it back and forth 
with their friends. This empowered participants to create a sonic environment that was as ordered and 
sparse or chaotic and dense as they collectively desired. Pendaphonics has subsequently been used for 
research and art installations at numerous institu­tions, including Ålborg Universitet, Arizona State 
University, and the University of California, Berkeley [3]. Its uses have included mathematics education, 
laptop orchestra performances, position tracking for robot navigation, and additional interactive art 
installations, including one at the New Interfaces for Musical Expression (NIME) conference [4]. Pendaphonics 
is formally documented in Hansen et al. s 2009 Tangible and Embedded Interaction paper [5]. Freed et 
al. provide extensive documentation of artistic applications of the Gametrak, including Pendaphonics 
[6]. Pendaphonics System The Pendaphonics system includes modified off-the-shelf hardware and custom 
software. Pendaphonics Hardware The base hardware for the Pendaphonics system is a game controller called 
the Gametrak [7] (Figure 4). Though no longer in production, the Gametrak remains useful for human-computer 
interactions beyond the scope of its original design purpose. Gametrak controllers have a simple but 
very effective mechanism for tracking two points in 3D space. The device uses a small two-axis joystick 
for each tracked point. As with traditional joysticks, these provide two degrees of freedom (X and Y 
rotational angles). The third degree of freedom (Z distance) is achieved by sensing the motion of a thin, 
retractable nylon string that pulls out from the end of the joystick. Electronically, the positions are 
sensed by the rotation of potentiometers that provide variable voltage to an analog-to-digital converter. 
The data are formatted by an embedded microcontroller (with a small modification to the board), which 
provides the data to a computer via USB as a standard human interface device (HID). Depending on the 
number of devices to be used and their spatial configuration, it is sometimes more efficient to consolidate 
the output of several Gametrak sensor sets into a third-party microcon­troller. In some cases, the original 
controller packaging works perfectly well, while in other cases, for compactness, specific functional 
requirements or aesthetics, we have transferred the essential sensing hardware into custom enclosures. 
The sensing space for the original Gametrak controller is a cone with a side length of approxi­mately 
three meters and a total angle of approximately 80 degrees (40 degrees in each direction from perpendicular). 
For use in the Translation performance, this sensing space was not sufficient. The length of the retractable 
string had to be extended to approximately nine meters. Replacing the original coil spring retraction 
hardware with another from a modified tape measure, replacing the original potentiometer with a multi-turn 
potentiometer, and substituting a longer nylon string accomplished this (Figure 5). Pendaphonics Software 
The raw data from the Gametrak controller can be read as a standard HID. The analog-to-digital conversion 
is 12 bit, providing values for X, Y and Z ranging from 0 4095. We use custom Max [8] software to process 
these data and translate them into meaningful feedback. This software varies significantly depending 
on the specific application. For the Translation performance, the raw data are received in Max, normalized 
and filtered, then sent via UDP network connection to a secondary show-control computer running custom 
Open Frameworks (a C++ toolkit) [9] software to control parameters of the visualization. This software 
is further explained in the System Architecture section. Augmenting Translation with Pendaphonics The 
previous sections have provided background information on the Translation performance and have covered 
technical and creative aspects of the Pendaphonics system. The following sections will go into more depth 
on the integration of these two projects. Motivation and Benefits For the first generation of Translation, 
the medium was entirely cued and controlled manually, by technicians pressing computer keys. While this 
system worked, it was not able to fully capitalize on the affordances of the interactive 3D program generating 
the visual feedback. With manually activated triggers, the system could only produce predefined movements, 
such as a large or small leap off of the lunar surface. With the Pendaphonics sensor system, the program 
can provide visualizations, in real time, that correspond directly to the continuous movements of the 
dancers. The effect of transferring significant parts of the show control from a technician to the dancers 
did not, and was not intended to, change the choreography of the performance. The performance retains 
the same movements, scene shifts, and timing, but several key improvements were immediately obvious. 
The chance of a cue being triggered at the wrong time, while rare with manual control, was essentially 
eliminated. The high-resolution position sensing allowed the magnitude of the dancers movements to be 
matched with perfectly scaled movements of the projected ground under their bodies. The sensor control 
allowed the show technician to focus on other aspects of the presentation. Pendaphonics Versus Alternative 
Motion Capture Technology The team working at the STREB Lab for Action Mechanics (SLAM) had long considered 
the benefits of integrating motion sensing with their multimedia dance performances. Surfaces are often 
outfitted with microphones to amplify the acoustics of the bodies that impact them. Elizabeth Streb has 
compared the use of physical apparatuses for expanding the range of human movement with the use of musical 
instruments to augment the human voice [10, 11]. Technology, especially in the form of mechanical inventions, 
is integral to the vision of this performance group. The reason for not including motion sensing has 
not been ideological. It has been purely practical. Optical motion capture was not considered viable 
for several reasons. The complex visual environments that include performance apparatuses, video projections, 
and the presence of audiences and support technicians in unpredictable locations make the occlusion of 
tracking markers extremely likely. Physical markers would create pressure points incompatible with the 
nature of the actions of the dancers and would be difficult or impossible to keep in place. Calibration 
requirements would be too time-consuming for live and traveling performances. Markerless optical systems 
are even more sensitive to environmental variables. Beyond these technical obstacles, full-blown motion 
capture systems optimized for special effects production and research activities provide much more data 
than what is required for this application. While a comprehensive survey of alternative human interfaces 
and motion tracking systems is beyond the scope of this paper, a few interesting, related alternatives 
should be noted. Kaufman presents a mechanically linked, harness-based motion capture system targeted 
at military virtual reality training applications [12]. This system would not match the low encumbrance 
require­ments for the STREB performers. Yang and Pai discuss the use of a harness outfitted with load 
cells [13]. In their research, the application automatically detects slips for use in movement therapy. 
While this is a significantly different application area, the availability of force sensing in the performers 
harnesses could expand the creative potential of our system. Char Davies Osmose [14] used a Polhemus 
Fastrak [15] sensor to measure position and orientation, and a custom vest/harness to measure the expansion 
and contraction of the wearer s chest. The Polhemus system costs around $6,000, so while this sensor 
could technically be a viable alternative, it would be much more expensive. The approach used to sense 
breathing in Osmose is an interesting one to consider for future collaborations with STREB, but it would 
require carefully designed wearable hardware for the extreme demands of the performers. The Pendaphonics 
system was a natural fit for this particular performance, as the dancers are suspended in harnesses (see 
Figure 6) and effectively become pendulums. The Pendaphone hardware allowed us to track the dancers movements 
in three dimensions as they traveled up and down the wall. The Pendaphone hardware, being based on a 
commercial game interface, is designed to be simple, low cost and very robust. Since the sensing is mechanical, 
visual occlusions and complexity are not relevant, and radio-frequency interference is never an issue. 
Pendaphonics has no encumbering effects on the dancers, enhances the expressiveness of the visual feedback 
system, and reduces the workload of the show technicians during live performances. System Architecture 
The integrated Translation and Pendaphonics system includes: 25-foot-tall vertical wall Custom harnesses 
that allow rotation on the torso axis Swivel connectors allowing rotation on the support cable axis Steel 
cable rigging line from the harness to the anchor point Electric motor winches to lift and lower dancers 
Pendaphonics hardware with line connected to rigging cable Laptop computer running Max Pendaphonics software 
Main show-control computer running Open Frameworks Translation visualization software Ethernet cable 
connecting Pendaphonics computer and show-control computer Audio-cue computer and PA system Video projector 
Three performers Technical support staff to supervise and run computers and motors, and assist performers 
Aaron Henderson programmed the visualization of the lunar surface using the Open Frame­works C++ toolkit. 
This visualization has a spherical object mapped with an image of the moon s surface. This sphere can 
be rotated in any direction at any speed and can be oriented to and positioned at any distance from the 
virtual camera. This control allows the performers to walk on the real floor towards the wall with an 
image of the moon very low on the horizon. As the performers transition from standing on the floor to 
walking up the wall, the virtual moonscape gradually shifts to a top-down view, so it appears that the 
dancers are walking on the surface of the moon and are being seen from overhead. When the dancers leap 
off the wall, the virtual distance to the moon is increased. This virtual distance is increased in an 
exaggerated scale, giving the optical impression of extremely large leaps. As the performers move toward 
one side of the wall, the moonscape rotates under their feet (as a treadmill would). Exaggerated rotational 
speeds are used expressively to give the illusion of very fast motion. Control of these visualiza­tion 
parameters is split between manually triggered cues and real-time Pendaphonics-driven modulation. Manual 
cues are used for major scene transitions (for example, when the performers transition to and from the 
wall) and when real-time sensing is potentially incongruous with the desired feedback for a particular 
section. Real-time Pendaphonics control can be manually overridden in such cases. Project Outcome The 
idea of taking mechanization, and taking robotics, and taking machines, and mixing them with human movement 
potential, and space and time, is really what the whole category of investigation is about [16]. Elizabeth 
Streb states: I think that people ignore and don t perceptually notice movement [17]. Streb describes 
the importance of having microphones positioned everywhere to allow the audience to hear the impacts 
of bodies against floors, walls, and performance apparatuses. The idea is to convey the substantiality 
of these impacts to the audience. The Pendaphonics system serves the same conceptual function as the 
microphones: amplifying a signal (in this case motion) to make it more perceptible to a large audience 
viewing the performers movements at a distance. Streb suggests that this amplified movement induces a 
feeling of vertigo in the audience. Streb, the production staff of Streb Extreme Action Company, and 
the Pendaphonics creators viewed the integration of the Pendaphonics system with the Translation performance 
as a great success. With this system, the dancers had direct control of key visual feedback parameters. 
This transfer of control improved the expressive range of the feedback by providing real-time position 
control of the virtual height and rotation of the lunar surface. This project served as a proof of concept 
of the effectiveness of using low-cost sensors and custom software to sense the motion of dancers and 
performance apparatuses in a challenging environ­ment. This sensing can enhance control of existing feedback 
and allow for the creation of new data-driven media that can reveal additional forces and actions, expanding 
the creative palette of the artistic director. For this iteration of the project, a single Pendaphonics 
sensor connected to a single performer was used as a simple resolution to the problem of potentially 
conflicting data when, for example, one performer made a big leap while the other two remained close 
to the wall. For future iterations, all the performers positions will be monitored and a more sophisticated 
algorithm will be generated to selectively average, filter, and prioritize sensor data for particular 
segments of the performance. Opportunities While working on the integration of Pendaphonics with Translation, 
we experimented with using Nintendo Wii Remotes [18] to measure the acceleration of spring boots worn 
in another perfor­mance. The wireless data from this type of sensor could enhance the perceptual experience 
of this performance by revealing the forces involved. Of particular interest might be the moments of 
zero gravity at the apex of leaps or the distinct data patterns created when the performers do flips. 
Feedback from these data could be in the form of audio, projection of light, or any other computer-controlled 
form. The application of real-time sensing need not be limited to audio and visual feedback. Physical 
actuation of performance apparatuses based on real-time sensing would open up new movement experiences 
and choreographic opportunities. Acknowledgements The authors would like to thank Bruce W. Ferguson and 
the Future Arts Research program at Arizona State University for their vision and financial support of 
this research. We thank the entire STREB Lab for Action Mechanics community for their warm welcome and 
collaborative spirit and action. References and Notes 1. F.A.R. @ ASU: Future Arts Research at Arizona 
State University, futureartsresearch.asu.edu/, accessed March 21, 2012. 2. A. Skriver Hansen, Pendaphonics 
installation at Platform4, 2008, www.platformart.net/pendaphonics_demo.htm, accessed March 21, 2012. 
3. A. Schmeder, A Portable Pendaphonics Rig, cnmat.berkeley.edu/user/andy_schmeder/blog/2009/05/31/portable_pendaphonics_rig, 
accessed March 21, 2012. 4. D. Overholt, et al., Pendaphonics, art installation at the International 
Conference on New Interfaces for Musical Expression, Carnegie Mellon University, Pittsburgh, 2009. 5. 
A. Skriver Hansen, et al., Pendaphonics: A Tangible Pendulum-based Sonic Interaction Experience, Proceedings 
of the 3rd International Conference on Tangible and Embedded Interaction (New York: ACM, 2009) 153 160. 
6. A. Freed, et al., Musical Applications and Design Techniques for the Gametrak Tethered Spatial Position 
Controller, Proceedings of the 6th Sound and Music Computing Conference, Porto, Portugal, 23-25 (2009). 
7. Gametrak, en.wikipedia.org/wiki/Gametrak, accessed January 7, 2012. 8. Cycling 74, cycling74.com, 
accessed January 7, 2012. 9. OpenFrameworks, www.openframeworks.cc/, accessed January 7, 2012. 10. E. 
Streb, Streb: How to Become an Extreme Action Hero (New York: The Feminist Press at CUNY, 2010) 83. 11. 
CUNYMedia, Streb: How to Become an Extreme Action Hero, 2010, www.youtube.com/watch?v=pOAHYF-WtBM, accessed 
March 21, 2012. 12. R.E. Kaufman, A Family of New Ergonomic Harness Mechanisms for Full-Body Natural 
Constrained Motions in Virtual Environments, 3D User Interfaces, 2007, 10 11 (2007). 13. F. Yang &#38; 
Y. Pai, Automatic Recognition of Falls in Gait-slip Training: Harness Load Cell Based Criteria, Journal 
of Biomechanics Vol. 44, No. 12, 2243 2249 (2011). 14. C. Davies &#38; J. Harrison, Osmose: Towards Broadening 
the Aesthetics of Virtual Reality, ACM SIGGRAPH Computer Graphics Vol. 30, No. 4, 25 28 (1996). 15. Motion 
tracking, 3D scanning, and eye tracking solutions from Polhemus, www.polhemus.com, accessed March 15, 
2012. 16. Motivational Environments, STREB BRAVE, video-recorded conversation between Elizabeth Streb 
and Winslow Burleson, 2009, vimeo.com/17161251, accessed March 21, 2012. 17. E. Streb, excerpt from Dancers 
Defy Gravity, KJZZ 91.5 FM, November 7, 2009. 18. Wii, www.nintendo.com/wii, accessed January 10, 2012. 
 Byron Lahey PhD Student Arizona State University School of Arts, Media and Engineering 699 S. Mill Ave., 
Room 395 Tempe, Arizona 85281 USA byron.lahey@asu.edu Winslow Burleson Assistant Professor Arizona State 
University School of Computing, Informatics, and Decision Systems Engineering P.O. Box 878809 Tempe, 
Arizona 85287-8809 USA winslow.burleson@asu.edu Elizabeth Streb Artistic Director STREB Extreme Action 
Company S.L.A.M. (STREB LABORATORY for ACTION MECHANICS) 51 North 1st Street Brooklyn, New York, 11211 
USA  Figure 1. Performers falling face-forward toward the wall after executing a synchronized leap. 
The projected lunar surface, visible on the wall, zooms in and out based on the performers distance from 
the wall. Image captured from video documentation of performance. &#38;#169; 2009 Elizabeth Streb.  
 &#38;#169; 2012 Byron Lahey, Winslow Burleson, Elizabeth Streb | Leonardo, Vol. 45, No. 4, pp. 322 329, 
2012 322  Figure 2. This early conceptual sketch of Translation shows the performers in relation to 
the required hardware that supports this performance. &#38;#169; 2009 Elizabeth Streb.   Translation 
+ Pendaphonics = Movement Modulated Media | Lahey et al. 323  Figure 3. Pendaphonics interactive art 
installation at the Platform 4 gallery in Ålborg, Denmark. Five Pendaphones are visible; one is being 
"plucked" by a boy. A video projec­tion shows the positions and movements of all the pendulum bobs. &#38;#169; 
2008 Dan Overholt.  Lahey et al. | Translation + Pendaphonics = Movement Modulated Media 324  Figure 
4. The Gametrak video game interface in its unmodified form. The two joystick connectors visible on the 
top of the interface pull out and retract allowing the hardware to provide 3D position information for 
two tracked points. This interface foreshadowed full body motion interfaces such as the Nintendo Wii, 
Microsoft Kinect and Playstation Move. &#38;#169; 2009 Byron Lahey.  Figure 5. Extended-range Pendaphone 
hardware attached above the performance wall. The line from the Pendaphone connects to the rigging used 
by the performers to ascend the wall. The larger retraction spring in the tape measure replaces the smaller 
original spring in the Gametrak, allowing the Pendaphone to track 3D motion from floor to ceiling. &#38;#169; 
2009 Byron Lahey.  Translation + Pendaphonics = Movement Modulated Media | Lahey et al. 325  Lahey 
et al. | Translation + Pendaphonics = Movement Modulated Media 326  Figure 6. Custom harnesses that 
allow for free rotation about the torso and rigging line axes. These harnesses, similar to those used 
for special effects stunt-work, allow the performers to flip, twist, and move freely across the wall. 
&#38;#169; 2009 Elizabeth Streb. Photo &#38;#169; 2009 Byron Lahey.  Translation + Pendaphonics = Movement 
Modulated Media | Lahey et al. 327  Lahey et al. | Translation + Pendaphonics = Movement Modulated 
Media 328  Translation + Pendaphonics = Movement Modulated Media | Lahey et al. 329  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2012</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>2341934</article_id>
		<sort_key>30</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>08-05-2012</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[From Wunderkammern to Kinect]]></title>
		<subtitle><![CDATA[the creation of <i>Shadow Worlds</i>]]></subtitle>
		<page_from>330</page_from>
		<page_to>337</page_to>
		<doi_number>10.1145/2341931.2341934</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=2341934</url>
		<abstract>
			<par><![CDATA[<p>This paper focuses on two projects, <i>Still Life No. 1</i> and <i>Shadow Worlds | Writers' Rooms [Bront&#235; Parsonage]</i>, to reveal the creative approaches the authors take to site, technology, and the self in their production of shadow worlds as sites of wonder. Informed by the uncanny (re-animation and the double) and an interest in the limen (thresholds in the real and virtual realms), the projects explore white light and infrared digital 3D scanning technologies as tools for capture and transformation. The authors will discuss how they suture the past with the present and ways that light slips secretly between us, revealing other realms.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P3734341</person_id>
				<author_profile_id><![CDATA[81504684879]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chara]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lewis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Manchester, United Kingdom]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P3734342</person_id>
				<author_profile_id><![CDATA[81504687870]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kristin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mojsiewicz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Manchester, United Kingdom]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P3734343</person_id>
				<author_profile_id><![CDATA[81504688591]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Annek&#233;]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pettican]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Manchester, United Kingdom]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P3734344</person_id>
				<author_profile_id><![CDATA[81504687609]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Brass]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Art]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Manchester, United Kingdom]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Brass Art, www.brassart.org.uk.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[B. M. Stafford, <i>Devices of Wonder</i> (Los Angeles: Getty Research Institute, 2001) 2.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[The Whitworth Gallery (www.whitworth.manchester.ac.uk/) and Manchester Museum (www.museum.manchester.ac.uk/) are both part of Manchester University. The commission by The Whitworth for the international group exhibition Dark Matters: Shadow Technology Art (www.whitworth.manchester.ac.uk/whatson/exhibition/darkmatters) gave Brass Art a unique opportunity to gain access to the museum stores and the expertise of individual curators. <i>Still Life No. 1</i> was supported by the Association of Art Historians, the University of Huddersfield, Ogle Models and Prototypes Ltd, and Huntsmen. darkmattersart.com]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M. Kingwell, "Husserl's Sense of Wonder," <i>The Philosophical Forum</i> Vol. 31, Issue 1, 85 (2000).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C. Olalquiaga, "Object Lesson/Transitional Object," <i>Cabinet</i> Issue 20, Ruins (2005/06).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Digital Doubles, www.digitaldoubles.org.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Scanning at Manchester Metropolitan University, School of Engineering, United Kingdom. 3D body scanning supported by Wicks and Wilson Ltd., United Kingdom.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[3D data were repaired at Liverpool National Museum's Conservation Technologies Department and printed at Ogle Models Ltd., United Kingdom, with sponsorship from Huntsmen.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[The circular table for <i>Still Life No. 1</i> with motorized revolving light was designed by theater engineer Andy Plant. This enabled Brass Art to move away from the garden model railway sets, which had facilitated linear light locomotion in previous installations (<i>Moments of Death</i> and <i>Revival</i>) and return the audience's focus to the shadow play.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[S. Greenblatt, "Resonance and Wonder," <i>Bulletin of the American Academy of Arts and Sciences</i> Vol. 43, No. 4, 11--34 (January 1990).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[The Bront&#235; Parsonage was the family home from 1820 to 1861. Charlotte's novel <i>Jane Eyre</i> (1847), Emily's <i>Wuthering Heights</i> (1847), and Anne's <i>The Tenant of Wildfell Hall</i> (1848) were written in this house. The Bront&#235;s, who published under the pseudonyms of Currer, Ellis, and Acton Bell, were acknowledged at the time for their directness and powerful emotional energy, qualities which were sometimes interpreted by the critics as "coarse" and "brutal." www.bronte.info/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[In 2009, we researched the potential of using Lidar scanning for a commission at the Lyric Theatre, Hammersmith, London, to capture both the outside of the building during its architectural transformation and performances that took place within its interior. Our aim had been to composite these viewpoints and to focus on the negative spaces within the process -- in other words, focus on what was most often unseen. A colleague, Spencer Roberts, working with the Kinect, was interested in how we envisaged using the technology to explore the shadows created in the captured data, and a collaboration was formed.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[V. I. Stoichita, <i>A Short History of the Shadow</i> (London: Reaktion Books, 1997) 171.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[V. I. Stoichita, <i>A Short History of the Shadow</i> (London: Reaktion Books, 1997) 145.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[V. I. Stoichita, <i>A Short History of the Shadow</i> (London: Reaktion Books, 1997) 185.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Simon Pantling, www.pantlingstudio.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Spencer Roberts, author of custom-built software for Kinect, spencerroberts.artsident.org/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[R. Descartes, <i>Discourse on Method and the Meditations</i> (Harmondsworth, United Kingdom: Penguin Classics, 1968) 110.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 From Wunderkammern to Kinect The Creation of Shadow Worlds Chara Lewis, Kristin Mojsiewicz, Anneké Pettican 
ABSTRACT This paper focuses on two projects, Still Life No. 1 and Shadow Worlds | Writers Rooms [Brontë 
Parsonage], to reveal the creative approaches the authors take to site, technology, and the self in their 
production of shadow worlds as sites of wonder. Informed by the uncanny (re-animation and the double) 
and an interest in the limen (thresholds in the real and virtual realms), the projects explore white 
light and infrared digital 3D scanning technologies as tools for capture and transformation. The authors 
will discuss how they suture the past with the present and ways that light slips secretly between us, 
revealing other realms. Introduction This paper will focus on two recent projects: Still Life No. 1, 
installed for Dark Matters: Shadow Technology Art, The Whitworth, Manchester, UK (2011-12), and Shadow 
Worlds | Writer s Rooms [Brontë Parsonage] (2011-12). Our description of these two projects will reveal 
the different creative approaches we take to site, technology, and the self, in our engagement with and 
production of shadow worlds as sites of wonder. For 10 years, a major focus for our collaborative practice 
has been to examine the nature of the double what it means to create one, how one might engage with 
an alter ego, how a double can stand-in for oneself, and how to populate chosen spaces with them. It 
is important for us to make these playful explorations manifest through our work, which often has improvised 
performance at its heart. Our artistic practice is informed by ideas of the uncanny (re-animation and 
the double) and an interest in the limen (thresholds in the real and virtual realms). We return to these 
themes again and again in our collaborative practice. Our work reveals our long-term fascination with 
heterotopic spaces the airport, the museum, publicly inaccessible spaces, as well as culturally loaded 
spaces [1]. For these reasons we find ourselves, or our doubles, in no-man s land, in imagined realms 
or occupying well-known collections. The projects described in this paper incorporate our interest in 
exploring digital technology as a tool for capture and transformation and as a hand-made, improvised, 
creative response to a situation or space. For the past four years we have been researching and developing 
a body of work that uses digital scanning to capture ourselves as faithfully as possible exploring the 
ontological question of what it is to be. In Moments of Death and Revival, our first project to use this 
technology, a moving light source illuminated a procession of human and hybrid animal models, casting 
their shadows upon the gallery wall. To create our shrunken doppelgängers, we were scanned using 3D body-scanning 
white-light technology (Figure 1). As part of this process, we actively tested and pushed the physical 
dimensions of the 3D body-scanning booth using improvised poses, explored 4D facial scanning to create 
faithful impressions of our features in motion (in order to develop large-scale 3D inflatable objects), 
and combined custom-written software with Microsoft s Kinect to capture a mise en abyme revealing our 
disguised selves being recorded. Through these processes, we created doubles and doppelgängers from live 
data and selected museological specimens. Still Life No. 1, Dark Matters: Shadow Technology Art Perceptual 
Wonder - The Collection Revisited The awe evoked by global multiplexing, online streaming and desktop 
computer animations recalls the wonder once aroused by obsolete gadgets and registered in mostly forgotten 
modes of perception. These magical artefacts similarly operated somewhere between game and experiment, 
toy and tech. Locating emergent private and mass media in the long tradition of optical aids exposes 
the multiple ways in which humans have been, and continue to be, playfully entangled with their beautiful 
devices [2]. Our interest in technological developments in the 18th and 19th centuries which led to 
the phantasmagoria show, the panorama and hot air balloon flight has been a significant aspect of our 
practice, traceable to the beginning of our collaboration. This interest is made manifest in shadow plays 
using a motorized light source and in creation of virtual shadows and digital sprites. From 2009 2011, 
we explored and responded to Manchester University Museum collections for a shadow installation commissioned 
by the Whitworth Art Gallery [3] (Figure 2). In our previous work with museum stores, we produced photographic 
works that appear to re-animate taxidermy specimens and illuminate strange juxtapositions of objects. 
It is significant that we were once again drawn to seek out specimens that had once lived and breathed 
and were now held in suspended animation, eschewing crafted artifacts and the ethnographic collections 
in favour of the zoology, mineralogy, and palaeontology collections. The phenomenology of wonder the 
experience of astonishment before the world and the beginning of philosophy [4] is worthy of exploration 
as an aspect of our encounter with the museum, as well as the audience s experience of the final installation 
of re-animated objects. Our sense of wonder comes from the overwhelming quantity of specimens, the surprising 
juxtapositions and revelations at the turn of a handle or the opening of a drawer. As non-scien­tists, 
we approach the museum collection with the same wonder as the collectors of the first Wunderkammern. 
These cabinets of curiosity were legitimate precursors of the public museum: ...the fabulous Wunderkammern, 
or wonder chambers, of the Renaissance, those immense collections of rare objects, where the natural 
and the artificial products of divine and human craft, respectively lived side-by-side as objects of 
amazement [5]. Our approach to the museum collection was eclectic, enabling the formation of our own 
taxonomies and collections of curiosities for our own ends. We enjoyed the strange illogical relationships 
that occur between objects not on public display. We were drawn to objects rejected as useful scientific 
specimens for lack of provenance, the anthropomorphic, the outsized or miniaturized models, the overlooked 
and outmoded. Our role was as both explorers responding to unexpected finds and physical phenomena, 
remaining open to shifts in the outcomes and directors of a growing number of individuals and companies 
who worked with us to realize the project. The Object Twice Removed Our ongoing work with 3D laser body 
scanning was extended to include the museum artifacts [6], and we selected a number of objects from the 
museum collection to be scanned [7]. Using the 3D scanner enabled us to watch a 3D digital copy of each 
object as it emerged on the screen, piece by piece. Twice displaced and now replicated, this process 
of removal and digitiza­tion marked the beginning of the objects transformation. The data were stitched, 
filled, and remotely printed using stereo laser-sintering processes in a transparent resin [8]. The transformation 
in scale between the original object and its copy is echoed in our own shrunken doppelgängers. These 
objects are combined on the tabletop still-life landscape and through their re-animation in the revolving 
shadow play cast onto the wall [9] (Figure 3). Still Life No. 1 A Shadow Play The evolution of Still 
Life No. 1 has been a playful and experimental process; each test leading to the introduction of new 
materials, bringing more delicate, temporary, and translucent elements to create both shadows and unexpected 
plays of light. There is a sense of the Kantian Sublime in relation to the gigantic scale of shadow achieved 
in the installation space. Our small 3D printed figures are absorbed into a landscape that turns as the 
motorized light makes its orbit, suggesting a shifting and allegorical relationship to cosmology. In 
direct reference to the heavens and our historical relationship to its signs, two comets appear. One 
is harnessed as a kite. The other haired star plummets toward a tiny figure holding a net. In other uncanny 
doublings, our figures appear to hold up elements of the landscape both inside and outside the transparent 
forms (Figure 4). In Still Life No. 1, the most solid element is not the tabletop collection of imperceptible 
transparent objects and figures, but the shadow play which animates and completes it. There is a preserved 
wonder inspired by the museum and the continuous transformations and shifting relationships made possible 
by the agency of the light. Ordinary cellulose wrapping is transformed into shadows that belie their 
flimsy origins and in turn create a poetic light play. This is the second aspect of wonder in the work. 
Stephen Greenblatt, writing in the bulletin of the American Academy of Arts and Science, describes resonance 
in relation to the museum object as: the power of the displayed object to reach out beyond its formal 
boundaries to a larger world, to evoke in the viewer the complex, dynamic cultural forces from which 
it has emerged and for which it may be taken by the viewer to stand. And Wonder as the power of an object 
to stop the viewer in his or her tracks, to convey an arresting sense of uniqueness, to evoke an exalted 
attention. He describes an experience of wonderful resonance and resonant wonder in an exhibition worth 
visiting [10]. In Still Life No. 1, the audience becomes entangled in the shadow world as the orbiting 
light slips past. Shadow Worlds | Writers Rooms [Brontë Parsonage] (2011-12) Three artists have gathered 
at night in the Brontë Parsonage, Haworth, England [11]. Inside the shuttered dining room, they wait, 
with disguises in hand, to begin an improvised performance. A photographer leans into the scene and attempts 
to capture the shadow narrative cast upon the papered wall. An intimate connection among performers, 
site, and photographer is established. Outside the scene, a curator and a collections manager watch from 
a distance. Between them and the wall, a fifth member of the assembled crowd hovers, approaches the scene, 
darts forward, and then steps back, Kinect and laptop balanced precariously in hand, like a director 
overseeing a film the moment is captured. This was our first performative foray inside the Brontë Parsonage, 
and it marked the beginning of a new series of works exploring the shadow. It is the second focus for 
our examination of shadow worlds. The Spectral Nature of Technology This site-specific project uses two 
forms of light to capture shadows: a medium-format digital camera to capture frozen moments from each 
scene as shadows on the wall, and Microsoft s Kinect, an on-range camera technology, coupled with custom-built 
software, to capture the live data from the improvised performance. It was an artistic decision to move 
our shadows into a new color-tinted realm that drew us to the wallpaper in the Brontë Parsonage (Figure 
5). We wanted to foreground this shift in our practice and draw parallels between our imaginary realm 
and those evoked by other female artists (writers Charlotte Perkins Gillman; Charlotte, Emily, and Anne 
Brontë; artist Francesca Woodman, et al.). We chose to work with the Kinect because it was designed for 
domestic spaces and would capture the mise en abyme the scene within the scene successfully in the 
darkened room [12]. The captured shadows in the Kinect footage are, in fact, the points where there is 
no data, an invisible shadow realm that the human eye cannot trace. The potential of the Kinect and its 
lasers to reveal and trace this shadowy territory is mysterious: people and objects unexpectedly appear 
and disappear, sometimes passing through a surface that would appear solid. This invisible realm, with 
its surprising spatial transformations, intrigues us. It offers us the potential to develop a new form 
of shadow play as yet uncharted (Figure 6). On our first nighttime visit to the parsonage, the focus 
was on using the Kinect to capture our close working relationship with the photographer. We wanted to 
show the process of our playful action research by recording it as a digitized shadow play. The work 
in situ is a form of private performance. It is not scripted but is pre-planned to a degree, and it requires 
spontaneity coupled with our willingness to adopt different personas, characters, props, and roles at 
will. Our aim is to arrange ourselves into tableaux that can be frozen at a moment in time. The recording 
of this moment ordinarily becomes the artwork. However, by capturing each of these short durational performances 
using the Kinect, we are able to review all the possibilities inherent in this new technology and foresee 
how we might further extend our practice. The Kinect data can be re-viewed in a number of dynamic ways 
because the Kinect records the geometry of the space, and everything that takes place within that space, 
using depth algo­rithms. We are able to view our actions in real time, fully rotated around any 360-degree 
point, zoomed, angled, looped, or inverted. The timeline opens up a wealth of editorial possibilities. 
It was this realization that allowed a conceptual shift in the project, enabling us to put the Kinect 
center stage on our second nighttime visit, and allowing the digital still camera to capture moments 
that emerged from our action research. Once again it was possible to capture the scene within the scene, 
this time with the still camera offering the expanded view of the tableaux. Having scrutinized the original 
footage, we further tested some of the scanning parameters, including the effect of reflective surfaces, 
foil, and mirrors. As artists, we were keen to see if we could disrupt the capture process and influence 
the likelihood of objects and people appearing and disappearing. As an example, we discovered that the 
Kinect could not easily see aluminum foil, so we used this material to mask and remove a head in one 
of the perfor­mances. Similarly, mirrors proved to be magical. As in real life, they presented us with 
a new way to see the scene. They enabled us to re-present the view of the room back to the Kinect and 
allowed parts of the performers to vanish as the frame and reflection occluded our forms. Throughout 
this iterative process, there remained a key focus: how could we manipulate the data holes and thus extend 
the reach of the shadow forms? Our discovery, achieved through playful improvisation with the equipment, 
was that the larger the distance between the objects, the walls, and the Kinect, so too the greater and 
more immersive became the shadow forms on screen. By placing ourselves at specific distances from the 
Kinect, we could manipulate the scale and reach of our shadows, and achieve a new, digital shadow world. 
The still images provide interesting documentation, particularly when the camera records reflected or 
deflected action in a mirror and captures unexpected forms cast onto the scenes and figures. Concurrently, 
the data captured by the Kinect in the second visit is more considered. With a refined understanding 
of the playback possibilities for the Kinect footage, we were able to fully utilize the rotating view 
for an improvised dance scene around the dining table the table the sisters walked around whilst reading 
aloud to each other from their works. Other scenes necessitated a fixed view to enable the illusion of 
disappearance, which a rotating view of the room would have undermined. In a site laden with historical 
resonance, our actions have both connected with the past and recorded a new layer. The Shadow Realm Throughout 
history, there have been interesting and divergent ideas about the shadow (Plato, Descartes, Stoichita, 
et al.) and differing views of what a shadow reveals. A shadow can mark a determined reality: It is through 
a shadow that a being is determined, where his identity is defined [13]. It can also open up a mysterious 
space: There are many more enigmas in the shadow of a man who walks in the sun, than in all religions 
of the past, present and future [14]. The shadow realm suggests both substance and outline. It can reveal 
the world for what it is, and it can surprise us with an unexpected glimpse of a positive world turned 
negative. This shifting dichotomy is what makes this territory such a rich and fascinating world for 
us to inhabit as artists. We are drawn to the shadow as a recurrent motif in our collaborative practice 
because of its ability to act as a source of wonder. It enables us to oscillate between these shifting 
and polarized viewpoints: For is the soul, in turn, nothing but yet another representation a butterfly, 
a shadow? [15] The Wonder of Vision In capturing the mise en abyme, we wanted to reveal the whole scene, 
the entire improvised performance, including the photographer [16], the Kinect director [17], the museum 
curator, and surrounding artifacts using two distinct time-based technologies. As Decartes wrote: What 
do I see . . . but hats and cloaks, which can cover ghosts or dummies who move only by means of springs? 
[18]. What is interesting and disorienting about the process is that the shadows cast by our figures 
(both disguised and simply being ) and seen by the lasers are entirely unseen by us during the process. 
They are also different to those captured by the lens of the medium-format camera. The two approaches 
we have used offer different perceptions of the space. The photo­graphs allude to a scene unseen outside 
the frame (Figure 7). The video reveals that scene but simultaneously records an unseen shadow realm. 
The juxtaposition of the works might lead the viewer to question their perception of the space, just 
as Descartes questioned his perception of an ordinary view. A Shadow Play for the Brontës When we show 
the clips of us working within the Brontë Parsonage, we are aware of a rapt attention within the audience. 
Whether this is the result of a perceived hauntology within the space or whether it is the surprising 
ability of new technologies to simply reveal what we cannot see, it is fascinating to us. It was this 
willing suspension of disbelief that first drew us to pre-cinematic spectacle as an important area for 
research within our own practice. In approaching this new project, Shadow Worlds | Writers Rooms, and 
in particular the Brontës world, we were drawn to the Glass Town Country of the Brontës childhood. This 
deliberately playful world is one that intrigued us. Play is at the heart of our own collaborative practice 
a way of exploring possible futures and alternative pasts. Literature is an important source of inspiration 
for us, and our engagement with the parsonage as a site where narratives were imagined, acted-out, written, 
and inscribed in time presented not only a resonant site, but also a site where shadows could be revealed 
and re-written. It is important to make clear that we had no desire to re-tell the life story of the 
Brontës, nor the plot of any of their novels. Rather, we wanted to inhabit their creative space and allow 
it to influence us in unexpected ways. The constraints and possibilities afforded by the interior architecture 
distorted and contained the shadows. We were aware of inhibitions of physical action coupled with an 
unbounded imagination. New dynamics between characters and sequential narratives emerged alongside our 
shape shifting and digital disappearances. In this sense, the space itself acted as a shadow, casting 
an echo of its past into our present. In turn, we created something in the present sutured together with 
the past. This is the final point to make: The uncanny pervades time, slipping forwards and backwards, 
unraveling the past and creating the future. Light slips secretly between us and those who came before 
us. Like an agent of wonder, it reveals a mysterious realm. Acknowledgements Brass Art would like to 
thank Helen Stalker, curator, The Whitworth Art Gallery, UK, and Jenna Holmes, curator, Brontë Parsonage 
Museum. All images courtesy of the artist (Brass Art) and The International 3 Gallery, UK. References 
and Notes 1. Brass Art, www.brassart.org.uk. 2. B.M. Stafford, Devices of Wonder (Los Angeles: Getty 
Research Institute, 2001) 2. 3. The Whitworth Gallery (www.whitworth.manchester.ac.uk/) and Manchester 
Museum (www.museum.manchester.ac.uk/) are both part of Manchester University. The commission by The Whitworth 
for the international group exhibition Dark Matters: Shadow Technology Art (www.whitworth.manchester.ac.uk/whatson/exhibition/ 
darkmatters) gave Brass Art a unique opportunity to gain access to the museum stores and the expertise 
of individual curators. Still Life No. 1 was supported by the Association of Art Historians, the University 
of Huddersfield, Ogle Models and Prototypes Ltd, and Huntsmen. darkmattersart.com 4. M. Kingwell, Husserl 
s Sense of Wonder, The Philosophical Forum Vol. 31, Issue 1, 85 (2000). 5. C. Olalquiaga, Object Lesson 
/ Transitional Object, Cabinet Issue 20, Ruins (2005/06). 6. Digital Doubles, www.digitaldoubles.org. 
7. Scanning at Manchester Metropolitan University, School of Engineering, United Kingdom. 3D body scanning 
supported by Wicks and Wilson Ltd., United Kingdom. 8. 3D data were repaired at Liverpool National Museum 
s Conservation Technologies Department and printed at Ogle Models Ltd., United Kingdom, with sponsorship 
from Huntsmen. 9. The circular table for Still Life No. 1 with motorized revolving light was designed 
by theater engineer Andy Plant. This enabled Brass Art to move away from the garden model railway sets, 
which had facilitated linear light locomotion in previous installations (Moments of Death and Revival) 
and return the audience s focus to the shadow play. 10. S. Greenblatt, Resonance and Wonder, Bulletin 
of the American Academy of Arts and Sciences Vol. 43, No. 4, 11 34 (January 1990). 11. The Brontë Parsonage 
was the family home from 1820 to 1861. Charlotte s novel Jane Eyre (1847), Emily s Wuthering Heights 
(1847), and Anne s The Tenant of Wildfell Hall (1848) were written in this house. The Brontës, who published 
under the pseudonyms of Currer, Ellis, and Acton Bell, were acknowledged at the time for their directness 
and powerful emotional energy, qualities which were sometimes interpreted by the critics as coarse and 
brutal. www.bronte.info/ 12. In 2009, we researched the potential of using Lidar scanning for a commission 
at the Lyric Theatre, Hammersmith, London, to capture both the outside of the building during its architectural 
transformation and performances that took place within its interior. Our aim had been to composite these 
viewpoints and to focus on the negative spaces within the process in other words, focus on what was 
most often unseen. A colleague, Spencer Roberts, working with the Kinect, was interested in how we envisaged 
using the technology to explore the shadows created in the captured data, and a collaboration was formed. 
13. V.I. Stoichita, A Short History of the Shadow (London: Reaktion Books, 1997) 171. 14. V.I. Stoichita, 
A Short History of the Shadow (London: Reaktion Books, 1997) 145. 15. V.I. Stoichita, A Short History 
of the Shadow (London: Reaktion Books, 1997) 185. 16. Simon Pantling, www.pantlingstudio.com/. 17. Spencer 
Roberts, author of custom-built software for Kinect, spencerroberts.artsident.org/. 18. R. Descartes, 
Discourse on Method and the Meditations (Harmondsworth, United Kingdom: Penguin Classics, 1968) 110. 
 Chara Lewis Artist Kristin Mojsiewicz Artist Anneké Pettican Artist Brass Art 12 Thorpe Street Old 
Trafford Manchester M16 9PR United Kingdom  Figure 1. Moments of Death and Revival (installation detail), 
2008. 3D printed objects (14 figures, 19cm to 25cm high) in acrylic polymer, train, track, lights, plinth, 
switch. Dimensions variable. Commissioned for Skyscraping at Yorkshire Sculpture Park, 2008, and shown 
as part of Concrete and Glass, Hoxton Square, London, 2010. &#38;#169; 2008 Brass Art. Photo &#38;#169; 
2008 Jonty Wilde.  &#38;#169; 2012 Chara Lewis, Kristin Mojsiewicz, Anneké Pettican | Leonardo, Vol. 
45, No. 4, pp. 330 337, 2012 330  Figure 2. Still Life No. 1 (installation mid-shot), 2011. Polypropylene, 
3D printed objects in resin, from 7cm to 75cm high. Dimensions variable, tabletop 2m diameter. Uncanny 
digital doubles, coupling the artists bodies with mineralogy specimens, create the transparent tabletop 
landscape. A motorized revolving light suggests a shifting and allegorical relationship to cosmology 
as it re-animates the landscape and objects through shadow play. &#38;#169; 2011 Brass Art. Photo &#38;#169; 
2011 Brass Art and Michael Pollard.  From Wunderkammern to Kinect The Creation of Shadow Worlds | Lewis 
et al. 331  Figure 3. Still Life No. 1 (installation view), 2011. Polypropylene, 3D printed objects 
in resin, heights from 7cm to 75cm. Dimensions variable, tabletop 2m diameter. This installation view 
reveals the scale of the 360-degree shadow play. &#38;#169; 2011 Brass Art. Photo &#38;#169; 2011 Brass 
Art and Michael Pollard.  Lewis et al. | From Wunderkammern to Kinect The Creation of Shadow Worlds 
 332  Figure 4. Still Life No. 1 (installation detail), 2011. Polypropylene, 3D printed objects in resin, 
heights from 7cm to 75cm. Dimensions variable, tabletop 2m diameter. In other uncanny doublings, the 
artists figures appear to hold up sculpted copies of the delicate landscape, standing both inside and 
outside the transparent forms. &#38;#169; 2011 Brass Art. Photo &#38;#169; 2011 Brass Art and Michael 
Pollard.  From Wunderkammern to Kinect The Creation of Shadow Worlds | Lewis et al. 333  Figure 5. 
Shadow Worlds | Writers Rooms [Brontë Parsonage] No. 6, 2011. Digital print on Hahnemühle Photo Rag, 
70cm x 1m. The artists, working with hand-made masks and props, improvised roles to create shadow tableaux 
to be photographed. The resulting images allude to "a scene unseen" outside the frame of the final image. 
&#38;#169; 2011 Brass Art. Photo &#38;#169; 2011 Brass Art and Simon Pantling.  Lewis et al. | From 
Wunderkammern to Kinect The Creation of Shadow Worlds 334  Figure 6. Shadow Worlds | Writers Rooms 
[Brontë Parsonage] Dining Room (video capture from Kinect scanner), 2011. Projection dimensions variable. 
Using infrared light to capture short sequential narratives offered new possibilities for creating a 
shadow play using depth algorithms, distance, and a variety of materials and props some visible and 
others invisible. This playful approach expanded narrative possibilities through a series of carefully 
crafted illusions. &#38;#169; 2011 Brass Art. Photo &#38;#169; 2011 Brass Art and Spencer Roberts.  
From Wunderkammern to Kinect The Creation of Shadow Worlds | Lewis et al. 335  Figure 7. Shadow Worlds 
| Writers Rooms [Brontë Parsonage] No. 3, 2011. Digital print on Hahnemühle Photo Rag, 70cm x 1m. This 
photo­graph was captured in the alcove of Mr. Brontë s Study. It reveals an intimate yet ambiguous relationship 
and demonstrates how the interior architecture of the site distorted and contained the cast-shadow realm. 
&#38;#169; 2011 Brass Art. Photo &#38;#169; 2011 Brass Art and Simon Pantling.  Lewis et al. | From 
Wunderkammern to Kinect The Creation of Shadow Worlds 336  From Wunderkammern to Kinect The Creation 
of Shadow Worlds | Lewis et al. 337  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2012</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>2341935</article_id>
		<sort_key>40</sort_key>
		<display_label>Pages</display_label>
		<pages>10</pages>
		<article_publication_date>08-05-2012</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Entr'acte]]></title>
		<page_from>338</page_from>
		<page_to>347</page_to>
		<doi_number>10.1145/2341931.2341935</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=2341935</url>
		<abstract>
			<par><![CDATA[<p>Looking at new public-space formations today, the roles of new technologies grow not only prominent but also noticeably time-sensitive. Due in part to the rapidly changing nature of communications media and the diverse stakeholders, the theatrical "entr'acte" appears to be an apt model for forms and durations of public space with diverse performers (both human and material elements) of different sorts: entr'acteurs. How is public space as physical construct changing with new embedded forms of computing? How is a public formed? What new material sensibilities emerge? And what role does their essentially fleeting or transitional character play?</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P3734345</person_id>
				<author_profile_id><![CDATA[81414603085]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jordan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Geiger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University at Buffalo, Buffalo, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[jordang@buffalo.edu]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[The field of urban computing is already being vigorously studied, and its history and theory are being written as they evolve. Refer for example to the annual UbiComp, Pervasive, and MediaCity conferences around the world and to recent books such as M. Shepard, ed., <i>Sentient City: Ubiquitous Computing, Architecture, and the Future of Urban Space</i> (Cambridge: MIT Press, 2011) for more.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M. Weiser, "The Computer for the 21st Century," <i>Scientific American</i>, Vol. 3, Issue 3, 94--104 (September 1991).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[G. Hardin, "The Tragedy of the Commons," <i>Science</i>, Vol. 162, 1243--1248 (December 1968).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Bouchard, La Langue Th&#233;atrale, Vocabulaire (Paris: Arnaud et Labat, Libraires-Editeurs,1878).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[E. Canetti, <i>Masse und Macht</i> (Hamburg: Claassen Verlag, 1960). www.google.com/url?q=http%3A%2F%2Fopenlibrary.org%2Fsearch%3Fpublisher_facet%3DClaassen&sa=D&sntz=1&usg=AFQjCNFavVRy62zoHaouVOCjSST7c3SPeQ]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>579424</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[H. Rheingold, <i>Smart Mobs: The Next Social Revolution</i> (New York: Basic Books, 2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[W. H. Whyte, <i>The Social Life of Small Urban Spaces</i> (New York: Municipal Art Society of New York, 1979).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. Boal, <i>Theatre of the Oppressed</i> (New York: Theatre Communications Group, 1993).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[This dialogue of sorts plays out in text, first proposed in A. Artaud, "Le Th&#233;&#226;tre et son Double," <i>Collection M&#233;tamorphoses No. IV</i> (Paris: Gallimard, 1938), and continued in B. Brecht, 1948--1956: Antigonemodell 1948: Couragemodell 1949. &#220;ber die Benutzung von Modellen (Berlin: Aufbau-Verlag, 1964).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[The show is presented online at www.continuouscity.org.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Super Vision, a collaboration with the design firm dbox, is documented online at www.google.com/url?q=http%3A%2F%2Fwww.superv.org&sa=D&sntz=1&usg=AFQjCNFzwr4qSQ8wmJsG-CPSpGrTRHc7xQ.org/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[A precursor to this sort of event construct that has received a fair bit of interpretation of late is Ant Farm's 1975 <i>Media Burn</i>, in which the group created an elaborate Independence Day faux-reportage at the launch and crash of a souped-up Cadillac into a pyramid of flaming televisions at San Francisco's Cow Palace parking lot.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[This work and its history are recounted thoughtfully and with quotes from the artist on the web site of the Dia Center for the Arts, at www.diaart.org/sites/page/51/1295.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[The project was produced in my 2010 graduate level "Entr'acte" studio, taught for the Situated Technologies Research Group at the University at Buffalo.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Entr acte Jordan Geiger ABSTRACT Looking at new public-space formations today, the roles of new technologies 
grow not only prominent but also noticeably time-sensitive. Due in part to the rapidly changing nature 
of communications media and the diverse stakeholders, the theatrical entr acte appears to be an apt model 
for forms and durations of public space with diverse performers (both human and material elements) of 
different sorts: entr acteurs. How is public space as physical construct changing with new embedded forms 
of computing? How is a public formed? What new material sensibilities emerge? And what role does their 
essentially fleeting or transitional character play? The proliferation of embedded technologies over 
the past 20 years the gradual migration of human-computer interaction from desktop to things, place-based, 
wearable and otherwise, situated often invisibly but strategically in the routine situations of daily 
life has starkly affected both the conception and use of public space. Thanks to the evolving forms 
and practices of urban computing [1] ranging from instant messaging to successful organizing and demonstrating 
in city squares against dictators to everyday navigation for a coffee date place-based, wearable, and 
mobile electronics represent a current iteration of the phenomenon identified in 1991 by Mark Weiser 
as ubiquitous computing [2], and it most recognizably affects uses of open public spaces, from streets 
and plazas to the very air above. After all this time, we can now also begin to recognize some relationships 
between material and scalar orders in the behavior of very large organizations (VLOs). VLOs are a phenomenon 
of our day and subject to further elaboration elsewhere, as the built environments of public assembly, 
work, agriculture, incarceration, trade, travel, education, even death join global financial and communication 
networks. The planning and infrastructure for these systems demand logistics, capital, and services for 
a new order of population magnitude that must accommodate volatile shifts in spatial and computational 
stability. Adaptability is at the crux of dealing with diverse users or publics and unprecedented technical, 
cultural, social, and ecological challenges. Thanks to urban computing, Garrett Hardin s notion of the 
commons [3] understood here as both public space and discourse today calls for new modes of work to 
harness its potentials for architecture, and new models to name it. One such model is the entr acte. 
The entr acte, a term from theater also translated as Zwischenspiel and as intermezzo, denotes the time 
and space between parts of a stage performance. Generally taking place before closed curtains as settings 
are changed, the entr acte delivers a fleeting new purpose and event to the otherwise sometimes inert 
space between stage and pit. While the history of this term (the French being not only the earliest, 
but appropriately close to our current use of the word interact ) reaches back at least to 1760 [4], 
its use in print clearly spiked twice in 1924, with the release of French Dadaist René Clair s film Entr 
acte, performed with the premiere of Erik Satie s Furniture Music and shown in Paris as part of Jean 
Börlin and Francis Picabia s ballet Relâche. This was the first known intervention of cinema in a live 
dance performance and hence perhaps the first intermedial construction of space-time in performance. 
The music and film were intended to fall into the background unnoticed and mimic the chatter that audiences 
would ordinarily produce during an intermission, much as ubiquitous computing tends to do today. As legend 
has it, audiences ironically sat quietly listening, thus frustrating the performers. And so the theatrical 
entr acte presents its mixture of mediated and physical space, its effort to create cultural and social 
relations within a space-time of distraction; its ephemeral protocols of spectator-actor disruptions 
are characteristics of the urban entr acte s appearance in mediated public space today. In today s public-space 
formations, roles of new technologies are both prominent and noticeably time-sensitive. Communication 
media and practices of urban space use and uses of technology change rapidly, yet physical construction 
of urban spaces changes slowly and with investments of capital from discreet sources (developers, governments) 
rather than the distributed, sometimes user-driven development of media networks that so abruptly change 
the lives of urban spaces. The entr acte is an apt model for analyzing and synthesizing creating new 
forms and durations of public space. The entr acte as model public space is one that can defy traditional 
limits of design and construction, allowing us to build publics without vast material intervention and 
deployment of capital to consider differences between publics and commons, to revisit old notions of 
planned obsolescence, and to recognize a diverse new set of players both human and material elements 
 as entr acteurs. This paper examines a set of cases in different fields in order to identify different 
forms of entr acte that emerge today, and to speculate on how they can reframe the spatial, temporal, 
and social terms of the commons now. It also self-consciously attempts to learn from the inherently interdisciplinary 
origin of the theatrical entr acte, as something that was always medial, architectural, social, and performative. 
In this sense, the use of this term is intended to promote an ongoing invention where fields and discourses 
meet. Analysis The entr acte has already been identified through numerous important analyses of publics 
and public space, all found between the disciplinary boundaries of media theory, urban studies, crowd 
psychology, architecture, and performance theory. A family of such analyses can be found in works by 
by Elias Canetti [5], Howard Rheingold [6], and William H. Whyte [7]. In the books Crowds and Power and 
Smart Mobs, and in the film The Social Life of Small Urban Spaces, respectively, these authors test diverse 
positions on public-space formations viewed from the outside, observing the movements and props, shapes, 
and boundaries of crowds themselves. In Canetti s book, each section identifies and then analyzes a different 
type of crowd or pack by its boundary condition, its process of formation, its mentality, or other circumstantial 
catalysts. Topics like The Fear of Being Touched, Slowness, Kinds of Pack, and Epidemics typify a study 
that tries to understand often inherently violently relating publics through history. Canetti formulates 
a taxonomy of crowd types and psychological affects, correlating these to timeless protocols of public 
interaction. Public space and public behavior are always fleeting and intertwined for Canetti, yet their 
forms persist and reappear over time. Rheingold s 2003 work, on the other hand, is to be read in its 
moment and projecting forward, both declaring and calling for development of collective intelligence 
and new social practices in the use of mobile technologies in urban space. Smart Mobs is a celebratory 
work that finds nothing less than social revolution in distributed power provided by mobile telecommunications 
and anyone who is able to be an effective activist thanks to technologies of cooperation and swarm intelligence. 
Rheingold continues to advocate for wirelessly communicating publics as an emergent political-social-technological-urban 
form an inherently contemporary entr acte, in short through the book s continuing web site and his 
blogging, tweeting, and public speaking. Whyte, by contrast, takes a fairly laconic stance in his use 
of film. Produced in 1980 for New York City s Municipal Art Society, Whyte s film trains its camera on 
Mies van der Rohe s Seagram Building (Figure 1) but pointedly chooses to say nothing of it per se. Rather, 
the building plaza and other nearby places like Paley Park appear as a proscenium for unscripted (or, 
perhaps, subconsciously scripted) actors, each with their own props: movable chairs, water, even sunlight 
itself. This could be seen as proto-technological in its relation to Canetti and Rheingold, as public 
space literally frays at the edges, and its activities are observed live, albeit from a distance, to 
be growing and improvisational by design and within controlled parameters tacitly determined by the administrations 
of these urban spaces. In other words, one might see all three authors as identifying and analyzing fleeting 
public-space formations, yet each associates particular temporal, technological, and spatial characteristics 
to their subject. For Canetti, power and hegemony determine ur-entr acte formations. For Rheingold, mobile 
communications unleash unpredictable, anti-hierarchical, productive formations that transcend physical 
boundaries in public space (Figure 2). For Whyte, everyday public interactions are literally viewed as 
performances, loosely staged by elemental physical mediators like warmth, sound, and rest. These all 
analyze crowds as actors, individuals with collective behaviors, and temporal and spatial patterns subject 
to manipulation, optimization, suppression, and perhaps emancipation. Control comes to the fore in this 
mode, a measure of rupture in the life of public spaces relative to their programmed uses and regulation 
of things like movable chairs, fountains, network outages, and place-based sensors. By contrast, Brazilian 
theater director Augusto Boal [8] literally analyzes or dismantles actor-public relations with the spectactor. 
This creation, both literally theatrical and generative of a public, was conceived against the backdrops 
of complementary positions found in Brecht s Epic theater and Artaud s Theater of Cruelty [9]. Briefly, 
the three theatrical models seek audience engagement as publics by way of framing the experience of immersion, 
a byword familiar to media-interaction design today. Artaud sought literally to surround and envelop 
audiences viscerally, physically, and ultimately psychologically with stage and production, setting publics 
into sudden unity through their immersion in the spectacle. Brecht departed from this with his total 
distaste for illusion, constructing stagings that fostered an audience s intellectual awareness of the 
production, purging all illusion or emotional manipulation. This strategy separated social and spatial 
constructions in order to draw distinctions between the theater event (as a space of discourse) and public 
space outside (as real spaces of negotiation, where lessons learned in the theater could be implemented). 
Today, Boal sets out to eliminate the difference between performer and public altogether by developing 
a workshop method of collaborative spectactorship. Here, strategies involving workshop scenarios, erasure 
of proscenium seating, and the attendant inundation of all present with the event of performance contribute 
to the systematic disturbance of distinctions between the audience and actors, resulting in a mass of 
spectactors (Figure 3). The spectactors double lives as full participants are essential to fostering 
collaboration that is resistant to any fixed power structure or spatial configuration. This process actively 
seeks to transform its audience as actor, to construct a scenario with like participants from the start, 
and to plan ahead strategically rather than tactically. It stages interventions proactively, with precise 
arenas of interest and known starting points. Synthesis What, then, does the entr acte look like in the 
city itself, what situations does it model, and how is that model deployed? Beyond the immersion of media 
environments and their spectacular results in urban screens, the entr acte s greatest potential exists 
in the social and material amalgams that rapidly organize and reconfigure the commons. These constructs 
can be recog­nized by their different methods of synthesis, which are determined in turn by limited temporal 
and spatial circumstances. The following examples illustrate four of these synthetic methods of creating 
the entr acte, as Sampling, Retinal, Social, and Embodied. These are recognizable methods of deliberate 
creation of the entr acte today, and a starting point for new ones. Sampling In Continuous City [10] 
and Super Vision [11], two black-box theater performances conceived and performed by The Builders Association 
since 2005, onstage performers interact with one another, the seated audience, and a larger-than-life 
projected screen simultaneously. The many interwoven narratives that occur between the screen and the 
stage make reference to our habits of sampling ourselves and our databases in real time. Identity theft, 
border controls, business development all crisscross unstable regions of mediated space and time. Though 
these parafictional narratives take place in the theater, they are also networked in real time to family 
members of the cast (Figure 4). Through subtle variations in each iterative performance of the show, 
an evolving narrative structure is generated that combines on-site filming and a participatory web site 
that contributes new content for each location, resulting in a cinematic-staged hybrid not entirely unlike 
René Clair s 1924 Entr acte on the Champs-Elysées. The productions are semi-scripted, quasi-contained 
spectacles with the audience, a sampling also of routines undertaken outside by all present and necessarily 
evolving by location and over time as each new city provokes presen­tation of different common ways of 
interacting with media technologies. At the outset of each performance of Super Vision, the audience 
itself is converted to a protagonist by a welcoming speaker, who riffs on actual demographic information 
gleaned from anonymized postal code and credit card information used to purchase that night s tickets. 
As the speaker tells the audience about itself and its consumer, age, and political tendencies, sampling 
of the public s information its databody, as Builders director Marianne Weems refers to it in the show 
s script introduces the night s work and its space, straddling the proscenium and the spatial and computational 
spaces in which audience members live. Sampling is process and object here the spatial condition in which 
a public comes together and these are the terms of Super Vision as an entr acte. Retinal The retinal 
entr acte brings live audience engagement with its own data out to the urban sphere by deploying provocations 
that match-cut scales of experience to one another, from the eye (the space of vision) to the sky itself 
(perhaps the most elusively public space to define) [12]. Here we can revisit Hardin s notion of the 
commons and its shifting atmospheric construction. In Hardin s argument, the commons is bound up with 
its tragedy in human selfishness: shepherds will always have individual incentive to bring another sheep 
to graze on a commons, but the inability for a common pasture to support limitless sheep leads to its 
destruction when the pasture is overexploited. This calls for a fundamental extension of morality rather 
than any technical solution, and an abandonment of key freedoms in the commons. In the context of population 
density, Hardin grimly concludes: Freedom to breed will bring ruin to all. This global conclusion is 
literally a result of the global problem that was his subject. For this discus­sion, we can scale down 
the commons from the global again. As an urban construct of both public space and public discourse, atmosphere 
serves as both space (the air, the sky, pollution) and discourse (urban policy, public events). This 
atmospheric commons opens participants to engage with the questions of morality that Hardin described. 
Nuage Vert (Green Cloud), conceived and mounted since 2004 by the Paris-based partner­ship of HeHe (Heiko 
Hansen and Helen Evans), relies on the courageous collaboration of an enlightened local power utility 
(hence there has been only one full realization to date, hosted in Helsinki). This cloud looms over the 
city nominally as a nighttime urban light installation, relying technologically only on thermo­graphic 
cameras and a high- power laser light. Projected on the plume of exhaust from a power plant chimney, 
the green laser draws and redraws the cloud s contours perpetually (Figure 5) as an index of the city 
s household waste incineration. The resultant spectacle might end as a classically detourned urban moment, 
a monumentalization of an environmental pathogen hiding in collective plain sight. But the project is 
supported by a city-run media campaign to get residents to produce less waste and collectively make the 
cloud vanish. This process uses the spectacle as a prop to mediate between the power plant itself, the 
mayor, non-profits, and citizens, all as entr acteurs. Nuage Vert s particular constellation of media 
does not include the typical components of urban computing, but many of its protocols engage with remote 
sensing within the context of a contemporary atmospheric commons, one that fuses the public as space, 
as participant, and as air quality. As an entr acte, the project is also fleeting in its month-long administration 
as an art project, but maybe even more so in its self-destructive formation, since it attempts to reduce 
waste until the project s own matter itself vanishes. Social This type of participation gestures toward 
a form of the social entr acte, a construct independent of visual spectacle. The social entr acte might 
have its progenitor in social sculpture as it was coined by Josef Beuys. In his 7000 Eichen (7000 Oaks) 
(1982-1987) [13], Beuys dutifully if heroically replanted a barren Kassel at the behest of the Documenta 
art festival its visual artifacts not so much spectacular as hiding in plain sight, literally about 
as interesting to watch as grass grow, and measurable for their progress alongside the one-meter basalt 
steles placed next to each tree. Anyone could plant one of these trees and contribute to the healing 
that Beuys hoped to bring about for the city. Participation is at the heart of social sculpture, an invitation 
organized by the artist that constructs a visible commons but by social protocols. The social entr acte 
is visible but sometimes only incidentally so. Its deployment of crowds, space, and mediation creates 
new forms of agency for largely familiar objects. Participatory Urbanism, for example, is a set of objects 
 mostly cell phone attachments created by Eric Paulos and his collaborators and generated out of his 
expertise as an electrical engineer, his practice as an artist, and his personal love of citizen science. 
Participatory Urbanism consists of various simple custom electronic devices that ride opportunistically 
on mobile hosts, each with environmental sensors on taxis in Accra, Ghana (Figure 6), on street sweepers 
in San Francisco, or attached to cellular phones anywhere. These devices append existing urban technologies, 
in each case gradually turning pedestrian and automotive participants alike into expert amateurs. The 
expert amateur is a key term for Paulos, as it is born of the practice known as citizen science that 
empowers anyone to be a generator of data rather than only a recipient or reader. Here we see entr acteurs 
come into focus and assume names. Akin to the spectactor in the realms of research, the citizen scientist 
began with the annual Christmas Bird Count inaugurated a century ago by the Audubon Society, for which 
anyone is invited to collect and help build a collaborative sense of bird migrations. Similarly in Paulos 
works, any participant enabled with his team s devices can feel empowered as an expert amateur, contributing 
to and benefiting from a live feed of data on urban NOx conditions mono-nitrogen oxides, an indicator 
of greenhouse gases by receiving live maps and messages on their phones that help make decisions about 
their move­ments in the city. Paulos conducts workshops in which he discusses the many sensors that most 
cell phones already contain, from light meters to accelerometers, and how urban computing can engage 
citizens by asking questions about their cities. Paulos objects resemble and even attach to the technologies 
situated in public space already, yet they suggest a potential to spark next objects, next spaces, as 
their own usefulness fades into obsolescence. Embodied Finally, the embodied entr acte synthesizes movement 
and sensation, allowing dynamically shifting relations between individuals and crowds in motion. Motion 
is an essential freedom in urban space and in urban computing environments created by the embodied entr 
acte. Ultimately, freedom of motion may emerge as the most salient if classical characteristic of the 
entr acte in general. It enables rapidly shifting formations of publics, of public discourses and public 
spaces. It also fuses the roles of haptic and sensed, material qualities of public space as they have 
been defined, from sound and warmth (Whyte) to touch and fear (Canetti), with the rapidly evolving forms 
of urban computing that are changing participation in the commons by mediating air (Paulos) and privacy 
(Builders Association). These are some of the ideas present in Michael Kirschner s Feeling, a set of 
speculative studies for the moving crowds that Elias Canetti identified in his book and that can be found 
in Toronto s citizens in their daily commute [14]. Feeling is located in three sites (underground, above 
water, and above ground) (Figure 7) along a major commuter artery that leads to Nathan Philips Square, 
the plaza in front of city hall downtown. In each, invented new prototypes augment everyday interactions 
in public spaces and occupy the place of distraction between strangers, sometimes literally reaching 
their hearts. The Feeling wearable heart monitor (Figure 8), for example, is based on the same technology 
found in common running gear today for sensing biometrics, but it also taps pressure points on its wearer 
in response to received pulses from nearby wearers. This interaction is based on proximity and on feeling 
a common urban object, such as a straphanger on a streetcar. It opens the opportunity for a public formation 
based on purely felt communication and in which the sort of pack mentalities analyzed in Canetti s Crowds 
and Power can be made palpable, negotiable individually, and built collectively, and fused with the physical 
matter of public-space infrastructures of the city. The proposal has an unabashed creepiness to it, since 
it pushes corporeal, informatic, and urban boundaries to a logical convergence in a way that might already 
be occurring and that could well turn completely dystopic. But it also hands agency back to the extension 
of morality that Garrett Hardin found necessary in preserving any commons, since pulse itself becomes 
everyone s concern once they opt in. Conclusion The entr acte is a fact not a cause but a model and 
a method; it has long been with us in our performances and in our formation as publics onstage and in 
the streets, online, and in motion. Today the stakes and the opportunities for us all as entr acteurs 
are different: to live within the fleeting changes in technologies and motion, in physically and digitally 
mediated spaces, as citizens and scientists, artists, architects, and so on. The entr acte might ask 
us to stop thinking of public space altogether and replace it with the commons in all its appearances 
as both space and discourse, material and immaterial. This entr acte serves us, in short, not only for 
analyzing and understanding the hybrid and evanescent natures of the commons in transition today; it 
also charges us with engaging, synthesizing, and, importantly, disciplining how we form it (through the 
retina, through embodiment, etc.). The entr acte now requires qualification and cultivation at each instance, 
so we can all continually learn to best participate as individuals within a world of very large organizations. 
References and Notes 1. The field of urban computing is already being vigorously studied, and its history 
and theory are being written as they evolve. Refer for example to the annual UbiComp, Pervasive, and 
MediaCity conferences around the world and to recent books such as M. Shepard, ed., Sentient City: Ubiquitous 
Computing, Architecture, and the Future of Urban Space (Cambridge: MIT Press, 2011) for more. 2. M. Weiser, 
The Computer for the 21st Century, Scientific American, Vol. 3, Issue 3, 94 104 (September 1991). 3. 
G. Hardin, The Tragedy of the Commons, Science, Vol. 162, 1243 1248 (December 1968). 4. A. Bouchard, 
La Langue Théatrale, Vocabulaire (Paris: Arnaud et Labat, Libraires-Editeurs,1878). 5. E. Canetti, Masse 
und Macht (Hamburg: Claassen Verlag, 1960). www.google.com/url?q=http%3A%2F%2Fopenlibrary.org%2Fsearch%3Fpublisher_facet%3DClaassen&#38;sa=D&#38;sntz=1&#38;usg=AFQjCNFavVRy62zoHaouVOCjSST7c3SPeQ 
6. H. Rheingold, Smart Mobs: The Next Social Revolution (New York: Basic Books, 2003). 7. W.H. Whyte, 
The Social Life of Small Urban Spaces (New York: Municipal Art Society of New York, 1979). 8. A. Boal, 
Theatre of the Oppressed (New York: Theatre Communications Group, 1993). 9. This dialogue of sorts plays 
out in text, first proposed in A. Artaud, Le Théâtre et son Double, Collection Métamorphoses No. IV (Paris: 
Gallimard, 1938), and continued in B. Brecht, 1948 1956: Antigonemodell 1948: Couragemodell 1949. Über 
die Benutzung von Modellen (Berlin: Aufbau-Verlag, 1964). 10. The show is presented online at www.continuouscity.org. 
11. Super Vision, a collaboration with the design firm dbox, is documented online at www.google.com/url?q=http%3A%2F%2Fwww.superv.org&#38;sa=D&#38;sntz=1&#38;usg=AFQjCNFzwr4qSQ8wmJsG-CPSpGrTRHc7xQ.org/. 
12. A precursor to this sort of event construct that has received a fair bit of interpretation of late 
is Ant Farm s 1975 Media Burn, in which the group created an elaborate Independence Day faux-reportage 
at the launch and crash of a souped-up Cadillac into a pyramid of flaming televisions at San Francisco 
s Cow Palace parking lot. 13. This work and its history are recounted thoughtfully and with quotes from 
the artist on the web site of the Dia Center for the Arts, at www.diaart.org/sites/page/51/1295. 14. 
The project was produced in my 2010 graduate level Entr acte studio, taught for the Situated Technologies 
Research Group at the University at Buffalo.  Jordan Geiger Architect and Assistant Professor University 
at Buffalo Department of Architecture 114 Diefendorf Hall Buffalo, NY 14214 USA jordang@buffalo.edu 
 &#38;#169; 2012 Jordan Geiger | Leonardo, Vol. 45, No. 4, pp. 338 347, 2012 338  Figure 1. Still from 
the 1980 film The Social Life of Small Urban Spaces, by William H. Whyte, showing time-lapse camera and 
daylight washing across Seagram Plaza. &#38;#169; 1980 Municipal Art Society.  Entr acte | Geiger 339 
 Figure 2. Video still from youtube, Michael Jackson Flash Mob, Embarcadero Plaza San Francisco, 2009. 
&#38;#169; 2008 The Hero.  Geiger | Entr acte 340  Figure 3. Boal workshop at Riverside Church in 
New York City, 13 May 2008. &#38;#169; 2009 equalityisforall.  Entr acte | Geiger 341  Figure 4. Production 
photo: The Builders Association, Super Vision, 2005. &#38;#169; 2005 The Builders Association. Photo 
by dbox.  Geiger | Entr acte 342  Figure 5. HeHe, Nuage Vert, St. Ouen, France, 2008. &#38;#169; 2009 
HeHe.  Entr acte | Geiger 343  Figure 6. Eric Paulos, Participatory Urbanism: carbon monoxide readings 
across Accra, Ghana, 2006. &#38;#169; 2008 Eric Paulos.  Geiger | Entr acte 344  Figure 7. Michael 
Kirschner, Feeling, systems diagram at trolley turnaround, 2010. &#38;#169; 2010 Buffalo Architecture 
/ Michael Kirschner.  Entr acte | Geiger 345  Figure 8. Michael Kirschner, Feeling, heart monitor, 
2010. &#38;#169; 2010 Buffalo Architecture / Michael Kirschner.  Geiger | Entr acte 346  Entr acte 
| Geiger 347  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2012</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>2341936</article_id>
		<sort_key>50</sort_key>
		<display_label>Pages</display_label>
		<pages>10</pages>
		<article_publication_date>08-05-2012</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Soundspheres]]></title>
		<subtitle><![CDATA[Resonant Chamber]]></subtitle>
		<page_from>348</page_from>
		<page_to>357</page_to>
		<doi_number>10.1145/2341931.2341936</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=2341936</url>
		<abstract>
			<par><![CDATA[<p>This paper develops a brief historical account of the architectural development of auditory space and identifies the "soundsphere" as an acoustic project that connects the interrelationships between material, spatial form and sound. The instrumental design of the soundsphere has focused on three types of shells: hard, static, and inflexible; physically manipulable; and immaterial (or electroacoustic). This frames a disciplinary and historical context for Resonant Chamber, a prototype-based design research project that develops a kinetic and interactive interior envelope system aimed at transforming the acoustic environment through dynamic spatial, material, and electroacoustic technologies.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P3734346</person_id>
				<author_profile_id><![CDATA[81504688097]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Geoffrey]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Th&#252;n]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Michigan, Ann Arbor, MI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[gthun@umich.edu]]></email_address>
			</au>
			<au>
				<person_id>P3734347</person_id>
				<author_profile_id><![CDATA[81504688203]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kathy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Velikov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Michigan, Ann Arbor, MI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[kvelikov@umich.edu]]></email_address>
			</au>
			<au>
				<person_id>P3734348</person_id>
				<author_profile_id><![CDATA[81504683057]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Colin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ripley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ryerson University, ARC, Toronto, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[cripley@ryerson.ca]]></email_address>
			</au>
			<au>
				<person_id>P3734349</person_id>
				<author_profile_id><![CDATA[81504684362]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Lisa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sauv&#233;]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Research associate and designer, Ann Arbor, MI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[lisa@rvtr.com]]></email_address>
			</au>
			<au>
				<person_id>P3734350</person_id>
				<author_profile_id><![CDATA[81504686344]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Wes]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McGee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Michigan, Ann Arbor, MI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[wesmcgee@umich.edu]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M. McLuhan, "Inside the Five Sense Sensorium," <i>The Canadian Architect</i> Vol. 6, No. 6, 50 (1961).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M. Treib, <i>Space Calculated in Seconds: The Philips Pavilion, Le Corbusier, Edgard Var&#232;se</i> (Princeton: Princeton University Press, 1996).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[H. Bagenal, "Influence of Buildings on Musical Tone," <i>Music &amp; Letters</i> Vol. 8, No. 4, 439--441 (October 1927).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[H. Morgan, ed., <i>Vitruvius: The Ten Books on Architecture</i> (New York: Dover Publications, 1960).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bagenal, 442--443.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[H. Bagenal, "Bach's Music and Church Acoustics," <i>Music &amp; Letters</i> Vol. 11, No. 2, 146--155 (April 1930).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[F. A. Yates, <i>Theatre of the World</i> (Chicago: University of Chicago Press, 1969).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Crunelle, "Is There an Acoustical Tradition in Western Architecture?" <i>First International Conference On Acoustic Ecology</i> (1993), www.wseas.us/e-library/conferences/skiathos2001/papers/102.pdf (accessed March 10, 2012).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[E. Thompson, <i>The Soundscape of Modernity: Architectural Acoustics and the Culture of Listening in America, 1900--1933</i> (Cambridge: MIT Press, 2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Thompson, Ibid.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[R.M. Schafer, <i>The Tuning of the World</i> (New York: A. A. Knopf, 1977).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[K. Velikov, et al., "Toward Responsive Atmospheres: Prototype Exploration Trough Material and Computational Systems," <i>Integration through Computation: Proceedings of the 31st Annual Conference of the Association for Computer Aided Design in Architecture (ACADIA)</i> 2011, 326--333 (2011).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. O'Rourke, <i>How to Fold It: The Mathematics of Linkages, Origami and Polyhedra</i> (Cambridge: Cambridge University Press, 2011).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1499744</ref_obj_id>
				<ref_obj_pid>1499586</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[R. Resch, "The Topological Design of Structural and Architectural Systems," <i>AFIPS Conference Proceedings</i> Vol. 42, National Computer Conference (1973).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[T. Tachi, "Rigid-Foldable Tick Origami," <i>Proceedings of 5OSME</i>, Singapore (2010).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[E. Corteel et al., "Objective and Subjective Comparison of Electrodynamic and MAP Loudspeakers for Wave Field Synthesis," AES 30th International Conference (2007).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[V.M.A. Peutz, "The Variable Acoustics of the Espace de Projection of IRCAM," <i>Proceedings of the 59th AES Convention</i> (1978).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 354 355 Soundspheres: Resonant Chamber Geoffrey Thün, Kathy Velikov, Colin Ripley, Lisa Sauvé, Wes 
McGee ABSTRACT This paper develops a brief historical account of the architectural development of auditory 
space and identifies the soundsphere as an acoustic project that connects the interrelationships between 
material, spatial form and sound. The instrumental design of the soundsphere has focused on three types 
of shells: hard, static, and inflexible; physically manipulable; and immaterial (or electroacoustic). 
This frames a disciplinary and historical context for Resonant Chamber, a prototype-based design research 
project that develops a kinetic and interactive interior envelope system aimed at transforming the acoustic 
environment through dynamic spatial, material, and electroacoustic technologies. Introduction Auditory 
space, so critical to architectural problems today, is usually defined as a field of simultaneous relations 
without center or periphery. That is, auditory space contains nothing and is contained in nothing. - 
Marshall McLuhan [1] In his 1958 Poème Electronique, the architect Le Corbusier developed, in collaboration 
with composer Edgard Varèse, a total sensorial experience of light, sound, and image. The carefully curated 
imagery and colors presented in essence a cosmogony in seven sections. Meanwhile, Varèse s soundscape 
(although this term had not yet been invented) made use of 350 loudspeakers to create a spatial sonic 
experience, localizing sounds within the space and moving sounds through the space. Curiously, perhaps, 
Le Corbusier seems to have prioritized the spatial effects of sound and light production over his efforts 
on the design of the vessel the Philips Pavilion, which he seems to have left primarily in the hands 
of the project manager in his office, Iannis Xenakis [2]. Was it that Le Corbusier was more concerned 
with the fluid and dynamic auditory space (identified a few years later by McLuhan) than with its static 
container? In the ongoing project of defining the relationship between space and enclosure, center and 
periphery, material and void, transient and static, the electronic technology of the loudspeaker and 
artificial lighting had rendered the enclosure, the building, the architecture in a classic sense, superfluous. 
Ceci tuera cela. Within the architectural traditions of auditory space, two distinct histories may be 
found: one of sound control in the physical realm of form and material, and the other in the electroacoustic 
realm of signal processing technologies. Resonant Chamber is a prototype for a responsive acoustic envelope 
system that aims to create a transformable acoustic environment that operates within the space of tension 
between these two realms. The work is developed through computa­tional and material testing, as well 
as full-scale prototype installation, and it combines kinetic components with computationally driven 
sensing and actuation regimes that dynamically transform the acoustic environment relative to both sonic 
inputs and human interaction. Background Soundspheres Within architecture, the acoustic project, or what 
might be termed the soundsphere, may be defined as a perceived volume of acoustic control or apprehension, 
variable according to spatial, material, physiological, psychological, social, and political contexts. 
The intentional shaping and control of aural space through the interaction of form and matter goes back 
to the original traditions of Western architectural practice and theory: ancient Greek amphitheaters, 
such as those at Miletus, Rhodes, Syracusa and Epidaurus, have all been found to deploy specific geometric 
and construction techniques to control and project the sounds of the performers [3]. Vitruvius famously 
and influentially describes the use of bronze sounding vessels to tune the acoustic properties of performance 
spaces, while reminding us of the need for architects to understand the harmonic properties of music 
[4]. In the context of the soundsphere, it has been argued that the building itself may become an instrument, 
coevolving with music, as has been proposed in the case of the evolution of medieval plainsong in the 
highly reverberant cathedrals to elaborate counterpoint in the less lively churches of the German reformation 
[5], or musical works designed for the highly specific acoustics of particular buildings [6]. Frances 
Yates has convincingly analyzed the Elizabethan theater as a carefully constructed and controlled sound­sphere, 
with the actor placed strategically at the acoustic focus of the space [7]. Outside of spaces for music 
and performance, acoustic spaces within other listening contexts, such as Marin Mersenne s acoustic lenses, 
Athanasius Kircher s listening machines, and Christopher Wren s Whispering Gallery in St. Paul s Cathedral, 
all deliberately control, measure, understand, and make use of soundspheres as fundamentally borne of 
the synchronicity of material and geomet­ric properties [8]. Shells: Material and Immaterial The first 
major scientific breakthrough in control of the acoustic environment was Wallace Sabine s 1895 formulation 
of a mathematical model of reverberation time in relation to spatial volume and surface absorption [9]. 
For the first time, by linking formal, material and spatial variables to perception, the shape of the 
soundsphere could be opened to instrumental design. Design of spaces for acoustic performance became 
a science, but a maddening one: it soon became clear that a solution that works well for one listening 
need might not work for another. The shell hard, heavy, and inflexible offered control but also became 
a limit (Figure 1, left). Variable acoustic engineering developed highly sophisticated and often cumbersome 
mechanical and hydraulic systems for adjusting the parameters of concert halls, most notably in experimen­tal 
facilities such as IRCAM in Paris, SARC in Belfast, or EMPAC in Troy, New York (Figure 1, center). Less 
flexible (and less costly) versions, offering a smaller range of variability but with more ease of operation, 
appeared in concert halls, especially those designed for contemporary music. Hung ceilings could be lowered 
or raised, wall panels rotated to absorptive or reflective surfaces, spaces expanded or contracted with 
the use of temporary enclosures. Outside the concert hall, the modern world became one of unprecedented 
noise and brute suppression, aided by the ubiquitous acoustic ceiling tile [10]. As composer R. Murray 
Schafer put it, in a world in which the internal combustion engine provides the fundamental sound of 
contemporary civilization, the design of the soundscape turned from productive to reactive ideals [11]. 
As Le Corbusier no doubt understood, technological developments in the electroacoustic production of 
sound the invention of the multi-speaker array made possible the shaping of a soundsphere without the 
introduction of a hard shell. By varying placement of sound sources, by moving sounds from one source 
to another, by varying volume and, in more sophisticated examples, wave phase, the perceived acoustics 
of a space could be rendered independent of physical form. The development of hard acoustic shells was 
accompanied by a contrary movement in which the acoustic envelope was dematerialized. This precisely 
paralleled the general fascination with the dematerialization of the building envelope in avant-garde 
architectural discourse in the 1960s and 70s. The clear physical presence of audio equipment in Banham 
and Dallegret s architecturally reductive Environment Bubble is telling (although the likely unpleasant 
acoustic conditions inside the bubble have not been considered). Sound artists as divergent in their 
practices as LaMonte Young, Janet Cardiff, George Bures Miller (Figure 1, right), and Bernhard Leitner 
are all engaged in the production of these immaterial shells and spheres. So is anyone who has ever worn 
a pair of headphones while walking down a noisy street, creating a personal, mobile soundsphere, immaterial, 
invisible, and transient. Resonant Chamber Resonant Chamber is an exploration of the acoustic project 
through computational and prototype-based design research (Figure 2). The work emerges from an interest 
in the acoustic, spatial, and social possibilities of the acoustic shell as neither material-but-static 
nor flexible- but-immaterial; a soundsphere that is able to adjust its spatial, material, and electroacoustic 
properties in response to changing sonic conditions, to dynamically alter the sound of a performance 
space during performance, or to become itself an instrument inviting new forms of performance and play. 
Utilizing contemporary technologies for computational design, acoustic performance, material testing, 
digital fabrication, ubiquitous sensing, and real-time micro-actuation, we explore development of a system 
that might be robust enough, flexible enough, and adaptive enough to move out of the concert hall and 
make everyday spaces acoustically tunable to changing activities or needs. Through the use of interactive 
technologies, this flexible prosthetic shell could afford an almost seamless and perhaps even unconscious 
connection between listener and soundsphere, operating as a second-order cybernetic system. Dynamic Surface 
Geometries The first constructed prototype of Resonant Chamber is designed as an installation of a thick 
kinetic surface, transformable through the geometric properties of rigid origami. Rigid origami was explored 
as a flexible geometric system, as it makes it possible to achieve predictable spatial configurations 
through its surface properties of developability (folded from a single sheet), flat-foldability (ability 
to fold into a flat shape), and degrees of freedom (DOF) [12]. The origami-based geometry allows both 
for gross deformation of the surface to dynamically alter the aural volume s overall spatial form, as 
well as localized manipulation to vary the ratios of exposed surfaces with variable material (and therefore 
acoustic) properties and linkages. Previous work by the authors in responsive envelopes has explored 
cable-strut tensegrity weaves as a lightweight, distributed structural framework that would be able to 
support kinetic deformation [13]. Rigid origami offers different advantages: as a result of the interconnected 
reactions between interior vertices and crease lines, which determine the DOF of the surface, physical 
actuation in one location has calculable effects on adjacent elements, thus reducing the number of points 
of actuation required to induce overall formal adjustments. The property of flat-foldability optimizes 
angles around a central vertex to allow the surface to tuck, enabling compact deployable structures within 
a limited space. Rhinoceros 4.0 software, and Grasshopper and Kangaroo plug-ins, were used to script 
and accurately simulate the relationship among geometries and gravitational and applied forces. This 
computational software will also allow us to develop different folding patterns that can be customized 
to suit a variety of spaces, potential aural volumes, and uses. The Resonant Chamber prototype uses a 
tessellated pattern first developed by Ron Resch [14], which deploys two sizes of triangular cells (Figure 
3). This specific cell geometry, prototyped in bamboo plywood, was chosen as it proved to be most acoustically 
sensitive in a series of comparative tests evaluating performance of formal and material configurations, 
as well as integration with electroacoustics (Figure 4). Performative Material Systems Flat-foldability 
relies on the fundamental physical property of optimum zero thickness, as is the case with paper origami; 
to shape acoustic performance, however, materials with multiple thicknesses, three-dimensional profiles, 
and specific properties are necessary. Three parallel streams of development were necessary for this 
translation into a performative surface. First, joint details were developed that would allow for the 
flat-folding of thick surfaces [15]. This included material prototyping with laminated membrane hinge 
assemblies and development of panel profiles for folding. Second, three primary types of panel composites 
were developed to absorb, reflect, or elecroacoustically generate sound (Figure 5). Third, suspension 
and actuation technologies were prototyped that would allow the surface to be physically deployed within 
a space, and for its facets to move, either in response to sensor inputs or in pre-programmed modes (Figure 
6). The reflective, absorptive, and sound-generating panel types that comprise the material characteristics 
of the system were developed in collaboration with consultants at ARUP Acoustics. Digital acoustic simulations 
and physical panel prototype testing were undertaken to determine optimal geometry and material characteristics 
relative to acoustic performance when combined with the proposed geometric configurations and electroacoustic 
technology (Figure 7). The sound-generating panels have Distributed Mode Loudspeaker (DML) exciters embedded 
within their composition, effectively turning these panels into speakers. Although the integration of 
DMLs into a multichannel system has been realized successfully in the past [16], their integration into 
a kinetic surface has not been widely explored and opens up an array of possible applications. On one 
hand, the DMLs provide an augmented level of reverberation control and directional sound reinforcement, 
which can now be actively manipulated for greater acoustic control. On the other hand, they comprise 
an entirely different interactive interface from the spatial-material control approach of the physical 
system, opening up a variety of possibilities for interactive sound installations, immersive live performance 
spaces, or acoustically enhanced learning facilities. Resonant Chamber thus has the possibility to become 
a hybrid architecturally scaled instrument, a dynamic aural environment that not only facilitates performance, 
but also might perform itself. Variable Actuation and Response A series of linear actuators mechanize 
the folding motion of the Resonant Chamber surface, locally varying material exposure for optimum acoustical 
tuning (Figure 8). A track system of stepper motors provides gross-motor positioning of the system within 
the space. Currently, Arduino micro-controllers are used to manipulate localized folding movements. Commands 
tied to the digital surface model communicate data via the Firefly software plug-in to calculate and 
coordinate desired movements. For the next prototype, we are collaborating with Jerome Lynch at the University 
of Michigan to incorporate into the assembly his Narada® system for wireless sensing, actuation, and 
on-board data processing. The synchronized actuation systems will allow geometric optimization for early 
acoustic energy and alter surface material exposure for late acoustic energy. Early acoustic energy controls 
the acoustics occurring shortly after the direct sound at both a listener and performer location by adjusting 
the height, location, and curvature of the prototype. Late acoustic energy controls diffusion and reverberation 
by adjusting the absorption material exposure, size, and location of the prototype. Though there are 
precedents for control of late room response through the use of systems to manipulate height or orientation 
of a ceiling reflector [17], the use of a kinetic system to control wavefront curvature, level and time 
of arrival of early reflections constitutes a new advance in acoustic research. In order to explore sensing 
and response, the installation space will be equipped with frequency, volume, and acoustic pressure sensors, 
which will process audio input in order to trigger physical and/or electroacoustic responses. Devices 
such as the Kinect sensor will locate the presence of people within the space and trigger transformations 
of the Resonant Chamber surface relative to location, number, and activity of occupants. Interaction 
modes will vary from tuning acoustics for specific performances to pattern languages that develop machine 
learning and cognitive responses relative to both actions and sounds of occupants. Projection Resonant 
Chamber is currently in its second phase of research and prototyping, which will allow for refinement 
of material and technological components and performance, as well as for testing relative to human interaction 
and feedback. We will also be refining sensing and control regimes with regard to how the system might 
be deployed in a variety of spaces and uses prioritizing, for example, particular aural qualities to 
enhance various configurations of live musical performance, blending aural and occupancy feedback to 
reconfigure the relationships between audience and performer, or developing individual need-based recognition 
systems that could dynamically recalibrate learning environments relative to inhabitant s aural ability 
 and assessing real-world manufacturing and installation issues. Resonant Chamber, in its aspirations 
to combine kinetic spatial reconfigurability, multiple surface material properties, electroacoustics, 
and interactivity, thereby produces a system of incredible complexity, both functionally and operationally. 
This is both its attractiveness and its limit. As an engineering problem to be solved, the adaptive system 
of such complexity is inherently difficult to predict and control, and its many moving parts are prone 
to failure and mechanical difficulties. However, the work makes a case for the territory within which 
the architectural project of the soundsphere may be located in our contemporary context as a hybrid 
investigation of material, electronic, and human-interactive environments. Acknowledgements Project Team: 
Geoffrey Thün, Kathy Velikov, Lisa Sauvé, Wes McGee, Mary O Malley, Colin Ripley, Adam Smith, Katie Wirtz, 
David Lieberman, Ian Ting, Lief Millar, Dr. Jerome Lynch, Devki Desai, Mike Kane. Acoustic Consulting 
Engineers: ARUP Acoustics - Raj Patel, Terence Caulkins, Dave Rife. Funding: University of Michigan Taubman 
College Research Through Making Grant, OVPR Small Projects Grant, and Center for Wireless Integrated 
MicroSystems; SSHRC Research Creation Grant. References 1. M. McLuhan, Inside the Five Sense Sensorium, 
The Canadian Architect Vol. 6, No. 6, 50 (1961). 2. M. Treib, Space Calculated in Seconds: The Philips 
Pavilion, Le Corbusier, Edgard Varèse (Princeton: Princeton University Press, 1996). 3. H. Bagenal, Influence 
of Buildings on Musical Tone, Music &#38; Letters Vol. 8, No. 4, 439 441 (October 1927). 4. H. Morgan, 
ed., Vitruvius: The Ten Books on Architecture (New York: Dover Publications, 1960). 5. Bagenal, 442 443. 
6. H. Bagenal, Bach s Music and Church Acoustics, Music &#38; Letters Vol. 11, No. 2, 146 155 (April 
1930). 7. F.A. Yates, Theatre of the World (Chicago: University of Chicago Press, 1969). 8. M. Crunelle, 
Is There an Acoustical Tradition in Western Architecture? First International Conference On Acoustic 
Ecology (1993), www.wseas.us/e-library/conferences/skiathos2001/papers/102.pdf (accessed March 10, 2012). 
9. E. Thompson, The Soundscape of Modernity: Architectural Acoustics and the Culture of Listening in 
America, 1900 1933 (Cambridge: MIT Press, 2002). 10. Thompson, Ibid. 11. R.M. Schafer, The Tuning of 
the World (New York: A. A. Knopf, 1977). 12. K. Velikov, et al., Toward Responsive Atmospheres: Prototype 
Exploration Through Material and Computational Systems, Integration through Computation: Proceedings 
of the 31st Annual Conference of the Association for Computer Aided Design in Architecture (ACADIA) 2011, 
326 333 (2011). 13. J. O Rourke, How to Fold It: The Mathematics of Linkages, Origami and Polyhedra (Cambridge: 
Cambridge University Press, 2011). 14. R. Resch, The Topological Design of Structural and Architectural 
Systems, AFIPS Conference Proceedings Vol. 42, National Computer Conference (1973). 15. T. Tachi, Rigid-Foldable 
Thick Origami, Proceedings of 5OSME, Singapore (2010). 16. E. Corteel et al., Objective and Subjective 
Comparison of Electrodynamic and MAP Loudspeakers for Wave Field Synthesis, AES 30th International Conference 
(2007). 17. V.M.A. Peutz, The Variable Acoustics of the Espace de Projection of IRCAM, Proceedings of 
the 59th AES Convention (1978). Geoffrey Thün Educator and designer University of Michigan Art and Architecture 
2000 Bonisteel Blvd Ann Arbor, MI 48109 USA gthun@umich.edu Kathy Velikov Educator and architect University 
of Michigan Art and Architecture 2000 Bonisteel Blvd Ann Arbor, MI 48109 USA kvelikov@umich.edu Colin 
Ripley Educator and architect Ryerson University ARC 200L 350 Victoria St. Toronto, ON M5B 2K3 Canada 
cripley@ryerson.ca Lisa Sauvé Research associate and designer 305 W. Liberty St. Ann Arbor, MI 48103 
USA lisa@rvtr.com Wes McGee Educator and designer University of Michigan Art and Architecture 2000 Bonisteel 
Blvd Ann Arbor, MI 48109 USA wesmcgee@umich.edu  Figure 1. (l-r) Solid shells: Danish Radio Concert 
House Auditorium, Copenhagen, 2009, Ateliers Jean Nouvel; manipulable shells: Danish Radio Concert House 
Recording Studio, 2009, Ateliers Jean Nouvel; immaterial shells: 40 Part Motet, Venice, 2010, Janet Cardiff. 
All photos by the authors.  &#38;#169; 2012 Geoffrey Thün, Kathy Velikov, Colin Ripley, Lisa Sauvé, 
Wes McGee | Leonardo, Vol. 45, No. 4, pp. 348 357, 2012 348  Soundspheres: Resonant Chamber | Thün 
et al. 349  Figure 2. Resonant Chamber prototype: (left) Surface detail. &#38;#169; RVTR. (right) Prototype 
installation of three operational acoustic clouds. &#38;#169; Peter Smith Photography. Photo by Peter 
Smith.  Thün et al. | Soundspheres: Resonant Chamber 350  Figure 3. Rigid origami geometry and flat 
folding logic drawing. &#38;#169; 2012 RVTR.  Soundspheres: Resonant Chamber | Thün et al. 351  Figure 
4. (above) Acoustic sensitivity comparison of panel shapes for identical DML exciter and amplification 
settings (chosen is the dashed line: 18" triangle); (below) Acoustic sound pressure analysis and acoustic 
reflections of surface configurations. &#38;#169; 2012 RVTR.  Thün et al. | Soundspheres: Resonant Chamber 
 352  Figure 5. Composite panel assembly and materials. &#38;#169; 2012 RVTR.  Soundspheres: Resonant 
Chamber | Thün et al. 353  Figure 6. (above) Variable surface configuration through folding properties; 
(below left) circuit diagram and wiring network; (below right) wiring of prototype surface with actuators 
from above, and folded surface from below. &#38;#169; 2012 RVTR. Thün et al. | Soundspheres: Resonant 
Chamber  Figure 7. Physical sensitivity comparison and testing of DML exciter types with panel (chosen 
is the dashed line: MAG-063). &#38;#169; 2012 RVTR. Soundspheres: Resonant Chamber | Thün et al.  Figure 
8. Resonant Chamber: ray-tracing of acoustic reflections due to variable spatial configurations delivered 
through gross displacement. &#38;#169; 2012 RVTR. Thün et al. | Soundspheres: Resonant Chamber Soundspheres: 
Resonant Chamber | Thün et al.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2012</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>2341937</article_id>
		<sort_key>60</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>08-05-2012</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Within an ocean of light]]></title>
		<subtitle><![CDATA[creating volumetric lightscapes]]></subtitle>
		<page_from>358</page_from>
		<page_to>365</page_to>
		<doi_number>10.1145/2341931.2341937</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=2341937</url>
		<abstract>
			<par><![CDATA[<p>This paper documents explorations into an alternative platform for immersive and affective expression within spatial mixed reality installation experiences. It discusses and analyzes experiments that use an advanced LED cube to create immersive, interactive installations and environments where visitors and visuals share a common physical space. As a visual medium, the LED cube has very specific properties and affordances, and optimizing the potential for such systems to create meaningful experiences presents many interlinked challenges. Two artworks exploring these possibilities are discussed. Both have been exhibited internationally in a variety of settings. Together with this paper, the works shed some light on the design considerations and experiential possibilities afforded by LED cubes and arrays. They also suggest that LED grids have potential as an emerging medium for immersive volumetric visualizations that occupy physical space.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P3734351</person_id>
				<author_profile_id><![CDATA[81100148835]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Anthony]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rowe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Centre for Design Research, Institute of Design, Oslo School of Architecture and Design (AHO), Oslo, Norway]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[anthony.rowe@aho.no; ant@squidsoup.org]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. L&#252;tgens, "Twentieth-Century Light and Space Art," <i>Olafur Eliasson: Your Lighthouse: Works with Light 1991--2004</i> (Ostfildern: Hatje Cantz, 2004).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[N. De Oliveira et al., <i>Installation Art</i> (London: Tames and Hudson, 1994) 14.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Morris, "Notes on Sculpture," <i>Artforum</i> (February and October 1966), reprinted in G. Battcock, ed., <i>Minimal Art: A Critical Anthology</i> (New York: E. P. Dutton, 1968) 222--235.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Butterfield, <i>The Art of Light and Space</i> (New York: Abbeville, 1993) 8.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[P. Milgram &amp; F. Kishino, "A Taxonomy of Mixed Reality Visual Displays," <i>IEICE Transactions on Information Systems</i>, Vol. E77-D, No. 12 (1994).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[C. Paul, <i>Digital Art</i> (London: Tames and Hudson, 2003) 71--72.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1518920</ref_obj_id>
				<ref_obj_pid>1518701</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Snibbe &amp; H. Raffle, "Social Immersive Media: Pursuing Best Practices for Multi-user Interactive Camera/Projector Exhibits," <i>Proceedings of ACM CHI 2009 Conference on Human Factors in Computing Systems</i> (Boston: ACM, 2009) 1447--1456.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Lavin, <i>Kissing Architecture</i> (Princeton: Princeton University Press, 2011).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1979097</ref_obj_id>
				<ref_obj_pid>1978942</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[For example, see P. Dalsgaard &amp; K. Halskov, "3D Projection on Physical Objects: Design Insights from Five Real Life Cases," <i>Proceedings of ACM CHI 2011 Conference on Human Factors in Computing Systems</i> (New York: ACM, 2011) 1041--1050.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Squidsoup, www.squidsoup.org/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[C. Frayling et al., <i>Practice-based Doctorates in the Creative and Performing Arts and Design</i> (Lichfield, UK: UK Council for Graduate Education, 1997).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[B. Sevaldson, "Discussions &amp; Movements in Design Research: A Systems Approach to Practice Research in Design," <i>FORMakademisk</i> Vol. 3, No. 1, 8--35 (2010).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1805898</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[C. Salter, <i>Entangled: Technology and the Transformation of Performance</i> (Cambridge: MIT Press, 2010) xxxiii.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[A. Rowe &amp; A. Morrison, "Dynamic Visualisation in Tree Physical Dimensions," <i>Digital Arts and Culture</i> (2009).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[S. Schubiger-Banz &amp; M. Eberle, "The NOVA Display System," <i>Transdisciplinary Digital Art: Sound, Vision and the New Screen</i> (Berlin: Springer, 2008) 476--487.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[T. Cuevas, H. Obrist, &amp; P. Santoscoy, <i>Jes&#250;&#250;s Rafael Soto: Visione in movimento</i> (Milan: Silvana Editoriale, 2007).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>168657</ref_obj_id>
				<ref_obj_pid>168642</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[S. Feiner, et al., "Windows on the World: 2D Windows for 3D Augmented Reality," <i>UIST '93 Proceedings of the 6th Annual ACM Symposium on User Interface Software and Technology</i> (New York: ACM, 1993).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Squidsoup, <i>Surface</i>, www.squidsoup.org/surface/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[E. T. Hall, <i>The Hidden Dimension</i> (Garden City, New York: Doubleday, 1966).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2092123</ref_obj_id>
				<ref_obj_pid>2092088</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[C. Randall &amp; A. Rowe, "Come Closer: Encouraging Collaborative Behaviour in a Multimedia Environment," Interactive Technology and Sociotechnical Systems; 12th International Conference, VSMM 2006, 281--289 (2006).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Squidsoup, <i>Scapes</i>, www.squidsoup.org/scapes/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Within an Ocean of Light: Creating Volumetric Lightscapes Anthony Rowe ABSTRACT This paper documents 
explorations into an alternative platform for immersive and affective expression within spatial mixed 
reality installation experiences. It discusses and analyzes experiments that use an advanced LED cube 
to create immersive, interactive installations and environments where visitors and visuals share a common 
physical space. As a visual medium, the LED cube has very specific properties and affordances, and optimizing 
the potential for such systems to create meaningful experiences presents many interlinked challenges. 
Two artworks exploring these possibilities are discussed. Both have been exhibited internationally in 
a variety of settings. Together with this paper, the works shed some light on the design considerations 
and experiential possibilities afforded by LED cubes and arrays. They also suggest that LED grids have 
potential as an emerging medium for immersive volumetric visualizations that occupy physical space. Introduction 
With Light-Space-Modulator (1922-30), László Moholy-Nagy is often cited as bringing together for the 
first time all the fundamental elements of twentieth-century art: [...] space and movement, perception, 
experimental machinery and viewer participation [1]. By the mid-1960s, the legacies of Futurism, Dada, 
Constructivism, the Bauhaus, and elements from other art movements had cross-fertilized to produce what 
would eventually become installation art [2]. Minimalism was altering the relationships among audience, 
work, and the space in which it is seen [3]. Simultaneously, James Turrell, Robert Irwin and other light 
and space artists were using the materiality of light, space, and time to create immersive phenomenological 
experiences, often with no physical component, or object, as central focus [4] a trend still developing 
today with artists such as Olafur Eliasson. This lack of physicality has clear resonances with the digital 
paradigm, from the virtual art of the 80s and 90s to recent explorations of pervasive augmented reality 
and mixed reality [5] experiences. The relationship and interplay between the digital and the physical, 
the tangible and the intangible, has been of fundamental interest to digital art, particularly the area 
of digital or mixed reality installation art [6]. Though explored in numerous ways, installation techniques 
using light and space are even now predominantly screen-, or projector-, based. Such works are well documented, 
and their relationships to the spaces, people and architectures in which they exist have been analyzed 
from various perspectives, from the social [7] to the perceptual, spatial, and architectural [8]. Numerous 
media artists have also explored the use of large-scale dynamic architectural lighting, appropriating 
technologies and techniques from concert stage lighting, signage, and architec­tural media façades to 
produce architectural-scale experiences. This focus on controlling light as it relates to physical structures 
and within real space has also tantalized with the possibility of creating visual impressions that are 
three-dimensional and dynamic, that occupy physical space, and that can be seen from any angle yet are 
also highly ephemeral and retain the abstract phenomenological approach of light and space art experiences. 
Various forms of holography and stereoscopy attempt to fulfil these requirements, but they do not occupy 
physical 3D space, and they have various constraints of their own. Another technique currently in vogue 
is projection mapping: the use of bespoke media projected onto physical objects and buildings with the 
aim of augmenting and altering perception of those objects and spaces [9]. Though still not occupying 
physical space, this approach is at least located clearly within physical space. An emerging alternative 
is to configure individually addressable LEDs (light emitting diodes) into three-dimensional arrays 
so-called LED cubes (Figure 1). Such systems have significant limitations as a visualization tool but 
they occupy physical space in a literal way, defining volumes of the same space that we inhabit. This 
paper aims to shed light on some of the design considerations and experiential possibilities afforded 
by such LED cubes or grids, as they offer increasing potential for visualization tech­niques that occupy 
three physical dimensions. It follows the development of two artworks by digital arts group Squidsoup 
[10], developed as part of a practice-led [11] research project explor­ing the possibilities afforded 
by this medium using a research-through-design methodology [12]. Both artworks were built on an advanced 
LED cube, Ocean of Light, explore ways in which such systems can be used to augment reality in new and 
interesting ways, and assist in the task of finally doing away with the tired dichotomies of digital 
versus analog, real versus virtual [13], while retaining the power and flexibility of the digital domain. 
LED Cubes To create the illusion of representation of form, advanced LED cubes or grids use the same 
technique as flat screens. They rely on the brain accepting that disparate points of light form a cohesive 
whole where visual representations can move from one point to the next, by careful control of the light 
emitting from each point [14]. The main design difference between screens and 3D grids is that when they 
are constituted in three dimensions, one needs to be able to see beyond each layer to the ones behind. 
This requires transparency, or gaps between the points of light to reduce occlusion. Little formal research 
has been done on the design and build of such systems beyond the technical [15], although prominent realized 
projects by architecture and design companies such as United Visual Artists (Volume, Constellation), 
Jason Bruges Studios (Pixel Cloud) and rAndom International (Swarm) show that practical examples exist, 
and that this approach is beginning to enter the public consciousness. However, most of the developments 
in these works have focused on the physical hardware and the aesthetics of the physical objects that 
constitute the grid of lights, rather than the content they display. An underlying premise of this paper 
is that such structures are effectively heralding a new medium with its own properties and affordances. 
This medium can be used in different ways, but of particular interest here is the creation of immersive 
environments, rather than representing objects seen from without. Ocean of Light In Ocean of Light, the 
three-dimensional grid of LEDs used to convey the experiences discussed below, Squidsoup seeks to create 
immersive visual experiences that become a part of the environ­ment. As most LED grids are designed and 
positioned to be seen as objects in their entirety, from a distance (and often from below), a re-thinking 
of the physical relationship between object, viewer, and space is required. This alternative approach 
requires viewers to be able to get very close to, even within, the LED space. The cube must therefore 
be proximal, accessible, and touchable. It is also desirable to maximize the distance between LEDs and 
to minimize each unit's size to be able to see through the LED space, to create space among the LED 
units, and to blur the boundaries of the cube, calling to mind the pénétrables works of Jesús Rafael 
Soto [16]. This approach to the design of the physical structure differs significantly from the norm, 
where lights are larger and more densely positioned (see, for example, the NOVA LED display by ETHZ, 
or the works mentioned above). Ocean of Light has 3,456 individually addressable points of light arranged 
in a 12 x 12 x 24 (high) grid. The lights are suspended from an aluminium rig in strings containing 24 
LED pairs, each light consisting of two naked tri-color LEDs emitting a tiny 1mm-diameter point of light 
(Figure 2) in opposing directions (so as to be visible from any angle). This setup suffers little from 
occlusion, but does have a particular visual aesthetic. Additionally, small points of light are less 
revealing of their physical location they do not perceptibly shrink with distance requiring viewers 
to move in order to receive clear depth cues. The wires connecting the strings are flexible, pliable 
but retaining bends, resulting in an irregular grid structure (Figure 3). The Moiré effects so prominent 
in regular grids (see for example Erwin Redl s work) thus become less dominant, giving the structure 
a more organic aesthetic. The distance between each string can be altered, from 10cm to 20cm. Vertical 
pitch is fixed at 10cm, meaning that at its largest the grid occupies a 2.4m cube. At this size, the 
space between each string (20cm) is large enough to stick an arm or a head inside, and the physical electronics 
occupy only a small percentage of the volume within the grid. Technical Setup By appropriating video 
wall technology and reconfiguring the standard 2D screen grid into a series of sheets placed behind each 
other, it was possible to develop a simple screen-based programming approach to producing volumetric 
visualizations by slicing up 3D shapes on screen, which are then reconstituted in the grid. Screen pixels 
are allocated to individual LEDs within the grid, so a much more visual development process was possible, 
as designs can be developed to a large extent on a standard screen. This meant that early tests and experiments 
could be performed by visual designers as well as coders (see Figure 4). Dynamic experiments were also 
simplified using this approach, as changes and refinements can be seen on-screen without the constant 
need to be connected to the cube. This, combined with the low resolution of the content, meant that rapid 
prototyping was possible using any screen-based software. Processing and Adobe Flash both worked well 
and were used to develop content for the project. Experience and Perception The phenomenological effects 
of Ocean of Light were noticeably stronger when spread over a larger area the visualizations appeared 
more immersive and more powerful. At larger sizes, it becomes much more of an environment, i.e. occupying 
a significant volume, rather than an object, as represented by the smaller version. Interestingly, the 
distance between the strings (at least up to 20cm) does not add perceptibly to our ability to connect 
adjacent points of light. The overall visual experience is definitely still one of a volume rather than 
a series of columns of light, a volume where digital entities within have scale, position, and presence 
within our physical world. Also, as an environment situated within our world, it does not involve any 
kind of locative disjunct, or window-into-another-world metaphors, that build perceptual boundaries between 
the perceiver and the perceived [17]. Finally, its abstract visual qualities have many advantages, among 
which are a clear distance from any attempts at mimicking reality, an ability to captivate and dominate 
physical space through its luminous qualities, and the need to be relatively unspecific and open to interpretation. 
Content and Designs Two contrasting artworks were developed for the Ocean of Light hardware. Both use 
forms derived in real time from a combination of generative and interactive stimuli but develop the potential 
of the medium in different ways, to create different visual and affective outcomes. Discussion of the 
works, entitled Surface and Scapes, follows. Surface Surface is a responsive virtual eco-system that 
occupies physical space [18]. It uses the hardware as a 3D canvas to visualize movement in physical space. 
The space is dominated by a surface the boundary between two fluid virtual materials. The materials 
are affected by sound in the real world, whereby nearby noises create waves that ripple across the surface. 
These fluids are, how­ever, unstable: the turbulence caused by physical sounds also triggers luminous 
blasts. Abstract autonomous agents, whose movements are inspired by dragonfly flight patterns, are aware 
of their surroundings as they navigate and negotiate the environment and the surface (Figure 5). They 
also make sounds that affect both physical and virtual spaces. Thus, physical and virtual worlds are 
intertwined and interconnected; changes in either space affect both. The paring down of the visuals to 
striking ultra-simple components (a fluid surface and one to four dragonfly agents) meant that despite 
the resolution issues, the piece was instantly recognizable as an eco-system with specific and clear 
components. This is a significant departure from much other volumetric work using 3D grids, where abstract 
patterns, color cycling, and moving planes are the norm. Surface was first exhibited at Kinetica Art 
Fair (London, 2010) in a small (4m x 3.6m) space with black walls and a single access point, leaving 
less than a 1m corridor for visitors. This, combined with high visitor numbers, meant that people were 
in very close proximity to the work. The effect was highly immersive and visceral, with people becoming 
mesmerized and disoriented by the work. The boundaries of personal space [19, 20] were challenged, creating 
a very intimate setting where visitors are almost forcibly inserted into the environment, triggering 
strong phenomeno­logical reactions to the conditions. Subsequent exhibitions at the Ars Electronica festival 
and museum (September to December 2010, Linz, Austria) had a different ambience. The work was set in 
a much larger and calmer space, allowing visitors to experience the work in a manner more under their 
control. The experience (judging from responses) was not as viscerally powerful, but it had a contemplative 
edge that was still able to draw people in for extended viewing periods. Scapes, or Paysages de Lumière 
Scapes conjures into being three-dimensional cities, landscapes and abstract architectures purely from 
sound, software and light. Chimaera-like visions of ephemeral spaces are created and destroyed in real 
time. They occupy physical space, but only fleetingly. They leave nothing behind when they, and the sounds 
that spawned them, vanish. [21] Scapes was the result of a tripartite co-design ecology combining music, 
programming, and light. Sound design, dynamic movement patterns, and vectors derived from tuned Fast 
Fourier Transforms (FFTs) were the materials used to create parametric volumetric forms that could be 
manipulated and visualized in real time. An iterative design process evolved where the final aesthetic 
results were achieved through designing and altering the relationships between these materials. The system 
is completed by a feedback loop that uses a microphone to take ambient sound from within the gallery 
space (including the sound composition that forms the basis of the work) back into the same designed 
set of software filters, thus affecting the visual forms once again. The resulting system can therefore 
be intercepted, corrupted, and significantly altered in real time by visitors making their own sounds 
to interfere with the original audiovisual designs. This process was performed on numerous initial sketches, 
each starting from a visual, coding, and/or musical idea. The sketches were whittled down to a suite 
of five scapes paysages de lumière (Figure 6). The name derives from the notion running through all 
five pieces of creating representations of vistas or landscapes. The landscapes represented a waterfall 
suspended in time, an abstracted cityscape with skyscrapers and a bustling ground level, the slow inexorable 
power of an ocean wave, passing scenery watched through a car windscreen in the rain, and the moon under 
duress. Scapes was first shown at Tenderpixel, a small and intimate art gallery in Central London, and 
subsequently in a large black box at Scopitone, an experimental music and art festival in Nantes, France. 
Reflections on Exhibition Space and Physical Considerations In a perfect world, Scapes s would be invisible 
and the lights everywhere. We used various methods to enhance the illusion of volumetric form and reduce 
the visibility of the technology (strings, LEDs, support structures). Of particular note was the use 
of fabric as a semi-transparent veil in Scapes. Taut Lycra has curious optical properties, blurring what 
is behind the veil, and also obscuring whatever comes through the material at an angle. The result has 
a chimeric quality, reminiscent of the illusion of a dream, or a memory of what once was. Blurred points 
of light forming defined 3D shapes are clearly visible, but all else (electronic and other paraphernalia) 
recedes to near-invisibility. These aesthetic properties were clearly appropriate for Scapes. However, 
the use of a fabric veil, in effect a boundary, calls into question the conceit of moving away from screen-based 
techniques and also counters the aim of blurring the borders between accessible space and the grid of 
LEDs. The Lycra forms a screen a 2D surface that (it can be argued) makes whatever is beyond it a flat 
visualization, and beyond reach. This takes the project a step back from physicality, and produces another 
boundary between the virtual world of Scapes and the physical world in which it exists. But at an experiential 
level, the piece seems surprisingly more convincing as a result of the veil, the visual ambiguity proving 
at least as attractive as the screen is distancing. Both pieces were shown in various spaces and situations. 
The size of the exhibition space has a strong effect on immer­sion; smaller spaces that coerce participants 
into being nearer the work than they would otherwise choose to be create a significantly more powerful 
experience. This feeling is reinforced by the use of dark walls, as they are less visible and so do not 
distract from the work. In a small, dark space, the work has an affective quality, appealing directly 
to multiple senses through, for example, light and electrostatic radiation that can be sensed on the 
skin. Additionally, a feeling of sensory overload is more likely, as the visuals cover the viewer s complete 
visual field. Larger exhibition spaces allow for a distance that, by enabling a clearer impression of 
the work as a whole, also creates an intellectual barrier to visceral immersion. One of the stated aims 
of the Ocean of Light project was to move away from the grid presenting the appearance of an object and 
toward integrating the grid with the local environment. When placed in a small room, the grid cannot 
be seen as an object; it appears to occupy all available space, confined only by the room it is in. However, 
the use of larger spaces, and also the Lycra diffusing barrier used in Scapes, creates other impressions. 
The abstraction gained from the veil and the ability to get very different impressions from viewing the 
work from different distances fundamentally alter the overall experience. Conclusions The two contrasting 
pieces described here were designed in part to evaluate the effectiveness of an advanced LED cube as 
a platform for creating a range of visual impressions, from the visceral, entangled immersion of Surface 
to the tranquil, beguiling, enfolding qualities of Scapes. These examples suggest that this emerging 
medium can be effective at creating experiences that immerse participants and give the impression of 
presence in three-dimensional physical space. They also have a clear ability to bring virtual worlds 
into the physical in new and different ways. The visual effect of these pieces is fairly abstract (due 
in part to the constraints of low resolution) but definitely three dimensional, and it clearly illustrates 
movement, form, and presence. Resolution is partly a size issue; future work with larger grid environments 
that are more easily penetrable will increase this effect and, it is anticipated, also heighten immersive 
potential. Finally, it is also clear that the design of the space in which the experience is to occur 
is crucial. The particular attributes of the space its size relative to the LED grid, the available 
space between participant and grid, wall color, and so on all have a fundamental effect on the balance 
of prominence between virtual and real components of such mixed-reality experiences. These factors must 
be taken into consideration when designing such projects, as the balance between real and virtual defines 
the overall user experience. Acknowledgements Thanks to my comrades at Squidsoup (Gareth Bushell, Chris 
Bennewith and Liam Birtles); Ollie Bown (sound design, Surface) and Alexander Rishaug (sound design, 
Scapes); and to Andrew Morrison and colleagues at the Centre for Design Research, Institute for Design, 
Oslo School of Architecture and Design for support and guidance. Research supported by Oslo School of 
Architecture and Design (Norway) and Technology Strategy Board (UK). References 1. A. Lütgens, Twentieth-Century 
Light and Space Art, Olafur Eliasson: Your Lighthouse: Works with Light 1991 2004 (Ostfildern: Hatje 
Cantz, 2004). 2. N. De Oliveira et al., Installation Art (London: Thames and Hudson, 1994) 14. 3. R. 
Morris, Notes on Sculpture, Artforum (February and October 1966), reprinted in G. Battcock, ed., Minimal 
Art: A Critical Anthology (New York: E.P. Dutton, 1968) 222 235. 4. J. Butterfield, The Art of Light 
and Space (New York: Abbeville, 1993) 8. 5. P. Milgram &#38; F. Kishino, A Taxonomy of Mixed Reality 
Visual Displays, IEICE Transactions on Information Systems, Vol. E77-D, No. 12 (1994). 6. C. Paul, Digital 
Art (London: Thames and Hudson, 2003) 71 72. 7. S. Snibbe &#38; H. Raffle, Social Immersive Media: Pursuing 
Best Practices for Multi-user Interactive Camera/Projector Exhibits, Proceedings of ACM CHI 2009 Conference 
on Human Factors in Computing Systems (Boston: ACM, 2009) 1447 1456. 8. S. Lavin, Kissing Architecture 
(Princeton: Princeton University Press, 2011). 9. For example, see P. Dalsgaard &#38; K. Halskov, 3D 
Projection on Physical Objects: Design Insights from Five Real Life Cases, Proceedings of ACM CHI 2011 
Conference on Human Factors in Computing Systems (New York: ACM, 2011) 1041 1050. 10. Squidsoup, www.squidsoup.org/. 
11. C. Frayling et al., Practice-based Doctorates in the Creative and Performing Arts and Design (Lichfield, 
UK: UK Council for Graduate Education, 1997). 12. B. Sevaldson, Discussions &#38; Movements in Design 
Research: A Systems Approach to Practice Research in Design, FORMakademisk Vol. 3, No. 1, 8 35 (2010). 
13. C. Salter, Entangled: Technology and the Transformation of Performance (Cambridge: MIT Press, 2010) 
xxxiii. 14. A. Rowe &#38; A. Morrison, Dynamic Visualisation in Three Physical Dimensions, Digital Arts 
and Culture (2009). 15. S. Schubiger-Banz &#38; M. Eberle, The NOVA Display System, Transdisciplinary 
Digital Art: Sound, Vision and the New Screen (Berlin: Springer, 2008) 476 487. 16. T. Cuevas, H. Obrist, 
&#38; P. Santoscoy, Jesús Rafael Soto: Visione in movimento (Milan: Silvana Editoriale, 2007). 17. S. 
Feiner, et al., Windows on the World: 2D Windows for 3D Augmented Reality, UIST 93 Proceedings of the 
6th Annual ACM Symposium on User Interface Software and Technology (New York: ACM, 1993). 18. Squidsoup, 
Surface, www.squidsoup.org/surface/. 19. E.T. Hall, The Hidden Dimension (Garden City, New York: Doubleday, 
1966). 20. C. Randall &#38; A. Rowe, Come Closer: Encouraging Collaborative Behaviour in a Multimedia 
Environment, Interactive Technology and Sociotechnical Systems; 12th International Conference, VSMM 2006, 
281 289 (2006). 21. Squidsoup, Scapes, www.squidsoup.org/scapes/. Anthony Rowe Artist, researcher, designer 
Centre for Design Research, Institute of Design Oslo School of Architecture and Design (AHO) PO Box 6768 
St. Olavs Plass, 0130 Oslo Norway anthony.rowe@aho.no ant@squidsoup.org &#38;#169; 2012 Anthony Rowe 
| Leonardo, Vol. 45, No. 4, pp. 358 365, 2012  Figure 1. Ocean of Light, an advanced LED cube. Electronics, 
2.5m x 2.5m x 2.5m, 2010. &#38;#169; 2011 Squidsoup. Within an Ocean of Light: Creating Volumetric Lightscapes 
| Rowe  Figure 2. Detail from Ocean of Light: a suspended LED pair front and back, and an LED string. 
&#38;#169; 2010 Squidsoup. Rowe | Within an Ocean of Light: Creating Volumetric Lightscapes  Figure 
3. The irregular features of Ocean of Light. &#38;#169; 2010 Squidsoup. Within an Ocean of Light: Creating 
Volumetric Lightscapes | Rowe  Figure 4. Five examples of volumetric visualizations broken down to a 
series of 12 vertical planes, which are then physically placed behind each other. &#38;#169; 2010 Squidsoup. 
 Rowe | Within an Ocean of Light: Creating Volumetric Lightscapes 362  Figure 5. Surface (at Ars Electronica 
Festival, September 2010), showing a dynamic surface and two autonomous agents. &#38;#169; 2010 Squidsoup. 
 Within an Ocean of Light: Creating Volumetric Lightscapes | Rowe 363  Figure 6. Scapes example paysages 
de lumière (at Tenderpixel, London, 2011). &#38;#169; 2011 Squidsoup.  Rowe | Within an Ocean of Light: 
Creating Volumetric Lightscapes 364  Within an Ocean of Light: Creating Volumetric Lightscapes | Rowe 
 365  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2012</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
	<section>
		<section_id>2341938</section_id>
		<sort_key>70</sort_key>
		<section_seq_no>2</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[In search of the miraculous]]></section_title>
		<section_page_from>366</section_page_from>
	<article_rec>
		<article_id>2341939</article_id>
		<sort_key>80</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>08-05-2012</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Kapit&#228;n Biopunk]]></title>
		<subtitle><![CDATA[fermentation madness]]></subtitle>
		<page_from>370</page_from>
		<page_to>371</page_to>
		<doi_number>10.1145/2341931.2341939</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=2341939</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P3734352</person_id>
				<author_profile_id><![CDATA[81504682507]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Julian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Abraham]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[melt.togar@gmail.com]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Julian Abraham Independent artist melt.togar@gmail.com  Kapitän Biopunk: Fermentation Madness. &#38;#169; 
2012 Julian Abraham. Photo &#38;#169; 2012 Selina Anna Shah. &#38;#169; 2012 Julian Abraham | Leonardo, 
Vol. 45, No. 4, pp. 370 371, 2012 Kapitän Biopunk : Fermentation Madness | Julian Abraham Julian Abraham 
Kapitän Biopunk: Fermentation Madness Kapitän Biopunk: Fermentation Madness is an artistic research project 
manifested via a series of workshops and an acoustic and performative installation. The artist developed 
the project in response to the high number of poisonings and deaths of alcohol consumers after an increased 
excise tax was placed on alcoholic products in Indonesia. The project, using do-it-yourself and open-source 
technologies, strives to educate individuals on fermentation processes to produce safe and affordable 
alcoholic products, and a means to democratize the laboratory and liberate knowledge for a wider society. 
In the installation, fermenting tanks filled with exotic fruit juice and yeast cultures are mediated 
with audio microphones. The audio draws attention to the fermentation process, permitting the audience 
to listen to the sound of fermentation, as yeast transforms sugar into ethanol and CO2. The sounds generated 
change in relation to various factors: temperature, sugar level, types of fruit, quantity of yeast, light 
intensity, and container volume. Julian Abraham is a media artist, musician, programmer, amateur scientist, 
and social researcher. Words like manipulating, decomposing, degenerating, and dematerializing are often 
used to describe his work. Connecting one thing to another, expressed in complex algorithms, helped him 
understand how art, the environment, science, and technology relate to one another providing new tools 
to educate and engage both himself and society into a wiser, richer, and more independent existence in 
a world of creation and annihilation. From 2006 until 2011, Abraham dedicated his life to The House of 
Natural Fiber, a media artist collective based in Yogyakarta, Indonesia. He has produced and organized 
numerous festivals, workshops, exhibitions, performances, and concerts.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2012</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>2341940</article_id>
		<sort_key>90</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>08-05-2012</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Snail trail]]></title>
		<page_from>372</page_from>
		<page_to>373</page_to>
		<doi_number>10.1145/2341931.2341940</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=2341940</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P3734353</person_id>
				<author_profile_id><![CDATA[81504688724]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Philipp]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Artus]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Kunsthochschule f&#252;r Medien K&#246;ln]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[post@philippartus.com]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Philipp Artus snail trail Philipp Artus snail trail is a 360-degree laser animation loop projected onto 
a column. The two-minute anima­tion relates the story of a snail which, in response to its environment, 
keeps evolving new means of locomotion, ultimately inventing the wheel and eventually devolving back 
to its original form. The projection surface is made from a phosphorescent material creating an afterglow 
that slowly fades out. As a result of the phosphorescent trails, viewers can simultaneously see what 
happens, what has happened, and what will happen. This reflection on time is elaborated further through 
the endlessly cycling structure of the work as well as through the recurring pulse of sound and light, 
which refers to periodic natural phenomena like the tides or the seasons. The concept for the animation 
stems from Artus reflections on the processes of exponential evolutionary acceleration in different periodic 
ages, Darwin s theory of evolution, and the manner in which environment influences our own communication 
and behavior. snail trail is accompanied with music by Madalena Graça. Philipp Artus experimental animations 
and site-specific installations explore the manifestations of life through movement, sound, and imagery. 
He composes audio/ visual experiences that unite playful elements with minimalist structures, timeless 
themes with contemporary observations, turbulent acceleration with contemplative silence. Philipp Artus 
was born in Bremen, Germany and began studying art at the École des Beaux Arts in Nantes (France). He 
continued his autodidactic studies of animation and music theory in Portugal and is currently finishing 
his graduation project at the Kunsthochschule für Medien Köln (Germany). Artus work has been shown in 
various museums, festivals, and galleries around the world, including the Museum of Contemporary Art 
Kanazawa (Japan), the European Media Art Festival (Germany), Athens Video Art Festival (Greece), Videoformes 
(France), LUMINALE (Germany), and the DOTMOV Festival (Japan). Philipp Artus Kunsthochschule für Medien 
Köln post@philippartus.com www.philippartus.com   snail trail. &#38;#169; 2011 Philipp Artus. &#38;#169; 
2012 Philipp Artus | Leonardo, Vol. 45, No. 4, pp. 372 373, 2012  snail trail. &#38;#169; 2011 Philipp 
Artus.  snail trail. &#38;#169; 2011 Philipp Artus. snail trail | Philipp Artus  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2012</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>2341941</article_id>
		<sort_key>100</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>08-05-2012</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Saturation]]></title>
		<page_from>374</page_from>
		<page_to>375</page_to>
		<doi_number>10.1145/2341931.2341941</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=2341941</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P3734354</person_id>
				<author_profile_id><![CDATA[81504685056]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Barry]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University at Buffalo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[dan.djbarry@gmail.com]]></email_address>
			</au>
			<au>
				<person_id>P3734355</person_id>
				<author_profile_id><![CDATA[81504688614]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Adam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Laskowitz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University at Buffalo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[lasko25@gmail.com]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Daniel Barry and Adam Laskowitz Saturation Saturation is an installation that highlights the abundance 
of wireless signals occupying the electromagnetic spectrum. The work indexes the FM radio spectrum to 
reveal the density of the invisible communications infrastructure saturating the environment and our 
bodies. The work is installed in the form of an enormous chandelier; a set of open aluminum boxes housing 
FM radios are strung together and hung from the center of the ceiling. At rest, while concealed within 
their enclosures, the radio receivers output an ocean of static. Once exposed, the radios each connect 
to a different station, filling the space with a cacophony of noise. This process reveals a densely populated, 
dynamic array of electromagnetic fields that, while intangible, constantly permeate our bodies and environment. 
The aluminum enclosures act as Faraday Cages, preventing the radios from receiving a signal. Each enclosure 
s aggregation and directionality is determined through the installation s spatial orienta­tion to the 
source of the broadcast, disrupting the signal s reception, and creating a field of static noise. Because 
the body absorbs electromagnetic signals, the radios may connect to the signal when a human hand is within 
close proximity of the radio inside the enclosure. This engagement with the installation exposes a realization 
of the effects that bodies and wireless signals impose upon one another. While this experience remains 
confined to a single broadcast, the multitude of signals can be experienced through simultaneously releasing 
each of the radios with a single pulley actuation. This releases an eruption of sounds, which exposes 
the dense saturation of the environment and reveals the wonderment of experiencing the multiplicity of 
signal presence at any given moment. Daniel Barry is a member of the media . architecture . computing 
program at the University at Buffalo (USA). In 2009, he graduated from the University at Buffalo with 
a bachelor of science in architecture and continued at the University at Buffalo in the Department of 
Architecture and the Department of Media Study to pursue both a master of architecture and a master of 
fine arts. His research interests are focused on mobile computing technologies and how they negotiate 
social and spatial relationships. His work indexes mobile devices as prosthetic extensions of the body 
and their modification to extend our cognition of the complex invisible architectures of contemporary 
urban environments. His work has been internationally recognized through exhibitions and publications 
in France, Japan, and the United States. As the Fred Wallace Brunkow Fellow, he is the designer and editor 
of Intersight, the University at Buffalo School of Architecture and Planning s annual journal of student 
work. Adam Laskowitz is an artist, designer, and musician. He is currently a member of the media . architecture 
. computing program at the University at Buffalo (USA), pursuing a master of architecture and master 
of fine arts. He received a bachelor of science in architecture from the University at Buffalo in 2009. 
His current research focuses on the ways in which digital technologies can make mundane, everyday interactions 
with space surprising, entertaining, and exciting through a particular lens of sound production and consumption. 
His work deals with the interactions among people, places, and the objects that occupy space, focusing 
on the social and spatial implications of computing technologies. His work has been exhibited and published 
in Germany, France, Japan, and the United States. In the summer of 2012, he joined the Intel research 
labs in Portland, Oregon, where he is focusing on sensor networks and how complex datasets can be visualized 
for use by the public. Daniel Barry University at Buffalo dan.djbarry@gmail.com Adam Laskowitz Design 
5, University at Buffalo lasko25@gmail.com http://djbarrydesign.com http://adamlaskowitz.com  Saturation. 
&#38;#169; 2011 Adam Laskowitz and Daniel Barry. &#38;#169; 2012 Daniel Barry and Adam Laskowitz | Leonardo, 
Vol. 45, No. 4, pp. 374 375, 2012  Saturation. &#38;#169; 2011 Adam Laskowitz and Daniel Barry.  Saturation. 
&#38;#169; 2011 Adam Laskowitz and Daniel Barry. Saturation | Barry and Laskowitz  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2012</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>2341942</article_id>
		<sort_key>110</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>08-05-2012</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[90&#176; South]]></title>
		<page_from>376</page_from>
		<page_to>377</page_to>
		<doi_number>10.1145/2341931.2341942</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=2341942</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P3734356</person_id>
				<author_profile_id><![CDATA[81504688220]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alejandro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Borsani]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rensselaer Polytechnic Institute]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[alejandrobs@gmail.com]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Alejandro Borsani 90° South Alejandro Borsani s 90° South provides a contemplative point of view that 
allows the viewer to witness and be immersed in the constant evolution of a growing landscape. The work 
utilizes an irrigation system in conjunction with a highly absorbent material (sodium polyacrylate) to 
produce a slowly emerging landscape. A thin layer of the white material is placed on top of a round surface. 
When water reaches the surface, the sodium polyacrylate expands 300 times, producing subtle undulations. 
The profiles of these miniature mountains are projected onto the walls of the gallery using a flashlight 
attached to a rotating mechanism. In 90° South, Borsani attempts to create the experience of a constantly 
changing landscape by building a system with an unpredictable emergent topography. For Borsani, all the 
knowledge of the world is gained from our own particular points of view, or from some experience of the 
world without which the symbols of science would be meaningless. In order to find new possibilities, 
we must begin by reawakening the basic experience of the world of which words are the second-order expression. 
Wonderment is critical, since it allows for continued curiosity to this basic experience and thus creates 
the possibility for change. Borsani s work is an active exploration of the nature of perception and media 
representation in the form of sculptures, installations, and environments. With non-spectacular technologies 
he creates ambiguous moments between the event and the effect so the viewer may experience an instant 
where rational reflection, bodily experimentation, and emotional contemplation become indivisible. He 
is fascinated by the idea of using physical phenomena as the main materials for his installations. Borsani 
s most recent work uses gravity, heat, cold, and chemical reactions to investigate how human beings deal 
with the inorganic, wordless nature of their environments. Alejandro Borsani is currently pursuing an 
MFA at the Rensselaer Polytechnic Institute (USA). He received an MFA in electronic visualization from 
the School of Art and Design of the University of Illinois at Chicago in 2010 and a BA in audio/visual 
design from the School of Architecture, Design and Urbanism of the University of Buenos Aires (Argentina) 
in 2007. His work has been shown in several international venues, including the Museum of Modern Art 
of Buenos Aires (Argentina), the Metropolitan Art Preview Buenos Aires-Berlin, Centro Hipermediático 
Experimental Latinoamericano (Argentina), Collections and Archives of Mess Hall (USA), Gallery 400 (USA), 
Centro Cultural Borges (Argentina), and Albany Underground Artists Athletic Annex Exhibition (USA). 
 Alejandro Borsani Rensselaer Polytechnic Institute alejandrobs@gmail.com www.alejandroborsani.com.ar 
 90° South. &#38;#169; 2010 Alejandro Borsani. &#38;#169; 2012 Alejandro Borsani | Leonardo, Vol. 45, 
No. 4, pp. 376 377, 2012  90° South. &#38;#169; 2010 Alejandro Borsani. 90° South | Alejandro Borsani 
 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2012</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>2341943</article_id>
		<sort_key>120</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>08-05-2012</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[The galloping horse]]></title>
		<page_from>378</page_from>
		<page_to>379</page_to>
		<doi_number>10.1145/2341931.2341943</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=2341943</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P3734357</person_id>
				<author_profile_id><![CDATA[81493644004]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[R&#233;mi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Brun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[remi.brun@mocaplab.com]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Rémi Brun The Galloping Horse The Galloping Horse is created using 18 bright diodes that trace their 
trajectories through a system of steel bars, LEDs, and cables that coincide to create the illusion of 
a moving image of a life-size galloping horse. The work pays homage to the work of Etienne-Jules Marey 
and Eadweard Muybridge, both pioneers at the frontier of art, science, cinema, and biomechanics, who 
were interested in the movement created by galloping horses. Beyond the gallop of the horse, Brun s animated 
sculpture asks viewers to question their own movements, sparking a sense of curiosity and wonderment. 
Rémi Brun holds a PhD in biomechanics and has been working for over 18 years in the field of motion capture 
(mocap) for video games, cinema, dance, and scientific research. He was the mocap specialist behind the 
virtual actress Eve Solal (SIGGRAPH 2000/2001) and the feature film Renaissance (the first mocap movie 
in Europe), as well as many other projects. Through his own company, MocapLab, he continues to push the 
boundaries of motion capture. As an artist, he has come to see movement as a material of its own, independent 
from the matter that comes with it. In his recent projects involving dance, sports, and everyday movements, 
he searches for ways to extract movement from the body matter and to confront it with new appearances. 
 Rémi Brun remi.brun@mocaplab.com www.motion-in-blue.com  The Galloping Horse. &#38;#169; 2012 Rémi 
Brun. Photo &#38;#169; 2011 Stéphanie Sidhu-Brun. &#38;#169; 2012 Rémi Brun | Leonardo, Vol. 45, No. 
4, pp. 378 379, 2012  The Galloping Horse. &#38;#169; 2012 Rémi Brun. Photo &#38;#169; 2008 Hugo Ramirez. 
 The Galloping Horse | Rémi Brun  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2012</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>2341944</article_id>
		<sort_key>130</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>08-05-2012</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[A planetary order (terrestrial cloud globe)]]></title>
		<page_from>380</page_from>
		<page_to>381</page_to>
		<doi_number>10.1145/2341931.2341944</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=2341944</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P3734358</person_id>
				<author_profile_id><![CDATA[81504688068]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Martin]]></first_name>
				<middle_name><![CDATA[John]]></middle_name>
				<last_name><![CDATA[Callanan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University College London]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[m@greyisgood.eu]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Martin John Callanan A Planetary Order (Terrestrial Cloud Globe) A Planetary Order is a terrestrial 
globe depicting clouds from a single moment in time. The globe itself is a physical visualization of 
real-time scientific data. To create the work, Callanan took one second of readings from all six cloud-monitoring 
satellites currently overseen by NASA and the European Space Agency and transformed the information physically 
into outlines and profiles of the clouds that were emerging at that moment across the surface of the 
Earth. The shimmering white cloud globe freeze-frames the entire operation of the global atmospheric 
regime and highlights the fragility of the environmental (and informational) systems that operate across 
the world. Martin John Callanan is an artist whose work spans numerous media and engages both emerging 
and commonplace technology. His work has included translating active communication data into music; freezing 
in time the earth s water system; writing thousands of letters; capturing newspapers from around the 
world as they are published; taming wind onto the internet; and broadcasting his precise physical location 
live for over two years. Callanan s work has been exhibited, published and screened at venues throughout 
Europe, Russia, North America, South America, Asia and Australia. He obtained degrees from both the Birmingham 
Institute of Art and Design (UK) and University College London (UK). Callanan is currently a Teaching 
Fellow in Fine Art Media (Digital Media &#38; Print) at the Slade School of Fine Art, University College 
London (UK).  Martin John Callanan Slade School of Fine Art University College London m@greyisgood.eu 
http://greyisgood.eu  A Planetary Order (Terrestrial Cloud Globe). &#38;#169; 2012 Martin John Callanan. 
 &#38;#169; 2012 Martin John Callanan | Leonardo, Vol. 45, No. 4, pp. 380 381, 2012  A Planetary Order 
(Terrestrial Cloud Globe). &#38;#169; 2012 Martin John Callanan.  A Planetary Order (Terrestrial Cloud 
Globe). &#38;#169; 2012 Martin John Callanan. A Planetary Order (Terrestrial Cloud Globe) | Martin John 
Callanan  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2012</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>2341945</article_id>
		<sort_key>140</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>08-05-2012</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Biopoiesis]]></title>
		<page_from>382</page_from>
		<page_to>383</page_to>
		<doi_number>10.1145/2341931.2341945</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=2341945</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P3734359</person_id>
				<author_profile_id><![CDATA[81372594154]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Carlos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Castellanos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[DPrime Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[carlos@ccastellanos.com]]></email_address>
			</au>
			<au>
				<person_id>P3734360</person_id>
				<author_profile_id><![CDATA[81100476455]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Barnes]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[DPrime Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[sjb@nervouscreation.com]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Carlos Castellanos and Steven J. Barnes Biopoiesis Biopoiesis is a series of experiments exploring 
the relationships between structure, matter, and self-organization. The project features the construction 
of analog computation and control systems that harness electrochemical reactions and form what can be 
described as a computational primordial soup. Information (an electrical signal) is passed through electrodes 
to a tank filled with a metallic salt solution (e.g. stannous chloride). The resultant electrochemical 
reaction grows into dendritic metallic threads ultimately leading to the formation of a continuously 
shifting signal network that can be used to develop a complex, self-organizing media system. Carlos Castellanos 
is an interdisciplinary artist and researcher with interests in embodiment as it relates to systems theory, 
artificial intelligence, and artificial life. He is exploring the aesthetics of information technologies 
and their effects on lived, embodied human experience. This has taken a variety of forms, including scholarly 
writing, net art, interactive installation, sound, performance, and techno-conceptual systems. He is 
currently pursuing a PhD at the School of Interactive Arts and Technology, Simon Fraser University (Canada), 
and splits his time between Vancouver and San Francisco. Steven J. Barnes holds a PhD from the University 
of British Columbia (Canada). Trained as a behavioral neuroscientist, his neuroscientific expertise lies 
in the areas of learning and memory, psychiatric disorders, epilepsy, neuroplasticity, and metaplasticity. 
He currently teaches neuroscience and psychology at UBC; does research in the areas of (non-traditional) 
virtual reality, bodily awareness, and embodied cognition; and runs a consulting and programming business. 
Biopoiesis was developed by Carlos Castellanos and Steven J. Barnes of DPrime Research.  Carlos Castellanos 
DPrime Research carlos@ccastellanos.com Steven J. Barnes DPrime Research sjb@nervouscreation.com http://dprime.org 
 Biopoiesis. &#38;#169; 2011-2012 DPrime Research. &#38;#169; 2012 Carlos Castellanos and Steven J. 
Barnes | Leonardo, Vol. 45, No. 4, pp. 382 383, 2012  Biopoiesis. &#38;#169; 2011-2012 DPrime Research. 
 Biopoiesis | Castellanos and Barnes  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2012</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>2341946</article_id>
		<sort_key>150</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>08-05-2012</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Sustainable cinema no. 4]]></title>
		<subtitle><![CDATA[shadow play]]></subtitle>
		<page_from>384</page_from>
		<page_to>385</page_to>
		<doi_number>10.1145/2341931.2341946</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=2341946</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P3734361</person_id>
				<author_profile_id><![CDATA[81442617926]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Scott]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hessels]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[School of Creative Media, City University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[dshessels@hotmail.com]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Scott Hessels Sustainable Cinema No. 4: Shadow Play The wind-powered Sustainable Cinema No. 4: Shadow 
Play is a kinetic public sculpture that harnesses sus­tainable energy to generate a moving image. By 
using natural power to re-create an early art form that led to the beginnings of cinema, the sculpture 
references the histories of both motion pictures and industrialization. It explores a possible future 
of environmentally responsible media; looking forward by looking back. The Sustainable Cinema is a series 
of artworks that considers alternative systems to create a moving image (as if cinema had continued to 
evolve with sustainable elements instead of being co-opted by the industrial and digital ages). Despite 
the spreading audiovisuality of culture, and finding oneself surrounded by screens, there is rarely an 
understanding of the technology behind them. The sculptures in this series attempt to offer moments where 
the mystery of the moving image can be grasped. They are simple illusions created with simple energy 
that ask viewers to reflect on the original magic of film. It is a primal media experience, which, due 
to the rapid development of cinema technologies, is no longer an oxymoron. Scott Hessels is a filmmaker, 
sculptor, and media artist who explores new relationships between the moving image and the environment. 
His artworks span several media, including film, video, the web, music, broadcast, print, kinetic sculpture, 
and performance. His films have been shown in numerous international film festivals, and his new media 
installations have been presented in exhibitions around the world, included in books on new media art 
and in publications such as Wired and Discover. His recent projects have mixed film with sensors, robotics, 
GPS systems, and alternative forms of interactivity, and have included partnerships with NASA, Federal 
Aviation Administration, and Nokia, among others. He is currently an associate professor at the School 
of Creative Media at the City University of Hong Kong (China). Scott Hessels School of Creative Media 
City University of Hong Kong dshessels@hotmail.com www.dshessels.com  Sustainable Cinema No. 4: Shadow 
Play. &#38;#169; 2011 Scott Hessels. &#38;#169; 2012 Scott Hessels | Leonardo, Vol. 45, No. 4, pp. 384 
385, 2012  Sustainable Cinema No. 4: Shadow Play. &#38;#169; 2011 Scott Hessels. Sustainable Cinema 
No. 4: Shadow Play | Scott Hessels  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2012</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>2341947</article_id>
		<sort_key>160</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>08-05-2012</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[The HeartBeats watch]]></title>
		<page_from>386</page_from>
		<page_to>387</page_to>
		<doi_number>10.1145/2341931.2341947</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=2341947</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P3734362</person_id>
				<author_profile_id><![CDATA[81498658542]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Julie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Legault]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[julie@julielegault.com]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Julie Legault The HeartBeats Watch Stretching or shrinking hours at the beat of your heart, The HeartBeats 
Watch is a timepiece in which the duration of time is paced not by seconds but according to the wearer 
s heartbeat. Through a heightened awareness of self, The HeartsBeats Watch brings together art and science 
to reveal emotional complexity of time and the human body. A poetic investigation of the physiology of 
emotions, health, immortality and control, the watch bridges the gap between society and medical science, 
invoking a broader cultural perception of life. Through the premise of accessories and jewelry as providers 
of superpowers and the idea of objects of comfort, Julie Legault explores the possible futures of accessories 
through technology, function, and fantasy, using the premise of technology as magic to combine materials 
and circuitry, creating wearable wonders. Her current research concerns the relationships that mentally 
and emotionally disabled individuals have with objects and accessories. Working from the outside in, 
she hopes not only to understand and improve these relationships and their impact on the individual s 
social presence, but also to distill the essence of these relationships to benefit a wider audience, 
adding some missing magic along the way. To avoid the impending under the skin aspect of hybridization, 
Legault s work also explores the ethics and obsolescence of consumer culture by providing insights and 
tools for self-awareness and wonder. Julie Legault is an interdisciplinary designer. She was born in 
Montréal, Canada, and lives and works in London, UK. She received her BA from Concordia University (Canada) 
where she studied design, art, and digital technologies. In 2011, she received an MA in Goldsmithing, 
Silversmithing, Metalwork, and Jewelry at the Royal College of Art, London (UK). Having worked with Moritz 
Waldemeyer, Joanna Berzowska, and the V2_Unstable Media Lab in Rotterdam, she recently presented her 
work on wearable wonders (the results of her ongoing research in the hybridization of humans and machines) 
in Europe and North America, notably at the Victoria &#38; Albert Museum (UK), ISEA 2011 (Turkey), and 
TEI 2012 (Canada). Julie Legault julie@julielegault.com www.julielegault.com  The HeartBeats Watch. 
&#38;#169; 2011 Julie Legault. &#38;#169; 2012 Julie Legault | Leonardo, Vol. 45, No. 4, pp. 386 387, 
2012  The HeartBeats Watch. &#38;#169; 2011 Julie Legault.  The HeartBeats Watch. &#38;#169; 2011 Julie 
Legault. Photo &#38;#169; 2011 V2_Institute of the Unstable Media. The HeartBeats Watch | Julie Legault 
 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2012</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>2341948</article_id>
		<sort_key>170</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>08-05-2012</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[SymbiosisS]]></title>
		<page_from>388</page_from>
		<page_to>389</page_to>
		<doi_number>10.1145/2341931.2341948</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=2341948</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P3734363</person_id>
				<author_profile_id><![CDATA[60000000145]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[K&#228;rt]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ojavee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Estonian Academy of Arts]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[k2rt@piafraus.com]]></email_address>
			</au>
			<au>
				<person_id>P3734364</person_id>
				<author_profile_id><![CDATA[60000000146]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Eszter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ozsvald]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[New York University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[eszter@fiveyearstobefamous.com]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Kärt Ojavee and Eszter Ozsvald SymbiosisS SymbiosisS is part of a collection of textile interfaces, 
SymbiosisO ( O for objects), which behave as organic displays and react to definable impulses by showing 
pre-defined patterns that animate slowly over the surface. It welcomes viewers to sit and rest on soft-folded 
material that displays an active, slowly shifting pattern. When excited, the pattern starts forming, 
in a playful, curious way, around the place where the textile was touched. Once the disturbance is abated, 
the pattern continues its peaceful expansion. This vivacious interaction of a vibrant pattern is a demonstration 
of the potential for tangible textile interfaces. Ubiquitous computation an active, programmable secondary 
skin to surround everyday objects is an ambient, noiseless, and thus vigorous way to visualize information 
and form space. Production of SymbiosisS involves both handicraft and specialized digital fabrication. 
Electronics that activate a heat-sensitive coating layer are embedded in the soft structure. The substrate 
is felt, which has exceptional material properties (sound isolation, heat preservation, biodegradable, 
etc.). The geometry of the patterns is derived from Voronoi tessellation algorithms, which, in this case, 
intuitively suggest folding the material into a three-dimensional landscape. The general concept of the 
work is a tribute to the ultimate power of evolution, where not only human civilization affects the environment, 
but nature itself also reacts and adapts to these changes. Instead of criticizing civilization s impact 
on the environment, the emphasis focuses on exploration of new types of mutant living beings. Kärt Ojavee 
is an Estonian designer and researcher who has been working on active and interactive textiles since 
2004. Currently, she is working with the Centre for Biorobotics (Estonia) to create interactive textiles 
for waiting rooms. The focus in her textile designs is on patterns and new approaches to materials. Eszter 
Ozsvald is a Hungarian designer, technologist, and media artist based in New York. Currently, she is 
enrolled in New York University s Interactive Telecommunications Program (USA), where she continues to 
seek creative interdisciplinary applications with a technological edge. Kärt Ojavee Estonian Academy 
of Arts k2rt@piafraus.com Eszter Ozsvald Interactive Telecommunications Program New York University eszter@fiveyearstobefamous.com 
www.symbiosiso.com  SymbiosisS. &#38;#169; 2011 Kärt Ojavee and Eszter Ozsvald. Photo &#38;#169; 2011 
Eszter Ozsvald. &#38;#169; 2012 Kärt Ojavee and Eszter Ozsvald | Leonardo, Vol. 45, No. 4, pp. 388 389, 
2012  SymbiosisS. &#38;#169; 2011 Kärt Ojavee and Eszter Ozsvald. Figure &#38;#169; 2011 Kärt Ojavee. 
 SymbiosisS. &#38;#169; 2011 Kärt Ojavee and Eszter Ozsvald. Photo &#38;#169; 2011 Eszter Ozsvald. 
SymbiosisS | Ojavee and Ozsvald  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2012</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>2341949</article_id>
		<sort_key>180</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>08-05-2012</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Coronado]]></title>
		<page_from>390</page_from>
		<page_to>391</page_to>
		<doi_number>10.1145/2341931.2341949</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=2341949</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P3734365</person_id>
				<author_profile_id><![CDATA[81504687144]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kian-Peng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Los Angeles]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[bin@ctrlsave.com]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Kian-Peng Ong Coronado Coronado is a six-channel sound installation in which an ocean drum is controlled 
by autonomous mechanical arms, creating a feedback loop that bounces sound waves and produces a spatial 
interpretation of the beach s soundscape. A sense of wonder and awe is at the heart of Coronado, which 
was inspired by the artist s personal encounter with the Coronado beach in California, where he found 
beauty appearing and disappearing in all directions. Kian-Peng Ong (a.k.a. Bin) works across a range 
of media that include software, electronics, sound, and video. For the past five years, he has been using 
new media as a means to question and transcode human perception and understanding of the environment 
and the problems associated with it. Kian-Peng Ong s works are very often a result of his personal experiences 
and encounters with the world. Kian-Peng Ong is a new media artist based in Los Angeles. He received 
his BA (interactive arts) from Lasalle College of the Arts (Singapore). Currently, he is a graduate student 
in the UCLA Design | Media Arts program (USA). His interest in sound stems from its abstract yet powerful 
affective qualities. Of equal interest to him, and a focus of one of his ongoing research projects, is 
the human relationship with nature, specifically how humans adapt or perceive environmental changes. 
Technology often plays a central role in his work, creating an experience, harmonizing with the theme 
and conceptual framework, without focusing the work on the technology itself. Kian-Peng Ong University 
of California, Los Angeles bin@ctrlsave.com http://news.ctrlsave.com  Coronado. &#38;#169; 2012 Kian-Peng 
Ong. &#38;#169; 2012 Kian-Peng Ong | Leonardo, Vol. 45, No. 4, pp. 390 391, 2012  Coronado. &#38;#169; 
2012 Kian-Peng Ong.  Coronado. &#38;#169; 2012 Kian-Peng Ong. Coronado | Kian-Peng Ong  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2012</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>2341950</article_id>
		<sort_key>190</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>08-05-2012</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Tardigotchi]]></title>
		<page_from>392</page_from>
		<page_to>393</page_to>
		<doi_number>10.1145/2341931.2341950</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=2341950</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P3734366</person_id>
				<author_profile_id><![CDATA[81504688260]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Swamp]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Michigan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[mattckenyon@gmail.com]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SWAMP Tardigotchi Tardigotchi is an artwork featuring two pets: a living organism and an alife avatar. 
These two disparate beings find themselves the unlikely denizens of a portable computing enclosure. The 
main body for this enclosure is a brass sphere, housing the avatar in an LED screen and a tardigrade 
within a prepared slide. A tardigrade is a common microorganism measuring half a millimeter in length. 
The avatar is a caricature of this tardigrade; the avatar's behavior is partially autonomous, but it 
also reflects a considerable amount of expression directly from the tardigrade s activities. This portable 
sphere playfully references the famous Tamagotchi toy from the 1990s that provoked the artists to ask 
questions such as: Does simple interaction engender emotional attachment? Can feelings of affection blossom 
from the ritual of assisting the persistence of a pattern? Does biological life make a difference? A 
Tardigotchi owner cares for a real and a virtual creature simultaneously. By pushing a button, the virtual 
pet is fed, this in turn will feed the tardigrade. An owner may also attend to the Tardigotchi online 
through a social web presence. Sending an email to the virtual character triggers a heating lamp, relaying 
a momentary signal of warmth to the tardigrade, while prompting the pixilated tardigrade to recline and 
soak up animated sunrays. Tardigotchi applies a salve to our yearnings for care and nurture through a 
unique design that symbiotically merges biological and artificial life within a single interface/enclosure. 
It also serves as a reminder of the special inclination humans have to commune with other animals, perhaps 
equally with artificial ones. Humans, along with the inhabitants of Tardigotchi, and every other living 
being, are neighbors subsisting on an incredibly precarious life-sphere known as Earth. SWAMP (Studies 
of Work Atmosphere and Mass Production) is the collaborative effort of artists Matt Kenyon and Douglas 
Easterly with Tiago Rorke. Their work focuses on critical themes addressing the effects of global corporate 
operations, mass media and communication, military industrial complexes, and general meditations on the 
liminal area between life and artificial life. SWAMP has been making work in this vein since 1999, using 
a wide range of media, including custom software, electronics, mechanical devices, and living organisms. 
 SWAMP School of Art and Design University of Michigan mattckenyon@gmail.com www.swamp.nu  Tardigotchi. 
&#38;#169; 2012 SWAMP. Photo &#38;#169; 2012 SWAMP + Tiago Rorke.  &#38;#169; 2012 SWAMP | Leonardo, 
Vol. 45, No. 4, pp. 392 393, 2012 392  Tardigotchi. &#38;#169; 2012 SWAMP. Photo &#38;#169; 2012 SWAMP 
+ Tiago Rorke.  Tardigotchi. &#38;#169; 2012 SWAMP. Photo &#38;#169; 2012 SWAMP + Tiago Rorke.  Tardigotchi 
| SWAMP 393  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2012</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
</content>
</proceeding>
